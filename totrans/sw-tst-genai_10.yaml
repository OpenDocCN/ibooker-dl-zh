- en: 9 AI agents as testing assistants
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how AI agents can be built using LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a basic AI agent to demonstrate their value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over the previous few chapters, we saw how large language models (LLMs) can
    assist us in testing. We also learned how to employ various prompt techniques
    to get the most out of LLMs and curate different prompts that can be utilized
    when required. This is a great position to be in, but what if we could take our
    new understanding one step further to create custom-made AI testing assistants?
  prefs: []
  type: TYPE_NORMAL
- en: As LLMs have advanced, so have the opportunities to create AI agents, applications
    that can take a goal and autonomously interact with other systems, collect data,
    analyze information, and adapt a suitable response to achieve said goal. In the
    field of AI, an agent can be implemented in many ways, but the goal tends to be
    the same—to create something that we can give a task to be solved. The scope of
    designing and building AI agents is large, but in this chapter, we’ll learn a
    bit more about their potential and how they work in the context of generative
    AI. We’ll also create our own basic test data AI agent to demonstrate the power
    and potential of this technology.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Understanding AI agents and LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we discuss AI agents, we need to specify what we mean. AI agents can be
    implemented in different ways, depending on the field of AI we are working in.
    But that’s not to say that there aren’t expected behaviors of an agent regardless
    of how it works. So, before we begin to implement our agents, let’s first define
    what these expected behaviors might look like and then how agents might be built
    in the context of generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.1 What defines an AI agent?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To comprehend what defines an agent, we have to focus more on the characteristics
    that are imbued within it than on its implementation. There is no explicit list
    of characteristics an agent is expected to meet, but the following attributes
    are usually found:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Being goal-driven*—An agent must be able to receive a goal that it can ultimately
    achieve. The goal itself can be something that is either specific, such as “Make
    me a hotel booking for X,” or more abstract, such as “Determine the most successful
    stock to buy next month based on current trends.” Regardless of the scope of the
    goal, some sort of direction is required to help us evaluate whether the actions
    an agent is taking are bringing it closer to completing its task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Being perceptive—*An agent must also be able to interact with the wider world.
    This might mean extracting information, or interacting with a system to produce
    results. Examples might include making an HTTP request to a web API to get data
    for processing or running web automation code to complete a booking form. Whatever
    we want our agent to achieve, we have to give it the ability to interact with
    the world outside so that it can solve problems for us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Have autonomy*—Perhaps most crucially, an agent must be able to autonomously
    decide how a problem is solved. Instead of following a clear, algorithmic path
    that we set out, it can pick and choose what tasks to do and in what order. This
    is where the core element of an agent is usually found. By evaluating the goal
    it has been given, it can interact with the world, carry out tasks, and evaluate
    whether said tasks align with the goal it’s been set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Being adaptive*—Finally, agents must also be able to learn from actions. For
    example, agents that can complete video games do so by learning from the mistakes
    they make. But it can just mean reacting to specific information that is retrieved
    at a given point in time. Much like in autonomy, the goal that has been set plays
    a role in determining if an agent has been successful when carrying out a specific
    task. If it has not, we want our agent to be able to react to that failure not
    to repeat it or to work around it to achieve its set goal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is not an exhaustive list of characteristics. Depending on the problem
    an agent is being asked to solve will determine which characteristics matter more.
    However, the examples provided give us a sense of what an AI agent might look
    like and how it behaves. Thus, an agent is an autonomous piece of software thar
    can be given a relatively complex task and solve it for us.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.2 How an agent works with LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So, how are these characteristics created when using LLMs to drive an agent?
    The answer is, “through the use of an LLM feature called *function calling*,”
    which allows us to encapsulate code into functions that an LLM can trigger for
    us when it is prompted to complete a task. To help us better understand this process,
    figure 9.1 outlines the general process of how function calling works.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH09_F01_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 An outline of an LLM agent using function calling
  prefs: []
  type: TYPE_NORMAL
- en: As described in the figure, function calling works by providing both a prompt
    and encapsulated code to an LLM. The LLM can then determine which function to
    run to achieve the goal set within our prompt. Inside each function, there will
    be code built by us that will process information or interact with the outside
    world in some shape, form, or manner. For example, a function might extract data
    from a web API, scrape a web page, or gather information from a sensor. A function
    may also be sent parameters from the LLM to apply further processing on received
    data before sending it back to the LLM for future use.
  prefs: []
  type: TYPE_NORMAL
- en: What gives our agents their autonomous characteristic is an LLM’s ability to
    determine which functions are called when and with what data. Each function we
    create is provided with some additional instructions to help the LLM determine
    what our code within the function does. When given a task to complete, the LLM
    can process the initial prompt, select the right function to call first, and store
    any information that is returned by a function into the prompt itself.
  prefs: []
  type: TYPE_NORMAL
- en: This autonomy is what distinguishes an agent from a tool that executes an ordered
    list of functions that interacts with different APIs or services. An agent may
    be given a large collection of various functions that process information and
    interact with the world in different ways, utilizing only the necessary functions
    to solve a problem.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Creating an AI Test Assistant
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have a grounding in what agents are and how they work in the context
    of generative AI, let’s build our own. For this example, we’ll be building an
    AI agent that will read and create data for us when given instructions. This might
    feel like a somewhat simple agent, but to get into more advanced topics around
    agents would require another whole book. However, with this example, we’ll get
    a better understanding of how an agent can be built with the use of LLMs so that
    we can take both our prompt engineering and agent building to the next level.
    We’ll go through the process of creating our AI agent step by step, but you can
    check our completed version for reference at: [https://mng.bz/aVlJ](https://mng.bz/aVlJ).'
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Setting up our dummy AI agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We begin by creating a Maven project, and within our `pom.xml` file, we add
    the following dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Functions to quickly connect to OpenAI platform
  prefs: []
  type: TYPE_NORMAL
- en: ❷ AI services to create our AI agent
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Database to manipulate with our agent
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll be using LangChain4J (h[ttps://docs.langchain4j.dev](https://docs.langchain4j.dev))
    to manage both the communication with our LLM and the necessary functions we want
    our agent to execute. This will become clearer when we implement said functions,
    but first, let’s establish our connection to LLM by creating a new class called
    `DataAssistant` with a `main` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can update the class with the necessary code to send a basic prompt
    to a gpt-3.5-turbo model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Creates an interface to add our AI services into
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Sets up access to our OpenAI model and model preference
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Uses AiServices.builder to add our model to our DataAssistantService
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Sends a basic prompt to OpenAI, stores the response, and outputs it
  prefs: []
  type: TYPE_NORMAL
- en: 'The `OpenAiChatModel` portion of the code establishes which model we want to
    connect and our authorization method. Within the `.apiKey` method, we provide
    an API key from OpenAI that can be generated via their API keys page found at
    [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys).
    We then provide the model as a parameter when setting up our `DataAssistantService`
    using the `AiServices` library. This lets us keep our model choice and our AI
    services separate, allowing us to easily change the model we want to use. The
    `DataAssistantService` interface helps to configure the method we want to use
    to send our prompt, as well as add other advanced features if we desire, such
    as system prompts that contextualize the user prompts that we want to send once
    our service is established. We’ll start to see how `AiServices` comes into its
    own shortly, but for now, we can test our implemented code out by running it and
    getting a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Hello, I am a language model AI assistant created by OpenAI. I am here to
    help answer your questions and assist you with any information you may need. How
    can I help you today? |'
  prefs: []
  type: TYPE_TB
- en: 'Now that we are connected to our LLM, we can begin to build out the tasks we
    want our agent to trigger to give our assistant some agency. To do this, we create
    a new class called `DataAssistantTools` and add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ve now created three functions that our LLM can choose to trigger when prompted.
    But how does the LLM determine which function to trigger at a given time? This
    is achieved by using the `@Tool` annotation provided by `LangChain4J`. The `@Tool`
    annotation not only identifies what method to trigger, but also indicates to the
    LLM in natural language what the code does, so that the LLM can determine if it’s
    a function that is worth calling. For example, our first tool has the annotation
    `@Tool("Create` `room records")`. If we send a prompt to our LLM, along with our
    tool, asking it to create some rooms, then the LLM will determine that our tool
    should be executed. If we were to send a prompt with an entirely different message,
    then the tool might not be used. We’ll see this in action shortly, but first,
    let’s update our `AiServices` builder so that it incorporates our newly created
    `DataAssistantTools`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Adds our tools via the tools() method within the builder
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Sets up a Scanner to keep the app running and receive prompts
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the `AiServices` builder begins to demonstrate its value by allowing
    us to set both the model we want to use and the tools we want the agent to use.
    We’ve also updated our means of inputting prompts so that the application stays
    up and running continuously and we can test out our new agent with different instructions.
    So, when we run the agent and are asked
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: 'we can submit our prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Can you create me 4 rooms and 2 bookings and tell me what’s in the db |'
  prefs: []
  type: TYPE_TB
- en: 'to be returned the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You want me to create 4 rooms.You want me to create 2 bookings.I’ll then
    share current database details |'
  prefs: []
  type: TYPE_TB
- en: Let’s break down how this output has been generated. First, we’ve sent our prompt
    and tools to gpt-3.5-turbo to process. The model then evaluates the details of
    the prompts and looks through the list of tools we’ve tagged using the `@Tool`
    annotation to find which tools are relevant to our instructions. At the start
    of the prompt, we requested “Can you create me 4 rooms,” and the LLM has determined
    that our `createRooms` tool should be run because of its relevance to the annotation
    `@Tool("Create` `room records")`. Next, we can see that the output correctly stated
    that we want to create four rooms. This is because we passed a parameter into
    our `createRooms` method using LangChain’s `@P` annotation in the form of `@P("Amount`
    `of` `room` `records` `to` `create") int` `count`. Notice how we provide natural
    language context again to the `@P` annotation in a similar fashion to the `@Tool`
    annotation. This allows the LLM to do a similar relevancy match, extract what
    it believes is the necessary data from our prompt, and provide it as a parameter
    to be output.
  prefs: []
  type: TYPE_NORMAL
- en: We can now also test our agent’s ability to determine which tool to use autonomously
    by giving it different instructions. This time, when asked for a prompt, we sent
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Can you tell me what’s in the database currently |'
  prefs: []
  type: TYPE_TB
- en: 'Running this would return the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| I’ll then share current database details |'
  prefs: []
  type: TYPE_TB
- en: In this case, the LLM has triggered only one of our tools, specifically `displayDatabase`
    annotated as `@Tool("Show` `results` `of` `database")`. Since we’ve not mentioned
    creating rooms or bookings in our prompt, the related tools are deemed not relevant
    to our instructions and are therefore ignored. This demonstrates the power of
    agents. Imagine if we had not just 3 tools, but 10, 20, or more. The more we add,
    the more ways we give an agent the ability to react to our instructions and solve
    our requested problems.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 Giving our AI agent functions to execute
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have the decision-making process wired up, so now let’s complete our agent
    and give it the ability to carry out some database queries for us. For this, we’re
    going to create a dummy database using `h2` with some basic tables to demonstrate
    how we can have our LLM execute actions for us. To do this, we’ll start by creating
    a new class `QueryTools` and adding the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ❶ On startup, creates a database with the necessary tables
  prefs: []
  type: TYPE_NORMAL
- en: ❷ A basic method to create rooms
  prefs: []
  type: TYPE_NORMAL
- en: ❸ A basic method to create bookings
  prefs: []
  type: TYPE_NORMAL
- en: ❹ A basic method to output the contents of each table
  prefs: []
  type: TYPE_NORMAL
- en: 'With our `QueryTools` class created, we can then expand our tools to interact
    with the database how we like by updating `DataAssistantTools`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ❶ Creates a new instance of our database on startup
  prefs: []
  type: TYPE_NORMAL
- en: ❷ Creates rooms by looping through the number of rooms requested
  prefs: []
  type: TYPE_NORMAL
- en: ❸ Creates bookings by looping through the amount of bookings requested
  prefs: []
  type: TYPE_NORMAL
- en: ❹ Outputs the contents of each table
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we update our `main` method within our `DataAssistant` class to handle
    `SQLException`, resulting in the following completed code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'With everything in place, we can now test the agent by first requesting it
    create our desired data:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create me 2 rooms and 3 bookings |'
  prefs: []
  type: TYPE_TB
- en: 'It then results in a response such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Two rooms and three bookings have been successfully created. |'
  prefs: []
  type: TYPE_TB
- en: We can then confirm that our data has been created by sending additional instructions
    to the agent
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| List me the database contents |'
  prefs: []
  type: TYPE_TB
- en: resulting in an output that looks similar to
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Current ROOM database state:101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100Current BOOKING database state:1 James Dean TRUE
    2022-02-01 2022-02-051 James Dean TRUE 2022-02-01 2022-02-051 James Dean TRUE
    2022-02-01 2022-02-05 |'
  prefs: []
  type: TYPE_TB
- en: With our database queries now wired into our tools, we can interact with our
    agents and have them carry out our tasks. However, let’s go one step further with
    our agent and give it the capability to run multiple tools in a chain, utilizing
    data created in one tool in another.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.3 Chaining tools together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Currently, our tools are independent of one another. The room tool creates rooms
    that generate unique `roomid` keys for each row, but we’re not using them when
    we create new bookings. We’re simply hardcoding our values. So, to make our agent
    more dynamic, and to give it a more complex problem, let’s look at how we could
    pass the `roomid` of the most recently created room to the booking tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we need to create an additional method in our `QueryTools` class
    that will either return the `roomid` of the most recently created room or an `id`
    of `0` if there are no rooms currently in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With our new method in place, we next create a new tool with `DataAssistantTools`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how we have set out within the `@Tool` annotation that we expect this
    prompt to be run after rooms have been created. Although this doesn’t guarantee
    the order in which tools are run by our LLM, it acts as a guardrail if we want
    rooms and bookings to be created in a specific order. Additionally, we are returning
    the `roomid` integer to the LLM. This is then stored in the context of our original
    prompt for future use, which we’ll establish by updating our `createBookings`
    method to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In this updated method, we’ve added a new parameter in the form of `@P("Most
    recent` `roomid")` `int` `roomid`. To see the `roomid` extraction in action, we
    `System.out` the `roomid` before passing it `createBooking` for use in our `INSERT`
    statement. To use the `roomid`, we return to `QueryTools` and update the `createBooking`
    method to take `roomid` as a parameter and add it to our SQL statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have the code in place for our agent to extract the `roomid` from our
    database using one tool and then use that value within a second tool, which we
    can see in action in this example chat I had with my version of our agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create three rooms |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Three rooms have been successfully created. |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| List database |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Current ROOM database state:101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100Current BOOKING database state:The database has
    been successfully displayed. |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create three bookings |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| I will create the bookings for room: 3Current ROOM database state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Current BOOKING database state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Three bookings have been successfully created. |
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down the output, we can see that three rooms were created, which we
    confirm by asking the agent to list the current rooms. Then the agent was asked
    to create three bookings, which it did successfully. Notice the second integer
    on each row underneath `Current` `BOOKING` `database` `state:`. See how they are
    now using the `roomid:` `3`. The agent has successfully utilized both tools to
    query the most recent `roomid` before passing the retrieved `id` to the second
    tool that creates our bookings for us. We can confirm this isn’t a coincidence
    by creating further rooms to confirm that a newer, more recent `roomid` is added
    to the additional bookings we create (in this example, `roomid` ticks up to `6`).
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create three more rooms |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Three rooms have been created successfully. Here is the updated database:
    |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create three more bookings |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| I will create the bookings for room: 6Three bookings have been successfully
    created. |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What do you need? |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| List database |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Current ROOM database state:101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100101 single 1 TRUE /images/room2.jpg A generated
    description [TV, WiFi, Safe] 100Current BOOKING database state:3 James Dean TRUE
    2022-02-01 2022-02-053 James Dean TRUE 2022-02-01 2022-02-053 James Dean TRUE
    2022-02-01 2022-02-056 James Dean TRUE 2022-02-01 2022-02-056 James Dean TRUE
    2022-02-01 2022-02-056 James Dean TRUE 2022-02-01 2022-02-05 |'
  prefs: []
  type: TYPE_TB
- en: This completes our basic data creator agent. We’ve looked at how we can create
    multiple tools for an agent to use and solve specific requests for us. These tools
    allow us to give an agent the ability to interact with the world around us. For
    example, we could create code to extract relevant data from a data source, connect
    to sensors or IoT (Internet of Things) devices, or interact with external websites.
    We’ve also seen how the results of those interactions with third parties can be
    fed back into our LLM for it to determine what next steps to take, as well as
    utilize extracted information for further use.
  prefs: []
  type: TYPE_NORMAL
- en: Activity 9.1
  prefs: []
  type: TYPE_NORMAL
- en: Consider different ways in which this agent could be expanded to do further
    data assistant tasks. Perhaps it could delete or update data or carry further
    analysis on what exists with the example database. Alternatively, consider building
    an agent that carries out other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3 Moving forward with AI test assistants
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our test data assistant demonstrates the potential of AI agents as tools that
    can help support testing activities. We can see AI agents as an approach to use
    when we reach a point where our prompts become too complicated, or we want to
    extend them to interface with third-party systems. It’s important, however, to
    have a clear sense of both the opportunities and the challenges of developing
    AI agents. So, let’s reflect on the various areas of testing we’ve used LLMs to
    support us in, the way AI agents could be designed to take our prompts further,
    and what problems might await us.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.1 Examples of AI test assistants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve already seen how an AI agent could help extend the use of LLMs in the
    test data space. But to help tie it all together, here are some examples of other
    types of AI agents that would take our prompts and LLM work further.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis AI agents
  prefs: []
  type: TYPE_NORMAL
- en: We’ve learned how LLMs can help us expand our thinking, suggesting ideas and
    risks that we might not have considered. As AI agents can be connected to a range
    of data sources, an AI agent that enhances our suggestion prompts could be built
    into an assistant that offers suggestions based on collated information across
    a business domain. For example, we might have an agent like the one shown in figure
    9.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH09_F02_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 An AI agent connected to multiple data sources
  prefs: []
  type: TYPE_NORMAL
- en: An AI agent such as this one would be able to determine what data sources to
    access based on the instructions given. It might be able to pull in relevant documentation
    from knowledge bases and project management tools or raw data from monitoring
    and analytics tools. All this collated data can then be used to improve responses
    from the LLM when asked a question, a topic we’ll explore more in the following
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Automation assistant AI agents
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at how LLMs are most effective in the test automation space if
    we create prompts that focus on specific tasks when building automation. That
    said, an AI agent’s potential to interact, parse, and share information across
    tools means that we could create an agent like the one in figure 9.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH09_F03_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 An AI agent that processes information in different ways
  prefs: []
  type: TYPE_NORMAL
- en: An AI agent such as this one would be able to build the parts of automated tests
    in sections. The built sections could then be passed to other tools to be utilized
    in various ways. This doesn’t mean that these types of agents could still fully
    create valuable automation in one shot. Context, again, is an important factor
    that would need to be fed into these types of AI agents to enable them to embed
    rules and expectations into our automation that align with how our product works.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory testing AI Agents
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in this example, we’re not suggesting that the AI agent could do the
    exploratory testing for us, but an AI agent might prove useful as an assistant
    to the person testing, as shown in figure 9.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH09_F04_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 An AI agent that takes relevant information and uses additional prompts
    to build suggestions
  prefs: []
  type: TYPE_NORMAL
- en: Notice how, in the AI agent, we’re creating an assistant that takes an initial
    prompt and then fires off further prompts to an LLM to help develop valuable suggestions.
    Since AI agents can interact with any system via its tools, there’s no reason
    an AI agent couldn’t interact with an LLM as well. The agent in this example helps
    to parse initial instructions and then use them to determine which further prompts
    could be utilized, creating a cascade of different prompts being triggered to
    create some interesting outputs.
  prefs: []
  type: TYPE_NORMAL
- en: These are, of course, just hypothetical AI agents, but each example demonstrates
    that their success is rooted in the types of prompts created for the instructions
    an agent receives and the prompts assigned to each tool. Our data agent example
    had only rudimentary prompts, but it is in those spaces where we can provide the
    expectations, parameters, and context to each tool to help an AI agent react in
    a way that proves valuable to us.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.2 Handling the challenges of working with agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: However, it’s not to say that building, using, and maintaining agents comes
    without its challenges. Here are a few challenges that need to be kept in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Examining an LLM’s decision-making process
  prefs: []
  type: TYPE_NORMAL
- en: Unsurprisingly, one of the biggest challenges with developing agents is their
    indeterministic nature. There’s a good chance that, as you worked through the
    example agent in this chapter, you experienced the agent either not executing
    tools when expected or creating more or fewer data than required. The LLM component
    of an agent that determines what to run and what data to share between tools is
    opaque to us. In our example agent, we are using a third-party LLM, meaning we
    have no insight into its decision-making process. Nor do we have any ability to
    monitor its behavior or control how the LLM is tuned and operates. This lack of
    control and observability can become a major risk in developing agents. As they
    grow in complexity, not only can they become more brittle, but we also have little
    insight into what went wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Some steps can be taken to mitigate this risk. We could host models on our platforms
    and increase observability. But while this might give us more insights into what
    decisions were made and when by an LLM, it still doesn’t mean we can guarantee
    the outcome of an agent’s responses.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating guard rails and security concerns
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to the second problem when using agents: ensuring that we have
    the necessary prompts and code in place to handle situations in which an agent
    may hit an edge case, as well as preventing bad actors from using our agents to
    negatively affect our business or others. Utilizing good prompting techniques
    in outlining the purpose of each tool and adding checks and balances to help our
    agent reject invalid or undesirable requests is a must, but that means identifying
    those potential scenarios and implementing guard rails for them. The upshot is
    that agents require extensive testing and evaluation, which can come at a cost
    that outweighs the initial value of using them in the first place.'
  prefs: []
  type: TYPE_NORMAL
- en: Managing when things go wrong
  prefs: []
  type: TYPE_NORMAL
- en: That said, despite our best efforts, there will be times when an agent does
    something wrong. Either tools are run in an incorrect order, data isn’t passed
    between tools successfully, or the code within our tools has bugs. In the context
    of our example agent, these potential errors will be swallowed up by the OpenAI
    platform. When I first developed the example agent, it was throwing exceptions
    as the JDBC library failed, and the exceptions were consumed by the agent, which
    triggered all sorts of unusual behavior. In one example, the JDBC code failed
    in a way that caused the agent to continue attempting to create new records, repeatedly
    firing the broken function, to the point at which the whole agent crashed as it
    hit a limit in the amount of function calls it could carry out. The problem was
    that this exception wasn’t shared with me, making the debugging of the problem
    difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Again, observability and monitoring are essential, as well as ensuring our code
    is written defensively against potential exceptions or errors. If we don’t catch
    and report them, then they are hidden, leading to wasted time trying to debug
    what was wrong in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, agents promise the potential of making us, the individual, more
    efficient by supporting us in task completion. Given the autonomous abilities
    of agents, it can be easy to buy into the hype of their potential. But just like
    any software we seek to utilize, its creation, use, and maintenance come with
    a cost. Similarly, like all software, it’s not a silver bullet for all our problems.
    To use agents successfully, we need to take the time to consider the problem we
    are attempting to solve. At times, agents may be of use to us, but other options
    such as a well-crafted prompt might do the work just as well, or we might have
    better success with other non-AI-based tools. In the end, agents are just another
    addition to our tool belt to employ when the time is right.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI agents exist in many different fields of artificial intelligence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI agents are expected to be goal-driven, able to perceive the wider world,
    autonomous, and adaptable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agents within the context of LLMs are created using function calling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function calling is achieved by providing a prompt and code grouped into functions
    that an LLM can call to achieve a goal within a prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function calling can be used to interact with other sites and services, feeding
    information back to the LLM for further processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LangChain4J is a useful library for easily connecting to LLM platforms and managing
    AI services such as tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can create tools using the `@Tool` annotation, which helps the LLM match
    up our instructions to which method to run and when.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We pass extracted values from our prompt into methods as parameters using the
    `@P` annotation, which works similarly to the `@Tool` annotation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agents can also send data between tools by returning data out of a method and
    using the `@P` annotation to pull the data in as a parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When agents fail to carry out tasks or an error occurs, it can be hard to detect
    what went wrong.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are opaque when it comes to decision-making, which can also make debugging
    problems challenging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing agents to a wider user base means they require guard rails in place
    to prevent agents from either not fulfilling tasks or being vulnerable to bad
    actors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
