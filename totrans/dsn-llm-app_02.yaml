- en: Chapter 1\. Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章. 简介
- en: AI is no longer the realm of science fiction novels and dystopian Hollywood
    movies. It is fast becoming an integral part of people’s lives. Most of us interact
    with AI on a daily basis, often without even realizing it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能不再是科幻小说和反乌托邦好莱坞电影的领域。它正迅速成为人们生活的一个基本组成部分。我们大多数人每天都在与人工智能互动，有时甚至没有意识到这一点。
- en: Current progress in AI has to a large extent been driven by advances in language
    modeling. Large language models (LLMs) represent one of the most significant technological
    advances in recent times, marking a new epoch in the world of tech. Similar inflection
    points in the past include the advent of the computer that ushered in the digital
    revolution, the birth of the internet and the World Wide Web that laid the foundation
    for a hyperconnected world, and the emergence of the smartphone that reshaped
    human communication. The ongoing AI revolution is poised to make a similar transformative
    impact.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能当前的进步在很大程度上是由语言模型方面的进步所驱动的。大型语言模型（LLMs）代表了最近时期最重大的技术进步之一，标志着科技界的一个新时代。过去类似的转折点包括计算机的诞生，它引领了数字革命，互联网和万维网的诞生，为超连接的世界奠定了基础，以及智能手机的出现，重塑了人类沟通方式。正在进行的AI革命有望产生类似的变革性影响。
- en: LLMs belong to a class of models referred to as generative AI. The distinguishing
    factor is the ability of these models to generate responses to user queries, called
    *prompts*. Generative AI encompasses models that generate images, videos, speech,
    music, and of course text. While there is an increasing focus on bringing all
    these modalities together into a single model, in this book we will stick to language
    and LLMs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs属于一类被称为生成式AI的模型。区分因素是这些模型能够对用户查询生成响应，称为*提示*。生成式AI包括生成图像、视频、语音、音乐，当然还有文本的模型。虽然越来越关注将这些所有模态结合到一个单一模型中，但在本书中，我们将坚持语言和LLMs。
- en: In this chapter, we will introduce language models and define what makes a language
    model *large*. We will provide a brief history of LLMs, contextualizing their
    place within the field of natural language processing (NLP) and their evolution.
    We will highlight the impact LLMs are already having in the world and showcase
    key use cases, while discussing their strengths and limitations. We will also
    introduce LLM prompting and show how to interact with an LLM effectively, either
    through a user interface or through an API. Finally, we will end this chapter
    with a quick tutorial on building a *Chat with my PDF* chatbot prototype. We will
    then discuss the limitations of the prototype and the factors limiting its suitability
    for production use cases, thus setting the stage for the rest of the book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍语言模型，并定义什么使语言模型成为*大型*。我们将提供LLMs的简要历史，将其置于自然语言处理（NLP）领域的位置，并讨论其演变。我们将强调LLMs已经在世界上产生的影响，展示关键用例，同时讨论它们的优点和局限性。我们还将介绍LLM提示，并展示如何有效地与LLM互动，无论是通过用户界面还是通过API。最后，我们将以一个关于构建*Chat
    with my PDF*聊天机器人原型的小教程结束本章。然后我们将讨论原型的局限性以及限制其适用于生产用例的因素，从而为本书的其余部分奠定基础。
- en: Defining LLMs
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义大型语言模型（LLMs）
- en: A model is an approximation of a real-world concept or phenomenon. A faithful
    model will be able to make predictions about the concept it is approximating.
    A language model approximates human language and is built by training over a large
    body of text, thus imbuing it with various properties of language, including aspects
    of grammar (syntax) and meaning (semantics).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是对现实世界概念或现象的一种近似。一个忠实模型将能够对其近似的概念做出预测。语言模型近似人类语言，是通过在大规模文本上训练而构建的，从而赋予它各种语言属性，包括语法（句法）和意义（语义）的方面。
- en: One way to train a language model is to teach it to predict the next token (this
    is equivalent to a word or a subword, but we will ignore this distinction for
    now) in a known text sequence. The model is trained over a large number of such
    sequences, and its *parameters* are updated iteratively such that it gets better
    at its predictions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 训练语言模型的一种方法是将它教会预测已知文本序列中的下一个标记（这相当于一个词或一个子词，但我们现在将忽略这种区别）。模型在大量此类序列上训练，其*参数*通过迭代更新，以便它能够更好地进行预测。
- en: 'For example, consider the following text sequence appearing in a training dataset:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下出现在训练数据集中的文本序列：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: and the language model predicts the next word that comes after “…​ and proceeded
    to walk toward the **_*”*
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 并且语言模型预测了“…​然后继续走向**_*”*之后的下一个词。
- en: '*There are a large number of valid continuations to this text sequence. It
    could be “building” or “shelter,” but it could also be “embankment” or “catacomb.”
    However, it is definitely not “the” or “is,” because that would break the rules
    of the English language. After training on a sufficiently large body of text,
    the model learns that neither “the” nor “is” are valid continuations. Thus, you
    can see how a simple task like learning to predict the next word in a text sequence
    can lead the model to learning the grammar of the language in its parameters,
    as well as even more complex skills.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个文本序列有大量的有效后续内容。它可能是“建筑”或“避难所”，也可能是“堤坝”或“地下墓穴”。然而，它绝对不可能是“the”或“is”，因为这会违反英语语言的规则。在足够大的文本语料库上进行训练后，模型会学习到“the”和“is”都不是有效的后续内容。因此，你可以看到，像学习预测文本序列中的下一个词这样的简单任务，如何使模型在其参数中学习到语言的语法，以及甚至更复杂的技能。'
- en: Note
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, language models don’t exactly output a single word or subword as
    the next token in a text sequence. They output a probability distribution over
    the entire vocabulary. (We will explore how this vocabulary is defined and constructed
    in [Chapter 3](ch03.html#chapter-LLM-tokenization)). A well-trained model will
    have high probabilities for valid continuations and very low probabilities for
    invalid continuations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，语言模型并不精确地输出文本序列中的下一个标记词或子词。它们输出整个词汇表上的概率分布。（我们将在[第3章](ch03.html#chapter-LLM-tokenization)中探讨这个词汇表是如何定义和构建的）。一个训练良好的模型将对有效的后续内容有高概率，而对于无效的后续内容则有非常低的概率。
- en: '[Figure 1-1](#next-token-prediction) describes the model training process in
    a nutshell. The output of the model prediction is a probability distribution over
    the entire vocabulary of the language. This is compared to the original sequence,
    and the parameters of the model are updated according to an algorithm so that
    it makes better predictions in the future. This is repeated over a very large
    dataset. We will describe the model training process in detail in the next three
    chapters.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-1](#next-token-prediction)简要描述了模型训练过程。模型预测的输出是语言整个词汇表上的概率分布。这与原始序列进行比较，并根据算法更新模型的参数，以便在将来做出更好的预测。这在一个非常大的数据集上重复进行。我们将在接下来的三章中详细描述模型训练过程。'
- en: '![next-token-prediction](assets/dllm_0101.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![下一个标记词预测](assets/dllm_0101.png)'
- en: Figure 1-1\. Model training using next token prediction
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 使用下一个标记词预测进行模型训练
- en: Is there a limit to what a model can learn from next-token prediction alone?
    This is a very important question that determines how powerful LLMs can eventually
    be. There is plenty of disagreement in the research community, with [some researchers](https://oreil.ly/sUAcl)
    arguing next-token prediction is enough to achieve human-level intelligence in
    models, and [others pointing out](https://oreil.ly/7QG-l) the shortfalls of this
    paradigm. We will come back to this question throughout the book, and especially
    in [Chapter 8](ch08.html#ch8), where we will discuss skills like reasoning.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型仅从下一个标记词预测中能学到什么是有极限的吗？这是一个非常重要的问题，决定了LLM最终能有多强大。在研究界存在很多分歧，[一些研究人员](https://oreil.ly/sUAcl)认为仅通过下一个标记词预测就足以在模型中实现人类水平的智能，而[其他人指出](https://oreil.ly/7QG-l)这种范式的不足。我们将在整本书中回到这个问题，特别是在[第8章](ch08.html#ch8)，我们将讨论推理等技能。
- en: Modern-day language models are based on neural networks. Several types of neural
    network architectures are used to train LLMs, the most prominent being the Transformer.
    We will learn more about neural networks, Transformers, and other architectures
    in detail in [Chapter 4](ch04.html#chapter_transformer-architecture).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当代语言模型基于神经网络。用于训练大型语言模型（LLM）的神经网络架构有多种类型，其中最突出的是Transformer。我们将在[第4章](ch04.html#chapter_transformer-architecture)中详细了解神经网络、Transformer和其他架构。
- en: Language models can be trained to model not just human languages but also programming
    languages like Python or Java. In fact, the Transformer architecture and the next-token
    prediction objective can be applied to sequences that are not languages in the
    traditional sense at all, such as representations of chess moves, DNA sequences,
    or airline schedules.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型可以被训练来模拟不仅限于人类语言，还可以是像Python或Java这样的编程语言。实际上，Transformer架构和下一个标记词预测目标可以应用于根本不是语言的序列，例如棋步表示、DNA序列或航班时刻表。
- en: For example, Adam Karvonen trained [Chess-GPT](https://oreil.ly/oluZN), a model
    trained only on chess games represented in portable game notation (PGN) strings.
    PGN strings for chess look like “1\. e4 d5 2\. exd5 Qxd5…” and so on. Even without
    providing the rules of the game explicitly, and just training the model to predict
    the next character in the PGN sequence, the model was able to learn the rules
    of the game including moves like castling, check, and checkmate; and it could
    even win chess games against experts. This shows the power of the next-token prediction
    objective and the Transformer architecture that forms the basis of the model.
    In [Chapter 4](ch04.html#chapter_transformer-architecture), we will learn how
    to train our own Chess-GPT from scratch.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Adam Karvonen训练了[Chess-GPT](https://oreil.ly/oluZN)，这是一个仅使用便携式游戏表示法（PGN）字符串表示的棋局进行训练的模型。棋局的PGN字符串看起来像“1.
    e4 d5 2. exd5 Qxd5...”等等。即使没有明确提供游戏规则，只需训练模型预测PGN序列中的下一个字符，该模型也能学习到游戏规则，包括王车易位、将军和将军胜等走法；甚至能够战胜专家的棋局。这展示了下一个标记预测目标以及构成模型基础的Transformer架构的力量。在[第4章](ch04.html#chapter_transformer-architecture)中，我们将学习如何从头开始训练自己的Chess-GPT。
- en: Another such example is the [Geneformer](https://oreil.ly/31DXq), a model trained
    on millions of single-cell transcriptomes (representations of RNA molecules in
    a single cell), which can be used for making predictions in network biology, including
    disease progression, gene-dosage sensitivity, and therapeutic candidates.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个这样的例子是[Geneformer](https://oreil.ly/31DXq)，这是一个在数百万个单细胞转录组（单个细胞中RNA分子的表示）上训练的模型，可以用于网络生物学的预测，包括疾病进展、基因剂量敏感性和治疗候选者。
- en: Therefore, I encourage you to think beyond the realm of human language when
    brainstorming novel use cases for language models. If you have a concept or phenomenon
    that can be encoded in a discrete sequence using a finite vocabulary (we will
    more formally define vocabulary in [Chapter 3](ch03.html#chapter-LLM-tokenization)),
    then we can potentially train a useful model on it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我鼓励你在构思语言模型的创新用例时超越人类语言的范畴。如果你有一个可以用有限词汇编码的概念或现象（我们将在[第3章](ch03.html#chapter-LLM-tokenization)中更正式地定义词汇），那么我们可能可以在它上面训练出一个有用的模型。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Is there something special about the structure of language that makes it amenable
    to be modeled using the next-token prediction objective? Or is the word “language”
    in language models just a historical accident and any stream of tokens can be
    modeled using this paradigm? While this is still a [topic of debate](https://oreil.ly/nJiQW)
    in the research community, directly modeling speech, video, etc. using this paradigm
    hasn’t been as effective, perhaps showing that the discrete nature of text and
    the structure provided by language, be it a human language like English, a programming
    language like Python, or a domain-specific code like DNA sequences, is crucial
    to modeling success.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 语言的结构有什么特别之处，使得它适合使用下一个标记预测目标进行建模？或者，语言模型中的“语言”一词只是一个历史巧合，任何标记流都可以使用这种范式进行建模？尽管这在研究社区中仍然是一个[争论的话题](https://oreil.ly/nJiQW)，但直接使用这种范式对语音、视频等进行建模并没有那么有效，这可能表明文本的离散性质以及语言提供结构，无论是人类语言如英语，编程语言如Python，还是特定领域的代码如DNA序列，对于建模成功至关重要。
- en: Around 2019, researchers realized that increasing the size of the language model
    (typically measured by the number of parameters) predictably improved performance,
    with no saturation point in sight. This led to Kaplan et al.’s work on LLM scaling
    laws (see the following sidebar), which derives a mathematical formula describing
    the relationship between the amount of computation (henceforth referred to as
    “compute”) for training the model, the training dataset size, and the model size.
    Ever since then, companies and organizations have been training increasingly larger
    models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在2019年，研究人员意识到，通过增加语言模型的大小（通常通过参数数量来衡量）可以可预测地提高性能，而且似乎没有饱和点。这导致了Kaplan等人关于LLM缩放定律的研究工作（见下文边栏），该研究推导出一个数学公式，描述了训练模型所需的计算量（以下简称“计算”）、训练数据集大小和模型大小之间的关系。从那时起，公司和组织一直在训练越来越大的模型。
- en: There is no accepted convention about when a language model is considered “large.”
    In fact, as the largest models get even larger, some models that would have been
    designated as LLMs only a couple of years ago are now termed small language models
    (SLMs). In this book, we will remain generous and continue to refer to all language
    models over a billion parameters as “large.”
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 关于何时将语言模型视为“大型”的，没有公认的标准。事实上，随着最大模型变得更大，一些几年前还被指定为LLM的模型现在被称为小型语言模型（SLM）。在这本书中，我们将保持宽容，继续将超过十亿参数的所有语言模型称为“大型”。
- en: Another way in which a “large” language model differs from smaller ones is the
    emergent capabilities it possesses. First hypothesized by [Wei et al.](https://oreil.ly/RQfii),
    emergent capabilities are those capabilities exhibited by larger models but not
    smaller ones.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种“大型”语言模型与较小模型不同的方式是它所拥有的涌现能力。这种能力最初由[Wei等人](https://oreil.ly/RQfii)提出，涌现能力是那些较大模型展现但较小模型不具备的能力。
- en: According to this theory, for tasks that require these capabilities, the performance
    of smaller models is close to random. However, when the model size reaches a threshold,
    the performance suddenly starts to increase with size. Examples include multi-digit
    arithmetic operations, arithmetic and logical reasoning, etc. This also suggests
    that certain capabilities that are completely absent in current models could be
    exhibited by future larger models.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这一理论，对于需要这些能力的任务，较小模型的性能接近随机。然而，当模型大小达到阈值时，性能突然开始随着大小增加而提高。例如，包括多位数算术运算、算术和逻辑推理等。这也表明，当前模型中完全缺失的某些能力可能在未来更大的模型中展现出来。
- en: These thresholds are not absolute, and as we see more advances in language modeling,
    data quality improvements, etc., we can expect the thresholds to come down.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些阈值不是绝对的，随着我们在语言建模、数据质量等方面的更多进步，我们可以期待阈值会降低。
- en: Note
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '[Schaeffer et al.](https://oreil.ly/OXk6I) claim that the sudden jump in performance
    for certain tasks at a particular model size threshold is just an artifact of
    the evaluation metrics used to judge performance. This happens because many metrics
    do not assign partial credit and only reward fully solving the task, so model
    improvements might not be tracked. On the other hand, one could argue that for
    tasks like multi-step arithmetic, getting the answer partially right is just as
    useless as getting it completely wrong.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[Schaeffer等人](https://oreil.ly/OXk6I)声称，在特定模型大小阈值处某些任务性能的突然提升只是用于评估性能的指标所造成的伪象。这是因为许多指标不分配部分分数，只奖励完全解决任务，因此模型改进可能无法追踪。另一方面，有人可以争辩说，对于多步算术等任务，部分正确地得到答案与完全错误一样无用。'
- en: The question of what abilities are emergent is still being explored in the research
    community. In [Chapter 5](ch05.html#chapter_utilizing_llms), we will discuss its
    implications for selecting the right model for our desired use case.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于哪些能力是涌现的，研究社区仍在探索。在[第5章](ch05.html#chapter_utilizing_llms)中，我们将讨论其对选择适合我们所需用例的正确模型的影响。
- en: Warning
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Unfortunately the phrase “emergent properties” has multiple meanings in the
    literature. In some papers, the phrase is used to describe those capabilities
    that the model is not explicitly trained for. In this book, we will stick to [Wei
    et al.’s definition](https://oreil.ly/bkVoj).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，“涌现性质”这个短语在文献中有多重含义。在一些论文中，这个短语被用来描述模型没有明确训练的能力。在这本书中，我们将坚持[Wei等人](https://oreil.ly/bkVoj)的定义。
- en: To understand how current LLMs came to be, it is instructive to walk through
    a brief history of them. As more historical details are out of scope for the book,
    we will provide links to external resources for further reading throughout the
    section.*  *# A Brief History of LLMs
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解当前LLM是如何形成的，回顾它们简短的历史是有益的。由于本书的范围不包括更多历史细节，我们将在本节中提供外部资源的链接，以便进一步阅读。*  *#
    LLM的简要历史
- en: To present the history of LLMs, we need to start from the history of NLP, the
    field that LLMs originated from. For a more detailed history of NLP, refer to
    Daniel Jurafsky’s seminal book, [*Speech and Language Processing*, 2nd edition](https://oreil.ly/zzU9R).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要介绍LLM的历史，我们需要从LLM起源的领域——自然语言处理（NLP）的历史开始。关于NLP的更详细历史，请参阅丹尼尔·朱拉夫斯基的奠基性著作[*《语音与语言处理》，第二版*](https://oreil.ly/zzU9R)。
- en: Early Years
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 早期
- en: The field traces its origins to the 1950s, driven by demand for *machine translation*,
    the task of automatically translating from one language to another. The early
    days were dominated by symbolic approaches; these were rule-based algorithms based
    on [linguistic theories](https://oreil.ly/ELKSe) influenced by the works of linguists
    like Noam Chomsky.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域可以追溯到20世纪50年代，由对*机器翻译*的需求推动，即自动将一种语言翻译成另一种语言的任务。早期主要由符号方法主导；这些是基于[语言理论](https://oreil.ly/ELKSe)的算法，这些理论受到了诺姆·乔姆斯基等语言学家作品的影响。
- en: In the mid-1960s, Joseph Weizenbaum released ELIZA, a chatbot program that applied
    pattern matching using [regular expressions](https://oreil.ly/rIAWY) on the user’s
    input and selected response templates to generate an output. ELIZA consisted of
    several scripts, the most famous one being DOCTOR, that simulated a psychotherapist.
    This variant would respond by rephrasing the user’s input in the form of a question,
    similar to how a therapist would. The rephrasing was performed by filling in predefined
    templates with pattern-matched words from the input.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪60年代中期，约瑟夫·魏岑鲍姆发布了ELIZA，这是一个聊天机器人程序，它使用[正则表达式](https://oreil.ly/rIAWY)在用户的输入上应用模式匹配，并选择响应模板来生成输出。ELIZA由几个脚本组成，其中最著名的是DOCTOR，它模拟了一位心理治疗师。这个变体会通过将用户输入重新表述为问题来回答，类似于治疗师的做法。这种重新表述是通过用从输入中匹配到的模式匹配词填充预定义模板来完成的。
- en: 'As an example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can try chatting with [ELIZA online](https://oreil.ly/5g0e_). Even in the
    era of ChatGPT, ELIZA can hold a somewhat convincing conversation, despite the
    fact that it is just rules-based.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试与[ELIZA在线聊天](https://oreil.ly/5g0e_)。即使在ChatGPT的时代，ELIZA也能进行一些令人信服的对话，尽管它仅仅是基于规则的。
- en: Rule-based systems are brittle, hard to construct, and a maintenance nightmare.
    As the decades rolled by, the limitations of symbolic approaches became more and
    more evident, and the relative effectiveness of statistical approaches ensured
    that they became more commonplace. NLP researcher [Frederick Jelinek](https://oreil.ly/AmtvE)
    famously quipped, “Every time I fire a linguist, the performance of the speech
    recognizer goes up.”
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 基于规则的系统是脆弱的，难以构建，维护起来也是一个噩梦。随着几十年的推移，符号方法的局限性变得越来越明显，而统计方法相对的有效性确保了它们变得更加普遍。NLP研究员[弗雷德里克·杰利内克](https://oreil.ly/AmtvE)曾著名地打趣说：“每次我解雇一个语言学家，语音识别器的性能就会提高。”
- en: Machine learning–based approaches became more widely used in the 1990s and 2000s.
    Traditional machine learning relied on human-driven feature engineering and feature
    selection, the process of identifying features (characteristics of the input)
    that are predictive to solve a task. These features could be statistical, like
    the average word length, or linguistic, like parts of speech. To learn more about
    traditional statistical NLP, I recommend reading Christopher Manning’s book, [*Foundations
    of Statistical Natural Language Processing*](https://oreil.ly/MIC70).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于机器学习的方法在1990年代和2000年代得到了更广泛的应用。传统的机器学习依赖于人类驱动的特征工程和特征选择，这是一个识别特征（输入的特征）的过程，这些特征对解决任务具有预测性。这些特征可以是统计性的，如平均词长，或者是语言学的，如词性。要了解更多关于传统统计NLP的信息，我推荐阅读Christopher
    Manning的书籍[*统计自然语言处理基础*](https://oreil.ly/MIC70)。
- en: The relevance of linguistics to modern-day NLP application development is a
    point of debate. Many university courses on NLP have completely dropped content
    related to linguistics. Even though I don’t directly use linguistics in my work,
    I find that I rely on them to develop intuitions about model behavior more than
    I expect. As such, I recommend Emily Bender’s books on [syntax](https://oreil.ly/hWR8S)
    and [semantics](https://oreil.ly/7liiS) to understand the basics of this field.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 语言学与现代自然语言处理应用开发的相关性是一个有争议的话题。许多大学的NLP课程已经完全放弃了与语言学相关的内容。尽管我直接工作中并不直接使用语言学，但我发现我比预期的更多地依赖它们来发展对模型行为的直觉。因此，我推荐Emily
    Bender关于[句法](https://oreil.ly/hWR8S)和[语义](https://oreil.ly/7liiS)的书籍，以了解这个领域的基础知识。
- en: The 2010s saw the advent of deep learning and its widespread impact on NLP.
    Deep learning is characterized by multi-layer neural network models that learn
    informative features by themselves given only raw input, thus removing the need
    for cumbersome feature engineering. Deep learning forms the foundation for modern
    NLP and LLMs. To dig deeper into the principles of deep learning and neural networks,
    I recommend [Goodfellow et al.’s book](https://oreil.ly/0gv0D). For more hands-on
    deep learning training, I recommend Zhang et al.’s [*Dive into Deep Learning*](https://oreil.ly/YN_3Y).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 2010年代见证了深度学习的出现及其对自然语言处理（NLP）的广泛影响。深度学习以其多层神经网络模型为特征，这些模型仅通过原始输入自行学习信息性特征，从而消除了繁琐的特征工程需求。深度学习构成了现代NLP和大型语言模型（LLMs）的基础。要深入了解深度学习和神经网络的原则，我推荐阅读[Goodfellow等人所著的书籍](https://oreil.ly/0gv0D)。对于更多实践性的深度学习培训，我推荐张等人所著的[*《深度学习入门》*](https://oreil.ly/YN_3Y)。
- en: During the early years of deep learning, it was customary to construct a task-specific
    architecture to solve each task. Some of the types of neural network architectures
    used include multi-layer perceptrons, convolutional neural networks, recurrent
    neural networks, and recursive neural networks. To learn more about this era of
    NLP, I recommend [*Neural Network Methods for Natural Language Processing*](https://oreil.ly/MCOp4)
    by Yoav Goldberg (Springer Cham).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习的早期，构建特定任务的架构来解决每个任务是一种惯例。所使用的神经网络架构类型包括多层感知器、卷积神经网络、循环神经网络和递归神经网络。要了解更多关于这个NLP时代的知识，我推荐Yoav
    Goldberg所著的[*《自然语言处理中的神经网络方法》*](https://oreil.ly/MCOp4)（Springer Cham）。
- en: The Modern LLM Era
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代大型语言模型（LLM）时代
- en: 'In 2017, the [Transformer architecture](https://oreil.ly/AAuvL) was invented,
    quickly followed by the invention of efficient *transfer learning* techniques
    pioneered by [Howard et al.](https://oreil.ly/E15Yn) among others and Transformer-based
    language models like [BERT](https://oreil.ly/-Yhwz). These advances removed the
    need for constructing complex task-specific architectures. Instead, one could
    use the same Transformer model to train a variety of tasks. This new paradigm
    divided the training step into two stages: *pre-training* and *fine-tuning*. An
    initial large-scale pre-training step initialized the Transformer model with general
    language capabilities. Subsequently, the pre-trained model could be trained on
    more concrete tasks, like information extraction or sentiment detection, using
    a process called fine-tuning. We will cover fine-tuning extensively throughout
    the book.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，发明了[Transformer架构](https://oreil.ly/AAuvL)，随后[Howard等人](https://oreil.ly/E15Yn)等先驱发明了高效的*迁移学习*技术，以及基于Transformer的语言模型如[BERT](https://oreil.ly/-Yhwz)。这些进步消除了构建复杂特定任务架构的需求。相反，可以使用相同的Transformer模型来训练各种任务。这种新范式将训练步骤分为两个阶段：*预训练*和*微调*。一个初始的大规模预训练步骤用通用语言能力初始化Transformer模型。随后，预训练模型可以通过微调过程在更具体的任务上进行训练，例如信息提取或情感检测。我们将在本书中广泛介绍微调。
- en: 'While academia and open-source collectives have made crucial and critical contributions
    to language modeling, large tech companies like OpenAI, Google, Meta, and Anthropic
    have taken the lead in training and releasing progressively larger LLMs. OpenAI
    in particular has played a pioneering role in advancing language modeling technology.
    The trajectory of the evolution of LLMs in the modern era can be traced through
    the advances ushered in by each version of the GPT (Generative Pre-trained Transformer)
    family of models trained by OpenAI:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然学术界和开源团体对语言模型做出了关键和重要的贡献，但像OpenAI、Google、Meta和Anthropic这样的大型科技公司则在训练和发布越来越大的LLMs方面处于领先地位。特别是OpenAI在推进语言模型技术方面发挥了开创性的作用。现代时代LLMs演变的轨迹可以通过OpenAI训练的GPT（生成预训练Transformer）系列模型每个版本的进步来追踪：
- en: '[GPT-1](https://oreil.ly/dFPSE)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT-1](https://oreil.ly/dFPSE)'
- en: This version demonstrated unsupervised pre-training on large-scale data, followed
    by task-specific supervised fine-tuning.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本展示了在大规模数据上的无监督预训练，随后进行特定任务的监督微调。
- en: '[GPT-2](https://oreil.ly/JL-VO)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT-2](https://oreil.ly/JL-VO)'
- en: This version was one of the first models to be trained on large-scale web data.
    This version also marked the rise of natural language prompting as a means of
    interacting with a language model. It showed that pre-trained models could solve
    a variety of tasks *zero-shot* (solving a task without needing any examples) without
    any task-specific fine-tuning. We will discuss zero-shot and prompting in detail
    later in this chapter.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本是第一个在大型规模网络数据上训练的模型。这个版本也标志着自然语言提示作为与语言模型交互手段的兴起。它表明，预训练模型可以在没有任何特定任务微调的情况下解决各种任务*零样本*（无需任何示例即可解决问题）。我们将在本章后面详细讨论零样本和提示。
- en: '[GPT-3](https://oreil.ly/lIwad)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT-3](https://oreil.ly/lIwad)'
- en: Inspired by the scaling laws, this model is a hundred times larger than GPT-2
    and popularized in-context/few-shot learning, where the model is fed with a few
    examples on how to solve a given task in the prompt, without needing to fine-tune
    the model. We will learn more about few-shot learning later in this chapter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 受到扩展定律的启发，这个模型比GPT-2大一百倍，并普及了上下文/少样本学习，其中模型通过在提示中提供几个如何解决给定任务的示例来喂养，而无需微调模型。我们将在本章后面更深入地了解少样本学习。
- en: '[GPT-4](https://oreil.ly/gY1HL)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT-4](https://oreil.ly/gY1HL)'
- en: A key aspect of this release is the *alignment training* used to make the model
    more controllable and adhere to the principles and values of the model trainer.
    We will learn about alignment training in [Chapter 8](ch08.html#ch8).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本发布的关键方面是用于使模型更具可控性和遵循模型训练者原则和价值观的*对齐训练*。我们将在[第8章](ch08.html#ch8)中了解对齐训练。
- en: '[o1](https://oreil.ly/XJSMN)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[o1](https://oreil.ly/XJSMN)'
- en: This is a new family of models released by OpenAI that focuses on improving
    reasoning capabilities. This is one of the first models to focus on scaling inference-time
    computation. We will discuss more about inference-time computation in [Chapter 8](ch08.html#ch8).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个由OpenAI发布的新系列模型，专注于提高推理能力。这是第一个专注于扩展推理时间计算规模的模型。我们将在[第8章](ch08.html#ch8)中更详细地讨论推理时间计算。
- en: 'You might have noticed a trend here: through the years, the field has been
    experiencing a consolidation effect, with more and more parts of the NLP task
    pipeline being performed *end-to-end*, i.e., by a single model. Throughout this
    book, we will point out the consolidation effect where it is apparent and discuss
    its implications for the future of LLMs.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到了一个趋势：多年来，该领域一直在经历整合效应，越来越多的NLP任务管道部分由单个模型端到端执行。在本书中，我们将指出明显的整合效应，并讨论其对LLM未来的影响。
- en: A history of LLMs wouldn’t be complete without mentioning the impact of open
    source contributions to this field. Open source models, datasets, model architectures,
    and various developer libraries and tools have all had significant impacts on
    the development of this field. This book places a special importance on open source,
    providing a thorough survey of the open source LLM landscape and showcasing many
    open source models and datasets.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的历史如果不提及开源对这个领域的影响就不完整。开源模型、数据集、模型架构以及各种开发者库和工具都对这一领域的发展产生了重大影响。本书特别重视开源，提供了对开源LLM景观的全面调查，并展示了众多开源模型和数据集。
- en: Next, let’s explore how LLMs are being adopted and their impact on society so
    far.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探索LLM的采用情况及其对社会的影响。
- en: The Impact of LLMs
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM的影响
- en: The tech world has long been susceptible to hype cycles, with exhilarating booms
    and depressing busts. More recently, we have witnessed the crypto/blockchain and
    Web3 booms, both of which have yet to live up to their promises. Is AI heading
    toward a similar fate? We have hard evidence that it is not.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 科技界长期以来一直容易受到炒作周期的影响，经历着令人振奋的繁荣和令人沮丧的萧条。最近，我们见证了加密/区块链和Web3的繁荣，但这两者都尚未实现其承诺。AI是否正走向类似的命运？我们有确凿的证据表明它并非如此。
- en: At my company Hudson Labs, we [analyzed discussions](https://oreil.ly/_mTAs)
    in the quarterly earnings calls of the 4,000 largest publicly listed companies
    in the United States to track adoption of crypto, Web3, and AI in the enterprise.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的公司Hudson Labs，我们分析了美国4000家最大上市公司季度收益电话会议中的[讨论](https://oreil.ly/_mTAs)，以追踪企业对加密、Web3和AI的采用情况。
- en: We observed that 85 companies discussed Web3 in their earnings calls, with even
    fewer tangibly working on it. Crypto fared better, with 313 companies discussing
    it. Meanwhile, LLMs were discussed and adopted by 2,195 companies, meaning that
    at least 50% of America’s largest public companies are using LLMs to drive value,
    and it is strategically so important to them to merit discussion in their quarterly
    earnings call. Effective or not, LLM adoption in the enterprise is already a reality.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到，有85家公司在其收益电话中讨论了Web3，甚至更少的公司真正在从事相关工作。加密领域表现较好，有313家公司讨论了它。与此同时，有2,195家公司讨论并采用了LLMs，这意味着至少50%的美国最大上市公司正在使用LLMs来驱动价值，这对他们来说战略上如此重要，以至于在他们的季度收益电话中被讨论。无论有效与否，企业中LLMs的采用已经成为现实。
- en: '[Figure 1-2](#web3) shows the number of companies discussing Web3 in their
    earnings calls over time. As you can see, the Web3 hype seems to be tapering off.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-2（[Web3](#web3)）显示了在其收益电话中讨论Web3的公司随时间的变化。如您所见，Web3的炒作似乎正在减弱。
- en: '![web3](assets/dllm_0102.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![web3](assets/dllm_0102.png)'
- en: Figure 1-2\. Companies that discussed Web3 in their earnings calls across time
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 在其收益电话中讨论Web3的公司随时间的变化
- en: Similarly, [Figure 1-3](#crypto) shows the number of companies discussing crypto/blockchain
    in their earnings calls over time. As you can see, only 5% of companies discussed
    crypto at its peak.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，图1-3（[加密](#crypto)）显示了在其收益电话中讨论加密/区块链的公司随时间的变化。如您所见，在其顶峰时期，只有5%的公司讨论了加密。
- en: '![crypto](assets/dllm_0103.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![crypto](assets/dllm_0103.png)'
- en: Figure 1-3\. Companies that discussed crypto/blockchain in their earnings calls
    across time
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 在其收益电话中讨论加密/区块链的公司随时间的变化
- en: Finally, let’s look at AI. As mentioned before, AI has reached levels of adoption
    in the enterprise that no other recent technology trend has managed in the recent
    past. The trend is only accelerating, as shown in [Figure 1-4](#ai-adoption),
    which shows the number of companies that were asked questions about AI by analysts
    during their earnings calls in just the first two months of the year. The sharp
    spike in 2024 shows no sign of abating.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来看看AI。如前所述，AI在企业的采用程度是近期其他任何技术趋势都无法比拟的。这一趋势正在加速，如图1-4（[AI采用](#ai-adoption)）所示，该图显示了分析师在仅今年前两个月收益电话中询问AI问题的公司数量。2024年的急剧上升没有减缓的迹象。
- en: '![ai-adoption](assets/dllm_0104.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![ai-adoption](assets/dllm_0104.png)'
- en: Figure 1-4\. Companies that were asked questions about AI in their earnings
    calls during the first two months of the year
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 在其收益电话中在年初前两个月被询问AI问题的公司
- en: Note that these statistics only include generative AI/LLM adoption and not data
    science/data analytics, whose adoption is even more ubiquitous in the enterprise.
    AI adoption is also not limited to tech companies, with companies ranging from
    real estate companies to insurance firms joining in on the fun.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些统计数据仅包括生成式AI/LLMs的采用，而不包括数据科学/数据分析，其采用在企业的普及程度更高。AI的采用也不限于科技公司，从房地产公司到保险公司等各行各业的公司都在参与其中。
- en: LLM Usage in the Enterprise
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 企业中LLMs的应用
- en: 'From the same analysis, we observed the key ways in which LLMs are used in
    the enterprise:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从同样的分析中，我们观察到了企业中LLMs（大型语言模型）的关键应用方式：
- en: Employee productivity
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 员工生产力
- en: The primary means by which employee productivity has improved through LLM usage
    is with coding assistants like GitHub Copilot. LLMs are also widely used to help
    draft marketing and promotional text and automate marketing campaigns. In fact,
    the first major LLM commercial success stories were marketing startups like [Jasper
    AI](https://oreil.ly/Byw26) and [Copy.ai](https://oreil.ly/QmhJC). Another key
    LLM-driven productivity enhancement is question-answering assistants over a company’s
    extensive knowledge base drawn from heterogeneous data sources.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过LLMs的使用提高员工生产力的主要方式是通过像GitHub Copilot这样的编码助手。LLMs也被广泛用于帮助撰写营销和推广文本以及自动化营销活动。事实上，第一个主要的LLMs商业成功故事是营销初创公司[Jasper
    AI](https://oreil.ly/Byw26)和[Copy.ai](https://oreil.ly/QmhJC)。另一个关键的由LLMs驱动的生产力提升是通过公司从异构数据源中抽取的广泛知识库上的问答助手。
- en: Report generation
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 报告生成
- en: These include summarizing documents, completing mundane paperwork, and even
    drafting contracts. Summarization use cases include summarizing financial reports,
    research papers, or even meeting minutes from audio or call transcripts.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括总结文档、完成日常文书工作，甚至起草合同。总结用例包括总结财务报告、研究论文，甚至音频或通话记录中的会议纪要。
- en: Chatbots
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人
- en: LLM-driven chatbots increasingly are being deployed as customer service agents.
    They are also being used as an interface to a company’s documentation or product
    page.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LLM驱动的聊天机器人越来越多地被部署为客户服务代表。它们也被用作公司文档或产品页面的接口。
- en: Information extraction and sequence tagging
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 信息提取和序列标记
- en: Over the years, a large number of enterprises have developed complex NLP pipelines
    for language processing tasks. Many of these pipelines are being fully or partially
    replaced by LLMs. These pipelines are used to solve common NLP tasks like sentiment
    analysis, information extraction tasks like entity extraction and relation extraction,
    and sequence tagging tasks like named entity recognition (NER). For a detailed
    list of NLP tasks and their descriptions, see [Fabio Chiusano’s blog](https://oreil.ly/_11rN).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，许多企业已经为语言处理任务开发了复杂的NLP管道。其中许多管道正在被LLM完全或部分取代。这些管道用于解决常见的NLP任务，如情感分析、信息提取任务，如实体提取和关系提取，以及序列标记任务，如命名实体识别（NER）。有关NLP任务及其详细描述的列表，请参阅[Fabio
    Chiusano的博客](https://oreil.ly/_11rN)。
- en: Translation
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译
- en: Translation tasks include translating text from one language to another as well
    as tasks where text is converted to a different form but in the same language,
    for example, converting informal text to formal text, abusive text to polite text
    and so on. Real-time translation apps like [Erudite’s Instant Voice Translate
    promise](https://oreil.ly/xxENs) to make embarrassing language-barrier moments
    for tourists a thing of the past.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译任务包括将文本从一种语言翻译成另一种语言，以及将文本转换为同一语言的不同形式的任务，例如，将非正式文本转换为正式文本、侮辱性文本转换为礼貌文本等。实时翻译应用如[Erudite的即时语音翻译](https://oreil.ly/xxENs)承诺让游客尴尬的语言障碍时刻成为过去式。
- en: Workflows
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程
- en: LLMs are gradually being used to facilitate workflow automation, where a sequence
    of tasks can be performed by LLM-driven software systems, called agents. Agents
    can interact with their environment (search and retrieve data, run code, connect
    to other systems) and potentially operate autonomously. We will more formally
    define agents and explore how to build them in [Chapter 10](ch10.html#ch10).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: LLM正逐渐被用于促进工作流程自动化，其中一系列任务可以通过LLM驱动的软件系统（称为代理）执行。代理可以与其环境交互（搜索和检索数据、运行代码、连接到其他系统），并且可能自主操作。我们将在第10章（ch10.html#ch10）中更正式地定义代理，并探讨如何构建它们。
- en: Prompting
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示
- en: Now that we have our fundamentals in place, let’s begin learning how to effectively
    use LLMs.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了基础，让我们开始学习如何有效地使用LLM。
- en: The process by which you interact with an LLM is called prompting. Even though
    some companies attempt to anthropomorphize LLMs by giving them a name or a persona,
    it is good to remember that when you are interacting with an LLM, you are *prompting*
    them and not chatting with them as you would with a human being. Remember that
    LLMs are next-word predictors. This means that the text they generate is heavily
    dependent on the text they are fed, which includes the input (called the *prompt*)
    and the output tokens generated so far by the model. This is collectively called
    the *context*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 与LLM交互的过程称为提示。尽管一些公司试图通过给LLM起名字或赋予一个角色来拟人化LLM，但记住当你与LLM交互时，你是在*提示*它们，而不是像与人交谈那样聊天。记住LLM是下一词预测器。这意味着它们生成的文本高度依赖于它们所接收的文本，包括输入（称为*提示*）和模型迄今为止生成的输出token。这统称为*上下文*。
- en: 'By feeding the LLM the right text in the context, you are priming it to generate
    the type of output you need. The ideal prompt would be the answer to this question:
    “What would be the best prefix of N tokens that, when fed to an LLM, will lead
    it to generate the correct answer with the highest probability?”'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在上下文中向LLM提供正确的文本，你正在为它提供生成所需输出类型的启动。理想的提示将是这个问题的答案：“什么是最合适的N个token的前缀，当将其输入到LLM中时，将最有可能引导它生成正确的答案？”
- en: As of the book’s writing, language models simply aren’t smart enough for you
    to prompt a model exactly the way you would speak to a human and expect best results.
    As language models get better over time, prompts can become more like human conversation.
    Those of you who remember the early days of search engines might recall that effectively
    using a search engine by entering the right form of queries was seen as a skill
    that is not trivial to acquire, but as search engines got better, search queries
    could become more free-form.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 到本书写作时为止，语言模型还不够智能，无法让你以与人类交谈的方式提示模型并期望获得最佳结果。随着语言模型随着时间的推移而变得更好，提示可以变得更加像人类的对话。那些还记得搜索引擎早期日子的人可能会记得，通过输入正确的查询形式来有效地使用搜索引擎被认为是一项非同小可的技能，但随着搜索引擎的改进，搜索查询可以变得更加自由形式。
- en: When I started writing this book, I solicited opinions from the target readership
    on the topics they would like covered. I received the most requests for the topic
    of prompting, with practitioners wanting to understand how to effectively create
    prompts for their specific use cases.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始写这本书时，我征求了目标读者群对希望涵盖主题的意见。我收到了最多的关于提示（prompting）主题的请求，实践者希望了解如何有效地为他们特定的用例创建提示。
- en: Prompting is an important aspect of modern-day LLMs. In fact, you will probably
    end up spending a significant amount of your time on any LLM-based project iterating
    on prompts, very inaccurately referred to as *prompt engineering*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是现代LLM的一个重要方面。实际上，你可能会在任何一个基于LLM的项目上花费大量时间迭代提示，这通常被不准确地称为*提示工程*。
- en: Tip
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: There have been attempts to automatically optimize prompts, like [automatic
    prompt optimization (APO)](https://oreil.ly/SekPA) and [AutoPrompt](https://oreil.ly/upVKC).
    We will discuss this further in [Chapter 13](ch13.html#ch13).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 已有尝试自动优化提示，如[自动提示优化（APO）](https://oreil.ly/SekPA)和[AutoPrompt](https://oreil.ly/upVKC)。我们将在[第13章](ch13.html#ch13)中进一步讨论这个问题。
- en: It is important to manage one’s expectations about the effectiveness of prompt
    engineering. Prompts aren’t magical incantations that unlock hidden LLM capabilities.
    It is very unlikely that there are companies with a significant advantage over
    others just by using a superior prompting technique unknown to others. On the
    flip side, not following basic prompting principles can severely hamper the performance
    of your LLM.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 管理对提示工程有效性的期望是很重要的。提示并不是解锁隐藏LLM能力的魔法咒语。不太可能存在仅通过使用其他公司不知晓的优越提示技术就具有显著优势的公司。另一方面，不遵循基本的提示原则可能会严重损害你LLM的性能。
- en: Umpteen prompting tutorials are available online. I recommend [Learn Prompting’s
    prompting guide](https://oreil.ly/CQrzi) in particular. You do not need to know
    all the prompting techniques to become well-versed in prompting. Most of what
    you need to know about prompting can be learned in a couple of hours. What matters
    more is interacting with the LLMs you use frequently to observe their outputs
    and developing intuition about their behavior.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在线有大量的提示教程。我特别推荐[学习提示的指南](https://oreil.ly/CQrzi)。你不需要了解所有的提示技巧就能熟练掌握提示。关于提示，你所需了解的大部分内容可以在几个小时的学习中掌握。更重要的是，与经常使用的LLM进行互动，观察它们的输出，并发展对它们行为的直觉。
- en: If you have programming experience, I suggest viewing prompting through the
    lens of programming. In programming, instructions need to be explicit with no
    room for ambiguity. The challenge with prompting is that it is done in natural
    language, which is inherently ambiguous. Still, the best prompts state instructions
    that are explicit, detailed, and structured, leaving very little room for ambiguity.
    We will learn more prompting nuances in Chapters [5](ch05.html#chapter_utilizing_llms)
    and [13](ch13.html#ch13).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你具有编程经验，我建议从编程的角度来看待提示。在编程中，指令需要明确，不能有歧义。提示的挑战在于它是用自然语言进行的，而自然语言本质上是有歧义的。尽管如此，最好的提示都明确、详细且结构化，几乎不留任何歧义的空间。我们将在[第5章](ch05.html#chapter_utilizing_llms)和[第13章](ch13.html#ch13)中学习更多关于提示的细微差别。
- en: Note
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'A fun fact: language models are insensitive to word order. This property has
    been [observed](https://oreil.ly/gtDFg) even in [earlier models](https://oreil.ly/qI_IZ)
    like BERT. For example, ask ChatGPT or your favorite LLM provider the question
    “How do I tie my shoelaces?” in jumbled form, say “shoe tie my I how do laces?”
    ChatGPT responds with “Certainly! Here are step-by-step instructions on how to
    tie your shoelaces:…​” as if you asked a straightforward question.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的事实：语言模型对词序不敏感。这一特性甚至在[早期模型](https://oreil.ly/qI_IZ)如BERT中也被观察到。[观察](https://oreil.ly/gtDFg)。例如，向ChatGPT或你喜欢的LLM提供商提出“我该如何系鞋带？”这样的问题，以混乱的形式，比如说“鞋带我如何系鞋？”ChatGPT会回答“当然！以下是如何系鞋带的逐步说明：…”，就像你提出了一个直接的问题。
- en: Next, let’s discuss a few prompting modes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论几种提示模式。
- en: Zero-Shot Prompting
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本提示
- en: This is the standard approach to prompting, where you provide the LLM with an
    instruction and, optionally, some input text. The term *zero-shot* refers to the
    fact that no examples or demonstrations are provided on how to solve the task.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是标准的提示方法，其中你向LLM提供指令，以及可选的输入文本。术语*零样本*指的是没有提供如何解决任务的示例或演示。
- en: 'Consider an example where your task is to assess the sentiment expressed in
    a restaurant review. To achieve this through zero-shot prompting, you can issue
    the following prompt:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个例子，你的任务是评估餐厅评论中表达的情感。通过零样本提示实现这一点，你可以发出以下提示：
- en: '*Prompt:* Classify the given passage according to its sentiment. The output
    can be one of Positive, Negative, Neutral.'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 根据给定的段落情感进行分类。输出可以是积极、消极或中立之一。'
- en: ''
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Passage: “The mashed potatoes took me back to my childhood school meals. I
    was so looking forward to having them again. NOT!”'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '段落: “土豆泥让我想起了我童年的学校午餐。我非常期待再次享用它们。不！”'
- en: ''
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sentiment:'
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 情感：
- en: 'A good zero-shot prompt will:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的零样本提示应该：
- en: Provide the instruction in a precise and explicit manner.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以精确和明确的方式提供指令。
- en: Describe the output space or the range of acceptable outputs and output format.
    In this example, we state the output should be one of three values.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述输出空间或可接受的输出范围和输出格式。在这个例子中，我们声明输出应该是三个值之一。
- en: Prime it to generate the correct text. By ending the prompt with “Sentiment:,”
    we are increasing the probability of the LLM generating the sentiment value as
    the next token.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在提示中结束“Sentiment:”来引导它生成正确的文本。通过这样做，我们增加了LLM生成情感值作为下一个标记的概率。
- en: The better the model, the less you have to worry about getting these things
    right.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模型越好，你越不需要担心这些事情的正确性。
- en: In real-world settings, your output format needs to be highly controllable in
    order for it to fit in automated systems. We will discuss more techniques for
    ensuring controllability of outputs in [Chapter 5](ch05.html#chapter_utilizing_llms).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的设置中，你的输出格式需要高度可控，以便它能够适应自动化系统。我们将在[第5章](ch05.html#chapter_utilizing_llms)中讨论更多确保输出可控性的技术。
- en: Warning
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Prompts are sensitive to model changes. You might painstakingly construct a
    prompt that seems to work well, but you might notice that the same prompt does
    not work for a different model. In fact, the same prompt might see degraded performance
    on the same API endpoint if the underlying model is updated in the meanwhile.
    We call this *prompt drift*. It is a good idea to version control prompts.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 提示对模型变化敏感。你可能费尽心思构建了一个似乎效果很好的提示，但你可能会注意到，同样的提示对不同的模型不起作用。实际上，如果在此期间底层模型被更新，同样的提示在同一个API端点上的性能可能会下降。我们称之为*提示漂移*。对提示进行版本控制是个好主意。
- en: Few-Shot Prompting
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少样本提示
- en: In our example for zero-shot prompting, the LLM was able to solve the task without
    explaining it how to solve it. This is because the task is simple and clearly
    defined. In many cases, the tasks might be not so easy to describe in natural
    language. We can then add some examples in our prompt consisting of either outputs
    or input-output pairs. While this is called few-shot learning colloquially, the
    language model is not updated in any way through this prompting technique.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的零样本提示示例中，LLM能够解决任务，而无需解释如何解决它。这是因为任务简单且定义明确。在许多情况下，任务可能不容易用自然语言描述。然后我们可以在提示中添加一些示例，包括输出或输入-输出对。虽然这被称为少样本学习，但语言模型通过这种提示技术并没有以任何方式更新。
- en: 'Here is an example of few-shot prompting:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个少样本提示的例子：
- en: '*Prompt:* A palindrome is a word that has the same letters when spelled left
    to right'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 回文是一个在从左到右拼写时字母相同的词'
- en: ''
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: or right to left.
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 或者从右到左。
- en: ''
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Examples of words that are palindromes: kayak, civic, madam, radar'
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 是回文的单词示例：kayak, civic, madam, radar
- en: ''
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Examples of words that are not palindromes: kayla, civil, merge, moment'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不是回文的单词示例：kayla, civil, merge, moment
- en: ''
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Answer the question with either *Yes* or *No*
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用*是*或*否*回答问题
- en: ''
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is the word *rominmor* a palindrome?
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 单词*rominmor*是回文吗？
- en: ''
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Answer:'
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答案：
- en: Chain-of-Thought Prompting
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链提示
- en: If you are going to learn only one prompting technique, let that be chain-of-thought
    (CoT) prompting, because it is one of the most impactful prompting techniques
    in existence.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只打算学习一种提示技术，那就让它是思维链（CoT）提示，因为它是现有最具影响力的提示技术之一。
- en: As discussed earlier, the context of the LLM determines the next token it predicts.
    Therefore, we need to optimize the content in the context (the user prompt + output
    tokens generated so far) to maximize the probability of the LLM generating the
    correct future tokens. One way to do this is to prompt the LLM to *think* before
    generating. This elicits the LLM to generate the process to get to the answer
    instead of directly generating the answer. This might involve breaking the input
    task into subtasks and solving them one after the other.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，LLM的上下文决定了它预测的下一个token。因此，我们需要优化上下文中的内容（用户提示+迄今为止生成的输出token）以最大化LLM生成正确未来token的概率。一种方法是通过提示LLM在生成之前进行*思考*。这促使LLM生成获取答案的过程而不是直接生成答案。这可能涉及将输入任务分解为子任务并依次解决。
- en: When the LLM is eventually at the cusp of generating the answer, it can rely
    on a more relevant context that increases its probability of generating the right
    answer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM最终接近生成答案时，它可以依赖一个更相关的上下文，这增加了它生成正确答案的概率。
- en: 'Consider this example:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例：
- en: '*Prompt:* Solve the equation. 34 + 44 + 3 * 23 / 3 * 2\. Think step by step.'
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 解这个方程。34 + 44 + 3 * 23 / 3 * 2。逐步思考。'
- en: 'After receiving the instruction “Think step by step,” the LLM then breaks down
    the problem and solves each step sequentially:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到“逐步思考”的指令后，LLM随后将问题分解并按顺序解决每个步骤：
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Many LLMs solve tasks step-by-step without being explicitly prompted to do so.
    This is because they have been *instruction-tuned* to solve tasks that way. We
    will learn more about instruction-tuning in Chapters [5](ch05.html#chapter_utilizing_llms)
    and [6](ch06.html#llm-fine-tuning). LLMs that have been instruction-tuned are
    easier to prompt.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLM在未明确提示的情况下会逐步解决任务。这是因为它们已经被*指令微调*以这种方式解决任务。我们将在第[5](ch05.html#chapter_utilizing_llms)章和第[6](ch06.html#llm-fine-tuning)章中了解更多关于指令微调的内容。经过指令微调的LLM更容易被提示。
- en: In the case of LLMs accessible through a user interface, a hidden prompt (called
    a system prompt) by the LLM provider might apply CoT prompting to relevant user
    prompts.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户界面可访问的LLM的情况下，LLM提供商可能通过一个隐藏的提示（称为系统提示）将CoT提示应用于相关用户提示。
- en: Should we add the “think step-by-step” CoT instruction for every prompt, like
    a cheat code to a game? [Sprague et al.](https://oreil.ly/3zJDC) evaluated CoT
    prompting over a wide variety of tasks and found that CoT primarily helps with
    tasks that need mathematical or logical reasoning. For tasks involving common-sense
    reasoning, they found that gains by CoT are limited. For knowledge-based tasks,
    CoT might even hurt.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否应该在每个提示中添加“逐步思考”的CoT指令，就像游戏中的作弊码一样？[Sprague等人](https://oreil.ly/3zJDC)评估了CoT提示在广泛任务中的应用，发现CoT主要有助于需要数学或逻辑推理的任务。对于涉及常识推理的任务，他们发现CoT的收益有限。对于基于知识的任务，CoT甚至可能有害。
- en: Note that arithmetic and logical reasoning could also be performed by delegating
    them to external tools like symbolic solvers and code interpreters. We will discuss
    this in detail in [Chapter 10](ch10.html#ch10).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，算术和逻辑推理也可以通过委托给外部工具（如符号求解器和代码解释器）来完成。我们将在[第10章](ch10.html#ch10)中详细讨论这一点。
- en: Warning
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Using CoT prompting significantly increases the number of tokens generated by
    the model to solve a task, leading to higher costs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CoT提示可以显著增加模型解决任务时生成的token数量，从而导致更高的成本。
- en: Prompt Chaining
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示链
- en: Often, your tasks need multiple steps and a large number of instructions. One
    way to go about this is by stuffing all the instructions into a single prompt.
    An alternative is to break the task into multiple subtasks and chain the prompts
    such that the output of one prompt determines the input to another. I have observed
    that prompt chaining consistently performs better than managing the entire task
    through a single prompt.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你的任务需要多个步骤和大量指令。一种处理方式是将所有指令塞入一个单独的提示中。另一种方法是把任务分解成多个子任务，并将提示链式连接，使得一个提示的输出成为另一个提示的输入。我观察到，提示链式连接通常比通过单个提示管理整个任务表现更好。
- en: As an example, consider the task of extracting information from the text provided
    in a form and formatting the output in a structured manner. If there are missing
    or outlier values, then some special postprocessing rules are to be applied. In
    this case, it is good practice to split the task into two prompts, with the initial
    prompt performing the information extraction and the second prompt handling the
    postprocessing of the extracted information.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑从表单中提供的文本中提取信息并将输出格式化的任务。如果有缺失或异常值，则需要应用一些特殊的后处理规则。在这种情况下，将任务分成两个提示是一个好习惯，第一个提示执行信息提取，第二个提示处理提取信息的后处理。
- en: Adversarial Prompting
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性提示
- en: You might notice that, for some queries, the LLM declines to execute your request.
    This is because it has been specifically trained to refuse certain kinds of requests
    (We will learn how to achieve this behavior in [Chapter 8](ch08.html#ch8)). This
    kind of training, which we will call *alignment training*, is imparted to the
    model to align it with the values and preferences of the entity developing the
    model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，对于某些查询，LLM拒绝执行你的请求。这是因为它被专门训练成拒绝某些类型的请求（我们将在[第8章](ch08.html#ch8)中学习如何实现这种行为）。这种我们称之为*对齐训练*的训练，是为了使模型与开发该模型的实体的价值观和偏好保持一致。
- en: For example, asking any decent LLM directly for instructions to build a bomb
    will result in a refusal. However, as of today, alignment training provides only
    a weak layer of security, as it can be bypassed by cleverly prompting the LLM,
    called *adversarial prompting*. Adversarial prompts can be generated either manually
    or using algorithms. These cleverly phrased prompts trick the LLM into generating
    a response even if it was trained not to.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，直接要求任何合理的LLM构建炸弹的指令将导致拒绝。然而，截至今天，对齐训练只提供了一层薄弱的安全保障，因为它可以通过巧妙地提示LLM来绕过，这被称为*对抗性提示*。对抗性提示可以手动生成或使用算法生成。这些巧妙措辞的提示会诱使LLM生成响应，即使它被训练成不应该这样做。
- en: These clever prompting schemes are not just useful for illicit purposes. In
    many cases, the LLM simply does not respond the way you want it to, and clever
    prompting schemes might help. These clever prompting schemes range from asking
    the LLM to adopt a specific persona to outright emotional blackmail (“If you don’t
    respond correctly to this query, many children will suffer!”). While there has
    been [some work](https://oreil.ly/q1I_7) showing that adding emotion to a prompt
    may lead to better performance, there is no hard, sustained evidence that this
    is universally effective for a given model. Thus, I would not recommend using
    these in production applications.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这些巧妙的提示方案不仅对非法用途有用。在许多情况下，LLM可能不会以你期望的方式响应，巧妙的提示方案可能有所帮助。这些巧妙的提示方案包括让LLM采取特定的角色，甚至直接进行情感勒索（“如果你不正确响应这个查询，许多孩子将遭受痛苦！”）。尽管有一些研究表明，在提示中添加情感可能会带来更好的性能，但没有确凿的、持续的证据表明这对特定模型是普遍有效的。因此，我不建议在生产应用中使用这些方法。
- en: Accessing LLMs Through an API
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过API访问LLMs
- en: You most likely have already interacted with an LLM through a chat interface
    like ChatGPT, Gemini, or Claude. Let’s now explore how to access them using the
    API. We will use the OpenAI API as an example to access its GPT family of models.
    Most other proprietary models expose similar parameters through their API.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你很可能已经通过ChatGPT、Gemini或Claude等聊天界面与LLM互动过。现在让我们探索如何使用API访问它们。我们将以OpenAI API为例，访问其GPT系列模型。大多数其他专有模型也通过它们的API公开了类似的参数。
- en: 'GPT-4o mini and GPT-4o can be accessed through OpenAI’s Chat Completion API.
    Here is an example:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o mini和GPT-4o可以通过OpenAI的Chat Completion API访问。以下是一个示例：
- en: '[PRE4]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Roles can be system, user, assistant, or tool.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 角色可以是系统、用户、助手或工具。
- en: The system role is used to specify an overarching prompt.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统角色用于指定一个总体的提示。
- en: The user role refers to user inputs.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户角色指的是用户输入。
- en: The assistant role refers to the model responses.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 助手角色指的是模型响应。
- en: The tool role is used to interact with external software tools.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具角色用于与外部软件工具交互。
- en: We will discuss tools in more detail in [Chapter 10](ch10.html#ch10).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第10章[第10章](ch10.html#ch10)中更详细地讨论工具。
- en: Note
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: What is the difference between the system and user roles? Which instructions
    should go into the system prompt and which ones into the user prompt? System prompts
    are used for dictating the high-level overarching behavior of an LLM, like “You
    are a financial expert well versed in writing formal reports.” If you are allowing
    your users to directly interact with the LLM, then the system prompt can be used
    to provide your own instruction to the LLM along with the user request. My experiments
    have shown that it doesn’t matter much if you place your instructions in the system
    prompt versus user prompt. What does matter is the length and number of instructions.
    LLMs typically can handle only a few instructions at a time. Instructions at the
    end or the beginning of the prompt are more likely to be adhered to.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 系统角色和用户角色之间的区别是什么？哪些指令应该放入系统提示，哪些应该放入用户提示？系统提示用于规定大型语言模型（LLM）的高级总体行为，例如：“您是一位精通撰写正式报告的金融专家。”如果您允许用户直接与LLM交互，那么系统提示可以用来向LLM提供您的指令以及用户请求。我的实验表明，将指令放在系统提示还是用户提示中并不重要。重要的是指令的长度和数量。LLM通常一次只能处理少量指令。提示中的末尾或开头的指令更有可能被遵守。
- en: 'Here are some of the parameters made available by OpenAI:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是OpenAI提供的部分参数：
- en: '`n`'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`n`'
- en: The number of completions the model has to generate for each input. For example,
    if we used n = 5 in the given example, it would generate five different children’s
    stories.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 模型为每个输入必须生成的完成次数。例如，如果我们使用给定的示例中的 n = 5，它将生成五个不同的儿童故事。
- en: Tip
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: For tasks with high reliability requirements, I advise generating multiple completions,
    that is, n > 1 and then using a postprocessing function (which could involve an
    LLM call) to choose the best one. This is because the LLM samples the generated
    text from a probability distribution, and in some cases the answer might be wrong/bad
    just due to an unlucky token sampling. You might have to balance this process
    against your budget limitations.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可靠性要求高的任务，我建议生成多个完成项，即 n > 1，然后使用后处理函数（这可能涉及LLM调用）来选择最佳项。这是因为LLM从概率分布中采样生成的文本，在某些情况下，答案可能只是由于不幸的标记采样而错误/不好。您可能需要在预算限制与这个过程之间进行权衡。
- en: '`stop` and `max_completion_tokens`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`stop` 和 `max_completion_tokens`'
- en: Used to limit the length of the generated output. `stop` allows you to specify
    end tokens that, if generated, would stop the generation process. An example stop
    sequence is the newline token. If you ask the model to adhere to a particular
    output format, like a numbered list of sentences, then to stop generating after
    a particular number of sentences have been output, you can just provide the final
    number as a stop parameter.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 用于限制生成输出的长度。`stop` 允许您指定结束标记，如果生成这些标记，则将停止生成过程。一个示例结束序列是换行符。如果您要求模型遵循特定的输出格式，例如句子的编号列表，那么在输出特定数量的句子后停止生成，只需提供最终数字作为停止参数即可。
- en: '`presence_penalty` and `frequency_penalty`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`presence_penalty` 和 `frequency_penalty`'
- en: Used to limit the repetitiveness of the generated output. By penalizing the
    probability for tokens that have already appeared in the output, we can ensure
    that the model isn’t being too repetitive. These parameters can be used while
    performing more creative tasks.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 用于限制生成输出的重复性。通过惩罚已出现在输出中的标记的概率，我们可以确保模型不会过于重复。这些参数可以在执行更具创造性任务时使用。
- en: '`logit_bias`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`logit_bias`'
- en: Using `logit_bias`, we can specify the tokens whose generation probability we
    want to increase or decrease.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `logit_bias`，我们可以指定我们想要增加或减少生成概率的标记。
- en: '`top_p` and `temperature`'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`top_p` 和 `temperature`'
- en: Both parameters relate to decoding strategies. LLMs produce a distribution of
    token probabilities and will sample from this distribution to generate the next
    token. There are many strategies to choose the next token to generate given the
    token probability distribution. We will discuss them in detail in [Chapter 5](ch05.html#chapter_utilizing_llms).
    For now, just remember that a higher temperature setting results in more creative
    and diverse outputs, and a lower temperature setting results in more predictable
    outputs. This [cheat sheet](https://oreil.ly/DAa66) provides some recommended
    values for various use cases.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个参数都与解码策略相关。LLMs会生成一个标记概率分布，并从这个分布中采样以生成下一个标记。在给定标记概率分布的情况下，有许多策略可以选择生成下一个标记。我们将在[第5章](ch05.html#chapter_utilizing_llms)中详细讨论这些策略。现在，只需记住，更高的温度设置会产生更多创意和多样化的输出，而更低的温度设置会产生更可预测的输出。这份[速查表](https://oreil.ly/DAa66)为各种用例提供了一些推荐值。
- en: '`logprobs`'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`logprobs`'
- en: Provides the most probable tokens for each output token along with their log
    probabilities. OpenAI limits this to the top 20 most probable tokens. In later
    chapters, we will discuss how we can leverage `logprobs` information in various
    forms.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个输出标记提供最可能的标记及其对数概率。OpenAI将其限制为前20个最可能的标记。在后面的章节中，我们将讨论如何利用各种形式的`logprobs`信息。
- en: Strengths and Limitations of LLMs
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的优缺点
- en: Developing intuition about the strengths and limitations of LLMs is a crucial
    skill in being able to build useful LLM applications. Using the information in
    this book, and with ample hands-on practice, you will be able to build that intuition.
    In general, LLMs are proficient at language tasks. You will almost never see them
    make spelling or grammar errors. They are a vast improvement over previous techniques
    for understanding user instructions and intent. They also exhibit state-of-the-art
    performance on most NLP tasks like entity and relationship extraction and NER.
    And they are particularly strong at generating code, which is where LLMs have
    arguably found their greatest success through tools like [GitHub Copilot](https://oreil.ly/qvriE).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 理解LLMs（大型语言模型）的优缺点是构建有用LLMs应用的关键技能。通过使用本书中的信息和充分的动手实践，你将能够培养这种直觉。一般来说，LLMs在语言任务方面非常擅长。你几乎不会看到它们犯拼写或语法错误。它们在理解用户指令和意图方面比之前的技术有了巨大的改进。它们在大多数NLP任务（如实体和关系抽取以及命名实体识别）上也表现出最先进的性能。而且，它们在生成代码方面特别强大，这也是LLMs通过像[GitHub
    Copilot](https://oreil.ly/qvriE)这样的工具找到其最大成功的地方。
- en: Most LLM limitations boil down to the fact that LLMs are just not intelligent
    enough. Even state-of-the-art models suffer from significant limitations in reasoning,
    including arithmetic reasoning, logical reasoning, and common-sense reasoning.
    (We will define reasoning more formally in [Chapter 8](ch08.html#ch8).) LLMs are
    also unable to adhere to factuality, because of their lack of connection to the
    real world. Therefore, they tend to generate text that might be inconsistent with
    real-world facts and principles, colloquially called *hallucinations*. Hallucinations
    are the bane of LLMs and one of the key reasons for hesitations in adopting them.
    In [Chapter 8](ch08.html#ch8), we will dive deep into various methods to tackle
    hallucinations and address reasoning limitations.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数LLMs的局限性归结为LLMs本身并不足够智能。即使是最先进的模型也遭受着推理方面的重大限制，包括算术推理、逻辑推理和常识推理。（我们将在[第8章](ch08.html#ch8)中更正式地定义推理。）LLMs也无法坚持事实性，因为它们与现实世界缺乏联系。因此，它们倾向于生成可能与现实世界事实和原则不一致的文本，俗称为*幻觉*。幻觉是LLMs的噩梦，也是人们犹豫采用它们的关键原因之一。在[第8章](ch08.html#ch8)中，我们将深入探讨各种应对幻觉和解决推理局限性的方法。
- en: Tons of LLM-generated articles are being uploaded to the web daily, and many
    of them make their way to the top of search engine results. For example, for a
    short while, for the query “Can you melt eggs?”, [Google showed](https://oreil.ly/ivvv_)
    “Yes, an egg can be melted,” due to an AI-generated web page containing the incorrect
    answer. This kind of text is colloquially referred to as AI slop. Thus, there
    is a very strong incentive for search engines to accurately detect AI-generated
    text. Note that since LLMs are primarily trained on web text, future LLMs can
    be contaminated by polluted text as well.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 每天都有大量由LLM生成的文章被上传到网络上，其中许多文章登上了搜索引擎结果页的顶部。例如，对于“你能融化鸡蛋吗？”这个查询，[谷歌一度显示](https://oreil.ly/ivvv_)“是的，鸡蛋可以被融化”，这是因为一个包含错误答案的AI生成的网页。这类文本通常被称为AI垃圾。因此，搜索引擎有很强的动力准确检测AI生成的文本。请注意，由于LLM主要是基于网络文本进行训练的，未来的LLM也可能被污染文本所污染。
- en: While LLMs are frequently used to aid creative tasks, they are nowhere near
    the level of professional authors. Fiction authored by current LLMs is still unlikely
    to be a bestseller. LLM-generated text lacks the sheer ingenuity and the ability
    to evoke human emotions that human authors possess. Once you have read through
    enough LLM-generated text, it is not that difficult to spot it.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型（LLM）常被用于辅助创意任务，但它们与专业作者的水平相去甚远。目前由LLM创作的小说仍不太可能成为畅销书。LLM生成的文本缺乏人类作者所拥有的纯粹的创新性和唤起人类情感的能力。一旦你阅读了足够多的LLM生成的文本，就并不难发现它们。
- en: Every LLM generates text with a distinct signature, some more apparent to humans
    than others. For example, you might have noticed that ChatGPT tends to overuse
    certain words like “delve,” “tapestry,” “bustling,” etc. ChatGPT also tends to
    generate sentences with an explanatory final clause, like “He ate the entire pizza,
    indicating he was hungry.” Or “The vampire sent a thousand text messages in a
    month, suggesting effective use of digital technologies.” However, it is [extremely
    hard](https://oreil.ly/4skjI) to detect AI-generated text with 100% accuracy.
    Bad actors are also employing evasion techniques, for instance by asking another
    LLM to rephrase LLM-generated text to dilute the signature of the original LLM.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 每个LLM生成的文本都有独特的特征，有些比其他更容易被人类察觉。例如，你可能已经注意到ChatGPT倾向于过度使用某些词汇，如“深入研究”、“锦缎”、“繁忙”等。ChatGPT还倾向于生成带有解释性结尾句子的句子，例如：“他吃掉了整个披萨，这表明他很饿。”或者“吸血鬼在一个月内发送了一千条短信，这表明有效利用了数字技术。”然而，[极其困难](https://oreil.ly/4skjI)以100%的准确率检测到AI生成的文本。不良分子也在使用规避技术，例如让另一个LLM重新措辞LLM生成的文本，以稀释原始LLM的特征。
- en: Thus, plagiarism detection has become even more challenging, including cases
    of students being [unfairly accused of plagiarism](https://oreil.ly/hetca) due
    to inaccurate AI-text detectors. These trends are prompting universities worldwide
    to rethink how students are evaluated, depending less on essays. Students are
    some of the heaviest users of LLM products, as shown by a [decline in ChatGPT
    usage numbers](https://oreil.ly/5xECI) during summer months.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，抄袭检测变得更加困难，包括由于AI文本检测器不准确而导致学生被[不公平地指控抄袭](https://oreil.ly/hetca)的情况。这些趋势促使全球大学重新思考如何评估学生，减少对论文的依赖。正如夏季月份ChatGPT使用量的下降所示，学生是LLM产品的一些主要使用者。
- en: While words like “delve” are known to be overused by LLMs, single-token frequencies
    should not be relied upon as a means of detecting LLM-generated text. Having grown
    up in India learning Indian English, the word “delve” appears in my vocabulary
    a lot more frequently than the average Westerner, and this can be found in my
    writing and publications well before the launch of ChatGPT. These nuances show
    that more robust techniques need to be developed to discover LLM-generated text.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然已知“深入研究”这类词汇被LLM过度使用，但不应依赖单词频率作为检测LLM生成文本的手段。作为一个在印度长大、学习印度英语的人，单词“深入研究”在我的词汇中出现的频率比普通西方人高得多，这可以在ChatGPT推出之前我的写作和出版物中找到。这些细微差别表明，需要开发更稳健的技术来发现LLM生成的文本。
- en: One promising approach uses syntactic templates, a sequence of tokens having
    a particular order of part-of-speech (POS) tags, typically 5–8 tokens long. [Shaib
    et al.](https://oreil.ly/n_dXJ) show that some of these templates appear in generated
    text even when text generation strategies (also called decoding strategies, described
    in detail in [Chapter 5](ch05.html#chapter_utilizing_llms)) aimed to increase
    token diversity are used. They show that these templates are learned during the
    early stages of the pre-training process.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有希望的方法是使用句法模板，一系列具有特定词性（POS）标签顺序的标记，通常长度为5-8个标记。[Shaib等人](https://oreil.ly/n_dXJ)表明，即使在使用旨在增加标记多样性的文本生成策略（也称为解码策略，在第五章中详细描述）时，这些模板也会出现在生成的文本中。他们表明，这些模板是在预训练过程的早期阶段学习的。
- en: 'An example template is:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例模板是：
- en: 'VBN IN JJ NNS: VBN (Past Participle Verb) + IN (Preposition) + JJ (Adjective)
    + NNS (Plural Noun).'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 'VBN IN JJ NNS: VBN (过去分词动词) + IN (介词) + JJ (形容词) + NNS (复数名词)。'
- en: 'Examples of phrases that follow this template include:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 符合此模板的短语示例包括：
- en: Engaged in complex tasks
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从事复杂任务
- en: Trained in advanced techniques
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受过高级技术的训练
- en: Entangled in deep emotions
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深陷于深切的情感中
- en: Immersed in vivid memories
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沉浸在生动的记忆中
- en: Have you noticed any LLMs frequently using or overusing this template?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有注意到LLM经常使用或过度使用这个模板？
- en: Building Your First Chatbot Prototype
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建你的第一个聊天机器人原型
- en: Let’s get into the weeds and start building!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入细节，开始构建！
- en: Over the last couple of years, a healthy ecosystem of libraries has made experimenting
    and prototyping LLM applications much easier. In fact, you can build a *Chat with
    your PDF* question-answering chatbot in about a hundred lines of code!
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，一个健康的库生态系统使得实验和原型化LLM应用变得容易得多。事实上，你可以在大约一百行代码内构建一个“用你的PDF聊天”问答聊天机器人！
- en: Let’s implement a simple application that allows the user to upload a PDF document
    and provides a chat interface through which the user can ask questions about the
    PDF content and receive conversational responses.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现一个简单的应用程序，允许用户上传PDF文档，并通过聊天界面提问关于PDF内容，并接收对话式响应。
- en: 'The intended workflow for this application is:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用的预期工作流程是：
- en: The user uploads a PDF of their choice through the user interface.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户可以通过用户界面上传他们选择的PDF。
- en: The application parses the PDF using a PDF parsing library and splits the extracted
    text into manageable chunks.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序使用PDF解析库解析PDF，并将提取的文本分割成可管理的块。
- en: The chunks are converted into vector form, called embeddings.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将块转换为向量形式，称为嵌入。
- en: When a user issues a query through the chat interface, the query is also converted
    into vector form.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当用户通过聊天界面提出查询时，查询也被转换为向量形式。
- en: The vector similarity between the query vector and each of the chunk vectors
    is calculated.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算查询向量与每个块向量的向量相似度。
- en: The text corresponding to the top-k most similar vectors are retrieved.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取与最相似的k个向量对应的文本。
- en: The retrieved text is fed, along with the query and any other additional instructions,
    to an LLM.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索到的文本，连同查询和任何其他附加指令，一起输入到LLM中。
- en: The LLM uses the given information to generate an answer to the user query.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM使用给定的信息来生成对用户查询的答案。
- en: The response is displayed on the user interface.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 响应将在用户界面上显示。
- en: The user can now respond (clarification question, new question, gratitude, etc.).
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户现在可以做出回应（澄清问题、新问题、感谢等）。
- en: The entire conversation history is fed back to the LLM during each turn of the
    conversation.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次对话回合中，将整个对话历史反馈给LLM。
- en: '[Figure 1-5](#chatbot-prototype) illustrates this workflow.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-5](#chatbot-prototype)说明了这个工作流程。'
- en: '![chatbot-prototype](assets/dllm_0105.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![chatbot-prototype](assets/dllm_0105.png)'
- en: Figure 1-5\. Workflow of a chatbot application
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 聊天机器人应用程序的工作流程
- en: 'Let’s begin by installing the required libraries. For this setup, we are going
    to use:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先安装所需的库。为此设置，我们将使用：
- en: '[LangChain](https://oreil.ly/g833p)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[LangChain](https://oreil.ly/g833p)'
- en: This very popular framework enables building LLM application pipelines.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这个非常流行的框架使得构建LLM应用管道变得容易。
- en: '[Gradio](https://oreil.ly/XHqfT)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gradio](https://oreil.ly/XHqfT)'
- en: This library allows you to build LLM-driven user interfaces.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个库允许你构建由LLM驱动的用户界面。
- en: '[Unstructured](https://oreil.ly/sIFEX)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[Unstructured](https://oreil.ly/sIFEX)'
- en: This is a PDF parsing suite that supports a variety of methods for extracting
    text from PDFs.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个支持从PDF中提取文本的多种方法的PDF解析套件。
- en: '[Sentence Transformers](https://oreil.ly/UyN1k)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sentence Transformers](https://oreil.ly/UyN1k)'
- en: This library facilitates embeddings generation from texts.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这个库简化了从文本生成嵌入的过程。
- en: '[OpenAI](https://oreil.ly/zbroe)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenAI](https://oreil.ly/zbroe)'
- en: This API provides access to the GPT family of models from OpenAI.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此API提供了对OpenAI的GPT系列模型的访问。
- en: 'Let’s import the required libraries and functions:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入所需的库和函数：
- en: '[PRE5]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, let’s implement the PDF loading and parsing function. LangChain supports
    several PDF parsing libraries. PDF parsing can be performed in a variety of ways,
    including using LLMs. For this example, we will choose the Unstructured library:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们实现PDF加载和解析功能。LangChain支持多个PDF解析库。PDF解析可以通过多种方式执行，包括使用LLM（大型语言模型）。在这个例子中，我们将选择Unstructured库：
- en: '[PRE6]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `data` variable contains the parsed PDF that has been split into paragraphs.
    We will refer to each paragraph as a chunk. Each chunk is now converted into its
    vector representation using an embedding model. LangChain supports a wide variety
    of embedding models. For this example, we will use the *all-MiniLM-L6-V2* embedding
    model, available through the Hugging Face platform:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`data`变量包含已分割成段落的解析PDF。我们将每个段落称为一个块。现在，每个块都使用嵌入模型转换为它的向量表示。LangChain支持广泛的嵌入模型。在这个例子中，我们将使用通过Hugging
    Face平台提供的*all-MiniLM-L6-V2*嵌入模型：'
- en: '[PRE7]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that we have loaded the embedding model, we can generate the vectors from
    the data and store them in a vector database. Several vector database integrations
    are available on LangChain. We will use Chroma for this example, as it is the
    simplest to use:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了嵌入模型，我们可以从数据中生成向量并将它们存储在向量数据库中。LangChain上有几个向量数据库集成。在这个例子中，我们将使用Chroma，因为它使用起来最简单：
- en: '[PRE8]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The vector database is ready with the vectors! We can ask queries and get responses.
    For instance:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库已经准备好了，带有向量！我们可以提出查询并获得响应。例如：
- en: '[PRE9]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This code retrieves the paragraph in the PDF whose vector is most similar to
    the vector representing the user query. Since vectors encode the meaning of the
    text, this means that the paragraph representing the similar vector has content
    similar to the content of the query.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码检索了PDF中与表示用户查询的向量最相似的段落。由于向量编码了文本的意义，这意味着表示相似向量的段落内容与查询内容相似。
- en: Note that it is not guaranteed that the paragraph contains the answer to the
    query. Using embeddings, we can only get text that is similar to the query. The
    matched text need not contain the answer or even be relevant to answering the
    query.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，不能保证段落包含查询的答案。使用嵌入，我们只能得到与查询相似的文字。匹配的文本不一定包含答案，甚至可能不与回答查询相关。
- en: 'We will depend on the LLM to distinguish between irrelevant and relevant context.
    We provide the LLM with the query and the retrieved text and ask it to answer
    the query given the provided information. This workflow can be implemented using
    a `chain` in LangChain:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将依赖LLM来区分无关和相关的上下文。我们向LLM提供查询和检索到的文本，并要求它根据提供的信息回答查询。这个工作流程可以使用LangChain中的`chain`实现：
- en: '[PRE10]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We use the `ConversationalRetrievalChain`, which supports the following workflow:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`ConversationalRetrievalChain`，它支持以下工作流程：
- en: Takes the previous conversational history, if it exists, and the current response/query
    from the user and creates a standalone question.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果存在，从先前的对话历史中获取并创建一个独立的查询。
- en: Uses a chosen retrieval method to retrieve top-k most similar chunks to the
    question.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用选择的检索方法检索与问题最相似的top-k个块。
- en: Takes the retrieved chunks, the conversational history, the current user/response
    query, and instructions and feeds it to the LLM. The LLM generates the answer.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从检索到的块、对话历史、当前用户/响应查询和指令中获取数据，并将其输入到LLM中。LLM生成答案。
- en: 'We can call the chain and append the result to the chat history:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以调用链并追加结果到聊天历史中：
- en: '[PRE11]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Our chatbot is ready. Let’s wrap it up by connecting it with a user interface.
    We will use [Gradio](https://oreil.ly/dzYJv), a lightweight Python framework for
    building LLM-driven user interfaces:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的聊天机器人已经准备好了。让我们通过连接用户界面来结束它。我们将使用[Gradio](https://oreil.ly/dzYJv)，这是一个用于构建LLM驱动用户界面的轻量级Python框架：
- en: '[PRE12]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We need some more code for writing the event handlers that wait for user events.
    Refer to the full code on the book’s [GitHub repo](https://oreil.ly/llm-playbooks).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要更多的代码来编写等待用户事件的处理器。请参阅书籍的[GitHub仓库](https://oreil.ly/llm-playbooks)中的完整代码。
- en: 'Finally, we initialize the application:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们初始化应用程序：
- en: '[PRE13]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Our chatbot application is ready!
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的聊天机器人应用程序已经准备好了！
- en: Note
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Why can’t we feed the entire PDF to the LLM instead of breaking it down into
    chunks and retrieving only the relevant information? This depends on the maximum
    effective context length supported by the LLM, which limits the size of the input
    it can accept. Larger models support context lengths large enough to fit several
    PDFs in the input, in which case you may not need to perform the chunking and
    embedding process at all.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们不能将整个PDF直接喂给LLM，而不是将其拆分成块并只检索相关信息？这取决于LLM支持的最大有效上下文长度，这限制了它可以接受的输入大小。较大的模型支持足够长的上下文长度，可以容纳多个PDF作为输入，在这种情况下，你可能根本不需要执行分块和嵌入过程。
- en: From Prototype to Production
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从原型到生产
- en: Is building LLM applications that easy? Unfortunately, no. We have built a prototype,
    and a decent one at that. For many noncritical use cases, the performance of this
    application might even be sufficient. However, a large number of use cases demand
    accuracy and reliability guarantees that this application is not able to meet.
    This book aims to address the gap between prototype and production.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 构建LLM应用程序真的这么容易吗？不幸的是，并非如此。我们已经构建了一个原型，而且是一个相当不错的原型。对于许多非关键用例，该应用程序的性能可能甚至足够。然而，大量用例需要准确性和可靠性保证，而该应用程序无法满足这些要求。本书旨在填补原型与生产之间的差距。
- en: In the prototype tutorial, we treated LLMs as a black box. But if you are building
    serious applications using LLMs, it is important to understand what happens under
    the hood, even if you might never train an LLM yourself. Therefore, in Chapters
    [2](ch02.html#ch02), [3](ch03.html#chapter-LLM-tokenization), and [4](ch04.html#chapter_transformer-architecture),
    we will walk through each of the ingredients that go into making an LLM and show
    how they are trained. Developing a strong understanding of what LLMs are made
    of and how they are trained will come in handy when debugging failure modes.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在原型教程中，我们将LLM视为一个黑盒。但如果你正在使用LLM构建严肃的应用程序，了解底层发生的事情很重要，即使你可能永远不会自己训练LLM。因此，在第[2章](ch02.html#ch02)、[3章](ch03.html#chapter-LLM-tokenization)和[4章](ch04.html#chapter_transformer-architecture)中，我们将逐一介绍构成LLM的各个组成部分，并展示它们是如何被训练的。对LLM的构成和训练过程有深入的理解，在调试故障模式时将非常有用。
- en: In the tutorial, we used a proprietary LLM from OpenAI, without putting much
    thought into whether it is the optimal LLM to use for the application. Today,
    hundreds or even thousands of LLMs are available for commercial use. In [Chapter 5](ch05.html#chapter_utilizing_llms),
    we will explore the LLM landscape, covering both open source and proprietary models,
    the relevant dimensions along which models differ, and how to choose the right
    model that satisfies the criteria for a given use case. For example, one of the
    criteria for our PDF chatbot might be to operate within a severe budgetary restriction.
    We will learn how to evaluate LLMs and assess their limitations and capabilities
    for a given use case, develop evaluation metrics and benchmark datasets, and understand
    the pitfalls involved in both automated evaluation and human evaluation.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在教程中，我们使用了来自OpenAI的专有LLM，并没有过多考虑它是否是适用于该应用的理想LLM。如今，数百甚至数千种LLM可供商业使用。在[第5章](ch05.html#chapter_utilizing_llms)中，我们将探讨LLM的生态系统，涵盖开源和专有模型，以及模型之间差异的相关维度，以及如何选择满足特定用例标准的正确模型。例如，我们PDF聊天机器人的一个标准可能是在严格的预算限制下运行。我们将学习如何评估LLM，评估它们在特定用例中的局限性和能力，开发评估指标和基准数据集，并了解自动评估和人工评估中可能遇到的陷阱。
- en: What if the PDFs we intend to upload to the PDF chatbot belong to a specialized
    domain that the LLM doesn’t seem to be adept at? What if the LLM is unable to
    follow the instructions in user queries? We might need to update the model’s parameters
    by fine-tuning it over data from the specialized domain. In [Chapter 6](ch06.html#llm-fine-tuning),
    we will introduce model fine-tuning, understand the scenarios in which it might
    be useful, and demonstrate how to construct a fine-tuning dataset.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打算上传到PDF聊天机器人的PDF属于LLM似乎不太擅长的专业领域怎么办？如果LLM无法遵循用户查询中的指示怎么办？我们可能需要通过在专业领域的数据上微调模型来更新模型的参数。在[第6章](ch06.html#llm-fine-tuning)中，我们将介绍模型微调，了解可能有用的情况，并演示如何构建微调数据集。
- en: It is possible that standard fine-tuning might not be suitable for our purposes.
    Maybe it is too expensive or ineffective. In [Chapter 7](ch07.html#ch07), we will
    learn about techniques like parameter-efficient fine-tuning that update only a
    small subset of the model’s parameters.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 标准微调可能不适合我们的目的。也许它太昂贵或效果不佳。在[第7章](ch07.html#ch07)中，我们将了解像参数高效微调这样的技术，它只更新模型参数的一小部分。
- en: We may notice that our chatbot is hallucinating, or that it is having difficulty
    answering questions because of faulty reasoning. In [Chapter 8](ch08.html#ch8),
    we will discuss methods for detecting and mitigating hallucinations as well as
    methods for enhancing reasoning capabilities, including various inference-time
    compute techniques.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会注意到我们的聊天机器人正在进行幻觉，或者它因为推理错误而难以回答问题。在[第8章](ch08.html#ch8)中，我们将讨论检测和减轻幻觉的方法，以及增强推理能力的方法，包括各种推理时计算技术。
- en: A production-grade PDF chatbot will need to satisfy a lot of nonfunctional requirements,
    including minimizing latency (the time the user needs to wait for the model response)
    and cost. In [Chapter 9](ch09.html#ch09), we will discuss techniques for inference
    optimization, including caching, distillation, and quantization.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 一个生产级别的PDF聊天机器人需要满足许多非功能性需求，包括最小化延迟（用户等待模型响应的时间）和成本。在[第9章](ch09.html#ch09)中，我们将讨论推理优化的技术，包括缓存、蒸馏和量化。
- en: We may want to extend functionality of our chatbot by connecting the LLM to
    code interpreters, databases, and APIs. We might also want the chatbot to answer
    complex queries that need to be broken into multiple steps. In [Chapter 10](ch10.html#ch10),
    we’ll explore how to interface LLMs with external tools and data sources and enable
    LLMs to break down tasks, make autonomous decisions, and interface with their
    environment.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望通过将LLM连接到代码解释器、数据库和API来扩展聊天机器人的功能。我们可能还希望聊天机器人能够回答需要分解成多个步骤的复杂查询。在[第10章](ch10.html#ch10)中，我们将探讨如何将LLM与外部工具和数据源接口，并使LLM能够分解任务、做出自主决策并与环境接口。
- en: In the tutorial, we demonstrated a rudimentary method to parse, chunk, and embed
    documents. But during usage, we might notice that the vector similarity measures
    might be ineffective and often return irrelevant document chunks. Or that the
    retrieved chunks do not contain all the information to answer the query. In [Chapter 11](ch11.html#chapter_llm_interfaces),
    we will explore embeddings in more detail and learn how to fine-tune our own embeddings.
    We will also show how to more effectively chunk data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在教程中，我们演示了一种基本的解析、分块和嵌入文档的方法。但在使用过程中，我们可能会注意到向量相似度度量可能无效，并且经常返回不相关的文档块。或者检索到的块不包含回答查询所需的所有信息。在[第11章](ch11.html#chapter_llm_interfaces)中，我们将更详细地探讨嵌入，并学习如何微调我们自己的嵌入。我们还将展示如何更有效地分块数据。
- en: The PDF chatbot follows a paradigm called retrieval-augmented generation (RAG).
    RAG refers to systems where LLMs are connected to external data sources, like
    the PDFs uploaded by users in our chatbot use case. In [Chapter 12](ch12.html#ch12),
    we will define a comprehensive RAG pipeline and learn how to architect robust
    RAG systems.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: PDF聊天机器人遵循一种称为检索增强生成（RAG）的范式。RAG指的是LLM连接到外部数据源的系统，例如我们聊天机器人用例中用户上传的PDF。在[第12章](ch12.html#ch12)中，我们将定义一个全面的RAG管道，并学习如何构建健壮的RAG系统。
- en: Finally, in [Chapter 13](ch13.html#ch13) we will discuss design patterns and
    programming paradigms for developing LLM applications.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在[第13章](ch13.html#ch13)中，我们将讨论开发LLM应用程序的设计模式和编程范式。
- en: These topics and more will be covered in the rest of the book. I am excited
    to go on this journey with you, hopefully providing you with the tools, techniques,
    and intuition to develop production-grade LLM applications!
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主题以及更多内容将在本书的其余部分进行讨论。我很高兴与您一起踏上这段旅程，希望为您提供开发生产级LLM应用程序所需的工具、技术和直觉！
- en: Summary
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced language models, provided a brief history, and
    discussed the impact they are already having on the world. We showed how to effectively
    interact with the model using various prompting techniques. We also gave an overview
    of the strengths and limitations of language models. We showed how easy it is
    to build prototype applications and highlighted the challenges involved in taking
    them to production. In the next chapter, we will begin our journey into the world
    of LLMs by introducing the ingredients that go into making an LLM.*
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了语言模型，提供了简要的历史背景，并讨论了它们对世界产生的影响。我们展示了如何使用各种提示技术有效地与模型互动。我们还概述了语言模型的优点和局限性。我们展示了构建原型应用是多么容易，并强调了将它们推向生产所涉及到的挑战。在下一章中，我们将通过介绍构成大型语言模型（LLM）的要素，开始我们的LLM世界之旅。*
