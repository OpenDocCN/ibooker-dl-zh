- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Deep Learning in the World Today
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当今世界的深度学习
- en: Hello and welcome! This book will introduce you to deep learning via PyTorch,
    an open source library released by Facebook in 2017\. Unless you’ve had your head
    stuck in the ground in a very good impression of an ostrich the past few years,
    you can’t have helped but notice that neural networks are everywhere these days.
    They’ve gone from being the *really cool bit of computer science that people learn
    about and then do nothing with* to being carried around with us in our phones
    every day to improve our pictures or listen to our voice commands. Our email software
    reads our email and produces context-sensitive replies, our speakers listen out
    for us, cars drive by themselves, and the computer has finally bested humans at
    Go. We’re also seeing the technology being used for more nefarious ends in authoritarian
    countries, where neural network–backed sentinels can pick faces out of crowds
    and make a decision on whether they should be apprehended.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你好，欢迎！本书将通过PyTorch这个由Facebook于2017年发布的开源库来介绍深度学习。除非你过去几年一直把头埋在地里，否则你一定会注意到神经网络如今无处不在。它们已经从*计算机科学中人们学习后却不做任何事情的非常酷的部分*，变成了我们每天随身携带的手机中，用来改善我们的图片或听取我们的语音指令。我们的电子邮件软件读取我们的邮件并生成上下文相关的回复，我们的扬声器倾听我们，汽车自动驾驶，计算机终于在围棋上战胜了人类。我们还看到这项技术被用于更邪恶的目的，在威权国家，神经网络支持的哨兵可以从人群中识别出面孔，并决定是否应该逮捕他们。
- en: And yet, despite the feeling that this has all happened so fast, the concepts
    of neural networks and deep learning go back a long way. The proof that such a
    network could function as a way of replacing *any* mathematical function in an
    approximate way, which underpins the idea that neural networks can be trained
    for many different tasks, dates back to 1989,^([1](preface01.html#idm45762375164216))
    and convolutional neural networks were being used to recognize digits on check
    in the late ’90s. There’s been a solid foundation building up all this time, so
    why does it feel like an explosion occurred in the last 10 years?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管感觉一切发生得如此迅速，但神经网络和深度学习的概念早已存在很久。证明这样一个网络可以作为一种以近似方式替代*任何*数学函数的方式运行的证据，这是神经网络可以被训练用于许多不同任务的基础，可以追溯到1989年，而卷积神经网络在90年代后期就被用来识别支票上的数字了。这一切时间里一直在建立坚实的基础，那么为什么感觉在过去的10年里发生了爆炸呢？
- en: There are many reasons, but prime among them has to be the surge in *graphical
    processing units* (GPUs) performance and their increasing affordability. Designed
    originally for gaming, GPUs need to perform countless millions of matrix operations
    per second in order to render all the polygons for the driving or shooting game
    you’re playing on your console or PC, operations that a standard CPU just isn’t
    optimized for. A 2009 paper, “Large-Scale Deep Unsupervised Learning Using Graphics
    Processors” by Rajat Raina et al., pointed out that training neural networks was
    also based on performing lots of matrix operations, and so these add-on graphics
    cards could be used to speed up training as well as make larger, *deeper* neural
    network architectures feasible for the first time. Other important techniques
    such as *Dropout* (which we will look at in [Chapter 3](ch03.html#convolutional-neural-networks))
    were also introduced in the last decade as ways to not just speed up training
    but make training more *generalized* (so that the network doesn’t just learn to
    recognize the training data, a problem called *overfitting* that we’ll encounter
    in the next chapter). In the last couple of years, companies have taken this GPU-based
    approach to the next level, with Google creating what it describes as *tensor
    processing units* (TPUs), which are devices custom-built for performing deep learning
    as fast as possible, and are even available to the general public as part of their
    Google Cloud ecosystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多原因，但其中最主要的原因必须是*图形处理单元*（GPU）性能的激增以及它们日益可负担的价格。最初设计用于游戏的GPU需要每秒执行数以百万计的矩阵运算，以便在您的游戏机或PC上渲染所有多边形，这些操作是标准CPU无法优化的。2009年的一篇论文，“使用图形处理器进行大规模深度无监督学习”由Rajat
    Raina等人指出，训练神经网络也是基于执行大量矩阵运算，因此这些附加的图形卡可以用于加速训练，同时使更大、*更深*的神经网络架构首次变得可行。其他重要技术，如*Dropout*（我们将在[第3章](ch03.html#convolutional-neural-networks)中讨论），也在过去的十年中被引入，作为不仅加速训练而且使训练更*泛化*的方法（这样网络不仅学会识别训练数据，还会遇到我们将在下一章中遇到的*过拟合*问题）。在过去几年里，公司们已经将这种基于GPU的方法推向了一个新的水平，谷歌创建了他们所描述的*张量处理单元*（TPUs），这些设备专门用于尽可能快地执行深度学习，并且甚至作为谷歌云生态系统的一部分向普通公众提供。
- en: Another way to chart deep learning’s progress over the past decade is through
    the ImageNet competition. A massive database of over 14 million pictures, manually
    labeled into 20,000 categories, ImageNet is a treasure trove of labeled data for
    machine learning purposes. Since 2010, the yearly ImageNet Large Scale Visual
    Recognition Challenge has sought to test all comers against a 1,000-category subset
    of the database, and until 2012, error rates for tackling the challenge rested
    around 25%. That year, however, a deep convolutional neural network won the competition
    with an error of 16%, massively outperforming all other entrants. In the years
    that followed, that error rate got pushed down further and further, to the point
    that in 2015, the ResNet architecture obtained a result of 3.6%, which beat the
    average human performance on ImageNet (5%). We had been outclassed.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年来，追踪深度学习的进展的另一种方式是通过ImageNet竞赛。ImageNet是一个包含超过1400万张图片的庞大数据库，手动标记为20000个类别，对于机器学习目的来说，ImageNet是一个标记数据的宝库。自2010年以来，每年的ImageNet大规模视觉识别挑战赛一直试图测试所有参与者对数据库的1000个类别子集的处理能力，直到2012年，挑战的错误率一直在25%左右。然而，那一年，一个深度卷积神经网络以16%的错误率赢得了比赛，远远超过了所有其他参赛者。随着接下来的几年，错误率不断下降，直到2015年，ResNet架构获得了3.6%的结果，超过了ImageNet上的平均人类表现（5%）。我们被超越了。
- en: But What Is Deep Learning Exactly, and Do I Need a PhD to Understand It?
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 但深度学习究竟是什么，我需要博士学位才能理解吗？
- en: Deep learning’s definition often is more confusing than enlightening. A way
    of defining it is to say that deep learning is a machine learning technique that
    uses multiple and numerous layers of nonlinear transforms to progressively extract
    features from raw input. Which is true, but it doesn’t really help, does it? I
    prefer to describe it as a technique to solve problems by providing the inputs
    and desired outputs and letting the computer find the solution, normally using
    a neural network.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的定义通常比启发性更令人困惑。一种定义深度学习的方式是说，深度学习是一种利用多个和众多层的非线性变换逐渐从原始输入中提取特征的机器学习技术。这是正确的，但并没有真正帮助，对吧？我更喜欢将其描述为一种通过提供输入和期望输出来解决问题的技术，并让计算机找到解决方案，通常使用神经网络。
- en: 'One thing about deep learning that scares off a lot of people is the mathematics.
    Look at just about any paper in the field and you’ll be subjected to almost impenetrable
    amounts of notation with Greek letters all over the place, and you’ll likely run
    screaming for the hills. Here’s the thing: for the most part, you don’t need to
    be a math genius to use deep learning techniques. In fact, for most day-to-day
    basic uses of the technology, you don’t need to know much at all, and to really
    understand what’s going on (as you’ll see in [Chapter 2](ch02.html#image-classification-with-pytorch)),
    you only have to stretch a little to understand concepts that you probably learned
    in high school. So don’t be too scared about the math. By the end of [Chapter 3](ch03.html#convolutional-neural-networks),
    you’ll be able to put together an image classifier that rivals what the best minds
    in 2015 could offer with just a few lines of code.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中吓倒很多人的一件事是数学。看看这个领域的任何论文，你将会看到几乎无法理解的大量符号，到处都是希腊字母，你可能会吓得四处奔跑。事实是：在大多数情况下，你不需要成为数学天才来使用深度学习技术。实际上，对于技术的大多数日常基本用途，你根本不需要了解太多，要真正理解正在发生的事情（正如你将在[第2章](ch02.html#image-classification-with-pytorch)中看到的那样），你只需要稍微努力一下，理解你可能在高中学到的概念。所以不要太害怕数学。到[第3章](ch03.html#convolutional-neural-networks)结束时，你将能够用几行代码组建一个图像分类器，与2015年最优秀的人才所能提供的相媲美。
- en: PyTorch
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch
- en: As I mentioned back at the start, PyTorch is an open source offering from Facebook
    that facilitates writing deep learning code in Python. It has two lineages. First,
    and perhaps not entirely surprisingly given its name, it derives many features
    and concepts from Torch, which was a Lua-based neural network library that dates
    back to 2002\. Its other major parent is Chainer, created in Japan in 2015\. Chainer
    was one of the first neural network libraries to offer an eager approach to differentiation
    instead of defining static graphs, allowing for greater flexibility in the way
    networks are created, trained, and operated. The combination of the Torch legacy
    plus the ideas from Chainer has made PyTorch popular over the past couple of years.^([2](preface01.html#idm45762372338792))
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在开头提到的，PyTorch是Facebook提供的一个开源工具，可以在Python中编写深度学习代码。它有两个来源。首先，也许并不奇怪，鉴于其名称，它从Torch中获得了许多功能和概念，Torch是一个基于Lua的神经网络库，可以追溯到2002年。它的另一个主要来源是Chainer，于2015年在日本创建。Chainer是最早提供了一种急切的差异化方法而不是定义静态图的神经网络库之一，这种方法允许在创建、训练和操作网络时具有更大的灵活性。Torch的遗产加上Chainer的思想使得PyTorch在过去几年中变得流行。
- en: The library also comes with modules that help with manipulating text, images,
    and audio (`torchtext`, `torchvision`, and `torchaudio`), along with built-in
    variants of popular architectures such as ResNet (with weights that can be downloaded
    to provide assistance with techniques like *transfer learning*, which you’ll see
    in [Chapter 4](ch04.html#transfer-learning-and-other-tricks)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 该库还配备了一些模块，可帮助处理文本、图像和音频（`torchtext`、`torchvision`和`torchaudio`），以及流行架构的内置变体，如ResNet（可下载权重以提供对*迁移学习*等技术的帮助，你将在[第4章](ch04.html#transfer-learning-and-other-tricks)中看到）。
- en: Aside from Facebook, PyTorch has seen quick acceptance by industry, with companies
    such as Twitter, Salesforce, Uber, and NVIDIA using it in various ways for their
    deep learning work. Ah, but I sense a question coming….
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Facebook之外，PyTorch在工业界得到了快速的接受，包括Twitter、Salesforce、Uber和NVIDIA等公司在其深度学习工作中以各种方式使用它。啊，但我感觉到有一个问题要来了……
- en: What About TensorFlow?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么TensorFlow呢？
- en: Yes, let’s address the rather large, Google-branded elephant in the corner.
    What does PyTorch offer that TensorFlow doesn’t? Why should you learn PyTorch
    instead?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，让我们来谈谈那只角落里的相当大的、带有Google标志的大象。PyTorch提供了什么，TensorFlow没有的？为什么你应该学习PyTorch呢？
- en: The answer is that traditional TensorFlow works in a different way than PyTorch
    that has major implications for code and debugging. In TensorFlow, you use the
    library to build up a graph representation of the neural network architecture
    and then you execute operations on that graph, which happens within the TensorFlow
    library. This method of declarative programming is somewhat at odds with Python’s
    more imperative paradigm, meaning that Python TensorFlow programs can look and
    feel somewhat odd and difficult to understand. The other issue is that the static
    graph declaration can make dynamically altering the architecture during training
    and inference time a lot more complicated and stuffed with boilerplate than with
    PyTorch’s approach.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, PyTorch has become popular in research-oriented communities.
    The number of papers submitted to the International Conference on Learning Representations
    that mention *PyTorch* has jumped 200% in the past year, and the number of papers
    mentioning *TensorFlow* has increased almost equally. PyTorch is definitely here
    to stay.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: However, things are changing in more recent versions of TensorFlow. A new feature
    called *eager execution* has been recently added to the library that allows it
    to work similarly to PyTorch and will be the paradigm promoted in TensorFlow 2.0\.
    But as it’s new resources outside of Google that help you learn this new method
    of working with TensorFlow are thin on the ground, plus you’d need years of work
    out there to understand the other paradigm in order to get the most out of the
    library.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: But none of this should make you think poorly of TensorFlow; it remains an industry-proven
    library with support from one of the biggest companies on the planet. PyTorch
    (backed, of course, by a different biggest company on the planet) is, I would
    say, a more streamlined and focused approach to deep learning and differential
    programming. Because it doesn’t have to continue supporting older, crustier APIs,
    it is easier to teach and become productive in PyTorch than in TensorFlow.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Where does Keras fit in with this? So many good questions! Keras is a high-level
    deep learning library that originally supported Theano and TensorFlow, and now
    also supports certain other frames such as Apache MXNet. It provides certain features
    such as training, validation, and test loops that the lower-level frameworks leave
    as an exercise for the developer, as well as simple methods of building up neural
    network architectures. It has contributed hugely to the take-up of TensorFlow,
    and is now part of TensorFlow itself (as `tf.keras`) as well as continuing to
    be a separate project. PyTorch, in comparison, is something of a middle ground
    between the low level of raw TensorFlow and Keras; we will have to write our own
    training and inference routines, but creating neural networks is almost as straightforward
    (and I would say that PyTorch’s approach to making and reusing architectures is
    much more logical to a Python developer than some of Keras’s magic).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: As you’ll see in this book, although PyTorch is common in more research-oriented
    positions, with the advent of PyTorch 1.0, it’s perfectly suited to production
    use cases.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following typographical conventions are used in this book:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '*Italic*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '**`Constant width bold`**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a general note.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Using Code Examples
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supplemental material (including code examples and exercises) is available for
    download at [*https://oreil.ly/pytorch-github*](https://oreil.ly/pytorch-github).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 可下载补充材料（包括代码示例和练习）请访问[*https://oreil.ly/pytorch-github*](https://oreil.ly/pytorch-github)。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing a CD-ROM
    of examples from O’Reilly books does require permission. Answering a question
    by citing this book and quoting example code does not require permission. Incorporating
    a significant amount of example code from this book into your product’s documentation
    does require permission.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书旨在帮助您完成工作。一般来说，如果本书提供示例代码，您可以在程序和文档中使用它。除非您复制了代码的大部分内容，否则无需联系我们以获得许可。例如，编写一个程序使用本书中的几个代码块不需要许可。出售或分发包含O'Reilly图书示例的CD-ROM需要许可。引用本书并引用示例代码回答问题不需要许可。将本书中大量示例代码整合到产品文档中需要许可。
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Programming PyTorch for
    Deep Learning* by Ian Pointer (O’Reilly). Copyright 2019 Ian Pointer, 978-1-492-04535-9.”'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢但不要求署名。署名通常包括标题、作者、出版商和ISBN。例如：“Ian Pointer（O'Reilly）的《深度学习PyTorch编程》。2019年Ian
    Pointer著，978-1-492-04535-9。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您使用的代码示例超出了合理使用范围或上述许可，请随时通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)与我们联系。
- en: O’Reilly Online Learning
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O'Reilly在线学习
- en: Note
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For almost 40 years, [*O’Reilly Media*](http://oreilly.com) has provided technology
    and business training, knowledge, and insight to help companies succeed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 近40年来，[*O'Reilly Media*](http://oreilly.com)提供技术和商业培训、知识和见解，帮助公司取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, conferences, and our online learning platform. O’Reilly’s
    online learning platform gives you on-demand access to live training courses,
    in-depth learning paths, interactive coding environments, and a vast collection
    of text and video from O’Reilly and 200+ other publishers. For more information,
    please visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过图书、文章、会议和我们的在线学习平台分享他们的知识和专长。O'Reilly的在线学习平台为您提供按需访问实时培训课程、深入学习路径、交互式编码环境以及来自O'Reilly和其他200多家出版商的大量文本和视频。有关更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。
- en: How to Contact Us
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题发送给出版商：
- en: O’Reilly Media, Inc.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O'Reilly Media, Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastopol, CA 95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/prgrming-pytorch-for-dl*](https://oreil.ly/prgrming-pytorch-for-dl).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为这本书创建了一个网页，列出勘误、示例和任何其他信息。您可以访问[*https://oreil.ly/prgrming-pytorch-for-dl*](https://oreil.ly/prgrming-pytorch-for-dl)。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)以评论或提出有关本书的技术问题。
- en: For more information about our books, courses, conferences, and news, see our
    website at [*http://www.oreilly.com*](http://www.oreilly.com).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有关我们的图书、课程、会议和新闻的更多信息，请访问我们的网站[*http://www.oreilly.com*](http://www.oreilly.com)。
- en: 'Find us on Facebook: [*http://facebook.com/oreilly*](http://facebook.com/oreilly)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在Facebook上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上观看我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: A big thank you to my editor, Melissa Potter, my family, and Tammy Edlund for
    all their help in making this book possible. Thank you, also, to the technical
    reviewers who provided valuable feedback throughout the writing process, including
    Phil Rhodes, David Mertz, Charles Givre, Dominic Monn, Ankur Patel, and Sarah
    Nagy.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 衷心感谢我的编辑Melissa Potter，我的家人和Tammy Edlund在使这本书成为可能的过程中提供的所有帮助。还要感谢在写作过程中提供宝贵反馈的技术审阅人员，包括Phil
    Rhodes、David Mertz、Charles Givre、Dominic Monn、Ankur Patel和Sarah Nagy。
- en: ^([1](preface01.html#idm45762375164216-marker)) See [“Approximation by Superpositions
    of Sigmoidal Functions”](https://oreil.ly/BQ8-9), by George Cybenko (1989).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见George Cybenko（1989）的“由Sigmoidal函数的叠加逼近”。
- en: ^([2](preface01.html#idm45762372338792-marker)) Note that PyTorch borrows ideas
    from Chainer, but not actual code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，PyTorch从Chainer借鉴了一些想法，但没有实际代码。
