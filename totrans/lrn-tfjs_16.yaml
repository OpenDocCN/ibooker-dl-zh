- en: Appendix B. Chapter Challenge Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html#the_chapter_2): Truck Alert!'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MobileNet model can detect all kinds of different trucks. You could solve
    this problem by going through the list of identifiable trucks, or you can simply
    search for the word *truck* in the given list of class names. For simplicity,
    the provided answer did the latter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entire solution with HTML and JavaScript is here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_chapter_challenge_answers_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Load the MobileNet model from a CDN.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_chapter_challenge_answers_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Access the image on the DOM via ID. The DOM has probably been loaded for a while
    now due to waiting for the model to load.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_chapter_challenge_answers_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Set `foundATruck` to true if the word *truck* was detected in any prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_chapter_challenge_answers_CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The moment of truth! Alert only if `foundATruck` is true.
  prefs: []
  type: TYPE_NORMAL
- en: This Chapter Challenge answer with a truck image is available in the [GitHub](https://github.com/GantMan/learn-tfjs)
    source code for this book.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.html#the_chapter_3): What Makes You So Special?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This simple exercise is about finding the TensorFlow.js `tf.unique` method.
    Once you find this friendly method, it’s easy to build a solution, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Don’t forget to wrap this code in a `tf.tidy` for automatic tensor cleanup!
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ch04.html#the_chapter_4): Sorting Chaos'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One elegant solution to sorting the generated randomness would be to use `topk`
    on a `randomUniform`-created tensor. Since a `randomUniform` creates values between
    `0` and `1` and `topk` sorts values along the final axis, you can complete this
    exercise with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_chapter_challenge_answers_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Create a 2D 400 x 400 tensor of random values between `0` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_chapter_challenge_answers_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Use `topk` to sort the last dimension (width), and return all 400 values.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_chapter_challenge_answers_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optional: reshape the tensor to a 3D value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous solution is quite verbose and could be condensed into a single
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[Chapter 5](ch05.html#the_chapter_5): Cute Faces'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the first model has given the coordinates of the face, a tensor crop
    would supply just those pixels. This works almost exactly like `strokeRect`, because
    you supply a starting position and desired size. However, all of our previous
    measurements will not work for this crop, because they were calculated on a resized
    version of the image. You’ll need to do similar calculations on the original tensor
    data so you can extract the correct information.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you don’t want to recalculate the positions, you could resize the tensor
    to match `petImage` width and height. This would allow you to reuse the same `startX`,
    `startY`, `width`, and `height` variables for your crop.
  prefs: []
  type: TYPE_NORMAL
- en: 'The follow code may reference some of the variables created in the original
    face localization code, most specifically `myTensor`, which was the original `fromPixels`
    tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_chapter_challenge_answers_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the order for tensors is height and then width. They are formatted
    like a mathematical matrix rather than image-specific standards of width by height.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_chapter_challenge_answers_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Subtracting ratios can leave floating-point values; you’ll need to round these
    to specific pixel indices. In this case, the answer is using `parseInt` to remove
    any decimals.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_chapter_challenge_answers_CO3-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, batching and then unbatching and then rebatching is inefficient.
    Whenever possible, you should leave all your operations batched until absolutely
    necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Now you’ve successfully prepared the dog’s face tensor for passing into the
    next model, which will do something like return a percentage likelihood that the
    dog is panting.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting model output was never specified, but you can be assured that
    it will be either a two-value rank-one tensor, with index 0 meaning not panting
    and index 1 meaning panting, or a single-value rank-one tensor with a likelihood
    of panting from zero to one. Both of these are easy enough for you to handle!
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.html#the_chapter_6): Top Detective'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem with using `topk` is that it works only on the final dimension of
    a particular tensor. So one way you can find a max value across two dimensions
    is to call `topk` twice. The second time you can limit the results to the top
    three.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can then loop over the results and access the top values from the `topvals`
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.html#the_chapter_7): R.I.P. You will be MNIST'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By using the wizard you can select all the desired settings; you should have
    created some interesting results. The results should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 100 bin files were generated in a single grouping.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final size was around 1.5 MB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the size was 1.5 MB, this could have fit in a single 4 MB shard if the
    defaults were used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 8](ch08.html#the_chapter_8): The Model Architect'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You’ve been tasked to create a Layers model that fits the specifications given.
    The model should have an input shape of five and an output shape of four with
    several layers between with specified activations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to build the model should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The number of trainable parameters is calculated as the number of lines into
    a layer + number of units in that layer. You can solve this with the calculation
    `layerUnits[i] * layerUnits[i - 1] + layerUnits[i]` for each layer. The output
    of `model.summary()` will verify your math. Compare your summary to [Example B-1](#challenge_summary).
  prefs: []
  type: TYPE_NORMAL
- en: Example B-1\. The model summary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[Chapter 9](ch09.html#the_chapter_9): Ship Happens'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of course, there are plenty of ways to get this information. This is just one
    way.
  prefs: []
  type: TYPE_NORMAL
- en: To extract the honorific of each name, you could use `.apply` and split via
    spaces. This would get you most of your answers pretty quickly. However, some
    names have things like “von,” which would cause extra spaces and slightly ruin
    your code. To do this, a good trick is to use a regular expression. I used `/,\s(.*?)\./`,
    which looks for a comma followed by a space and then matches everything up to
    the first dot.
  prefs: []
  type: TYPE_NORMAL
- en: You can apply this to create a new row, group by that row, and then table the
    survivors’ average using `.mean()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `mega_df['Name']` is replaced with something useful and then grouped for
    verification. This could then be easily encoded or binned/bucketized for your
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure B-1](#ship_happens) shows the results of the grouping code displayed
    in a Dnotebook.'
  prefs: []
  type: TYPE_NORMAL
- en: '![screenshot of Dnotebook solution](assets/ltjs_ab01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure B-1\. Honorifics and survival averages
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Chapter 10](ch10.html#the_chapter_10): Saving the Magic'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To save the highest validation accuracy, rather than the last validation accuracy,
    you can add a conditional save to the epoch’s end callback. This can save you
    the headache of accidentally landing on an overfitting epoch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'There is *also* the [`earlyStopping`](https://oreil.ly/BZw2o) prepackaged callback
    that monitors and protects against overfitting. Setting your callbacks to `callbacks:
    tf.callbacks.earlyStopping({monitor: ''val_acc''})` would stop training the moment
    that validation accuracy regresses.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 11](ch11.html#the_chapter_11): Warp-Speed Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You now know plenty of ways to solve this problem, but we’ll go fast and simple.
    There are four steps to solving this:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the new image data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Shave the base model into a feature model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create new layers that read features
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the new layers
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load the new image data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Shave the base model into a feature model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create new layers that read features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the new layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The result trains to excellent accuracy in 10 epochs, as shown in [Figure B-2](#trek_transfer_results).
  prefs: []
  type: TYPE_NORMAL
- en: '![Perfect validation accuracy in a few epochs](assets/ltjs_ab02.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure B-2\. Trained from only 150 images
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The full answer of this challenge is available with [the associated source code
    for this chapter](https://oreil.ly/lKaUm) so you can view the code and even interact
    with the result.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 12](ch12.html#the_chapter_12): Easy as 01, 10, 11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can convert an image to grayscale easily. Once you’ve done that, you can
    use `tf.where` on an image to replace each pixel with a white or a black pixel.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code converts an image with an ID of `input` into a binarized
    image that is displayed in a canvas named `output` on the same page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: A fully functioning example of this Chapter Challenge answer is [available in
    the associated source code for this chapter](https://oreil.ly/gMVzA).
  prefs: []
  type: TYPE_NORMAL
- en: There are more advanced and robust ways to binarize an image. Check into binarization
    algorithms if you’re looking to handle more images.
  prefs: []
  type: TYPE_NORMAL
