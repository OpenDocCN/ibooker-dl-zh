["```py\npip install opencv-python==4.8.1.78\n```", "```py\npip install requests==2.31.0\n```", "```py\n{'role':'user', 'content':[\n    {'type':'text', 'text':question},  #1\n    {'type':'image_url', 'image_url':{\n        'url':image_url}}          #2\n    ]\n}\n```", "```py\nimport argparse\nimport openai\nimport time\n\nclient = openai.OpenAI()\n\ndef analyze_image(image_url, question):       #1\n    \"\"\" Use language model to answer questions about image.\n\n    Args:\n        image_url: URL leading to image.\n        question: question about image.\n\n    Returns:\n        Answer generated by the language model.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model='gpt-4o',\n                messages=[                  #2\n                    {'role':'user', 'content':[\n                        {'type':'text', 'text':question}, \n                        {'type':'image_url', 'image_url':{\n                            'url':image_url\n                            }\n                        }]\n                    }]\n                )\n            return response.choices[0].message.content\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()                   #3\n    parser.add_argument('imageurl', type=str, help='URL to image')\n    parser.add_argument('question', type=str, help='Question about image')\n    args = parser.parse_args()\n\n    answer = analyze_image(args.imageurl, args.question)\n    print(answer)\n```", "```py\npython [URL] 'Is this a banana (\"Yes\",\"No\")?'\n```", "```py\n{'type':'image_url', 'image_url':{'url':image_url, 'detail':'low'}}\n```", "```py\nwith open(image_path, 'rb') as image_file:\n    encoded = base64.b64encode(image_file.read())\n```", "```py\nimage = encoded.decode('utf-8')\n```", "```py\n{'type':'image_url', 'image_url':{'url':image_url}}\n```", "```py\nimage_url = {'url':f'data:image/png;base64,{image}'}\n```", "```py\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer ...'\n}\n```", "```py\npayload = {\n    'model': 'gpt-4o',  #1\n    'messages': [\n        {'role': 'user', 'content': ...}  #2\n        ],\n    'max_tokens':1  #3\n    }\n```", "```py\nresponse = requests.post(\n        'https://api.openai.com/v1/chat/completions', \n        headers=headers, json=payload)\n```", "```py\nresponse.json()['choices'][0]['message']['content']\n```", "```py\nimport argparse\nimport base64\nimport os\nimport requests\nimport shutil\n\ndef load_images(in_dir):            #1\n    \"\"\" Loads images from a directory.\n\n    Args:\n        in_dir: path of input directory.\n\n    Returns:\n        directory mapping file names to PNG images.\n    \"\"\"\n    name_to_image = {}\n    file_names = os.listdir(in_dir)\n    for file_name in file_names:\n        if file_name.endswith('.png'):\n            image_path = os.path.join(in_dir, file_name)\n            with open(image_path, 'rb') as image_file:\n                encoded = base64.b64encode(image_file.read())\n                image = encoded.decode('utf-8')\n                name_to_image[file_name] = image\n\n    return name_to_image\n\ndef create_prompt(             #2\n    person_image, image_to_label): \n    \"\"\" Create prompt to compare images.\n\n    Args:\n        person_image: image showing a person.\n        image_to_label: image to assign to a label.\n\n    Returns:\n        prompt to verify if the same person appears in both images.\n    \"\"\"\n    task = {'type':'text', \n            'text':'Do the images show the same person (\"Yes\"/\"No\")?'}\n    prompt = [task]\n    for image in [person_image, image_to_label]:\n        image_url = {'url':f'data:image/png;base64,{image}'}\n        image_msg = {'type':'image_url', 'image_url':image_url}\n        prompt += [image_msg]\n\n    return prompt\n\ndef call_llm(ai_key, prompt):              #3\n    \"\"\" Call language model to process prompt with local images.\n\n    Args:\n        ai_key: key to access OpenAI.\n        prompt: a prompt merging text and local images.\n\n    Returns:\n        answer by the language model.\n    \"\"\"\n    headers = {\n        'Content-Type': 'application/json',\n        'Authorization': f'Bearer {ai_key}'\n    }\n    payload = {\n        'model': 'gpt-4o',\n        'messages': [\n            {'role': 'user', 'content': prompt}\n            ],\n        'max_tokens':1\n        }\n    response = requests.post(\n        'https://api.openai.com/v1/chat/completions', \n        headers=headers, json=payload)\n    return response.json()['choices'][0]['message']['content']\n\nif __name__ == '__main__':  #4\n\n    parser = argparse.ArgumentParser()             #5\n    parser.add_argument('peopledir', type=str, help='Images of people')\n    parser.add_argument('picsdir', type=str, help='Images to tag')\n    parser.add_argument('outdir', type=str, help='Output directory')\n    args = parser.parse_args()\n\n    people_images = load_images(args.peopledir)\n    unlabeled_images = load_images(args.picsdir)\n\n    for person_name, person_image in people_images.items():  #6\n        for un_name, un_image in unlabeled_images.items():   #7\n            prompt = create_prompt(person_image, un_image)\n            ai_key = os.getenv('OPENAI_API_KEY')\n            response = call_llm(ai_key, prompt)\n            description = f'{un_name} versus {person_name}?'\n            print(f'{description} -> {response}')\n\n            if response == 'Yes':              #8\n                labeled_name = f'{person_name[:-4]}{un_name}'\n                source_path = os.path.join(args.picsdir, un_name)\n                target_path = os.path.join(args.outdir, labeled_name)\n                shutil.copy(source_path, target_path)\n```", "```py\npython listing2.py /tagging/people  /tagging/pics /tagging/processed\n```", "```py\nvideo = cv2.VideoCapture(video_path)\n```", "```py\nsuccess, frame = video.read()\n```", "```py\n_, buffer = cv2.imencode('.jpg', frame)\n```", "```py\nencoded = base64.b64encode(buffer)\nframe = encoded.decode('utf-8')\n```", "```py\nvideo.release()\n```", "```py\nimport argparse\nimport cv2\nimport base64\nimport openai\nimport time\n\nclient = openai.OpenAI()\n\ndef extract_frames(video_path):    #1\n    \"\"\" Extracts frames from a video.\n\n    Args:\n        video_path: path to video file.\n\n    Returns:\n        list of first ten video frames.\n    \"\"\"\n    video = cv2.VideoCapture(video_path)\n    frames = []\n    while video.isOpened() and len(frames) <= 10:\n        success, frame = video.read()\n        if not success:\n            break\n\n        _, buffer = cv2.imencode('.jpg', frame)\n        encoded = base64.b64encode(buffer)\n        frame = encoded.decode('utf-8')\n        frames += [frame]\n\n    video.release()\n    return frames\n\ndef create_prompt(frames):                     #2\n    \"\"\" Create prompt to generate title for video.\n\n    Args:\n        frames: frames of video.\n\n    Returns:\n        prompt containing multimodal data (as list).\n    \"\"\"\n    prompt = ['Generate a concise title for the video.']\n    for frame in frames[:10]:\n        element = {'image':frame, 'resize':768}\n        prompt += [element]\n    return prompt\n\ndef call_llm(prompt):                             #3\n    \"\"\" Query large language model and return answer.\n\n    Args:\n        prompt: input prompt for language model.\n\n    Returns:\n        Answer by the language model.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model='gpt-4o',\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ]\n                )\n            return response.choices[0].message.content\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('videopath', type=str, help='Path of video file')\n    args = parser.parse_args()\n\n    frames = extract_frames(args.videopath)  #4\n    prompt = create_prompt(frames)\n    title = call_llm(prompt)\n    print(title)\n```", "```py\npython listing3.py cars.mp4\n```"]