- en: 8 Genetic algorithm variants
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Gray-coded genetic algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding real-valued GA and its genetic operators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding permutation-based GA and its genetic operators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding multi-objective optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adapting genetic algorithms to strike a balance between exploration and exploitation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solving continuous and discrete problems using GA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This chapter continues with the topic of chapter 7: we will look at various
    forms of genetic algorithms (GAs) and delve deeper into their real-world applications.
    We’ll also look at a number of case studies and exercises, such as the traveling
    salesman problem (TSP), proportional integral derivative (PID) controller design,
    political districting, the cargo bike loading problem, manufacturing planning,
    facility allocation, and the opencast mining problem in this chapter and its supplementary
    exercises included in the online appendix C.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Gray-coded GA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Hamming cliff effect refers to the fact that small changes in a chromosome
    can result in large changes in a solution’s fitness, which can lead to a sharp
    drop-off in the fitness landscape and cause the algorithm to converge prematurely.
    In binary genetic algorithms, the crossover and mutation operations can significantly
    affect the solution due to this Hamming cliff effect, especially when the bits
    that are to be changed are among the most significant bits in the binary string.
    To mitigate the Hamming cliff effect, Gray-coded GA uses a Gray-code encoding
    scheme for the chromosomes.
  prefs: []
  type: TYPE_NORMAL
- en: The reflected binary code, commonly referred to as *Gray code* after its inventor
    Frank Gray, is a unique binary numbering system characterized by adjacent numerical
    values differing by only one bit, as shown in table 8.1\. In this numeral system,
    each value has a unique representation that is close to the representations of
    its neighboring values, which helps minimize the effect of crossover and mutation
    operations on the solution. This coding ensures a smooth transition between values
    and minimizes the risk of errors during conversions or when used in various applications,
    such as rotary encoders and digital-to-analog converters. Table 8.1 shows the
    decimal numbers 1 to 15 and their corresponding binary and Gray equivalents.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.1 Decimal, binary, and Gray coding
  prefs: []
  type: TYPE_NORMAL
- en: '| Decimal number | Binary code | Gray code |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0000 | 0000 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0001 | 0001 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0010 | 0011 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0011 | 0010 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0100 | 0110 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0101 | 0111 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0110 | 0101 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 0111 | 0100 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 1000 | 1100 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 1001 | 1101 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1010 | 1111 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 1011 | 1110 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 1100 | 1010 |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | 1101 | 1011 |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 1110 | 1001 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 1111 | 1000 |'
  prefs: []
  type: TYPE_TB
- en: Exclusive OR (XOR) gates are used to convert 4-bit binary numbers to Gray codes,
    as illustrated in figure 8.1 for the ticket pricing example discussed in the previous
    chapter. These XOR gates result in 1 only if the inputs are different and 0 if
    the inputs are the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 Gray coding and binary-to-Gray conversion
  prefs: []
  type: TYPE_NORMAL
- en: In Gray code, two successive values differ by only one bit. This property reduces
    the Hamming distance between adjacent numbers, leading to a smoother search space
    or smoother genotype-to-phenotype mapping.
  prefs: []
  type: TYPE_NORMAL
- en: Hamming cliff problem
  prefs: []
  type: TYPE_NORMAL
- en: One of the drawbacks of encoding variables as binary strings is the presence
    of Hamming cliffs. In binary-coded GAs, a small change in the encoded value (e.g.,
    flipping a single bit) can lead to a significant change in the decoded value,
    especially if the flipped bit is located toward the most significant bit position.
    This abrupt change between two adjacent numbers in the search space is referred
    to as a Hamming cliff. This problem negatively affects binary-coded GAs by disrupting
    the search space’s smoothness, causing poor convergence and leading to inefficient
    exploration and exploitation. To address the Hamming cliff problem, alternative
    representations like Gray code or real-valued encoding can be used, as they offer
    better locality and smoother search spaces, minimizing the disruptive effects
    of small changes on decoded values.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, assume that we have a decision variable in the range [0, 15],
    as shown in the following figure. In binary-coded GA, we would use 4-bit binary
    representation to encode the candidate solutions. Let’s assume we have two adjacent
    solutions in the search space: 7 and 8, or 0111 and 1000 in binary representation.
    The Hamming distance is the number of bit-wise differences, so the Hamming distance
    between 1000 and 0111 is 4\. These two solutions (7 and 8) are neighbors in the
    search space, but when you look at their binary representations, you can see that
    they differ in all 4 bits. Flipping the most significant bit causes a significant
    change in the decoded value. In the case of Gray code, the Hamming distance between
    the Gray code representation 0100 (7 in decimal) and 1100 (8 in decimal) is only
    1\. This means that these Gray code representations for the two adjacent solutions
    differ by only 1 bit, providing a smoother search space and potentially improving
    the performance of the GA.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F01_UN01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Hamming distances for decimal number change from 0 to 15 for binary and Gray
    coding
  prefs: []
  type: TYPE_NORMAL
- en: Gray code representations provide better locality, meaning that small changes
    in the encoded value result in small changes in the decoded value. This property
    can improve the convergence of the GA by reducing the likelihood of disruptive
    changes during crossover and mutation operations. However, it is worth noting
    that the performance improvements offered by Gray coding are problem-dependent,
    and this representation method is not commonly used compared to binary-coded GA.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Real-valued GA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Real-valued GA is a variation on the standard GA that uses real numbers for
    encoding chromosomes instead of binary or Gray code representations. Many optimization
    problems involve continuous variables or real-valued parameters, such as curve
    fitting, function optimization with real-valued inputs, proportional integral
    derivative (PID) controller parameter tuning, or optimizing the weights of a neural
    network. To handle these continuous problems, it’s recommended that we use real-value
    GA directly for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Precision*—Real-valued GAs can achieve a higher level of precision in the
    search space than binary GAs. Binary encoding requires the discretization of the
    search space into a finite number of possible solutions, which can limit the accuracy
    of the search. Real-valued encoding, on the other hand, allows for a continuous
    search space, which can provide a more precise search.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Efficiency*—Real-valued GAs can require fewer bits to encode a solution compared
    to binary GAs. For example, assume that the decision variable to be represented
    has a lower bound (*LB*) of 0 and an upper bound (*UB*) of 10, and we need to
    represent the solution with a precision (*P*) of 0.0001\. As explained in the
    previous chapter, the number of bits required to represent a range between *LB*
    and *UB* with a desired precision *P* is *number_of_bits* = ceil(log2(*UB* – *LB*)/*P*))
    = ceil(log2(ceil(10/0.0001))) = ceil(log2(100000)) = 17 bits. A real-valued encoding
    can use floating-point numbers with a smaller number of bits to represent a wider
    range of values than a binary encoding. This can result in a more efficient use
    of the available memory and computation resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Smoothness*—Real-valued GAs can maintain the continuity and smoothness of
    the search space, which can be important in some applications. In contrast, binary
    GAs can suffer from the Hamming cliff effect, as discussed in the previous section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adaptability*—Real-valued GAs can adapt more easily to changes in the search
    space or the fitness landscape. For example, if the fitness landscape changes
    abruptly, real-valued GAs can adjust the step size or mutation rate to explore
    the new landscape more effectively. Binary GAs, on the other hand, can require
    a more extensive redesign of the encoding or operator parameters to adapt to changes
    in the search space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following subsections, we’ll look at the crossover and mutation methods
    used in real-valued GA.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.1 Crossover methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some popular crossover methods for real-valued GAs are single arithmetic crossover,
    simple arithmetic crossover, and whole arithmetic crossover.
  prefs: []
  type: TYPE_NORMAL
- en: Single arithmetic crossover
  prefs: []
  type: TYPE_NORMAL
- en: 'The *single arithmetic crossover method* involves picking a gene (*k*) at random
    and generating a random weight *α*, which lies in the range [0, 1]. Genes with
    indices *i* before and after the crossover point (*i* < *k* or *i* > *k*) will
    inherit the genes from the corresponding parent chromosome. For genes at the crossover
    point (*i* = *k*), we create the offspring genes by taking a weighted average
    of the corresponding genes in the parent chromosomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Child*[1]*Gene[i]* = *α* × *Parent*[1]*Gene[i]* + (1 – *α*) × *Parent*[2]*Gene[i]*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Child*[2]*Gene[i]* = *α* × *Parent*[2]*Gene[i]* + (1 – *α*) × *Parent*[1]*Gene[i]*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 illustrates the single arithmetic crossover in real-valued GA.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F02_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 Single arithmetic crossover in real-valued GA
  prefs: []
  type: TYPE_NORMAL
- en: Simple arithmetic crossover
  prefs: []
  type: TYPE_NORMAL
- en: '*Simple arithmetic crossover* is similar to single arithmetic crossover. Before
    a randomly picked crossover point (*i* < *k*), the genes are inherited from the
    corresponding parent chromosome. After the crossover point (*i* >= *k*), we create
    the offspring genes by taking a weighted average of the corresponding genes in
    the parent chromosomes. Figure 8.3 illustrates the simple arithmetic crossover
    in real-valued GA.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F03_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 Simple arithmetic crossover in real-valued GA
  prefs: []
  type: TYPE_NORMAL
- en: Whole arithmetic crossover
  prefs: []
  type: TYPE_NORMAL
- en: In the *whole arithmetic crossover* method, we take a weighted average of the
    entire parent chromosomes to create the offspring. Figure 8.4 illustrates this
    method in real-valued GA.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F04_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 Whole arithmetic crossover in real-valued GA
  prefs: []
  type: TYPE_NORMAL
- en: Simulated binary crossover
  prefs: []
  type: TYPE_NORMAL
- en: '*Simulated binary crossover* (SBX) [1] is another crossover method in real-valued
    GA. In SBX, real values can be represented by a binary notation, and then the
    point crossovers can be performed. SBX is designed to generate offspring close
    to the parent chromosomes by creating a probability distribution function, thus
    maintaining a balance between exploration and exploitation in the search space.
    SBX is implemented in pymoo.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Mutation methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The simplest way to mutate a continuous variable is to introduce small, random
    perturbations to the genes of an individual to maintain diversity in the population
    and help the search process escape from local optima. There are several common
    mutation methods used in real-valued GAs:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Gaussian mutation*—Gaussian mutation adds a random value to the gene, where
    the random value is sampled from a Gaussian distribution with 0 mean and a specified
    standard deviation *σ*. The standard deviation controls the magnitude of the mutation
    (aka the *mutation step*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cauchy mutation*—Similar to Gaussian mutation, Cauchy mutation adds a random
    value to the gene, but the random value is sampled from a *Cauchy distribution*
    (aka a *Lorentz distribution* or *Cauchy–Lorentz distribution*) instead of a Gaussian
    distribution. The Cauchy distribution has heavier tails than the Gaussian distribution,
    leading to a higher probability of larger mutations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Boundary mutation*—In boundary mutation, the mutated gene is randomly drawn
    from the uniform distribution within the variable’s range, defined by the lower
    bound (*LB*) and upper bound (*UB*). This method is analogous to the bit-flipping
    mutation in a binary-coded GA, and it helps explore the boundaries of the search
    space. It may be useful when optimal solutions are located near the variable limits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Polynomial mutation*—Polynomial mutation is a method that generates offspring
    close to the parent by creating a probability distribution function [2]. A distribution
    index (*η*) controls the shape of the probability distribution function, with
    higher values resulting in offspring closer to their parents (exploitation) and
    lower values leading to offspring more spread out in the search space (exploration).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To illustrate these genetic operators, let’s consider a curve-fitting example.
    Assume we have the data points shown in table 8.2 and that we want to fit a third-order
    polynomial to these data points using real-valued GA.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.2 Curve-fitting problem data
  prefs: []
  type: TYPE_NORMAL
- en: '| x | 0 | 1.25 | 2.5 | 3.75 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| y | 1 | 5.22 | 23.5 | 79.28 | 196 |'
  prefs: []
  type: TYPE_TB
- en: 'The third-order polynomial takes the form *y* = *ax*³ + *bx*² + *cx* + *d*.
    A real-valued GA can be used to find the four coefficients of the polynomial:
    *a, b, c*, and *d*. This problem is treated as a minimization problem where the
    objective is to minimize the mean squared error (MSE) that measures how close
    a fitted polynomial is to given data points. MSE is calculated using the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F04_Khamis-EQ02.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.1 |'
  prefs: []
  type: TYPE_TB
- en: where *n* is the number of data points, *y* is the *y*-coordinate value of each
    data point, and *y*′ is the desired value that sits on the line we created.
  prefs: []
  type: TYPE_NORMAL
- en: 'In real-valued GA, a candidate solution is represented by a vector of parameters
    *a, b, c*, and *d* that can be represented by real values. Let’s start with the
    following initial random solution: *Parent*[1] = [1 2 3 4]. We calculate its fitness
    by substituting these values in the function (*y* = *x*³ + 2*x*² + 3*x* + 4),
    calculating *y*′ for each corresponding *x* and calculating the MSE as in table
    8.3.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.3 MSE calculation for parent 1
  prefs: []
  type: TYPE_NORMAL
- en: '| x | 0 | 1.25 | 2.5 | 3.75 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| y | 1 | 5.22 | 23.5 | 79.28 | 196 |'
  prefs: []
  type: TYPE_TB
- en: '| *y*′ | 4 | 12.83 | 39.63 | 96.11 | 194 |'
  prefs: []
  type: TYPE_TB
- en: '| *Square* *of error* | 9 | 57.88 | 260 | 283.23 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| MSE | 122.83 |'
  prefs: []
  type: TYPE_TB
- en: 'Let’s generate another random solution: *Parent*[2] = [2 2 2 2], which gives
    the formula 2*x*³ + 2*x*² + 2*x* + 2 and the MSE in table 8.4.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.4 MSE calculation for parent 2
  prefs: []
  type: TYPE_NORMAL
- en: '| x | 0 | 1.25 | 2.5 | 3.75 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| y | 1 | 5.22 | 23.5 | 79.28 | 196 |'
  prefs: []
  type: TYPE_TB
- en: '| *y*′ | 2 | 11.53 | 50.75 | 143.09 | 312 |'
  prefs: []
  type: TYPE_TB
- en: '| *Square of* *error* | 1 | 39.83 | 742.56 | 4,072.2 | 13,456 |'
  prefs: []
  type: TYPE_TB
- en: '| MSE | 3,662.32 |'
  prefs: []
  type: TYPE_TB
- en: 'Applying whole arithmetic crossover on the two parents *P*[1] = [1 2 3 4] and
    *P*[2] = [2 2 2 2] with weight *α* = 0.2 results in the following offspring:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F04_Khamis-EQ03.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/CH08_F04_Khamis-EQ04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s assume *Child*[1] is subject to Gaussian mutation. This mutation process
    results in another child as follows: *Child*[3] = *Child*[1] + *N*(0, *σ*), where
    *N*(0, *σ*) is a random number from a normal distribution with a mean of 0 and
    a standard deviation of *σ*. Assuming that *σ* = 1.2, a random value of 0.43 is
    generated by `numpy.random.normal(0, 1.2)`, *s*o *Child*[3] = [1.8 2 2.2 2.4]
    + 0.43 = [2.23 2.43 2.63 2.83].'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.1 shows how to perform this curve-fitting using real-valued GA implemented
    in pymoo. We’ll start by generating a dataset driven by a third-order polynomial,
    to be used later as a ground truth. Feel free to replace this synthetically generated
    data with any experimental data you may have.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.1 Curve fitting using real-valued GA
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ① Define coefficients for the third-order polynomial.
  prefs: []
  type: TYPE_NORMAL
- en: ② Generate five values as in the hand-iteration example.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Calculate y values using the third-order polynomial function.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Combine x and y values into an array of data samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 8.1, we can define a problem for curve fitting
    by subclassing pymoo’s `Problem` class, ensuring we pass the parameters to the
    superclass and provide an `_evaluate` function. The `CurveFittingProblem` class
    has an initializer method that sets the number of decision variables to 4, the
    number of objectives to 1, the number of constraints to 0, the lower bound of
    the decision variables to –10.0, and the upper bound of the decision variables
    to 10.0\. The `vtype` parameter specifies the data type of the decision variables,
    which is set to `float`. This initializer method creates an instance of the problem
    to be solved using the genetic algorithm. The `_evaluate` method takes as input
    a set of candidate solutions (`X`) and an output dictionary (`out`) and returns
    the fitness of each candidate solution in the `F` field of the `out` dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ① Import the GA implementation for single-objective optimization in nonconvex
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: ② Import the simulated binary crossover (SBX) operator.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Import the polynomial mutation operator.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Import the rounding repair operator to ensure that the generated solutions
    remain within specified bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Import the float random sampling operator to generate random initial solutions.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Import the generic optimization problem class.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Import the minimize function.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Define the optimization problem for curve fitting.
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Initialize the problem with four decision variables, ranging from –10.0 to
    10.0, and a single objective with no constraints.
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Calculate the mean squared error for each set of coefficients in the input
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can instantiate the `CurveFittingProblem` class to create an instance
    of the problem to be solved. We can then define the genetic algorithm to be used
    for the optimization. The `GA` class is used to define the algorithm, and the
    `pop_size` parameter sets the population size to 50\. The `sampling` parameter
    uses the `FloatRandomSampling` operator to generate the initial population of
    candidate solutions randomly. The `crossover` parameter uses the `SBX` operator
    with a crossover probability of 0.8\. The `mutation` parameter uses the `PolynomialMutation`
    operator with a mutation probability of 0.3 and a rounding repair operator to
    ensure that the decision variables remain within the specified bounds. The `eliminate_duplicates`
    parameter is set to `True` to remove duplicate candidate solutions from the population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can run the genetic algorithm to solve the curve fitting problem using
    the `minimize` function. This function takes three arguments: the instance of
    the problem to be solved (`problem`), the instance of the algorithm to be used
    (`algorithm`), and a tuple specifying the stopping criterion for the algorithm
    `(''n_gen'', 100)`, which specifies that the algorithm should run for 100 generations.
    The `seed` parameter is set to 1 to ensure the reproducibility of the results.
    The `verbose` parameter is set to `True` to display the progress of the algorithm
    during the optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ① Initialize an instance of the CurveFittingProblem class.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create a GA solver.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Perform the optimization for 100 generations.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can print the four coefficients obtained by GA as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the estimated values of the four coefficients are same as the
    coefficients of the ground truth polynomial (a, b, c, d = 2, –3, 4, 1). You can
    experiment with the code by changing the polynomial coefficients, using your own
    data, and using different crossover and mutation methods.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at permutation-based GA.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Permutation-based GA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Permutation-based GAs are designed to solve optimization problems where the
    solutions are permutations of a set of elements. Examples of such problems include
    the traveling salesman problem (TSP), vehicle routing problem, sports tournament
    scheduling, and job scheduling problem. In these problems, the solutions are represented
    as optimal orders or permutations of a set of elements or events.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are typically two main types of problems where the goal is to determine
    the optimal order of events:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Resource or time-constrained problems*—In these problems, the events rely
    on limited resources or time, making the order of events crucial for optimal solutions.
    One example of this type of problem is ride-sharing scheduling, where the goal
    is to efficiently allocate resources like vehicles and drivers to serve the maximum
    number of passengers in the shortest possible time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adjacency-based problems*—In these problems, the proximity or adjacency of
    elements plays a significant role in finding the best solution. An example of
    such a problem is the traveling salesman problem (TSP), where the aim is to visit
    a set of cities while minimizing the total travel distance, taking into account
    the distances between adjacent cities in the tour.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These problems are often formulated as permutation problems. In a permutation
    representation, if there are *n* variables, the solution is a list of *n* distinct
    integers, each occurring exactly once. This representation ensures that the order
    or adjacency of the elements in the solution is explicitly encoded, which is essential
    for finding the optimal sequence of events in these types of problems. For example,
    let’s consider the following TSP for 8 cities. A candidate solution for this TSP
    is represented by a permutation such as [1, 2, 3, 4, 5, 6, 7, 8]. In permutation-based
    GA, specialized crossover and mutation operators are employed to preserve the
    constraints of the permutation problem, such as maintaining a valid sequence of
    cities in the TSP, where each city appears only once.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsections describe commonly used crossover and mutation methods
    in permutation-based GAs. The choice of crossover and mutation methods in GAs
    depends on the problem being solved, the type of solutions being sought, and the
    objectives of the optimization problem. By carefully selecting and designing these
    operators, GAs can effectively explore and exploit the search space to find high-quality
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.1 Crossover methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several crossover methods are commonly used in permutation-based GAs, such as
    partially mapped crossover (PMX), edge crossover (EC), order 1 crossover (OX1),
    and cycle crossover (CX).
  prefs: []
  type: TYPE_NORMAL
- en: Partially mapped crossover
  prefs: []
  type: TYPE_NORMAL
- en: The *partially mapped crossover* (PMX) method creates offspring by combining
    the genetic information from two parent chromosomes while preserving the feasibility
    of the resulting offspring with the procedure shown in algorithm 8.1.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 8.1 Partially mapped crossover (PMX)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Figure 8.5 illustrates these steps for an 8-city TSP. In step 1, two random
    crossover points are chosen, and the cities between these two points are copied
    from parent P1 to child C1 and from the second parent P2 to the second child C2\.
    Then we follow steps 2 to 5 for the cities that were not included in step 1\.
    For the first city in C1, which is 3, we need to find the corresponding city in
    the P2 segment, which is 7\. City 7 is not already included in C1, so we need
    to place city 7 in the place where city 3 appears in P2, which is the last position
    on the right, as shown by the solid black arrow in figure 8.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F05_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 Partially mapped crossover (PMX)
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows code that performs a partially mapped crossover
    on two parents to generate two offspring.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.2 Partially mapped crossover (PMX)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ① Select two random crossover points.
  prefs: []
  type: TYPE_NORMAL
- en: ② Copy the segment between crossover points from a parent to a child.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Map the remaining elements from the other parent.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Return the generated offspring.
  prefs: []
  type: TYPE_NORMAL
- en: Running this code will produce output like that shown in figure 8.6, depending
    on the generated random sample.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F06_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 PMX results
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 8.2 is available in the book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Edge crossover
  prefs: []
  type: TYPE_NORMAL
- en: The *edge crossover* (EC) method preserves the connectivity and adjacency information
    between elements from the parent chromosomes. In order to achieve this, an *edge
    table* (or *adjacency list*) is constructed. For example, in the 8-cities TSP,
    the edge table for two parents P1 = [1, 2, 3, 4, 5, 6, 7, 8] and P2 = [1, 6, 7,
    8, 5, 2, 4, 3] is created by counting the adjacent elements in both parents, as
    in table 8.5\. The “+” signs in the table denote a common edge between the two
    parents.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.5 An edge table (or adjacency list)
  prefs: []
  type: TYPE_NORMAL
- en: '| City | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| Edges | 2,8,6,3 | 1,3,5,4 | 2,4+,1 | 3+,5,2 | 4,6,8,2 | 5,7+,1 | 6+,8+ |
    7+,1,5 |'
  prefs: []
  type: TYPE_TB
- en: Algorithm 8.2 shows the steps involved in edge crossover.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 8.2 Edge crossover (EC)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Figure 8.7 illustrates these steps for the 8-cities TSP. This figure illustrates
    how to construct the edge table or adjacency list of each city. The process of
    counting the edges is shown in this figure. For example, cities 3 and 5 are adjacent
    cities or edges to city 4 in the first parent. In the second parent, cities 2
    and 3 are edges for city 4\. This means that city 3 is a common edge.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a child starts by selecting city 1 randomly or as a home city. In the
    second row of the table, we list the adjacent cities of city 1, which are 2, 8,
    6 and 3\. Note that cities loop around, meaning city 1 is adjacent to city 8 in
    the first parent, and city 1 is adjacent to city 3 in the second parent. Discarding
    the already visited city 1, these cities have the following adjacent cities {3,5,4}
    for city 2, {7,5} for city 8, {5,7} for city 6, and {2,4} for city 3\. We discard
    city 2, as it has three adjacent cities, and we select city 3 arbitrarily from
    8, 6, and 3, as they have the same number of edges. We keep adding cities to the
    child following algorithm 8.2 until all the cities are added.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F07_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 Edge crossover
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 8.2 is available in the book’s GitHub repository.
    It shows the Python implementation of edge crossover with a TSP example.
  prefs: []
  type: TYPE_NORMAL
- en: Order 1 crossover
  prefs: []
  type: TYPE_NORMAL
- en: '*Order 1 crossover* (OX1) creates offspring by combining the genetic information
    from two parent chromosomes while preserving the relative order of the elements
    in the resulting solutions. Algorithm 8.3 shows the steps involved in order 1
    crossover.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 8.3 Order 1 crossover (OX1)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Figure 8.8 illustrates these steps for the 8-cities TSP. Starting from the second
    crossover point, cities 4 and 3 cannot be added, as they are already included
    in C1\. The next element in P2 is city 1, so it is added to C1 after the second
    crossover point, followed by city 7, as city 6 is already included. City 8 is
    added next, followed by city 2, as city 5 is already included in C1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F08_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 Order 1 crossover (OX1)—The numbers in circles show the sequence
    in which elements are added from parent 2 to child 1.
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 8.2 is available in the book’s GitHub repository,
    and it shows the Python implementation of OX1 with the TSP example.
  prefs: []
  type: TYPE_NORMAL
- en: Cycle crossover
  prefs: []
  type: TYPE_NORMAL
- en: '*Cycle crossover* (CX) operates by dividing the elements into cycles, where
    a *cycle* is a subset of elements that consistently appear together in pairs when
    the two parent chromosomes are aligned. Given two parents, a cycle is formed by
    selecting an element from the first parent, finding its corresponding position
    in the second parent, and then repeating this process with the element at that
    position until returning to the starting element. The CX operator effectively
    combines the genetic information from both parents while preserving the order
    and adjacency relationships among the elements in the resulting offspring and
    maintaining the feasibility and diversity of the offspring solutions. Algorithm
    8.4 shows the steps of this crossover method.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 8.4 Cycle crossover (CX)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Figure 8.9 illustrates these steps for the 10-cities TSP.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F09_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 Cycle crossover (CX)
  prefs: []
  type: TYPE_NORMAL
- en: A Python implementation of CX with a TSP example is included in the complete
    version of listing 8.2, available in the book’s GitHub repository. It’s important
    to note that the performance of crossover operators is often problem-dependent
    and may also be influenced by the specific parameter settings of the genetic algorithm,
    such as population size, mutation rate, and selection pressure. Therefore, it
    is recommended that you experiment with different crossover operators and fine-tune
    the genetic algorithm’s parameters to suit the problem being addressed.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.2 Mutation methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Insert, swap, inversion, and scramble are commonly used mutation methods in
    permutation-based GA. These methods are designed to introduce small perturbations
    to the solution while still preserving its feasibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Insert mutation*—Pick two gene values at random, and move the second to follow
    the first, shifting the rest along to accommodate them. This method primarily
    maintains the order and adjacency information of the genes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Swap mutation*—Pick two genes at random, and swap their positions. This method
    mainly retains adjacency information while causing some disruption to the original
    order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Inversion mutation*—Randomly select two genes, and invert the substring between
    them. This method largely maintains adjacency information but is disruptive to
    the order information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Scramble mutation*—Randomly select two gene values, and rearrange the genes
    between the chosen positions non-contiguously, applying a random order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 8.10 illustrates these methods on the first parent as a selected individual
    in the 8-cities TSP.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F10_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 Mutation methods in permutation-based GA
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 8.2, the following code snippet shows how you
    can implement inversion mutation in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Running this code will produce output like that in figure 8.11.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F11_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 Inversion mutation result
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 8.2, available in the book’s GitHub repository,
    includes implementations of different crossover and mutation methods commonly
    used in permutation-based genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 8.4 Multi-objective optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier in section 1.3.2, optimization problems with multiple objective
    functions are known as multi-objective optimization problems (MOPs). These problems
    can be handled using a preference-based multi-objective optimization procedure
    or by using a Pareto optimization approach. In the former approach, the multiple
    objectives are combined into a single or overall objective function by using a
    relative preference vector or a weighting scheme to scalarize the multiple objectives.
    However, finding this preference vector or weight is subjective and sometimes
    is not straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pareto optimization*, named after Italian economist and sociologist Vilfredo
    Pareto (1848–1923), relies on finding multiple trade-off optimal solutions and
    choosing one using higher-level information. This procedure tries to find the
    best trade-off by reducing the number of alternatives to an optimal set of nondominated
    solutions known as the Pareto front (or Pareto frontier), which can be used to
    make strategic decisions in multi-objective space. A solution is Pareto optimal
    if there is no other solution that improves one objective without worsening another
    objective, in the case of conflicting objective functions. Thus, the optimal solution
    for MOPs is not a single solution, as for mono-objective or single optimization
    problems (SOPs), but a set of solutions defined as *Pareto optimal solutions*.
    These Pareto optimal solutions are also known as acceptable, efficient, nondominated,
    or non-inferior solutions. *Nondominated solutions* in Pareto optimization represent
    the best compromises that are not outperformed by any other solution across multiple
    conflicting objectives.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In chapter 1, we looked at an electric vehicles example: acceleration time
    and driving range are conflicting objective functions, as we need to minimize
    the acceleration time and maximize the driving range of the vehicle. There is
    no universal best vehicle that achieves both, as shown in figure 8.12, which is
    based on real data retrieved from the *Inside EVs* website ([https://insideevs.com/](https://insideevs.com/)).
    For example, the Lucid Air Dream Edition has the highest driving range but not
    the lowest acceleration time. The dotted line shows the Pareto front—the vehicles
    that achieve the best trade-off between the acceleration time and the driving
    range.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F12_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 Acceleration time vs. driving range of 19 electric vehicles, as
    per September 2021
  prefs: []
  type: TYPE_NORMAL
- en: Multi-objective optimization algorithms
  prefs: []
  type: TYPE_NORMAL
- en: There are several algorithms for solving multi-objective optimization problems.
    The nondominated sorting genetic algorithm (NSGA-II) is one of the most commonly
    used. Other algorithms include, but are not limited to, the strength Pareto evolutionary
    algorithm 2 (SPEA2), the Pareto-archived evolution strategy (PAES), the niched-Pareto
    genetic algorithm (NPGA), multi-objective selection based on dominated hypervolume
    (SMS-EMOA), and multi-objective evolutionary algorithm based on decomposition
    (MOEA/D).
  prefs: []
  type: TYPE_NORMAL
- en: These algorithms have their own strengths and weaknesses, and your choice of
    algorithm will depend on the specific problem being solved and your preferences.
    NSGA-II has several advantages, such as diversity maintenance, non-dominated sorting,
    and fast convergence. For more details about multi-objective optimization, see
    Deb’s “Multi-objective optimization using evolutionary algorithms” [3] and Zitzler’s
    “Evolutionary algorithms for multiobjective optimization” [4].
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s solve a MOP using NSGA-II in an example. Assume that a manufacturer produces
    two products, P1 and P2, involving two different machines, M1 and M2\. Each machine
    can only produce one product at a time, and each product has a different production
    time and cost on each machine:'
  prefs: []
  type: TYPE_NORMAL
- en: P1 requires 2 hours on M1 and 3 hours on M2, with production costs of $100 and
    $150 respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P2 requires 4 hours on M1 and 1 hour on M2, with production costs of $200 and
    $50 respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In each shift, the two machines, M1 and M2, have the capacity of producing 100
    units of P1 and 500 units of P2\. The manufacturer wants to produce at least 80
    units of P1 and 300 units of P2 while minimizing production costs and minimizing
    the difference in production times between the two machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll let *x*[1] and *x*[2] be the number of units of P1 produced on M1 and
    M2, respectively, and *y*[1] and *y*[2] be the number of units of P2 produced
    on M1 and M2, respectively. The problem can be formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F12_Khamis-EQ05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Subject to:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F12_Khamis-EQ06.png)'
  prefs: []
  type: TYPE_IMG
- en: The first objective function (*f*[1]) represents the total production costs,
    and the second objective function (*f*[2]) represents the difference in production
    times between the two machines. Listing 8.3 shows the code for finding the optimal
    number of units to be produced in a shift using NSGA-II.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by inheriting from `ElementwiseProblem`, which allows us to define
    the optimization problem in an element-wise manner. `n_var` specifies the number
    of variables (4 in this case), `n_obj` defines the number of objectives (2), and
    `n_ieq_constr` indicates the number of inequality constraints (2). The `xl` and
    `xu` parameters define the lower and upper bounds for each variable respectively.
    The `_evaluate` method takes an input `x` (a solution candidate) and computes
    the objective values `f1` and `f2`, as well as the inequality constraints `g1`
    and `g2`. The third constraint is boundary constraint represented by the lower
    and upper bounds of the decision variables.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.3 Solving a manufacturing problem using NSGA-II
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ① Import an instance of the problem class.
  prefs: []
  type: TYPE_NORMAL
- en: ② Define the number of variables, objective functions, constraints, and lower
    and upper bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Total production costs as a first-objective function
  prefs: []
  type: TYPE_NORMAL
- en: ④ Difference in production times between the two machines as a second-objective
    function
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Define the constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now set up an instance of the NSGA-II algorithm as the solver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: ① Import the NSGA-II class.
  prefs: []
  type: TYPE_NORMAL
- en: ② Import simulated binary crossover (SBX) as a crossover operator.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Import polynomial mutation (PM) as a mutation operator.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Import the FloatRandomSampling method to generate random floating-point values
    for each variable within a specified range.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Set up an instance of NSGA-II.
  prefs: []
  type: TYPE_NORMAL
- en: The solver has a population size (`pop_size`) of 40 individuals, generates 10
    offspring using `FloatRandomSampling`, employs SBX crossover with a probability
    of 0.9, and fine-tunes the exponential distribution with an `eta` parameter of
    15\. PM mutation is used with an `eta` parameter of 20\. This `eta` parameter
    controls the spread of the mutation distribution. `eliminate_duplicates` is set
    to `True` so that duplicate candidate solutions will be removed from the population
    at each generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the termination criterion by specifying the number of generations
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run the solver to minimize both objective functions simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we print the best 10 solutions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will produce output representing the best 10 non-dominated solutions
    obtained by NSGA-II and will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As there is no universal best solution for these two objective functions, multi-criteria
    decision-making can be applied to select the best trade-off—the Pareto optimal.
    In pymoo, the decision-making procedure starts by defining boundary points called
    *ideal* and *nadir* points:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The ideal point*—This refers to the best possible values for each objective
    function that can be achieved in the entire feasible region of the problem. This
    point represents the scenario where all the objective functions are minimized
    simultaneously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The nadir point*—This is the point where each objective function is maximized
    while satisfying all the constraints of the problem. It is the opposite of the
    ideal point and represents the worst possible values for each objective function
    in the entire feasible region of the problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These points are used in multi-objective optimization problems to normalize
    the objective functions and convert them to a common scale, allowing for a fair
    comparison of different solutions. The two points are calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We then define weights, which are required by the decomposition functions,
    based on the level of importance of each objective function from the developer’s
    perspective:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: ① Weights for f1 and f2 respectively
  prefs: []
  type: TYPE_NORMAL
- en: 'A decomposition method is defined using the augmented scalarization function
    (ASF), discussed in Wierzbicki’s “The use of reference objectives in multiobjective
    optimization” [5]:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'To find the best solutions, we choose the minimum ASF values calculated from
    all the solutions and use the inverse of the weights as required by ASF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The output is shown in figure 8.13.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F13_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 Manufacturing problem solution—the point marked with the X represents
    the selected Pareto optimal or best trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The complete version of listing 8.3 is available in the book’s GitHub repository.
    It includes another method using pseudo-weights to choose a solution from a solution
    set in the context of multi-objective optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 8.5 Adaptive GA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adaptation methods help genetic algorithms strike a balance between exploration
    and exploitation, using different parameters such as initialization population
    size, crossover operators, and mutation operators. These parameters can be deterministically
    or dynamically adapted based on the search progress, allowing the algorithm to
    converge on high-quality solutions for complex optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: For example, population size can be adaptive. A larger population size promotes
    diversity and exploration, while a smaller size allows for faster convergence.
    The population size can be increased if the algorithm is struggling to find better
    solutions or decreased if the population has become too diverse.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mutation operator parameters can be used to adapt the genetic algorithm and
    balance its exploration and exploitation aspects. For example, in the case of
    Gaussian mutation, we can adaptively set the value of the standard deviation *σ*
    of the Gaussian distribution during the run. The standard deviation of the Gaussian
    distribution can be changed following a deterministic approach, an adaptive approach,
    or a self-adaptive approach. If you’re using a deterministic approach, the value
    of *σ* can be calculated in each generation using this formula: *σ*(*i*) = 1 –
    0.9 * *i*/ *N* where *i* is the generation number, ranging from 0 to *N* (the
    maximum generation number). In this case, the value of *σ* is 1 at the beginning
    of the optimization process and gradually reduces to 0.1 toward the end to move
    the search algorithm’s behavior from exploration to exploitation.'
  prefs: []
  type: TYPE_NORMAL
- en: The adaptive approach incorporates feedback from the search process to adjust
    the variance and improve the search performance. Rechenberg’s *1/5 success rule*
    is a well-known method that adjusts the step size of the search by monitoring
    the success rate of the search. This rule involves increasing the variance if
    a certain percentage of the previous mutations were successful in finding better
    solutions (i.e., if there was more than one successful mutation out of five tries),
    favoring exploration in order to avoid getting trapped in local optima. Otherwise,
    if there was a lower success rate, the variance should be decreased to favor exploitation.
    This allows the search to fine-tune its parameters based on its progress, leading
    to better performance and faster convergence to optimal solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.14 shows the steps of applying Rechenberg’s 1/5 success rule. This
    update rule is applied in every generation, and a constant 0.82 <= *c* <= 1 is
    used to update the standard deviation of the Gaussian distribution. As you can
    see, the higher the standard deviation, the higher the value of *x*, and the higher
    the deviation from the current solution (more exploration), and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F14_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 Rechenberg’s 1/5 success rule. Following this rule, the Gaussian
    distribution’s standard deviation is updated by a constant. The higher the standard
    deviation, the higher the value of *x* (i.e., larger step size), the higher the
    deviation from the current solution (more exploration), and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'The self-adaptive approach incorporates the mutation step size into each individual—a
    technique originally employed in evolution strategies (ES). In this method, the
    value of *σ* (the standard deviation or the mutation step size) evolves alongside
    the individual, resulting in distinct mutation step sizes for each individual
    in the population. The following equations are used in this self-adaptive approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F14_Khamis-EQ07.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.2 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F14_Khamis-EQ08.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.3 |'
  prefs: []
  type: TYPE_TB
- en: where *τ[o]* is the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have a solid understanding of the various components of GAs, we
    can apply this powerful optimization technique to real-world problems. In the
    following sections, we will use GAs to solve three distinct problems: the traveling
    salesman problem, tuning the parameters of a PID controller, and the political
    districting problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.6 Solving the traveling salesman problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s consider the following traveling salesman problem (TSP) for 20 major cities
    in the USA, starting from New York City, as illustrated in figure 8.15.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F15_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 The 20 major US cities TSP
  prefs: []
  type: TYPE_NORMAL
- en: In listing 8.4, we start by importing the libraries we’ll use and defining the
    TSP. First, we define the city names and their latitudes and longitudes. We then
    use those coordinates to create a haversine distance matrix and then convert the
    data dictionary into a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.4 Solving TSP using GA
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: ① Define city names, latitudes, and longitudes for 20 major US cities.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create a haversine distance matrix based on latitude-longitude coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the distance dictionary into a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create a networkx graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then create `TravelingSalesman` as a subclass of the `ElementwiseProblem`
    class available in pymoo. This class defines the number of cities and the intercity
    distances as problem parameters, and it evaluates the total path length as an
    objective function to be minimized:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function is a subclass of the `Repair` class, and it provides
    a method to repair solutions for the TSP, ensuring that each solution starts with
    the city indexed as 0 (New York City, in this example). The repair operator in
    pymoo is used to make sure the algorithm is only searching the feasible space.
    It is applied after the offspring have been reproduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: It’s time now to define a GA solver and apply it to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: ① Create a TSP instance for the given cities and intercity distances.
  prefs: []
  type: TYPE_NORMAL
- en: ② Define the GA solver.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Terminate (and disable the max generations) if the algorithm did not improve
    in the last 300 generations.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Find the shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can print the found route and its length as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is used to visualize the obtained route using NetworkX:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: ① Create an independent shallow copy of the problem graph and attributes.
  prefs: []
  type: TYPE_NORMAL
- en: ② Reverse latitude and longitude for correct visualization.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create a list of keys in the original dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create a new dictionary with the keys in the desired order.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create an edge list.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Draw the closest edges on each node only.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Draw and show the route.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.16 shows the obtained route for this traveling salesman problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F16_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.16 The 20 major US cities TSP solution
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with the full code in the book’s GitHub repository by changing
    the problem data and the genetic algorithm parameters, such as population size,
    sampling, crossover, and mutation methods.
  prefs: []
  type: TYPE_NORMAL
- en: 8.7 PID tuning problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Have you ever wondered how your room stays at a comfortable temperature? Have
    you ever thought about how the heating or cooling system knows when to turn on
    and off automatically to maintain the temperature set on the thermostat? This
    is where control systems come into the picture. Control systems are like behind-the-scenes
    wizards that ensure things work smoothly and efficiently. They are sets of rules
    and mechanisms that guide devices or processes to achieve specific goals.
  prefs: []
  type: TYPE_NORMAL
- en: 'One type of control system is a *closed-loop system*. Picture this: you’ve
    set your room’s thermostat to a cozy 22°C (72°F), and the heating or cooling system
    kicks in to reach that temperature. But what happens if it becomes too chilly
    or too warm? That’s when the closed-loop system starts to take action. It’s continually
    tracking the room’s current temperature, comparing it to the desired temperature,
    and making the necessary heating or cooling tweaks.'
  prefs: []
  type: TYPE_NORMAL
- en: The proportional integral derivative (PID) controller is the most commonly used
    algorithm in control systems engineering. This controller is designed to compensate
    for any error between the measured state (e.g., the current room temperature)
    and the desired state (e.g., the desired temperature value). Let’s consider room
    temperature control using a PID controller as an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in figure 8.17, the controller takes the error signal *e*(*t*) (the
    difference between the desired state and the feedback signal) and produces the
    appropriate control signal *u*(*t*) to turn on or off the heater in order to minimize
    the difference between the current room temperature and the desired value. The
    control signal is calculated using equation 8.4:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F16_Khamis-EQ09.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.4 |'
  prefs: []
  type: TYPE_TB
- en: As shown in this equation, the *proportional term* *K[p]e*(*t*) tends to produce
    a control signal that is proportional to the error and aims to rectify it. The
    *integral term* (the second term on the right side of the equation) tends to produce
    a control signal that is proportional to the magnitude of the error and its duration,
    or the area under the error curve. The *derivative term* (the third term on the
    right side of the equation) tends to produce a control signal that is proportional
    to the rate of error change, thus providing an anticipatory control signal.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F17_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.17 PID-based closed-loop control system—the PID controller takes the
    error signal and produces a control signal to reduce the error to zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'Utilizing a PID controller allows the system (e.g., an air conditioner or heater)
    to follow the specified input and attain a desired or optimal steady-state error,
    rise time, settling time, and overshoot:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Rise time*—The rise time is the time required for the response to rise from
    10% to 90% of its final value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Peak overshoot*—The peak overshoot (aka maximum overshoot) is the deviation
    of the response at peak time from the final value of the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Settling time*—The settling time is the time required for the response to
    reach the steady state and stay within the specified tolerance bands (e.g., 2–5%
    of the final value) after the transient response has settled.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Steady-state error*—The steady-state error is the difference between the desired
    value and the actual value of the system output when the system has reached a
    stable condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As shown in figure 8.18, the heater is turned on (i.e., energized) when the
    current room temperature is lower than the set point or the desired value. The
    heater is turned off (i.e., de-energized) when the temperature is above the set
    point.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F18_new_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.18 Step response of a system. The heater is turned on or off according
    to the difference between the actual temperature and the desired value.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.6 shows the effect of PID controller parameters on the time response
    of the system. Note that these correlations may not be exactly accurate, because
    *K[p], K[i]*, and *K[d]* are dependent on each other. In fact, changing one of
    these variables can change the effect of the other two. For this reason, the table
    should only be used as a reference when you are determining the values for *K[p],
    K[i]*, and *K[d]*.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.6 Effects of adding PID controller parameters on the system’s response
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | Rise time | Overshoot | Settling time | Steady-state error |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| K[p] | Decreases | Increases | Small change | Decreases |'
  prefs: []
  type: TYPE_TB
- en: '| K[i] | Decreases | Increases | Increases | Decreases significantly |'
  prefs: []
  type: TYPE_TB
- en: '| K[d] | Small change | Decreases | Decreases | Small change |'
  prefs: []
  type: TYPE_TB
- en: 'Finding the optimal values of the PID controller parameters for an optimal
    controller response is a multivariate optimization problem commonly referred to
    as the *PID tuning problem*. The following four performance metrics are commonly
    used to evaluate the quality of a control system such as a PID controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '*ITAE (integral time absolute error)*—This metric penalizes errors that persist
    over time, making it suitable for systems where transient response and settling
    time are important. It is calculated using this formula: ITAE = ∫(*t*|*e*(*t*)|)
    *dt*, where *t* is the time, *e*(*t*) is the error at time *t* defined as *e*(*t*)
    = *r*(*t*) – *y*(*t*), *r*(*t*) is the reference signal (desired output) at time
    *t* (for step response *r*(*t*) = 1), and *y*(*t*) is the actual output of the
    system at time *t*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ITSE (integral time square error)*—Like ITAE, this metric also penalizes errors
    that last for a long time but places more emphasis on larger errors due to the
    squared term. It is calculated using this formula: ITSE = ∫(*te*(*t*)²) *dt*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*IAE (integral absolute error)*—This metric measures the overall magnitude
    of the error without considering the duration of the error. This is a simple and
    widely used performance metric, and it’s calculated using this formula: IAE =
    ∫|*e*(*t*)| *dt*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ISE (integral squared error)*—This metric emphasizes larger errors due to
    the squared term, making it useful for systems where minimizing large errors is
    a priority. It is calculated using this formula: ISE = ∫*e*(*t*)² *dt*. It penalizes
    errors more heavily if they occur later in the evolution of the response. It also
    penalizes an error *E* for time *dt* more heavily than *E*/*α* for time *αdt*,
    where *α* > 1. This expected response may have a slow rise time but with a more
    oscillatory behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Combined criteria*—This metric combines overshoot, rise time, settling time,
    and steady-state error [6]. It is calculated using this formula: *W* = (1 – *e*^–*^β*)(*M[p]*
    + error*[ss]*) + *e*^–*^β* (*t[s]* – *t[r]*), where *M*[p] is the overshoot, error[ss]
    is the steady-state error, *t[s]* is the settling time, *t[r]* is the rise time,
    and *β* is a balancing factor in the range of 0.8 to 1.5\. You can set *β* to
    be larger than 0.7 to reduce the overshoot and steady-state error. On the other
    hand, you can set *β* to be smaller than 0.7 to reduce the rise time and settling
    time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these metrics quantifies the error between the desired output and the
    actual output of the system in different ways, emphasizing different aspects of
    the control system’s performance. Note that performance metrics are not strictly
    confined to the aforementioned metrics. Engineers have the flexibility to devise
    custom performance metrics tailored to the specific goals and characteristics
    of the control system under consideration.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.19 shows a closed-loop control system where a transfer function is
    used to describe the relationship between the input and output of the system in
    a Laplace domain. This domain is a generalization of a frequency domain, providing
    a more comprehensive representation that includes transient behavior and initial
    conditions. Assume that *T[sp]* is the set point or the desired output and *G*
    represents the transfer functions indicated in the block diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F19_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.19 Closed-loop control system
  prefs: []
  type: TYPE_NORMAL
- en: 'All variables are a function of *s*, which is the output variable from a Laplace
    transform. The transfer function of a PID controller is given by this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F19_Khamis-EQ10.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.5 |'
  prefs: []
  type: TYPE_TB
- en: 'where *K[p]* is the proportional gain, *K[i]* is the integral gain, and *K[d]*
    is the derivative gain. Assume that the transfer function of the HVAC system is
    given by this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F19_Khamis-EQ11.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.6 |'
  prefs: []
  type: TYPE_TB
- en: 'Assuming that *G[s]* = 1 (unity feedback) and using block diagram reduction,
    we can find the overall transfer function *T*(*s*) of the closed loop system:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F19_Khamis-EQ12.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 8.7 |'
  prefs: []
  type: TYPE_TB
- en: Let’s now look at how we can find the optimal values for the PID parameters
    with Python. In the next listing, we start by importing the libraries we’ll use
    and defining the overall transfer function of the control system.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.5 Solving the PID tuning problem using GA
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: ① Import the control module.
  prefs: []
  type: TYPE_NORMAL
- en: ② Take PID parameters as input.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Define the numerator of the transfer function.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Define the denominator of the transfer function.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create a transfer function.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Get time response output using a step function as a system input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can define the objective functions or performance criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: ① ITAE (integral time absolute error)
  prefs: []
  type: TYPE_NORMAL
- en: ② ITSE (integral time square error)
  prefs: []
  type: TYPE_NORMAL
- en: ③ IAE (integral absolute error)
  prefs: []
  type: TYPE_NORMAL
- en: ④ ISE (integral squared error)
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ W (combined criteria)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define the optimization problem for the PID controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: ① Three decision variables, representing the PID controller’s Kp, Ki, and Kd
    gains
  prefs: []
  type: TYPE_NORMAL
- en: ② Number of objective functions
  prefs: []
  type: TYPE_NORMAL
- en: ③ No constraints
  prefs: []
  type: TYPE_NORMAL
- en: ④ Lower and upper bounds for the decision variables
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Evaluate the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can set up and solve the PID tuning problem using GA. The previously
    defined `PIDProblem` class is used to model the optimization problem. The GA solver
    is configured with a population size of 50\. Initial solutions are sampled using
    `FloatRandomSampling`, and the crossover operation employs a two-point crossover
    with a probability of 0.8\. Additionally, polynomial mutation is applied with
    a probability of 0.3, and the algorithm runs for 60 generations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s now print the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'And we’ll visualize the time response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Figure 8.20 depicts the step response of the system, demonstrating how its outputs
    change over time when the inputs swiftly transition from 0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F20_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.20 Step response
  prefs: []
  type: TYPE_NORMAL
- en: 'To show the step response characteristics (rise time, settling time, peak,
    and others), you can use the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: You can experiment with adjusting the algorithm’s parameters (such as population
    size, crossover method and probability, mutation method and probability, number
    of generations, etc.) and altering the performance metric to observe the effects
    on the system’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: 8.8 Political districting problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I introduced political districting in section 2.1.5—it can be defined as the
    process of grouping *n* subregions within a territory into *m* electoral districts
    while adhering to certain constraints. Suppose we need to merge *n* neighborhoods
    in the City of Toronto into *m* electoral districts while ensuring a sufficient
    level of population equality. Figure 8.21 shows a sample dataset that contains
    population and median household income for 16 neighborhoods in East Toronto.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F21_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.21 The 16 neighborhoods in East Toronto with their population and median
    household income
  prefs: []
  type: TYPE_NORMAL
- en: 'In addressing the political districting problem, a viable solution must ensure
    that there is a satisfactory degree of population equilibrium (i.e., a fair and
    balanced distribution) in every electoral district. For example, we can evaluate
    a district’s population balance by calculating the deviation from an ideal population
    size within an upper bound (pop[UB]) and lower bound (pop[LB]) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F21_Khamis-EQ13.png)'
  prefs: []
  type: TYPE_IMG
- en: where *pop[av]* represents the target population size that can be considered
    the average of all the neighborhoods and *pop[margin]* indicates the acceptable
    degree of deviation from the ideal population size. *n* is the number of the neighborhoods,
    and *m* is the number of districts.
  prefs: []
  type: TYPE_NORMAL
- en: A district will be regarded as overpopulated if its total population exceeds
    the upper bound, and conversely, a district will be deemed underpopulated if its
    total population falls below the lower bound. A district whose population falls
    within the upper and lower bounds will be regarded as having an appropriate population
    size. The objective function is to minimize the total number of overpopulated
    and underpopulated districts. The search process will persist until the objective
    function’s minimum value is obtained, ideally zero. This indicates that no districts
    are either overpopulated or underpopulated.
  prefs: []
  type: TYPE_NORMAL
- en: The next listing shows how to find the political districts using GA. We’ll start
    by reading the data from a local folder or using a URL.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.6 Solving a political districting problem using GA
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: ① URL for the data folder
  prefs: []
  type: TYPE_NORMAL
- en: ② Read the Toronto region administration boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Read the neighborhood information (e.g., names, populations, and median household
    incomes).
  prefs: []
  type: TYPE_NORMAL
- en: ④ Pick 16 neighborhoods as a subset to represent neighborhoods in East Toronto.
  prefs: []
  type: TYPE_NORMAL
- en: After reading the dataset, we’ll do the following data preprocessing to get
    the population of each neighborhood, and the adjacency relationship among every
    possible pair of neighborhoods, in a Boolean matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: ① Get the population of each neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: ② Prepare the population dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Represent the adjacency relationship among every possible pair of neighborhoods.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll now define the political districting class with a single objective function,
    three constraints, a given number of districts, a given population margin, and
    an adjacency matrix between the neighborhoods. `PoliticalDistricting` is a custom
    problem class that extends the `Problem` class from pymoo. The `Problem` class
    implements a method that evaluates a set of solutions instead of a single solution
    at a time, like in the case of the `ElementwiseProblem` class. In the `PoliticalDistricting`
    class, the following parameters are defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '`num_dist`—The number of districts to divide the region into'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`neighbor`—A matrix representing the neighborhood relationships between locations
    in the region'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`populations`—The population of each neighborhood'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`margin`—The acceptable degree of deviation from the ideal population size'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`average`—The average population'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_var`—The number of decision variables, which is equal to the number of neighborhoods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_obj=1`—The number of objectives, which is 1 for this problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_eq_constr=3`—The number of equality constraints, which is 3 for this problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`xl=0`—The lower bound for the decision variables, which is 0 for this problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`xu=num_dist-1`—The upper bound for the decision variables, which is `num_dist-1`
    for this problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vtype=int`—The type of decision variables, which is integer for this problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how to define a `PoliticalDistricting` class with
    different parameters, such as the number of districts, neighbor information, populations,
    and margin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: ① Define a constructor with specific parameters.
  prefs: []
  type: TYPE_NORMAL
- en: ② Hold the population data.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Store the mean population of all districts.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Call the constructor of the parent class with specific parameters.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Evaluate the solution against the objective function and constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation and as part of the `problem` class, we’ll extract the neighborhoods
    that belong to a specific district using the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll then calculate the upper and lower bounds based on the given population
    values and margin as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function is used to decide whether an electoral district is overpopulated
    or underpopulated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'As all the constraints are equality constraints, the following function returns
    true if the constraint is satisfied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'To make sure that there is no isolated neighborhood far from other neighbors
    within a district, unless the district only has one neighborhood, the following
    function is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The following function determines the best approximation to make an electoral
    district a contiguous block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The last function in the `problem` class is used to evaluate the solution against
    the objective function, including checking the constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '① Constraint 1: make sure that there is no empty district,'
  prefs: []
  type: TYPE_NORMAL
- en: '② Constraint 2: make sure there is no lone neighborhood within a district,
    unless the district only has one neighborhood.'
  prefs: []
  type: TYPE_NORMAL
- en: '③ Constraint 3: ensure the electoral district is a contiguous block by achieving
    the best possible approximation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define the GA solver and apply it to solve the problem as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The resultant political districts are listed here and visualized in figure
    8.22:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/CH08_F22_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.22 The three political districts that combine the 16 neighborhoods
  prefs: []
  type: TYPE_NORMAL
- en: The problem is treated as a single objective optimization problem where the
    objective is to minimize the total number of overpopulated and underpopulated
    districts. The dataset contains the median household income of each neighborhood,
    so you can replace the objective function to focus on the heterogeneity of the
    median household income. You can also treat the problem as a multi-objective optimization
    problem by considering both criteria.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter marks the end of the third part of the book, which focused on genetic
    algorithms and their applications in solving complex optimization problems. The
    fourth part of the book will delve into the fascinating realm of swarm intelligence
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Hamming cliff problem, which results from the inherent nature of binary
    representation, negatively affects binary-coded GAs by disrupting the search space’s
    smoothness, causing poor convergence and leading to inefficient exploration and
    exploitation. To address this problem, alternative representations like Gray code
    or real-valued encoding can be used, as they offer better locality and smoother
    search spaces, minimizing the disruptive effects of small changes on decoded values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-valued GA is well suited for optimization problems involving continuous
    variables or real-valued parameters. It offers benefits such as better representation
    precision, faster convergence, diverse crossover and mutation operations, and
    reduced complexity, making it an attractive choice for many continuous optimization
    problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Permutation-based GA is a class of genetic algorithms specifically designed
    to handle combinatorial optimization problems where the solutions can be represented
    as ordered sequences, or permutations, of elements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-objective optimization problems can be tackled using either a preference-based
    multi-objective optimization method or a Pareto optimization approach. In the
    preference-based method, the multiple objectives are combined into a single or
    overall objective function by using a weighting scheme. The Pareto optimization
    approach focuses on identifying multiple trade-off optimal solutions known as
    Pareto-optimal solutions. These solutions can be further refined using higher-level
    information or decision-making processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crossover is primarily exploitative, as it combines the genetic material of
    two parent individuals to produce offspring, promoting the exchange of beneficial
    traits between solutions. However, depending on the implementation, crossover
    can also have some explorative properties, as it can produce offspring with new
    combinations of genes, leading to the discovery of new solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutation can act as an explorative or exploitative operator depending on influencing
    factors such as the mutation rate and the mutation step size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, the crossover rate should be relatively high, as it promotes the
    exchange of genetic information between parent chromosomes. On the other hand,
    mutation is typically applied with a low probability, as its main purpose is to
    introduce random variations into the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
