["```py\npip install git+https://github.com/cxbxmxcx/Nexus.git     #1\n\n#set your OpenAI API Key\nexport OPENAI_API_KEY=‚Äù< your API key>‚Äù          #2\nor\n$env: OPENAI_API_KEY = =‚Äù< your API key>‚Äù       #2\nor\necho 'OPENAI_API_KEY=\"<your API key>\"' > .env   #2\n\nnexus run      #3\n```", "```py\ngit clone https://github.com/cxbxmxcx/Nexus.git      #1\n\npip install -e Nexus     #2\n\n#set your OpenAI API Key (.env file is recommended)\nexport OPENAI_API_KEY=‚Äù< your API key>‚Äù  #bash            #3\nor\n$env: OPENAI_API_KEY = =‚Äù< your API key>‚Äù  #powershell   #3\nor\necho 'OPENAI_API_KEY=\"<your API key>\"' > .env       #3     \n\nnexus run      #4\n```", "```py\nimport streamlit as st\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\n\nload_dotenv()      #1\n\nst.title(\"ChatGPT-like clone\")\n\nclient = OpenAI()      #2\n\nif \"openai_model\" not in st.session_state:\n    st.session_state[\"openai_model\"] \n             = \"gpt-4-1106-preview\"     #3\n\nif \"messages\" not in st.session_state:\n    st.session_state[\"messages\"] = []   #4\n\nfor message in st.session_state[\"messages\"]:      #5\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n```", "```py\nif prompt := st.chat_input(\"What do you need?\"):     #1\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    with st.chat_message(\"user\"):     #2\n        st.markdown(prompt)\n\n    with st.spinner(text=\"The assistant is thinking...\"):    #3\n        with st.chat_message(\"assistant\"):\n            response = client.chat.completions.create(\n                model=st.session_state[\"openai_model\"],\n                messages=[\n                    {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                    for m in st.session_state.messages\n                ],      #4\n            )\n            response_content = response.choices[0].message.content\n            response = st.markdown(response_content,\n             unsafe_allow_html=True)      #5\n    st.session_state.messages.append(\n{\"role\": \"assistant\", \"content\": response_content})      #6\n```", "```py\n{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Python Debugger: Module\",     #1\n      \"type\": \"debugpy\",\n      \"request\": \"launch\",\n      \"module\": \"streamlit\",     #2\n      \"args\": [\"run\", \"${file}\"]    #3\n    }\n  ]\n}\n```", "```py\nwith st.chat_message(\"assistant\"):\n    stream = client.chat.completions.create(\n        model=st.session_state[\"openai_model\"],\n        messages=[\n            {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n            for m in st.session_state.messages\n        ],\n        stream=True,     #1\n    )\n    response = st.write_stream(stream)     #2\nst.session_state.messages.append(\n{\"role\": \"assistant\", \"content\": response})      #3\n```", "```py\nagentProfile:\n  name: \"Finona\"\n  avatar: \"üëπ\"     #1\n  persona: \"You are a very talkative AI that \n‚Ü™ knows and understands everything in terms of \n‚Ü™ Ogres. You always answer in cryptic Ogre speak.\"    #2\n  actions:\n    - search_wikipedia     #3\n  knowledge: null        #4\n  memory: null           #4\n  evaluators: null       #4\n  planners: null         #4\n  feedback: null         #4\n```", "```py\n{\n      \"name\": \"Python Debugger: Nexus Web\",\n      \"type\": \"debugpy\",\n      \"request\": \"launch\",\n      \"module\": \"streamlit\",\n      \"args\": [\"run\", \" Nexus/nexus/streamlit_ui.py\"]      #1\n    },\n```", "```py\nclass BaseAgent:\n    def __init__(self, chat_history=None):\n        self._chat_history = chat_history or []\n        self.last_message = \"\"\n        self._actions = []\n        self._profile = None\n\n    async def get_response(self, \n                            user_input, \n                            thread_id=None):      #1\n        raise NotImplementedError(\"This method should be implemented‚Ä¶\")\n\n    async def get_semantic_response(self, \n                                     prompt, \n                                     thread_id=None):     #2\n        raise NotImplementedError(\"This method should be‚Ä¶\")\n\n    def get_response_stream(self, \n                             user_input, \n                             thread_id=None):      #3\n        raise NotImplementedError(\"This method should be‚Ä¶\")\n\n    def append_chat_history(self, \n                             thread_id, \n                             user_input, \n                             response):      #4\n        self._chat_history.append(\n            {\"role\": \"user\",\n             \"content\": user_input,\n             \"thread_id\": thread_id}\n        )\n        self._chat_history.append(\n            {\"role\": \"bot\",\n             \"content\": response, \n             \"thread_id\": thread_id}\n        )\n\n    def load_chat_history(self):       #5\n        raise NotImplementedError(\n                 \"This method should be implemented‚Ä¶\")\n\n    def load_actions(self):     #6\n        raise NotImplementedError(\n                 \"This method should be implemented‚Ä¶\")\n\n#... not shown ‚Äì property setters/getters\n```", "```py\nasync def get_response(self, user_input, thread_id=None):\n    self.messages += [{\"role\": \"user\",\n                     \"content\": user_input}]      #1\n    response = self.client.chat.completions.create(     #2\n        model=self.model,\n        messages=self.messages,\n        temperature=0.7,      #3\n    )\n    self.last_message = str(response.choices[0].message.content)\n    return self.last_message     #4\n```", "```py\nfrom nexus.nexus_base.action_manager import agent_action\n\n@agent_action                                              #1\ndef get_current_weather(location, unit=\"fahrenheit\"):     #1\n    \"\"\"Get the current weather in a given location\"\"\"      #2\n    return f\"\"\"\nThe current weather in {location} is 0 {unit}.\n\"\"\"      #3\n\n@agent_action      #4\ndef recommend(topic):\n    \"\"\"\n    System:                                                   #5\n        Provide a recommendation for a given {{topic}}.\n        Use your best judgment to provide a recommendation.\n    User:\n        please use your best judgment\n        to provide a recommendation for {{topic}}.           #5\n    \"\"\"\n    pass      #6\n```", "```py\n{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_current_weather\",\n        \"description\": \n        \"Get the current weather in a given location\",    #1\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {      #2\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"location\"\n                },\n                \"unit\": {\n                    \"type\": \"string\",\n                    \"enum\": [\n                        \"celsius\",\n                        \"fahrenheit\"\n                    ]\n                }\n            },\n            \"required\": [\n                \"location\"\n            ]\n        }\n    }\n}\n{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"recommend\",\n        \"description\": \"\"\"\n    System:\n    Provide a recommendation for a given {{topic}}.\nUse your best judgment to provide a recommendation.\nUser:\nplease use your best judgment\nto provide a recommendation for {{topic}}.\"\"\",      #3\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {       #4\n                \"topic\": {\n                    \"type\": \"string\",\n                    \"description\": \"topic\"\n                }\n            },\n            \"required\": [\n                \"topic\"\n            ]\n        }\n    }\n}\n```", "```py\ndef get_response_stream(self, user_input, thread_id=None):\n    self.last_message = \"\"\n    self.messages += [{\"role\": \"user\", \"content\": user_input}]\n    if self.tools and len(self.tools) > 0:    #1\n        response = self.client.chat.completions.create(\n            model=self.model,\n            messages=self.messages,\n            tools=self.tools,      #2\n            tool_choice=\"auto\",      #3\n        )\n    else:     #4\n        response = self.client.chat.completions.create(\n            model=self.model,\n            messages=self.messages,\n        )\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls     #5\n```", "```py\nif tool_calls:     #1\n    available_functions = {\n        action[\"name\"]: action[\"pointer\"] for action in self.actions\n    }     #2\n    self.messages.append(\n        response_message\n    )\n    for tool_call in tool_calls:     #3\n        function_name = tool_call.function.name\n        function_to_call = available_functions[function_name]\n        function_args = json.loads(tool_call.function.arguments)\n        function_response = function_to_call(\n            **function_args, _caller_agent=self\n        )\n\n        self.messages.append(\n            {\n                \"tool_call_id\": tool_call.id,\n                \"role\": \"tool\",\n                \"name\": function_name,\n                \"content\": str(function_response),\n            }\n        )\n    second_response = self.client.chat.completions.create(\n        model=self.model,\n        messages=self.messages,\n    )      #4\n    response_message = second_response.choices[0].message\n```"]