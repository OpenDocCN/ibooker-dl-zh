# 第九章：建立和运行您自己的大型语言模型

### 本章内容包括

+   为什么您可能想要建立自己的大型语言模型

+   选择一个 LLM 模型作为您自定义配置的基础

+   如何（在非常一般的术语中）进行模型微调

建立（或修改）您自己的 LLM？但 OpenAI（及其投资者）花费数十亿美元优化和训练他们的 GPT。通过使用本地硬件进行自己的项目，是否有可能生成甚至远程竞争力的结果？

令人难以置信的是，在 LLM 技术的旋风演变到这一步时，对这个问题的答案是"是的"。由于 Meta 的开源 LLaMA 模型的存在，模型权重的未经授权泄漏（我将在接下来解释），以及许多卓越的公共贡献，现在有数百种高效而又资源友好的 LLM 可供任何人下载、选择性修改和运行。

话虽如此，如果操作到这种技术深度不是你的菜 - 尤其是如果你没有合适的硬件访问权限 - 那么可以跳过到下一章。

## 9.1 建立自己的模型的一些背景知识

在我们解释所有这些是如何工作之前，我们应该解决一个更大的问题：为什么有人*想要*建立自己的 LLM？以下是值得考虑的一些事项：

+   通过建立自己的 LLM，您可以更好地控制其架构、训练数据和微调。这使您能够将模型专门定制到您的需求和领域。您可以为特定任务、行业或应用程序进行优化，这可能会带来更好的性能和更准确的结果。

+   一些组织可能有严格的数据隐私要求或无法与第三方服务共享的敏感信息。事实上，三星最近禁止其员工使用 GPT 或 Bard，因为他们担心他们的互动可能会意外泄漏专有公司信息。建立自己的 LLM 可以确保所有数据和处理都留在您的组织内部，减少隐私和安全方面的担忧。

+   如果您的应用需要专业知识或在一个小众领域操作，建立自己的 LLM 可以让您将特定的数据源和领域专业知识纳入到训练过程中。这可以增强模型的理解能力，并生成更符合您特定领域需求的响应。

+   像 GPT 这样的预训练模型被设计为通用型，并且在各种领域都能工作得相当好。然而，对于特定任务，建立一个定制的 LLM 可能会导致性能和效率的提升。您可以优化架构、训练方法和配置设置，以在特定用例上获得更好的结果。

+   构建自己的 LLM 可以让你拥有对模型的知识产权的所有权和控制权。你可以修改、扩展和分发模型以满足你的需求，而不受使用现有模型所带来的限制或许可协议的约束。

在 Meta 泄露事件后，社区中许多聪明的人们将注意力集中在构建可以用更少硬件完成更多任务的 LLM 变体上。例如，量化是一种将模型压缩以便在没有图形处理器单元（GPU）的计算机上运行的方法。超高效的微调技术，包括一种称为 Low-Rank Adaptation (LoRA)的技术，使得模型微调所需的资源和时间大大减少。

所有这些内容都在一份 p.html 上被广泛阅读的内部 Google 文档中提到，不知何故，这份文档进入了公开的互联网。未知作者强烈指出，包括 OpenAI、Meta 和 Google 在内的大公司在人工智能领域已经完全失去了竞争优势。从现在开始，技术上的重大进展将发生在野外，远离大公司或政府的控制之外。

那么为什么你可能想要拥有自己的 LLM 呢？因为此时，你可以享受全新的定制和优化水平。它会如何工作呢？嗯，因为我实在想不到你有任何理由从零开始启动自己的 LLM 项目，所以我假设你对现有平台感兴趣。你会面临三个选择：一个模型，一组权重，以及你是否还想对所选择的模型进行微调。

构建一个 LLM 对不同的人可能意味着不同的事情，这是因为我们所谓的"LLMs"由多个组成部分组成。从技术上讲，有输入编码、神经网络架构、嵌入层、隐藏层、注意力机制、训练数据、解码算法以及大量的训练数据。

老实说，我真的不太明白大部分这些是什么，以及它们应该做什么。就我们现在的目的而言，仅仅将定义编码和一般架构的代码视为*模型*就足够了。至于基于 Transformer 的语言模型（LLMs），至少对于像 GPT 那样的 LLMs，我们可以将"注意力机制"视为定义*权重*的原因。顺便说一句，注意力机制能够以更复杂的方式对上下文和单词或令牌之间的关系进行建模。

权重到底是什么？在神经网络中，每个神经元之间的连接都被赋予一个权重，表示该连接的强度或重要性。对于一个模型来说，这些权重是可学习的参数，在训练过程中进行调整。在训练过程中，LLM 暴露于大量的训练数据，并学会预测下一个单词或生成连贯的文本。

权重确定了信息如何通过网络流动以及它们如何影响 LLM 的最终预测或输出。通过调整权重，模型可以学习将更高的重要性赋予某些输入特征或模式，并根据其接触到的训练数据进行更准确的预测。没有权重，LLM 模型几乎没有用处。

## 选择基本 LLM 模型进行配置

一个很好的开始你的研究的地方是 Hugging Face 开放 LLM 排行榜，其中列出了许多免费提供的基于 transformers 的 LLM 的评估性能。您可以切换每个评估列，以通过特定功能缩小搜索范围。这些功能包括“ARC” - A12 推理挑战 - 它测试模型如何回答有关高中科学的问题。点击该页面上的“关于”选项卡将为您提供所有评估标准的优秀描述。

当您在列表中浏览替代品时，您会注意到有几个关键的 LLM 系列，例如 Meta 的 LLaMA 和 Together Computer 的 RedPajama。还有一些从其他模型派生出来的模型。例如，OpenLLaMA 是一个“复制 Meta AI 的 LLaMA 7B”模型，该模型在“RedPajama 数据集”上进行了训练。

您会注意到模型名称通常包括其参数大小（以十亿为单位）：7B、13B、33B、65B 等等。一般来说，用于构建模型的参数越多，您就需要更好的硬件来运行它。点击模型的单独文档页面通常会向您显示模型训练所使用的*标记*数量。一个较大的模型可能会包含超过一万亿个标记。

一旦您选择了一个模型，您通常会转到其 GitHub 页面，那里通常会有使用说明以及如何克隆或下载模型本身的说明。其中一个很好的例子是 llama.cpp LLaMA 推理。但是即使您已经在您的机器上获得了软件，通常您仍然需要单独下载一组权重。

他们为什么不直接将权重与他们的模型捆绑在一起呢？首先，您可能需要为您的特定任务定制一种权重组合。但还有另一件事情正在进行。有些权重集只有在您的请求获得批准后才能获得。而且，许多免费提供的集合来自……我们应该说……可疑的来源。在这种情况下，将它们都放在一个地方提供可能实际上并不实际。

话虽如此，Alpaca-LoRA 和 RedPajama-INCITE-3B 模型附带了可以在构建过程中为您获取权重集的脚本。我们将在接下来的几分钟内演示一个 RedPyjama 构建示例。

在选择 LLM 时的最后一个考虑因素是，你需要确保模型能够在你拥有的硬件上运行。由于它们严重依赖计算处理能力，大多数模型都需要图形处理单元（GPUs），有时还需要大量的专用*视频内存*。如果你计划在任务中使用常规的消费者笔记本电脑或台式机，请确保你使用的是仅 CPU 模型。另外，你也可以随时向云提供商（例如亚马逊网络服务）租用所需的所有 GPU 计算能力。

## 9.3 配置和构建你的模型

如果你尝试以下说明，你可能会发现在你的 LLM 构建时一切都进行得很顺利，但突然间一切都停滞了下来。"但是"你喊道，"我完美地遵循了模型的指令。"

你确实做到了。实际上，太完美了。你知道，这些说明通常需要进行一点定制才能起作用。最常见的更改涉及到这个命令参数：

```py
/path/to/downloaded/llama/weights
```

那个`/path/to/downloaded/...`应该被更新以反映存储着你所下载的`.bin`预训练权重文件的实际文件系统位置。可能看起来像这样：

```py
~/redpajama.cpp/examples/redpajama/models/pythia/
```

这个文档页面很好地指导我们如何下载和启动他们的模型。你可以从克隆基本存档开始：

```py
git clone https://github.com/togethercomputer/redpajama.cpp.git
cd redpajama.cpp
```

你将运行`make`来，在这种情况下，构建一个压缩的（quantized）聊天环境所必需的。

```py
make redpajama-chat quantize-gptneox
```

这个脚本实际上会下载并构建适当的一组量化（quantized）权重：

```py
bash \
 ./examples/redpajama/scripts/install-RedPajama-INCITE-Chat-3B-v1.sh
```

最后，你可以使用`redpajama-chat`命令启动聊天，该命令以`ggml-RedPajama-INCITE-Chat-3B-v1-f16.bin`权重文件为目标，并传递一个长长的配置参数列表（其中任何一个都可以根据你的需求进行更改）。

```py
./redpajama-chat -m ./examples/redpajama/models/pythia/\
	ggml-RedPajama-INCITE-Chat-3B-v1-f16.bin \
       -c 2048 \
       -b 128 \
       -n 1 \
       -t 8 \
       --instruct \
       --color \
       --top_k 30 \
       --top_p 0.95 \
       --temp 0.8 \
       --repeat_last_n 3 \
       --repeat_penalty 1.1 \
       --seed 0
```

Git 存档附带了 Python 脚本，帮助你进一步定制你的体验。例如，你可以通过向`./examples/redpajama/scripts/quantize-gptneox.py`脚本传递诸如`--quantize-output-type q4_1`之类的参数，来尝试各种量化方法。

## 9.4 调整你的模型

调整需要比我们刚刚看到的配置更多的工作。如果你有 GPU，那么你可以考虑自己调整下载的模型。作为一个基准，一张流行的高端 GPU 卡，对于许多 LLM 构建操作来说是有效的，可能包括曾经主要用于游戏电脑的 Nvidia 3090。

就我所知（从未拥有过自己的）3090 将配备 24GB 的图形内存。显然，这对于使用我们之前提到的高效的 LoRA 方法进行调整足够了。否则，你可能需要将*多个* Nvidia 3090 链接在一起。这不会便宜（3090 似乎每张要价约 1400 美元），但它与 OpenAI、Meta 和 Google 一直在做的事情完全不同。

微调和简单配置模型（我们刚刚看到的方式）之间的一个区别是，微调涉及重新在通常包含数千亿令牌（每个令牌大致相当于一个单词）的数据集上训练您的模型。正是这些大型数据集，有望使模型捕捉到通用的语言模式和知识。真正的定制工作发生在这里，你可以自由使用自己的数据。

尽管说了这么多，我不打算在实践层面向你展示任何工作原理。我不仅缺乏使其工作的硬件，而且我怀疑你也是如此。但至少从一般的角度来思考一下是值得的。

### 9.4.1 创建数据集

例如，要构建一个专门供律师或医疗专业人士使用的模型，你需要一个包含大量法律或医疗内容的数据集。但考虑到训练有效模型所需的内容量之大，你可以理解为什么你需要一些更强大的硬件。

构建您的数据集，然后执行微调构建已经超出了本书的范围。更不用说，当你阅读这些文字时，它们的执行方式几乎肯定已经发生了不可识别的变化。所以如果在你的未来有微调事件，很遗憾，这里不是你找到答案的地方。

### 9.4.2 训练您的模型

因为它们在 LLMs 的训练和微调的背景下经常被使用，我应该简要描述一下**零样本**和**少样本**方法来进行模型训练。零样本和少样本训练通常会在模型暴露于其大型训练数据集的预训练阶段之后进行。

零样本学习涉及使用语言模型执行其没有接受任何特定训练的任务。相反，它利用其对语言的一般理解来根据提示或指令完成任务。关键的想法是模型可以从其预先训练的知识中概括，并将其适应于新任务。通过提供详细的提示，指定所需的任务和格式，模型可以生成相关的输出。

例如，即使模型尚未针对翻译任务进行特定的微调，你也可以使用零样本提示指导模型，比如，“将以下英语句子翻译成法语：Hello, how are you?”。然后，该模型将基于其对语言和提示的理解生成翻译输出。

少样本学习涉及提供少量特定任务的训练示例或演示给语言模型，以便它可以快速适应新任务。虽然零样本学习不涉及任何特定任务的训练，但少样本学习提供了少量示例来帮助模型更好地理解任务。通过在这些少量示例上对模型进行条件设置，它可以学会更准确地执行所需的任务。

例如，如果您想让模型总结新闻文章，您可能会提供一些文章摘要的例子以及文章本身。然后，模型可以使用这些信息为其他文章生成摘要。

零样本学习和少样本学习方法都允许语言模型在不需要进行广泛的微调或在大型数据集上进行训练的情况下执行各种任务。它们展示了这些模型惊人的泛化能力，使它们能够将其语言理解应用于各种任务。

## 9.5 摘要

+   定制大型语言模型可以解决那些通用模型不合适的问题。

+   配置您自己的模型需要从一个 base LLM 开始。

+   对新模型进行良好的调整需要访问您自己的数据集和重要的硬件资源。
