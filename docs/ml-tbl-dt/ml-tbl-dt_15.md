# 附录 A. 经典机器学习模型的超参数

表 A.1 线性模型的超参数

| 超参数 | 描述 |
| --- | --- |
| `C`  | 与正则化成反比，较小的值对应更强的正则化。在范围 `np.logspace(-4, 4, 10)` 中搜索。 |
| `alpha`  | 乘以正则化项的常数，较大的值对应更强的正则化。在范围 `np.logspace(-2, 2, 10)` 中搜索。 |
| `l1_ratio`  | 在 Elasticnet 中混合 L1 和 L2 正则化，从值 [.1, .5, .7, .9, .95, .99] 中选择。 |

表 A.2 随机森林和 ERTs 的超参数

| 超参数 | 描述 |
| --- | --- |
| `max_features`  | 降低此参数以增加偏差并降低方差。尝试 `sqrt`、`log2` 以及代表特征 1/10 和 1/20 的整数等值。 |
| `min_samples_leaf`  | 一种正则化树的方法，通常设置为 1；尝试将其增加到 30。 |
| `bootstrap`  | 一个布尔值，表示是否使用自助重采样。如果存在噪声或异常值，有时子采样可能比自助重采样更有效。 |
| `n_estimators`  | 树越多越好，但超过一定点后你会浪费计算能力。从 100 开始，增加到 1,000。它适用于大多数问题。 |

表 A.3 Scikit-learn 的 HistGradientBoosting 的超参数

| 超参数 | 描述 |
| --- | --- |
| `learning_rate`  | 决策树结果的乘法值。介于 0.001 和 0.1 之间的实数。 |
| `max_iter`  | 增强过程中构建的树的最大数量。介于 100 和 1,000 之间的整数。 |
| `max_depth`  | 每棵树的最大深度作为对树生长的正则化。选择介于 1 和 12 之间的整数。 |
| `max_leaf_nodes`  | 每棵树的最大叶子节点数。与 `max_depth` 相关，它也控制树的生长。优化此参数或 `max_depth`，但不要同时优化。选择介于 2 和 4,096 之间的整数。 |
| `min_samples_leaf`  | 每个叶子节点所需的最小样本数是对树生长的正则化。选择介于 2 和 300 之间的整数。 |
| `l2_regularization`  | 集成中的 L2 正则化参数。选择介于 0.0 和 100.0 之间的浮点数。 |
| `max_bins`  | 在直方图中使用的最大箱数。一种间接的正则化树的方法。选择介于 32 和 512 之间的整数。 |

表 A.4 XGBoost 的超参数

| 超参数 | 描述 |
| --- | --- |
| `learning_rate`  | 用于缩小决策树结果的乘法值。介于 0.001 和 0.1 之间的实数。 |
| `n_estimators`  | 增强集中树的数量。介于 100 和 1,000 之间的整数。 |
| `max_depth`  | 树的最大深度是控制估计方差的一种方法。介于 1 和 12 之间的整数。 |
| `min_child_weight`  | 子节点中需要的最小实例权重（海森）之和。默认值为 1。`min_child_weight`越大，算法越保守。我们建议一个介于 1 和 10 之间的整数。 |
| `max_delta_step`  | 通常为零，表示无约束，如果设置为正数，则充当正则化器，因为它限制了更新的限制。在分类中类之间存在不平衡时很有益，因为它防止一个类主导其他类。我们建议一个介于 0 和 10 之间的浮点数。 |
| `max_bin`  | 历史图使用的最大箱数。一个介于 32 和 512 之间的整数。 |
| `subsample`  | 训练实例的采样比率。一个介于 0.1 和 1.0 之间的实数。 |
| `colsample_bytree`  | 构建每个树时列的子采样比率。一个介于 0.1 和 1.0 之间的实数。 |
| `reg_lambda`  | 权重的 L2 正则化项。一个介于 1e-9 和 100.0 之间的实数。 |
| `reg_alpha`  | 权重的 L1 正则化项。一个介于 1e-9 和 100.0 之间的实数。 |
| `gamma`  | 另一个通过设置最小损失减少来限制树分割的正则化器。将其设置为介于 0 和 0.5 之间的实数。 |
| `scale_pos_weight`  | 控制正负权重平衡的权重值，对于不平衡的二进制分类问题很有用。默认设置为 1；一个典型的考虑值：负实例数/正实例数。我们建议一个介于 1e-6 和 500 之间的实数。 |

表 A.5 LightGBM 的超参数

| 超参数 | 描述 |
| --- | --- |
| `learning_rate`  | 用于缩小决策树结果的乘法值。一个介于 0.001 和 0.1 之间的实数。 |
| `n_estimators`  | 增强迭代的数量。一个介于 100 和 1,000 之间的整数。 |
| `max_depth`  | 决策树的最大深度限制。控制复杂性和过拟合的一种方法。一个介于 1 和 12 之间的整数。 |
| `num_leaves`  | 一个介于 2 和 2`max_depth`之间的整数，它表示树将拥有的最终叶子节点数，如果设置得较低，则充当树复杂性的正则化器。 |
| `min_data_in_leaf`  | 一个叶子节点中的最小数据量。设置此参数有助于处理过拟合。零表示无约束。一个介于 0 和 300 之间的整数。 |
| `min_gain_to_split`  | 决策树中进行分割的最小增益。一个介于 0 和 15 之间的浮点数。 |
| `max_bin`  | 用于历史图的最大箱数。通过将其设置得较低来处理过拟合的一个间接方法。一个介于 32 和 512 之间的整数。 |
| `subsample`  | 在不重采样的情况下选择随机数据百分比的参数。一个介于 0.1 和 1.0 之间的实数。 |
| `subsample_freq`  | 子采样频率：一个介于 0 和 10 之间的整数。如果设置为 0，则算法将忽略与子采样相关的任何设置，并且不会执行子采样。 |
| `feature_fraction`  | 每次迭代中使用的特征分数。一个介于 0.1 和 1.0 之间的实数。 |
| `reg_lambda`  | L2 正则化。一个介于 0.0 和 100.0 之间的实数。 |
| `reg_alpha`  | L1 正则化。一个介于 0.0 和 100.0 之间的实数。 |
| `scale_pos_weight`  | 用于在类别不平衡的二分类中抵消正类标签权重的系数。一个介于 1e-6 和 500 之间的实数。 |
