# 12 数据分布

本章涵盖了

+   在机器学习中应用分布的统计原理

+   理解精选数据集和非精选数据集之间的差异

+   使用总体、抽样和子总体分布

+   在训练模型时应用分布概念

作为数据科学家和教育工作者，我经常收到软件工程师关于如何提高模型准确性的问题。我给出的五个基本答案，以提高模型的准确性如下：

+   增加训练时间。

+   增加模型的深度（或宽度）。

+   添加正则化。

+   通过数据增强扩展数据集。

+   增加超参数调整。

这些是最有可能需要解决的问题，并且通常解决其中之一或多个将提高模型准确性。但重要的是要理解，准确性的限制最终在于*用于训练模型的数据库集*。这正是我们要探讨的：数据集的细微差别，以及它们如何以及为什么会影响准确性。而“细微差别”指的是数据的分布模式。

在本章中，我们将深入探讨三种类型的数据分布：总体、抽样和子总体。特别是，我们将研究这些分布如何影响模型在现实世界中对数据的准确泛化能力。你会发现，模型的准确性通常与训练或评估数据集生成的预测不同，这种差异被称为服务偏差和数据漂移。

在本章的后半部分，我们将通过一个实际案例来展示如何在训练过程中将不同的数据分布应用于同一模型，并观察在推理阶段，对真实世界服务偏差和数据漂移的不同影响结果。

要理解分布及其对结果和准确性的影响，我们需要回到基础统计学，这可能是你在高中或大学学过的。术语*模型*不是由人工智能、机器学习或任何其他计算机技术的新发展创造的。这个术语起源于统计学。作为一个软件工程师，你习惯于编写一个算法，该算法通常具有输入和输出之间的多对一关系。我们通常将这种关系称为输入与输出之间的*线性关系*——换句话说，输出是*确定的*。

在统计学中，输出不是确定的，而是一个概率分布。让我们考虑一下抛硬币的情况。你无法编写一个算法来输出任何单次抛硬币的正确结果（正面或反面），因为它不是确定的。但你可以*建模*单次、十次或上千次抛硬币的概率分布。

## 12.1 分布类型

统计学领域处理的是非确定性算法，但其结果是概率分布。就像我们的抛硬币例子一样，如果我抛两次硬币，结果不是确定的。相反，一次抛出正面和一次抛出反面的概率是 50%，两次都是正面的概率是 25%，两次都是反面的概率也是 25%。这些算法被称为*模型*，它们模拟一个行为，使得预测在概率分布上的输出（或结果）。

在本节中，我们考察了在机器学习建模中最常用的三种分布：总体分布、抽样分布和子总体分布。我们的目标是了解每种分布如何影响深度学习模型的训练，特别是它的准确性。

使用神经网络开发模型的深度学习出现于人工智能领域。近年来，统计建模和深度学习这两个独立的领域已经融合在一起，我们现在将它们都归类为机器学习。但无论你是在做我所说的经典机器学习（统计学）还是基于神经网络的深度学习，你能够建模或学习到的限制都归结于数据集。

为了查看这三个分布，我们将使用 MNIST 数据集([`keras.io/datasets/`](https://keras.io/datasets/))。这个数据集足够小，我们可以用它来演示这些概念，同时给你留下代码示例，你可以复制并使用这些代码，亲眼看到为什么（以及如何）数据是限制。

### 12.1.1 总体分布

当你构建一个模型，结果发现它没有像你预期的那样在“野外”（在生产环境中）泛化，通常原因之一是你没有理解你所建模的总体分布。

假设你正在构建一个模型，根据身体特征（身高、发色等）预测美国成年男性的鞋码。这个模型的总体分布将是*所有*美国成年男性。让我强调*所有*。当我们说一个*总体分布*时，它包含人口中的每一个例子——整个人口。有了总体分布，我们就知道鞋码的完整分布以及相应的特征（身高、发色等）。

当然，问题是，你不会拥有美国所有成年男性的数据。相反，你将拥有数据的一个子集：我们随机抽取数据的一批（我们称之为*随机样本*）来确定批次内的分布，你希望这个分布尽可能接近整体人口的分布。

图 12.1 展示了在总体分布内的随机抽样。外圈，标记为*总体*，代表总体中的所有例子，例如在我们关于美国所有成年男性鞋码的例子中。内圈，标记为*随机样本*，代表随机选择的一组例子，例如在美国随机选择的一定数量的成年男性。对于总体分布，我们知道诸如确切的大小（成年男性的数量）、平均值（平均鞋码）和标准差（不同尺寸的百分比）等信息。这些在统计学上被称为总体的*参数*，这是一个确定性分布。假设我们没有总体分布，我们希望使用随机样本来估计参数——这被称为*统计量*。样本越大、越随机，我们的估计就越有可能接近参数。

![图片](img/CH12_F01_Ferlitsch.png)

图 12.1 展示了总体分布及其内部的随机抽样

### 12.1.2 抽样分布

使用抽样分布的目标是拥有足够多的来自总体的随机样本，这样，这些样本内部的分布可以共同用来预测整个总体的分布，从而我们可以将模型推广到总体。这里的关键词是*预测*，意味着我们从样本中确定一个概率分布，而不是从总体中确定一个确定性分布。

让我们以我们的鞋码例子为例。如果我们只有一个例子，我们可能无法充分地模拟分布的参数。但如果我们有一千个例子，我们可能能够显著提高模拟参数的能力。但是等等，如果那一千个例子并不是真正随机的——比如说它们是从专业运动鞋店的购买中收集的。这些例子可能会倾向于某些非随机例子的特征（特性）。因此，抽样分布中的例子需要是随机选择的。

图 12.2 描述了一个总体抽样分布。一个*抽样分布*由随机选择的一组例子组成，通常大小相同。例如，我们可能雇佣了不同的调查公司来收集我们的鞋码数据，每个公司使用自己的选择标准。每个公司根据其选择标准收集了一百个随机样本的数据。

![图片](img/CH12_F02_Ferlitsch.png)

图 12.2：预测总体分布参数的抽样分布

我们可以假设这些单独的随机样本是总体参数的弱预测器。相反，我们将它们视为一个整体。例如，如果我们取每个随机样本均值的平均值，给定足够数量和足够大小的随机样本，我们可以更准确地预测总体的均值。

通常，您用于训练模型的数据库是一个抽样分布，样本量越大，例子越随机，您的模型就越有可能推广到群体的参数。

### 12.1.3 子群体分布

您需要理解，无论您的数据集有多大、多么全面，它很可能是一个子群体的抽样分布，而不是整个群体。子群体是群体的一部分，由一组特征定义，并且与群体的概率分布不同。例如，在我们的早期成年男性鞋类例子中，假设我们的样本都来自一家专门为职业运动员销售运动鞋的连锁店。有了足够的样本，我们可以开发出一个具有代表性的抽样分布，因此可以预测职业运动员的子群体，但它不太可能代表整个群体。

这与偏差不同，只要我们的意图是模拟该子群体而不是整个群体。当从随机样本批次中抽取时，会出现偏差，无论我们抽取多少，相应的抽样分布都不会代表我们正在模拟的群体——因为我们是从子群体中抽取的随机样本。图 12.3 展示了子群体分布。

![图片](img/CH12_F03_Ferlitsch.png)

图 12.3 子群体分布

## 12.2 分布外

假设您已经训练了一个模型并将其部署在数据集上，但它并没有像您的评估数据那样在生产中推广。这个模型可能看到了与训练时不同的例子分布。我们称这种情况为“分布外”，也称为“服务偏差”。换句话说，您的模型是在一个与部署模型看到的不同的子群体分布上训练的。

在本节中，我们将使用 MNIST 数据集来演示在模型部署时如何检测分布外的群体。然后我们将探讨改进模型以推广到分布外群体的方法。我们已在第二章中首次讨论了 MNIST 数据集。我们将从对该数据集的简要回顾开始。

### 12.2.1 MNIST 精选数据集

MNIST 是一个包含 70,000 个手写数字图像的数据集，每个数字的比例平衡。训练一个模型以在数据集上达到接近 100%的准确率非常容易（因此它是机器学习的“hello, world”示例）。但几乎所有的“实际应用”中的训练模型都会失败——因为 MNIST 中的图像分布是一个子群体。

MNIST 是一个*精选*的数据集。数据管理员选择了符合一定定义的特征的样本进行包含。换句话说，精选数据集足以代表一个亚群体，可以对该亚群体的参数进行建模，但否则可能不代表整个群体（例如，所有数字）。

在 MNIST 的情况下，每个样本是一个 28-×-28 像素的图像，数字的绘制位于中间。数字是白色的，背景是灰色的，数字周围至少有 4 像素的填充。图 12.4 显示了 MNIST 图像的布局。这个数字 7 的实例只是从数据集中随机选择的任意随机选择，仅用于示例目的。

![](img/CH12_F04_Ferlitsch.png)

图 12.4 MNIST 图像的布局

### 12.2.2 设置环境

首先，让我们做一下我所说的*家务管理*。以下是我们将在所有示例中使用的代码片段。它包括导入 TF.Keras API 以设计和训练模型，我们将使用的各种 Python 库，以及最后，加载预建在 TF.Keras API 中的 MNIST 数据集：

```
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, Activation, ReLU, 
from tensorflow.keras.layers import MaxPooling2D, Conv2D, Dropout

import numpy as np
import random
import cv2

from tensorflow.keras.datasets import mnist                 ❶

(x_train, y_train), (x_test, y_test) = mnist.load_data()    ❶
```

❶ 获取 MNIST 的内置数据集

Keras 的数据集是通用格式，因此我们需要进行一些初始数据准备，以便用于训练 DNN 或 CNN。这些准备包括以下内容：

+   像素数据（`x_train`和`x_test`）包含原始 INT8 值（0 到 255）。我们将像素数据归一化到 0 到 1 的 FLOAT32。

+   图像数据矩阵的形状为*高度* × *宽度* (*H* × *W*)。Keras 期望张量的形状为*高度* × *宽度* × *通道*。这些是灰度图像，因此我们将训练和测试数据调整为(*H* × *W* × 1)。

在准备（我们将在 12.2.3 节中讨论）之前，我们将留出一份数据集的测试和训练数据的副本。

```
x_test_copy  = x_test                                ❶
x_train_copy = x_train                               ❶

x_train = (x_train / 255.0).astype(np.float32)       ❷
x_test  = (x_test  / 255.0).astype(np.float32)       ❷

x_train = x_train.reshape(-1, 28, 28, 1)             ❸
x_test  = x_test.reshape(-1, 28, 28, 1)              ❸

print("x_train", x_train.shape, "x_test", x_test.shape)

print("y_train", y_train.shape, "y_test", y_test.shape)
```

❶ 留出原始训练和测试数据的副本

❷ 将像素数据归一化并转换为 32 位浮点数

❸ 调整形状以符合 TF.Keras 模型 API

### 12.2.3 挑战（在野外）

除了从这个精选数据集中随机选择测试数据（称为*保留集*）之外，我们还将创建另外两个测试数据集，作为展示训练模型在野外可能看到的示例。这两个额外的数据集，称为*反转集*和*筛选集*，将包含训练数据未表示的示例。换句话说，原始 MNIST 数据集是数字群体中的一个亚群体，而我们这两个新的数据集是数字的不同亚群体。反转集和筛选集的分布与 MNIST 数据集不同，因此我们称它们相对于 MNIST 数据集为*分布外*。

我们将使用这两个额外的测试数据集来展示模型将如何失败，并找到我们可能修改训练和数据集以克服这些局限性的方法。每个集合由什么构成？

+   *倒置集*——像素数据被倒置，使得图像现在是在白色背景上的灰色数字。

+   *平移集*——图像向右平移了 4 个像素，因此不再居中。由于至少有 4 个像素的填充，没有任何数字会被裁剪。

图 12.5 是从原始测试数据、倒置测试数据和平移测试数据中选取的单个测试图像的示例。

![](img/CH12_F05_Ferlitsch.png)

图 12.5 原始和野外分布外的示例

在此代码中，我们从原始测试数据集的副本中创建了两个额外的测试数据集：

```
x_test_invert = np.invert(x_test_copy)                        ❶
x_test_invert = (x_test_invert / 255.0).astype(np.float32)    ❶

x_test_shift = np.roll(x_test_copy, 4)                        ❷
x_test_shift = (x_test_shift / 255.0).astype(np.float32)      ❷

x_test_invert = x_test_invert.reshape(-1, 28, 28, 1)
x_test_shift  = x_test_shift.reshape(-1, 28, 28, 1)
```

❶ “野外”倒置数据

❷ “野外”平移数据

### 12.2.4 作为 DNN 进行训练

我们将首先基于现有的 MNIST 子集训练一个模型，将准确率与来自同一子集的保留集进行比较，最后测试并比较它们与野外分布数据。

MNIST 非常简单，我们可以用 DNN 构建一个 97%+准确率的分类器。下一个代码示例是一个构建简单 DNN 的函数，包括以下内容：

+   参数`nodes`是一个列表，指定每层的节点数。

+   DNN 的输入是形状为 28 × 28 × 1 的图像

+   输入被展平成一个长度为 784 的 1D 向量。

+   每个层后都有一个可选的 dropout（用于正则化）。

+   最后一个有 10 个节点的密集层，带有 softmax 激活函数，是分类器。

![](img/CH12_F06_Ferlitsch.png)

图 12.6 MNIST 模型的可配置 DNN 架构

图 12.6 展示了本例中可配置的 DNN 架构。

```
def DNN(nodes, dropout=False):                                             ❶
  model = Sequential()
  model.add(Flatten(input_shape=(28, 28, 1)))
  for n_nodes in nodes:
    model.add(Dense(n_nodes))
    model.add(ReLU())
    if dropout:
      model.add(Dropout(0.5))
      dropout /= 2.0
  model.add(Dense(10))
  model.add(Activation('softmax'))

  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])                                      ❷
  model.summary()
  return model
```

❶ 构建简单 DNN 的函数

❷ 编译多类分类器的 DNN

在我们的第一次测试中，我们将数据集在一个包含 512 个节点的单层（不包括输出层）上进行训练。图 12.7 展示了相应的架构。

![](img/CH12_F07_Ferlitsch.png)

图 12.7 我们第一个 MNIST 模型的单层、512 节点 DNN

下面是构建、训练和评估我们第一次测试模型的代码：

```
model = DNN([512])
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True,
          verbose=2)                                                 ❶
score = model.evaluate(x_test, y_test, verbose=1)                    ❷
print("test", score)
```

❶ 在 MNIST 上训练模型

❷ 评估训练好的模型

`summary()`方法的输出将如下所示：

```
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               401920    
_________________________________________________________________
re_lu_1 (ReLU)               (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 407,050
```

可训练参数的数量是我们模型复杂度的衡量标准，共有 408,000 个参数。我们总共训练了 10 个 epoch（我们将整个训练数据通过模型输入 10 次）。以下是从训练中得到的输出。训练准确率迅速达到 99%+，我们在测试（保留）数据上的准确率接近 98%。

```
Epoch 1/10
2019-02-08 12:14:59.065963: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
 - 5s - loss: 0.2007 - acc: 0.9409
Epoch 2/10
 - 5s - loss: 0.0897 - acc: 0.9743
Epoch 3/10
 - 5s - loss: 0.0651 - acc: 0.9817
Epoch 4/10
 - 5s - loss: 0.0517 - acc: 0.9853
Epoch 5/10
 - 5s - loss: 0.0419 - acc: 0.9887
Epoch 6/10
 - 5s - loss: 0.0341 - acc: 0.9913
Epoch 7/10
 - 5s - loss: 0.0273 - acc: 0.9928
Epoch 8/10
 - 5s - loss: 0.0236 - acc: 0.9939
Epoch 9/10
 - 5s - loss: 0.0188 - acc: 0.9953
Epoch 10/10
 - 5s - loss: 0.0163 - acc: 0.9961
10000/10000 [==============================] - 0s 21us/step

test [0.11250439590732676, 0.9791]
```

到目前为止，看起来不错。现在让我们尝试在倒置和平移的测试数据集上使用模型：

```
score = model.evaluate(x_test_invert, y_test, verbose=1)     ❶
print("inverted", score)
score = model.evaluate(x_test_shift, y_test, verbose=1)      ❷
print("shifted", score)
```

❶ 在野外分布的倒置数据集上评估模型

❷ 在野外分布的平移数据集上评估模型

以下是从测试中得到的输出。我们在倒置数据集上的准确率仅为 2%，在平移数据集上表现较好，但只有 41%：

```
inverted [15.660332287597656, 0.0206]
shifted [7.46930496673584, 0.4107]
```

发生了什么？对于反转数据集，看起来我们的模型将灰色背景和数字的纯度作为数字识别的一部分来学习。因此，当我们反转数据时，模型完全无法对其进行分类。

对于移动数据集，密集层没有保留像素之间的空间关系。每个像素都是独特的特征。因此，即使像素的微小移动也足以大幅降低准确率。

因此，为了提高准确率，我们可能尝试增加输入层的节点数量——节点越多，学习效果越好。让我们用 1024 个节点重复相同的测试。图 12.8 展示了相应的架构。

![图片](img/CH12_F08_Ferlitsch.png)

图 12.8 为我们的第二个 MNIST 模型训练的更宽的单层 1024 节点深度神经网络

下面是构建、训练和评估第二个测试模型的代码：

```
model = DNN([1024])                   ❶
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True, 
verbose=2)
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 节点数量加倍（变宽）。

`model.summary()`的输出如下：

```
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_2 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1024)              803840    
_________________________________________________________________
re_lu_2 (ReLU)               (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_2 (Activation)    (None, 10)                0         
=================================================================
Total params: 814,090
Trainable params: 814,090
```

你可以看到，通过将输入层的节点数量加倍，我们也将计算复杂度（可训练参数的数量）加倍。让我们看看这能否提高我们替代测试数据的准确率。

没有，我们在反转数据集上看到了微小的提升，大约 5%，但这太低了，可能只是噪声，而在移动数据集上的准确率大约相同，为 40%。所以增加输入层的节点数量（变宽）并没有帮助过滤掉（未学习）数字的背景和纯度，也没有学习空间关系：

```
inverted [15.157325344848633, 0.0489]
shifted [7.736222146606445, 0.4038]
```

另一种我们可能尝试的方法是增加层数（变深）。这次，让我们使用两个 512 节点的层。图 12.9 展示了我们的模型架构。

![图片](img/CH12_F09_Ferlitsch.png)

图 12.9 为我们的第三个 MNIST 模型训练的更深的两层深度神经网络（512 + 512 个节点）

下面是构建、训练和评估第三个测试模型的代码：

```
model = DNN([512, 512])                                              ❶
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True, 
verbose=2)
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 增加层数（变深）

`model.summary()`的输出结果：

```
Total params: 669,706
Trainable params: 669,706
```

让我们看看这能否提高我们替代测试数据的准确率：

```
inverted [14.464950880432129, 0.1025]
shifted [8.786513813018798, 0.3887]
```

我们在移动数据集上看到了另一个轻微的提升，达到 10%。但这真的有所改善吗？我们有 10 个类别（数字）。如果我们随机猜测，我们会有 10%的时间猜对。这仍然是一个纯粹随机的结果——这里没有学习到任何东西。看起来增加层并没有帮助学习空间关系。

另一种方法可能是添加一些正则化，以防止模型过度拟合训练数据并使其更具泛化能力。我们将使用每层 512 节点的相同两层深度神经网络，并在第一层后添加 50%的 dropout，在第二层后添加 25%的 dropout。过去，在第一层使用更高的 dropout（学习粗糙特征）和在后续层使用较小的 dropout（学习更精细的特征）是一种常见的做法。图 12.10 显示了模型架构。

![图片](img/CH12_F10_Ferlitsch.png)

图 12.10 添加 dropout 以改善泛化的 DNN

下面是构建、训练和评估我们第四次测试模型的代码：

```
model = DNN([512, 512], True)         ❶
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True,
          verbose=2)
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 添加 dropout 进行正则化

让我们看看这能否提高我们备用测试数据上的准确率：

```
inverted [15.862942279052735, 0.0144]
shifted [8.341207506561279, 0.3965]
```

没有改进。因此，加宽层、加深层和正则化并没有帮助模型在分布外的测试数据集中识别数字。也许问题在于 DNN 根本不是泛化到分布外模型的正确模型架构。接下来，我们将尝试 CNN 并看看会发生什么。

### 12.2.5 作为 CNN 的训练

好的，现在让我们在一个卷积神经网络中测试三个数据集的准确率。有了卷积层，我们至少应该学会空间关系。也许卷积层会过滤掉背景以及数字的白色。

以下代码按照以下方式构建我们的 CNN：

+   参数`filters`是一个列表，指定每个卷积的过滤器数量。

+   CNN 的输入是形状为 28 × 28 × 1 的图像。

+   每次卷积后，最大池化将特征图大小减少 75%。

+   每个卷积/最大池化层之后发生 25%的 dropout（正则化）。

+   最后一个具有 10 个节点和 softmax 激活函数的密集层是分类器。

```
def CNN(filters):                                                           ❶
  model = Sequential()
  first = True
  for n_filters in filters:
    if first:
      model.add(Conv2D(n_filters, (3, 3), strides=1, input_shape=(28, 28, 1)))
    else:
      model.add(Conv2D(n_filters, (3, 3), strides=1))
    model.add(ReLU())
    model.add(MaxPooling2D((2, 2), strides=2))
    model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(10))
  model.add(Activation('softmax'))

  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])                                       ❷
  model.summary()
  return model
```

❶ 构建简单 CNN 的函数

❷ 编译 CNN 以进行多类分类器

让我们从具有单个 16 个过滤器的卷积层的 CNN 开始。图 12.11 说明了模型架构。

![](img/CH12_F11_Ferlitsch.png)

图 12.11 用于 MNIST 训练的单层 CNN

下面是我们使用 CNN 进行第一次测试的构建、训练和评估模型的代码：

```
model = CNN([16])                                                    ❶
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True,
           verbose=2)
score = model.evaluate(x_test, y_test, verbose=1)  
print("test", score)
```

❶ 构建具有 16 个过滤器的 CNN

`model.summary()`的输出如下：

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       
_________________________________________________________________
re_lu_1 (ReLU)               (None, 26, 26, 16)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 13, 13, 16)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 13, 13, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2704)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                27050     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 27,210
Trainable params: 27,210
```

下面是我们 CNN 训练的结果：

```
test [0.05741905354047194, 0.9809]
```

您可以看到，我们可以使用具有许多更少的可训练参数的 CNN（27,000 个参数与超过 400,000 个参数相比）在测试数据上获得相当准确的准确率（98%）。

让我们看看这能否提高我们备用测试数据上的准确率：

```
inverted [2.1893138484954835, 0.5302]
shifted [2.231996842956543, 0.5682]
```

是的，这确实产生了可测量的差异。我们从之前倒置数据集上的 10%准确率提高到 50%准确率。因此，卷积层似乎有助于过滤（而不是学习）数字的背景或白色。

但准确率仍然太低。对于偏移数据集，我们将其提高到 57%。这仍然低于我们的目标，但我们也可以看到，现在卷积层正在学习空间关系。那么，我们在这里学到了什么呢？嗯，如果你有一个错误的模型架构，无论你如何加深或加宽模型，或者添加多少正则化，模型都不会泛化到分布外的测试数据。我们还了解到，CNN 不仅泛化得更好，而且在参数方面也更为高效，在我们的第一次测试中，我们只使用了茎而没有学习组件。

如果一个卷积层能改善事情，那么让我们看看使用两个卷积层我们能做得更好。我们将使用两层：第一层有 16 个过滤器，第二层有 32 个过滤器。随着 CNN 逐渐加深，加倍过滤器数量是一种常见的做法。图 12.12 展示了我们的模型架构。

![](img/CH12_F12_Ferlitsch.png)

图 12.12 深度两层 CNN 用于 MNIST 训练

这里是构建、训练和评估我们第二次测试中 CNN 模型的代码：

```
model = CNN([16, 32])                                               ❶
model.fit(x_train, y_train, epochs=10, batch_size=32, shuffle=True, 
verbose=2)
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 构建一个两层 CNN

这是我们的 CNN 训练结果：

```
test [0.03628469691830687, 0.9882]
```

再次，我们在测试数据上获得了相当准确的精度，略有提升，达到约 99%。让我们看看添加卷积层是否能够提高我们在替代测试数据上的精度：

```
inverted [1.2761547603607177, 0.6332]
shifted [0.6951200264453888, 0.7679]
```

我们确实看到了一些渐进的改进。我们的反转数据集上升到 63%。因此，它正在学习更好地过滤掉数字的背景和白色，但仍然没有达到目标。我们的平移数据集测试跃升至 76%。所以你可以看到卷积层是如何学习数字的空间关系与图像中的位置（与 DNN 相比）。

### 12.2.6 图像增强

最后，让我们使用图像增强来尝试改进对分布外替代测试数据的泛化。回想一下，*图像增强*是一个通过在现有样本上进行小修改来生成新样本的过程。这些修改不会改变图像的分类，而且图像仍然会被人类眼睛识别为那个类别。

图 12.13 展示了图像增强的一个示例，其中一张猫的图片被随机旋转，然后裁剪并调整大小回到原始形状。这张图片仍然可以被人类眼睛识别为猫。

![](img/CH12_F13_Ferlitsch.png)

图 12.13 使用随机选择的平移生成的图像增强示例管道

除了向训练集中添加更多样本外，某些类型的增强可以帮助模型泛化，以便准确分类测试（保留）数据集之外的图像，否则模型可能会在这些图像上失败。

正如我们在 CNN 中看到的，我们在平移图像上仍然缺乏足够的精度；因此，我们的模型还没有完全学会将数字的空间关系从图像中的位置和背景中分离出来。我们可以添加更多过滤器并增加卷积层，以尝试提高平移图像上的精度。这将使模型更复杂，训练时间更长，并且在部署进行预测（推理）时会有更大的内存占用和更长的延迟。

或者，我们将通过使用图像增强来随机左右移动图像最多 20%来改进模型。由于我们的图像宽度为 28 像素，20%意味着图像在任一方向上最多移动 6 像素。我们有一个最小 4 像素的边界，因此数字的裁剪将很少或没有。

我们将使用 TF.Keras 中的`ImageDataGenerator`类来进行图像增强。在下面的代码示例中，我们执行以下操作：

+   创建与之前相同的 CNN 模型。

+   实例化一个`ImageDataGenerator`生成器对象，其参数`width_shift_range=0.2`将在训练期间通过随机左右移动图像+/- 20%来增强数据集。

+   调用`fit_generator()`方法，使用我们的图像增强生成器和现有的训练数据来训练模型。

+   在生成器中指定`steps_per_epoch`的数值为训练样本数除以批大小；否则，生成器将在第一个 epoch 上无限循环：

```
from tensorflow.keras.preprocessing.image import ImageDataGenerator

model = CNN([16, 32])
datagen = ImageDataGenerator(width_shift_range=0.2)                  ❶
model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch= 60000 // 32 , epochs=10)        ❷
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 实例化随机左右移动图像 +/- 20%的生成器

❷ 使用图像增强训练模型

下面是我们对 CNN 训练的结果：

```
test [0.046405045648082156, 0.986]
```

让我们看看这能否提高分布外测试数据的准确率：

```
inverted [4.463096208190918, 0.2338]
shifted [0.06386796866590157, 0.9796]
```

哇，现在我们在移动数据上的准确率接近 98%。所以我们能够训练模型学习数字在图像中移动时的空间关系，而不会增加模型的复杂性。但在倒置数据上我们还没有看到任何改进。

现在我们来训练模型，以过滤掉数字的背景和白色，以提高模型泛化到分布外倒置测试数据的能力。在下面的代码中，我们像测试数据那样取了 10%的训练数据(`x_train_copy[0:6000]`)并对其进行倒置。为什么是 10%而不是全部训练数据？当我们想要训练一个模型来过滤掉某些东西时，我们通常可以用整个训练数据分布的 10%来完成。

接下来，我们将原始训练数据与额外的倒置训练数据合并，将两个训练集连接在一起——包括`x_train`（数据）和`y_train`（标签——在我们的训练集中总共 66,000 张图像（与 60,000 张相比）：

```
x_train_invert = np.invert(x_train_copy[0:6000])                        ❶
x_train_invert = (x_train_invert / 255.0).astype(np.float32)            ❶
x_train_invert = x_train_invert.reshape(-1, 28, 28, 1)                  ❶

y_train_invert = x_train[0:6000]                                        ❷

x_combine = np.append(x_train, x_train_invert, axis=0)                  ❸
y_combine = np.append(y_train, y_train_invert, axis=0)                  ❸

model = CNN([16, 32])
datagen = ImageDataGenerator(width_shift_range=0.2)
datagen.fit(x_train_combine)
model.fit_generator( datagen.flow(x_combine, y_combine, batch_size=32), 
                     steps_per_epoch= 66000 // 32 , epochs=10)          ❹
score = model.evaluate(x_test, y_test, verbose=1)
print("test", score)
```

❶ 从（副本）训练数据中选择 10%并对其进行倒置

❷ 选择相同的 10%的对应标签

❸ 将两个训练数据集合并成一个训练集

❹ 使用合并的训练数据集训练模型

下面是我们对 CNN 训练的结果：

```
test [0.04763028650498018, 0.9847]
```

让我们看看这能否提高我们备用测试数据的准确率：

```
inverted [0.13941174189522862, 0.9589]
shifted [0.06449916120804847, 0.979]
```

哇，我们在倒置图像上的测试准确率接近 96%。

### 12.2.7 最终测试

作为最后的测试，我从谷歌图片搜索中随机选择了一些手写单个数字的“野外”图像。这些图像包括用彩色绘制的、用圆珠笔绘制的、用画笔绘制的以及由小孩子用蜡笔绘制的图像。在我完成测试后，我使用本章训练的 CNN 只得到了 40%的准确率。

为什么只有 40%，我们该如何诊断原因？问题应该是模型学习了哪个子群体分布？模型是否学会了独立于背景对比的数字轮廓的泛化，还是它只是学会了数字要么是白色要么是黑色？如果我们用黑色数字在灰色背景上（而不是白色）进行测试会发生什么？

MNIST 的训练和测试数据是用笔或铅笔绘制的数字，所以线条很细。我的一些“野外”图像线条较粗，是用圆珠笔、画笔或蜡笔绘制的。模型是否学会了泛化线条的粗细？关于纹理呢？用蜡笔和颜料绘制的数字有粗糙的纹理；这些纹理差异是否作为边缘在卷积层中被学习？

作为最后的例子，假设你开发了一个用于在工厂中检测零件缺陷的模型。相机位于一个固定的位置，其视角覆盖着一个有凹槽的灰色输送带。一切正常，直到有一天，所有者用一条光滑的黄色输送带来替换它，以给工厂增添一些色彩，现在缺陷检测模型失败了。发生了什么？好吧，因为灰色输送带在所有训练图像中，它就会成为潜在空间中学习特征的一部分，在进入任务学习器（分类器）之前。这类似于经典的狗与狼的案例，其中所有的狼照片都是在冬天拍摄的。在这个经典案例中，当训练模型被给了一张背景有雪的狗的照片（分布外）时，模型预测的是*狼*。在这种情况下，模型只是学会了*雪*意味着*狼*。

## 摘要

+   样本分布模型了一个群体分布的参数。

+   子群体分布模型了一个偏差，这是群体分布的一个子部分。

+   如果你在一个子群体分布上进行训练，并且你的模型在生产中对它看到的例子没有泛化，那么生产数据很可能超出了你训练的子群体分布。这也被称为服务偏差。

+   添加更深或更宽的层以及/或更多的正则化通常不会帮助泛化到分布外的群体。

+   从图像增强中生成训练样本有时可以帮助泛化到分布外的群体。

+   当图像增强不足以泛化时，你需要添加来自分布外子群体的训练示例。
