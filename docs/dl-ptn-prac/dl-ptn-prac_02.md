# 1 设计现代机器学习

本章涵盖

+   从经典人工智能发展到尖端方法

+   将设计模式应用于深度学习

+   介绍用于建模神经网络的程序重用设计模式

深度学习的最新革命是在宏观层面而不是微观层面，通过在谷歌云人工智能工作期间我提出的**模型融合**方法。在这种方法中，模型被分解成可组合的单元，这些单元共享和适应组件以使用相同初始数据实现不同的目标。组件以各种连接模式相互连接，其中每个组件通过设计*学习*模型之间的通信接口，而不需要后端应用程序。

此外，模型融合可用于训练物联网（IoT）设备进行数据丰富，将物联网传感器从静态转变为动态学习设备——一种称为**模型融合**的技术。融合正在提供将人工智能投入生产并在规模和操作复杂性方面实现 2017 年难以想象的方法，当时将人工智能投入生产的推动力刚开始出现。

例如，考虑一下在租赁市场的各个方面（如定价、物业状况和设施）上视觉房地产数据的操作复杂性。使用模型融合方法，您可以创建一个连接单个模型组件的视觉分析管道，每个组件处理这些方面的一个。最终，您将拥有一个系统，可以自动*学习*确定条件、设施和一般市场吸引力以及相应的适当租金定价。

模型融合方法鼓励工程师将模型视为可以适应以创建单个组件的设计模式或模板。因此，如果你希望使用这种方法，你需要了解其他工程师为解决与你将遇到的类似问题而开发的键模型和系统的设计。

本书的目标是通过向您介绍开创性深度学习模型的设计模式以及将这些组件组合在一起以开发、训练、部署和服务的更大深度学习系统的设计或系统架构，帮助您深入理解。即使您从未与大型企业融合合作，熟练掌握这些模型和架构的底层设计也将提高您创建的任何深度学习系统的工程水平。

## 1.1 适应性重点

由于本书针对的是不太经验的深度学习工程师和数据科学家，第一部分从基本深度神经网络（DNNs）、卷积神经网络（CNNs）和残差神经网络（ResNets）的设计开始。第一部分还探讨了简单训练管道的架构。关于这些网络和架构的整本书都是写的，所以在这里你将更多地回顾它们是如何工作的，重点是设计模式和原则。这里的目的是概述基本深度学习组件的设计，这些组件将适合第二部分中你将看到的所有模型。

话虽如此，如果你对基础知识了如指掌，你可以直接跳到第二部分，这部分将探讨深度学习发展中的关键模型。我的方法是提供每个模型设计的足够信息，以便你可以对它们进行实验，并提出解决你可能会遇到的 AI 挑战的方案。这些模型大致按照时间顺序介绍，因此第二部分也充当了深度学习历史的一部分，重点在于从一种模型到另一种模型的演变。

现在，如果企业生产正在向模型开发自动学习转变，你可能会质疑检查这些手动设计、以前的前沿（SOTA）模型的价值。然而，许多这些模型继续作为标准模型使用，尤其是在迁移学习方面。其他一些模型从未进入生产，但它们负责的发现至今仍在使用。

模型开发用于生产仍然是一系列自动和手工设计的学习的组合——这对于专有需求或优势往往至关重要。但手工设计并不意味着从头开始；通常，你会从一个标准模型开始，进行微调和调整。为了有效地做到这一点，你需要知道模型是如何工作的以及为什么它会以这种方式工作，其设计背后的概念，以及你将从其他 SOTA 模型中学到的替代构建块的优缺点。

书的最后一部分深入探讨了用于生产的训练和部署的设计模式。虽然并非所有读者都会部署我关注的那些企业级系统，但我认为这些信息对所有读者都相关。熟悉许多类型和规模的系统，这些系统针对各种问题，可以帮助你在需要跳出思维定势解决问题时有所帮助。你对底层概念和设计的了解越多，你变得越有能力且适应性越强。

这种适应性可能是这本书最有价值的收获。生产涉及大量的移动部件，并且不断有“猴子 wrench”被扔进混合物中。如果工程师或数据科学家只是机械地记住框架中可重复的步骤集合，他们将如何处理他们遇到的多样化任务，以及解决扔向他们的“猴子 wrench”呢？雇主寻找的不仅仅是技能和经验；他们想知道你的技术适应性如何。

想象一下自己在面试中：你在技能和工作经验上得分很高，并且在股票机器学习（ML）编码挑战中表现出色。然后面试官给你一个意外或不同寻常的问题，一个“猴子 wrench”。他们这样做是为了观察你如何思考挑战，你应用了哪些概念以及背后的推理，你如何评估各种解决方案的优缺点，以及你的调试能力。这就是适应性。这正是我希望深度学习开发者和数据科学家从这本书中获得的东西。

### 1.1.1 计算机视觉引领潮流

我主要在计算机视觉的背景下教授所有这些概念，因为设计模式最初是在计算机视觉中演化的。但它们也适用于自然语言处理（NLP）、结构化数据、信号处理和其他领域。如果我们把时钟拨回到 2012 年之前，所有领域的机器学习（ML）主要使用基于经典统计的方法。

诸如斯坦福大学的 Fei-Fei Liu 和加拿大多伦多大学的 Geoffrey Hinton 等学术研究人员开始率先将神经网络应用于计算机视觉。Liu 及其学生编制了一个计算机视觉数据集，现在被称为 ImageNet，以推进计算机视觉的研究。ImageNet，连同 PASCAL 数据集，成为 2010 年年度 ImageNet 大规模视觉识别挑战（ILSVRC）竞赛的基础。早期参赛者使用了传统的图像识别/信号处理方法。

然后，在 2012 年，多伦多大学的 Alex Krizhevsky 提交了一个使用卷积层的深度学习模型，AlexNet。这个模型赢得了 ILSVRC 竞赛，并且领先优势明显。与 Hinton 和 Ilya Sutskever 共同设计的 AlexNet 模型开启了深度学习。在他们相应的论文《使用深度卷积神经网络的 ImageNet 分类》（[`mng.bz/1ApV`](http://mng.bz/1ApV)）中，他们展示了如何设计神经网络。

在 2013 年，纽约大学的 Matthew Zeiler 和 Rob Fergus 通过微调 AlexNet 成为他们所说的 ZFNet 赢得了比赛。这种基于彼此成功的模式持续发展。牛津大学的视觉几何组在此基础上扩展了 AlexNet 的设计原则，并在 2014 年的比赛中获胜。2015 年，微软研究院的 Kaiming He 等人进一步扩展了 AlexNet/VGG 的设计原则，并引入了新的设计模式，赢得了比赛。他们的模型 ResNet 以及他们的“用于图像识别的深度残差学习”论文([`arxiv.org/abs/1512.03385`](https://arxiv.org/abs/1512.03385))，引发了探索 CNN 设计空间的热潮。

### 1.1.2 超越计算机视觉：自然语言处理（NLP）、自然语言理解（NLU）、结构化数据

在这些早期使用深度学习为计算机视觉开发设计原则和设计模式的年份里，自然语言理解（NLU）和结构化数据模型的发展落后，并继续专注于经典方法。他们使用了经典的机器学习框架，如自然语言工具包（NLTK）用于文本输入，以及基于决策树的经典算法，如随机森林，用于结构化数据输入。

在自然语言理解（NLU）领域，随着循环神经网络（RNNs）、长短期记忆（LSTM）和门控循环单元（GRU）层的引入，取得了进展。2017 年，随着自然语言中的 Transformer 设计模式的引入以及 Ashish Vaswani 等人撰写的相应论文“Attention Is All You Need”([`arxiv.org/abs/1706.03762`](https://arxiv.org/abs/1706.03762))，这一进展实现了飞跃。谷歌大脑，作为谷歌 AI 内部的一个深度学习研究组织，在 ResNet 中早期采用了类似的注意力机制。同样，随着结构化数据设计模式的引入，例如 2016 年由 Google Research 的技术无关研究小组 Heng-Tze Cheng 等人概述的“Wide & Deep Learning for Recommender Systems”([`arxiv.org/abs/1606.07792`](https://arxiv.org/abs/1606.07792))，设计模式的发展也随之演进。

当我专注于计算机视觉，以教授设计模式的发展和当前状态时，我会适当提及自然语言理解（NLU）和结构化数据方面的相应进展。本书中的许多概念适用于多个领域和数据类型。例如，第二章到第四章涵盖了通用基础，而第三部分除了第一章外，所有章节都涵盖了与模型和数据类型无关的概念。

在有意义的章节中，主要在第二部分，我引入了来自计算机视觉之外的例子。例如，在第五章，我比较了具有身份链接的残差块在 NLU 中与注意力在 Transformer 中的发展。在第六章，我们将探讨宽 CNN 如何与结构化数据的宽度和深度模型以及 TabNet 的发展相关。第九章解释了自编码器在 NLU 中与嵌入的比较，第十一章讨论了迁移学习步骤如何与 NLU 和结构化数据相媲美。

通过从计算机视觉、自然语言处理和结构化数据中分享的例子进行泛化，你应该能够将概念、方法和技术应用到你的领域中的问题。

## 1.2 机器学习方法的演变

要理解现代方法，我们首先必须了解我们在人工智能和机器学习方面的现状，以及我们是如何到达这个阶段的。本节介绍了在当今生产环境中工作的几个顶级方法和设计模式，包括智能自动化、机器设计、模型融合和模型合并。

### 1.2.1 经典人工智能与窄人工智能

让我们简要地介绍一下经典人工智能和当今现代窄人工智能之间的区别。在*经典人工智能*（也称为*语义人工智能*）中，模型被设计为基于规则的系统。这些系统被用来解决无法用数学方程式解决的问题。相反，系统被设置成模仿一个主题或领域专家。图 1.1 展示了这种方法的一个视觉表示。

![图片](img/CH01_F01_Ferlitsch.png)

图 1.1 在经典人工智能方法中，领域专家设计规则来模仿他们的知识。

经典人工智能在低维输入空间（例如，具有少量不同输入）中表现良好；输入空间可以被分成离散的段，如类别或箱；并且离散空间与输出之间保持强烈的线性关系。领域专家设计了一套基于输入和状态转换的规则，以模仿他们的专业知识。然后程序员将这些规则转换成一个基于规则的系统，通常是“如果*A*和*B*为真，则*C*为真”的形式。

这种系统非常适合像预测葡萄酒的质量和适宜性这样的问题，这只需要一小套规则。例如，对于葡萄酒选择器，输入可能包括餐点是午餐还是晚餐、主菜、场合以及是否包含甜点。但经典人工智能无法扩展到更大的问题；准确性会大幅下降，规则需要不断细化以试图避免下降。设计规则的领域专家之间的不一致性是导致不准确性的另一个问题。

在*窄人工智能*（也称为*统计人工智能*）中，模型在大量数据上得到训练，减轻了对领域专家的需求。相反，模型使用统计原理来学习输入数据分布中的模式，也称为*抽样分布*。这些模式可以以高精度应用于训练中未见的样本。当使用由大量代表更大人群或*总体分布*的数据组成的抽样分布进行训练时，我们可以建模没有经典人工智能带来的约束的问题。换句话说，窄人工智能可以在输入空间具有显著更高维度（意味着大量不同的输入）以及可以混合离散和连续输入的情况下工作得非常好。

让我们通过将两者都应用于预测房屋售价来对比基于规则的窄人工智能。基于规则的系统通常只能考虑少量输入；例如，地块大小、平方英尺、卧室数量、浴室数量和财产税。这样的系统可以预测类似房屋的中位价格，但不能预测任何单个房屋的价格，因为财产与价格之间的关系是非线性的。

让我们退一步，讨论线性关系和非线性关系之间的区别。在*线性关系*中，一个变量的值可以预测另一个变量的值。例如，假设我们有一个函数*y* = *f*(*x*)，我们将其定义为 2 × *x*。对于任何值*x*，我们可以以 100%的置信度预测*y*的值。在*非线性关系*中，只能通过任何值*x*的概率分布来预测*y*的值。

使用我们的住房示例，我们可以说*y* = *f*(*x*)作为*售价* = *sqft* × *每平方英尺价格*。现实情况是，许多其他变量会影响*每平方英尺价格*，并且这些变量如何影响价格存在一些不确定性。换句话说，房屋的平方英尺与售价之间存在非线性关系，它本身只能预测售价的概率分布。

在窄人工智能中，我们显著增加了输入的数量以学习非线性，例如添加房屋建造年份、升级许可发放时间、建筑类型、屋顶和侧面的材料、学区信息、就业机会、平均收入、社区以及犯罪率、公园、公共交通和高速公路的邻近程度。这些额外的变量有助于模型以高置信度学习概率分布。值来自固定集合的输入，如建筑架构，是*离散的*，而来自无界范围的输入，如平均收入，是*连续的*。

窄 AI 模型通过学习分割输入的边界来处理具有高非线性输出（预测）的输入，如果这些分割与输出有强烈的线性关系。这些类型的模型基于统计学，需要大量数据，因此被称为*窄 AI*，因为它们擅长解决一个领域内有限范围的任务的狭窄问题。窄模型在泛化到广泛范围的问题上并不擅长。图 1.2 说明了窄 AI 的方法。

![](img/CH01_F02_Ferlitsch.png)

图 1.2 在窄 AI 中，模型通过在大数据集上训练，这些数据集代表了更广泛的群体，来学习成为领域专家。

另一种区分经典 AI 和窄 AI 的方法是观察这两种模型在误差率降低方面的差异，因为深度学习不断推动向贝叶斯理论误差极限迈进。贝叶斯将这个理论误差极限描述为一种进步，如图 1.3 所示。

![](img/CH01_F03_Ferlitsch.png)

图 1.3 机器学习向贝叶斯理论误差极限迈进。

首先，一个普通非专家解决任务的误差率会是什么？然后，一个专家解决任务的误差率会是什么（这类似于语义 AI）？一群专家解决任务的误差率会是什么？最后，理论极限：无限多个专家解决任务的误差率会是什么？

在大量计算机视觉和 NLP 任务中，深度学习已经达到了一群专家的误差率，远远超过了传统的软件应用和专家系统。到 2020 年，研究人员和企业机器学习工程师开始追求处于贝叶斯理论误差极限范围内的生产系统。

### 1.2.2 计算机学习的下一步

现在我们已经了解了我们是如何到达这里的，我们确切地在哪里？随着计算机学习的改变，我们首先从人工智能转向智能自动化。然后我们进入了机器设计、模型融合和模型合并。让我们定义这些现代进步。

智能自动化

正如我们刚才看到的，早期的人工智能意味着经典 AI，这主要是基于规则的，需要领域专家。这使我们能够基本上编写软件程序来开始自动化通常手工完成的任务。然后，在窄 AI 中，我们将统计学应用于学习，消除了对领域专家的需求。

下一个主要进步是*智能自动化*（*IA*）。在这种方法中，模型学习自动化过程的（近）最优方式，其性能和准确性超过了手动或计算机自动化的对应物。

通常，IA 系统作为一个管道流程工作。累积信息、转换和状态转换是管道中各个点的模型输入。每个模型的输出或预测被用来执行下一个信息转换和/或决定下一个状态转换。通常，每个模型都是独立训练和部署的，通常作为一个微服务，后端应用程序驱动整个管道流程。

IA 的一个例子是从来自不同来源和格式的患者医疗记录中自动提取患者信息，包括模型从未训练过的来源。我在 2018 年从事了医疗保健领域这类系统的架构设计工作。如今，许多现成的提供商使这些系统可用；Google Cloud Healthcare API ([`cloud.google.com/healthcare`](https://cloud.google.com/healthcare))就是其中之一。

到 2019 年，AI 正在大量企业规模的公司中进入全面生产。在整个一年中，我会与谷歌最大的客户进行越来越多的会议。我们现在用商业术语来谈论 AI。这些技术概念已经演变成了商业概念。

在这些会议中，我们不再使用*AI*，而是用*IA*来揭示这个过程。我们让客户描述他们想要应用 AI 的过程中的每个步骤（手动和计算机辅助）。假设一个步骤的成本是 100,000 美元。过去，我们的倾向是直接跳到那个步骤并应用 AI——“大回报”。但假设另一个步骤的成本只是几分钱，但每天发生一百万次——那就是每天 10,000 美元，或每年 3,650,000 美元。假设我们可以用每年运营成本为 40,000 美元的模型来替代这个低垂的果实。没有人会留下 3,610,000 美元。

这就是智能自动化。程序员不再编写预设计的算法来自动化，而是引导模型智能地学习最优算法。图 1.4 展示了我们将如何将智能自动化应用于索赔处理流程的单一步骤。

![图片](img/CH01_F04_Ferlitsch.png)

图 1.4 智能自动化应用于索赔处理

让我们对这个管道中发生的事情进行一个高级回顾。在第 1 步，与索赔相关的文件被扫描并摄入到 IA 管道中。在第 2 步，以前文档操作员随后查看每个扫描的文档并标记的做法被一个为这个索赔处理任务训练的自然语言分类模型所取代。

这种替代有几个优点。首先，消除了人工成本。除了计算机比人类速度快之外，这个过程可以分布，以便可以并行处理大量文档。

第二，正确标记文档类别的错误率与人类错误率相比大幅降低。让我们考虑一下原因。每个操作员可能具有不同的训练水平和经验，以及广泛的准确性差异。此外，人类疲劳也会导致错误率上升。但假设我们有一千名经过培训的人类操作员查看相同的文档，并且我们使用多数投票法来决定如何标记文档。我们预计错误率将大幅降低，接近于零。

模型就是这样做的：它已经在大量由大量经过培训的人类操作员标记的文档上进行了训练。通过这种方式，一旦训练完成，模型的性能就等同于一群经过培训的人类操作员的集体性能。

在手动版本的步骤 3 中，专家人工操作员会检查标记以进一步减少错误。这一步骤在 IA 流程中并未被消除——但由于步骤 2 中错误的大幅减少，人工操作员的工作量显著减少。

IA 流程下游继续降低/消除人工操作员成本，并进一步降低错误率。一旦到达最后一步，经过培训的主题专家（SME）将对支付授权（或非授权）进行最终审查。现在，由于 SME 审查的信息准确性更高，人类主观决策更加可靠，进一步降低了错误主观决策的成本。

我们在行业中已经停止使用*机器学习*这个术语，并用*机器设计*来代替它，以便与计算机辅助设计（CAD）进行类比。我们将 CAD 应用于那些即使设计一个次优解也太复杂的工程问题。这些系统具有建筑组件、数学知识和专家系统规则，而 SMEs 则指导 CAD 系统找到良好的次优解。

在机器设计中，系统学习的是建筑组件、数学知识和规则，而机器学习工程师则指导机器设计以找到最优解。通过转向机器设计，我们释放了高价值的人力资源去解决下一阶段的挑战性问题，加速他们的技术进步，并为业务带来更高的投资回报率（ROI）。

机器设计

在深度学习之前，SMEs 设计软件程序来搜索软件和硬件中具有高复杂性的部分中的良好解决方案。通常，这些程序是搜索优化和基于规则技术的组合。

在下一个发展阶段，*机器设计*，模型学习了一种（近似）最优的方式来设计和集成软件和硬件组件。这些系统在性能、准确性和复杂性方面都超越了由具有 CAD 程序辅助的小型企业专家（SME）设计的模型。人类设计师利用他们的现实世界专业知识来引导模型搜索解决方案的空间。

考虑一个有两个 X 射线部门的医院；一个部门有一台昂贵的 X 射线机，另一个部门有一台低成本 X 射线机。一位检查医生根据患者患有肺炎的可能性选择将患者送往哪个部门进行肺炎诊断确认。如果肺炎的可能性低，或者不太可能，医生会根据医院政策和降低保险提供商成本的愿望，将患者送往低成本 X 射线机。如果确定的可能性高，或者很可能，患者应得到昂贵的 X 射线。这是一个机器设计影响超参数和架构搜索空间，并指导从不同分布（在这种情况下是 X 射线机）自动学习医学图像的系统管道的例子。

请记住，如果使用两个 X 射线设备产生的累积 X 射线和诊断确定数据来训练一个模型，我们会有数据偏差。模型不是从数据中学习，而是可能无意中学习了两个医疗设备的独特特征——*视角偏差*。模型中视角偏差的经典例子是确定狗与狼的情况，模型无意中学习了狼的雪，因为所有狼的训练图片都是在冬天拍摄的。

在机器设计中，除了训练模型外，系统还学习了对抗性模型（称为*代理*）的最佳训练管道。如果您想深入了解，请参阅“一种用于从胸部 X 光片中稳健分类肺炎的对抗性方法”（[`arxiv.org/pdf/2001.04051.pdf`](https://arxiv.org/pdf/2001.04051.pdf)），这是一篇关于这个问题的基础机器设计论文。

模型融合

*模型融合*是开发更精确、成本更低的预测维护和故障检测系统（例如在物联网传感器系统中使用的系统）的下一项进步。传统上，非常昂贵的设备和基础设施，如工厂机器、飞机和地区电力基础设施，都内置了物联网传感器。这些连续的感官数据将被输送到由专家设计的基于规则的算法中。

这些传统系统的问题在于它们容易受到高环境变化的影响，这影响了它们的可靠性。例如，在电力行业中，输电线路在每个塔上都有传感器，用于监控塔之间的线路阻抗异常。由于风对线路连接的压力、温度变化影响导电性以及次要因素（如水分积累）的影响，阻抗可能会波动。

模型融合通过使用具有更高操作成本的机器学习模型生成标签数据来转换专家设计的系统，从而提高了物联网系统的可靠性。继续我们的例子，电力行业今天使用无人机和计算机视觉训练的深度学习模型定期检查输电线路。这个过程非常准确，但操作成本更高。因此，它被用来为低成本传感器系统创建的阻抗传感器数据生成标签数据。在较高操作成本下生成的标签数据随后被用来训练另一个模型，该模型使用阻抗传感器（低成本系统）来实现可比的可靠性。

模型融合

在深度学习之前，应用程序要么是运行在后端服务器上的单体应用程序，要么是服务器上的核心骨干，该服务器使用分布式微服务。在*模型融合*中，模型（们）本质上成为整个应用程序，直接共享模型组件和输出，并在模型之间学习通信接口。所有这些都不需要庞大的后端应用程序或微服务。

想象一下房地产行业的模型管道，它使用房屋和公寓大楼的照片进行视觉分析，以确定租金定价。一组模型中的模型是串联在一起的，每个模型都针对特定的特征进行训练；一起，它们自动确定租赁条件、租赁设施和市场吸引力，并得出相应的定价。

让我们比较一下更传统的 IA，其中流程管道中的每一步都是一个单独部署的模型实例，输入可以是原始图像、转换和状态，所有这些都由专家设计的基于规则的后端应用程序控制。相比之下，在融合中，模型实例直接相互通信。每个模型都学会了执行其专业任务的最佳方法（例如，确定条件）；学会了模型之间的最佳通信路径和表示（房屋、房间和设施模型）；以及学会了确定状态变化（财产条件）的最佳方法。

在 2021 年，我预计在企业层面，生产将转向模型融合。我们仍在努力弄清楚如何使其运作。在融合之前，多个模型会被部署执行不同的任务，开发者会构建一个后端应用程序，该程序执行表示状态转移（REST）或微服务调用。我们仍然编写了应用程序的逻辑，以及应用程序和模型之间的接口和数据通信。图 1.5 是我在 2019 年底为体育广播设计的模型融合的一个示例。

![图片](img/CH01_F05_Ferlitsch.png)

图 1.5 应用到体育广播的模型融合

让我们逐步了解这个过程。首先，合并处理实时视频；也就是说，合并处理正在实时连续处理视频。视频被实时解析为一系列时间序列的帧。每一帧都是比赛的图像，例如一个准备击球的棒球运动员。每一帧首先由一组共享的卷积层（共享卷积层）进行处理，生成跨下游任务的通用内部编码。换句话说，每个下游任务（模型）不是从相同的输入图像开始并处理成内部编码，而是输入图像只编码一次，编码在下游重复使用。这加快了模型的响应速度，并缩小了其在内存中的大小。

接下来，生成的通用编码通过一个对象检测模型，该模型已经针对通用编码进行训练，而不是输入图像，从而减少了检测对象的大小并提高了速度。比如说，对象检测被训练以识别包括人物、球员装备、体育场和场地在内的对象。对于它在画面中识别的每个对象，它将输出一个对象级别的嵌入，这是一个低维度的表示（例如，缩小尺寸的编码）以及在上游输入帧内的空间坐标。

这些对象级别的嵌入现在成为另一组下游任务的输入。接下来，你会看到被分类为人物的嵌入被传递到一个已经针对嵌入与原始图像进行训练的面部识别模型。例如，该模型可能被训练以识别球员、官员、裁判、教练和安全人员，并相应地标记嵌入。然后，特定于球员的对象嵌入被传递到一个姿态估计模型，该模型找到人体关键点并分类识别的人物的姿态，例如球员 *A* 处于击球位置。

接下来，对象级别的嵌入（球员、齿轮、体育场等）与特定于球员的姿态结合成一个信息丰富的密集嵌入。所有这些丰富的信息都传递给另一个模型来预测球员的动作，例如球员 *A* 正在准备击球。这个预测动作随后传递给另一个模型，将动作转换为叠加在直播上的字幕文本。

假设体育赛事正在全球范围内播出，被各种语言的观众观看。图像字幕模型的输出（例如，英语）被传递给另一个模型，该模型执行针对每个市场的特定语言翻译。在每个市场中，翻译的文本被转换为语音进行实时解说。

正如你所见，模型已经从单一任务的预测和独立部署，发展到执行多项任务、共享模型组件并集成形成解决方案的模型，例如在医疗文档处理和体育广播的例子中。另一种描述这些集成模型解决方案的方式是作为*serving pipeline*（服务管道）。管道由连接的组件组成；一个组件的输出是另一个组件的输入，每个组件都是可配置的、可替换的，并且具有版本控制和历史记录。在今天的生产机器学习中，使用管道的范围涵盖了整个端到端流程。

## 1.3 设计模式的益处

在 2017 年之前，所有领域的神经网络模型的实现大多数都是用批处理脚本风格编写的。随着人工智能研究人员和经验丰富的软件工程师越来越多地参与研究和设计，我们开始看到模型编码的转变，这反映了软件工程原则的重用和设计模式。

*设计模式*意味着存在一种最佳实践，用于构建和编码一个可以在广泛情况下重用的模型，例如图像分类、目标检测和跟踪、人脸识别、图像分割、超分辨率和图像数据的风格迁移；文本数据的文档分类、情感分析、实体提取和摘要；以及非结构化数据的分类、回归和预测。

深度学习设计模式的发展导致了模型融合、模型融合和机器设计——其中模型组件可以被重用和适应。这些模型组件的设计模式允许研究人员和其他深度学习实践者逐步开发模型组件和应用的最佳实践，适用于所有模型和数据类型。这种知识共享加速了设计模式的发展，并促进了模型组件的重用，使得深度学习能够广泛应用于生产应用。

我在这本书中介绍的历史上最先进的模型中，许多都揭示了被纳入今天现代生产中的知识和概念。尽管许多这些模型最终停止使用，但理解其背后的知识、概念和构建块组件对于理解和实践今天的深度学习至关重要。

神经网络模型最早的设计模式之一是*过程重用*，它同时被应用于计算机视觉、NLU 和结构化数据。与软件应用一样，我们设计过程重用模型作为反映数据流和将组件分解为可重用函数的组件。

使用过程重用设计模式有许多好处——并且现在仍然如此。首先，它简化了在架构图中表示模型的任务。在正式设计模式的使用之前，每个研究团队都在其发表的论文中发明了自己的方法来表示其模型架构。设计模式还定义了如何表示模型结构和流程。拥有一致和精细的方法简化了架构图的表示。其次，模型架构对其他研究人员和机器学习工程师来说更容易理解。此外，从标准模式开始工作揭示了设计的内部运作，这反过来使得模型更容易修改，也更容易进行故障排除和调试。

在 2016 年，研究论文开始提出组件流——通常被称为*茎*，（表征性）*学习器*和（转换性）*任务*。在 2016 年之前，研究论文将它们的模型作为单一架构提出。这些单一架构使得研究人员难以证明新概念改善了模型中的任何一部分。因为这些组件包含重复的流程模式，最终出现了可配置组件的概念。这些重复的流程模式随后被其他研究人员在他们的模型架构设计中重用和改进。尽管在 NLU 和结构化数据中模型组件的应用落后，但到 2017 年，我们开始看到它们在研究论文中的出现。今天，无论模型类型和领域如何，你都会看到模型设计由相同的三种主要模型组件组成。

将模型分解为组件的早期设计模式是 SqueezeNet ([`arxiv.org/pdf/1602.07360.pdf`](https://arxiv.org/pdf/1602.07360.pdf))，它使用了基于元参数的可配置组件。元参数的引入，描述了如何配置模型组件，有助于正式化如何表示、设计和实现可配置组件。基于可配置组件设计模型为研究人员提供了在尝试各种组件配置的同时，按组件衡量性能改进的手段。这种设计方法在开发应用软件时是标准做法；其众多好处之一是它促进了代码重用。

用于重用的过程模式是第一个，也是最基本的可重用设计，因此它们是本书的重点。后来，我们所说的工厂模式和抽象工厂模式被引入来进行机器设计。*工厂设计模式*使用 SOTA（最先进的技术）构建块作为工厂，并寻找与需求匹配的最佳设计。*抽象工厂模式*进一步抽象，寻找最佳的工厂，然后使用该工厂来寻找最佳模型。

但在这本书中，你将学习基石设计，从第一部分的基本 DNN 和 CNN 架构开始，过渡到第二部分为程序重用编码的原始模型，最后在第三部分完成对现代生产管道的巡礼。

## 摘要

+   深度学习从经典 AI 发展到窄 AI，这导致了使用 AI 来解决具有高维输入的问题。

+   深度学习已经从实验模型发展到数据、训练、部署和服务的可重用和可配置管道方法。

+   在企业规模的尖端，机器学习从业者正在使用模型融合、模型融合和机器设计。

+   程序重用设计模式是构建块，也是通往今天企业规模尖端领先地位的过渡。
