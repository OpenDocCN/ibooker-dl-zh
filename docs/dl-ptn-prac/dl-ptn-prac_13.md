# 10 超参数调整

本章涵盖

+   在预热训练之前初始化模型中的权重

+   手动和自动进行超参数搜索

+   为训练模型构建学习率调度器

+   在训练过程中正则化模型

超参数调整是寻找训练超参数最优设置的过程，以便我们*最小化训练时间*和*最大化测试准确率*。通常，这两个目标无法完全优化。如果我们最小化训练时间，我们可能无法达到最佳准确率。同样，如果我们最大化测试准确率，我们可能需要更长时间进行训练。

*调整*是找到满足你目标的最优超参数设置组合。例如，如果你的目标是尽可能高的准确率，你可能不会关心最小化训练时间。在另一种情况下，如果你只需要良好的（但不是最好的）准确率，并且你持续进行重新训练，你可能希望找到在最小化训练时间的同时获得这种良好准确率的设置。

通常，一个目标没有特定的设置。更有可能的是，在搜索空间内，各种设置组合都能实现你的目标。你需要找到其中之一——这就是调整的目的。

现在，我们调整的超参数有哪些？我们将在本章中详细探讨这些内容，但基本上它们是指导模型训练以最大化实现目标的参数。本章我们将调整的参数，例如，包括批量大小、学习率和学习率调度器。

在本章中，我们将探讨几种常用的超参数搜索（调整）技术。图 10.1 展示了传统生产环境中整体超参数过程的概览。目前不必担心细节，我们将一步步进行讲解。

![图片](img/CH10_F01_Ferlitsch.png)

图 10.1 传统生产训练环境中的超参数过程

我将简要地浏览这个图表，以便你了解本章余下部分我们将遵循的过程。第一步是选择模型权重最佳初始化，我们将花些时间了解为什么这个选择可以显著影响训练结果。我们将从基于研究和进展的预定分布开始，进而探讨选择分布中抽取的一种替代方法：彩票原则。

接下来，在权重初始化后，我们转向预热预训练。这个过程从数值上稳定了权重，这将增加在训练时间和模型准确率方面获得更优结果的可能性。

一旦权重数值稳定，我们将探讨搜索和调整超参数的技术。

在我们初始化良好且数值稳定的权重和超参数调整完毕后，我们进入实际训练阶段，首先采用一些技术来进一步提高获得更优结果的可能性。其中一种我们将在此使用的技术是在训练的后期部分调整学习率。这可以显著提高收敛到全局或近似最优解的机会。换句话说，这些技术增加了在较低总体经济成本下产生更精确模型的概率。

我们将通过介绍在训练过程中权重更新时实施的常见正则化技术来结束本章。正则化有助于减少记忆（过拟合），同时增加模型在生产部署时对示例的泛化能力。我们将讨论生产中最常用的两种技术：权重衰减（也称为*核正则化*或*层正则化*）和标签平滑。

## 10.1 权重初始化

当我们从零开始训练一个模型时，我们需要给权重一个初始值。这个过程称为*初始化*。为了简单起见，我们可以先设置所有权重为相同的值——比如说，0 或 1。然而，这样做是不行的，因为反向传播中梯度下降的工作方式意味着每个权重都会进行相同的更新。

那个神经网络将是对称的，相当于一个单独的节点。一个单独的节点只能做出单一的二元决策，并且只能解决具有线性分离的问题，如逻辑与或或。逻辑异或问题不能通过单个节点解决，因为它需要一个非线性分离。早期感知器模型无法解决异或问题，这归因于从 1984 年到 2012 年人工智能研究减少和资金减少，这被称为*人工智能冬天*。

因此，我们需要将模型中的权重设置为随机值分布。理想情况下，分布范围应较小（在-1 和 1 之间），且以 0 为中心。在过去几年中，为了初始化权重，已经使用了几个随机分布的范围。为什么权重应该在一个小的分布范围内？好吧，如果我们的范围很大，较大的初始化权重将主导模型更新中的较小权重，导致稀疏性、准确性降低，并可能无法收敛。

### 10.1.1 权重分布

让我们先澄清权重初始化和权重分布之间的区别。*权重初始化*是在训练模型之前为权重设置的初始值，是起点。*权重分布*是我们选择那些初始权重的来源。

三种权重分布已被证明是最受研究人员欢迎的。**均匀分布**在整个范围内均匀分布。这不再使用。**Xavier**，或**Glorot**分布，是对均匀分布的改进，是一种以零为中心的随机正态分布。其标准差设置为以下公式，其中*fan_in*是层的输入数量：

sqrt(1 / *fan_in*)

这是在早期 SOTA 模型中流行的一种方法，最适合激活函数为 tanh（双曲正切）时使用。现在很少使用。

最后，我们有**He-normal 分布**，它是对 Xavier 分布的改进。如今，几乎所有权重初始化都是使用 He-normal 分布进行的；它是当前的主流分布，最适合 ReLU 激活函数。这种随机分布是以零为中心的正态分布，其标准差设置为以下公式，其中*fan_in*是层的输入数量：

sqrt(2 / *fan_in*)

现在我们来看看如何实现这一点。在 TF.Keras 中，默认情况下，权重初始化为 Xavier 分布（称为`glorot_uniform`）。要将权重初始化为 He-normal 分布，必须显式设置关键字参数`kernel_initializer`为`he_normal`。以下是实现方式：

```
x = Conv2D(16, (3, 3), strides=1, padding='same', activation='relu',
           kernel_initializer='he_normal')(inputs)                      ❶

outputs = Dense(10, activation='softmax',
                    kernel_initializer='he_normal')(x)                  ❶
```

❶ 将权重初始化为 He-normal 分布

### 10.1.2 彩票假设

一旦研究人员就用于初始化神经网络的权重分布达成共识，下一个问题是，从分布中抽取的最佳方法是什么？我们将从讨论彩票假设开始，它引发了一系列从分布中抽取的快速进展，这进而导致了数值稳定性概念（在第 10.1.3 节中介绍）。

2019 年提出了用于权重初始化的**彩票假设**。该假设包含两个假设：

+   从随机分布中抽取的两个值不会相等。对于权重初始化的随机分布抽取中，有些抽取结果比其他抽取结果更好。

+   大型模型具有高精度，因为它们实际上是一系列小型模型的集合。每个模型从随机分布中抽取不同的值，其中一个抽取值是“中奖彩票”。

随后尝试从训练的大型模型中识别和提取具有“中奖彩票”的子模型到一个紧凑模型，但从未成功。因此，由 Jonathan Frankle 和 Michael Carbin 在“彩票假设”（[`arxiv.org/abs/1803.03635`](https://arxiv.org/abs/1803.03635)）中提出的方法现在不再使用，但后续研究导致了其他变体。在本节中，我们将探讨其中一种常用的变体。

然而，关于“中奖彩票”的问题尚未解决。另一群机器学习实践者使用预训练多个模型实例的方法，每个实例都有单独的抽取。通常，当使用这种方法时，我们使用非常小的学习率（例如，0.0001）运行少量 epoch。对于每个 epoch，步数远少于训练数据的大小。通过这样做，我们可以在短时间内预训练大量实例。一旦完成，选择具有最佳目标指标（如训练损失）的模型实例。假设这种抽取的中奖彩票比其他抽取更好。

图 10.2 通过使用彩票假设方法展示了预训练模型实例。创建了多个参考模型架构的副本以进行训练，每个副本从随机分布中抽取不同的样本。然后，每个实例使用相同的小学习率进行少量 epoch/减少的步数进行预训练。如果计算资源可用，预训练是分布式的。一旦完成，检查每个预训练模型的训练损失。具有最低训练损失的实例是具有最佳抽取的实例——即中奖彩票。

![图片](img/CH10_F02_Ferlitsch.png)

图 10.2 使用彩票假设方法进行预训练

我们可以使用以下代码实现此过程。样本中显示的主要步骤如下：

1.  创建 10 个模型实例，每个实例都有单独的抽取进行权重初始化。我们这样做是为了模拟这样一个原则：没有两个抽取是相同的。在这个例子中，选择 10 只是一个任意数。实例数量越多，每个实例都有单独的抽取，那么其中某个抽取是中奖彩票的可能性就越大。

1.  对每个实例进行少量 epoch 和步数的训练。

1.  选择具有最低训练损失的模型实例（`best`）。

这里是代码：

```
def make_model():
    ''' make an instance of the model '''
    bottom = ResNet50(include_top=False, weights=None, 
                       input_shape=(32, 32, 3))
    model = Sequential()
    model.add(bottom)
    model.add(Flatten())
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=Adam(0.0001),
                  metrics=['acc'])
    return model

lottery = []                            ❶
for _ in range(10):
    lottery.append(make_model())

from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = (x_train / 255.0).astype(np.float32)

best = (None, 99999)                    ❷
datagen = ImageDataGenerator()
for model in lottery:

    result = model.fit(datagen.flow(x_train, y_train, batch_size=32),
                       epochs=3, 
                       steps_per_epoch=100)
    print(result.history['loss'][2])
    loss = result.history['loss'][2]
    if loss < best[1]:
        best = (model, loss)
```

❶ 创建 10 个模型实例，每个实例都有单独的抽取进行初始化

❷ 预训练并选择具有最低训练损失的实例

接下来，我们看看另一种权重初始化的方法，即使用预热来对权重进行数值稳定性。

### 10.1.3 预热（数值稳定性）

与彩票假设方法在权重初始化方面采取不同方法的*数值稳定性方法*，是目前在完整训练之前初始化权重的流行技术。在彩票假设中，大模型被视为子模型的集合，其中一个子模型拥有中奖彩票。在数值稳定性方法中，大模型被分为上层（底部）和下层（顶部）。

虽然我们之前讨论了*底部*与*顶部*的区别，但这种术语可能对一些读者来说仍然显得有些倒退——对我来说确实如此。在神经网络中，输入层是底部，输出层是顶部。输入从模型的底部馈入，预测从顶部输出。

假设较低（顶部）层在训练期间为较高（底部）层提供数值稳定性。或者更具体地说，较低层为较高层提供数值稳定性，以便它们可以*学习*获胜的彩票（初始化抽签）。图 10.3 描述了此过程。

![](img/CH10_F03_Ferlitsch.png)

图 10.3 预训练以实现底层数值稳定性，以便高层学习获胜的彩票初始化

此方法通常在模型完整训练之前作为一个预热训练周期来实现。对于预热训练，我们从一个非常小的学习率开始，以避免引起权重的大幅波动，并使权重向获胜彩票移动。预热学习率的典型初始值在 1e-5 到 1e-4 的范围内。

我们对模型进行少量周期（通常是四到五个）的训练，并在每个周期后逐步提高学习率到为训练所选的初始学习率。

图 10.4 说明了预热训练方法，如图 10.1 中的步骤 1、2 和 3 所示。与彩票假设不同，我们从一个参考模型的单个实例开始训练。从非常低的学习率开始，其中权重通过微小的调整，模型以完整周期进行训练。每次学习率逐渐与完整训练的初始学习率成比例。达到最终周期后，模型实例中的权重被认为是数值稳定的。

![](img/CH10_F04_Ferlitsch.png)

图 10.4 预热预训练以实现数值稳定性

在下面的代码示例中，你可以看到实现了以下五个关键步骤：

1.  实例化一个模型的单个权重初始化实例。

1.  定义学习率调度器`warmup_scheduler()`，在每个周期后提高学习率。第 10.3 节详细介绍了学习率调度器。

1.  将预热调度器作为`fit()`方法的回调。

1.  训练少量周期（例如，四个）。

```
def make_model(w_lr):
    ''' make an instance of the model '''
    bottom = ResNet50(include_top=False, weights=None, 
                       input_shape=(32, 32, 3))
    model = Sequential()
    model.add(bottom)
    model.add(Flatten())
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy', 
                   optimizer=Adam(w_lr),
                  metrics=['acc'])
    return model

w_lr = 0.0001                                                     ❶
i_lr = 0.001  
w_epochs = 4  
w_step   = (i_lr - w_lr) / w_epochs 

model = make_model(w_lr)                                          ❷

def warmup_scheduler(epoch, lr):
    """ learning rate scheduler for warmup training
        epoch : current epoch iteration
        lr    : current learning rate
    """
    if epoch == 0:
        return lr
    return lr + w_step                                          ❸

from tensorflow.keras.callbacks import LearningRateScheduler    ❹
lrate = LearningRateScheduler(warmup_scheduler, verbose=1)

from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = (x_train / 255.0).astype(np.float32)

result = model.fit(x_train, y_train, batch_size=32, epochs=4, 
                    validation_split=0.1,  
                   verbose=1, callbacks=[lrate])
```

❶ 设置预热学习率和学习率步长

❷ 创建模型并设置初始学习率为预热率

❸ 从预热率逐步增加到完整训练的初始学习率

❹ 创建回调到学习率调度器

现在我们已经介绍了预训练，让我们来看看超参数搜索背后的基础。然后我们将把在这里学到的所有内容付诸实践，并对模型进行完整训练。

## 10.2 超参数搜索基础

一旦你的模型权重初始化具有数值稳定性（无论是由抽签还是预热），我们进行**超参数搜索**，也称为**超参数调整**或**超参数优化**。

记住，超参数搜索的目的是找到（近似）最佳超参数设置，以最大化您模型针对目标（例如，训练速度或评估准确性）的训练。而且，正如我们之前讨论的，我们区分模型配置的参数，称为*元参数*，以及训练的参数，称为*超参数*。在本节中，我们只关注调整超参数。

通常，在训练预配置模型时，我们尝试调整的超参数如下：

+   学习率

+   批量大小

+   学习率调度器

+   正则化

注意：不要在权重未进行数值稳定的模型上进行超参数搜索。如果没有权重的数值稳定，实践者可能会无意中丢弃性能较差的组合，而这些组合可能原本是好的组合。

让我们从视觉开始。图 10.5 展示了搜索空间。黑色区域代表产生最佳结果的超参数组合。搜索空间中可能存在多个最佳组合区域；在这种情况下，我们有三个黑色点。通常，在每个最佳区域附近都有一个较大的近似最佳结果区域，用灰色表示。搜索空间的大部分，用白色空间表示，产生非最佳（和非近似）的结果。

![图片](img/CH10_F05_Ferlitsch.png)

图 10.5 超参数搜索空间

如您所见，白色区域相对于黑色区域的数量，如果您随机挑选一些超参数组合，您不太可能找到一个最佳或近似最佳结果。因此，您需要一个策略。一个好的策略是具有高概率落在近似最佳区域（s）的策略；处于近似最佳区域内可以缩小搜索空间，以找到附近的最佳区域。

### 10.2.1 超参数搜索的手动方法

在我们进入自动化搜索之前，让我们先通过一个手动方法来了解一下。我在训练计算机视觉模型方面有很多经验，并且在选择超参数方面有很强的直觉。我能够利用这种学到的直觉来进行手动引导的搜索。我通常遵循以下这四个初始步骤：

1.  粗调初始学习率。

1.  调整批量率。

1.  精调初始学习率。

1.  调整学习率调度器。

粗调初始学习率

我首先使用固定的批量大小和固定的学习率。如果是一个小数据集，通常少于 50,000 个示例，我使用 32 个批量大小；否则，我使用 256 个。我选择一个学习率的中心点——通常为 0.001。然后我在中心点（例如，0.001）及其一个数量级更大（例如，0.01）和更小（0.0001）的位置进行实验。我查看三个运行之间的验证损失和准确性，并决定哪个方向会导致更好的收敛。

如果我有一个具有最低验证损失和最高验证准确率的运行，我将选择那个。有时一个运行上的较低验证损失不会导致更高的准确率。在这些情况下，我更多地依赖直觉，但倾向于倾向于基于最低验证损失做出决定。

然后，我在现有和更好的收敛点之间选择一个新的中心点。例如，如果中心和收敛点是 0.001 和 0.01，我选择 0.005 作为中心，并使用一个数量级更大（0.05）和更小（0.0005），然后重复实验。我重复这种分而治之的策略，直到中心点给我最佳的收敛，这成为粗调的初始学习率。我很有可能接近最优区域（灰色）。

调整批量大小

接下来，我调整批量大小。一般来说，对于小型数据集使用 32，对于大型数据集使用 256 代表最低水平。所以我将尝试更高的值。我使用 2 倍因子。例如，如果我的批量大小是 32，我将尝试使用粗略学习率的 64。如果收敛性有所改善，我将尝试 128，依此类推。当它没有改善时，我选择之前的好值。

微调初始学习率

在这一点上，我很有可能已经接近了最优区域（黑色）。批量大小越大，每批损失的变化就越小。因此，如果我们增加了批量大小，我们通常可以提高学习率。

考虑到较大的批量大小，我重复进行了学习率的调整实验，以粗略学习率作为初始中心点。

学习率调度

在这一点上，我开始一个完整的训练运行，当验证准确率停止提高时进行早期停止。我通常首先尝试在学习率上使用余弦退火（随后讨论）。如果那有显著的改进，我通常就停在那里。否则，我会回顾最初的完整运行，并找到验证准确率平顶或发散的时期。然后我设置一个学习率调度器，在该点之前的一个时期将学习率降低一个数量级。

这通常给我一个非常好的起点，我现在可以专注于其他预训练步骤，如增强和标签平滑（在第 10.4 节中讨论）。

### 10.2.2 网格搜索

*网格* *搜索* 是超参数搜索的最古老形式。这意味着你在狭窄的搜索空间中搜索每一个可能的组合；这是对于新问题获得洞察力的固有的人类方法。这种方法只有少数参数和值时才是实用的。例如，如果我们有三个学习率值和两个批量大小，组合的数量将是 3 × 2 或 6，这是实用的。让我们稍微增加一下，增加到五个学习率值和三个批量大小。现在就是 5 × 3 或 15。哇，看看组合是如何快速增长的！

由于与整个搜索空间相比，（近）最优区域要小得多，我们不太可能早期就找到一个好的组合。

这种方法不再使用，因为它计算开销大。以下是一个网格搜索的示例实现。我在这里提出它，以便你可以在下一小节中将它与随机搜索进行比较。

在这个例子中，我们在两个超参数上进行网格搜索：学习率（`lr`）和批量大小（`bs`）。对于两者，我们指定要尝试的值集，例如学习率指定为`[0.1, 0.01]`。然后我们使用两个嵌套循环迭代器生成学习率和批量大小值集的所有组合。对于每个组合，我们获取模型预训练实例的副本（`get_model()`）并对其进行几个 epoch 的训练。保持最佳验证分数及其对应的超参数组合的运行总计（`best`）。完成后，`best`元组包含导致最低验证损失的超参数设置。

```
best = (None, 0, 0, 0)
epochs = 5

for lr in [0.1, 0.01]:                                     ❶
    for bs in [32, 64]:
        model = get_model(lr)                              ❷

        result = model.fit(x_train, y_train, batch_size=bs, epochs=epochs,
                           validation_split=0.1)           ❸

        val_acc = result.history['val_acc'][epochs-1]      ❹
        if val_acc > best[1]:
            best = (model, val_acc, lr, bs)
```

❶ 对三个学习率和两个批量大小进行网格搜索

❷ 在编译模型时设置学习率

❸ 训练几个 epoch

❹ 使用验证准确率来选择最佳的学习率和批量大小组合

### 10.2.3 随机搜索

让我们转向随机搜索方法，这种方法在寻找好的超参数方面比网格搜索计算成本更低。你可能会问，随机搜索怎么可能比网格搜索计算成本更低（它只是随机的）？

为了回答这个问题，让我们回顾一下我们之前对超参数搜索空间的描述。我们知道其中只有一小部分有最优组合，所以我们随机找到它的概率非常低。但我们还知道，大量更大的区域是近最优的，所以我们使用随机搜索落在这些区域之一的概率大大提高。

一旦搜索找到一个近最优组合，我们就知道在附近很可能存在一个最优组合。在这个时候，我们将随机搜索缩小到围绕近最优组合的区域。如果新的组合提高了结果，我们可能会进一步缩小围绕新组合附近的随机搜索。

总结这些步骤：

1.  设置搜索空间的边界。

1.  在整个搜索空间内进行随机搜索。

1.  一旦找到一个近最优组合，将搜索空间缩小到新组合的附近。

1.  持续重复，直到找到一个满足你的目标标准的组合。

    +   如果新的组合提高了结果，进一步缩小围绕新组合的搜索空间。

    +   如果在预定义的试验次数后结果没有改善，则返回到搜索整个搜索空间（步骤 2）。

图 10.6 说明了前三个步骤。

![](img/CH10_F06_Ferlitsch.png)

图 10.6 超参数随机搜索

这里是前三个步骤的一个示例实现。在这段代码中，我们做了以下操作：

1.  在整个搜索空间上运行五个`试验`。因为这个例子只有少数几种组合，通常五个试验就足够了。

1.  选择一个随机组合的学习率（`lr`）和批量大小（`bs`）。

1.  在模型的一个预训练实例上进行短时间训练。

1.  维护最佳验证准确率和超参数组合（`best`）的累计记录。

1.  从五个试验中选择最佳验证准确率作为接近最优的。

1.  在接近最优的超参数（2*X* 和 1/2X ）周围设置一个狭窄的搜索空间。

1.  在狭窄的搜索空间内再运行五个试验。

```
from random import randint

learning_rates = [0.1, 0.01, 0.001, 0.0001]                            ❶
batch_sizes = [ 32, 128, 512]                                          ❶

trials = 5  
epochs = 3  

best = (None, 0, 0, 0)

for _ in range(trials):                                                ❷
    lr = learning_rates[randint(0, 3)]                                 ❸
    bs = batch_sizes[randint(0, 2)]                                    ❸
    model = get_model(lr)
    result = model.fit(x_train, y_train, epochs=epochs, batch_size=bs,  
                       validation_split=0.1, verbose=0)                ❹

    val_acc = result.history['val_acc'][epochs-1]                      ❺
    if val_acc > best[1]:                                              ❺
        best = (model, val_acc, lr, bs)                                ❺

learning_rates = [ best[2] / 2, best[2] * 2]                           ❻
batch_sizes = [best[3] // 2, int(best[3] * 2)]
for _ in range(trials):                                                ❼
    lr = learning_rates[randint(0, 1)]
    bs = batch_sizes[randint(0, 1)]
    model = get_model(lr)
    result = model.fit(x_train, y_train, epochs=epochs, batch_size=bs,  
                       validation_split=0.1, verbose=0)

    val_acc = result.history['val_acc'][epochs-1]
    if val_acc > best[1]:
        best = (model, val_acc, lr, bs)
```

❶ 如果我们进行网格搜索，我们将有 4 × 3 = 12 种组合。

❷ 步骤 1：第一轮试验，找到最佳接近最优组合

❸ 步骤 2：选择随机组合

❹ 步骤 3：为试验进行短时间训练

❺ 步骤 4 和 5：记录当前最佳结果

❻ 步骤 6：将搜索空间缩小到最佳接近最优的附近

❼ 步骤 7：在缩小后的搜索空间周围运行另一组试验

我在没有数值稳定化的情况下运行了这段代码，使用了 CIFAR-10 数据集。在完整搜索空间的前五个试验之后，最佳验证准确率为 0.352。在缩小搜索空间后，最佳验证准确率跃升至 0.487，学习率为 0.0002，批量大小为 64。

我然后重复了这个过程，但这次我在进行超参数搜索之前首先对模型进行了数值稳定化。在完整搜索空间的前五个试验之后，最佳验证准确率为 0.569。在缩小搜索空间后，最佳验证准确率跃升至 0.576，学习率为 0.1，批量大小为 512。哇，这真是太好了。而且我们还没有对学习率调度、正则化、增强和标签平滑进行调整！

接下来，我们将讨论如何使用自动超参数搜索工具 KerasTuner，它是一个 TF.Keras 的附加模块。你可能会问，为什么我们要学习手动方法，而不是直接使用自动方法？即使使用自动方法，你也需要引导搜索空间。使用手动方法可以帮助你获得引导搜索空间的专长。对我来说，以及研究人员来说，开发手动方法让我们对未来自动搜索的改进有了洞察。最后，你可能会发现，现成的自动方法并不适合你的专有数据集和模型，你可以通过你独特的学习方法来改进它。

### 10.2.4 KerasTuner

*KerasTuner* 是 TF.Keras 的一个附加模块，用于进行自动化超参数调整。它有两种方法：随机搜索和超参数搜索。为了简洁，本节将介绍随机搜索方法。了解这种方法将使您对在搜索空间稀疏且好的组合较少的情况下搜索超参数的整体方法有所了解。

注意，我建议您参考在线文档（[`keras-team.github.io/keras-tuner/`](https://keras-team.github.io/keras-tuner/)）了解超参数调整，这是一种用于改进随机搜索时间的 bandit 算法方法。您可以在李莎·李等人的“Hyberband”中找到更多信息（[`arxiv.org/abs/1603.06560`](https://arxiv.org/abs/1603.06560)）。

像所有自动化工具一样，KerasTuner 既有优点也有缺点。自动化且使用起来相对简单显然是优点。对我来说，无法调整批量大小是一个很大的缺点，因为你最终不得不手动调整批量大小。

这是安装 KerasTuner 的`pip`命令：

```
pip install -U keras-tuner
```

要使用 KerasTuner，我们首先创建一个 tuner 实例。在以下示例中，我们创建了一个`RandomSearch`类的实例。这个实例化需要三个必需的参数：

1.  可调整超参数（`hp`）模型

1.  目标测量（例如，验证准确率）

1.  训练试验的最大数量（实验）

```
from kerastuner.tuners import RandomSearch

tuner = RandomSearch(hp_model,               ❶
                     objective='val_acc',    ❷
                     max_trials=3)           ❸
```

❶ 获取可调整超参数的模型

❷ 用于比较（改进）的训练指标

❸ 训练试验次数

在这个例子中，为了演示目的，我将试验次数设置得较低（3 次）。最多尝试三种随机组合。根据你的搜索空间大小，你通常会使用更大的数字。这是一个权衡。试验次数越多，探索的搜索空间就越大，但所需的计算成本（时间）也越高。

接下来，我们创建一个函数来实例化一个可调整超参数的模型。该函数接受一个参数，表示为`hp`。这是一个由 KerasTuner 传入的超参数控制变量。

在我们的例子中，我们将仅调整学习率。我们首先获取我们模型的一个数值稳定的版本实例，正如我之前推荐的那样。然后，我们使用`compile()`方法中的`optimizer`参数设置实例的学习率。在我们的例子中，我们将使用超参数调整器（`hp`）控制方法`hp.Choice()`指定四个学习率的选择。这告诉调整器要搜索的参数值集合。在这种情况下，我们将选择设置为`[1e-1, 1e-2, 1e-3, 1e-4]`：

```
def hp_model(hp):
    ''' hp is passed in by the tuner '''
    model = tf.keras.models.load_model('numeric')                             ❶

    model.compile(loss='sparse_categorical_crossentropy', metrics=['acc'],    ❷
                  optimizer=Adam(hp.Choice('learning_rate',  
                                           values=[1e-1, 1e-2, 1e-3, 1e-4]))) ❸
    return model
```

❶ 加载已保存（在磁盘上）的模型

❷ 重新编译模型以重置学习率

❸ 将学习率设置为可调整的参数

接下来，我们准备进行超参数调整。我们使用`tuner`的`search()`方法开始搜索。该方法接受与 Keras 模型`fit()`方法相同的参数。注意，在`search()`中明确指定了批大小，因此它不是自动可调的。在我们的例子中，我们的训练数据是 CIFAR-10 训练数据：

```
tuner.search(x_train, y_train, batch_size=32, validation_data=(x_test, y_test))
```

现在是结果！首先，使用`results_summary()`方法查看试验的摘要：

```
tuner.results_summary()
```

这里是输出，它显示 0.1 是最佳学习率：

```
Results summary
|-Results in ./untitled_project
|-Showing 10 best trials
|-Objective(name='val_acc', direction='max')
Trial summary
|-Trial ID: 0963640822565bfc03280657d5350d26
|-Score: 0.4927000105381012
|-Best step: 0
Hyperparameters:
|-learning_rate: 0.0001
Trial summary
|-Trial ID: 9c6ed7a1276c55a921eaf1d3f528d64d
|-Score: 0.28610000014305115
|-Best step: 0
Hyperparameters:
|-learning_rate: 0.01
Trial summary
|-Trial ID: d269858c936c2b6a2941e66f880304c7
|-Score: 0.10599999874830246
|-Best step: 0
Hyperparameters:
|-learning_rate: 0.1      ❶
```

❶ 选定的最佳学习率

然后，你使用`get_best_models()`方法来获取相应的模型。此方法根据参数`num_models`按降序返回最佳模型列表。在这种情况下，我们只想得到最佳的一个，所以我们将它设置为 1。

```
models = tuner.get_best_models(num_models=1)
model = models[0]
```

最后，你的结果和模型存储在一个文件夹中，可以在实例化`tuner`时通过参数`project_name`指定。如果没有指定，文件夹名称默认为`untitled_project`。为了清理试验后的文件夹，你会删除这个文件夹。

## 10.3 学习率调度器

到目前为止，在我们的示例中，我们一直在整个训练过程中保持学习率不变。你可以用恒定的学习率得到好的结果，但它不如在训练过程中调整学习率有效。

通常，在训练过程中，你会从较大的学习率逐渐降低到较小的学习率。最初，你希望尽可能开始使用较大的学习率，而不引起数值不稳定性。较大的学习率允许优化器探索不同的路径（局部最优解），并在最小化损失方面取得一些初始的大幅收益，从而加快训练速度。

但一旦我们朝着良好的局部最优解取得良好进展，如果我们继续使用高学习率，我们可能会开始来回震荡，无法收敛，或者无意中跳出良好的局部最优解，开始向较差的局部最优解收敛。

因此，随着我们接近收敛，我们开始降低学习率，以采取越来越小的步骤，这样就不会震荡，并找到局部最优解中的最佳路径以收敛。

那么，“学习率调度器”这个术语是什么意思呢？这意味着我们将有一个方法来监控训练过程，并根据一定的条件对学习率进行调整，以找到并收敛到最佳或近似的局部最优解。在本节中，我们将介绍几种常见的方法：包括时间衰减、斜坡、常数步长和余弦退火。我们将从描述时间衰减方法开始，这是 TF.Keras 优化器集内置的方法，用于在训练过程中逐步降低学习率。

### 10.3.1 Keras 衰减参数

TF.Keras 优化器支持使用`decay`参数逐步降低学习率。优化器使用时间衰减方法。时间衰减的数学公式如下，其中*lr*是学习率，*k*是衰减系数，*t*是迭代次数（例如，epochs）：

*lr* = *lr* 0 / (1 + *kt*)

在 TF.Keras 中，时间衰减的实现方式如下：

*lr* = *lr* × (1.0 / (1.0 + decay × iterations))

以下是在`compile()`方法中指定优化器时设置学习率时间衰减的示例：

```
model.compile(optimizer=SGD(lr=0.1, decay=1e-3))
```

表 10.1 显示了使用先前设置的前 10 个 epochs 的学习率进度；典型的衰减值在 1e-3 和 1e-6 之间。

表 10.1 学习率随 epoch 的衰减进度

| 迭代（epoch） | 学习率 |
| --- | --- |
| 1 | 0.0999 |
| 2 | 0.0997 |
| 3 | 0.0994 |
| 4 | 0.0990 |
| 5 | 0.0985 |
| 6 | 0.0979 |
| 7 | 0.0972 |
| 8 | 0.0964 |
| 9 | 0.0955 |
| 10 | 0.0945 |

### 10.3.2 Keras 学习率调度器

如果使用时间衰减没有产生最佳结果，你可以使用`LearningRateScheduler`回调函数实现自己的自定义方法来逐步降低学习率。在生产环境中，ML 团队随着时间的推移进行实验并找到自定义调整，使训练更加高效，并在目标上产生更好的结果，例如在生产部署时的分类准确率。

以下代码是一个示例实现，其步骤在此概述：

1.  定义我们的学习率调度器回调函数。

1.  在训练过程中（通过`fit()`方法），传递给回调函数的参数是当前 epoch 计数（`epoch`）和学习率（`lr`）。

1.  对于第一个 epoch，返回当前的（初始）学习值。

1.  否则，实现一个逐步降低学习率的方法。

1.  实例化一个用于学习率调度器的回调函数。

1.  将回调函数传递给`fit()`方法。

```
from tensorflow.keras.callbacks import LearningRateScheduler

def lr_scheduler(epoch, lr):
    ''' Set the learning rate at the beginning of epoch
       epoch: The epoch count (first epoch is zero)
       lr:  The current learning rate
    '''
    if epoch == 0:                                                        ❶
        return lr

      return n_lr                                                         ❷

model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))   ❸

lr_callback = LearningRateScheduler(lr_scheduler)                         ❹

model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,  
          callbacks=[lr_callback])                                        ❺
```

❶ 步骤 3：对于第一个（0）epoch，从初始学习率开始

❷ 步骤 4：添加你的逐步降低学习率的实现

❸ 步骤 1：设置初始学习率

❹ 步骤 5：创建学习率调度器的回调函数

❺ 步骤 2 和 6：为训练启用学习率调度器

### 10.3.3 渐增

因此，你已经完成了数值稳定性的预训练步骤和批量大小以及初始学习率的超参数调整。现在你准备好实现你的学习率调度器算法了。通常，你可以使用一个渐增算法来实现这一点，该算法在指定数量的 epochs 后重置学习率。通常，在这个阶段，我会进行一次扩展的训练运行。我通常从 50 个 epochs 开始，并在评估损失上设置一个提前停止条件（`patience`为 2）。无论数据集如何，我通常会看到两种情况之一：

+   在最后（50）个 epochs 中，评估损失保持稳定和一致地减少。

+   在最后一个时期之前，验证损失出现平台期，并且提前停止已经启动。

如果我看到验证损失持续减少，我将继续重复额外的 50 个时期，直到出现提前停止。

一旦我设置了提前停止，我会查看它发生在哪个时期。比如说，它发生在第 40 个时期。然后我会减去几个时期，通常是 5 个（在这种情况下，结果是 35）。然后我将我的学习率调度器硬编码为在该时期降低一个数量级的学习率。几乎 100%的情况下，我的训练会改善到更低的验证损失和更高的验证准确率。图 10.7 显示了降低的学习率。

![图片](img/CH10_F07_Ferlitsch.png)

图 10.7 降低的学习率

以下是一个斜坡学习率调度器的示例实现：

```
epoch_ramp = 35                  ❶

def lr_scheduler(epoch, lr):
    if epoch == epoch_ramp:      ❷
        return lr / 10.0         ❷
    return lr
```

❶ 设置降低一个数量级的时期

❷ 在斜坡时期降低学习率一个数量级

这通常不是我的最后一步，而是我用它来了解这个数据集的损失地形可能是什么样子。从那以后，我计划我的完整训练学习率调度器。在这个层面上，解释损失地形会太具有挑战性。相反，我将介绍你可以尝试的各种学习率调度器策略。

### 10.3.4 恒定步长

在恒定步长方法中，我们希望在最后一个时期内以等量递增的方式从初始学习率到零。这个方法很简单。你将初始学习率除以时期数。图 10.8 展示了这个方法。

![图片](img/CH10_F08_Ferlitsch.png)

图 10.8 恒定步长学习率

这是一个学习率调度器的步长方法的示例实现：

```
epochs = 200            ❶
lr = 0.001              ❷
step = lr / epochs      ❸

def lr_scheduler(epochs, lr):
    ''' step learning rate '''
    return lr - step
```

❶ 训练的时期数

❷ 由超参数调整确定的初始学习率

❸ 每个时期后步长衰减的大小

### 10.3.5 余弦退火

*余弦退火方法*在研究人员中很受欢迎，在关于消融研究的学术论文中经常出现。它也被称为*循环学习率*。这里的理念是，不是在训练过程中逐渐降低学习率，而是在周期中这样做。

更简单地来说，我们从初始学习率开始，逐渐降低到一个较低的学习率，然后我们再次逐渐提高它。我们持续重复这个循环，但每次循环开始时的速率（高）和结束时的速率（低）都更低——因此我们在循环中仍然在向更低的方向进步。

那么，它的优势是什么？它提供了定期探索其他局部最优解（跳出）和逃离鞍点的机会。对于局部最优解，它就像进行一次梁搜索。训练过程可能会跳出当前的局部最优解，并开始深入另一个。虽然一开始没有任何迹象表明新的局部最优解更好，但最终会是这样。原因如下。随着训练的进行，我们将深入到比较差的局部最优解更好的局部最优解。随着学习率的下降，我们跳出好的局部最优解的可能性越来越小。另一种思考这种周期性行为的方式是探索与利用：在周期的较高端，训练正在探索新的路径，而在较低端，它正在利用好的路径。随着训练的进展，我们逐渐减少探索，增加利用。

另一个优势是，在我们使用学习率周期的低端深入挖掘后，我们可能会卡在鞍点上。让我们使用以下图表来帮助理解鞍点是什么。

如果我们的特征（自变量）与标签（因变量）之间存在线性关系，一旦我们发现了变化率，我们就会深入到全局最优解，无论学习率如何（如图中第一条曲线所示）。

另一方面，如果关系是多项式的，我们将看到更像是凸曲线的东西，全局最优解作为曲线的最低点。原则上，只要我们持续降低学习率，我们就会下降到最低点，避免在曲线两侧来回弹跳（如图中第二条曲线所示）。

但深度学习的力量在于特征与标签之间存在非线性（和非多项式）关系（如图中第三条曲线所示）。在这种情况下，考虑损失空间由山谷、山峰和鞍点组成，一个山谷是全局最优解。我们的目标当然是找到这个山谷，这就是探索多个局部最优解（山谷）的优势。

鞍点是在山谷中具有平台的部分；它在继续下降之前变得平坦。如果我们的学习率非常低，我们将在平台上无休止地弹跳。因此，虽然我们希望在训练接近结束时拥有那个很小的学习率，但我们希望它偶尔上升，以推动我们在下降到最低点时离开鞍点。

图 10.9 对比了线性/多项式与非线性关系之间的损失表面，显示了峰值、谷值和平台——这些可以成为鞍点。

![图像](img/CH10_F09_Ferlitsch.png)

图 10.9 梯度下降和学习率变化率斜率

当使用余弦衰减与早停结合时，我们必须重新思考停止的目标（验证准确率）。如果我们使用非周期性衰减进行训练，我们可能会在停止前使用非常小的阈值差异。但是，由于周期性行为，我们在探索（周期的末端）时可能会看到差异的突然激增（验证损失增加）。因此，我们需要为早停使用更大的差距。另一种选择是使用自定义早停，随着周期末端的降低，逐渐减小差异。

以下是一个使用余弦衰减的学习率调度器的示例实现。该函数有点复杂。我们使用余弦函数`np.cos()`从 0 到 1 生成正弦波。例如，余弦(π)是-1，余弦(2π)是 1，所以传递给`np.cos()`的值的计算是π的倍数。这样，值就是正的，计算中加 1，结果现在将在 0 到 2 的范围内。然后，该值减半（0.5 倍），所以结果现在将在 0 到 1 的范围内。然后，衰减通过 alpha 调整，它设置最小学习率的下限。

```
def cosine_decay(epoch, lr, alpha=0.0):
        """ Cosine Decay
        """
        cosine_decay = 0.5 * (1 + np.cos(np.pi * (e_steps * epoch) / t_steps)) ❶
        decayed = (1 - alpha) * cosine_decay + alpha                           ❷
        return lr * decayed                                                    ❸

def lr_scheduler(epochs, lr):
    ''' cosine annealing learning rate '''
    return cosine_decay(epochs, lr)                                            ❹
```

❶ 计算介于 0 和 2 之间的余弦值并减半

❷ 通过 alpha 调整值

❸ 返回衰减后的学习率

❹ 将学习率调度器回调连接到余弦衰减函数

在 TF 2.x 中，余弦衰减被添加为内置的学习率调度器：

```
from tf.keras.experimental import CosineDecay                       ❶

lrate = CosineDecay(initial_learning_rate, decay_steps, alpha)      ❷

model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,  
          callbacks=[lrate])                                        ❸
```

❶ 导入 CosineDecay 内置学习率调度器

❷ 实例化 CosineDecay 学习率调度器

❸ 在训练期间将学习率调度器作为回调添加

## 10.4 正则化

下一个重要的超参数是*正则化*。这指的是向训练中添加噪声的方法，使得模型不会记住训练数据。我们可以延迟记忆的时间越长，在预测未训练数据（如测试（保留）数据）时获得更高模型准确率的机会就越好。

让我们更简单地重申这一点。我们希望模型学习基本特征（泛化），而不是数据（记忆）。

关于正则化中的 dropout 的说明：现在没有人那样做了；这是古老的。

### 10.4.1 权重正则化

目前最广泛使用的正则化形式是*权重正则化*，也称为*权重衰减*。权重正则化是按层应用。其目的是在反向传播中向权重更新添加与权重大小相关的噪声。这种噪声通常被称为*惩罚*，权重较大的层比权重较小的层有更大的惩罚。

不深入探讨梯度下降和反向传播，可以说损失计算是更新每一层权重计算的一部分。例如，在回归器模型中，我们通常使用均方误差来表示预测值 (*ŷ*) 和实际（真实 – *y*）值之间的损失，可以表示如下：

损失函数 = MSE(*ŷ*, *y*)

为了为每一层添加噪声，我们希望按权重大小比例添加一小部分作为惩罚：

损失函数 = MSE(*ŷ*, *y*) + *penalty*

惩罚 = *decay* × *R*(*w*)

在这里，*decay* 是权重衰减，其值 << 1。而 *R*(*w*) 是应用于该层权重 *w* 的正则化函数。TF.Keras 支持以下正则化函数：

+   *L1*—绝对权重的总和，也称为 *Lasso 正则化*

+   *L2*—平方权重的总和，也称为 *Ridge 正则化*

+   *L1L2*—绝对和平方权重的总和，也称为 *Elastic Net 正则化*

现代 SOTA 研究论文中引用的消融研究使用 L2 权重正则化，其值范围在 0.0005 到 0.001 之间。根据我的经验，我发现 0.001 以上的值在权重正则化上过于激进，并且训练无法收敛。

在 TF.Keras 中，使用关键字参数 `kernel_regularizer` 来设置每层的权重正则化。如果您使用它，您应该在所有具有学习参数的层上指定它（例如，`Conv2D`，`Dense`）。以下是一个为卷积层（`Conv2D`）指定`L2`权重衰减正则化的示例实现：

```
from tensorflow.keras.regularizers import L2

inputs = Input((128, 128, 3))
x = Conv2D(16, (3, 3), strides=(1, 1), kernel_regularizer=L2(0.001))(inputs)
```

### 10.4.2 标签平滑

*标签* *平滑*方法从不同的角度进行正则化。到目前为止，我们讨论了添加噪声以防止记忆化的技术，从而使模型能够泛化到模型在训练期间未见过的同一分布内的示例。

然而，我们发现，即使我们惩罚这些权重更新以防止记忆化，这些模型在预测上往往过于自信（高概率值）。

当模型过于自信时，真实标签和非真实标签之间的距离可以有很大差异。当绘制时，它更倾向于看起来像散点图而不是簇；如果真实标签聚集在一起，即使置信度较低，这也是更理想的情况。图 10.10 展示了使用硬目标标签的过于自信的模型。

![](img/CH10_F10_Ferlitsch.png)

图 10.10 训练时作为独热编码标签（0 或 1）的标签

标签平滑通过使预测不那么自信来帮助模型泛化，这导致真实标签和非真实标签之间的距离聚集在一起。

在标签平滑中，我们将 one-hot 编码的标签（真实值）从绝对确定性（1 和 0）调整为小于绝对确定性，用*α*（阿尔法）表示。例如，对于真实标签，我们不是将其值设置为 1（100%），而是将其设置为略低一些的值，比如 0.9（90%），然后将所有非真实值从 0（0%）调整到降低真实标签的相同数量（例如，10%）。

图 10.11 说明了标签平滑。在这个描述中，将输出密集层的预测与标签平滑后的真实标签进行比较，称为*软目标*。损失是从软目标而不是硬目标计算出来的，这在实践中已被证明可以使真实值和非真实值之间的距离更加一致。这些距离更有可能形成簇，这有助于模型更加泛化。

![图片](img/CH10_F11_Ferlitsch.png)

图 10.11 标签平滑作为当标签小于绝对确定性时的软目标

在 TF 2.x 中，标签平滑内置在损失函数中。要使用它，显式实例化相应的损失函数并设置关键字参数`label_smoothing`。在实践中，*α*因子保持较小，0.1 是最常用的值。

```
from tensorflow.keras.losses import CategoricalCrossentropy

model.compile(loss=CategoricalCrossentropy(label_smoothing=0.1),   ❶
              optimizer='adam', metrics=['acc'])                   ❶
```

❶ 在编译模型时设置标签平滑

接下来，我们将总结我们在超参数方面所涵盖的内容，以及它们如何影响在训练时间和目标（例如，准确率）方面实现最佳结果。

## 10.5 超越计算机视觉

所有深度学习模型架构，无论数据类型或领域，都有可调整的超参数。调整它们的策略是相同的。无论你是在处理计算机视觉、自然语言理解还是结构化数据，深度学习领域的四大超参数都存在：学习率、学习率衰减、批量大小和正则化。

正则化的超参数在模型架构和不同领域之间可能类型不同。很多时候它们并不不同。例如，权重衰减可以应用于任何具有可学习权重的层，无论它是计算机视觉、NLU 还是结构化数据模型。

一些模型架构，如深度神经网络和提升树，有一些历史上独特的超参数。例如，对于 DNN，你可能看到调整层数和每层的单元数。对于提升树，你可能看到调整树的数量和叶子数。但是，由于超参数（用于训练模型）和元参数（用于配置模型架构）的划分，这些可调整的参数现在被称为*元参数*。因此，如果你在深度神经网络中同时调整层数和单元数以及学习率，实际上你正在进行宏观架构搜索和超参数调整的并行操作。

## 摘要

+   不同的权重分布和抽取会影响训练过程中的收敛性。

+   在搜索最佳权重初始化（抽签原则）与学习最佳权重初始化（预热）之间的区别在于，模型学习最佳初始化而不是通过经验找到它。

+   当数据集较小时，使用手动方法进行超参数搜索是最佳选择，但其缺点是您可能会忽略在训练过程中实现更好结果的超参数值。

+   网格搜索用于小搜索空间，而在大搜索空间中进行超参数调整时，随机搜索效率更高。

+   使用 KerasTuner 进行超参数搜索可以自动化搜索过程，但其缺点是您无法手动引导搜索。

+   用于学习率衰减的各种算法包括时间衰减、恒定步长、斜坡步长和余弦退火。

+   设置学习率调度器涉及定义回调函数，在回调函数中实现自定义学习率算法，并将回调函数添加到`fit()`方法中。

+   常规的正则化方法包括权重衰减和标签平滑。
