# 附录 B 负责任的人工智能工具

随着生成式人工智能模型在企业中的日益普及，确保它们负责任地开发和部署至关重要。负责任的人工智能（RAI）实践可以帮助组织建立利益相关者的信任，满足监管要求，并避免意外后果。幸运的是，许多工具可供开发者和技术架构师使用，以将 RAI 原则融入他们的 AI 系统中。

以下部分概述了一些这些工具和框架，它们可以帮助确保 AI 中的透明度、公平性、可解释性和安全性。

## B.1 模型卡

模型卡是伴随 AI 模型的一种特殊文档。它提供有关模型目的、性能、训练数据、伦理考量等方面的标准化信息集。它类似于产品数据表，提供透明度并促进负责任的人工智能实践。

虽然将模型卡视为 RAI 工具可能看似奇怪，但它们在 RAI 的背景下发挥着重要作用。模型卡被视为 RAI 的必要工具。它们帮助利益相关者了解基于 GPT 架构等生成式 AI 模型的性能和局限性，确保这些强大的工具被道德和有效地使用：

+   *促进透明度*——它们详细说明了模型的特点、局限性和理想用例。

+   *鼓励问责制*——通过记录模型的发展过程，模型卡有助于确保创作者对其 AI 系统负责。

+   *促进明智使用*——它们为用户提供必要的信息，以了解如何使用模型，从而防止误用。

对于大型语言模型（LLMs），模型卡通常包括以下详细信息：

+   *模型详情*——有关模型架构、大小、训练数据和训练程序的信息

+   *预期用途*——描述模型设计用于的任务及其预期用途的限制

+   *性能指标*——显示模型在各项任务上表现如何的基准和评估结果

+   *伦理考量*——与模型使用相关的任何伦理问题，包括潜在的偏见

+   *注意事项和建议*——对模型用户的任何警告或建议

例如，OpenAI 的 GPT-4 模型卡被称为系统卡，长达 60 页。它指出了与安全挑战相关的多个风险，例如幻觉、有害内容、可能的风险涌现行为、过度依赖等。有关模型卡的更多详细信息，请参阅[`mng.bz/M1gB`](https://mng.bz/M1gB)。

## B.2 透明度笔记

透明度笔记是一份概述人工智能技术能力、局限性和环境影响文档。它旨在阐明人工智能系统的工作原理，这对于负责任地实施人工智能至关重要。透明度笔记是应用人工智能原则和指导人工智能技术的负责任使用和部署的实用工具。企业应考虑以下原因将透明度笔记作为其人工智能开发的一部分：

+   *理解人工智能系统*—他们应该了解人工智能系统不仅包括技术，还包括用户、受其影响的人以及其部署的环境。

+   *知情部署*—透明度笔记可以帮助企业就开发部署人工智能系统做出明智的决定，确保它们适合其预期用途。

透明度笔记是一种有助于提高透明度和问责制的有用方式，这对于人工智能系统的道德创造和使用至关重要。例如，Azure OpenAI 服务的透明度笔记解释了系统功能、边界、应用和最佳实践，以优化系统性能。您可以在[`mng.bz/aVKm`](https://mng.bz/aVKm)访问这些透明度笔记。

## B.3 HAX 工具包

HAX 工具包（[`aka.ms/haxtoolkit`](https://aka.ms/haxtoolkit)），由微软研究院与微软在工程和研究中的道德和影响咨询机构 Aether 合作开发，是一套旨在促进负责任的人类-人工智能体验创建的实用工具。它包括人类-人工智能交互指南、工作簿、设计模式、剧本和设计库，所有这些都有助于团队战略性地创建与人类互动的人工智能技术。

企业在实施其人工智能开发过程中的负责任人工智能（RAI）时，应将 HAX 工具包视为一项宝贵资源。它提供了基于研究和通过实际应用验证的可操作指导。工具包可以帮助团队优先考虑指南，规划资源，并解决常见的设计挑战。它还准备应对意外错误，确保人工智能系统以以人为本的方法开发，并与负责任的人工智能原则保持一致。

HAX 工具包通过提供将人类-人工智能交互知识转化为人工智能创造者可操作指导的实际工具，来解决人工智能系统中的偏见和公平性问题。它帮助团队优先考虑指南并规划资源以应对优先事项，包括偏见和公平性。工具包包括

+   *人类-人工智能交互指南*—人工智能应用应如何与人类互动的最佳实践

+   *HAX 工作簿*—帮助团队优先考虑指南并规划解决高优先级项目所需的时间和资源

+   *HAX 设计模式*—为设计人类-人工智能系统中的常见问题提供灵活的解决方案

+   *HAX 操作手册*—帮助团队识别和规划不可预见错误，例如转录错误或假阳性，这些可能是偏见来源。

+   *HAX 设计库*—一个可搜索的设计模式和实现示例数据库

通过利用这些资源，团队可以确保他们的 AI 系统在设计时考虑到以人为中心的方法，在整个 AI 应用生命周期中考虑公平性并减轻偏见。更多详情可以在[`mng.bz/gAxv`](https://mng.bz/gAxv)找到。

## B.4 负责任 AI 工具箱

负责任 AI 工具箱([`mng.bz/5OWO`](https://mng.bz/5OWO))是微软提供的一套工具，旨在帮助实施 RAI 实践。它包括集成工具和功能，使用户能够评估他们的 AI 模型并做出更有效的面向用户的决策。工具箱旨在灵活且不依赖于特定模型，这意味着它可以与各种 AI 模型一起使用，包括生成模型。

工具箱提供了接口和库，使 AI 系统开发者和利益相关者能够更有责任地开发和监控 AI。其功能可以惠及那些希望确保其生成 AI 的使用与 RAI 原则一致的企业。它涵盖的一个关键领域是负责任 AI 仪表板，该仪表板结合了各种 RAI 能力，帮助从业者优化他们的机器学习（ML）模型以实现公平性、可解释性和其他期望的特性。

它旨在协助评估和调试机器学习模型，提供洞察力以帮助业务决策者做出更明智的决策。它结合了模型可靠性、可解释性、公平性和合规性等领域的多个高级工具，为基于数据的决策提供完整的评估和故障排除。

这主要适用于传统的机器学习模型，而不是像 LLM 这样的生成模型。然而，有时这些模型在工作流程中一起工作，相互增强，在这种情况下，RAI 仪表板是有用的。仪表板有助于以下方面：

+   *全面评估*—它提供了一个单一界面，用于各种 RAI 工具，能够对机器学习模型进行完整评估。

+   *可定制界面*—用户可以根据自己的使用场景定制仪表板，只包含相关的工具。

+   *模型调试*—它通过评估、理解和缓解的阶段支持模型调试，重点关注模型可靠性、可解释性、公平性和合规性。

## B.5 学习可解释性工具（LIT）

学习可解释性工具（LIT）是一个开源工具([`pair-code.github.io/lit`](https://pair-code.github.io/lit))，旨在帮助我们理解和解释机器学习模型。它支持多种数据类型，包括文本、图像和表格数据，并且可以与不同的机器学习框架如 TensorFlow 和 PyTorch 一起使用。

LIT 是谷歌更广泛的负责任通用人工智能工具包（[`ai.google.dev/responsible`](https://ai.google.dev/responsible)）的一部分，旨在谷歌云上运行。LIT 提供如下功能：

+   *局部解释*——通过显著性图、注意力可视化和模型预测生成

+   *聚合分析*——包括自定义指标、切片、分箱和嵌入空间的可视化

+   *反事实生成*——用于动态创建和评估新示例

企业可以使用 LIT 与生成式人工智能应用结合，用于调试和分析模型，帮助他们理解模型为何以及如何表现出特定的行为。LIT 还可以通过使用诸如序列显著性等可解释性技术来分析提示设计对模型输出的影响，并测试假设的改进。通过分析和记录生成模型的运行行为，企业可以与负责任人工智能（RAI）原则保持一致。

## B.6 AI Fairness 360

AI Fairness 360（AIF360 论文：[`arxiv.org/abs/1810.01943`](https://arxiv.org/abs/1810.01943)）是一个开源工具包（[`github.com/Trusted-AI/AIF360`](https://github.com/Trusted-AI/AIF360)），帮助用户在任何人工智能应用生命周期的任何阶段检查、衡量和减少机器学习模型中的歧视和偏见。它提供了一套由研究社区创建的公平性指标和偏差缓解算法，以处理人工智能系统中的偏差。它可以作为人工智能开发过程的一部分，用于监控和减少不希望的偏差。使用 AIF360，组织可以通过超过 70 个公平性指标来量化偏差。在测量偏差之后，AIF360 可以通过应用高级算法来减少训练数据和模型中的偏差，并确保合规性，遵循伦理标准和法规，并展示解决人工智能公平性的努力。

最后，AIF360 有助于进行红队测试，企业通过确保其公平和均衡的人工智能系统，与用户和利益相关者建立信任。

## B.7 C2PA

内容来源和真实性联盟（C2PA）是一个开发技术标准以认证在线媒体内容来源和历史的计划。它旨在通过提供一种追踪不同类型媒体（如图像、视频和文档）起源的方法来防止误导性信息的传播。该标准是主要科技公司之间的合作成果，它使内容创作者能够将加密签名元数据、C2PA 清单附加到数字资产上。这些元数据可以验证内容的来源和任何后续编辑，从而增加数字媒体的可信度和真实性。

C2PA 允许为数字媒体文件创建内容凭证，这些凭证显示了创作过程，包括创作者的身份和使用的工具。这些凭证随后通过数字签名进行加密，以防止篡改。当媒体被分享时，嵌入的 C2PA 元数据使其他人能够检查媒体的真实性以及任何已做的更改。一些开源工具，如 c2patool，可以帮助完成这项任务 ([`github.com/contentauth/c2patool`](https://github.com/contentauth/c2patool)).
