# 前置内容

## 前言

我有幸在过去十年左右的时间里从事数据和机器学习工作。我的背景是机器学习，我的博士研究集中在将机器学习应用于无线网络。我在顶级会议和期刊上发表了关于强化学习、凸优化以及将经典机器学习技术应用于 5G 蜂窝网络的论文([`mng.bz/zQR6`](https://shortener.manning.com/zQR6))。

在完成我的博士学业后，我开始在工业界作为数据科学家和机器学习工程师工作，并在多个行业（如制造、零售和金融）为客户部署复杂的 AI 解决方案方面积累了经验。正是在这段时间里，我意识到了可解释人工智能的重要性，并开始深入研究。我还开始在实际场景中实施和部署可解释性技术，以便数据科学家、商业利益相关者和专家能够更深入地理解机器学习模型。

我撰写了一篇关于可解释人工智能和提出构建稳健、可解释人工智能系统的原则性方法的博客文章([`mng.bz/0wnE`](https://shortener.manning.com/0wnE))。这篇文章意外地收到了来自数据科学家、研究人员和来自各行各业实践者的巨大反响。我还在多个 AI 和机器学习会议上就这个主题进行了演讲。通过将我的内容公之于众并在领先会议上发言，我学到了以下内容：

+   对这个主题感兴趣的不止我一个人。

+   我能够更好地理解社区对哪些具体主题感兴趣。

这些经验教训导致了你现在正在阅读的这本书的诞生。你可以找到一些资源来帮助你了解可解释人工智能的最新动态，比如综述论文、博客文章和一本书，但没有单一的资源或书籍涵盖了所有对人工智能从业者有价值的重要可解释性技术。也没有关于如何实施这些尖端技术的实用指南。本书旨在填补这一空白，首先为这个活跃的研究领域提供一个结构，并涵盖广泛的可解释性技术。在这本书中，我们将探讨具体的现实世界案例，并了解如何使用最先进的技术构建复杂模型并进行解释。

我坚信，随着复杂机器学习模型在现实世界的部署，理解它们至关重要。缺乏深入理解可能导致模型传播偏见，我们在刑事司法、政治、零售、面部识别和语言理解中都看到了这方面的例子。所有这些都对信任产生了有害影响，根据我的经验，这也是公司抵制人工智能部署的主要原因之一。我很高兴你也意识到这种深入理解的重要性，并希望你能从这本书中学到很多。

## 致谢

写一本书比我想象的要难得多，这需要大量的工作——真的！如果没有我父母 Krishnan 和 Lakshmi Thampi、我的妻子 Shruti Menon 和我的兄弟 Arun Thampi 的支持和理解，这一切都不可能实现。我的父母让我走上了终身学习的道路，并始终给予我追逐梦想的力量。我也永远感激我的妻子，她在我写这本书的艰难旅程中一直支持我，耐心地倾听我的想法，审阅我的草稿，并相信我能够完成它。我的兄弟也值得我衷心的感谢，因为他总是支持我！

接下来，我想感谢 Manning 团队：Brian Sawyer，他阅读了我的博客文章，并建议这可能是一本好书；我的编辑 Matthew Spaur、Lesley Trites 和 Kostas Passadis，因为他们与我合作，提供高质量的反馈，并在事情变得艰难时保持耐心；以及 Marjan Bace，因为他批准了这个整个项目。还要感谢所有其他与我在这本书的生产和推广工作中合作的 Manning 团队成员：Deirdre Hiam，我的生产编辑；Pamela Hunt，我的校对编辑；以及 Melody Dolab，我的页面校对员。

我还想感谢那些在书的发展过程中花时间阅读我的手稿并在各个阶段提供宝贵反馈的审稿人：Al Rahimi、Alain Couniot、Alejandro Bellogin Kouki、Ariel Gamiño、Craig E. Pfeifer、Djordje Vukelic、Domingo Salazar、Dr. Kanishka Tyagi、Izhar Haq、James J. Byleckie、Jonathan Wood、Kai Gellien、Kim Falk Jorgensen、Marc Paradis、Oliver Korten、Pablo Roccatagliata、Patrick Goetz、Patrick Regan、Raymond Cheung、Richard Vaughan、Sergio Govoni、Shashank Polasa Venkata、Sriram Macharla、Stefano Ongarello、Teresa Fontanella De Santis、Tiklu Ganguly、Vidhya Vinay、Vijayant Singh、Vishwesh Ravi Shrimali 和 Vittal Damaraju。特别感谢 James Byleckie 和 Vishwesh Ravi Shrimali，技术校对员，在书进入生产前仔细审查了代码。

## 关于这本书

*可解释人工智能*旨在帮助您实现复杂机器学习模型的最先进可解释技术，并构建公平可解释的人工智能系统。可解释性是研究的热点话题，但只有少数资源和实用指南涵盖了所有对现实世界从业者有价值的重要技术。本书旨在填补这一空白。

### 应该阅读这本书的人

*可解释人工智能*是为那些对深入了解模型工作原理以及如何构建公平无偏模型感兴趣的数据科学家和工程师而设计的。本书对希望了解驱动人工智能系统的模型以确保公平性并保护企业用户和品牌的企业架构师和业务利益相关者也应有帮助。

### 本书是如何组织的：一个路线图

本书分为四个部分，共涵盖九章内容。

第一部分带您进入可解释人工智能的世界：

+   第一章介绍了不同类型的 AI 系统，定义了可解释性及其重要性，讨论了白盒和黑盒模型，并解释了如何构建可解释人工智能系统。

+   第二章介绍了白盒模型及其解释方法，具体关注线性回归、决策树和广义加性模型（GAMs）。

第二部分专注于黑盒模型，并理解模型如何处理输入并得出最终预测：

+   第三章介绍了一类称为树集成（tree ensembles）的黑盒模型，以及如何使用全局范围内的后验模型无关方法来解释它们，例如部分依赖图（PDPs）和特征交互图。

+   第四章介绍了深度神经网络及其解释方法，使用局部范围内的后验模型无关方法来解释它们，例如局部可解释模型无关解释（LIME）、SHapley 加性解释（SHAP）和锚点。

+   第五章介绍了卷积神经网络，以及如何使用显著性图来可视化模型关注的重点，具体关注的技术包括梯度、引导反向传播、梯度加权类激活映射（Grad-CAM）、引导 Grad-CAM 和光滑梯度（SmoothGrad）。

第三部分继续关注黑盒模型，但转向理解它们学习到的特征或表示：

+   第六章介绍了卷积神经网络，以及如何剖析它们以理解神经网络中间或隐藏层学习到的数据表示。

+   第七章介绍了语言模型，以及如何使用主成分分析（PCA）和 t 分布随机邻域嵌入（t-SNE）等技术可视化它们学习到的高维表示。

第四部分专注于公平性和偏差，为可解释人工智能铺平道路：

+   第八章涵盖了公平的多种定义以及检查模型是否存在偏差的方法。它还讨论了减轻偏差的技术以及使用数据表来标准化记录数据集的方法，这将有助于提高与 AI 系统的利益相关者和用户的透明度和问责制。

+   第九章通过理解如何构建这样的系统为可解释人工智能铺平道路，同时也涵盖了使用反事实示例的对比解释。

### 关于代码

这本书包含了许多源代码示例。在大多数情况下，源代码以`fixed-width` `font` `like` `this`这样的`固定宽度`字体格式化，以将其与普通文本区分开来。

在许多情况下，原始源代码已被重新格式化；我们已添加换行符并重新处理缩进来适应书中的可用页面空间。在极少数情况下，即使这样也不够，列表中还包括了行续续标记（➥）。此外，当代码在文本中描述时，源代码中的注释通常已从列表中删除。代码注释伴随着许多列表，突出显示重要概念。

您可以从这本书的在线版本 liveBook 中获取可执行的代码片段，网址为[`livebook.manning.com/book/interpretable-ai`](https://livebook.manning.com/book/interpretable-ai)。书中示例的完整代码可在 Manning 网站[`www.manning.com/books/interpretable-ai`](https://www.manning.com/books/interpretable-ai)和 GitHub[`mng.bz/KBdZ`](https://shortener.manning.com/KBdZ)上下载。

### liveBook 讨论论坛

购买《可解释人工智能》包括免费访问 Manning 的在线阅读平台 liveBook。使用 liveBook 的独特讨论功能，您可以在全球范围内或针对特定章节或段落附加评论。为自己做笔记、提问和回答技术问题以及从作者和其他用户那里获得帮助都非常简单。要访问论坛，请访问[`livebook.manning.com/book/interpretable-ai/discussion`](https://livebook.manning.com/book/interpretable-ai/discussion)。您还可以在[`livebook.manning.com/discussion`](https://livebook.manning.com/discussion)了解更多关于 Manning 论坛和行为准则的信息。

曼宁对读者的承诺是提供一个场所，让读者之间以及读者与作者之间可以进行有意义的对话。这并不是对作者参与特定数量活动的承诺，作者对论坛的贡献仍然是自愿的（且未付费）。我们建议您尝试向作者提出一些挑战性的问题，以免他的兴趣转移！只要这本书有售，论坛和以前讨论的存档将可通过出版社的网站访问。

## 关于作者

![图片](img/fm_ajaythampi.png)

阿贾伊·桑皮在机器学习方面有着坚实的背景。他的博士研究专注于信号处理和机器学习。他在强化学习、凸优化以及将经典机器学习技术应用于 5G 蜂窝网络等主题的领先会议和期刊上发表了论文。阿贾伊目前是一家大型科技公司的高级机器学习工程师，主要专注于负责任的 AI 和公平性。在过去，阿贾伊曾在微软担任首席数据科学家，负责为多个行业如制造业、零售业和金融业等客户部署复杂的 AI 解决方案。

## 关于封面插图

《可解释人工智能》封面上的图像是“Mourcy 的橙商”，或“橙商”，取自雅克·格拉塞·德·圣索沃尔的收藏，该收藏于 1797 年出版。每一幅插图都是手工精细绘制和着色的。

在那些日子里，仅凭人们的服饰就能轻易地识别出他们居住的地方以及他们的职业或社会地位。曼宁通过基于几个世纪前丰富多样的地域文化的书封面，庆祝计算机行业的创新精神和主动性，这些文化通过如这一系列图片的图片被重新带回生活。
