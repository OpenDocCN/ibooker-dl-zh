# 第六章：使用生成式 AI 进行高级文本挖掘

### 本章涵盖

+   使用生成式 AI 语言模型进行情感分析

+   使用生成式 AI API 进行情感分析

+   使用机器学习进行情感分析

+   使用生成式 AI 进行文本摘要

+   使用专用库进行文本摘要

+   主题建模

在上一章中，您已经尝到了文本挖掘基础的味道，并发现了生成式 AI 如何加速和精炼您的分析。现在，让我们更进一步。接下来，您将应对诸如情感分析和文本摘要等高级 NLP 技术。这些工具在商业世界中极为宝贵，使公司能够迅速从评论、社交媒体或客户服务互动中评估客户情绪，从而做出更明智的决策。另一方面，文本摘要可以将冗长的报告、研究结果或客户反馈提炼成可消化的洞察，节省您宝贵的时间，并确保关键信息不会被人忽视。这些技术共同可以显著提高企业理解和回应其受众的方式，推动更好的策略和结果。

在本章中，您将看到第五章中简单情感分析方法与机器学习模型的先进功能和生成式 AI 的语言技巧相比的表现。准备好亲眼见证超越生成式 AI 在 NLP 任务中的挑战。您的目标？一如既往，给老板留下深刻印象。但这次，通过迅速准确地从负面评论中提取和总结关键客户洞察来实现。有了生成式 AI 作为您的盟友，您将能够顺利地通过这些复杂的过程。

## 6.1 评论分析

随着您在本章中的前进，请记住老板交给您的任务：根据客户的评论，揭示客户对您公司产品和服务的主要问题。您在上一章中采取的初步步骤提供了一些线索，但现在您面临一个有趣的挑战：您能否通过利用更高级的 NLP 技术来深化您的理解？让我们一起来找出答案。

您在上一章中检查的数据集包含了客户评论（在 5.2.2 节中详细描述）。这种数据通常比较杂乱无章。此外，如果您的葡萄牙语不熟悉，那么评论是葡萄牙语的事实又提出了另一个挑战。为了应对这种混乱，我们将探索从非结构化数据中提取洞察的各种技术，其中这些是最重要的两种：

+   *情感分析*——确定文本中表达的基本情感、观点或态度的过程，例如积极、消极或中性情感。这项技术对于希望衡量客户满意度、监控品牌声誉或了解消费者需求的企业来说非常有价值。例如，在应用于客户评论后，一家公司可以确定产品或服务的哪些特性最受赞赏，或者哪些方面导致了不满。

+   *文本摘要*——将大量文本压缩成更短、连贯的表示，同时保留最基本的信息和关键思想的技术。这种方法对于需要快速吸收大量信息而不牺牲理解的专业人士特别有用。例如，财务分析师可以使用文本摘要将全面的市场报告和研究论文提炼成简洁的摘要，从而加快决策速度，并有效地掌握关键市场趋势和预测。

你可能已经注意到，上一章中描述的基本 NLP 技术已经为情感分析和文本摘要奠定了基础。利用关键词或预定义的词汇表来过滤出正面评论确实是一种基本的情感分析形式，而即使是基本的频率分析也足以突出客户反馈中出现的主要问题，从而提供一种文本摘要形式。那么，在这一章中你将学到什么新东西呢？绝对会有的。

简单来说，你到目前为止所学的就像学习如何削土豆。在这一章中，我们将掌握美食烹饪的艺术。然而，我们的方法仍然非常实用，这意味着你不需要在心理上执行复杂的计算。相反，我们将向你介绍实现目标的最佳工具。具体来说，我们将使用在线可用的预训练机器学习模型来进行情感分析和文本摘要，生成式 AI 将引导我们完成整个过程。我们还将利用生成式 AI 固有的语言能力直接执行这些 NLP 任务。接下来的章节将对这两种方法以及之前介绍的基本 NLP 技术进行比较，提供它们相对性能和实用性的见解。

## 6.2 情感分析

情感分析是一种文本分类类型，其中给定的文本被分配一个标签或类别。例如，可以使用“正确”、“错误”或“未知”等标签根据文本的语法正确性对文本进行分类。具体来说，在情感分析中，通常使用“正面”、“负面”和“中性”这些标签来反映作者对某一主题的情感和态度。例如，一个像“我讨厌你的公司和你的糟糕的量子泡沫！”这样的陈述就带有强烈的负面情感。没有自然语言处理工具，这样的情感强烈的评论很容易在众多反馈中被公司公关部门忽视。然而，希望负面意见不会被其他客户看到，这不过是美好的愿望。这样的观点往往像草原上的野火一样迅速传播，可能危及公司的声誉。因此，学习如何自动检测客户情感对于企业健康至关重要。

重要的是要注意，文本分类的应用范围比情感分析广泛得多。考虑一种情况，其中输入不仅涉及单一文本，如客户评论，还涉及两个文本，目的是确定它们之间的关系。这导致了自然语言推理（NLI）领域，它极大地扩展了语言分析的范围。

NLI 任务可以根据输入和分配的标签而有所不同，但最终它们都归结为文本分类。例如，第一个输入文本可能是一个前提，比如“知更鸟是一种鸟”，第二个输入可能是一个假设，比如“知更鸟会飞”。可能的标签可以是“蕴涵”，表示假设逻辑上从前提中得出（例如，既然知更鸟是一种鸟，而大多数鸟都会飞，那么可以推断知更鸟会飞）；“矛盾”，表示假设与前提相矛盾；“中性”用于与前提无关或难以分类的情况。这个框架允许开发出至少在理论上可以执行某种形式阅读理解的程序。然而，这些程序的实用实施取决于各种因素，包括任务复杂性、训练数据量和质量，以及我们创建能够承担这种挑战的模型的能力（也许还有一点运气）。

您老板分配的任务——对评论进行分类——与提到的 NLI 任务相比要简单得多。尽管如此，它为探索文本分类和情感分析的基本原理提供了极好的机会。

在上一章中，我们展示了如何进行基本的情感分析，特别是使用基于规则（关键词搜索）和基于词典（词汇表）的方法提取正面评论。现在，考虑一下我们的简单分类器，利用这些方法，会如何对以下评论进行分类：“太好了，又一个软件更新，什么问题都没解决。”鉴于存在“太好了”和“解决”等词语，它可能会错误地将这个陈述归类为正面，尽管它带有讽刺的语气，表达了对于软件更新未能实现改进承诺的挫败感。

预训练模型在检测文本中的讽刺意味方面变得越来越擅长，但它们并非万能。它们通过分析语言技巧和了解更广泛的语境来实现这一成就。通过在包括充满讽刺意味的例子和直白的例子在内的海量文本数据上训练，这些模型熟悉了人类用来传达隐含意义的语言技巧。它们学会了识别红旗，如用于负面情境中的正面词语（“在令人沮丧的经历之后，这是完美的”）或违反常规对话的短语（“迫不及待地期待周一早上！”）。但讽刺不仅仅是文字游戏。预训练模型还会扩大视野，检查周围文本和说话者与听者之间的关系。例如，朋友之间的讽刺评论比在绩效评估期间老板的讽刺评论更有可能。

现在，让我们来分析一下短语“回到原点”。通过基本的关键词或基于词典的分析，准确地对这个表达进行分类是一个挑战，因为它缺乏明确的情感指示。然而，“回到原点”通常用来表示一个尝试已经失败，是时候重新开始了，这通常带有失望或挫折的意味。

相比之下，通过大量和多样化的文本数据集开发的机器学习模型，可以准确地理解习语表达及其语境意义，有效地识别失望或挫败的情感。这种能力对于彻底的情感分析至关重要，特别是在评估反馈、评论或内部沟通中，这些表达是常见的。这种模型的另一个优点是它们能够通过很少的人工努力适应不同的领域或语言，使它们成为跨各种数据集的情感分析的多功能工具。这类预训练模型的典型例子是一个大型语言模型或 LLM。

大型语言模型（LLM）是一个强大的 AI 系统，它在大量文本上进行训练，以便理解并生成人类语言。它使用深度学习执行各种 NLP 任务，包括翻译、摘要、问答和情感分析，通过预测一系列单词的可能性。LLMs 的能力超越了简单的文本处理，使它们能够理解上下文、推断意义，甚至生成连贯且与上下文相关的文本响应，使它们在研究和应用领域都成为强大的工具。

到目前为止讨论的所有生成式 AI 模型以及本书中使用的模型都是大型语言模型（LLMs）。尽管它们最初是为了通用对话而不是作为专门的审查分类器而设计的，但它们理解文本和提取见解的非凡能力使它们能够有效地用于情感分析任务。在接下来的章节中，我们将展示如何将它们应用于情感分析，并将结果与来自较小机器学习模型的结果进行比较。

### 6.2.1 从情感分析中你可以学到什么？

情感分析在各个商业领域提供了无价的见解，使您的公司能够从细粒度上理解客户情绪、偏好和反馈。例如，如果您为一家零售品牌工作，您可以通过分析社交媒体提及来衡量消费者对新产品发布的情绪，识别兴奋或担忧的区域，从而相应地调整营销策略。如果您从事金融行业，对新闻文章和金融论坛的情感分析可以帮助您和您的投资者预测市场趋势并做出明智的决策。如果您从事酒店和餐饮等酒店业，利用评论平台上的情感分析来突出服务或氛围的改进区域，可以直接影响客户满意度和忠诚度。此外，在科技公司中，您可以在软件更新中利用情感分析来获取用户反馈，优先修复和添加解决用户最紧迫问题的功能和特性。这种战略性的情感分析应用不仅提高了产品和服务的质量，而且通过展示对客户需求和意见的响应，促进了与客户的更紧密联系。

最简单且最常用的情感分析形式是将文本分为三个类别：积极、消极和中性情绪。在许多情况下，例如在我们的评论中，这足以理解客户情绪。然而，您可能会遇到需要探索人类灵魂更复杂方面（即：要求）的情况，并应用其他情感分析实例，例如这些：

+   *情感检测*—这涉及到识别文本中表达的具体情感，例如快乐、悲伤、愤怒、惊讶、恐惧和厌恶，从而更深入地理解用户的感受和反应。这可能至关重要，例如在社交媒体上检测自杀倾向。另一个情感检测至关重要的商业应用是在客户支持和服务互动中，尤其是在电信、银行或公用事业等行业，在这些行业中，客户的不满可能会迅速升级。例如，在电信公司中，情感检测可以用于分析客户支持聊天或通话记录。通过识别特定的情感，如挫败感、愤怒或失望，公司可以标记出需要立即关注或干预的案件。这允许在客户在网络上告诉每个人 Quantum Fluff（贵公司的特色功能）实际上弊大于利之前，优先响应高度不满的客户。

+   *基于方面的情感分析*—这项技术专注于识别与文本中特定方面或特征相关的情感。例如，在产品评论中，它区分了对产品价格、质量、设计等方面的情感，为顾客反馈的各个方面提供了详细的见解。谁知道呢——也许如果 Quantum Fluff 更便宜，它将获得更多的客户赞赏？

+   *情感强度或情感强度*—情感分析还可以评估表达的情感的强度或程度，区分轻微和强烈的情感。这有助于理解情感的实质，以及其强度或紧迫性。例如，经过这样的分析，可能会发现 Quantum Fluff 引发了如此强烈的负面情感，以至于人们愿意支付更多费用来摆脱它，这为贵公司提供了新的盈利机会。

+   *意图分析*——除了识别情感之外，一些方法旨在理解文本背后的意图，例如用户是否打算购买、推荐或对产品或服务提出投诉。这可能有助于评估客户支持工单、电子邮件和社交媒体消息。通过分析客户使用的语言和短语，系统可以确定他们的意图，例如寻求有关新计划的详细信息、报告服务中断、请求技术支持或表达取消服务的意图。例如，如果客户的消息被发现包含诸如“把这个该死的量子绒毛关掉”、“其他地方有更好的绒毛”或“在考虑更换”之类的短语，系统可以将此标记为高优先级的流失意图。这可以触发来自专业客户保留团队的即时响应，他们可以提供个性化的优惠（例如免费五个月的量子绒毛），支持或旨在解决他们关注的问题的解决方案。这种主动的方法不仅通过提供及时和相关的响应来提高客户满意度，还有助于降低流失率，直接影响公司的底线。

这些高级情感分析方法允许对文本数据进行更丰富、更复杂的理解，从而更深入地洞察消费者行为、市场趋势和公众舆论。

### 6.2.2 使用生成式 AI 进行直接情感分析

尽管生成式 AI 最初的设计目的是生成文本补全而不是执行情感分析，但它们理解文本的能力可以用于快速评估任何给定文本中表达的情感。您可以通过检查我们示例数据集中的三个评论来测试这一点。这些评论的评分分别为 5、3 和 1，分别表示积极、中立和消极情感。这些评论及其翻译在表 6.1 中展示。还详细介绍了 ChatGPT 4 和 Gemini Advanced 进行的情感分析结果。要获得类似的结果，您可以使用提示“这些评论的情感是什么？”然后包括葡萄牙语的评论。

##### 表 6.1 使用生成式 AI 进行直接情感分析

| 由谷歌翻译翻译的评论 | 评分 | 真实情感 | ChatGPT 4 的情感分析 | Gemini Advanced 的情感分析 |
| --- | --- | --- | --- | --- |

| 我在规定的时间之前就收到了。 | 5 | 积极的 | *积极的* 客户在规定截止日期之前就收到了产品，这表明他们有积极的送货体验。

| *积极* 评价者收到的产品早于预计的送货日期。

|

| 好产品，但收到的产品与广告中的照片不符。  | 3  | 中立  | *混合/中立* 评论提到产品不错（正面情感），但也指出收到的产品与广告中的照片不符（负面情感）。这种情感的组合使得整体情感为混合或中立。

| *混合* 评论者表示产品不错，但与广告中的照片不符。

|

| 我想知道为什么我的产品还没有到达我的住处，没有人给我满意的答复或类似的东西。  | 1  | 负面  | *负面* 客户表达了对产品尚未到达其住处以及他们没有收到任何解释或关于延迟的沟通的不满。这表明了在配送和客户服务方面的负面体验。

| *负面* 评论者尚未收到产品，也没有收到卖家的任何更新。

|

如表格所示，ChatGPT 4 和 Gemini Advanced 都完美地理解了评论。这个小型实验的结果令人鼓舞，值得进一步探索直接应用生成式 AI 与第 5.5.4 节中概述的基本情感分析技术之间的比较。在该节中，最简单的关键词搜索（列表 5.6）成功识别出大约 47% 的灵敏度以及高达 90% 的特异性。

您将看到直接利用生成式 AI 的语言能力是否能产生更好的结果。我们示例数据集中的评论评分将再次用作评估分析质量（通过计算灵敏度和特异性）的参考点。但在我们得出任何结论之前，我们需要使用其 API 在更大的样本上直接进行情感分析。

### 6.2.3 使用生成式 AI API 进行情感分析

为了评估生成式 AI 在更广泛范围内检测情感的能力，我们将使用 ChatGPT 4 API。有关 API 使用详情，请参阅第一章。还重要的是要注意，访问 API 可能需要订阅或特定的定价计划。您的目标是让 ChatGPT 评估数据集中前 500 个非空评论的情感，并将这些结果与第 5.5.4 节（列表 5.6）中进行的基于关键词的基本情感分析结果进行比较。

以下代码演示了如何利用 ChatGPT 4 的内在语言能力通过 API 对评论进行情感分析。为了使其生效，您需要将 `your-api-key` 替换为您的实际 ChatGPT API 密钥，并确保您的账户有足够的资金。幸运的是，您也可以在 GitHub 仓库的 Sentiment_Analysis_500reviews.csv 文件中找到此分析的结果。

##### 列表 6.1 使用 ChatGPT 的内在语言能力进行情感分析

```py
from openai import OpenAI
*# Replace 'your_openai_api_key' with your actual OpenAI API key*
client = OpenAI(
    api_key= "your-api-key",
)
def get_sentiment(review):
    response = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": f"The sentiment of this review is: {review}",
            }
        ],
        model="gpt-4-0125-preview",
    )
    completion = response.choices[0].message.content
    if "positive" in completion:
        return "positive"
    elif "neutral" in completion:
        return "neutral"
    elif "negative" in completion:
        return "negative"
    else:
        return "unknown"
*# Analyze the reviews and store the output (manually adapted)*
sentiments = []
for review in reviews:
    sentiments.append(get_sentiment(review))
df["GPT4"] = sentiments
```

上述代码很简单。对于 DataFrame 中存储的 500 条评论中的每一条，我们通过 API 向 ChatGPT 发送以下提示：“这篇评论的情感是：”，并附加实际的评论文本。然后模型生成一个响应，如果它包含“positive”这个词，则将其分类为正面。使用“negative”和“neutral”术语分别识别负面和中性情感。如果没有找到这些单词，则评论不会被分配任何情感。请注意，这种方法分析 ChatGPT 的响应相当基础，可能会忽略更细微的答案，例如那些表明评论中存在混合情感的答案。尽管这种方法很简单，但它仍然可以产生显著的结果，如表 6.2 所示。

##### 表 6.2 使用 ChatGPT 4 API 进行情感分析的质量

| 情感分析（n=500） | 被分类为正面的评论数量 | 敏感性 | 特异性 |
| --- | --- | --- | --- |

| 参考评论分数 | 320 (64%) 真阳性

| 1 | 1 |
| --- | --- |
| 基本关键词搜索 | 163 (33%) | 0.45 | 0.9 |
| ChatGPT 4 API | 250 (50%) | 0.74 | 0.93 |

与我们之前的方法一样，你可以使用数据集中的`review_score`变量来评估提取正面评论的敏感性和特异性。任何获得 4 或 5 分的评论都被认为是正面的。显然，使用`review_score`变量进行的情感评估获得了敏感性和特异性为 1，因为这是我们基准。

表 6.2 中所示的结果表明，基本关键词分析和利用 ChatGPT 4 API 的方法都表现出非常高的特异性，超过 0.9。这意味着这两种方法很少将负面或中性评论误分类为正面。此外，ChatGPT 4 显示出显著更高的敏感性（0.74），捕捉到了基本关键词搜索遗漏的许多正面评论。在前一章中，我们尝试提高提取正面评论的敏感性，但取得了有限的成果。尽管我们采用了更先进的清洗评论技术、应用词形还原和使用预定义的葡萄牙语情感分析词典，但我们只成功提高了几个百分点的敏感性。然而，通过利用 ChatGPT 4 来确定评论的情感，我们成功地将敏感性提高了超过 20%！这一显著改进即使在模型响应的最基本解释下也实现了，尽管代价不菲。鉴于 ChatGPT API 根据令牌使用量收费，分析大量真实数据——不仅仅是 500 个样本评论，而是数千条——可能带来财务挑战，引发对其成本效益的质疑。虽然我欣赏这种方法简单有效，但可能还为时尚早向财务部门申请额外资金。

在这个关键时刻，我们必须认识到，当 ChatGPT 被询问关于情感分析或任何它因“阅读”理解能力而天生能够执行的任务时，它的典型建议通常围绕指导你编写特定的代码来完成当前任务。该模型可能会强调传统 NLP 方法的优点，强调它们在分析细微和特定数据等方面的能力。然而，在实践中，遇到的大部分数据相对标准，并且主要是英语，正如所展示的，这些数据可以通过生成式 AI 快速有效地分析。这种分析的主要缺点是涉及的时间和成本，以及对外部方可能随时修改或更新的工具的有限控制。

对生成式 AI 的常见批评是其“黑箱”性质，在响应生成方式和依据方面提供有限的可透明性。当将生成式 AI 的性能与基本 NLP 工具如关键词搜索进行比较时，这种论点是有效的。然而，一旦我们开始使用任何规模的训练语言模型，这种论点就变得不那么有说服力了。尽管如此，是否可以认为，具有高级“阅读”能力的生成式 AI 是解决 NLP 任务的最佳选择？一年前（在 ChatGPT 4 API 的 API 访问可用之前），我们使用早期的 OpenAI 模型进行了类似的测试，结果并不令人印象深刻。我们更倾向于传统的 NLP 方法。然而，随着生成式 AI 技术的进步，我们对这一问题的信心有所减弱。

说到这里，让我们继续探讨使用传统和成熟的机器学习方法进行情感分析。在下一节中，我们将探讨借助预训练模型，我们能否达到 ChatGPT 4 API 所提供的结果那样引人入胜。

### 6.2.4 使用机器学习进行情感分析

之前，你学习了如何使用频率分析、关键词搜索或基于词典的方法等最简单的情感分析方法。虽然掌握这些基础技术仍然至关重要，尤其是对于不太常见的研究语言，但现实是，对于大多数日常任务，更复杂的方法，如机器学习，更受欢迎。

机器学习已经存在了一段时间，不应该让那些自称数据分析师的人感到害怕。那个只要精通 Excel 就足够了的年代已经过去了；如今，教会计算机识别模式已经成为一项常规任务。幸运的是，随着新技术的出现，库、管道和模型，有效利用这些模型比过去容易得多。虽然了解底层机制，如矩阵乘法，是有益的，我们鼓励深入研究这些概念，但深入的技术掌握不再是有效使用这些模型的先决条件。这种情况类似于开车：了解发动机的工作原理并不是成为一名合格司机的必要条件，但在某些情况下，这种知识可以帮助你避免事故或防止你的汽车修理工欺骗你。而且，你不必自己组装汽车就能驾驶它！大多数人通过购买和销售交易获得车辆。预训练的机器学习模型甚至更容易获得，许多模型都可以在线免费获得。

#### 我在哪里可以找到我的模型？

因此，在寻找一个新、亮、快、安全且无碰撞的模型时，您有哪些选择？一如既往，您可以使用传统的网页浏览器，或者通过与您选择的生成式 AI（如 Gemini，如前所述推荐）讨论您的需求来节省时间。然而，所有这些努力很可能会在任何情况下都将您引导到 Hugging Face 网站([`huggingface.co/`](https://huggingface.co/))。

Hugging Face 网站为 AI 从业者提供了一个中央枢纽，提供针对自然语言处理和机器学习的丰富资源。其核心是模型库，用户可以探索和下载适用于各种 NLP 任务的预训练模型，例如情感分析、文本生成和语言翻译。该网站还提供全面的文档和教程，以帮助开发者将这些模型集成到他们的项目中。此外，Hugging Face 平台鼓励社区参与，使用户能够分享自己的模型并与他人合作。

虽然 Hugging Face 模型是推进 NLP 任务的强大工具，但您应该谨慎行事。已经有人提出了一些模型可能包含漏洞或恶意代码的担忧。尽管该平台对上传的内容进行恶意软件扫描并积极移除任何恶意代码，但网络安全竞赛仍在继续。恶意行为者不断寻求新的安全漏洞以利用。为了避免成为这场网络冲突的无意识受害者，主动保护您的安全至关重要。以下十项安全戒律不仅适用于 Hugging Face 模型，也适用于从网络下载的任何模型（或软件）：

1.  *使用经过验证的模型*—优先选择平台验证的模型或来自知名组织的模型。

1.  *审查模型文档*—仔细阅读模型的文档，寻找潜在的红旗。

1.  *检查贡献者声誉*—研究模型的贡献者以确保他们是可信赖的。

1.  *进行安全评估*—使用安全工具扫描模型中的漏洞或恶意代码。

1.  *隔离测试*—在安全、隔离的环境中测试新模型，远离敏感数据或系统。

1.  *关注社区反馈*—关注关于特定模型或贡献者的社区反馈和报告。

1.  *定期更新*—保持您的模型及其依赖项的最新状态，以确保您拥有最新的安全补丁。

1.  *限制权限*—在将模型集成到您的系统中时，授予它们执行其功能所需的最小权限。

1.  *使用加密*—加密敏感数据，以防恶意模型意外泄露。

1.  *保持信息更新*—定期关注 Hugging Face 和更广泛的 AI 社区的最新更新和安全建议。

另一个寻找适用模型的流行选项是 GitHub（https://github.com/）。这个庞大的仓库托管着来自世界各地开发者和研究者的众多预训练模型。虽然 GitHub 为各种任务提供了广泛的选择，但你应该像对待 Hugging Face 模型一样谨慎对待它。GitHub 的开放性意味着任何人都可以上传代码，这可能会包含潜在的安全漏洞或恶意内容。这十诫可以作为实现最大安全的指南。

#### 如果我需要的模型不存在怎么办？

理论上是这样，但现实生活要复杂得多。如果你的梦想中的新、亮、快、安全且无碰撞的模型不存在，你应该怎么办？让我们回顾一下我们的例子。如果我们的评论是用标准英语写的，找到执行情感分析的预训练模型会很简单。然而，我们的输入是葡萄牙语，这为我们探索额外的选项提供了机会。

我们在执行所需分析时有哪些替代方案，尤其是在处理不太常用的语言时？如果我们的任务非常复杂，比如评估一个笑话的政治正确性如何？或者如果我们结合两者，处理评估用韩国语（比如，北方方言）写的笑话的政治正确性的任务呢？（在你继续之前，我们建议咨询你最喜欢的生成式 AI 关于开发此类模型的潜在影响，并考虑你是否真的应该参与其中。）

这里有一些选项：

+   *寻找次优模型*——无论你的任务或语言多么不常见，这都应该是你的起点。总是值得检查是否有人已经解决了类似的，但可能不是完全相同的挑战。为什么要重新发明轮子呢？探索像 Hugging Face 模型库和 GitHub 这样的资源，使用网络浏览器，或者请生成式 AI 协助你的搜索。虽然你可能对找到的任何现有模型都不完全满意，但它们可以为你进一步的努力提供有价值的基准。

    这种方法的优点包括时间效率，因为它可以让你避免从头开始。此外，它还提供了通过分析现有模型进行学习和改进的机会。然而，缺点可能包括寻找完全符合你特定需求的完美匹配的挑战，模型性能或适应性的限制，以及依赖于可能没有积极维护或更新的模型的风险。

+   *将输入翻译成英语*—这是一种在较少见语言上执行 NLP 任务的实用方法，利用自动翻译工具并应用英语训练的模型。这种方法受益于英语模型的广泛可用性和复杂性，增强了准确分析的可能性。然而，它存在失去细微差别和文化背景的风险，可能由于翻译不完美而引入错误或偏见。生成式 AI 可以通过提供更准确的翻译并预处理文本以更好地与英语训练模型对齐来减轻这些挑战，从而保留更多原始意义并减少与翻译相关的误差。

+   *使用多语言模型*—如果你找不到针对你的任务和语言专门微调的模型，另一种有效的方法是使用多语言模型，如 XLM-RoBERTa 或多语言 BERT。这些模型在涵盖广泛语言的大量数据集上训练，使它们能够同时理解和处理多种语言，而无需针对特定语言进行训练。这种方法使它们非常灵活，当没有特定任务或语言的模型可用时，它们是一个有效的解决方案。使用多语言模型的主要优势在于它们的广泛适用性，节省了为每种语言开发或寻找模型的努力，并在各种 NLP 任务中提供可接受的表现。然而，由于它们的通用性，这些模型在某些任务或语言上的性能可能无法与专用模型相匹配。此外，为高度特定或细微的任务进行定制可能很复杂。

+   *利用零样本学习模型*—这些模型经过训练，能够理解自然语言中的指令，在利用语义知识和概念之间的关系泛化到它们未明确训练的任务上表现出色。这使得它们能够根据从相关任务中获得的理解，推断例如从未直接接触过的类别或上下文中的文本的情感。然而，尽管零样本学习模型提供了使用单个模型处理广泛任务的灵活性，但它们的性能可能并不总是与针对特定任务微调的模型相匹配，尤其是在高度细微或特定领域的上下文中。

+   *微调现有模型*—当数据收集资源有限时，这是一个实用的选项，允许你通过任务特定的调整来增强预训练模型。这种方法时间效率高，成本低，并降低了高级建模技术的门槛。然而，这取决于预训练模型与你的任务的关联性以及用于微调的标记数据的质量。如果调整不当，也存在过拟合的风险。

    对于 NLP 任务，你可能考虑微调现有的 LLM 之一，例如在 Hugging Face 平台上广泛认可的 BERT。这类 LLM 已经在大量的文本语料库上进行了预训练，并具有对语言的全面理解，可以通过相对较小的数据集进一步定制以适应特定的 NLP 任务。这可以减少所需的工作量和专业知识，尽管仍然需要计算资源和理解模型行为。

    如往常一样，生成式 AI 可以通过提供帮助和专业知识来显著简化这一过程。但在这个案例中，它们可以提供更多。由于本书中讨论的所有生成式 AI 本身都是 LLM，它们可以成为你正在开发的模型的语料库基础。换句话说，你可以微调生成式 AI 以适应你的特定任务！

+   *训练自己的模型*——这个选项涉及收集足够数量的标记数据并自行训练模型。这种方法允许根据数据集和任务的特定细微差别定制和优化模型。主要优势是模型直接从反映你领域的数据中学习，因此具有高准确性和针对特定用例的相关性。然而，缺点包括收集标记数据、设计和有效训练模型所需的显著时间、努力和专业知识。这些挑战在生成式 AI 提供的任何帮助下仍然存在。此外，这种方法还需要大量的计算资源。

让我们测试这些选项中的几个，并比较它们的结果。微调现有模型和从头开始训练需要更多的专业知识，这超出了本书的范围。然而，如果你选择这条路线，生成式 AI 可以通过提供定制化的指导、资源和工具来提供重大帮助。此外，你可以参考 Sebastian Raschka 的《构建大型语言模型（从头开始）》一书（Manning，2024），以获取进一步的操作指导和洞察力。

### 6.2.5 使用次优模型进行情感分析

为了尝试第一种选项，即寻找一个次优模型，你可以先搜索现有的葡萄牙语情感分类器，但这次尝试并未成功（截至 2024 年 3 月）。与 ChatGPT 4 和 Gemini Advanced 的咨询提供了一些建议，但没有一个完全满足我们的要求，而且许多提供的链接都是无效的。两个生成式 AI 最终建议手动在 Hugging Face 网站和 GitHub 上搜索合适的模型，但遗憾的是，这项任务并没有带来任何显著发现。

因此，你可以选择 Gemini 提出的次优解决方案——在葡萄牙语财经新闻上训练的 FinBERT-PT-BR 分类器。尽管这不是分析客户评价的理想数据集，但人工介入的方法和错误监控可能有助于你识别和解决模型的不足。总的来说，即使如此，继续使用此模型并评估其有效性可能还是有用的。

首先，让我们充分认识到这种方法的潜在缺点。为了实现这一点，你可以先向 ChatGPT 提出以下问题：

**![image](img/Init-MA.png)**我有一个包含客户评价的`review_comment_message`列的数据框，这些评价是用葡萄牙语写的。我想使用这个网站上找到的情感分类器来提取正面评价：[`huggingface.co/lucas-leme/FinBERT-PT-BR`](https://huggingface.co/lucas-leme/FinBERT-PT-BR)

使用此模型进行我的任务的潜在缺点是什么？

**![image](img/Response.png)**[...] 可能的缺点：

1.  领域不匹配：FinBERT-PT-BR 专门用于财务环境，这可能与一般客户评价不太相符。

1.  情感分析复杂性：该模型可能在讽刺或文化表达等细微差别上遇到困难，影响准确性。

1.  语言特异性：葡萄牙语的区域差异可能导致不同葡萄牙语地区的表现不一致。

1.  模型偏差：预训练模型会从其训练数据中携带固有的偏差和局限性，这可能会扭曲结果。

1.  计算需求：使用基于 transformer 的模型处理大量评价需要大量的计算资源。

1.  道德考量：确保对客户评价进行道德和尊重隐私的使用至关重要。

简而言之，虽然 FinBERT-PT-BR 提供了一个有趣的解决方案，但其财务焦点、潜在的语言和区域局限性、计算需求以及进行道德审慎的必要性，为从一般客户反馈数据集中提取正面评价带来了显著的挑战。

这场对话说明了与生成式 AI 讨论你的分析想法的潜在好处。值得注意的是，ChatGPT 能够对一个它之前不熟悉的资源提出有见解的评论。此外，ChatGPT 坚称它没有使用提供的链接进一步调查该模型的网站以获取更多信息。这引发了一个问题：它是如何知道的？在询问后给出的解释是惊人的：

您根据“FinBERT-PT-BR”这个名字进行了一些过度推断，从“Fin”前缀推断，这通常表示与金融相关的模型（例如，FinBERT 是 BERT 在金融文本上的一个知名改编）。这种假设是，鉴于其名称，这个模型专门用于分析葡萄牙语的金融文本。这种命名规范对于 BERT 和其他语言模型的特定领域版本来说是典型的，其中前缀或后缀表示模型的专门训练语料库或预期应用领域。然而，由于我截至 2023 年 4 月的最后更新没有直接访问提供的链接或对这种模型的具体知识，我依赖这些规范来提供我的回答。

如果这不是纯粹智能的展示，那么我就不确定什么是了。然而，即使你不分享我的惊奇感，现在应该很清楚，在规划你的研究时咨询像 ChatGPT 4 这样的高级生成式 AI 绝对不是浪费时间。

##### 生成式 AI 解释外部资源

询问生成式 AI 是否使用特定的外部资源（如模型、数据库等）进行你的研究是合理的，或者讨论与特定资源相关的潜在缺点可能是有益的。即使生成式 AI 第一次遇到这个资源，也有可能推断出资源的内容以及它可能如何影响你的分析。

让我们的生成式 AI 准备一个代码片段。我们在同一个 ChatGPT 会话中使用了以下提示：“提出一个代码片段，利用这个模型从我的数据中提取正面评论。”获得的代码片段如下所示。

##### 列表 6.2 使用次优模型提取正面评论

```py
import pandas as pd
from transformers import pipeline

*# Assuming df is your DataFrame and it has a column named* 
↪*'review_comment_message'*
*# Load the sentiment analysis pipeline with the FinBERT-PT-BR model*
classifier = pipeline("sentiment-analysis", 
↪model="lucas-leme/FinBERT-PT-BR")
def get_sentiment(review):
    try:
        result = classifier(review)[0]
        return result['label'], result['score']
    except Exception as e:
        print(f"Error processing review: {e}")
        return None, None
*# Apply the sentiment analysis to each review*
df['sentiment'], df['score'] = 
↪zip(*df['review_comment_message'].map(get_sentiment))
*# Filter the DataFrame to only include positive reviews*
positive_reviews_df = df[df['sentiment'] == 'LABEL_1']  
*# Assuming 'LABEL_1' is positive; adjust label as necessary based on model*
*↪output*
*# Now positive_reviews_df contains only the positive reviews*
```

这段代码片段提供了如何安装所需库的说明，以及一个强调咨询模型文档以了解模型输出的重要性的详细注释。具体来说，需要手动将`LABEL_1`替换为适当的标签，表示正面评论，在我们的例子中是`POSITIVE`。生成式 AI 还详细说明了在分类器周围使用异常处理来管理处理过程中可能出现的任何潜在错误，例如输入过长或意外。

在书籍 GitHub 仓库的 Jupyter 笔记本中，你可以找到这个代码手动修改并应用于分析测试数据集的前 500 条评论。和以前一样，`review_score`变量被用来评估分类器的敏感性和特异性。FinBERT-PT-BR 模型以 0.56 的敏感性和 0.93 的特异性识别正面评论。这种性能超过了基于简单关键词的分类，但还没有达到通过直接应用 ChatGPT 4 的语言能力所达到的效果。

### 6.2.6 翻译输入的情感分析

现在你可能想探索翻译输入并使用英语文本的情感分类器是否会产生更好的结果。这种解决方案的优缺点已在第 6.2.4 节中列出，所以让我们直接进入实施阶段。

我们从一个具体的提示开始：“编写一个代码片段，从我们的数据集中提取正面评论。清理评论并将它们翻译成英语，然后应用最合适的英语情感分类器。”然后我们探索了几个选项，以确定翻译输入的最佳方法，目标是找到一个简单且可靠的解决方案，不需要注册或付费。最终，在生成式 AI 的帮助下，我们开发了以下代码片段。

##### 列表 6.3 对翻译输入进行情感分析

```py
import pandas as pd
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, 
↪pipeline
[...]
*# Initialize the M2M100 tokenizer and model for translation*
tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M")
model = 
↪M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")
*# Initialize the sentiment analysis pipeline*
sentiment_pipeline = pipeline('sentiment-analysis', 
↪model='distilbert-base-uncased-finetuned-sst-2-english'
)
def translate_review(review):
 *# Specify the source and target language*
    tokenizer.src_lang = "pt"
    encoded_pt = tokenizer(review, return_tensors="pt")
    generated_tokens = model.generate(**encoded_pt, 
    ↪forced_bos_token_id=tokenizer.get_lang_id("en"))
    translated_review = tokenizer.decode(generated_tokens[0], 
    ↪skip_special_tokens=True)
    return translated_review
def analyze_sentiment(review):
    result = sentiment_pipeline(review)[0]
    return result['label'], result['score']
*# Translate reviews from Portuguese to English*
df['translated_review'] = 
↪df['review_comment_message'].apply(translate_review)
*# Apply sentiment analysis to the translated reviews*
df['sentiment'], df['score'] = 
↪zip(*df['translated_review'].apply(analyze_sentiment))
*# Filter the DataFrame to only include reviews with positive sentiment*
positive_reviews_df = df[df['sentiment'] == 'POSITIVE']
*# positive_reviews_df now contains only the positive reviews, translated* 
↪*into English*
```

代码使用 Meta 模型进行翻译，m2m100_418M，支持包括葡萄牙语和英语在内的多种语言。对于情感分析，它使用 distilbert-base-uncased-finetuned-sst-2-english 模型。这两个模型都由生成式 AI 推荐，因为它们的广泛适用性和性能。然而，需要注意的是，我们可能需要考虑探索更适合我们特定需求的其它模型。

虽然代码执行顺利，但翻译 500 条评论花费了一些时间，所以如果你打算复制这个过程，请耐心等待。我们再次使用`review_score`变量评估了这种方法在识别正面评论时的敏感性和特异性。相应的代码可以在书籍 GitHub 仓库中的 Jupyter 笔记本中找到。值得注意的是，这种翻译输入的方法在正确分类正面评论时达到了 0.86 的敏感性和 0.89 的特异性，是目前为止的最佳结果，并且与使用 ChatGPT 4 的内置语言能力获得的结果相当。确实不错。

### 6.2.7 使用多语言模型进行情感分析

我们下一步要探索的是，使用多语言模型进行情感分析是否会产生更好的结果。这类模型的特点以及它们的潜在缺点在第 6.2.4 节中已有介绍，所以让我们继续实施。

我们使用了提示，“现在，我想重复这个练习，但不是翻译输入，我更愿意使用多语言模型。你能为我编写一个相关的代码片段吗？”不幸的是，由于包依赖问题，获得的代码无法立即工作。我们并没有手动解决这些问题或仔细审查整个错误日志，而是简单地复制了错误消息的最后几行到生成式 AI 聊天窗口以寻求帮助。ChatGPT 用简单的英语阐明了问题——比错误消息中常见的典型技术术语更有帮助——并提出了两个解决方案：要么降级一个包，要么升级另一个，这迅速解决了问题。

随着你在这本书中的学习进展，你可能会遇到类似的情况，其中软件包会演变，今天的代码明天就可能过时。通常，解决方案需要微小的调整，这些调整可能只需几秒钟就能实现，但可能需要数小时才能找到。有了生成式 AI，你可以超越无休止地滚动 Stack Overflow 以获取调试提示。

##### 生成式 AI 是除虫的终极工具

想象一下最致命、最无情的杀虫剂。将其有效性乘以一千倍，你仍然无法捕捉到生成式 AI 在解决 bug 方面的全部熟练程度！与其试图自己解码错误信息，不如简单地将其（或片段）粘贴到模型的聊天中，并请求将其翻译成人类语言以及相应的解决方案。在大多数情况下，你会收到迅速且令人满意的回复。

在解决所有依赖项错误并手动纠正输出标签后，我们得到了以下可运行的代码片段（别忘了安装所需的库）。

##### 列表 6.4 使用多语言模型进行情感分析

```py
import pandas as pd
from transformers import pipeline
*# Assuming df is your DataFrame and it has a column named* 
↪*'review_comment_message'*
*# Initialize the sentiment analysis pipeline with the multilingual model*
sentiment_pipeline = pipeline('sentiment-analysis', 
↪model='cardiffnlp/twitter-xlm-roberta-base-sentiment')
def analyze_sentiment_multilingual(text):
    result = sentiment_pipeline(text)[0]
    return result['label'], result['score']
*# Apply sentiment analysis to the reviews*
df['sentiment'], df['score'] = 
↪zip(*df['review_comment_message'].apply(analyze_sentiment_multilingual))
*# Filter the DataFrame to only include positive reviews*
positive_reviews_df = df[df['sentiment'] == 'positive']
*# positive_reviews_df now contains only the reviews classified as positive*
```

此脚本利用 twitter-xlm-roberta-base-sentiment 模型直接对数据集中的每个评论进行情感分类，无需先将它们翻译成英语。它达到了 0.79 的敏感度和 0.93 的特异性，这些分数与使用 ChatGPT 4 的内在语言能力所达到的分数相当。这一发现表明，我们已经找到了一个质量相似但成本效益更高、速度更快的解决方案，比使用生成式 AI API 更优。然而，在你急忙向老板要求加薪之前，让我们探讨一下，我们是否可以通过利用零样本学习模型来超越这一性能。

### 6.2.8 使用零样本学习模型进行情感分析

提醒一下，零样本学习模型特别适合于标记的训练数据稀缺或不可用的情况。这些模型可以泛化到它们未明确训练过的任务，使它们非常适合于将文本分类到类别中（如情感分析），而无需特定于该任务的数据库。对于使用零样本学习方法从我们的葡萄牙语数据集中提取正面评论，你可以利用为多语言理解设计的模型，例如通过 Hugging Face Transformers 库提供的模型。

所有这些，以及更多，当你向生成式 AI 提出类似以下问题的时候，你将学到：“我想在零样本学习模型的帮助下从我的数据集中提取正面评论。评论是用葡萄牙语写的。我该如何实现这一点？”作为回应，ChatGPT 4 生成了以下代码，该代码已被手动调整以适应我们的输入数据。要运行此代码，您需要使用命令`pip install transformers`安装 transformers 库。

##### 列表 6.5 使用零样本学习模型进行情感分析

```py
from transformers import pipeline
import pandas as pd
*# Load the zero-shot classification pipeline*
classifier = pipeline("zero-shot-classification", 
↪model="facebook/bart-large-mnli")
*# Specify the candidate labels*
candidate_labels = ["positive", "negative"]
*# Define a function to classify a single review*
def classify_review(review):
    result = classifier(review, candidate_labels=candidate_labels, 
    ↪hypothesis_template="This review is {}.", multi_label=False)
    return result['labels'][0]
*# Apply the classification to each review*
df['sentiment'] = df['review_comment_message'].apply(classify_review)
*# Filter the DataFrame to only include positive reviews*
positive_reviews_df = df[df['sentiment'] == 'positive']
```

由生成式 AI 提出的代码使用了 facebook/bart-large-mnli 模型，该模型能够处理多语言文本，并在 Multi-Genre Natural Language Inference (MNLI)数据集的变体上进行了训练。这使得模型能够对包括葡萄牙语在内的各种语言的文本进行零样本分类。然而，ChatGPT 指出，这个模型仅作为一个示例，我们可能会发现其他模型，对于特定数据集来说可能产生更好的结果。例如，typeform/distilbert-base-uncased-mnli 模型被提出作为一个替代方案，它更小、更快，尽管可能不太精确。

零样本学习模型的有效性是通过`review_score`变量来评估的。该模型在识别正面评论时达到了 0.87 的敏感性，以及 0.74 的特异性。虽然这种性能略逊于多语言模型，但它仍然足够稳健，值得在分析中考虑零样本学习模型。

### 6.2.9 比较高级情感分析的结果

在前几节中，我们探讨了使用预训练机器学习模型进行情感分析的几种方法。最初，我们利用 ChatGPT 4 固有的语言能力来识别正面评论（第 6.2.3 节）。随后，我们采用了一个针对葡萄牙语金融文本情感分析的低效预训练模型（第 6.2.5 节）。接下来，我们使用了一个为英语设计的情感分类器，并将其应用于翻译后的输入（第 6.2.6 节）。为了规避翻译引入的错误和偏差，我们选择了多语言模型（第 6.2.7 节）和能够支持多种语言的零样本学习模型（第 6.2.8 节）。这些方法在包含 500 条非空评论的数据集上进行了测试，使用`review_score`变量来评估分类的敏感性和特异性。所有结果都汇总在表 6.3 中。

##### 表 6.3 使用不同预训练模型的情感分析质量

| 情感分析（*n*=500） | 被分类为正面的评论数量 | 敏感性 | 特异性 |
| --- | --- | --- | --- |

| 参考评论评分  | 320 (63%) 真阳性

| 1  | 1  |
| --- | --- |
| 基本关键词搜索  | 163 (33%)  | 0.45  | 0.9  |
| ChatGPT 4 API  | 250 (50%)  | 0.74  | 0.93  |
| 低效模型  | 193 (39%)  | 0.56  | 0.93  |
| 翻译后的输入  | 295 (59%)  | 0.86  | 0.89  |
| 多语言模型  | 265 (53%)  | 0.79  | 0.93  |
| 零样本学习模型  | 325 (65%)  | 0.87  | 0.74  |

这些结果表明，在我们的测试中，多语言模型优于所有其他模型，独特地超越了 ChatGPT 4 API。一个支持多种语言的零样本学习模型达到了与生成式 AI 固有的语言能力相当的结果。同样，涉及翻译输入的方法也显示出高性能的潜力。相反，仅基于关键词搜索的分类在灵敏度方面明显落后，尽管更细致的关键词选择可能会提高其有效性。

值得注意的是，仅仅一年前，这样的评估结果会有很大不同，当时的 ChatGPT 3——当时通过 API 可用的唯一选项——甚至在性能上都无法匹配基本的关键词分析。想想看，如果 ChatGPT 5 最终发布，我们能实现什么？

总结来说，本节说明了如何使用各种高级预训练模型进行情感分析。选择适合你数据和任务的方法可能需要测试几个选项，通常是在数据的一个较小子集上进行，以确定最经济有效的策略，这可能会带来你一直渴望的晋升（想象一下：星期天不再需要量子泡沫伪装了！）。生成式 AI 可以通过提供选项列表、讨论它们的优缺点、编写必要的代码片段以实现它们，然后测试和总结结果来促进这一过程。在某些情况下，你可能会选择直接利用语言能力，通过访问它们的 API 或作为调整你自己的模型的基础来使用它们，尽管后者在本书中尚未探讨。

## 6.3 文本摘要

在前面的章节中，我们成功根据情感对评论进行了分类。从效率的角度来看，获得的结果可能并不完全令人满意，还需要进行额外的分析来增强所提出的基本方法。然而，假设你的老板对结果感到满意，并希望进一步探索。当前的问题是，客户最常抱怨什么？

这个任务与即将探索的另一种 NLP 方法非常吻合：文本摘要。这项技术旨在将长文档缩短为更简洁的版本，同时保持关键信息并使其连贯。通过使用基于规则的方法或机器学习等途径，文本摘要使用户能够迅速从大量文本集合中捕捉主要概念和相关信息。

### 6.3.1 你如何从文本摘要中受益？

你可以在各种商业场景中应用文本摘要来提高效率、改善理解和简化沟通。以下是一些例子：

+   *客户支持*—自动生成客户询问或来自电子邮件、聊天消息或社交媒体的反馈的简洁摘要，将有助于加快响应时间。即使普遍预期反馈将涉及对量子泡沫的投诉，但对其进行定量确认也是有价值的。

+   *高管简报*—总结冗长报告、财务分析或市场研究的关键点，以便高管和决策者快速审阅，可以帮助您的老板和他的同事引导公司走向辉煌和财务成功。如果您成功，您将获得一份……荣耀的份额。

+   *新闻聚合*—创建新闻文章的简短摘要不仅对新闻聚合应用或网站有益，也对您的公司有益。毕竟，了解量子泡沫市场的发展情况是任何重视其声誉的泡沫制造商的常规任务。

+   *法律文件审查*—您认为律师和其他法律专业人士在阅读他们密集的法律术语时会陷入狂喜，不是吗？然而，现实是他们会非常感激能够减轻这种负担。如果您能开发出一个总结法律文件、合同或案件文件的工具，帮助更快地掌握其核心内容，他们可能会用纪念碑来表彰您（您可以将它添加到您的养老金计划中，连同您之前获得的荣耀股份一起）。

+   *学术研究*—至于学者和研究人员呢？他们喜欢他们的科学术语吗？也许吧，但一个能够总结学术论文或期刊的工具，使人们能够快速理解前提、方法、结果和结论，而不必阅读全文，可能会受到学生、博士后以及那些仍然希望获得终身职位的科研人员的重视。特别是那些生存依赖于快速阅读和发表的人。 

+   *医疗记录摘要*—医疗专业人员是另一个可以从快速摘要中大大受益的群体，例如患者病史、实验室报告或临床发现。这可能有助于加快诊断并改善治疗计划。但受益的不仅仅是医生——患者也会受益。想象一下，如果您的医生有时间真正与您进行交谈，那将是多么愉快和人性化的体验！

+   *会议记录*—文本摘要技术可以将记录的讨论或会议记录简化为简洁、可操作的摘要，强调关键决策、行动项目和讨论点。然而，自愿开发这样的工具也伴随着风险。如果您的程序在公司内部揭露了一个众所周知但未公开的事实：许多会议实际上纯粹是浪费时间，那会怎样？

+   *电子邮件管理*——你还记得公司里关于订购哪种咖啡机的好长一段电子邮件对话吗？如果你有一个能够总结长篇电子邮件的工具，那么错过这个肥皂剧的几集就不再是问题。这个工具可以将讨论、决策或行动项目提炼成简洁的摘要，可能从“之前，在新咖啡机传奇中……”开始。

+   *内容营销*——有了新的量子蓬松功能来推广，无论怎样，你的营销部门都在拼尽全力。为什么不帮他们创建一个工具，可以生成博客文章、文章或白皮书摘要，用于通讯、社交媒体或营销材料，吸引读者并鼓励他们探索完整内容？

+   *产品评论分析*——总结产品或服务的客户评论和反馈可以帮助快速识别趋势、偏好和改进领域。这个目标与你的老板对你的期望一致，在接下来的章节中，我们将指导你如何满足这些期望。

这些例子说明了文本摘要如何成为各种行业的强大工具，有助于节省时间、减少信息过载并增强决策过程。

### 6.3.2 生成式 AI 如何帮助进行文本摘要？

生成式 AI 在高效有效地总结文本方面具有巨大的潜力。通过利用其对语言结构、上下文和语义的深入理解，生成式 AI 可以处理大量文本信息，并将其压缩成更短、更连贯的摘要。这种能力特别适用于提取最重要的信息并以易于消化的形式呈现，为您和您的同事节省大量时间和精力。

此外，生成式 AI 的高级自然语言处理能力使其能够生成两种类型的摘要：

+   *提取摘要*——这种方法涉及从文本中直接选择和编译关键短语或句子来创建摘要。例如，它可以总结新闻文章，提取涵盖谁、什么、何时、何地、为什么的最具信息量的句子。

+   *抽象摘要*——这些摘要重新表述原始文本，通常生成新的短语和句子，这些在初始文档中并不存在，以更创造性和流畅的方式捕捉其精髓。例如，可以将小说的情节压缩成一个概述，概述主要主题和情节点，而不直接引用文本。

两种类型的摘要都可以根据具体细节和原创性进行调整。此外，生成式 AI 对不同领域和语言的适应性使其成为广泛应用和行业的灵活工具。

然而，这种卓越并非没有缺陷。其中大部分在我们讨论选择生成式 AI 而非传统 NLP 方法的风险时已经提及。

+   *成本效益*—大规模部署基于生成式 AI 的解决方案可能速度较慢，但成本可能会迅速上升。

+   *缺乏控制*—对于许多公司来说，获取和维护表现最佳的生成式 AI 模型可能具有挑战性，导致他们依赖第三方。

对于生成式 AI 和传统 NLP 方法在文本摘要方面的更详细比较，包括它们的潜在缺点和权衡，请参阅表 6.4。

##### 表 6.4 文本摘要：生成式 AI 与传统 NLP 方法的比较

| 因素 | 生成式 AI | 传统 NLP 方法 |
| --- | --- | --- |

| 总结类型 | 提取式 • 当正确提示时可以生成提取式摘要，但它往往倾向于抽象式摘要

抽象式

• 处理整个文档，理解关键点和关系，并用自己的话生成传达基本意义的总结

• 可以重新表述观点，使用同义词，并改变句子结构

• 可以融入原文的整体情感或语气，或根据需求进行更改

| 提取式 | 选择最重要的单词和句子

• 优先考虑事实准确性

• 以清晰简洁的方式呈现主要思想

抽象式

• 使用预定义模板生成总结

• 通常不会生成全新的文本来创建总结

• 可能无法捕捉整体情感

|

| 计算效率 | 低 • 训练和推理计算成本高

| 高 | 训练和推理速度更快

|

| 可扩展性 | 低 • 可能难以处理长文档

• 可能需要大量资源来处理复杂的摘要

• 使用 API 速度慢且成本高

| 高 | 与更大的数据集具有良好的扩展性

• 使用成本相对较低

|

| 可解释性 | 低 • 难以理解模型如何得出总结

• 像一个黑盒

| 高 | 对所选句子的清晰图景

|

| 模型优化 | 复杂 • 需要复杂的技巧，如强化学习，以优化特定目标（例如，事实准确性，情感分析）

• 提示工程可能有助于设定摘要目标，但它不是完全确定的，需要监控

| 简单 | 可以通过简单的技术进行优化，例如优先考虑事实关键词或特定情感的句子评分函数

|

考虑到这些因素，你可能会在生成式 AI 提供的准确性、简单性和乐趣之间做出妥协，以开发更传统、尽管可能更适合您公司的解决方案。

### 6.3.3 使用 ChatGPT 进行文本摘要

让我们回到你老板的询问，并找出客户最常抱怨的问题。为了完成这个任务，你首先需要使用前几节中描述的方法之一来识别负面评论。为了演示目的，我们将采取捷径，使用由`review_score`变量确定的负面评论集，该变量之前被用来评估我们情感分析的有效性。一旦提取出负面评论，它们将接受文本摘要以获得更深入的见解。

这是个好机会来提及客户评论等文本的另一个潜在问题。随着全球化的扩展，你可以预期这些文本会出现在几十种语言中。当使用传统的 NLP 方法进行摘要时，评论应首先按语言进行聚类，然后翻译成一种共同语言（很可能是英语），然后才能进行进一步的分析。有了生成式 AI 的多语言能力，所有这些步骤都可以简化为提示中的一个提及，表明无论输入语言如何，你希望摘要使用你选择的语言。多么精彩！有了生成式 AI 在手，我们终于可以完成通天塔的建造，甚至可以通过短期出租来赚钱！

作为热身，让我们看看生成式 AI 如何总结我们示例数据集中最长的评论。

**![图片](img/Init-MA.png)**摘要以下文本“NÃO RECEBI O PRODUTO, O PRODUTO CONSTA COMO ENVIADO PARA O CORREIO DE RIBEIRÃO PRETO. O CORREIO NÃO RECEBEU O PRODUTO. ENVIE VARIAS MENSAGEM PARA A targaryen E NÃO OBTIVE. ESTA targaryen ESTA SUJANDO SEU NOME”。在摘要中使用葡萄牙语。为原文和摘要提供英语翻译。

**![图片](img/Response.png)**以下是使用基于提取最频繁单词的简单非机器学习方法对给定文本的摘要：

[...]

摘要（英文翻译）：

“产品未收到，邮局未收到，targaryen 无回应。”

请注意，这个摘要相对简单，可能无法捕捉原文的所有细微差别。为了获得更准确和连贯的摘要，你可以使用更高级的技术，如 TextRank，或者基于机器学习的方法。

这个回应快速，容易获得，且全面。你可以进一步使用你喜欢的生成式 AI，让它生成更长或更短的摘要，评论标题和评论描述，这些描述以你最喜欢的作者的风格写成，或者你可以甚至要求它将你无聊的评论变成像这样漂亮的俳句：

产品从未收到，

给 targaryen 的消息，

寂静，名誉受损。

记得查克·帕拉纽克的《搏击俱乐部》中的主角吗？他通过向所有员工传播俳句来对抗办公室的无聊？现在，凭借你新获得的知识，你可以利用生成式 AI 开发一个简单的应用，将负面反馈以这种优雅的形式发送给不满意的客户。至少，他们不应该再抱怨没有回应了。然而，不要期待在这项练习后老板会给你表扬。

### 6.3.4 使用专用库进行文本摘要

在选择自然语言处理摘要技术时，你的选择应主要取决于要摘要的文本的类型和长度。对于像书籍这样的长篇文本，抽象摘要技术通常更为合适。这些方法可以通过理解和改写关键概念来生成简洁的概述，这使得它们非常适合捕捉长篇叙述或详细讨论的精髓，而无需大量引用原文。对于科学文章或技术文档，提取和抽象方法的结合可能最佳，即提取重要的句子或术语（提取），然后将这些元素综合成一个连贯的摘要（抽象），以捕捉文档的主要发现和影响。转向更短的文本，如新闻文章或博客文章，提取摘要可能更有效，可以直接从源头识别和编译最有信息量的部分。

对于像客户评价这样的短文本，可能更倾向于集中提取主要关键词或主题，而不是创建摘要。情感分析结合关键词提取通常能提供足够的洞察力。实际上，鉴于前几节中的练习，你应该一般知道从负面评论的文本摘要中可以期待什么。

至于具体的方法，文本摘要技术通常可以分为两类：基于规则的方法和机器学习方法。每种方法都提供了生成文本摘要的独特方法，各有其优势和局限性。

基于规则的方法依赖于预定义的语言规则和启发式方法，如句子长度、位置和关键词的频率，以提取重要句子。虽然这些方法简单易懂，但可能过于僵化，可能无法适应不同文本的细微差别。以下是生成提取摘要的最常见的基于规则的方法：

+   *句子评分和提取*——这种方法根据预定义的标准对句子进行评分，例如句子的位置和关键词的存在。通常使用词频-逆文档频率（TF-IDF）根据重要术语的频率对句子进行评分。然后，将评分最高的句子组合起来形成摘要。

+   *TextRank*——PageRank 算法的一种变体，TextRank 将句子表示为图中的节点，边表示内容重叠。提取最中心的句子用于摘要。

+   *基于频率的方法*——这种方法识别并提取文本中的关键术语、*n*-gram 或短语，这些术语或短语代表了主要主题。然后，使用这些关键词来创建摘要。

+   *提示语方法*——利用特定的提示语（例如，“总之”，“总结”）来指示重要信息。包含这些提示语的句子被提取用于摘要。

+   *基于引言的摘要*——常用于新闻文章，这种方法涉及提取最初几句话或第一段，假设文本包含最重要的信息。

基于规则的途径也可以用于抽象摘要。然而，这需要基于规则的释义或预定义的模板，通过在文本中提取相关信息来填充槽位以生成摘要。正如你可能猜到的，输出并不像由生成式 AI 创建的抽象摘要那样流畅。

除了基于规则的途径，Python 提供了多种机器学习技术来总结文本：潜在语义分析（LSA）和潜在狄利克雷分配（LDA）可用于分析潜在主题，而预训练的语言模型如 BERT、文本到文本迁移转换器（T5）和双向自回归转换器（BART）可以针对特定任务进行微调。本书的范围不包括这些方法的详细信息和它们的能力，更不用说它们大多数是为其他目的而非总结像我们的评论这样简短的文本而设计的。然而，有了 Gensim、scikit-learn 和 Hugging Face Transformers 库等选项，你可以根据你的需求和文本类型选择合适的技巧。同时，生成式 AI 可以协助你并提供建议。

让我们重新审视我们的例子。为了了解传统自然语言处理方法如何总结评论，并将其与第 6.3.3 节中提出的直接方法进行比较，我们将使用一种简单的基于规则的技巧——基于频率的方法——来分析我们的负面评论。这种方法在去除停用词后识别最常见的单词，为每个评论中普遍关注的问题或关键词提供快速洞察。首先，我们将要求 ChatGPT 生成相关的 Python 代码，使用以下提示：“提供用于生成葡萄牙语非常简短客户评论摘要的 Python 代码。使用基于频率的方法。”经过对我们输入数据的某些调整后，生成的代码可以在本书 GitHub 存储库中的 Jupyter 笔记本中找到。

##### 列表 6.6 使用基于频率的方法总结最长的评论

```py
import pandas as pd
import nltk
import string
from collections import Counter
*# Download the required NLTK resources*
nltk.download('punkt')
nltk.download('stopwords')
*# Sample data (manually adapted to remove empty records)*
df = pd.read_csv('olist_order_reviews_dataset.csv')
df = df.dropna(subset = ['review_comment_message'])
*# Function to tokenize and remove stopwords*
def preprocess(text):
    stopwords = nltk.corpus.stopwords.words('portuguese')
    tokens = nltk.word_tokenize(text.lower())
    tokens = [token for token in tokens if token not in string.punctuation 
    ↪and token not in stopwords]
    return tokens
*# Function to create word frequency distribution*
def word_frequency(tokens):
    frequency = Counter(tokens)
    return frequency
*# Function to summarize short reviews*
def summarize_reviews(text, num_keywords=3):
    tokens = preprocess(text)
    frequency = word_frequency(tokens)
    important_words = [word for word, count in 
    ↪frequency.most_common(num_keywords)]
    summary = ' '.join(important_words)
    return summary
*# Apply the function to the DataFrame*
df['summary'] = df['review_comment_message'].apply(summarize_reviews)
*# Display the results (manually adapted to print the summary of the longest* 
↪*message)*
print("Longest review:", df.loc[1316]["review_comment_message"])
print("Summary:", df.loc[1316]["summary"])
```

生成式 AI 提出的代码运行良好，可以轻松地适应总结整个数据集中的评论。例如，6.3.3 节中示例评论的三个词摘要为“produto, correio, targaryen”（产品，邮件， targaryen）。在这个上下文中，“targaryen”，就像所有《权力的游戏》家族名称一样，是我们数据提供商匿名化商店名称的手段。

您可以通过修改前面代码中的`num_keywords`参数来生成更长、更有信息量的摘要。然而，我们认为，使用这种简单的基于频率的方法生成的输出并不像 ChatGPT 的俳句那样精确、简洁（甚至不有趣）。生成式 AI“手工制作”的直接三个词摘要似乎也好一些，尽管需要更严格的方法来评估哪种结果真正更优。

为了感受结果，您可以比较前五个评论的输出，这些评论收集在表 6.5 中。所有翻译均由 ChatGPT 提供。

##### 表 6.5 五个客户评论样本的摘要努力

| 翻译评论 | 基于频率方法的三个词摘要 | ChatGPT 4 的三个词摘要 | ChatGPT 的俳句 |
| --- | --- | --- | --- |

| 我在规定的截止日期之前就收到了。 | 收到得很好

在...之前

| 提前交付 | 在规定的截止日期之前就到达了

满意度

|

| 恭喜兰尼斯特商店，我喜欢在线购物，安全又实用。恭喜所有人，复活节快乐。 | 恭喜兰尼斯特

商店

| 兰尼斯特商店受到赞扬 | 兰尼斯特商店欢呼 安全又实用的购物

欢乐的复活节

|

| 高效设备。在网站上，设备品牌被标记为 3desinfector，但到达后，它有另一个名字... 更新为正确的品牌，因为这是同一设备。 | 高效品牌

设备

| 高效，标签错误设备 | 高效设备 错误命名但仍表现良好

使用真实品牌

|

| 但有点滞后... 对于价格来说，还不错。 | 稍微滞后

...

| 滞后，性价比高 | 稍微滞后出现，但价值依然稳固，

可接受的交易。

|

| 可靠的卖家，产品良好，且在截止日期前交付 | 可靠卖家

产品

| 可靠的卖家，响应迅速 | 信誉良好的卖家，产品符合预期，

提前交付。

|

##### 生成式 AI 提供提取和抽象摘要

虽然生成式 AI 可以执行两种类型的摘要，但其主要优势在于抽象摘要，因为它在大量文本数据上进行了训练，能够生成类似人类的连贯摘要。

另一个问题是，单独总结每条负面评价并不能有效解决你老板分配的任务。仍需要有人阅读所有总结并从中得出结论。为了更有效地解决这个问题，你可以采用另一种称为*主题建模*的方法，它有助于识别一系列文档（例如本例中的负面评价）中的共同主题和话题。

### 6.3.5 主题建模

主题建模本身不是一种文本摘要形式，但它可以用来生成一系列文档中主要主题和话题的高级摘要。虽然文本摘要技术旨在通过提取或生成最重要的句子或短语来创建单个文档的浓缩版本，但主题建模技术旨在揭示文本语料库中的潜在结构和主题。

主题建模可以帮助你理解一组文档中的主要主题及其分布，但它不会生成单个文本的易读摘要。相反，它将每个文档表示为一系列主题的混合，每个主题是单词的概率分布。

我们示例集中的负面客户评价是展示主题建模的理想候选，它可以将它们以方便、可读的形式进行总结。让我们先向 ChatGPT 请求相关代码，使用提示“我有一组存储在 pandas 数据框列中的简短负面客户评价。我想知道客户提出了哪些主要问题。如何从评价中提取这些信息？”

##### 列表 6.7 使用主题建模总结负面评价

```py
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
import re
*# Load data. Only negative reviews were chosen for the analysis* 
↪*(adapted manually).*
df = pd.read_csv('olist_order_reviews_dataset.csv')
df = df.dropna(subset = ['review_comment_message'])
df = df[(df["review_score"]==1) | (df["review_score"]==2)]
*# Preprocess the text*
def preprocess_text(text, language='portuguese'):
 *# Remove special characters, convert to lowercase*
    cleaned_text = re.sub(r'[^\w\s]', '', text.lower())
 *# Tokenize words*
    words = word_tokenize(cleaned_text, language=language)
 *# Remove stopwords*
    stop_words = set(stopwords.words(language))
    words = [word for word in words if word not in stop_words]
 *# Apply stemming*
    stemmer = SnowballStemmer(language)
    words = [stemmer.stem(word) for word in words]
    return words
df['preprocessed_reviews'] = 
↪df['review_comment_message'].apply(preprocess_text)
*# Loading the model.*
from gensim.corpora import Dictionary
from gensim.models import LdaModel
*# Create a dictionary and corpus for LDA*
dictionary = Dictionary(df['preprocessed_reviews'])
corpus = [dictionary.doc2bow(text) for text in df['preprocessed_reviews']]
*# Train an LDA model*
num_topics = 5  *# Adjust this value to the desired number of topics*
lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, 
↪random_state=42)
*# Displaying results (manually adapted to display 7 words).*
def display_topics(model, num_topics, num_words=7):
    for idx, topic in model.print_topics(num_topics, num_words):
        print(f"Topic {idx + 1}: {topic}\n")
display_topics(lda_model, num_topics)
```

提出的代码被手动修改，仅分析示例数据集中的负面结果（`review_score`为 1 或 2 的评价）。输出是提及频率最高的五个主题列表；然而，这些主题本身并没有以友好的形式呈现。幸运的是，我们手头有生成式 AI 来帮助我们阅读和解释那些本质上不是易读的。在这种情况下，直接向模型告知输入的负面性质会导致更好的结论。

**![image](img/Init-MA.png)**你能解释这个主题建模的输出吗？请提供英文翻译。请记住，输入仅包含负面客户评价：

```py
Topic 1: 0.055*"compr" + 0.043*"receb" + 0.032*"produt" + 0.020*"2" + 
↪0.019*"entreg" + 0.017*"apen" + 0.017*"ped"
Topic 2: 0.043*"entreg" + 0.035*"produt" + 0.035*"compr" + 
↪0.028*"receb" + 0.021*"agor" + 0.020*"praz" + 0.013*"falt"
Topic 3: 0.095*"produt" + 0.046*"receb" + 0.021*"entreg" + 
↪0.017*"compr" + 0.016*"aind" + 0.016*"vei" + 0.015*"quer"
Topic 4: 0.070*"produt" + 0.066*"entreg" + 0.040*"cheg" + 0.024*"aind" +
↪0.024*"dia" + 0.023*"praz" + 0.019*"receb"
Topic 5: 0.052*"produt" + 0.035*"receb" + 0.035*"compr" + 0.032*"vei" + 
↪0.017*"nao" + 0.012*"cheg" + 0.011*"entreg"
```

**![image](img/Response.png)**以下是针对主题建模输出的解释，考虑到输入仅包含负面客户评价：

```py
Topic 1:
Translation: 0.055*"purchase" + 0.043*"received" + 0.032*"product" + 
↪0.020*"2" + 0.019*"delivery" + 0.017*"only" + 0.017*"order"
Interpretation: Issues with purchase, receiving products, and delivery; 
↪possible complaints about incomplete or partially received orders.

Topic 2:
Translation: 0.043*"delivery" + 0.035*"product" + 0.035*"purchase" + 
↪0.028*"received" + 0.021*"now" + 0.020*"deadline" + 0.013*"missing"
Interpretation: Problems with product delivery, receiving products, and 
↪missing items; concerns about meeting deadlines.

Topic 3:
Translation: 0.095*"product" + 0.046*"received" + 0.021*"delivery" + 
↪0.017*"purchase" + 0.016*"still" + 0.016*"came" + 0.015*"want"
Interpretation: Dissatisfaction with products, delivery, and purchase 
↪experience; possible issues with products received or not yet 
↪received.

Topic 4:
Translation: 0.070*"product" + 0.066*"delivery" + 0.040*"arrived" + 
↪0.024*"still" + 0.024*"day" + 0.023*"deadline" + 0.019*"received"
Interpretation: Delivery and arrival of products, with possible delays 
↪or dissatisfaction with the time it took to receive them.

Topic 5:
Translation: 0.052*"product" + 0.035*"received" + 0.035*"purchase" + 
↪0.032*"came" + 0.017*"not" + 0.012*"arrived" + 0.011*"delivery"
Interpretation: Discontent with products, purchases, and deliveries; 
↪concerns about items not arriving or not being as expected.
```

如所示，生成式 AI 在处理难以阅读的输出时非常有用，尤其是当它是用您不熟悉的语言编写时。很明显，生成式 AI 能够从提取的关键词中构建出美好且合理的叙述。然而，在我们的例子中，五个最常见的主题都与同一问题相关：对交付的不满，这是给老板的启示信息。

##### 生成式 AI 解释输出

生成式 AI 有助于提取文本挖掘方法输出的精华，即使它以难以阅读的格式和外语呈现。

总结来说，本节展示了通过在客户评论集上应用文本摘要和主题建模技术来识别最常见的客户关注点，从而将生成式 AI 应用于识别。此外，我们还通过生成一些俳句来娱乐自己。这种全面的方法展示了生成式 AI 在自然语言处理和文本分析领域的多功能性和实用性。

然而，尽管生成式 AI 是一个在包括文本摘要在内的各种 NLP 任务中表现良好的强大语言模型，但其性能并不总是优于专门的摘要库。生成式 AI 和专用库之间的选择取决于几个因素，例如文本的性质、所需的摘要类型（提取式或抽象式）以及特定领域的上下文。

专门的摘要库可能针对特定任务进行了优化，并且通常可以提供对摘要过程的更多控制，使用户能够根据他们的需求微调输出。此外，它们可能在特定领域或技术文本上表现更好。

另一方面，生成式 AI 的优势在于其生成更连贯、更自然听起来摘要的能力，尤其是在抽象式摘要方面。它可以是生成类似人类摘要或当重点是产生易于理解输出的绝佳选择。

简而言之，没有一种适合所有情况的答案，生成式 AI 和专用摘要库之间的选择取决于手头任务的特定要求。评估不同的方法并选择最适合您需求的方法是至关重要的。

##### 向生成式 AI 提出的问题

+   如何使用您的 API 来执行您的任务？

+   这段文字是关于什么的？

+   哪种 NLP 方法最适合总结我的数据类型？

+   您能将这个输出变得可读吗？

## 摘要

+   对于复杂的 NLP 任务，某些专业工具可能仍然超越最先进的生成式 AI 的能力。

+   即使生成式 AI 可能在您的 NLP 任务中优于传统方法，但它可能并不总是具有成本效益。

+   顶级生成式 AI 模型就像需要精心照顾的宠物；许多公司发现很难将它们留在内部。要在工业规模上部署它们，通常需要依赖第三方解决方案，例如 API。

+   随着每个版本的更新，生成式 AI 的性能显著提升。

+   就算你偏好的生成式 AI 版本*n*无法制作咖啡，这并不意味着版本*n*+1 就不会具备这样的能力。

+   生成式 AI 在文本摘要和改写方面非常出色，无论是散文、诗歌、戏剧，还是其他形式。它提供提取式和抽象式摘要。

+   使用生成式 AI 来解释或总结结果——尤其是那些难以阅读的结果。
