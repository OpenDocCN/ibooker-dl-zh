# 前言

机器如何理解人类意图一直是我深感兴趣的主题。虽然我在 2007 年开始踏上 AI 和机器学习之旅，但直到 2016 年初，在构建一个虚拟数据分析师时，我对自然语言处理（NLP）产生了浓厚的兴趣。当谷歌在 2018 年发布 BERT 时，我坚信 NLP 正站在革命的边缘。

在 2022 年，随着 OpenAI 的 GPT-3 系列模型 text-davinci-002 的发布，我决定加入基于生成式 AI 的内容营销平台 Yarnit，构建应用的 AI 核心。我们的使命是创建一个平台，企业内容营销团队能够以高速、大规模和低成本生成营销资产——社交媒体帖子、博客、电子邮件等等，并且具有更高的准确性。很快，很明显，没有将品牌特定知识和对专有数据的访问纳入其中的生成模型无法有效地实现这一点。这一认识引导我探索检索增强生成（RAG）。

大型语言模型（LLMs）往往无法满足用户期望。虽然它们在存储和生成知识方面非常有效，但它们也容易产生幻觉——自信但错误的输出。这就是 RAG 提供突破的地方，它允许 LLMs 在生成响应之前检索相关、实时和事实信息。RAG 的美丽之处在于其概念简单性与实施细节的微妙结合。RAG 在克服 LLMs 核心限制方面的变革潜力，使得研究人员和实践者都保持着高度的兴趣。

当我开始研究 RAG 时，它还是一个相对未开发的领域。正式的学习资源很少，大部分知识都散布在博客、社交媒体帖子、研究论文和讨论论坛中。我在社交媒体平台和博客文章中分享了许多自己的发现。最终，将所有这些学习成果整合成一本综合书籍的想法逐渐成形。

为了创建一个简单、实用的资源，为构建基于大型语言模型（LLM）的应用的技术专业人士提供帮助，我在 2024 年中期开始着手编写这本书。随着时间的推移，它已经发展成一本关于检索增强生成（RAG）的基础指南，涵盖了广度和深度，同时通过清晰的解释和简单的 Python 代码确保了实际应用。

我坚信，RAG 是任何与 AI 应用工作的人必备的技能，而掌握它需要坚实的概念基础。这本书就是为了提供这样的基础而设计的。编写这本书是一次极其丰富的经历，我在其中学到了很多。我希望你们会发现它既启发人心又有趣味。
