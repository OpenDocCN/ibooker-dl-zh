# 前言

当 ChatGPT 发布时，像许多我的同事一样，我感到迷茫。让我感到惊讶的并不是模型的大小或能力。十多年来，人工智能社区都知道，扩大模型规模可以提升其性能。2012 年，AlexNet 的作者在他们的标志性论文[《他们的里程碑论文》](https://oreil.ly/XG3mv)中提到：“我们所有的实验都表明，通过等待更快的 GPU 和更大的数据集变得可用，我们的结果可以得到改善。”^(1)^, ^(2)

让我感到惊讶的是，这种能力提升解锁了大量的应用。我以为模型质量指标的微小增加可能会导致应用的小幅增加。相反，它导致了新可能性的爆炸式增长。

这些新的 AI 能力不仅增加了对 AI 应用的需求，还降低了开发者的入门门槛。开始构建 AI 应用变得如此简单。甚至可以构建一个不需要写一行代码的应用。这种转变将人工智能从一门专业学科转变为一个每个人都可以使用的强大开发工具。

尽管今天人工智能的采用似乎很新，但它建立在已经存在了一段时间的技术之上。关于语言建模的论文早在 20 世纪 50 年代就出现了。检索增强生成（RAG）应用建立在检索技术上，这种技术早在 RAG 这个术语被提出之前就已经推动了搜索和推荐系统。部署传统机器学习应用的最佳实践——系统性的实验、严格的评估、不懈的优化以实现更快和更便宜的模式——仍然是与基于基础模型的应用一起工作的最佳实践。

许多人工智能工程技术的熟悉性和易用性可能会误导人们认为人工智能工程没有新东西。但是，尽管构建人工智能应用的原则仍然相同，人工智能模型的规模和改进的能力引入了需要新解决方案的机会和挑战。

本书涵盖了将基础模型适应解决现实世界问题的端到端过程，包括来自其他工程领域的经过验证的技术以及随着基础模型出现的新的技术。

我着手写这本书是因为我想学习，而且我确实学到了很多。我从我参与的项目、阅读的论文以及我采访的人那里学到了知识。在撰写这本书的过程中，我使用了超过 100 次对话和采访的笔记，包括来自主要人工智能实验室（OpenAI、Google、Anthropic、...）、框架开发者（NVIDIA、Meta、Hugging Face、Anyscale、LangChain、LlamaIndex、...）、不同规模公司的执行人员和 AI/数据负责人、产品经理、社区研究人员以及独立应用开发者（见“致谢”)。

我特别从早期读者那里学到了很多，他们测试了我的假设，介绍了不同的观点，并让我接触到了新的问题和方法。本书的一些部分在[我的博客](https://huyenchip.com/blog/)上分享后，也收到了来自社区的数千条评论，许多人提供了新的观点或证实了一个假设。

我希望这本书现在在你手中时，这个学习过程会继续下去，因为你有独特于你的经验和观点。请随时通过[X](https://x.com/chipro)、[LinkedIn](https://www.linkedin.com/in/chiphuyen)或电子邮件 hi@huyenchip.com 与我分享你对该书的任何反馈。

# 本书的内容是什么

本书提供了一个框架，用于将基础模型（包括大型语言模型（LLMs）和大型多模态模型（LMMs））适应特定应用。

构建应用程序有许多不同的方法。本书概述了各种解决方案，并提出了你可以提出的问题来评估最适合你需求的最佳解决方案。本书可以帮助你回答的许多问题包括：

+   我是否应该构建这个 AI 应用程序？

+   我如何评估我的应用程序？我能用 AI 来评估 AI 输出吗？

+   幻觉是由什么引起的？我如何检测和减轻幻觉？

+   提示工程的最佳实践是什么？

+   为什么 RAG 会起作用？进行 RAG 的策略有哪些？

+   什么是代理？我如何构建和评估一个代理？

+   何时微调模型？何时不微调模型？

+   我需要多少数据？我如何验证数据的质量？

+   我如何使我的模型更快、更便宜、更安全？

+   我如何创建一个反馈循环来持续改进我的应用程序？

本书还将帮助你导航令人眼花缭乱的 AI 环境类型、评估基准以及看似无限的应用用例和应用模式。

本书的内容通过案例研究进行说明，其中许多案例是我参与工作的，并有充足的参考文献支持，并由来自不同背景的专家进行了广泛审查。尽管这本书花费了两年时间来撰写，但它汲取了我过去十年与语言模型和机器学习系统合作的经验。

与我之前出版的 O’Reilly 书籍《设计机器学习系统》（DMLS）一样，这本书专注于人工智能工程的基础知识，而不是任何特定的工具或 API。工具很快就会过时，但基础知识应该更持久.^(3)

然而，确定某物是否会持续存在，通常是一个挑战。我依赖三个标准。首先，对于一个问题，我确定它是否是由人工智能工作的基本局限性引起的，或者它是否会随着更好的模型而消失。如果问题本质上是基本的，我会分析其挑战和解决方案，以解决每个挑战。我是一个简单开始的支持者，所以对于许多问题，我会从最简单的解决方案开始，然后随着挑战的上升，逐步采用更复杂的解决方案。

其次，我咨询了一个由比我聪明的学者和工程师组成的广泛网络，他们关于他们认为最重要的问题和解决方案的看法。

有时，我也会依赖[Lindy 效应](https://en.wikipedia.org/wiki/Lindy_effect)，它推断出一种技术的未来预期寿命与其当前年龄成正比。所以，如果某样东西已经存在了一段时间，我会假设它还会继续存在一段时间更长。

然而，在这本书中，我偶尔也会包含一些我认为是暂时性的概念，因为它们对某些应用开发者来说立即有用，或者因为它们展示了有趣的解决问题的方法。

# 这本书不是什么

这本书不是教程。虽然它提到了特定的工具，并包括伪代码片段来展示某些概念，但它不教你如何使用工具。相反，它提供了一个选择工具的框架。它包括许多关于不同解决方案之间的权衡以及评估解决方案时应提出的问题的讨论。当你想使用一个工具时，通常很容易在网上找到它的教程。AI 聊天机器人也相当擅长帮助你开始使用流行的工具。

这本书不是一本机器学习理论书。它不解释神经网络是什么，或者如何从头开始构建和训练模型。虽然它解释了许多与讨论直接相关的理论概念，但本书是一本实用的书，专注于帮助你构建成功的 AI 应用来解决现实世界的问题。

虽然在没有机器学习专业知识的情况下可以构建基于基础模型的应用，但了解机器学习和统计学的基本知识可以帮助你构建更好的应用，并让你免受不必要的痛苦。你可以没有先前的机器学习背景来阅读这本书。然而，如果你知道以下概念，在构建 AI 应用时你会更加有效：

+   概率论概念，如抽样、确定性、分布。

+   机器学习概念，如监督学习、自监督学习、对数似然、梯度下降、反向传播、损失函数和超参数调整。

+   各种神经网络架构，包括前馈、循环和转换器。

+   指标，如准确率、F1 分数、精确率、召回率、余弦相似度和交叉熵。

如果你还不了解它们，不要担心——这本书要么提供了简短的高级解释，要么提供了可以让你快速掌握的资源。

# 这本书面向谁

本书适合任何希望利用基础模型解决现实世界问题的人。这是一本技术书，因此本书的语言面向技术角色，包括 AI 工程师、ML 工程师、数据科学家、工程经理和技术产品经理。如果您能理解以下任何一种情况，这本书就是为您准备的：

+   您正在构建或优化一个 AI 应用，无论您是从零开始还是希望从演示阶段过渡到生产就绪阶段。您可能还面临幻觉、安全性、延迟或成本等问题，并需要针对性的解决方案。

+   您想简化团队的人工智能开发流程，使其更加系统化、快速和可靠。

+   您想了解您的组织如何利用基础模型来提高业务的底线，以及如何组建一个团队来实现这一点。

您也可以从这本书中受益，如果您属于以下任何一组：

+   工具开发者，希望识别 AI 工程中的未充分服务的领域，以便在生态系统中定位您的产品。

+   希望更好地理解 AI 用例的研究人员。

+   寻求清晰了解追求 AI 工程师职业所需技能的求职者。

+   任何希望更好地理解 AI 的能力和局限性，以及它可能如何影响不同角色的人。

我喜欢深入探究事物，所以有些部分会稍微深入到技术方面。虽然许多早期读者喜欢这些细节，但这可能不是每个人都适合的。在事情变得过于技术性之前，我会提前给您一个提示。如果您觉得有点太深入了，请随时跳过。

# 导航本书

本书的结构遵循开发 AI 应用的典型流程。以下是这个典型流程的样子以及每一章如何融入这个过程。由于本书是模块化的，您可以跳过任何您已经熟悉或与您不太相关的部分。

在决定构建一个 AI 应用之前，了解这个过程涉及的内容并回答以下问题是很必要的：这个应用是必要的吗？需要 AI 吗？我必须自己构建这个应用吗？这本书的第一章帮助您回答这些问题。它还涵盖了一系列成功的用例，以展示基础模型可以做什么。

虽然构建 AI 应用不需要 ML 背景，但了解基础模型在底层是如何工作的，对于充分利用它是有用的。第二章分析了基础模型的制作及其对下游应用有重大影响的设计决策，包括其训练数据配方、模型架构和规模，以及模型是如何训练以与人类偏好对齐的。然后讨论了模型是如何生成响应的，这有助于解释模型看似令人困惑的行为，如不一致性和幻觉。改变模型的生成设置通常是便宜且简单的方法，可以显著提高模型的表现。

一旦你决定使用基础模型来构建一个应用，评估将贯穿整个过程的每一步。评估是 AI 工程中最困难，如果不是最困难的挑战之一。本书用两章，即第三章和第四章，来探讨不同的评估方法和如何使用它们为你的应用创建一个可靠和系统的评估流程。

给定一个查询，模型响应的质量取决于以下方面（除了模型生成设置之外）：

+   指示模型应该如何行为的说明

+   模型可以用来响应查询的上下文

+   模型本身

书的接下来的三章专注于如何优化这些方面的每一个，以提高模型在应用中的性能。第五章涵盖了提示工程，从提示是什么，为什么提示工程有效，以及提示工程的最佳实践开始。然后讨论了恶意行为者如何利用提示攻击来利用你的应用，以及如何防御这些攻击。

第六章探讨了为什么上下文对于模型生成准确响应很重要。它深入研究了两种主要的上下文构建应用模式：RAG 和代理。RAG 模式更容易理解，并且在生产中已经证明效果良好。另一方面，虽然代理模式承诺将具有更大的威力，但它也更复杂，并且仍在探索中。

第七章 讲述了如何通过微调模型本身来适应一个应用。由于基础模型的规模，原生模型的微调是内存密集型的，因此已经开发了许多技术，以允许使用更少的内存来微调更好的模型。本章涵盖了不同的微调方法，并补充了一种更实验性的方法：模型合并。本章包含一个更技术性的部分，展示了如何计算模型的内存占用。

由于许多微调框架的可用性，微调过程本身通常很简单。然而，获取微调数据是困难的。下一章全部关于数据，包括数据获取、数据标注、数据合成和数据处理。第八章中讨论的许多主题超出了微调的范围，包括数据质量的意义以及如何评估你的数据质量。

如果第五章到第八章是关于提高模型质量，那么第九章则是关于使其推理更便宜、更快。它讨论了在模型级别和推理服务级别的优化。如果你使用模型 API——即其他人为你托管模型——这个 API 可能会为你处理推理优化。然而，如果你自己托管模型——无论是开源模型还是内部开发的模型——你需要实现本章讨论的许多技术。

书中的最后一章将本书中的不同概念汇集起来，构建了一个端到端的应用程序。章节的第二部分更加关注产品，讨论了如何设计一个用户反馈系统，该系统能够帮助你收集有用的反馈，同时保持良好的用户体验。

###### 注意

我在这本书中经常使用“我们”来指代你（读者）和我。这是我从教学日子里养成的习惯，因为我把写作看作是作者和读者共同的学习体验。

# 本书使用的约定

本书使用以下排版约定：

*斜体*

表示新术语、URL、电子邮件地址、文件名和文件扩展名。

`常宽`

用于程序列表，以及段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句、输入到模型中的提示和关键字。

**`常宽粗体`**

表示用户需要直接输入的命令或其他文本。

*`常宽斜体`*

表示应替换为用户提供的值或由上下文确定的值的文本。

###### 小贴士

此元素表示提示或建议。

###### 注意

此元素表示一般性说明。

###### 警告

此元素表示警告或注意事项。

# 使用代码示例

补充材料（代码示例、练习等）可在[*https://github.com/chiphuyen/aie-book*](https://github.com/chiphuyen/aie-book)下载。该存储库包含关于 AI 工程的额外资源，包括重要论文和有用的工具。它还涵盖了本书中未能深入探讨的主题。对于那些对本书的写作过程感兴趣的人，GitHub 存储库还包含了幕后信息和关于本书的统计数据。

如果您在使用代码示例时遇到技术问题或问题，请发送电子邮件至*support@oreilly.com*。

本书旨在帮助您完成工作。一般来说，如果本书提供了示例代码，您可以在您的程序和文档中使用它。除非您正在复制代码的很大一部分，否则您不需要联系我们获得许可。例如，编写一个使用本书中几个代码块的程序不需要许可。通过引用本书并引用示例代码来回答问题不需要许可。将本书的大量示例代码纳入您产品的文档中需要许可。

我们感谢，但通常不需要署名。署名通常包括标题、作者、出版社和 ISBN。例如：“*AI Engineering* by Chip Huyen (O’Reilly). 版权 2025 Developer Experience Advisory LLC, 978-1-098-16630-4。”

如果您认为您对代码示例的使用超出了合理使用或上述许可的范围，请随时联系我们：*permissions@oreilly.com*。

# O’Reilly 在线学习

###### 注意

40 多年来，[*O’Reilly Media*](https://oreilly.com)一直为科技公司提供技术和商业培训、知识和洞察力，以帮助公司取得成功。

我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。O’Reilly 的在线学习平台为您提供按需访问实时培训课程、深入的学习路径、交互式编码环境以及来自 O’Reilly 和 200 多家其他出版商的大量文本和视频。更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。

# 如何联系我们

请将有关本书的评论和问题寄给出版社：

+   O’Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   加州塞巴斯蒂波尔，95472

+   800-889-8969 (美国或加拿大境内)

+   707-827-7019 (国际或本地)

+   707-829-0104 (传真)

+   *support@oreilly.com*

+   [*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)

我们为这本书有一个网页，其中列出了勘误表、示例和任何其他附加信息。您可以通过[*https://oreil.ly/ai-engineering*](https://oreil.ly/ai-engineering)访问此页面。

了解我们书籍和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。

在 LinkedIn 上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)

在 YouTube 上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)

# 致谢

如果没有这么多帮助我完成这个过程的好人，这本书的编写将会花费更多时间，并且会错过许多重要主题。

由于项目的截止时间紧迫——在两年内完成一本涵盖如此广泛内容的 15 万字的书籍——我非常感激那些抽出宝贵时间迅速审阅这本书的技术审稿人。

卢克·梅茨是一位出色的顾问，他检查了我的假设，防止我走错路。韩钟·李总是紧跟最新的 AI 新闻和社区发展，为我指出了我遗漏的资源。卢克和韩钟在我将草稿发送给下一轮技术审稿人之前，首先审阅了我的草稿，我永远感激他们容忍我的愚蠢和错误。

维托里奥·克雷特拉和安德烈·洛帕滕科在财富 500 强公司领导 AI 创新，他们提供了宝贵的反馈，结合了深厚的专业技术知识和管理层的洞察力。维基·赖兹尔曼帮助我将内容接地气，并使其对具有软件工程背景的读者保持相关性。

尤金·严是一位亲爱的朋友和出色的应用科学家，为我提供了技术和情感上的支持。肖恩·王（swyx）提供了一次重要的氛围检查，帮助我更有信心地对待这本书。萨扬·布塔尼，是我所知最好的学习者之一，最谦逊的灵魂，不仅给出了深思熟虑的书面反馈，还录制了视频来解释他的反馈。

凯尔·克兰恩是一位杰出的深度学习负责人，他采访了他的同事，并与我分享了他们微调过程的精彩总结，这指导了微调章节。马克·萨拉菲姆是一位好奇心旺盛的人，他总是关注最有趣的问题，并向我介绍了关于效率的宝贵资源。凯尔和马克的反馈对于撰写第七章和第九章至关重要。

除了回答我许多问题外，基蒂帕特“博特”坎帕还与我分享了他对 AI 平台的详细可视化思考。我赞赏德尼·林科夫在评估和平台开发方面的系统方法。切坦·特库尔提供了帮助我构建 AI 应用模式的优秀例子。我还想感谢沈志（亚历克斯）李和阮辉恩对我的 AI 架构草稿的深思熟虑的反馈。

艾琳·布伊是一位宝贵的财富，她从产品经理的角度分享了独特的反馈和例子。感谢托多·马尔科夫对 RAG 和代理章节的可操作建议。感谢塔尔·卡奇曼在最后一刻加入，推动微调章节顺利完成。

有许多优秀的人，他们的陪伴和对话给了我许多灵感，指导了这本书的内容。我尽力将所有帮助过我的人的名字都包括在内，但由于人类记忆的固有缺陷，我无疑遗漏了许多人。如果我没有包括你的名字，请知道这并不是因为我没有感激你的贡献，请友好地提醒我，以便我尽快纠正这一点！

安德鲁·弗朗西斯、阿尼什·纳格、安东尼·加尔查克、安东·巴卡伊、巴拉兹·加兰博西、查尔斯·弗赖伊、查尔斯·帕克、克里斯·布罗萨乌、埃里克·哈特福德、古库·莫汉达斯、哈梅尔·胡赛因、哈普雷特·萨霍塔、哈桑·埃尔·穆加里、胡安·诺伊恩、杰里米·豪厄德、杰西·西尔弗、约翰·库克、胡安·帕布洛·博塔罗、凯尔·加尔蒂宁、兰斯·马丁、卢西奥·德里、马特·罗斯、马克西姆·拉邦内、迈尔斯·布兰德奇、内森·兰伯特、奥马尔·卡塔布、 phong nguyen、普尔嫩杜·穆克赫杰、山姆·赖斯威格、塞巴斯蒂安·拉斯克卡、沙胡尔·ES、沙里夫·沙米姆、索乌米特·钦塔拉、Teknium、蒂姆·德特梅斯、Undi95、瓦莱·安德烈·法哈多、维尔·梁、维克多·桑赫、温·连、西泉·崔、英生、克里斯托弗。

我还想感谢所有提供反馈的早期读者。道格拉斯·贝利是一位超级读者，分享了如此多的深思熟虑的反馈。感谢纳坦·萨胡建议一种优雅的方式来解释困惑度。

我从与许多人的在线讨论中学到了很多。感谢所有曾经回答过我问题、评论过我帖子或给我发送邮件分享你们想法的人。

当然，没有 O’Reilly 团队的共同努力，这本书是不可能完成的，特别是我的开发编辑（梅丽莎·波特、科宾·柯林斯、吉尔·莱昂纳德）和我的出版编辑（伊丽莎白·凯利）。莉兹·惠勒是我合作过的最挑剔的校对编辑。妮可·巴特菲尔德是一位强大的力量，她从想法到最终产品监督了这本书。

总之，这本书是我整个职业生涯中学到的宝贵经验的积累。我非常感谢我的极富能力和耐心的同事和前同事。与我共事过的每一个人都教会了我如何将机器学习带入现实世界的新知识。

^(1) AlexNet 论文的作者伊利亚·苏茨克维尔继续共同创立了 OpenAI，通过 GPT 模型将这个教训变成了现实。

^(2) 即使是我在 2017 年的一个小项目[我的小项目](https://x.com/chipro/status/937384141791698944)，该项目使用语言模型来评估翻译质量，也得出我们需要“更好的语言模型”的结论。

^(3) 在 2017 年教授如何使用 TensorFlow 的课程让我深刻地认识到工具和教程更新换代的速度有多快。
