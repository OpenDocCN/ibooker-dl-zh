# 第一章. PyTorch 简介

当谈到创建人工智能（AI）时，机器学习（ML）和深度学习是很好的起点。然而，当你开始时，很容易被选项和所有新的术语所淹没。这本书旨在为你这个程序员揭开神秘的面纱。它带你通过编写代码来实现机器学习和深度学习概念，同时也带你构建行为更像人类的模型，例如计算机视觉、自然语言处理（NLP）等。因此，这些模型成为了一种合成或人工的智能形式。

但当我们提到*机器学习*时，它究竟是什么呢？在我们继续之前，让我们快速看一下它，并从程序员的角度来考虑它。之后，在本章的其余部分，我们将向您展示如何安装所需的工具，从 PyTorch 本身到您可以在此处编写和调试基于 PyTorch 的模型的开发环境。

# 什么是机器学习？

在我们深入探讨机器学习的细节之前，让我们考虑它是如何从传统编程中演变而来的。我们将首先检查传统编程是什么，然后考虑它的局限性。之后，我们将看到机器学习是如何演变来处理这些情况的，从而为实施新的场景打开了新的机会，从而解锁了许多人工智能的概念。

传统编程涉及编写用编程语言表达、作用于数据和给出答案的规则。这几乎适用于我们可以用代码编程的任何地方。

例如，考虑像流行的《Breakout》这样的游戏。代码决定了球的移动、得分以及赢得或输掉游戏的各个条件。想想球在砖块上弹跳的场景，就像图 1-1 中展示的那样。

![](img/aiml_0101.png)

###### 图 1-1\. 《Breakout》游戏中的代码

在这里，球的运动可以通过其 `dx` 和 `dy` 属性来确定。当球击中砖块时，砖块被移除，球的速率增加，球的运动方向改变。代码作用于游戏情况的数据。

或者，考虑一个金融服务场景。比如说，你有一家公司的数据，比如它的当前股价和收益。通过使用图 1-2 中的代码，你可以计算出一种非常有价值的比率，称为*市盈率*（或 P/E，代表价格除以收益）。

![](img/aiml_0102.png)

###### 图 1-2\. 金融服务场景中的代码

你的代码读取价格，读取收益，并返回一个值，即前者除以后者。

如果我要尝试用一张图来总结传统编程，它可能看起来像图 1-3。

![](img/aiml_0103.png)

###### 图 1-3\. 传统编程的高级视图

如您所见，这些规则是用编程语言表达的。这些规则作用于数据，结果是答案。

# 传统编程的局限性

图 1-3 中的模型自从其诞生以来一直是发展的基石。但它有一个固有的局限性：即你只能实现那些可以推导出规则的场景。但其他场景怎么办？通常，由于代码过于复杂，开发它们是不切实际的。编写代码来处理它们是不可能的。

以活动检测为例。能够检测我们活动的健身监测器是最近的一项创新，这不仅是因为便宜且小巧的硬件的可用性，还因为处理检测的算法之前是不可行的。让我们来探讨一下原因。

图 1-4 显示了一个用于走路的简单活动检测算法。它可以考虑人的速度，如果这个速度低于某个特定值，我们就可以确定他们可能是在走路。

![图片](img/aiml_0104.png)

###### 图 1-4。活动检测算法

既然我们的数据是速度，我们也可以将其扩展到检测他们是否在跑步，就像图 1-5 中所示。

![图片](img/aiml_0105.png)

###### 图 1-5。扩展跑步算法

如您所见，根据速度，我们可能会说如果速度低于某个特定值（比如说，4 英里/小时），那么这个人是在走路，否则，他们是在跑步。这仍然有点效果。

现在，假设我们想要将这种方法扩展到另一种流行的健身活动——骑自行车。算法可能看起来像图 1-6 中的那样。

![图片](img/aiml_0106.png)

###### 图 1-6。扩展骑自行车算法

我知道这个算法很天真，因为它只是检测速度——有些人跑得比其他人快，你可能会在下坡时跑得比上坡时骑自行车快——但总体来说，它仍然有效。然而，如果我们想要实现另一个场景，比如高尔夫球（见图 1-7），会发生什么呢？

![如何编写一个高尔夫球算法？](img/aiml_0107.png)

###### 图 1-7。我们如何编写一个高尔夫球算法？

现在，我们陷入了困境。无论一个人是否在打高尔夫球，他们可能会走一会儿，停下来，做一些活动，再走一会儿，然后停下来，等等。那么我们如何使用这种方法来判断他们是否在打高尔夫球呢？

我们使用传统规则检测这种活动的能力已经遇到了瓶颈。但也许有更好的方法。

进入机器学习。

# 从编程到学习

让我们回顾一下我们用来演示什么是传统编程的图（见图 1-8）。在这里，我们有作用于数据并给出答案的规则。在我们的活动检测场景中，数据是这个人移动的速度——从这个数据中，我们可以编写规则来检测他们的活动，无论是走路、骑自行车还是跑步。然而，当我们遇到高尔夫时遇到了障碍，因为我们无法提出规则来确定这项活动的样子。

![aiml_0108.png](img/aiml_0108.png)

###### 图 1-8\. 传统编程流程

但如果我们翻转这个图中的坐标轴会怎样呢？如果我们不是提出*规则*，而是提出*答案*，并且与数据一起找到可能规则的途径呢？

图 1-9 展示了这会是什么样子，我们可以说这个高级图定义了*机器学习*。

![aiml_0109.png](img/aiml_0109.png)

###### 图 1-9\. 改变坐标轴以获得机器学习

那么，这有什么影响呢？嗯，现在，我们不再试图找出规则，而是可以收集大量关于我们场景的数据，并标记这些数据，然后计算机可以找出使一块数据与特定标签匹配，另一块数据与不同标签匹配的规则。

这个方法对我们活动检测场景会有什么作用呢？嗯，我们可以查看所有为我们提供关于这个人数据的传感器。如果这个人有一个可以检测心率、位置和速度等信息的可穿戴设备——并且我们在他们进行不同活动时收集了大量此类数据实例——那么我们最终会得到一个数据场景，它会说：“这就是走路的样子”，“这就是跑步的样子”，等等（见图 1-10）。

![从编码到机器学习：收集和标记数据](img/aiml_0110.png)

###### 图 1-10\. 从编码到机器学习：收集和标记数据

现在，我们作为程序员的任务从找出规则转变为确定活动，再到编写将数据与标签匹配的代码。如果我们能这样做，那么我们就可以扩展我们可以用代码实现的场景。

机器学习是一种使我们能够做到这一点的技术，但为了开始，我们需要一个框架——这就是 TensorFlow 的用武之地。在下一节中，我们将探讨 TensorFlow 是什么以及如何安装它。然后，在本章的后面部分，你将编写你的第一个代码，学习两个值之间的模式，就像前面的场景一样。这是一个简单的“Hello World”场景，但它具有在极其复杂场景中使用的相同基础代码模式。

人工智能领域是庞大且抽象的，包括与使计算机像人类一样思考和行动有关的一切。人类采取新行为的一种方式是通过示例学习，因此机器学习学科可以被视为人工智能发展的入门途径。通过机器学习领域中的 *计算机视觉*，机器可以学会像人类一样看，通过另一个机器学习领域中的 *自然语言处理*，它可以学会像人类一样阅读文本。还有许多其他可能的机器学习应用，我们将通过使用 TensorFlow 框架来介绍机器学习的基础知识。

# 什么是 PyTorch？

PyTorch 是一个基于先前名为 *Torch* 的库的机器学习库，而 *Torch* 本身是一个开源的机器学习框架和脚本语言，它又基于一种名为 Lua 的编程语言。2017 年，Torch 的发展转移到了 PyTorch，这是一个在 Python 中的框架移植。

因此，当安装 PyTorch 时，您通常会看到它被称为“torch”。

PyTorch 最初由 Meta AI 开发，但为了建立开发者对其不是由大型科技公司制作和使用的信心，它被转移到了 Linux 基金会。它是两个最受欢迎的机器学习库之一，与 TensorFlow/Keras 生态系统并列。

随着生成式人工智能的出现，特别是生成文本和图像模型的“开源”，PyTorch 的受欢迎程度急剧上升。它通常用于训练模型（我们在本书的第一部分中介绍）以及模型的推理（我们在本书的第二部分中介绍）。

PyTorch 也可以被视为一个库的生态系统，每个库都针对特定场景进行了定制。以下是一些重要的库和需要考虑的场景：

TorchServe

这是一个易于使用的工具，可以让您大规模部署 PyTorch 模型。它设计为在多个环境中运行，并且通常是技术无关的。它支持多模型服务、日志记录、指标以及轻松创建 RESTful 端点，让您可以从各种客户端对模型进行推理。

分布式训练

当较大的模型无法适应单个芯片或机器时，有一些技术和技术允许您在多个设备之间共享它们。`torch.distributed` 库允许您在多个设备上轻松且本地地支持异步执行。

移动

对于推理来说，移动设备当然是一个重要的表面。您能够将您的 AI 工作部署到 Android 和 iOS 设备上非常重要，PyTorch 通过 PyTorch Mobile 支持这一点。

预训练模型

一群活跃的研究人员和开发者创建了一个丰富的模型生态系统，您只需一行代码即可使用，这些代码被封装在 torchvision.models 库中。

图 1-11 提供了这一概念的高级表示。

![图片](img/aiml_0111.png)

###### 图 1-11\. PyTorch 生态系统

创建机器学习模型的过程被称为**训练**，这是计算机使用一系列算法来了解输入以及它们之间区别的过程。所以，例如，如果你想让计算机识别猫和狗，你可以使用大量两者的图片来创建一个模型，然后计算机将使用这个模型来试图弄清楚什么使猫成为猫，什么使狗成为狗。一旦模型被训练，让模型识别或分类未来输入的过程被称为**推理**。

因此，对于训练模型，你需要考虑几个方面，我们将在本书中介绍它们。主要来说，你的选择将归结为以下三个方面之一：

+   从头开始自己创建模型

+   使用他人的模型，因为这对你的任务来说已经足够了

+   使用已经训练过的他人模型的部分，并在其基础上构建

列表中的最后一个选项被称为**迁移学习**，我们将在本书的后面部分介绍它。

训练模型有许多方法。大多数情况下，你可能只会使用单个芯片，无论是中央处理器（CPU）、图形处理器（GPU）还是一种新称为张量处理单元（TPU）的东西。在更高级的工作和研究环境中，你可以使用跨多个芯片的并行训练，采用智能地跨多个芯片的分布式训练。PyTorch 也支持这一点，通过“分布式训练”库，如图 1-11 所示。

任何模型的命脉都是其数据。正如我们之前讨论的，如果你想创建一个能够识别猫和狗的模型，你需要用大量猫和狗的例子来训练它。但你怎么管理这些例子呢？随着时间的推移，你会发现这往往比创建模型本身需要更多的编码。

但幸运的是，PyTorch 生态系统包含了许多内置数据集，这使得这一切对你来说变得容易。我们也将在这本书中探讨这些内容。

除了创建模型之外，你还需要能够将它们放到人们手中，让他们能够使用它们。为此，PyTorch 包含了用于服务的库，你可以通过 HTTP 连接为云端或网络用户提供模型推理。对于在移动或嵌入式系统上运行的模型，有 PyTorch Mobile，它提供了在 Android 和 iOS 上进行模型推理的工具。

接下来，我将向您展示如何安装 PyTorch，这样您就可以开始使用它创建和使用机器学习模型了！

# 使用 PyTorch

在本节中，我们将探讨您安装和使用 PyTorch 的三种主要方式。我们将从如何在您的开发箱上使用命令行安装它开始。然后，我们将探讨使用流行的 PyCharm IDE 来安装和使用 PyTorch。最后，我们将探讨 Google Colab 以及如何使用它通过浏览器中的基于云的后端访问您的 PyTorch 代码。

## 在 Python 中安装 Porch

PyTorch 中的 *Py* 代表 Python，因此已经设置好 Python 环境是很重要的。如果你还没有 Python，我强烈建议你访问[Python 网站](https://python.org)来安装它，并访问[学习 Python 网站](https://learnpython.org)来学习 Python 语言语法。

使用 Python，有多种安装框架的方法，但 TensorFlow 团队支持的是 `pip`。

因此，在你的 Python 环境中，安装 PyTorch 和使用以下命令一样简单：

```py
> pip install torch 
```

一旦你启动并运行，你可以使用以下代码测试你的 PyTorch 版本：

```py
import torch
print(torch.__version__)
```

你应该会看到图 1-12 中的类似输出。它将打印当前运行的 PyTorch 版本——在这里，你可以看到已安装版本 2.4.1。

![](img/aiml_0112.png)

###### 图 1-12\. 在 Python 中运行 PyTorch

###### 注意

如果你仔细看图 1-12，你会看到一个注释显示 torch 设备是“cpu”。在这种情况下，我原生地在我的 Mac 上安装了它，并且配置为使用 CPU。然而，对于需要 GPU 或 Metal 等加速器的复杂模型来说，这并不是最佳选择。我们将在本书的后面部分介绍为加速器安装 PyTorch。

## 在 PyCharm 中使用 PyTorch

我特别喜欢使用[PyCharm 的免费社区版](https://oreil.ly/I2mP2)来构建使用 PyTorch 的模型。PyCharm 有很多用途，但我最喜欢的是它使虚拟环境的管理变得容易。这意味着你可以拥有针对特定项目的 Python 环境，其中包含特定于项目的工具版本，例如 PyTorch。例如，如果你想在一个项目中使用 PyTorch 1.x，在另一个项目中使用 PyTorch 2.x，你可以通过虚拟环境将它们分开，在切换时不需要处理安装/卸载依赖项。此外，使用 PyCharm，你可以逐步调试你的 Python 代码——这对于初学者来说尤其重要！

例如，在图 1-13 中，我有一个名为 *example1* 的新项目，我指定我将使用 Conda 创建一个新环境。当我创建项目时，我将拥有一个干净、新的虚拟 Python 环境，我可以安装任何版本的 PyTorch。

一旦你创建了一个项目，你可以打开文件 → 设置对话框，并从左侧菜单中选择“项目： *<你的项目名称>*”。在左侧菜单中，你会看到更改 Python 解释器和项目结构的选项。如果你选择 Python 解释器链接，你会看到你正在使用的解释器，以及在这个虚拟环境中安装的包列表（见图 1-14）。

![](img/aiml_0113.png)

###### 图 1-13\. 使用 PyCharm 创建新的虚拟环境

![](img/aiml_0114.png)

###### 图 1-14\. 向虚拟环境添加包

然后，你可以点击左上角的“+”按钮，将打开一个对话框，显示当前可用的包。在搜索框中输入**`torch`**，你将看到所有名称中包含 *torch* 的可用包（见图 1-15）。记住，包的名称是 *torch*，即使技术是 PyTorch。

![](img/aiml_0115.png)

###### 图 1-15\. 使用 PyCharm 安装 torch

一旦你选择了 torch 或你想要安装的任何其他包，你可以点击“安装包”按钮，PyCharm 将完成剩余的工作。然后，一旦安装了 torch，你就可以在 Python 中编写和调试你的 PyTorch 代码。

## 在 Google Colab 中使用 PyTorch

另一个选项，可能是入门最容易的方法，是使用 [*Google Colab*](https://oreil.ly/c0lab)，这是一个可以通过浏览器访问的托管 Python 环境。Colab 真是 neat 的地方在于它提供了 GPU 和 TPU 后端，这样你就可以免费使用最先进的硬件来训练模型。

当你访问 Colab 网站，你会得到打开之前的 Colabs 或创建一个新的笔记本的选项（见图 1-16）。如果你点击“+ 新笔记本”按钮，它将打开编辑器，在那里你可以添加代码或文本面板（见图 1-17）。然后你可以通过点击面板左侧的播放按钮（箭头）来执行代码。

![](img/aiml_0116.png)

###### 图 1-16\. Google Colab 入门

![](img/aiml_0117.png)

###### 图 1-17\. 在 Colab 中运行 PyTorch 代码

总是检查 PyTorch 版本是个好主意，就像这里所示，以确保你正在运行适合当前任务的正确版本。

你还可以看到在图 1-17 中显示的版本是 2.4.1+cu121，你可能想知道 *cu121* 部分是什么！*cu* 代表 *Cuda*，这是 Nvidia 用于在 GPU 上加速机器学习的库。因此，前面的消息表明已安装 PyTorch 2.4.1，以及适用于 Cuda 版本 12.1 的加速器。

通常，Colab 内置的各种库的版本，包括 PyTorch，可能比最新版本落后一个或两个版本。如果情况如此，你可以像前面所示的那样使用 `pip install` 更新它，只需使用一个这样的代码块，其中指定了所需的版本：

```py
!pip install torch==<different version number>
```

一旦运行此命令，你的 Colab 当前环境将使用所需的 PyTorch 版本。然而，在 Colab 中进行此操作时你应该小心，因为你更改到的 PyTorch 版本可能没有安装 Cuda 驱动程序，这意味着你可能会降级到使用 CPU。

# 机器学习入门

如本章前面所述，机器学习范式是这样的：你拥有数据，这些数据被标记，而你想要找出匹配数据和标签的规则。在代码中展示这一点的最简单场景如下。

考虑这两组数字：

```py
*`x`* = –1, 0, 1, 2, 3, 4
*`y`* = –3, –1, 1, 3, 5, 7
```

*x* 和 *y* 值之间存在关系（例如，如果 *x* 是 –1，那么 *y* 是 –3；如果 *x* 是 3，那么 *y* 是 5；等等）。你能看到这个关系吗？

几秒钟后，你可能看到了这里的模式是 *y* = 2*x* – 1。你是怎么得到这个结果的？不同的人以不同的方式解决这个问题，但通常我听到这样的观察：*x* 在其序列中增加 1，而 *y* 增加 2；因此，*y* = 2*x* +/– 某个值。然后，他们看到当 *x* = 0 时，*y* = –1，所以他们推断答案可能是 *y* = 2*x* – 1。接下来，他们查看其他值，并看到这个假设“符合”，答案是 *y* = 2*x* – 1。

这非常类似于机器学习的过程。让我们看看你可以编写的代码，让神经网络为你解决这个问题。

这是完整的代码，使用 PyTorch。如果你现在还不理解没关系；我们会逐行讲解：

```py
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# Model
model = nn.Sequential(nn.Linear(1, 1))

# Loss and optimizer
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Data
xs = torch.tensor([[–1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], 
                  dtype=torch.float32)
ys = torch.tensor([[–3.0], [–1.0], [1.0], [3.0], [5.0], [7.0]], 
                  dtype=torch.float32)

# Train
for _ in range(500):
    optimizer.zero_grad()
    outputs = model(xs)
    loss = criterion(outputs, ys)
    loss.backward()
    optimizer.step()

# Predict
with torch.no_grad():
    print(model(torch.tensor([[10.0]], dtype=torch.float32)))
```

前几行是导入器，确保正确的库可用，所以我们跳到这一行：

```py
model = nn.Sequential(nn.Linear(1, 1))
```

你可能听说过神经网络，你可能见过使用相互连接的神经元层来解释它们的图表，就像图 1-18 中那样。

![图 1-18](img/aiml_0118.png)

###### 图 1-18。一个典型的神经网络

当你看到这样的神经网络时，你应该把每个圆圈看作是一个*神经元*，每个圆圈的列看作是一个*层*。所以，在图 1-18 中，有三个层：第一个有五个神经元，第二个有四个，第三个有两个。

这些层按照数据从左到右流动的顺序组织。

现在，如果我们回顾我们的代码，你会看到我们正在定义一个序列，括号内包含的是序列的定义：

```py
model = nn.Sequential(nn.Linear(1, 1))
```

当使用 PyTorch 时，你通过使用 `Sequential` 来定义你的层，然后在 `Sequential` 内部指定每个层的样子。我们 `Sequential` 内部只有一行，所以这个代码定义的神经网络将只有一个层。

然后，你通过使用 `torch.nn` 库来定义层的样子。有很多不同的层类型，但在这里，我们使用的是 `Linear` 层，其中可以定义或学习线性关系（其中线的定义是 *y* = *wx* + *b*）。

我们的 `Linear` 层指定了 (1,1) 参数，这表示一个特征“输入”和一个特征“输出”。所以最终，我们整个神经网络中只有一个层，包含一个神经元。

换句话说，包含参数 (1,1) 的 Sequential 最终看起来像图 1-19。

![图 1-19](img/aiml_0119.png)

###### 图 1-19。一个包含一个神经元的单层神经网络

接下来的几行是真正有趣的地方。让我们再看看它们：

```py
# Loss and optimizer
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)
```

如果你之前做过任何机器学习（ML）的事情，你可能已经看到它涉及大量的数学——如果你已经很多年没有学过微积分，它可能看起来像是一个入门的障碍。这里就是数学发挥作用的地方——它是机器学习的核心。

在这种场景中，计算机对*x*和*y*之间的关系一无所知。因此，它会做出猜测。比如说，它猜测*y* = 10*x* + 10。然后，它需要衡量这个猜测是好是坏——这是*损失函数*的工作。

当*x*为-1、0、1、2、3 和 4 时，计算机已经知道答案，因此损失函数可以将这些与猜测关系的答案进行比较。如果它猜测*y* = 10*x* + 10，那么当*x*为-1 时，*y*将是 0。然而，正确的答案那里是-3，所以它有点偏离。但当*x*为 4 时，猜测的答案是 50，而正确的答案是 7。这真的很远。

带着这些知识，计算机可以再次做出猜测。这是*优化器*的工作。这里使用了大量的微积分，但使用 PyTorch，这可以对你隐藏起来。你只需选择适用于不同场景的适当优化器。在这种情况下，我们选择了一个名为`sgd`的优化器，代表*随机梯度下降*——一个复杂的数学函数，当给定值、前一个猜测以及在该猜测上计算错误（或损失）的结果时，可以生成另一个猜测。随着时间的推移，它的任务是使损失最小化，并通过这样做使猜测的公式越来越接近正确答案。

接下来，我们只需将我们的数字格式化为层所期望的数据格式：

```py
# Data
xs = torch.tensor([[–1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], 
                  dtype=torch.float32)

ys = torch.tensor([[–3.0], [–1.0], [1.0], [3.0], [5.0], [7.0]], 
                  dtype=torch.float32)
```

在机器学习（ML）中，你会经常看到“张量”这个词；它给了 TensorFlow 框架它的名字。想象一下张量就像是一种存储数据的方式，它类似于数组，但为了适应数组大小的灵活性进行了优化。为了让 PyTorch 理解我们的数据，我们将值加载到表示*x*和*y*值的张量中。

然后，学习（learning）过程将以这样的训练循环开始：

```py
# Train
for _ in range(500):
    optimizer.zero_grad()
    outputs = model(xs)
    loss = criterion(outputs, ys)
    loss.backward()
    optimizer.step()
```

如果你刚开始接触机器学习（ML），这可能是最难理解的部分，所以让我们逐行分析。

记住，机器学习（ML）的过程看起来像图 1-20。

![图片](img/aiml_0120.png)

###### 图 1-20。机器学习过程

因此，前面的代码是这样实现的：

```py
optimizer.zero_grad()
```

这行代码的意思是“将优化器的梯度置零”。学习的微积分涉及沿着曲线导航以找到其最小值，而要做到这一点，我们需要曲线的梯度。曲线是在我们测量准确度时计算的，因此我们需要在每个循环的开始时重置它：

```py
outputs = model(xs)
```

这行代码创建了一个数组，其中包含了我们对输入 *x* 值计算得出的输出。尽管我们在 *Y* 数组中给出了计算机的 *正确* 答案，但我们想衡量计算机对定义此线的参数做出的猜测的准确性。在循环的第一次迭代中，神经元内的 *w* 和 *b* 参数将被随机初始化，因此我们的猜测可能是 *Y* = 10*x* + 10，例如：

```py
loss = criterion(outputs, ys)
```

这行代码随后将输出（即我们的猜测）与正确答案进行比较，以计算 *损失*——这实际上是一个告诉我们猜测有多好或多坏的价值：

```py
loss.backward()
```

这一行是学习过程中的关键部分，其中发生了一个称为 *反向传播* 的过程。这是优化器中的数学和损失函数结合来确定新参数集的梯度的位置。在我们的例子中，*Y* = 10*x* + 10 的误差非常高，甚至远未达到我们期望的值，因此确定损失的计算将给我们一个 *方向* 或梯度，告诉我们如何接近我们期望的结果：

```py
optimizer.step()
```

这行代码通过更新模型参数到先前反向传播步骤中计算的梯度值来完成工作。

然后，我们重复这个过程 500 次，目标是找到一组参数，使得单个神经元的 *y* 值接近我们期望的 *y* 值。如果这组参数做到了，它就可以推断出计算机从未见过的 *x* 值的 *y* 值。因此，它将学习我们提供的 *x* 和 *y* 值之间的关系。

图 1-21 展示了在 Colab 笔记本中运行的截图。看看损失值随时间的变化。

![](img/aiml_0121.png)

###### 图 1-21\. 训练神经网络

我们可以看到，在前 10 个时期，损失从 5.64 降至 0.86。也就是说，经过仅仅 10 次尝试，网络的表现比其初始猜测好了大约六倍。

然后，看看在第 500 个时期发生的情况（见 图 1-22）。

![](img/aiml_0122.png)

###### 图 1-22\. 训练神经网络——最后几个时期

我们现在可以看到损失是 9.52 × 10^(-6)。损失已经变得如此之小，以至于模型几乎已经确定出数字之间的关系是 *y* = 2*x* – 1。这意味着 *机器* 已经 *学习* 到它们之间的模式。

如果我们想让我们的神经网络尝试预测一个新值，我们可以使用如下代码：

```py
# Predict
with torch.no_grad():
    prediction = model(torch.tensor([[10.0]], dtype=torch.float32))
    print(prediction)
```

###### 注意

术语 *预测* 通常用于处理机器学习模型时——但不要把它想成是看未来！我们使用这个术语是因为我们处理了一定程度的不确定性。回想一下我们之前提到的活动检测场景。当这个人以一定的速度移动时，她很可能是走路。同样，当模型学习到两个事物之间存在的模式时，它会告诉我们答案很可能是怎样的。换句话说，它是在 *预测* 答案。（稍后，你还将了解到 *推理*，其中模型从多个答案中选择一个，并 *推断* 它已经选择了正确的答案。）

当我们要求模型预测当 *x* 为 10 时的 *y* 时，你认为答案会是什么？你可能立刻想到 19，但这并不正确。模型将选择一个非常接近 19 的值，这有几个原因。首先，我们的损失不是 0。它是一个非常小的数值，因此我们应该预期任何预测答案都会有一个非常小的误差。其次，神经网络仅在一小部分数据上进行了训练——在这个例子中，它只有六对 (*x*, *y*) 值。

模型中只有一个神经元，该神经元学习一个 *权重* 和一个 *偏差*，使得 *y* = *wx* + *b*。这看起来与期望的 *y* = 2*x* – 1 关系完全一样，我们希望模型学习到 *w* = 2 和 *b* = –1。鉴于模型仅基于六个数据项进行训练，我们永远不会期望答案会恰好是这些值；相反，我们期望它非常接近这些值。

现在，亲自运行代码看看你得到什么结果。我运行时得到了 18.991，但你的答案可能略有不同，因为当神经网络首次初始化时，存在随机元素：你的初始猜测将略不同于我的，也不同于第三个人的。

## 看看网络学到了什么

这显然是一个非常简单的场景，其中我们在线性关系中匹配 *x’* 和 *y’*。如前一小节所述，神经元有权重和偏差参数。这使得单个神经元非常适合学习这种关系；即当 *y* = 2*x* – 1 时，权重是 2，偏差是 –1。

使用 PyTorch，我们实际上可以查看学习到的权重和偏差，如下面的代码所示：

```py
# Access the first (and only) layer in the sequential model
layer = model[0]
# Get weights and bias
weights = layer.weight.data.numpy()
bias = layer.bias.data.numpy()
print("Weights:", weights)
print("Bias:", bias)
```

一旦网络完成学习，你可以打印出该层学习到的值（或权重）。在我的情况下，输出如下：

```py
Weights: [[1.998695]]
Bias: [–0.9959542]
```

因此，学习到的 *x* 和 *y* 之间的关系是 *y* = 1.998695 *x* – 0.9959542。

这非常接近我们预期的 (*y* = 2*x* – 1)，我们甚至可以说它更接近现实，因为我们 *假设* 这种关系将适用于其他值！

# 摘要

这就是你的第一个机器学习“Hello World”。你可能觉得这好像是对如此简单的事情——确定两个值之间的线性关系——过度杀鸡用牛刀——你是对的。但有趣的是，我们在这里创建的代码模式与用于更复杂场景的模式是相同的。你将在第二章中看到这些场景，我们将探讨一些基本的计算机视觉技术——在这些技术中，机器将学会“看到”图片中的模式并识别其中的内容！
