# 附录 B. 答案关键

# 第二章：答案关键

1.  B: 虽然 AWS 负责保护底层基础设施及其物理安全，但客户负责保护其应用程序、配置安全设置和管理其云环境。

1.  B: AWS Lambda 是一种无服务器计算服务。亚马逊 EC2 由于其提供虚拟化计算资源而成为 IaaS 服务。亚马逊 RDS 由于其托管数据库功能而成为 PaaS 服务。亚马逊 Chime 是一个用于通信的 SaaS 应用程序。

1.  C: 亚马逊 RDS 是一个托管的关系数据库服务，亚马逊 S3 提供存储能力，亚马逊 EC2 在云中提供可扩展的虚拟机，而 AWS Glue 用于数据准备和转换。

1.  B: 公共云环境不提供对基础设施的完全控制，或基于多租户模型通过共享资源实现成本节约。虽然公共云提供商实施强大的安全措施，但没有系统是完全免疫于网络威胁的。

1.  B: 云计算消除了公司购买和管理物理服务器的需求，提供对存储和计算能力等 IT 资源的按需访问，与私有数据中心等本地环境不同，虽然它可以支持 AI 应用，但其整体定义要广泛得多。

1.  B: IAM 负责管理权限、角色和策略以保护 AWS 资源，但不负责直接加密。相比之下，AWS CloudWatch 和 AWS CloudTrail 专注于监控和记录 AWS 内的活动，而 AWS Backup 是专门为自动化备份过程设计的特定服务。

# 第三章：答案关键

1.  A: 特征工程将原始数据转换为提高模型准确性和性能。尽管它可以帮助减少偏差，但它不是模型公平性的唯一决定因素。模型训练涉及一个从数据中学习模式的算法。模型评估在训练后评估性能。

1.  B: 监督学习涉及模型从标记的示例中学习，而强化学习通过试错、奖励和惩罚来训练模型。此外，异常检测通常采用无监督学习，而降维旨在减少输入特征的数量。

1.  D: SageMaker 简化并自动化了机器学习工作流程，使用户能够高效地训练、调整和部署模型。它还通过自动化减少了人工干预。它提供预训练和可定制的模型。

1.  C: 监督学习需要标记数据来学习模式，可用于分类和回归任务。相比之下，无监督学习在未标记数据中识别结构和模式，主要用于聚类和降维，而强化学习是一个与两者都不同的独立范式。

1.  C: 无监督学习用于在数据中聚类和寻找模式，而不需要预定义的标签，这使得它适用于客户细分。强化学习用于顺序决策，而不是聚类。监督学习不适合这项任务，因为它需要标记数据，而这通常在细分中不可用。半监督学习是一种混合方法，对于这项任务不是必要的。

1.  B: 模型监控的主要目的是跟踪性能随时间的变化，识别数据漂移等问题，并确保在现实世界应用中的准确度一致。它有助于确定何时需要重新训练，但并不消除重新训练的需求，因为没有任何机器学习模型可以在所有场景中保证 100%的准确率。尽管减少特征可以提高泛化能力，但这并不是监控的主要目标。

# 第四章：答案关键

1.  C: 生成对抗网络（GANs）采用两个相互竞争的神经网络——生成器和判别器——来生成逼真的内容。VAE 利用复杂的概率系统进行数据的编码和解码，而转换器模型利用注意力机制来理解复杂的模式。最后，扩散模型通过添加和去除噪声的过程创建逼真的内容，如图像。

1.  B: 位置编码在利用注意力机制的模式中至关重要，因为它重新排列了在应用注意力后变得无序的单词。它不会增强 GPU 的可靠性或降低 AI 模型的成本。反向传播是深度学习模型改进其结果的一种机制。

1.  D: RAG 的关键优势在于其能够从外部向量数据库中搜索数据，从而消除了修改模型内部权重的需求。虽然 RAG 通常使用较少的计算能力，但这并不是其主要优势。RAG 可能会因为数据处理而增加响应延迟。尽管 RAG 可以帮助减少偏差，但它并不能完全消除偏差。

1.  B: 由于注意力机制，转换器模型的一个关键优势是能够并行处理大量数据集，而循环神经网络（RNNs）则是按顺序处理数据。转换器和 RNN 模型都可以利用标记数据。RNNs 是为文本处理而设计的，而转换器通常需要大量数据进行训练。

1.  A: 转换器模型使用复杂概率系统处理大量数据集有时会导致错误或误导性的响应。虽然 GPU 对于 AI 至关重要，但并非不可预测。模型训练中存在标记数据并不必然导致幻觉。幻觉并非仅限于大型模型，也可能发生在小型和中型模型中。

1.  C: 隐藏层是应用权重到输入的地方，这使得模型能够检测模式。输入层接收原始数据，输出层产生网络的响应。神经网络中没有激活层。

# 第五章：答案关键

1.  C: NLP 是一个更广泛的领域，用于各种与语言相关的应用，如翻译和情感分析，而 IDP 是 NLP 的一个更专业的子集。IDP 主要专注于自动化处理业务文档，从结构化和非结构化格式中提取和分类信息。虽然 NLP 可以处理语音数据，但 IDP 的主要范围是文档输入，尽管两者都可以处理各种形式的输入，而不仅仅是手写或印刷语言。

1.  C: 亚马逊翻译服务提供在多种语言之间翻译文本的能力。亚马逊理解服务旨在进行 NLP 任务，如情感分析和实体识别。亚马逊 Polly 专注于将文本转换为逼真的语音。亚马逊 Textract 用于从图像和文档中提取文本。

1.  D: 亚马逊 Kendra 是一个利用自然语言查询的 AI 搜索服务；它不是一个财务分析工具。亚马逊翻译服务用于翻译外语，而亚马逊 Polly 提供文本到语音的转换服务。

1.  C: Kendra 使用 RAG 技术，使其能够生成更相关和上下文感知的搜索结果。Kendra 不使用量子数据库，线性回归也不是 Kendra 高级功能的核心。虽然关键词匹配是一种基本的搜索方法，但它不是 AI 功能。

1.  A: 亚马逊转录服务将音频转换为书面文本。亚马逊翻译服务将文本转换为其他语言。亚马逊理解服务可用于从文档中提取各种信息以进行情感分析。

1.  D: 亚马逊 Polly 提供从文本生成类似人类语音的能力。亚马逊转录服务将语音转换为文本，亚马逊翻译服务可以将文本翻译成其他语言，而亚马逊理解服务用于提取洞察力和执行数据分析。

# 第六章：答案关键

1.  B: 虽然模型将继续工作，但结合两者可能会导致不可预测的响应，通常不推荐这样做。同时使用两者并不能保证准确性，也不一定意味着响应将是确定性的。

1.  C: 负面提示用于排除不需要的元素（例如，模糊的、卡通的）。它不会改变图像的颜色或影响图像的大小。温度用于文本响应。

1.  D: 模态性指的是模型的输入和输出类型，例如文本、图像、音频和多模态。模态性与模型的许可类型、语言支持或是否可以无服务器部署无关。

1.  C: 较高的温度会使内容更具创意。较高的温度鼓励更不确定的内容，并且对于像摘要这样的任务也效果较差，因为内容将更加随机和具有创意。温度不用于创建视频。

1.  B: 亚马逊 Bedrock 中的模型配置文件不仅包括许可信息，还包括版本、发布日期、部署类型、模态性和模型 ID 等信息。它不会包括关于 GPU 使用或数据集的信息。

1.  B: 用户必须提交包含公司名称、用例和预期用户等详细信息的表格。配置模式与模型推理相关，而不是访问。使用模型不需要通过认证考试。模型不能直接从 Bedrock 下载。

# 第七章：答案关键

1.  C: 需要指令。没有指令，模型将不知道该做什么。上下文有帮助但不是必需的。当您希望模型分析特定内容时才需要输入数据。输出指示器用于格式化，但不是必需的。

1.  B: 输出指示器指导模型响应的外观，例如表格或 CSV 格式。输出指示器不提供如何编写更好的提示的示例。上下文组件提供任务的背景信息。提示与训练不同。

1.  B: 上下文通过提供相关背景信息，提高了模型理解任务的能力。输入数据组件提供相关输入数据。输出指示器指定输出格式。虽然上下文可以包括过去的交互，但它不是用来总结它们的。

1.  C: 分隔符通过显示输入开始的位置来提高提示的清晰度。它们不会减少令牌计数。它们不是用来分隔格式化选项的，而且它们只影响当前提示。

1.  B: 定义用户的角色有助于塑造 LLM 的理解和语气。

1.  C: 少样本提示是在你提供示例来引导模型的情况下。

# 第八章：答案关键

1.  C: 提前停止可以防止模型记住训练数据。增加模型的复杂性通常会增加过拟合的风险。噪声数据会增加方差并降低性能。调整超参数对于平衡偏差和方差很重要。

1.  D: 许可协议——如 OpenAI 与新闻集团的交易——被用来解决知识产权问题。移除所有公共数据是不切实际的，也不是标准解决方案。限制访问并不能解决知识产权所有权问题。内部限制会减少曝光，但这并不能完全解决知识产权问题。

1.  A: 没有准确性，模型可能不安全或不值得信赖。然而，即使是准确的模型也需要定期重新训练。准确性可能带来成本节约，但这并不是它对负责任的人工智能至关重要的核心原因。而且准确性对所有模型类型都很重要，而不仅仅是视觉模型。

1.  D: 公平意味着人工智能决策应该是无偏见的和非歧视性的。它与模型复杂性无关，它关注的是公平性，而不是速度。如果管理不当，个性化实际上可能会引入偏差。

1.  B: 可解释性帮助用户理解特定的输出，而透明度是关于系统级开放性的。这些概念密切相关但不可互换。用户界面设计与可解释性的核心概念无关。透明度在所有系统中都应得到鼓励，而不仅仅是开源模型。

1.  C: 隐私和安全是关于保护个人数据和用户权利的。模型权重和参数是技术方面，不是以用户为中心的。透明度与开放性相关，而不是数据保护。虽然知识产权很重要，但它不是隐私和安全的焦点。

# 第九章答案关键

1.  C: 管理为明智的决策和创新管理提供了一个结构，而合规性确保规则和标准得到持续遵循。管理不是关于强制执行法律。保护数据是安全的一部分，道德发展是跨职能共享的。管理对于组织成功至关重要，不是可选项。

1.  D: 深度防御意味着分层防御，以确保有多个安全措施。它假定没有任何单一的控制措施本身足够。尽管多层安全措施部分正确，但这并不能完全解释备份控制介入的概念。管道自动化的自动化很重要，但不是深度防御的一部分。

1.  C: AWS Shield 缓解 DoS 攻击，Amazon Cognito 安全处理用户身份验证和联合。GuardDuty 检测威胁，Private CA 管理证书。AWS KMS 和 AWS ACM 都有助于加密数据和管理证书。Amazon VPC 和 AWS WAF 帮助进行网络和 Web 层保护。

1.  A: PrivateLink 允许 VPC 和 AWS 服务之间进行私有连接，无需暴露公共互联网。Security Hub 聚合安全警报。Amazon VPC 创建私有网络，但并不专门处理服务间的私有路由。GuardDuty 检测可疑活动。

1.  C: 管理政策包括对数据来源、模型训练、结果评估和部署批准的明确标准。在人工智能治理中，人工监督至关重要，以确保道德使用。公共数据集仍需进行隐私和偏差评估。无限制的部署会增加法律、道德和运营风险。

1.  B: HIPAA 管理美国受保护健康信息（PHI）的安全和隐私。PCI DSS 专注于保护支付卡信息；GDPR 是关于欧盟居民的个人信息隐私；而 ENISA 专注于欧盟的网络安全标准。

# 实践考试答案关键

1.  B: AZ 提供了 AWS 区域内的冗余和容错。一个 AZ 由多个数据中心组成，但本身不是一个单一的数据中心。安全组控制访问，但不定义基础设施区域。AWS 区域与 AZ 分开，并且都不跨越多个大陆。参见第二章。

1.  C: SaaS 提供完全管理的应用程序。IaaS 提供虚拟化硬件，PaaS 为开发者提供工具，但这两者都不包括完全管理的应用程序。VaaS 不是一个标准的云计算模型。参见第二章。

1.  B: 混合云将私有和公有云环境集成在一起，以实现灵活性和降低成本。混合云允许在云环境之间共享数据和应用程序，而不是仅仅依赖本地系统。多租户是公有云的一个特性。请参阅第二章。

1.  B: AWS 区域通过允许用户在特定地理位置存储数据来帮助满足合规性需求。它们包含多个可用区（AZ），但并不取代它们。AWS 区域遍布全球。计算能力并非无限，冗余是 AWS 的核心特性。请参阅第二章。

1.  B: AWS Lambda 是一种无服务器计算服务，可以在不管理基础设施的情况下运行代码。Amazon EC2 要求用户管理服务器实例。Amazon RDS 是一种数据库服务。Amazon CloudFront 是一种内容分发网络（CDN）。请参阅第二章。

1.  B: Amazon S3 是为对象存储而设计的，提供可伸缩性、持久性和可用性。它不是一个关系型数据库。Amazon EC2 提供计算服务。Amazon CloudFront 是 AWS 的 CDN 服务，用于更快地交付内容。请参阅第二章。

1.  B: 混淆矩阵有助于通过显示正确和错误的预测数量来评估分类模型，特别是分析假阳性和假阴性。它不跟踪模型训练时间。使用的数据点的数量与模型评估是分开的。还需要额外的指标，如精确度、召回率和 F1 分数。请参阅第三章。

1.  C: 实时推理可以即时处理数据，这使得它在需要立即采取行动的欺诈检测中非常理想。批量推理用于在预定时间间隔处理大量数据集。异步推理适用于大型负载，但不适用于实时需求。按需推理适用于不频繁的查询，而不是持续的欺诈监控。请参阅第三章。

1.  B: 高维数据可能导致处理时间增加、内存使用增加以及模型过拟合，这使得提取有意义的见解变得更加困难。更多的维度通常需要额外的调整来防止过拟合，并且它们通常使解释更加困难，而不是更容易。更多的特征并不总是导致更高的准确性。请参阅第三章。

1.  D: 当输入数据的统计属性随时间变化时，会发生数据漂移，这会降低模型的准确性。当模型在训练数据上表现良好但在新数据上表现不佳时，就会发生过拟合，这不一定是因为长期变化。超参数调整优化模型，但不会解决数据分布随时间变化的问题。特征工程错误发生在数据预处理过程中。见第三章。

1.  C: SageMaker Model Monitor 跟踪已部署的机器学习（ML）模型，并提醒用户注意数据分布或概念漂移的变化。它不会加速训练。在 SageMaker 中独立管理部署，而不是通过 Model Monitor 进行。微调预训练模型是不同的机器学习任务，并非 Model Monitor 的目的。见第三章。

1.  C: SageMaker Data Wrangler 帮助自动化机器学习（ML）模型的数据预处理、特征工程和转换。Amazon Rekognition 用于图像和视频分析。Amazon Textract 从文档中提取文本。AWS Glue 是一种提取、转换、加载（ETL）服务。见第三章。

1.  B: Amazon Comprehend 提供自然语言处理（NLP）能力，包括情感分析。Amazon Textract 从扫描的文档中提取文本，但不分析情感。Lambda 用于无服务器计算。SageMaker Feature Store 用于存储机器学习（ML）模型特征。见第三章。

1.  B: 超参数调整通过调整学习率、批量大小等参数来优化模型性能。它不会生成新数据。数据预处理，而不是超参数调整，将分类数据转换为其他形式。调整可能会增加训练时间，而不是加快速度。见第三章。

1.  A: 扩散模型通过逐渐添加和移除噪声来创建逼真的内容。它们创建图像，而不是文本或声音。GANs，而不是扩散模型，使用竞争性神经网络。见第四章。

1.  B: 通过微调，您将根据专有数据集更改 FM 的参数，使其能够针对特定领域进行更专业化的定制。微调实际上使模型更加专业化，并且不会影响延迟。见第四章。

1.  D: 编码器将输入数据处理为转换器。它有助于找到上下文模式和关系。不是编码器，而是 AI 模型创建合成数据。微调超参数是一种提高模型性能的技术。您可以使用基准测试来评估模型，而不是编码器。见第四章。

1.  C: 大型语言模型（LLM）有上下文窗口。这些窗口固定了它一次可以处理的文本量。过拟合是指模型无法充分泛化关于某事物的情况。偏差通常与底层数据集的问题有关。判别器是 GAN 中的一个组件。它不会影响大型语言模型中可以处理的数据量。见第四章。

1.  A: RLHF 专注于通过结合人类偏好和反馈来改进生成式 AI 模型的响应。它不会影响模型的速度，并且可能会增加训练成本。深度学习模型通常是转换器模型的核心，这时会使用 RLHF。见第四章。

1.  B: 多模态模型允许处理不同类型的数据，如文本、图像和视频。它们通常需要大量的数据。它们并不一定比基于文本的模型更具可解释性。由于需要处理大量数据，GPU 对于多模态 FM 至关重要。见第四章。

1.  C: LLM 中的参数数量通常非常庞大，这意味着需要使用复杂的系统——如 GPU——来处理处理。RAG 确实会消耗计算资源，但这只是 LLM 整体中的一部分。LLM 使用复杂的线性代数，但这并不是大量使用计算资源的关键原因。人类反馈和评估是开发 LLM 过程中的一个较小部分。见第四章。

1.  B: RAG 将搜索一个包含专有文档的向量数据库。这些有助于提高响应的准确性。AI 模型可能有护栏，但这不是 RAG 所做的事情。RAG 也不会影响转换器模型中的概率算法，也不完全依赖于人类监督。见第四章。

1.  C: 亚马逊 Lex 通过使用意图和槽填充提供聊天机器人交互。您可以使用亚马逊欺诈检测器进行欺诈检测，亚马逊 Rekognition 进行视频分析，以及亚马逊 Textract 从扫描的文档中提取文本。见第五章。

1.  A: 亚马逊 Comprehend 允许您分析文本并提取关键信息。亚马逊 Transcribe 将音频转换为文本，亚马逊 Polly 将文本转换为语音，亚马逊 Translate 提供语言翻译。见第五章。

1.  D: 亚马逊 Rekognition 用于分析图像和视频。亚马逊 Transcribe 允许语音转文本转换。OCR 是亚马逊 Textract 的核心功能。您可以使用亚马逊 Lex 创建 AI 聊天机器人。见第五章。

1.  C: 词形还原是自然语言处理（NLP）预处理技术之一，有助于 AI 模型更有效地理解词语。NLP 模型通常不会自动纠正语法。翻译不是 NLP 中的预处理步骤。深度伪造检测用于媒体验证。参见第五章。

1.  D: 停用词去除法消除了那些意义不大的词。不常见的词通常比停用词更有信息量，因此自然语言处理（NLP）通常会更多地关注它们。停用词不会被去除以减少文本长度。参见第五章。

1.  D: 如果一个任务可以用传统软件处理，使用 AI 可能是不必要的且昂贵的。AI 在云环境中可以非常有效地工作。虽然人类监督很重要，但在许多情况下 AI 可以独立运行。AI 还可以处理复杂任务，而不仅仅是简单的自动化。参见第五章。

1.  D: 此功能允许你评估两个不同模型的响应，但它不会结合文本和图像响应或来自两个模型的响应。它也不会影响响应的长度。参见第六章。

1.  C: 微调使用标记数据定制模型以用于特定用例。由于需要额外的训练，微调实际上可能会增加计算成本，并且不会改善延迟。你不会在 Bedrock 中为图像使用微调。参见第六章。

1.  C: 开源模型提供了访问代码的权限，允许进行定制。还有来自贡献者社区的创新优势。Bedrock 仍然会为在 AWS 上托管模型收费。你可以指定实时推理，但默认情况下并未设置。虽然代码库可能可用，但数据集可能并非如此。参见第六章。

1.  A: 此类模型功耗更低，占用空间更小，更适合边缘设备。由于模型较小，上下文窗口可能也会更小。这种类型的模型并不意味着响应会更加有创意。较大模型的准确性可能更高。参见第六章。

1.  C: 每个代理都专注于某个特定领域，这有助于提高响应质量。你可以在 Bedrock 中使用任何类型的 AI 模型。因为生成式 AI 基于概率，所以不能保证 100%的准确性。多代理协作并不是关于编辑模型权重和偏差。参见第六章。

1.  D: 成本优势可能相当可观，与按需处理相比，高达 50%，但延迟通常很高。批量处理与上下文窗口无关，它不会影响模型的准确率。参见第六章。

1.  D: 提示模板提供可重用的结构，以促进清晰和效率。少样本提示意味着提示中已添加示例。零样本提示快速但通常一致性较差。思维链提示有助于推理，但不会影响提示的一致性。参见第七章。

1.  C: 思维链提示将推理分解成更小的步骤。少样本提示指定要使用哪些示例。输出长度限制了 LLM 的响应。提示不会调整模型参数。参见第七章。

1.  C: 少样本提示提供示例，以便模型可以学习模式。零样本提示不使用示例。思维链提示关注逐步逻辑。模板提示结构化提示，但不一定包括示例。参见第七章。

1.  B: 模型中毒是指攻击者恶意篡改训练数据以产生不道德或有害的输出。数据暴露允许模型处理个人健康数据。许可是一个法律问题。冲突的指令可能会使模型困惑，但这不被视为中毒。参见第七章。

1.  C: 暴露是指由于训练数据的一部分是机密或受监管的信息而泄露。公共使用可能存在风险，但本身并不构成暴露。训练过程中 GPU 性能的损失是硬件问题。在令牌限制内无法生成输出与隐私或数据安全无关。参见第七章。

1.  D: 解锁使用间接或复杂的提示来绕过模型的安全防护。硬件限制与解锁无关。重置模型的 API 令牌是 API 访问问题。除非设计用于保留会话历史，否则模型不会保留会话历史。参见第七章。

1.  B: 管理确保通过政策和监督实施负责任的 AI 实践。AI 管理不涉及营销或知识产权问题，也不是一种技术方法。参见第八章。

1.  C: 可控性确保 AI 可以被人类指导和监控。成本不是可控性的关键问题，速度与人类控制无关。参见第八章。

1.  A: 负责任的人工智能建立信任并提升品牌形象，这可以导致用户参与度的提高。数据收集仍然是必不可少的。负责任的人工智能旨在提高自动化并降低风险，尽管它不能消除所有错误。见第八章。

1.  C: SageMaker Clarify 突出显示偏差并帮助解释模型决策。它不扫描 URL，也不是为成本管理而设计的。数据加密由其他 AWS 工具处理。见第八章。

1.  D: 它支持在内容审核和翻译等任务中进行人工审查。它不关注模型训练速度，也不生成数据。GPU 管理不在 Amazon A2I 的范围内。见第八章。

1.  C: RLHF 使用人类输入来引导 AI 在复杂场景中的行为。它补充但不取代模型更新。RLHF 帮助系统适应，而不是保持静态。它仍然涉及某种形式的标记或反馈。见第八章。

1.  B: 意外能力是指可能产生新的合规风险的不预期行为。它们不涉及严格遵循功能。AI 系统不会自主处理监管报告。人类监督对于合规的 AI 操作仍然是必不可少的。见第九章。

1.  D: 受监管的工作负载必须遵守法律、行业或安全标准。它们通常涉及医疗保健、金融或航空航天等领域——而不是游戏。它们优先考虑安全、安全和问责制，而不仅仅是速度。合规性远不止加密；它涵盖了流程、监督和决策。见第九章。

1.  B: 记录提供用于跟踪、审计和改进模型性能的关键信息。数据记录与数据驻留分开。日志支持诊断和改进，但它们不能保证完美的准确性。见第九章。

1.  A: AWS Config 跟踪资源设置随时间的变化并帮助审计变更。AWS Trusted Advisor 提供建议。Amazon Inspector 专注于漏洞扫描。AWS Artifact 提供合规性文件。见第九章。

1.  D: 范围 1 指的是使用 ChatGPT 等公共生成式 AI 工具而不需要后端访问。预训练模型涉及使用现有模型构建应用程序，而不仅仅是使用公共工具。微调模型需要使用自己的数据调整模型，而不仅仅是简单使用。自训练模型涉及从头开始构建一切。见第九章。

1.  C: 亚马逊 Macie 利用机器学习来识别和分类敏感数据，如 PII 和 PHI。已验证权限有助于实现细粒度访问控制。Shield Advanced 专注于防止 DDoS 攻击。SageMaker 角色管理器协助为 ML 项目设置 IAM 角色。请参阅第九章。

1.  C: 模型卡提供了模型数据来源、使用指南、风险和限制的结构化摘要。它们不会触发重新训练。管理访问控制是 IAM 或类似服务处理的独立功能。计算优化与模型文档的目的无关。请参阅第九章。

1.  D: 客户和最终用户始终对其输入系统的数据进行控制。应用提供商可能控制其他类型的数据，但不能控制用户输入。云服务提供商托管基础设施，但不控制用户数据。数据标注团队对训练数据进行标注，但不控制用户生成的内容。请参阅第九章。
