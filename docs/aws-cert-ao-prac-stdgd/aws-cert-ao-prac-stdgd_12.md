# 附录 A. 实践考试

检查您的答案，请参阅“实践考试答案键”。

1.  可用性区域（AZ）是什么？

    1.  包含多个 AWS 服务器的物理数据中心

    1.  AWS 基础设施的逻辑分区，提供冗余

    1.  用于隔离 AWS 资源的安全组

    1.  涵盖多个大陆的区域

1.  哪种云服务模型向用户提供完整的应用程序，而无需他们管理基础设施？

    1.  基础设施即服务（IaaS）

    1.  平台即服务（PaaS）

    1.  软件即服务（SaaS）

    1.  虚拟化即服务（VaaS）

1.  混合云模型的一个定义特征是什么？

    1.  它专门使用私有数据中心处理所有工作负载。

    1.  它结合了公共和私有云环境。

    1.  它仅依赖于本地基础设施。

    1.  它使用多租户模型进行安全。

1.  AWS 区域的关键优势是什么？

    1.  它们消除了对可用性区域（AZs）的需求。

    1.  它们允许客户遵守数据居住要求。

    1.  它们仅在亚洲可用。

    1.  它们提供无限的计算能力，没有冗余。

1.  哪个 AWS 服务允许开发者部署应用程序而无需管理服务器？

    1.  Amazon EC2

    1.  AWS Lambda

    1.  Amazon RDS

    1.  Amazon CloudFront

1.  以下哪项最好地描述了 Amazon S3？

    1.  用于结构化数据存储的关系数据库服务

    1.  为耐用性和可用性而设计的可扩展对象存储服务

    1.  用于运行应用程序的高性能计算服务

    1.  用于加速网络流量的内容分发网络（CDN）

1.  使用混淆矩阵评估机器学习（ML）模型的主要好处是什么？

    1.  它显示了模型的训练时间。

    1.  它有助于分析假阳性和假阴性。

    1.  它计算训练中使用的总数据点数。

    1.  它消除了对额外性能指标的需求。

1.  一家银行希望实时检测欺诈交易。他们应该使用哪种类型的推理？

    1.  批量推理

    1.  异步推理

    1.  实时推理

    1.  按需推理

1.  使用高维数据集进行机器学习（ML）时面临的主要挑战是什么？

    1.  它减少了模型调整的需求。

    1.  它增加了计算成本和复杂性。

    1.  它使模型更有效地解释数据。

    1.  它确保了所有 ML 任务的更高准确性。

1.  一家公司注意到，由于客户行为的变化，其部署的机器学习（ML）模型随着时间的推移变得越来越不准确。这是哪个问题？

    1.  模型过拟合

    1.  超参数调整问题

    1.  特征工程错误

    1.  漂移

1.  使用 Amazon SageMaker Model Monitor 的主要原因是什么？

    1.  为了更快地训练深度学习模型

    1.  自动部署机器学习（ML）模型

    1.  为了检测数据漂移和概念漂移等问题

    1.  为了微调预训练模型

1.  一家公司希望通过自动化特征提取和转换来提高其数据处理管道的效率。哪个 AWS 工具最适合此目的？

    1.  Amazon Rekognition

    1.  Amazon Textract

    1.  Amazon SageMaker Data Wrangler

    1.  AWS Glue

1.  一家软件公司想要分析客户反馈以确定评论是正面、中性还是负面。他们应该使用哪个 AWS 服务？

    1.  Amazon Textract

    1.  Amazon Comprehend

    1.  AWS Lambda

    1.  Amazon SageMaker Feature Store

1.  机器学习中超参数调整的主要目的是什么？

    1.  为了创建新的训练数据

    1.  为了调整模型参数以改善性能

    1.  为了将分类数据转换为数值形式

    1.  为了加快训练过程

1.  扩散模型是如何工作的？

    1.  他们通过各种步骤添加和去除噪声。

    1.  他们使用竞争性神经网络。

    1.  他们只创建文本。

    1.  他们只创建声音。

1.  调整基础模型（FM）的主要目的是什么？

    1.  为了使模型更通用

    1.  为了定制特定领域的模型

    1.  为了降低延迟

    1.  为了从头开始训练模型

1.  编码器在转换器模型中是如何工作的？

    1.  它创建合成数据。

    1.  它微调超参数。

    1.  它评估模型预测。

    1.  它处理输入序列并提取有意义的表示。

1.  以下哪个描述了大型语言模型（LLM）一次可以处理的最大量？

    1.  过拟合

    1.  偏差

    1.  上下文窗口

    1.  判别器

1.  使用人类反馈强化学习（RLHF）在生成式 AI 模型中的原因是什么？

    1.  为了提高模型响应与人类偏好的对齐

    1.  为了降低训练成本

    1.  为了取代深度学习模型

    1.  为了降低模型的延迟

1.  多模态基础模型（FM）的关键好处是什么？

    1.  它需要较少的训练数据

    1.  它可以处理和创建不同类型的内容，如文本、图像和视频

    1.  它比基于文本的模型更具可解释性

    1.  它不需要 GPU

1.  在以下选项中，哪个是大型语言模型消耗大量计算资源的主要原因？

    1.  他们使用检索增强生成（RAG）。

    1.  他们使用复杂的线性代数。

    1.  他们处理数十亿个参数以生成准确的响应。

    1.  他们依赖于人类反馈和评估来处理所有响应。

1.  为什么 RAG 可以帮助降低 AI 模型中的幻觉？

    1.  它为某些类型的提示有防护措施

    1.  它搜索专有数据库以增强响应

    1.  它禁用了概率系统

    1.  它仅依赖于人类监督

1.  在这些选择中，Amazon Lex 的核心能力是什么？

    1.  它分析数据以进行欺诈检测。

    1.  它允许进行视频分析。

    1.  它支持意图和槽填充以创建对话式 AI 体验。

    1.  它自动从扫描的文档中提取文本。

1.  你可以用 Amazon Comprehend 做什么？

    1.  分析文本以提取见解，例如情感、关键词和实体。

    1.  将音频录音转录成文本。

    1.  将文本转换为类似人类的语音。

    1.  将文本翻译成多种语言。

1.  Amazon Rekognition 的主要能力是什么？

    1.  将口语语言翻译成文本。

    1.  使用光学字符识别（OCR）处理扫描文档。

    1.  生成 AI 驱动的聊天机器人响应。

    1.  在图像和视频中识别人脸、物体和场景的能力。

1.  在这些选项中，哪一项是自然语言处理（NLP）预处理中使用的技巧？

    1.  自动纠正句子中的所有语法错误。

    1.  在处理前将文本翻译成另一种语言。

    1.  词形还原，将单词还原为其词根形式。

    1.  将深度伪造检测应用于验证文本的真实性。

1.  为什么在自然语言处理（NLP）预处理中使用停用词去除？

    1.  停用词为文本增添了重要意义。

    1.  它有助于去除不常见的单词，以便只关注常用术语。

    1.  停用词被移除以缩短文本长度，从而加快处理速度。

    1.  移除如“the”和“is”之类的停用词有助于提高效率，同时不失重要意义。

1.  当 AI 不是商业用例的最佳解决方案时是什么时候？

    1.  AI 模型在基于云的环境中表现不佳。

    1.  AI 始终需要人类监督。

    1.  AI 只能用于简单的自动化任务。

    1.  当更简单的方法可能足够时，AI 解决方案可能既复杂又昂贵。

1.  Bedrock 游乐场中的“比较模型”功能是什么？

    1.  它允许使用图像和文本响应。

    1.  它允许为两个不同的模型提供更长的响应。

    1.  它结合了两个模型的响应。

    1.  它允许评估来自两个不同模型的并列响应。

1.  为什么你会在 Bedrock 中对模型进行微调？

    1.  为了降低计算成本

    1.  为了提高延迟

    1.  为了提高特定领域场景的响应准确性

    1.  为了使用图像

1.  使用 AWS Bedrock 中的开源基础模型（FMs）的关键优势是什么？

    1.  它们始终免费使用。

    1.  它们默认支持实时推理。

    1.  它们提供透明度、定制和社区创新。

    1.  它们提供代码库和数据集。

1.  在 Bedrock 中使用蒸馏模型的好处是什么？

    1.  它减少了计算需求，使其适合边缘设备。

    1.  它增加了上下文窗口。

    1.  它增加了响应的创造力。

    1.  它保证了比大型模型更高的准确性。

1.  Bedrock 中多智能体协作的关键好处是什么？

    1.  它依赖于蒸馏模型。

    1.  它提供 100%的准确性。

    1.  它允许不同的智能体专门从事特定任务，从而更好地解决问题。

    1.  它使用户能够编辑模型权重和偏差。

1.  使用 Bedrock 进行批量处理的关键好处是什么？

    1.  存在低延迟。

    1.  上下文窗口无限。

    1.  准确性更高。

    1.  成本更低。

1.  哪项技术在使用时可以提高提示的一致性和清晰度？

    1.  少样本提示

    1.  零样本提示

    1.  思维链提示

    1.  提示模板

1.  思维链（CoT）提示的目的是什么？

    1.  为大型语言模型（LLM）指定要使用的示例

    1.  为了限制大型语言模型（LLM）的响应

    1.  为了允许对复杂问题进行逐步推理

    1.  为了调整大型语言模型（LLM）的参数

1.  哪种提示类型涉及提供几个示例以帮助模型学习模式？

    1.  零样本提示

    1.  思维链（CoT）提示

    1.  少样本提示

    1.  模板提示

1.  什么是模型中毒？

    1.  这使得模型能够处理个人健康数据。

    1.  这就是当有偏见或恶意数据被注入到训练过程中时。

    1.  这时模型缺乏适当的许可。

    1.  这是在单个提示中存在冲突指令的地方。

1.  与基础模型（FMs）的安全风险相关的暴露是什么？

    1.  模型在消费者应用中的使用

    1.  训练期间 GPU 性能的损失

    1.  训练集中无意中包含敏感数据

    1.  在令牌限制内未能生成输出

1.  基础模型（FM）的越狱是什么？

    1.  不使用 GPU 加速运行模型

    1.  重置模型的 API 令牌以扩展访问权限

    1.  删除模型的训练历史

    1.  欺骗模型绕过安全和伦理限制

1.  以下哪项最能描述 AI 治理？

    1.  AI 采用的营销策略集

    1.  指导道德 AI 发展的政策和监督结构

    1.  AI 生成内容的法律所有权

    1.  构建大型语言模型（LLMs）的技术

1.  AI 中的可控性关注什么？

    1.  降低计算成本

    1.  构建更快的 AI 系统

    1.  将 AI 行为与人类意图和监督对齐

    1.  移除人类参与

1.  以下哪项是采用负责任 AI 实践的商务优势？

    1.  增强信任和改善品牌声誉

    1.  降低数据收集的需求

    1.  对人类干预的依赖增加

    1.  消除所有算法错误

1.  Amazon SageMaker Clarify 在负责任 AI 中扮演什么角色？

    1.  在用户提示中检测有害 URL

    1.  在训练期间管理计算成本

    1.  识别和解释数据和模型中的偏差

    1.  加密训练数据

1.  Amazon Augmented AI（A2I）主要用于什么？

    1.  加速神经网络的训练

    1.  从头创建合成数据

    1.  在 SageMaker 中管理 GPU

    1.  将人工审查整合到 AI 工作流程中

1.  强化学习从人类反馈（RLHF）的关键优势是什么？

    1.  它消除了模型重新训练的需要。

    1.  它确保 AI 系统保持静态。

    1.  它有助于模型使输出与人类偏好和判断一致。

    1.  它消除了数据标注的需要。

1.  由 AI 系统开发新兴能力引起的合规风险是什么？

    1.  它严格遵循预编程功能，没有惊喜。

    1.  它们可能会以原始设计者未计划的方式不可预测地表现。

    1.  随着它们的变化，它们会自动提交合规报告。

    1.  它们防止了任何人类监督的需要。

1.  调制工作负载的关键特征是什么？

    1.  它仅适用于游戏或娱乐系统。

    1.  它只关注使系统更快，而不是更安全。

    1.  它只需要加密存储的数据。

    1.  由于法律、行业或安全方面的考虑，它必须遵循特定的合规规则。

1.  为什么在 AI 系统中记录数据日志很重要？

    1.  它通过跳过错误检查来加速模型训练。

    1.  它捕获输入、输出和系统事件，支持调试、监控和透明度。

    1.  它防止了数据居住地合规性的需求。

    1.  它自动保证 100%的模型准确性。

1.  哪个 AWS 服务提供资源配置更改的详细历史记录及其与合规性审计的关系？

    1.  AWS 配置

    1.  AWS 受信任顾问

    1.  亚马逊检查器

    1.  AWS 文件

1.  在生成式人工智能安全范围矩阵中，哪个范围涉及使用公开可用的生成式人工智能工具，而没有后端访问或定制？

    1.  范围 3：预训练模型

    1.  范围 4：微调模型

    1.  范围 5：自训练模型

    1.  范围 1：消费者应用

1.  哪个 AWS 服务使用机器学习（ML）来检测和分类您的环境中敏感数据，如个人身份信息（PII）或受保护的健康信息（PHI）？

    1.  AWS 验证权限

    1.  AWS 防护盾高级版

    1.  亚马逊麦奇

    1.  亚马逊 SageMaker 角色管理器

1.  在生成式人工智能的背景下，模型卡的目的是什么？

    1.  为了自动使用新数据重新训练模型

    1.  为了管理跨云基础设施的访问控制

    1.  为了记录模型的数据来源、预期用途、风险和限制

    1.  为了优化计算资源以实现更快的模型部署。

1.  在生成式人工智能系统中，无论应用范围如何，谁总是控制用户数据？

    1.  应用程序提供商

    1.  云服务提供商

    1.  数据标注团队

    1.  客户或最终用户
