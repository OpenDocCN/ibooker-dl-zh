# 第三章：选择和评估人工智能工具

### 本章涵盖

+   不同类型人工智能或使用人工智能的方式之间的区别，以及如何选择最合适的一种

+   如何评估人工智能的性能并选择模型

+   测量人工智能在任务中性能的常见方法

本章提供了关于选择人工智能模型或工具以及评估其在特定任务中性能的指导。我们首先讨论了不同类型人工智能的三个常见区别：专有与开源人工智能、现成与微调人工智能，以及人工智能应用与基础模型。我们解释了这些含义以及如何选择最合适类型。之后，我们讨论了评估人工智能性能的常见流程，该流程使用不同的数据集进行验证和测试。我们还讨论了一些常见的性能指标，如准确率。附录包括流行生成式人工智能工具的目录。

## 专有与开源

在专有人工智能中，用户不允许修改甚至查看驱动底层机器学习模型的代码。该技术的内部运作被保密，以防止他人复制。使用专有人工智能的一种常见方式是通过面向客户的软件，如 ChatGPT。这些通常向用户收取月度订阅费以访问服务，尽管一些提供免费层，允许访问较少的功能。

另一种使用专有人工智能的常见方式是通过 API。这些 API 允许用户以编程方式与人工智能交互，以构建利用它的应用程序。人工智能软件在远程服务器上运行，因此用户看不到代码。API 通常根据使用情况（例如，输入和输出令牌的数量）计费。

相比之下，在开源人工智能中，提供商公开披露了机器学习模型的内部细节，包括使用它的代码和所有模型参数的值。如果需要，用户通常被授权修改或定制模型。此外，用户可以使用自己的基础设施自行托管这些模型；例如，您可以将模型的副本下载到您的本地计算机或自己的云计算实例上并自行运行代码。这并不意味着您*必须*自行托管模型，因为它也可能通过 API 提供，但您有选择自行托管它的选项。开源人工智能的一个例子是 Meta 生产的 Llama 模型系列，这些模型在多个网站上公开提供下载。

开源人工智能有时并不像听起来那么开放。首先，它们的制造商不会披露用于训练这些模型的数据。因此，虽然您可以查看最终模型的参数，但您无法自己训练那个精确的模型，因为您不知道要使用哪些数据。提供开源人工智能的 Mistral AI 公司解释说（[`mng.bz/rKQy`](https://mng.bz/rKQy)）：

> 我们不公开我们的训练数据集。我们保留一些中间资产（代码和资源）的专有性，这些资产是生产开源模型和优化模型所必需的。其中还包括模型的训练逻辑和用于训练的数据集。

注意，就像专有模型一样，开源模型是通过使用带有人类反馈的强化学习（见第一章）来改进（或对齐）的。这通常是通过由人工标注员手动创建的数据来完成的，在大多数情况下这些数据保持未公开。

使用开源 AI 的许可证通常带有限制。例如，你不允许在一个每月有超过 7 亿用户的 APP 中使用 Llama 模型——即使是你的副本（见[`mng.bz/VVoG`](https://mng.bz/VVoG)）。在这种情况下，你将不得不与 Meta 讨论许可选项，并且可能需要付费。此外，你不允许使用 Llama 模型或其输出以提高其他 LLMs；换句话说，你不能使用 Llama 来构建与其竞争的产品。

构建大型 ML 模型成本高昂，因此最强大的开源 AI 是由盈利公司构建的，这些公司收取或打算收取服务费用。这些服务通常包括咨询或访问高级专有模型。

### 如何决定

专有 AI 最适合当你需要一个现成的解决方案时。使用专有 AI 通常不需要专业知识，例如机器学习、编码和 DevOps。

使用开源 AI 的一个主要原因是能够自行托管它（在自己的服务器上运行），这可以提供更好的透明度和治理，因为你可以完全了解代码，并完全控制哪些数据离开组织。你的公司可能不想将任何敏感数据发送给第三方，例如 OpenAI，或者它可能想审计代码以确保它不会做它不应该做的事情。

然而，自托管 AI 的成本往往高于支付 API 的费用，因为你需要维护所需的基础设施，所以除非在非常大的规模上操作，否则通常不具有成本效益。你还需要非常小心——过去已经发布了恶意开源模型，这些模型在用户的机器上执行了意外的代码（见[`mng.bz/xKeX`](https://mng.bz/xKeX)）。

使用开源 AI 的另一个原因是定制。如果你想修改一个模型（例如，通过微调它，这在下一节中介绍），那么开源 AI 让你可以最自由地这样做。表 3.1 总结了专有 AI 和开源 AI 的最佳用途。

##### 表 3.1  专有 AI 与开源 AI 的比较

| 专有 AI 最佳用途 | 开源 AI 最佳用途 |
| --- | --- |
| • 一站式解决方案• 易于开始• 无需专业知识• 小规模使用，其中按需付费的 AI 比维护自己的基础设施更便宜 | • 自托管以享受更好的治理和透明度• 大规模使用，其中维护自己的基础设施比按需付费的 AI 更便宜• 模型定制（例如，微调） |

在输出质量方面，专有 AI 曾经比开源 AI 有优势。然而，差距正在缩小，许多人声称开源 AI 已经或很快将与其专有对应物一样强大。

## 现成的模型与微调

当提到提高生成式 AI 在特定任务上的性能时，存在两种主要的思想流派。其中之一是使用现成的模型——没有任何修改——并且它依赖于提示工程技术来提高其性能并使其更适合你的目标任务。例如，在提示中包含一些如何执行任务的演示已经变得很流行，这被称为*少样本提示*（与不提供任何示例的*零样本提示*相对）。这有助于消除歧义。来自 OpenAI 的研究人员争论([`arxiv.org/pdf/2005.14165`](https://arxiv.org/pdf/2005.14165))：

> 如果有人被要求“制作 200 米短跑的世界纪录表”，这个请求可能是模糊的，因为它可能不清楚表格应该有什么格式或应该包含什么内容（即使经过仔细的澄清，精确理解所需的内容也可能很困难）。

研究人员继续表明，在提示中包含一些如何执行任务的示例可以引导 LLM 走向正确的方向。

此外，RAG 方法（见第一章）已成为向 LLM 提供大量上下文信息以帮助其执行任务的一种流行方式。最先进的 LLM 的日益增大的上下文窗口使得 RAG 特别有效。

改进的提示可以帮助定制图像生成。例如，图像生成器 Midjourney 允许用户将图像作为他们提示的一部分上传，以指示生成图像所需的风格。

另一种思想流派建议修改模型以使其更适合目标任务，这被称为*微调*。模型的内部参数被调整，因此你使用修改后的原始模型的副本来生成你的输出。

微调需要训练数据，这些数据用于继续对原始模型进行更长时间的训练。例如，为了微调一个 LLM，你必须创建一个符合你预期风格的文本样本。这些数据被输入到训练算法中，以细化 LLM。用于微调的数据量通常比用于训练原始 LLM 的数据量小得多——你可能只需要几份文档就能做到这一点。开源模型非常适合微调，因为你可以访问整个模型及其参数，然后你可以调整参数以更好地满足你的需求。

微调可能面临的最大挑战可能是过度调整——如果你在微调训练数据上过度专门化你的模型，它可能会记住数据中存在的特定示例，而无法在其他实例上表现良好。这被称为*过拟合*。

有几种技术可以防止过拟合（见侧边栏）。你需要注意这些技术，并适当地配置微调算法以防止过拟合。我们将在本章后面讨论如何使用验证集和测试集来评估和比较不同的 AI 模型，这有助于选择最佳的微调策略，并确保最终模型没有过拟合数据。

##### 控制过拟合的技术

*提前停止**—*你只在微调数据上训练模型几次迭代。一旦性能不再提高（在单独的数据上衡量，称为*验证集*），你就停止训练。

*更新范围有限**—*你只允许模型的一些部分被更新。例如，一种名为 LoRA 的流行方法将带有新可学习参数的小层插入到模型中，同时保持其原始参数不变。

*正则化**—*你会在损失函数中添加一个项，惩罚过高的或过低的参数值。这通过防止参数过度专门化到特定的训练示例来降低过拟合的风险。

*Dropout**—*在训练过程的每次迭代中，随机移除模型的一部分，这防止了模型的内部单元过度专门化到训练示例。

一种称为 LoRA 的方法已成为微调（见[`arxiv.org/abs/2106.09685`](https://arxiv.org/abs/2106.09685)）的流行方法。LoRA 通过插入带有新可学习参数的小层来调整现有模型，而不是修改其原始参数。这使得微调更快，因为每个迭代只需要计算少量参数更新。它还有助于控制过拟合，因为你只修改了有限数量的参数（见侧边栏中的“更新范围有限”）。

Hugging Face 开发的库非常受欢迎，用于微调现有模型（[`huggingface.co/docs/trl/main/en/index`](https://huggingface.co/docs/trl/main/en/index)）。Hugging Face 还包含大量开源模型，您可以对其进行微调。许多用户通过连接到云计算实例的 Jupyter 笔记本进行微调。Google Collab 特别常用，因为它提供了易于访问的笔记本，并允许您免费使用其部分计算能力，这可能足以微调一些模型。

微调需要一些专门的机器学习知识，所以我建议您学习 ML 的基础知识以正确进行。您可能还需要基础设施来运行微调过程，然后您将不得不使用自己定制的模型副本。

在某些情况下，也可以微调专有 AI。例如，OpenAI 允许您上传自己的微调数据集并创建其模型的微调版本，您可以通过 API 访问。与使用 OpenAI 的原始模型相比，公司对使用微调模型收取额外费用。该过程友好，尽管不如微调开源模型可定制。

### 如何决定

提示工程是提高模型性能的最直接方法。常见的建议是，这是您应该尝试的第一件事（更多信息请参阅[`mng.bz/AQZx`](https://mng.bz/AQZx) 和 [`mng.bz/ZlQA`](https://mng.bz/ZlQA)）。随着上下文窗口变得很大，提示可以相当丰富。因此，当尝试了多种改进提示的方法后，输出仍然不是您期望的那样时，通常建议将微调作为最后的手段。然而，请注意，提示工程与最先进且成本最高的模型结合得最好，因为它们可以更好地适应更广泛的任务，并在它们的上下文窗口中适应更长的提示。表 3.2 比较了现成的 AI 与微调 AI。

##### 表 3.2  现成的 AI 与微调 AI 的比较

| 现成的 AI 最佳使用场景 | 微调 AI 最佳使用场景 |
| --- | --- |
| • 提示工程技巧效果良好。• 使用专有 AI 是可以的。• 您可以负担得起大型模型。• 您优先考虑易用性。 | • 您希望获得高度定制的输出，并且已经用尽了其他选项。• 您需要使用较小的模型（例如，用于自托管）。• 您拥有机器学习专业知识和访问计算资源。 |

对于较小的模型，微调可能是一个不错的选择，例如，因为您想降低成本。这在您必须自托管自己的模型时尤其相关。在这种情况下，使用小型、微调的模型可能比使用大型模型的提示工程更有效。

## 面向客户的 AI 应用与基础模型

面向客户的 AI APP 帮助最终客户完成任务。这些包括通用商业聊天机器人，如 ChatGPT，以及特殊用途的 APP，如 GitHub Copilot 和 Cursor，这些 APP 帮助软件工程师编写代码。

相比之下，基础模型是大型、多用途的 AI 模型。这些模型在幕后用于为面向客户的 APP 提供动力。例如，GPT-4o 等基础模型被用于为面向客户的 ChatGPT 提供动力。

一些公司既构建面向客户的 APP，又通过 API 提供其底层基础模型的访问权限，以便软件开发者可以在其上构建自己的 APP。

### 如何决定

当您希望 AI 协助您完成特定任务时，面向客户的 APP 是最合适的选择，因为它们易于使用，并且特别针对任务进行了定制。基础模型在您希望基于强大的 AI 创建自己的 APP 时，最好用作构建块。表 3.3 比较了面向客户的 AI APP 与基础模型。

##### 表 3.3  面向客户的 AI APP 与基础模型

| 面向客户的 AI APP 适用于... | 基础模型适用于... |
| --- | --- |
| • 特定任务的协助• 最终用户 | • 支持基于 AI 的 APP• 工程师 |

## 模型验证、选择和测试

如果您想准确比较和选择 AI 模型，建立一个基准来评估它们的各自性能是个好主意。此外，由于一些原因将在后面变得明显，我们经常高估机器学习的性能，因此遵循一个精心设计的评估过程以避免意外是个好主意。

本节描述了评估 AI 在任务上性能的理想协议。在这个协议中，AI 模型使用三种不同的数据集进行构建和评估，这些数据集被称为*数据集*。以下，我们将描述每种类型数据集的作用以及如何使用它们。

### 训练集

训练集是用于构建模型的数据库。它包含大量如何执行任务的示例。例如，对于图像生成，它包括大量与描述其内容的标题配对的图像。对于文本生成，它包括大量文本。还使用了一个较小的训练集来微调模型。

在训练或微调期间，训练算法试图找到最小化训练集损失的模型参数（见第一章）。损失是一个数学函数，它量化了模型在执行所需任务时的偏差程度，例如在 LLMs 的情况下预测下一个标记。

损失通常被设计成具有良好的数学属性，例如可微性，因此它不总是理解模型性能的最直观方式。此外，损失并不总是量化模型在你期望的任务上的表现。例如，如果你想使用人工智能来解决编码问题，训练损失并不明确量化其编码能力；相反，它量化了它自动完成文本的能力，这仅与编码能力间接相关。

除非你正在微调模型或从头开始训练模型，否则你不必过于担心创建训练集。然而，在创建验证集和测试集时，你可能需要注意用于训练的数据（关于这一点，稍后还会详细介绍）。

### 验证集

验证集用于比较不同模型的性能。例如，你可以使用验证集来比较 GPT-4o 和 Llama 3 在执行任务时的性能。这有助于你选择最佳模型，这被称为*模型选择*。

验证集上的性能通常使用接近你实际业务目标的度量来计算。例如，你可以计算模型正确解决编码问题的频率。注意，这通常与用于训练或微调模型的损失函数不同。本章后面将列出常见的性能度量。

确保验证集中的数据不在训练集中出现非常重要。否则，你可能会高估模型的性能。这是因为一个过度拟合训练数据（它记住了特定实例）的较差模型可能不会被检测到，因为一些被记住的数据也可能出现在它所评估的验证集中。如果验证集包含在训练集中，这就像是一场包含教科书上直接出现的问题的考试——学生可以记住答案而不真正学习并通过考试。

当使用大型语言模型（LLM）时，你需要特别注意这一点，因为它们是在包括许多问题解决方案在内的海量公开数据上训练的。假设你想使用 LLM 来帮助你解决填字游戏。你可以通过收集过去出版的真实《纽约时报》填字游戏的线索来创建一个验证集。然后，你统计 LLM 根据线索识别正确单词的频率。问题是，有众多网站明确提供了所有过去《纽约时报》填字游戏的解决方案，线索逐个列出。因此，至少在理论上，LLM 可以记住每个过去线索的确切解决方案。因此，你的验证数据将评估 LLM 解决其已有答案的问题的性能。更好的方法是创建一个包含过去谜题中未出现的新线索的验证集。这样，LLM 就无法“作弊”。或者，你可以确保验证集中的谜题是在 LLM 的训练数据截止日期之后出版的。

验证集也可以在你训练或微调自己的模型时帮助你做出高级决策。例如，你可以训练两个具有不同层数或不同学习率（模型参数在每次训练迭代中更新的程度）的模型，然后在验证集上选择性能最高的模型。你也可以使用验证集来比较不同的提示工程方法。

### 测试集

仅使用验证集不足以正确评估模型的表现。因为你专门选择了在验证集上表现最好的模型，你可能会对其性能有一个过于乐观的看法。毕竟，你丢弃了在该特定数据上表现不佳的模型。如果选定的模型只是偶然在验证数据上表现良好，而不是一个更优秀的模型，那会怎样？

因此，在你使用验证集挑选出最佳模型之后，你必须使用*另一个*数据集进行最终检查，这个数据集被称为*测试集*。测试集让你了解模型在从未用于建模决策的数据上的性能。这种最终评估是一种理智的检查。

测试集只能使用一次。如果在测试后发现性能令人失望，想要更新模型或考虑其他选择，你必须收集一个新的测试集来进行新的评估。否则，你将反复使用测试集进行模型选择，使其变成验证集。

在遵循此过程时，您需要决定您希望有多彻底。我知道一些对遵循此过程非常严格的对冲基金，因为涉及的资金量很大。例如，他们甚至试图不去查看测试集中的数据，比如绘制图表。这样，他们可以防止关于测试数据的知识渗透到建模决策中，从而使测试数据尽可能独立。

## 性能指标

本节描述了一些可以用来评估 AI 在预期任务中性能的常见性能指标。

### 准确度

*准确度*是任务执行正确的百分比。例如，90%的准确度意味着在验证集或测试集上测量的解决方案中有 9 个是正确的。

准确度通常用于分类任务。例如，它经常用来评估 AI 在分类图像或检测推文的情感方面的好坏。您还可以将其用于其他问题解决任务。例如，您可以使用准确度来衡量一个 LLM 解决编码问题的能力——您需要计算正确解决的问题数量，并将其除以验证集或测试集中的总问题数。

### 精确度和召回率

在信息检索中，我们感兴趣的是从大量数据中识别相关实例。例如，一家律师事务所可能使用 RAG 方法根据查询从大量过去的案例数据库中检索相关法律案例。作为另一个例子，一家银行可能希望从（希望是）更大的交易池中识别欺诈交易。

两个常见的性能指标是召回率和精确度。然而，正如我们稍后将讨论的，这两个指标都不能单独使用。

*召回率*衡量识别出的相关实例数量。例如，90%的召回率意味着 10 个相关实例中有 9 个被检索到，其余的未被检索到。

*精确度*衡量检索到的实例的相关性。例如，90%的精确度意味着 10 个检索到的实例中有 9 个确实是相关的，其余的要么是不相关的，要么是误报。

挑战在于精确度和召回率之间存在权衡。考虑一个检索过多内容的系统。例如，它可能确定几乎所有过去的法律案例都与每个查询相关。这个系统将实现非常高的召回率，可能接近 100%。然而，它将受到大量误报的困扰，因此其精确度会非常低。

相比之下，考虑一个几乎不检索任何内容的系统。例如，它可能认为几乎每个过去的法律案例都与查询无关。这个系统将实现接近 100%的精确度，但召回率会非常低。

因此，为了正确量化 AI 在信息检索方面的性能，您必须以某种方式将召回率和精确度结合成一个单一指标。一种常见的方法是计算*F 度量值*，它是精确度*P*和召回率*R*之间的调和平均（一种平均数）：

F = 2(P R)/(P + R)

F-measure 越高，召回率和精确率就越高。当召回率和精确率都达到 100% 时，它达到最大值。

我对 F-measure 不太感冒，原因有两个。首先，它对召回率和精确率给予同等的重要性。这是任意的。在现实中，企业可能不会对它们同等关心。我建议您对任何关于信息检索普遍适用的度量（无论是 F-measure 还是其他什么）的承诺持谨慎态度，因为精确率和召回率的相对需求是业务特定的。

第二，F-measure 难以解释，因为调和平均数并不直观。技术上，F-measure 是倒数平均数的倒数，经过一些代数运算后得到上述公式。祝您在与企业沟通这一点时好运！

在我看来，您的最佳选择是尝试理解企业在精确率和召回率方面的偏好，并据此制定一个考虑这些因素的定制度量。在接下来的段落中，我将解释我偏好的这种方法之一。

第一步是理解企业对召回率的最小期望水平（也可以用精确率来做，但这里我们使用召回率）。例如，企业可能希望确保至少召回 95% 的相关法律案例或欺诈交易。

然后，您调整系统以达到所需的召回率水平。一种方法是让 AI 输出相关性作为数值分数，分数范围从 0（完全不相关）到 1（完全相关）。高于某个相关性阈值的实例被认为是相关的。您选择有助于您达到所需召回率的阈值。例如，设定一个阈值为 0.7，高于这个阈值，实例被认为是相关的，可以帮助您达到所需的 95% 召回率（您可以使用验证集来计算阈值）。

最后，您使用另一个度量——在本例中是精确率——来报告性能。因此，您可以通过模型（所有达到所需的召回率）的精确度来比较不同的模型。

### 平均绝对误差和均方根误差

如果您使用 AI 进行数值预测，例如降雨量，您必须计算预测值与实际值之间的偏差。一种简单的方法是计算训练集或测试集中预测值与已知值之间的绝对差异，并平均结果。这被称为 *平均绝对误差*，或 MAE。

另一种方法是平方差异，使它们都变为正值，然后平均这些结果，最后取这个数的平方根以（某种程度上）抵消平方的影响。这被称为*均方根误差*，或 RMSE。由于它具有很好的数学性质（特别是其可微性）并且由于平方差异的平方，它对较大偏差的惩罚更多，因此这个度量相当受欢迎。然而，它不像 MAE 那样容易解释。

## 摘要

+   当你需要一个易于使用、现成的解决方案时，专有 AI 是一个不错的选择。

+   当你需要自行托管或定制模型时，开源 AI 是一个不错的选择。

+   如果人工智能没有按你期望的方式工作，或者你需要对其进行定制，通常建议仍然使用现成的模型并增强你的提示。如果这还不行，你可能想对你的数据进行微调。当你更喜欢使用较小的模型时，微调也是一个好选择。

+   面向客户的 AI 应用程序旨在对最终用户友好且有用。它们由幕后的大型通用 AI 模型提供支持，你可以使用这些模型来构建自己的基于 AI 的应用程序。

+   确保使用一个验证集（包含不在训练集中的数据）来比较和选择模型。一旦你选定了你最喜欢的模型，你也应该使用一个单独的测试集进行合理性检查。不要两次使用测试集。

+   模型的准确性衡量它正确执行任务的频率。例如，在信息检索中（例如，根据查询从大量法律案件中检索相关法律案例），使用精确度和召回率。精确度和召回率不能单独使用；它们必须以与业务偏好相匹配的方式结合，以反映它们相对重要性的关系。你可以使用平均绝对误差（MAE）或均方根误差（RMSE）来评估模型在预测数字（如降雨量）方面的性能。
