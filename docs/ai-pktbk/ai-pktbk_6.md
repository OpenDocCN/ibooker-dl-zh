# 附录 A  生成式 AI 工具目录

本附录列出了在撰写时许多流行的生成式 AI 工具。我预计 AI 市场的某些部分将组织成寡头垄断，这意味着将只有少数几个关键玩家而不是众多玩家。这尤其适用于构建基础模型的公司，因为模型训练涉及高昂的一次性成本，很少有公司能够承担得起。因此，基础模型市场将类似于云计算市场，该市场由三个主要竞争对手主导。

此外，我预计在模型能力方面将出现趋同，因为不同的基础模型正变得越来越相似。似乎也存在构建多模态 AI 的趋势，因此您可能不需要使用不同的模型来处理文本、图像和视频。

在其他情况下，例如较轻的 AI 应用（例如，围绕 LLM 的简单包装）或较小的专业 AI 模型，我们可能会观察到众多竞争对手。这个市场可能类似于健身应用市场，其中有许多选择。

## 通用对话式 AI

让我们先看看通用 AI 聊天机器人的市场，该市场分为面向客户的 APP、专有基础模型和开源基础模型。

### 面向客户的 APP

+   *ChatGPT*——由 OpenAI 开发的人工智能助手。它基于免费增值模式（免费访问某些功能，以及每月订阅以访问额外功能）。它可以在[`ChatGPT.com`](https://ChatGPT.com)访问。

+   *Claude*——由前 OpenAI 员工创立的 AI 公司 Anthropic 开发的人工智能助手。它基于免费增值模式，可以在[`claude.ai`](https://claude.ai)访问。

+   *Gemin*——由谷歌的子公司 Google DeepMind 开发的人工智能助手。它基于免费增值模式，可以在[`gemini.google.com`](https://gemini.google.com)访问。

+   *Microsoft Copilot*——由微软开发的人工智能助手。它基于免费增值模式，可以通过各种微软应用程序访问，例如 Word 和 Excel，以及直接通过浏览器在[`copilot.microsoft.com`](https://copilot.microsoft.com)访问。您还可以直接从 Windows 11 任务栏访问 Copilot，并且一些电脑已经在键盘上配备了专门的 Copilot 键。

+   *Perplexity AI*——一个免费增值 AI 聊天机器人，旨在用作搜索引擎。它依赖于各种基础模型，包括一些由其他公司（如 OpenAI 和 Anthropic）制造的基础模型。它可以在[`perplexity.ai`](https://perplexity.ai)使用。

### 基础模型（专有）

+   *GPT*——由 OpenAI 开发的一系列通用、多模态模型，包括 GPT-4 和 GPT-4o。它们可以通过 OpenAI API 访问。其中一些模型为面向客户的 ChatGPT 提供动力。

+   *Gemin**i*—由 Google 开发的一系列通用、多模态模型，包括 Gemini 1.5 Flash 和 Gemini 1.5 Pro，前者比其 Pro 版本更快但功能较弱。Gemini 模型为 Google 的客户界面 Gemini 提供动力。

+   *Claud**e*—由 Anthropic 开发的一系列通用、多模态模型，包括 Claude Haiku、Claude Sonnet 和 Claude Opus（按复杂性递增）。它们可以通过 Anthropic API 访问。其中一些模型为面向客户的 Claude 提供动力。

### 基础模型（开源）

+   *Llama*—由 Meta 开发的一系列通用、多模态模型。模型架构及其参数是公开的，但训练数据尚未公开。这些模型在称为 Meta Llama Community License 的特殊用途许可证下发布，该许可证施加了一些使用限制。

+   *DeepSeek*—由中国的 AI 公司 DeepSeek 开发的一系列模型。其最突出的模型 DeepSeek-V3 因其性能出色且训练成本远低于竞争对手而成为头条新闻，导致英伟达的股价下跌。运行该模型的代码是公开的，但训练代码和训练数据尚未公开。其许可证是许可性的，但施加了一些使用限制。

+   *Mistral*—由法国公司 Mistral AI 开发的一系列模型，该公司成立是为了成为 OpenAI 的欧洲竞争对手。公司发布仅包含文本的模型（例如，Mistral Large 2）和具有视觉能力的模型（例如，Pixtral 12B）。它们在高度许可的 Apache 2.0 许可证下发布，但训练数据尚未公开。

+   *Gemma*—由 Google 开发的一系列通用模型，作为其专有 Gemini 模型的开源替代品。一些模型仅处理文本（例如，Gemma 2），而其他模型可以处理输入图像（例如，PaliGemma）。这些模型在许可性 Apache 2.0 许可证下发布，但训练数据尚未公开。

+   *Phi*—由 Microsoft 开发的一系列轻量级通用语言模型，包括 Phi-3 Mini 和 Phi-3 Medium。它们在许可性 MIT 许可证下发布，但训练数据尚未公开。

## 编码助手

以下是一些帮助软件工程师编写代码的流行工具：

+   *GitHub Copilot*—一个可以安装为多个流行 IDE 插件的 AI 编码助手。它可以通过两种不同的方式使用。一种方式是在聊天窗口中输入以与聊天机器人交互并询问有关代码的问题或要求它执行任务。另一种方式是助手在您输入代码时自动完成您的代码——您可以通过按键盘上的 Tab 键接受建议。您必须支付月度订阅费才能使用它，但提供免费试用。

+   *Curso**r*—一个独立的、基于 AI 的 IDE，建立在 Visual Studio 之上。您可以与 AI 助手聊天或通过按 Tab 键接受代码自动完成。有一个免费版本，带有有限的完成次数，以及付费订阅，提供更多次数或无限次数的完成。

+   *JetBrains AI Pr**o*—PyCharm 和 IntelliJ 等流行 IDE 背后的公司提供附加订阅服务以访问 AI 助手。您可以与助手聊天关于代码，也可以通过按 Tab 键接受自动完成。这些自动完成由其基于云的 LLM 提供支持，但未订阅 AI 附加组件的用户仍然可以从本地运行的简单自动完成中受益。用户必须支付月度许可证才能将 AI 助手添加到其 IDE 中。

## 图像生成

我们现在讨论用于图像生成的 AI，分为面向客户的 APP、专有基础模型和开源基础模型。

### 面向客户的 APP

+   *Midjourne**y*—一种从文本描述生成图像的工具（可选地参考图像以影响输出）。该 APP 直接在 Midjourney 的网站上使用（[`midjourney.com`](https://midjourney.com)）或通过 Discord 聊天。该 APP 最初生成四个不同尺寸为 1024 × 1024 的图像变体。然后您可以挑选您最喜欢的一个，对其进行细化，并增加其大小（或进行超分辨率）。您必须支付月费才能访问 Midjourney，不同的计划有不同的使用限制。

+   *Dall-**E*—OpenAI 的旗舰文本到图像 APP。它现在已经集成到 ChatGPT 中，因此可以直接通过要求 ChatGPT 生成图像来使用（尽管 OpenAI 仍然在[`chatpgt.com`](https://chatpgt.com)上提供专门的 DALL-E 界面）。只有付费的 OpenAI 订阅者才能访问它。

### 基础模型（专有）

+   *Dall-**E*—OpenAI 为其图像生成模型提供 API 访问权限。用户按生成的图像付费，价格根据模型版本和图像大小而变化。

+   *Flux.1 Pr**o*—由 Black Forest Labs 开发的一种文本到图像模型，因其逼真度而受到赞誉。它可以通过与 Black Forest Labs 合作的各种 API 提供商访问，包括 Replicate 和 Together AI。

### 基础模型（开源）

+   *Stable Diffusio**n*—Stability AI 开发的一系列文本到图像模型，采用扩散方法构建（见第一章）。除了使模型公开可用外，该公司还发布了用于训练其模型的数据以及用于过滤和精选数据的算法。Stable Diffusion 在开源许可下发布，但有使用限制。特别是，用户不允许“生成或传播可验证的虚假信息”、“伤害未成年人”或“提供医疗建议”，以及其他限制（[`mng.bz/YDpe`](https://mng.bz/YDpe)）。

+   *Flux.1 Schnell* 和 *Flux.1 Dev*—这些模型是从专有的 Flux.1 Pro 衍生出来的，由 Black Forest Labs 开源。Flux.1 Schnell 在 Apache 2.0 许可下发布。更强大但速度较慢的 Flux.1 Dev 在禁止商业使用的许可下发布。训练数据尚未公开。

## DIY

我们以一些常用的工具和库结束，这些工具和库可以用于微调或创建您自己的 AI 模型：

+   *Hugging Face*—这家公司托管了 AI 模型的实际仓库。开源模型通常在那里发布。公司还维护了一系列库，包括*Transformers*，这有助于使用预训练模型。公司还维护了帮助轻松微调模型的库。

+   *PyTorch*—一个流行的 Python 库，用于创建和训练机器学习模型。历史上，PyTorch 受到学术界的青睐，他们使用这个库快速原型设计和分析模型，尽管它在其他地方似乎越来越受欢迎。Hugging Face 的 Transformers 库建立在 PyTorch 之上。

+   *TensorFlow*—PyTorch 的一个流行替代品。它通常受到在生产中部署高性能 ML 模型的人的青睐，尽管它似乎正在失去对 PyTorch 的流行度。OpenAI 公开了 GPT-2 模型的代码，该模型使用 TensorFlow ([`github.com/openai/gpt-2/`](https://github.com/openai/gpt-2/))。从那时起，OpenAI 将其首选库切换为 PyTorch ([`openai.com/index/openai-pytorch/`](https://openai.com/index/openai-pytorch/))).

# 索引

符号

--无参数

A

准确度

亚马逊

自回归

人工智能（AI）

大脑与意识, 第 2 版

人工智能（AI）

LLM 包装器, 第 2 版

大脑与意识, 第 2 版

基于 AI 的产品构建, 第 2 版

争议与讨论

对话式人工智能, 第 2 版

卷积, 第 2 版

版权, 第 2 版

经济学, 第 2 版

嵌入, 第 2 版

机器学习, 第 2 版

多模态人工智能, 第 2 版

性能指标, 第 2 版

选择和评估工具

自动驾驶汽车, 2nd

严格控制, 2nd

令牌, 2nd

Transformer 架构, 2nd

验证, 2nd

何时使用

自动化

大规模失业和, 2nd

人工神经网络

注意力机制

AI 工具

面向客户的 AI 应用与基础模型

选择专有和开源

现成产品与微调, 2nd

专有与开源, 2nd

B

批量

Boto3 库

构建基于 AI 的产品

可解释性

幻觉

将 AI 放在客户之前, 2nd

大脑与意识, 2nd

按令牌计费

字节对编码

C

版权, 2nd

上下文化, 2nd

多头注意力, 2nd

多层架构, 2nd

卷积神经网络（CNNs）, 2nd

卷积, 2nd

面向客户的 AI 应用

聊天

聊天模式

原因

世界模型不足

目标不一致

价格优化

世界模型

完成模式

对话式 AI, 2nd

描述任务和验证输出, 2nd

优秀的工作, 2nd

先前的工作, 2nd, 3rd, 4th

交叉熵损失

思维链提示, 第 2 版

条件扩散模型

连接组

碳强度

上下文窗口

竞争优势, 第 2 版

D

dropout

判别模型

数据集

深度学习

维度

点积

E

文本结束

嵌入

嵌入, 第 2 版

LLMs 和分析单个字母的挑战

初始

机器学习和

有用性

可视化

卓越差距, 第 2 版

在软件工程中, 第 2 版

利用

探索

周期

提前停止

外部软件函数

F

基础模型, 第 2 版

少样本提示

微调, 第 2 版

功能标志

合理使用

G

get_current_weather 函数, 第 2 版

GraphHopper

生成式 AI

GPT-2

Google 地点 API

H

哈兹利特，亨利

幻觉, 第 2 版, 第 3 版

原因, 第 2 版

对产品的影响, 第 2 版

问题的错误解决方案, 第 2 版

与...共存

编造的事实

误解

缓解措施, 第 2 版

过度自信

不可预测性

它们会消失吗？

I

图解 Transformer（书籍）

对工作的影响

使网络更具人性

输入提示

将文本细分为有效标记

推理时间

InstructGPT

J

工作

L

损失

LSTM（长短期记忆）

局部最小值

语言

除了英语之外

LLM 包装器

使用自然语言与产品交互

LLMs（大型语言模型）, 第 2 次, 第 3 次

调用外部软件函数

聊天

文本结束

对标记的需求

检索增强生成

在分析单个字母时遇到困难

系统提示

文本生成

训练, 第 2 次

可学习参数

LLM（大型语言模型）包装器, 第 2 次

使用自然语言与产品交互

LLM 包装器

更新范围有限

对数损失

M

编造的事实

多智能体 AI

多模态 AI, 第 2 次

多层架构

小批量

模型验证、选择和测试, 第 2 次

测试集

训练集

验证集

大规模失业, 第 2 次

MVP（最小可行产品）

护城河

模型选择

机器学习

深度学习

嵌入

损失

随机梯度下降, 第 2 次

训练 LLMs, 第 2 次

类型, 第 2 次

Mechanical Turk, 第 2 次

平均绝对误差（MAE）

目标不一致

机器学习（ML）, 第 2 次

架构, 第 2 次

深度学习

损失

随机梯度下降（SGD）, 第 2 次

训练大型语言模型（LLMs）, 第 2 次

类型, 第 2 次

多头注意力

误解

MAE（平均绝对误差）, 第 2 次

Maggiori, Emmanuel

N

国家安全局（NSA）

无免费午餐定理

O

开源 AI, 第 2 次

在专有和开源之间做出决定

现成与微调, 第 2 次

在两者之间做出决定, 第 2 次

OpenAI o1 模型

过度自信

运筹学

过拟合, 第 2 次

P

性能指标, 第 2 次

MAE, 第 2 次

RMSE, 第 2 次

准确性, 第 2 次

精确度, 第 2 次, 第 3 次, 第 4 次

召回率, 第 2 次, 第 3 次, 第 4 次

提示

提示工程

专有 AI, 第 2 次

在专有和开源之间做出决定

预测

精确度, 第 2 次

价格优化

参数

隐私

投影

Q

QA（质量保证）团队

R

RMSE（均方根误差）, 第 2 次

检索

均方根误差（RMSE）

RLHF（带人类反馈的强化学习）, 第 2 次, 第 3 次

强化学习（RL）

强化学习, 第 2 次

召回率, 第 2 次

RAG（检索增强生成）, 第 2 次, 第 3 次

资源消耗, 第 2 次

可复现的输出

正则化

奖励模型

检索增强生成（RAG）, 第 2 次

监管

基础模型

高风险系统

禁止的 AI 实践

透明度义务

S

自动驾驶汽车, 第 2 次

软件工程, 第 2 次

验证, 第 2 次

智能直到愚蠢（Maggiori）

监督学习

SMOTE（合成少数类过采样技术）

奇点事件

SGD（随机梯度下降）, 第 2 次

系统提示

自监督学习

将输入提示细分为有效标记

问题解决方案，错误, 第 2 次

模拟数据

T

Top-k 设置

文本生成

温度

Top-k 设置

Top-p 设置

测试集

类型

强化学习, 第 2 次

自监督学习, 第 2 次

模拟数据, 第 2 次

监督学习, 第 2 次

无监督学习, 第 2 次

Transformer 架构, 第 2 次

上下文化, 第 2 次, 第 3 次, 第 4 次

初始嵌入, 第 2 次

了解更多关于, 第 2 次

预测, 第 2 次

可复现的输出, 第 2 次

温度, 第 2 版

Top-p 设置

训练数据

严格控制, 第 2 版

在软件中, 第 2 版

推荐, 第 2 版

TDD（测试驱动开发）

透明度义务

训练集

标记, 第 2 版, 第 3 版

按计费

除英语以外的语言

需要

将输入提示细分为有效标记

训练时间

U

无监督学习

欠拟合

不可预测性

V

验证集

验证, 第 2 版

在软件工程中, 第 2 版, 第 3 版, 第 4 版

推荐, 第 2 版, 第 3 版, 第 4 版

可视化

嵌入

W

Waymo

世界模型, 第 2 版

X

XAI（可解释人工智能）

Z

零样本提示
