# 前言

## 前言

感谢您购买我们的书籍。我们希望这本书能为您揭示深度学习（*DL*）的内部机制，并为您提供一些关于如何在工作中使用概率深度学习方法灵感的启示。

我们三位作者在统计学方面都有背景。我们于 2014 年一起开始了深度学习的旅程。我们对它如此着迷，以至于深度学习至今仍然是我们职业生涯的中心。深度学习有着广泛的应用范围，但我们特别着迷于将深度学习模型与统计学中使用的概率方法相结合的力量。根据我们的经验，对概率深度学习潜力的深入理解需要深入了解底层方法和实践经验。因此，我们在本书中试图在这两种成分之间找到一个良好的平衡。

在这本书中，我们旨在在讨论涉及的方法之前，提供一些清晰的想法和示例应用。你们也有机会通过使用随书附带的 Jupyter 笔记本，实际应用所有讨论的方法。我们希望你们通过阅读这本书学到的东西，能和我们写作时学到的一样多。祝你们玩得开心，保持好奇心！

## 致谢

我们想要感谢所有帮助我们撰写这本书的人。特别感谢我们的开发编辑玛琳娜·迈克尔斯，她设法教会了一群瑞士人和德国人如何写出几百字以下的句子。没有她，你们就没有乐趣去解读文本。还要感谢我们的校对员弗朗西斯·伯兰，她在文本（以及公式中）发现了无数的错误和不一致（也要感谢你！）。我们在技术方面也得到了 Al Krinkler 和 Hefin Rhys 的大力支持，使笔记本中的文本和代码更加一致，更容易理解。还要感谢我们的项目编辑迪尔德丽·希姆；我们的校对员凯里·黑尔斯；以及我们的审稿编辑亚历山大·德拉戈萨夫利奇。我们还要感谢审稿人，他们在书的各个阶段提供了非常有价值的反馈：Bartek Krzyszycha、Brynjar Smári Bjarnason、David Jacobs、Diego Casella、Francisco José Lacueva Pérez、Gary Bake、Guillaume Alleon、Howard Bandy、Jon Machtynger、Kim Falk Jorgensen、Kumar Kandasami、Raphael Yan、Richard Vaughan、Richard Ward 和 Zalán Somogyváry。

最后，我们还想感谢理查德·谢泼德，他为本书提供了许多优秀的图形和插图，使书籍不那么枯燥，更加友好。

我，奥利弗，想感谢我的合作伙伴莱娜·奥本代克，在我长时间工作于这本书时，她的耐心。我还感谢来自“Tatort”观看俱乐部的朋友们，每周日晚上 8:15 提供食物和陪伴，并在写作这本书时帮助我避免发疯。

我，Beate，想要感谢我的朋友们，不仅仅是因为他们帮助我写这本书，而是因为他们与我分享了屏幕之外的快乐时光——首先是我的伴侣 Michael，还有臭名昭著的 Limmat BBQ 小组，以及苏黎世之外的朋友们和家人，尽管有 Rösti-Graben，即通往大州的国界，甚至还有中间的大湖，他们仍然与我共度休闲时光。

我，Elvis，想要感谢在撰写这本书的激动人心时刻支持我的人，不仅在专业上，而且在私下里，无论是品一杯美酒还是踢一场足球。

我们，Tensor Chiefs，很高兴我们一起走到了这本书的结尾。我们期待新的科学旅程，但也期待不那么紧张的时间，那时我们不仅为了工作，也为了乐趣而相聚。

## 关于这本书

在这本书中，我们希望将支撑深度学习（*DL*）的概率原理带给更广泛的读者。最终（几乎），深度学习（DL）中的所有神经网络（NNs）都是概率模型。

有两个强大的概率原理：最大似然和贝叶斯。最大似然（亲切地称为 MaxLike）支配着所有传统深度学习（DL）。将网络视为使用最大似然原理训练的概率模型，可以帮助你提升网络的性能（就像谷歌从 WaveNet 过渡到 WaveNet++时所做的那样）或生成惊人的应用（例如，OpenAI 使用 Glow，一个生成逼真面孔的网络）。在需要网络表示“我不确定”的情况下，贝叶斯方法就派上用场了。（奇怪的是，传统的神经网络无法做到这一点。）本书的副标题“使用 Python、Keras 和 TensorFlow Probability”反映了这样一个事实，即你真的应该亲自动手编写一些代码。

### 应该阅读这本书的人

这本书是为那些喜欢理解深度学习（DL）底层概率原理的人所写。理想情况下，你应该有一些深度学习（DL）或机器学习（ML）的经验，并且不应该对数学和 Python 代码感到过于恐惧。我们没有省略数学，并且在代码中总是包含了示例。我们相信数学与代码更相得益彰。

### 这本书的组织结构：路线图

本书分为三部分，共涵盖八章。第一部分解释了传统的深度学习（*DL*）架构以及神经网络（NNs）的技术训练过程。

+   第一章--设定场景，并介绍概率深度学习（DL）。

+   第二章--讨论网络架构。我们涵盖了全连接神经网络（fcNNs），这是一种全能型网络，以及卷积神经网络（CNNs），它们非常适合图像处理。

+   第三章--展示了神经网络如何拟合数百万个参数。我们尽量简化，展示了在可以想到的最简单网络上的梯度下降和反向传播--线性回归。

第二部分专注于将神经网络作为概率模型使用。与第三部分相比，我们讨论了最大似然方法。这些方法背后是所有传统深度学习（DL）。

+   第四章——探讨了最大似然（MaxLike），这是机器学习和深度学习的基本原理。我们首先将这个原理应用于分类和（简单的回归问题）。

+   第五章——介绍了 TensorFlow Probability (TFP)，这是一个用于构建深度概率模型的框架。我们用它来解决像计数数据这样的不太简单的回归问题。

+   第六章——从更复杂的回归模型开始。最后，我们解释了如何使用概率模型来掌握描述人类面部图像等复杂分布。

第三部分介绍了贝叶斯神经网络。贝叶斯神经网络允许你处理不确定性。

+   第七章——阐述了贝叶斯深度学习的必要性，并解释了其原理。我们再次通过简单的线性回归示例来解释贝叶斯原理。

+   第八章——展示了如何构建贝叶斯神经网络。在这里，我们涵盖了两种称为 MC（蒙特卡洛）dropout 和变分推理的方法。

如果你已经有深度学习的经验，你可以跳过第一部分。此外，第六章的第二部分（从 6.3 节开始）描述了正态流。你不需要了解这些来理解第三部分的内容。6.3.5 节在数学上有点复杂，所以如果你不感兴趣，可以跳过。8.2.1 和 8.2.2 节也是如此。

### 关于代码

本书包含许多源代码示例，无论是编号列表还是与普通文本混排。在两种情况下，源代码都以 `fixed-width` `font`，如 `this` 的格式呈现，以将其与普通文本区分开来。

代码示例是从 Jupyter 笔记本中提取的。这些笔记本包含额外的解释，并且大多数都包括一些你应该做的练习，以更好地理解本书中介绍的概念。你可以在 GitHub 上的这个目录中找到所有代码：[`github.com/tensorchiefs/dl_book/`](https://github.com/tensorchiefs/dl_book/)。一个不错的起点是在这个目录 [`tensorchiefs.github.io/dl_book/`](https://tensorchiefs.github.io/dl_book/)，在那里你可以找到笔记本的链接。笔记本是按照章节编号的。例如，nb_ch08_02 是第八章的第二本笔记本。

本书中的所有示例，除了 nb_06_05，都是使用 TensorFlow v2.1 和 TensorFlow Probability (TFP) v0.8 测试的。描述计算图的笔记本 nb_ch03_03 和 nb_ch03_04 在 TensorFlow v1 中更容易理解。对于这些笔记本，我们还包含了 TensorFlow 的两个版本。nb_06_05 笔记本只适用于 TensorFlow v1，因为我们需要在该版本的 TensorFlow 中提供的权重。

你可以在 Google 的 Colab 或本地执行这些笔记本。Colab 非常棒；你只需点击一个链接，然后在云端玩转代码。无需安装——你只需要一个浏览器。我们强烈建议你这样去做。

TensorFlow 仍在快速发展，我们无法保证代码在几年后仍能运行。因此，我们提供了一个 Docker 容器（[`github.com/oduerr/dl_book_docker/`](https://github.com/oduerr/dl_book_docker/)），您可以使用它来执行所有 notebooks，除了 nb_06_05 以及 nb_ch03_03 和 nb_ch03_04 的 TensorFlow 1.0 版本。如果您想在本地使用 notebooks，这是必走之路。

### liveBook 讨论论坛

购买《概率深度学习》包括免费访问由 Manning Publications 运营的私人网络论坛，您可以在论坛上对书籍发表评论，提出技术问题，并从作者和其他用户那里获得帮助。要访问论坛，请访问[`livebook.manning.com/book/probabilistic-deep-learning-with-python/welcome/v-6/`](https://livebook.manning.com/book/probabilistic-deep-learning-with-python/welcome/v-6/)。您还可以在[`livebook.manning.com/#!/discussion`](https://livebook.manning.com/#!/discussion)上了解更多关于 Manning 论坛和行为准则的信息。

曼宁对读者的承诺是提供一个平台，在这里读者之间以及读者与作者之间可以进行有意义的对话。这并不是对作者参与特定数量活动的承诺，作者对论坛的贡献仍然是自愿的（并且**未付费**）。我们建议您尝试向作者提出一些挑战性的问题，以免他们的兴趣转移！只要书籍在印刷中，论坛和先前讨论的存档将可通过出版社的网站访问。

## 关于作者

Oliver Dürr 是德国康斯坦茨应用科学大学的教授，教授数据科学。Beate Sick 在 ZHAW 担任应用统计学教授，并在苏黎世大学担任研究员和讲师，同时在苏黎世联邦理工学院（ETH Zurich）担任讲师。Elvis Murina 是一位研究科学家，负责本书伴随的广泛练习。

Dürr 和 Sick 都是机器学习和统计学的专家。他们监督了关于深度学习的众多学士、硕士和博士论文，并计划并实施了多个研究生和硕士学位的深度学习课程。所有三位作者自 2013 年以来一直在使用深度学习方法，并在教授该主题以及开发概率深度学习模型方面拥有丰富的经验。

## 关于封面插图

《概率深度学习》封面上的插图被标注为“丹萨·德·伊勒·奥塔希提”，或塔希提岛的舞者。这幅插图取自雅克·Grasset de Saint-Sauveur（1757-1810）的作品集，名为《不同国家的服饰》，1788 年在法国出版。每一幅插图都是手工精心绘制和着色的。Grasset de Saint-Sauveur 收藏中的丰富多样性生动地提醒我们，200 年前世界的城镇和地区在文化上是如何截然不同的。彼此孤立，人们说着不同的方言和语言。在街道或乡村，仅凭他们的服饰，就可以轻易地识别出他们居住的地方以及他们的职业或社会地位。

自那以后，我们的着装方式已经改变，而当时区域间的多样性，如此丰富，现在已经逐渐消失。现在很难区分不同大陆的居民，更不用说不同的城镇、地区或国家了。也许我们是以更丰富多彩的个人生活——当然，是更丰富多彩、节奏更快的技术生活——为代价，换取了文化多样性。

在难以区分一本计算机书与另一本计算机书的时代，曼宁通过基于两百年前丰富多样的区域生活所设计的书封面，庆祝了计算机行业的创新精神和主动性，这些封面由 Grasset de Saint-Sauveur 的画作赋予新生。
