# 第十一章\. 使用 LLM 构建

世界上关于 LLM 的最大开放问题之一是如何最好地将它们交给最终用户。在某种程度上，LLM 实际上是一种比之前出现的更直观的计算机界面。与传统的计算机应用相比，它们对拼写错误、口误和人类的一般不精确性更加宽容。另一方面，处理“稍微偏离”的输入的能力也带来了一种倾向，即有时会产生“稍微偏离”的结果——这与之前的计算趋势也非常不同。

事实上，计算机被设计成每次都能可靠地重复执行相同的指令并得到相同的结果。在过去几十年中，这一可靠性原则已经渗透到人机界面（统称为 HCI、UX 和 UI）的设计中，以至于许多通常的结构最终在依赖于 LLM 的应用中变得不够好。

让我们举一个例子：Figma 是一个设计师使用的软件应用，用于创建网站、移动应用、书籍或杂志封面等设计的忠实呈现——列表可以继续下去。正如几乎所有生产力软件（用于创建某种形式的长期内容）的情况一样，其界面是由以下组合构成的：

+   一系列工具和预构建的*基本元素*（基本构建块），在这种情况下是线条、形状、选择和绘图工具等等

+   画布，用户在其中插入这些构建块并将它们组织成他们的创作：网站页面、移动应用屏幕等

这个界面建立在软件功能事先已知的前提之上，实际上在 Figma 的情况下确实是如此。所有构建块和工具都是事先由软件工程师编写的。因此，在界面设计时就已经知道它们的存在。指出这一点听起来几乎有些荒谬，但同样的情况并不严格适用于大量使用 LLM 的软件。

看一下文字处理器（例如，Microsoft Word 或 Google Docs）。这是一个用于创建某种形式的长期文本内容的软件应用，例如博客文章、文章、书籍章节等。我们可用的界面也由一个熟悉的组合构成：

+   一系列工具和预构建的*基本元素*：在文字处理器的例子中，可用的基本元素包括表格、列表、标题、图像占位符等等，而工具则包括拼写检查、注释等。

+   *画布*：在这种情况下，它实际上是一张空白页，用户可以在其中输入文字，并可能包含上述提到的某些元素。

如果我们构建一个 LLM 原生文字处理器，这种情况会如何改变？本章探讨了三个可能的答案，这些答案广泛适用于任何 LLM 应用。对于我们所探讨的每个模式，我们将概述成功实现它所需的关键概念。我们并不想暗示这些是唯一的，关于这个特定问题的尘埃可能还需要一段时间才能落定。

让我们逐一查看这些模式，从最容易添加到现有应用中的开始。

# 交互式聊天机器人

这可以说是添加到现有软件应用中最容易提升的方法。在最基本的概念中，这个想法只是附加一个 AI 助手——以提出想法——而所有工作仍然在应用程序现有的用户界面中完成。这里的一个例子是 GitHub Copilot Chat，它可以在 VSCode 代码编辑器的侧边栏中使用。

将这种模式升级的一种方法是，在 AI 助手扩展和主应用程序之间添加一些通信点。例如，在 VSCode 中，助手可以“看到”当前正在编辑的文件内容或用户选定的代码的任何部分。在另一个方向上，助手可以在该打开编辑器中插入或编辑文本，从而实现用户和 LLM 之间的一种基本形式的协作。

###### 注意

正如我们所描述的流式聊天目前是 LLM 的典型应用。它几乎总是应用开发者在其 LLM 之旅中首先学习构建的内容，它几乎总是公司添加 LLM 到现有应用程序时首先寻求的内容。也许这种情况会持续多年，但另一种可能的结局可能是流式聊天成为 LLM 时代的命令行——即，最接近直接编程访问的，成为一种利基界面，就像它对计算机所做的那样。

要构建最基础的聊天机器人，你应该使用以下组件：

聊天模型

它们的对话调整非常适合与用户的多次交互。有关对话调整的更多信息，请参阅序言。

对话历史

一个有用的聊天机器人需要能够“越过你好”。也就是说，如果聊天机器人无法记住之前的用户输入，那么与它进行有意义的对话将会非常困难，这隐含地指的是之前的消息。

要超越基础，你可能需要添加以下内容：

流式输出

目前最佳的聊天机器人体验是将 LLM 的输出逐个 token（或更大块，如句子或段落）直接流式传输给用户，这减轻了今天 LLM 固有的延迟。

工具调用

为了让聊天机器人能够与应用程序的主要画布和工具交互，你可以将它们暴露为模型可以决定调用的工具——例如，“获取选中文本”工具和“在文档末尾插入文本”工具。

人工参与

一旦你为聊天机器人提供了可以更改应用程序画布内容的工具，你就需要将一些控制权交还给用户——例如，在插入新文本之前让用户确认，甚至编辑。

# 与 LLMs 的协作编辑

大多数生产力软件都内置了某种形式的协作编辑，我们可以将其分类为以下类别（或介于其中）：

保存并发送

这是最基本的版本，一次只支持一个用户编辑文档，然后在“推卸责任”给另一个用户（例如，通过电子邮件发送文件）并重复此过程，直到完成。最明显的例子是微软 Office 套件的应用程序：Excel、Word、PowerPoint。

版本控制

这是保存和发送的演变，它通过提供工具在多个编辑者同时工作（并且彼此不知情）后合并他们的工作来支持多个编辑者同时工作：合并策略（如何合并无关的更改）和冲突解决（如何合并不兼容的更改）。今天最受欢迎的例子是 Git/GitHub，软件工程师用它来协作软件项目。

实时协作

这使得多个编辑者可以同时编辑同一份文档，同时看到彼此的更改。这可以说是软件支持的最自然形式的协作方式，这在 Google Docs 和 Google Sheets 在技术和非技术计算机用户中的流行度得到了证明。

这种大型语言模型（LLM）用户体验模式包括将 LLM 代理作为“用户”之一，为这个共享文档做出贡献。这可以采取多种形式，包括以下几种：

+   一个始终在线的“副驾驶”，为你提供如何完成下一句的建议。

+   一个异步的“草稿人”，你可以分配给它，例如，去研究相关主题，并在稍后返回一个可以融入你最终文档的章节。

要构建这个，你可能会需要以下内容：

共享状态

LLM 代理和人类用户在访问和理解文档状态方面应该处于同等地位——也就是说，他们能够解析文档状态并产生对该状态的编辑，以兼容的格式。

任务管理器

生成有用的编辑文档将不可避免地是一个多步骤的过程，这可能需要时间，并且可能在半途中失败。这需要可靠地调度和编排长时间运行的任务，包括排队、错误恢复和对运行任务的控制。

合并分支

用户在分配 LLM 代理后将继续编辑文档，因此 LLM 输出需要与用户的工作合并，要么由用户手动（类似于 Git 的体验）合并，要么自动（通过如 CRDT 和操作转换（OT）这样的冲突解决算法合并，这些算法被 Google Docs 等应用程序使用）。

并发

人类用户和 LLM 代理同时处理同一件事情需要处理中断、取消、重新路由（做这个）和排队（也做这个）的能力。

撤销/重做堆栈

这是在生产力软件中普遍存在的一种模式，在这里也必然需要。用户可能会改变主意，想要回到文档的早期状态，而 LLM 应用需要能够跟随他们到那里。

中间输出

当输出是渐进的，并且一旦产生就分批到达，就像一个人一次写一句话地写一个 10 段落的页面一样，合并用户和 LLM 的输出就变得容易得多。

# 环境计算

一个非常有用的 UX 模式是始终在线的背景软件，当发生了一些“有趣”的事情需要你注意时，它会提醒你。你今天可以在很多地方找到这样的例子。以下是一些例子：

+   你可以在你的经纪应用中设置一个警报，当某些股票价格低于某个特定价格时通知你。

+   你可以要求谷歌在找到匹配某些搜索查询的新搜索结果时通知你。

+   你可以为你的计算机基础设施定义警报，当某些事情超出常规行为模式时通知你。

部署这种模式的主要障碍可能是在事先找到一个可靠的“有趣”定义，这个定义既符合以下两点：

有用

它会在你认为应该的时候通知你。

实用

大多数用户不会想要花费大量时间预先创建无尽的警报规则。

LLM 的推理能力可以解锁这种“环境计算”模式的新应用，这些应用同时更加有用（它们识别出更多你可能会感兴趣的东西）并且设置起来更简单（它们的推理可以替代大部分或全部的手动规则设置）。

协作和环境之间最大的区别是并发性：

协作

你和 LLM 通常（或有时）同时做工作，并从对方的工作中汲取灵感。

环境

LLM 在后台持续进行某种工作，而你，作为用户，可能在做其他完全不同的事情。

要构建这个，你需要：

触发器

LLM 代理需要从环境中接收（或定期轮询）新信息。这实际上是环境计算的动力：一个现有的周期性或连续的新信息来源，需要被处理。

长期记忆

没有咨询先前接收到的信息数据库，将无法检测到新的有趣事件。

反思（或学习）

理解什么是“有趣”的（什么值得人类输入）可能需要从每个已经发生的有趣事件中学习。这通常被称为“反思步骤”，其中 LLM 对其长期记忆进行更新，可能修改其检测未来有趣事件的内部“规则”。

总结输出

在后台工作的代理可能会产生比人类用户希望看到的多得多的输出。这要求代理架构进行修改，以生成工作摘要，并将新或值得注意的内容呈现给用户。

任务管理器

在后台持续工作的 LLM 代理需要采用某种系统来管理工作，排队新的运行，并处理和从错误中恢复。

# 摘要

大型语言模型（LLMs）有潜力改变我们构建软件的方式，甚至可以改变我们构建的软件本身。我们开发者现在可以利用的新能力来生成新内容，不仅将增强许多现有应用，还可以实现我们尚未梦想过的新事物。[如何构建软件](https://oreil.ly/RqnCm)。

这里没有捷径。你真的需要构建一些（质量）较差的东西，与用户沟通，然后重复这个过程，直到出现新的、意料之外的结果。

在最后一章以及整本书中，我们试图提供我们认为可以帮助你利用 LLMs 构建独特优秀产品的知识。我们感谢你与我们一同踏上这段旅程，并祝愿你在职业和未来中一切顺利。
