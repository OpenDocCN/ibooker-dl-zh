# 第七章：探索大局

本章包含了使用 Azure OpenAI 和其他微软技术进行生成式 AI 学习的最后一些知识。它包括一些未来愿景、专家访谈和成功案例。记住，生成式 AI（以及人工智能总体而言）是一个高度演进的领域，所以请将这本书视为您进入一个知识和学习资源的宇宙的入口。

让我们从讨论从 Azure OpenAI 视角来看的“接下来是什么”开始这一最后一章。对于一个像您这样热爱学习和采用 AI 的人，您还应该探索哪些其他领域？

# 接下来是什么？向微软协同伙伴的演进

Azure OpenAI 服务是更广泛生态系统的一部分。所有架构、API 以及与其他生成式 AI 构建块的集成都为我们在第一章中提到的 AI 协同伙伴概念做出了贡献。

AI 协同伙伴是技术驱动的助手，是帮助人类代理人变得更好、更高效的伴侣。它们背后的原则是提供一个界面（书面或口头），帮助人们执行复杂任务，例如查找特定信息或将信息添加到第三方系统（例如 CRM、支持票务系统）。

如您在图 7-1 中所见，端到端微软对 AI 协同伙伴的愿景包括 Azure OpenAI 的模型，但也包括它们与其他系统（如已包含[其自身的协同伙伴](https://oreil.ly/Jwuff)的 Microsoft 365）的连接。这可以通过利用[Microsoft Graph API](https://oreil.ly/3qy8E)（365 套件数据访问的开发接口，包括 Outlook 的日历和电子邮件、Teams 的会议录音和转录等）和[Microsoft Dataverse](https://oreil.ly/onOnS)（之前称为通用数据模型，是 Power Platform 和 [Dynamics 365](https://oreil.ly/omP3a) 生态系统中的数据存储）的数据来扩展额外的功能。

![图片](img/aoas_0701.png)

###### 图 7-1：端到端协同伙伴架构

所有这些构建块的组合使得新的开发模式成为可能，通过将其他数据源和系统与生成式 AI 模型相结合，协同伙伴的概念无疑将在未来几年内演变。您将看到这种端到端架构成为行业标准，因此我建议您了解所有这些部分是如何连接并启用新的生产力和生成式 AI 场景的。

话虽如此，要探索所有这些内容可能需要两三本书，但为了利用一些官方的微软资源，请查看微软英国团队提供的[学习路径网站](https://oreil.ly/kljOi)，并检查[人工智能学习伴侣路径](https://oreil.ly/SntTJ)，因为它包含大量视频、文章和培训项目。如果您有技术背景，还可以探索微软 Copilot 技术栈的[示例](https://oreil.ly/1_p3Q)，其中包括 Azure OpenAI 和其他微软服务——如果您有技术背景，这将非常有用。

现在让我们转向我认为这本书的隐藏宝藏：从一些最大专家那里获得的宝贵且独家见解，这些见解将从设计、数据质量、人工智能的未来等相关的多个角度补充本书的内容。

# 生成式人工智能时代的专家见解

能够接触到一些最相关的生成人工智能专家，这些人参与了塑造生成人工智能以及组织如何采用 Azure OpenAI 和其他相关构建块的工作，这非常罕见，是一种非凡的特权。

本节包括一系列访谈：

[大卫·卡莫纳](https://oreil.ly/FOSlv)

微软战略孵化副总裁兼首席技术官，也是[*《人工智能组织》*（O’Reilly）](https://oreil.ly/JvO8O)一书的作者。这次访谈讨论了人工智能的采用和高级用例，以及他对生成式人工智能未来的展望。我们将从一位有远见的领导者那里获得顶级见解。

[布伦丹·伯恩斯](https://oreil.ly/e_vU5)

微软公司副总裁，由于他在 Kubernetes 共同创始人以及多本 O’Reilly 书籍（如[*《Kubernetes：快速入门》*](https://oreil.ly/c86hW)、[*《Kubernetes 最佳实践》*](https://oreil.ly/DIsrj)、[*《管理 Kubernetes》*](https://oreil.ly/cJDzq)、[*《设计分布式系统》*](https://oreil.ly/5GcFO)）的作者身份，成为了云原生生态系统的真实传奇人物。这次对话讨论了生成式人工智能时代云原生架构的融合。

[约翰·梅达](https://oreil.ly/4jxQ0)

微软工程副总裁兼计算设计/人工智能平台负责人，以及语义内核项目的主要赞助人。这是对人工智能解决方案设计作用和 LLM 编排技术重要性的一个令人惊叹的探索。

[莎拉·伯德](https://oreil.ly/N_NK9)

微软负责任人工智能的首席产品官。这次访谈包括与负责 Azure 人工智能平台（包括 Azure OpenAI）RAI 发展的领导者的对话。莎拉为我们提供了对这个重要话题的不同视角。

[蒂姆·沃德](https://oreil.ly/cersn)

CluedIn 的 CEO，是数据管理主题的优秀来源。这次讨论深入探讨了数据质量作为生成式 AI 发展的推动力，同时也审视了 AI 如何改变公司执行主数据管理（MDM）和质量控制的方式。

[Seth Juarez](https://oreil.ly/oIrgI)

微软 AI 平台的首席项目经理。Seth 是 Azure OpenAI 时代的更知名面孔之一，多亏了他作为[AI Show](https://oreil.ly/h-Fvw)的主持人。Seth 是 Azure OpenAI 和 Azure AI Studio 主题最知名的专业人士之一，也是一个伟大的讲故事者，他能让复杂的话题看起来简单一些。

[Saurabh Tiwary](https://oreil.ly/qUK9P)

微软 Copilot & Turing 的副总裁。这次访谈包括关于微软 Copilot 作为利用 Azure OpenAI 服务的端到端架构的愿景的精彩交流。

让我们深入这些访谈！

## David Carmona：AI 的采用和生成式 AI 的未来

**A.G.**：所以，我知道你的背景，也知道你在微软的职业生涯，但谁是 David，你在微软组织中的角色是什么？

![图片](img/aoas_07in01.png)

**D.C.**：嗯，感谢你的邀请，这是一件非常愉快的事情。我认为我们都有写书的痛苦，所以当有人接受这个大冒险时，我总是非常敬畏。你做到了，所以恭喜你。我认为，当我最终审视我在微软的角色时，它全部关于创建新的孵化业务。我在微软已经快 23 年了，我一直非常专注于这个职能。我最初来自西班牙，我在西欧为微软工作，然后 15 年前我搬到了西雅图的总部。我曾参与云孵化项目，那是非常令人兴奋的。

然后，在云成为主流之后，我不再需要不断证明云的重要性，于是我被邀请领导 AI 孵化项目。那时正是云开始主流化的时期，大约八到九年前，它始于微软研究院。当时我正在与微软研究院合作，我们的目标是创造一个新的商业类别。就在那开始变得主流的时候，也就是两年前，就在我不需要在每次对话中再次证明 AI 的重要性时，我转向了下一个业务。我现在正在研究像 AI 的未来这样的领域，这些是我们在未来将会看到的 AI 的新前沿。例如，将 AI 应用于科学，这是一个惊人的用例场景。然后其他领域，如量子计算，我也很荣幸地参与了孵化，还有一些其他领域，如太空、通信、通信的未来等等。

**A.G.**: 你是谈论生成式 AI、一般人工智能以及我们将在未来几年如何使用它们的理想人选。你现在看到了哪些潜在的和有趣的东西？你对这个生成式 AI 时代的展望是什么？

**D.C.**: 对于我来说，最大的不同之处在于你可以用这个新的 AI 解决之前无法解决的问题，当然。在语言或其他任何模态之上进行推理的概念，而不仅仅是数据，这是非常强大的，我们可以有很多话要说。但对我来说，真正的变革，这一代新 AI 的革命性之处在于它更加广泛，更加通用。在过去，要创建一个 AI 模型，你需要一个特定的数据集和一个特定的模型。我仍然记得那些早期 AI 的时光，当时我们在微软研究院为 AI 创造了这些里程碑，比如图像分类、人类对等、语音识别等。所有这些都需要一个非常专业的团队，对那个领域有非常具体的了解，拥有非常具体的数据集和模型。

这种变化的大变化，这种影响的大影响在于可能性。现在，这个模型已经变成不仅仅是数据科学家可以创建的，甚至最终用户也可以定制并在他们的日常生活和工作中使用，这就是 Copilot 的概念。在那之后，其余的都是历史。但对我来说，这就是这一代新 AI 的核心区别。

**A.G.**: 正是如此。因为我们一直在使用 AI。我们在不同的产品中都有 AI，但大多数人并没有意识到他们正在使用 AI 或受到 AI 的影响。现在这是自然而然的，这就是民主化的概念，技术的可访问性，因为我们使用语言，这是最纯粹的沟通方式。我认为这非常令人兴奋。

**D.C.**: 这只是开始。正如你所知，我对接下来会发生什么感到非常兴奋。当然，技术本身将会发展，但我认为随着我们对技术的理解更加深入，我们开始在更多用例中使用它，我们将看到我们今天甚至无法想象的场景。我之前提到的一个我最近一直在研究的场景是，当然，它在科学发现中的应用，这将开辟一些我们甚至无法想象的令人惊叹的领域。

**A.G.**: 是的。将这种可扩展性应用到那些在传统世界中我们可能无法处理的情况中。有一个公共案例，是西班牙马德里卫生部门的 SERMAS，你可能知道朱利安·伊斯拉。他们试图利用生成式 AI 来识别好的信息，为罕见疾病检索好的信息。通常，每件事背后都有一个商业案例，而使用传统 AI，你会说，好吧，目标公众不够多，因为这是一种罕见疾病。而使用这种方法，你实际上可以将它带给全世界的医生，他们可以更快、更有效地识别这种情况。这是一个完美的例子，即使它听起来并不特别先进，因为它只是检索信息，但我个人非常喜欢它。

**D.C.**: 是的。我对这个用例爱不释手。我也是朱利安·伊斯拉领导的非营利组织[Foundation 29](https://oreil.ly/DCC5D)的一部分，还有卡洛斯·马斯西亚斯和其他人。对我来说，这是一个很好的例子，正如你所说，因为它专注于诊断罕见疾病。我们面临的一个问题是，像医生这样的职业很大程度上依赖于医生的经验。当你诊断常见疾病时，这工作得很好。但初级保健医生接触罕见疾病的机会非常少。他们很难诊断这些疾病。考虑到罕见疾病的平均诊断时间为七年。这七年你都没有对这种疾病应用正确的治疗。像这样的东西，一个模型可以帮助，因为它总是在帮助医生，引导医生，给他们提供疾病可能来源的线索，这是一个了不起的工具，我认为它是这种新的人机合作范例的一个很好的例子。

**A.G.**: 没错，这是在改善现状。一个无法否认的事实是，我们可以通过技术来改进某些事情。你提到了模型，你提到了平台。这本书是关于 Azure OpenAI 的，但你如何看待 Azure OpenAI 作为一项技术或作为一个平台，作为这个时代的技术推动者？你如何看待它的未来发展？这关乎模型，关乎平台，不同层次，以及与之相关的事物。我有我的看法，但我想听听你的。

**D.C.**：我认为这是一个更深层次的对话，我可以这么说。如果你只从生态系统的某一特定层来看待这个问题，你可能会错过很多东西。对我来说，AI 不仅仅是一种技术，它是一个新的范式，实际上是一个新的经济。你看，AI 对核心 GDP 增长的影响是巨大的。我们只是用技术栈的一层来应对这个问题，这还不够。你需要审视整个生态系统。在整个生态系统中，有众多参与者。当然，在最底层，你有芯片，甚至有你需要考虑的纯硬件。然后，在最上面，你需要解决和针对这些应用的大数据中心。再往上，你有基础模型，它们当然非常明显，它们是其中的关键部分。但除此之外，你还需要工具和平台，才能真正充分利用这些模型。这很容易，你知道这一点比任何人都清楚，很容易在服务和模型上启动一个概念验证，很容易开始进行提示并获取更多模型。但要创建一个真正的用例，要创建一个完整的场景，你需要的东西远不止这些。你需要开始谈论基础，安全性，以及像服务集成、插件等许多其他领域，这些虽然与模型相关，但同样重要。然后，在这之上，你还有更多的层次。你有责任，这是至关重要的。你有应用，你有分发。

在 Azure OpenAI 的情况下，我认为关键之处，当然它是整个技术栈中不可或缺的一部分。但在我们的情况下，从我们开始使用 AI 的那一刻起，我们就坚持的一个原则是，我们相信创新的速度应该与平台并驾齐驱。即使在微软内部，我们看待创新的方式也是将这种创新作为平台提供给公司的其他部分。同时，我们将这个平台带到 Azure，让我们的客户能够使用它。因此，Azure OpenAI 是这一点的完美例证，因为我们所做的是创造了“模型即服务”的概念，使得它对客户来说变得极其容易访问，并且让它成为 Azure 的第一公民。你可以像访问任何其他服务一样访问它，这再次将这一点带到了更广泛的平台，让开发者能够用它来创建新的应用程序。

**A.G.**: 是的。你提到的平台上的所有这些层级，这就是我提问的原因，因为通常讨论都是围绕模型进行的。我们正在创建一个更大的模型，在此之前，它更多的是参数更多，而现在它是在基准测试中表现更好的模型。但我认为模型正变成一种商品，非常昂贵且难以创建。但现在，真正的价值在于将这些模型与平台的其他部分相结合。这正是我从 Azure OpenAI 和 Azure AI Studio 在 2023-2024 年这一时期的发展中最为欣赏的部分。

**D.C.**: 是的。完全同意。

**A.G.**: 你对微软正在发生的一切都有一个全面的了解，无论是内部还是外部，比如平台、模型、酷炫项目、微软研究、论文，以及即将到来的一些新事物。哪一部分让你最兴奋？这是关于大型语言模型还是小型语言模型——你有什么偏好吗？

**D.C.**: 从研究的角度来看，可能是因为，当然，在全栈中，每一层都在发生着事情。我对每一层都感到兴奋，因为它们都非常重要。在我心中，我是一个软件开发者。我对与平台相关的一切都特别热情，因为它真正使开发者能够在其上创建重要的酷炫东西。我是 Azure AI Studio 和那里所有工具的超级粉丝。任何与模型整个生命周期编排相关的东西，我都是超级粉丝。在我最初的职位上，我非常专注于我们如何利用云来改变开发过程。DevOps 的概念，持续集成，持续部署等等。我们发布了当时被称为[Visual Studio Online (VSO)](https://oreil.ly/IJeOu)，现在它是 Azure DevOps。我认为我们总是忘记这部分栈，它非常重要。如果你只是采用非常具体的工具和模型方法来采用 AI，那么你不可能在企业中取得成功，所以你需要查看整个生命周期，并编排这个生命周期。这一点，我非常热情。

但现在，如果你问我关于令人惊叹的东西，那些让我兴奋的研究成果，我必须说我，可能是因为我的当前工作，我对将 AI 应用于科学的所有工作都是一个大粉丝。其中有些东西令人震惊，我们现在只是触及了表面。我们最近宣布的一个例子是将这些模型应用于实际的科学发现。在这种情况下，这是一项电池发现，其余的材料来制造电池。它是完全使用这些工具发现的。它们是这些模型可以做的三件事，但在某种程度上，其核心概念就像说，嘿，就像 AI 可以在文本之上进行推理，就像 AI 可以在图像、视频等之上进行推理一样，AI 也可以在图之上进行推理。一个非常重要的图就在我们周围，那就是分子。它们只是原子的图。AI 在那些结构、分子之上进行推理的可能性是令人惊叹的。我们看到与生成 AI 相同的理念也适用于图像。想想当你写一个提示时，模型会提供一个图像作为输出。DALL·E。我们现在开始看到这一点，微软研究院已经在一些模型上实现了这一点，这些模型可以用分子做到这一点。想想解释模型，你在特定的模型中寻找哪些特性，模型为该分子创造了很多变化和可能性。这是令人震惊的，想想这个的可能性。

但那部分是关于生成的。接下来的一部分是模拟。有了 AI，我们可以模拟这些分子的特性和相互作用，想象一下，这相当于亲自去“湿实验室”进行操作。现在，如果你能通过 AI 做到这一点，加速数千倍，那么在传统计算上所需的时间，这让你能够只是扩展你的搜索空间。现在，你可以筛选数百万种分子以找到那些特性。最后一点是帮助我们合成这些分子，给我们提供合成这些分子的最佳和更有效的方法。这在任何科学领域中的影响——从材料到健康，到可持续性，到气候变化，到许多其他领域——都是令人惊叹的。当你结合知识推理的概念时，现在你有一边是能够模拟自然的 AI 模型。另一方面，你有科学家的共飞行员概念，科学家可以使用它来与所有过去的科学知识和该领域的当前知识进行推理。它的可能性令人震惊。

**A.G.**: 这很令人印象深刻，影响到了所有层面，甚至学术层面。正在学习的人可以检索到所有信息，他们可以加速他们的学习，并且他们可以越来越多地贡献于研究。你看，这就是为什么我邀请你的原因，因为你对这些事情有远见。

**D.C.:** 这很有趣，因为我们总是谈论人工智能代表人类所能做的工作，但有了在科学界集体知识之上的 AI 推理这一概念，它实际上可以使这个社区更加紧密，因为现在科学家在基于其他科学家创造的知识进行推理时面临很大的障碍，因为知识太多了。几乎不可能让一个科学家掌握社区的集体知识。现在，有了这些工具，它将使科学家更容易建立在他人发现和进步的基础上，这真是太神奇了。

**A.G.**: 为了结束这次讨论，我会回到你的书，*《人工智能组织》*。学生们在思考，好吧，这和我们有关系吗？描述性人工智能，就像传统人工智能一样，当我谈论生成性人工智能时，我需要学习这些吗？现在我们有很多新的专家在谈论这个话题。我说，当然，这种考虑，技术考虑，但还有组织上的考虑，包括采用的障碍、技巧以及你需要做的事情，还有公司的数据组件，数据战略，这些都非常重要。我感觉你的书包含了很多很好的例子。我记得 Telefonica 和 Chema，Alonso 的那个例子，我特别喜欢，因为它非常具有说明性和创造性。但如果你要向公司层面的生成性人工智能采用者推销这本书的价值，它的价值会是什么？

**D.C.:** 是的，我的意思是，这本书是想着那些我看到的，大型公司拥抱人工智能时的学习经验而写的，对吧？所以，我在早期就看到了很多这样的例子，对吧？所以，人工智能的早期阶段就像是在八年前。所以并不是很久以前。而且很有趣，因为我看到阻碍大规模采用人工智能的因素与技术无关。所以这让我想，嘿，有很多书在谈论技术，但在这其中有一个缺口，就是没有讲述一个更广泛的故事，这是任何级别的组织领导者为了在人工智能方面取得成功而应该知道的。所以这就是这本书的写作方法。我确定了四个你需要解决的大领域，才能在规模化的采用人工智能方面取得成功。所以，再次强调，不是概念验证，也不是具体用例，而是真正用人工智能来转型你的公司，对吧？并成为那个人工智能组织的概念。是的，技术是其中之一。所以，当然，技术是存在的，我谈了很多关于技术的事情，但我还谈到了策略。你需要有一个全面综合的策略，它包括短期，但也包括长期，并且在这两者之间建立联系，对吧？所以我分享了在微软的所学。我们如何处理这个问题，我们称之为“地平线框架”，以及我们如何确保我们在地平线上平衡这些投资。我们有一个连接性的策略，它投资于短期，因为这对短期有价值，但也投资于长期，以及如何将两者联系起来，对吧？所以这是好的。我还谈到了有一个从技术到业务，然后从业务到技术的方法的必要性，对吧？这是至关重要的。我看到，当时我看到很多对话都是从技术的可能性开始的，但没有考虑到业务需求，对吧？所以你需要一个框架。我还分享了我们在微软使用的框架，以进行以业务为中心的对话，并将其与技术联系起来，以专注于识别我公司的用例和长期赌注。所以这就是策略。

第二个是文化，因为这也是一个关键因素。这种 AI 转型不是在实验室里发生的事情。并不是你可以创建一个 AI 卓越中心，把它当作一个黑盒子，然后忘记这个问题。这是一件会影响整个组织的事情。作为领导者，你需要知道这一点。所以每个员工都必须参与其中。这是一件需要具体行动和需求的事情。我也分享了如何做到这一点，一些来自微软的经验。我们在那方面有很多经验。你意识到这一点有多重要，如果你将失败与成功进行比较，你会发现文化通常是其中的一个巨大部分。当你有一个组织没有完全投入其中，有些事情是孤立的，没有连接起来，通过这种方式很难在业务上产生影响。最后一个是责任。正如你所知，这是一个关键因素。我们倾向于认为这只是为 AI 制定原则。这远远不止这些，对吧？你需要将这些原则付诸实践。现在甚至比那时更重要，因为那时没有法规，但现在随着法规的出现，它不仅仅是一个好的补充。它将变得绝对关键，每个公司都必须这样做。这不是你可以在过程结束时考虑的事情，这是你在开发的每一步都必须考虑的事情，从构思到开发，再到部署和监控。

**A.G.**: 我完全同意。看，这四个支柱今天仍然完全相同。我们面临的是同样的情况，人们对技术感到兴奋，然后忘记了公司的整体战略，创造出与公司战略、回报投资或公司潜在价值无关的案例。文化，所有的教育部分，现在越来越明显，人们需要了解基因人工智能，我们看到这一趋势在技术团队旁边。至于负责任的 AI 部分，我称之为问责制。现在这还不是 AI，因为它是有责任的。它是值得信赖的，是负责任的，是道德的，是一切你想要的，但有一个法规。所以现在我们希望遵守法规。所以它还是一样的。这就是为什么我认为它仍然是对任何生成式 AI 采用者来说非常好的经典。

## 布伦丹·伯恩斯：云原生在生成式 AI 开发中的作用

**A.G.**: 我很高兴你能来。我知道很多人都知道你，但你在微软的当前角色和经历是什么？

![图片](img/aoas_07in02.png)

**B.B.**: 当然。我目前是云原生开源和 Azure 管理平台的副总裁。所以重点是，我想最好的总结可能是所有关于 Azure 上的 DevOps 和现代应用开发的事情，特别关注容器和 Linux。

**A.G.**: 所以与云原生和微软生态系统相关的一切，你都在那里。

**B.B.**: 是的。还有 Azure 资源管理器，它有点像带策略的 API 网关，以及所有基础设施即代码的工具。

**A.G.**: 对于我们在书中讨论的那种架构来说非常重要。即使这是一个明显的问题，你在云原生和 Kubernetes 方面的经验是什么？

**B.B.**: 当然，是的。我的意思是，显然我是开始 Kubernetes 项目的。实际上，这已经接近十年了，这也是为什么我可能会有一些白发的原因，但你知道，我负责了那个项目的早期阶段，塑造并帮助塑造了社区。然后我来到了 Azure，专注于真正弄清楚 Azure 如何成为运行开源和云原生工作负载的最佳场所。作为那部分工作的一部分，我也认为帮助了许多企业，传统的微软客户，他们在向云原生应用程序的过渡中。我认为云原生就像是一个新的初创企业事物，但实际上，我认为今天正在构建的大多数云原生应用程序都是由需要这种开发敏捷性和可靠性的大型公司构建的。

**A.G.**: 是的，这与微软当前的时代生成式 AI 相关联。你对这场新潮流的个人观点是什么？

**B.B.**: 嗯，我对这个非常兴奋。我认为每个人都对此感到兴奋。我在个人层面上也非常兴奋，因为这实际上帮助了我。我认为使用 GitHub Copilot 这样的工具实际上确实可以加快速度，尤其是在我学习新事物的时候。我大概在六个月前开始学习 Rust。我发现当你处于一种新的语言中时，它对提高你掌握惯用模式的速度产生了巨大的影响。你可能会想，因为有时候，当你学习一种新语言时，你会像编程其他语言一样编程。所以你最终会像以前写 Java 一样写 Python，例如。我认为能够访问那些惯用模式有助于你更快地掌握语言。此外，我发现 Rust 的错误信息也不如它们本可以那么好，我认为。所以再次，有那种请为我修复这个错误信息的能力，对吧？它会给我我需要的代码片段。这也很有用。所以我认为这很酷。

我认为我们也非常兴奋地看到我们如何帮助客户在编程语言、基础设施或任何其他众多事物上实现类似的复杂性降低。成为云原生是一个很好的例子，实际上，基础设施即代码 (IaC) 对人们来说可能很难，而使人们能够轻松地从门户中的 ClickOps 过渡到基础设施即代码是非常棒的。而像基础设施即代码模板的机械导出这类事情并不总是那么好。我认为生成式 AI 给我们提供了走不同方向并做得更好、更流畅模板的机会，如果我们只是写一些试图完成这个任务的代码，我们可能做不到。

**A.G.**: 是的，我认为这很令人兴奋，因为它是双向的，不是吗？我们可以利用生成式 AI 来实现所有云原生目的。同时，我们也可以利用云原生的良好实践来在现有和新应用程序上实现生成式 AI。

**B.B.**: 绝对如此。是的，我认为这很有趣，对吧？声称没有 Kubernetes 就不会有生成式 AI，听起来似乎有些夸张。但我想实际上，这倒是真的，对吧？并不是说 Kubernetes 特别特殊，而是它让很多想要构建大规模系统的人可以不必再考虑机器管理。进行 AI 推理的第一步不再是想方设法让多台机器协同工作。容器和 Kubernetes 已经为你解决了这个问题。所以你可以说，好吧，我有一支配备了 GPU 等设备的机器群。我该如何将我的应用程序部署出去进行训练呢？我认为这实际上是计算机科学的历史，即构建更高层次的抽象，以使下一个平台能够在其之上构建。

**A.G.**: 这是我最喜欢的一个案例之一。如果你查看 *kubernetes.io* 或 [CNCF](https://oreil.ly/epXxD) 上的成功故事，他们会谈到 [OpenAI with Cloud Native](https://oreil.ly/b5EfH) 以及它是如何使我们看到的所有这些事物成为可能的，比如更广泛的规模，很多人可以连接到 ChatGPT。当然，背后还有微软的 AI 基础设施。但这为所有这些应用领域和 AI 编译器提供了一种新的推动力。

**B.B.**: 是的。再次提到复杂性降低的问题。所以，生成式 AI 不仅能够降低复杂性，而且拥有那个编排器还可以降低 AI 工程师们的复杂性，他们不必担心这个问题。而且当你从 Azure 获取它时，你甚至不必担心运行它。它只是为你处理这一切。

**A.G.**: 为像我这样的人节省了很多时间。

**B.B.**: 我认为这也是一个目标，对吧？消费一个想法比实施一个想法要容易得多。你可以这么说，好吧，我知道如何使用排序算法。你可能能写出排序算法，但写它的时间要比使用它的时间多得多。这赋予了许多人力量，这是很棒的。

**A.G.**: 是的。它加速了实施，以前需要花费很长时间才能完成的事情现在变得更容易实现。

**B.B.**: 是的。我想你会看到，我认为你会看到随后发生的创造性爆炸，许多可能没有耐心或技能集来实施生成式 AI 的人，但他们可以真正有创造性的想法来使用它。所以当你使这种能力可用时，你将仅仅产生大量关于如何使用它的创意。

**A.G.**: 当然。从微软的云原生角度来看，你是如何看待所有这些关于 Copilot、语义内核以及我们在本书中提到的所有不同酷炫组件的技术栈爆炸的？你对这些有什么个人看法？

**B.B.**: 嗯，我的意思是，你仍然需要在某处运行你的应用程序，对吧？你知道，生成式 AI 并不能让你不需要网页或者不需要某个地方的 Restful API。因此，不仅像 Azure Machine Learning 这样的工具建立在 Azure Kubernetes Service (AKS)之上，而且我们实际上还看到很多人在 AKS 上构建他们需要的客户端应用程序或 API，甚至还有 OpenAI 的插件。它仍然是一个非常好的托管代码和集成的场所。当然，我们在 AKS 中提供了 GPU 支持，所以有些人正在自己进行推理或构建自己的模型。实际上，我们最大的集群实际上是为了为各种不同的群体执行这种类型的 AI 而构建的。再次强调，我认为这是关于简单性，对吧？因为如果你想要专注于 AI，你不想专注于运行一个 5,000 节点 Kubernetes 集群所需的一切。这不是一件容易的事情。如果你只需点击一些按钮或执行一个基础设施即代码模板，就能拥有 5,000 个 GPU 节点，那就相当不错了。然后知道我的团队会随时待命。这可以节省你很多时间。

**A.G.**: 是的。这正是我们现在在 Azure AI Studio 中看到的情况，以及所有这些应用程序和部署任何类型模型的能力，因为这本书是关于 Azure OpenAI 和专有模型的。你是如何看待开源作为生成式 AI 推动者的角色的？

**B.B.**: 是的。我认为，随着时间的推移，我怀疑将会出现越来越多的模型，人们会为不同的情况调整、构建。我的意思是，你已经在看到这种模型共享和模型重新训练发生了。我认为这真的很棒。我认为你看某样东西，你知道，Semantic Kernel 正在开源共享我们的最佳实践。LangChain 也在开源中。我认为这一切都根植于开源。我认为随着时间的推移，还将发生一些事情，我认为将会是更高级的框架。我认为人们仍在试图弄清楚构建一个完整的协作者需要什么。我认为有很多我称之为垂直协作者的，你知道，擅长某一件事的协作者。但我认为，实际上，有一些非常广泛的领域，你可能实际上需要一种知道如何选择协作者的东西。我想象它有点像搜索，对吧，当你进行网络搜索时，地图、视频？你可以搜索各种不同类型的内容。我认为 Copilot 也会是这样。在选择你想要生成的内容方面，将会有多个层次。我的意思是，在某种程度上，它就像你的朋友一样。比如，你去找一个朋友寻求技术建议，你去找一个朋友寻求体育或其他什么。你将会找到同样的事情。

**A.G.**: 在一方面，有所有正在创建的构建块以及你提到的协调者，不同的方法，比如检索（RAG），比如我们可以使用的知识库，可以是数据库等。我感觉这正在快速发展，当然。

**B.B.**: 当然。我认为我有一个问题，你知道，我并不一定有正确的答案，那就是，你什么时候进行重新训练，什么时候进行检索增强生成？因为它们在某种程度上都做同样的事情，你可以通过重新训练或在你自己的语料库上重新训练，或者通过进行检索增强生成来影响你的结果。我认为像这样的问题，人们可能需要一段时间才能解决。

**A.G.**: 是的。对于这个问题没有单一的答案。在这本书的其中一个章节中，我提到（非常谨慎地，因为这个话题非常新）我们需要根据数据集，根据你想要的重新训练类型，你想要的微调类型，或者与分配的任务相比的 LLM 的一般行为来尝试和测试。

**B.B.**: 或者甚至应用。你可能无法为每位客户重新训练它。你可能必须这样做，因为你，嗯，我有一群多样化的用户。我想为每位用户提供个性化的内容，但我无法为每位用户重新训练，所以我将使用检索增强生成。但另一方面，你也可以这样想，我是我的公司，重新训练是值得的，因为我了解我的公司，我只会有针对我公司的结果。我认为这是很有趣的事情。

**A.G.**: 对，也许它是与分段或推荐系统的结合，某种预先过滤你面前用户类型的东西。然后根据用户可能访问信息的能力，基于活动目录或任何其他知识库，你可以定制那个答案。

**B.B.**: 我的意思是，基于角色的访问控制（RBAC）是一个迷人的部分。我们在 Azure 资源图中也面临这样的挑战，它用于大规模查询。它是所有 Azure 资源的索引。将访问控制应用于它是一个非常有趣的问题。因为显然你不能为每位用户构建一个索引，对吧？有一个所有资源的索引。然后你必须基本上这样做，好的，我进行了查询。我找到了一些数据。现在，我得到的数据中哪些是这位用户实际上可以访问的，或者将其放入查询本身，并在进行搜索查询时，只显示这位用户也有权限访问的内容。显然，正确地做到这一点非常重要。

**A.G.**: 完全同意。在这个复杂性中，你对于提升技能有什么建议，对于想要在这个领域跟进的人来说，比如任何有助于学习者读者跟上所有发生事情的东西？

**B.B.**: 我会说的两件事是，我肯定会推荐尝试一下。我认为 Bing 聊天是一个很好的入门方式，因为它真的非常重要，我认为，要了解它的优点和缺点。因为我认为当你看到或阅读文章，或者听到，甚至当你看到例子时，它们已经被挑选出来。它们永远不会展示给你不好的例子。我认为真正进入其中并意识到它并不完美是非常有价值的。甚至超出了幻觉，我认为人们正在掌握如何处理它，我认为对于一些问题，它并不是很好。我认为经验是关键。给自己一个任务，尝试找出系统擅长什么。

尤其是我想说，它在一般意义上的总结方面做得非常好。我发现它在提取信息并提炼信息方面相当出色。它可能在编译器的错误消息等方面做得很好。有时它也可能真的很糟糕。我认为你必须自己判断它擅长什么，不擅长什么。因为这将给你一个感觉，你可以用它来实现哪些想法。因为你可能会想，我可以使用生成式 AI 来做这件事，但实际上，这可能不会很顺利。所以这是第一部分，然后我认为第二部分是我非常相信通过一个对你有意义的玩具项目来“动手实践”。我在家里用一些随机的东西做很多黑客攻击，比如打开灯之类的。不要只是通过玩具示例，因为你没有个人联系。我认为这种个人联系有助于你构建。当然，你不可能一开始就构建整个应用程序。你需要一个小的、受限制的东西来确保你继续取得进步。我认为我学习新技术时通常就是这样做的。我真的想了解它是如何工作的，以及我是如何把它拼凑在一起的。那个框架。然后，你知道的，然后你可以继续说，好吧，我现在有了知识去构建我真正想要构建的应用程序。

**A.G.**: 我认为这两个点非常精确地描述了获得经验的过程。当然，有 Azure OpenAI，还有那里不同的技术或 Azure OpenAI 在不同产品上的版本，以及它们的局限性和优势。因为确实有很多优势，但也有局限性。例如，我检查了一些与查找特定人物相关信息的东西。也许这并不总是最好的用例场景，因为它是语言学，你有来自微软的阿德里安·冈萨雷斯（Adrián González）和另一位棒球运动员阿德里安·冈萨雷斯（Adrián González）。所以，是的，我完全同意这一点。

提醒我，你也有几本 O’Reilly 的书，对吧？你是拥有多本书的作者俱乐部的一员。你能告诉我们一些关于它们的内容和它们是关于什么的吗？

**B.B.**: 嗯，我写过几本关于 Kubernetes 的不同书籍。[《Kubernetes: Up and Running》](https://oreil.ly/NZcsJ)，这本书是我和凯尔西·海托沃（Kelsey Hightower）以及乔·贝达（Joe Beda）合著的。然后最近，[第三版](https://oreil.ly/IvoU6) 是和微软的另一位人士拉克兰·埃文森（Lachlan Evanson）合著的。实际上，我现在正在编写 [*Designing Distributed Systems*](https://oreil.ly/vbUwd) 的 [第二版](https://oreil.ly/7HkaR)。它实际上会涉及到一些内容，可能不会像你的书那样深入，但会涉及到如何在分布式系统的背景下构建 AI 系统。

然后，实际上我为第二版添加的最激动人心的章节，我将称之为“经典之作”章节，其中包含了人们遇到的所有问题，讨论了人们反复犯的错误。因为我们去现场，你会在故障和事后分析中度过时间，以及所有这类事情。在你做了几年之后，你会发现有一些模式是重复出现的。我已经做了一些笔记，并记下了那些反复出现的许多问题。例如，其中一个经常出现的问题是我们的监控没有意识到错误的缺失应该被视为一个错误。如果有大量的错误，你会注意到。但是，如果它完全安静下来，什么都没有，这可能意味着你完全正常，但也可能意味着你没有处理任何东西。我们曾多次看到系统存在监控缺口，由于某种原因，它们停止了处理任何东西。这种“没有消息就是好消息”的想法，他们直到客户说，嘿，等一下，我的货物在哪里？你可以在在线零售商的交付通道上进行监控，任何类似的事情，对吧？在线零售商可以监控包裹从我的配送中心到客户点 A 到点 B 需要多长时间。如果超过 12 小时或 whatever，他们可以发出警报。但是，如果你停止交付所有包裹，这个警报就不会触发。因为没有交付，所以没有花费时间。这样的细微差别，你一开始可能不会想到，因为你已经习惯了稳定状态。

**A.G.**: 我认为这适用于我们将在本书的未来版本中看到的内容。就像从行业中获得的那些学习经验，以及我们不知道的事情，因为我们还没有意识到。它将基于经验。我们刚刚开始这股生成式 AI 的浪潮，但在这里情况肯定是一样的。

**B.B.**: 是的。哦，是的。我想随着越来越多的人加入其中，这实际上会变化得非常快。前几年，当人们刚开始加入时，云原生开源的情况也是这样，对吧？甚至包括 UI 框架。我认为现在大多数人都在使用 React，但就像曾经有一段时间，我觉得人们每三个月就会更换一次 JavaScript 框架。每次我与人交谈时，他们似乎都会切换他们的 JavaScript 框架。我确信这种情况也会发生在 AI 上，因为我认为人们需要一点时间去弄清楚哪些抽象实际上有效。哪些抽象是有意义的？哪些是我们可以将其转化为库的常见问题？我认为现在正在进行大量的自由形式提示工程。我认为将来会有更多的科学进入这个领域。我不知道“科学”这个词是否恰当，但随着人们弄清楚哪些有效哪些无效，会有更多类似严谨的东西进入这个领域。模板、操作、最佳实践、对策。我认为在某个时候，你可能只需勾选一个复选框，就能得到一大堆修复和类似的东西，幻觉预防等。

**A.G.**: 嘿，就剩最后一个问题了，因为你提到了尸检，但我们书中还提到了一个概念，那就是生前检查。你有没有使用生前检查的概念来预想可能会出错的地方？

**B.B.**: 是的，这有点像我们所说的“红队”行动，你试图打破它，你知道，你是有意尝试破坏东西的。是的，我认为这非常重要。我认为你检查了坏的东西，显然，媒体上和其它地方都有关于如何欺骗这些模型的方法，但老实说，只是为了看看它是否做得好。我认为这更实际。你知道，没有人会写一个标题说，这个查询回答得不好。但显然，如果你在构建一个产品，真正重要的是要理解：它实际上是否有效？我认为实际测量也是另一件非常有趣的事情。我认为我们在这方面还没有做很多严格的科学测量。我的意思是，有一些排行榜和类似的东西可以用来与基准进行比较，但一旦你将其集成到产品中，这并不一定与用户体验的现实情况 100%相关。我认为我们就像在 Azure 门户等地方做的大量工作一样，去弄清楚，我们在哪里让用户感到困惑？你知道，我们的 UI 哪里不好？我认为我们也会对聊天系统做同样的事情，对吧，可能就是，人们点击我们建议的提示有多少次，或者他们按了多少次清除按钮，或者，你知道，有很多方法可以找出，我们是否提供了他们想要的答案？

**A.G.**: 完全同意，因为目前我们在 LangChain 和 Azure AI Studio 上的基准和评估类型的项目中，主要关注核心模型部分。但您提到的所有定量和定性指标，我们通常在产品分析中都会用到，例如。这一点我在书中也提到了。您会在一些章节中看到它，因为显然这部分会有很多变化，但了解这些指标，从用户的角度来看，你做得好还是不好，这是至关重要的。我认为这对公司也会非常有用。

**B.B.**: 当然。是的，绝对如此。我认为它目前还处于初级阶段。看到我们如何解决这个问题将非常有趣。所以我也是非常兴奋的。微软也非常重视可访问性和面向所有人的计算。我认为这也会在可用性方面带来变革，因为我们看到人们面临挑战，我们在我们的 UX 可访问性方面做了很多工作，但我认为由生成语言支持的聊天或基于语音的 UX 可能会比我们用鼠标或声音 UI 提供的要好得多。

**A.G.**: 我非常喜欢这个葡萄牙政府的案例，[为不能写字的人创建一个头像](https://oreil.ly/jMgb6)，然后你还有一个为能写字但不能说话的人准备的。我认为这就是我们正在走向的方向。我们说这种生成式 AI 相当于视觉界面与命令行之间的关系。我相信这是真的。

**B.B.**: 是的，我认为看到它如何改变事物将会非常激动人心。参与其中也很有趣。我想这就是我们一直在这里的原因。参与变革也很有趣。

## 约翰·梅达：关于 AI 设计和编排

**A.G.**: 我非常了解你，只是因为我某种程度上是你的粉丝，因为我喜欢你所做的学习资源。但让我们了解一下约翰是谁，以及你在微软的角色以及你的背景。

![图片](img/aoas_07in03.png)

**J.M.**: 我很幸运能参与到 AI 超级风暴的中心，有一个名为语义内核的项目，我在帮助推进它。这是一种让更多企业利用这种新型 AI 的方法。在那之前，我在物理安全行业工作。我是 Everbridge 这家中型安全公司的首席技术官。我们照顾了世界、国家、城市和公司。在那之前，我在风险投资公司工作过。我在麻省理工学院待了一段时间，进行过研究，还在一家后期初创公司工作，真正理解世界的发展方向。

**A.G.**: 太惊人了。这样的背景非常有趣。我真的很喜欢你的一个地方，就是你将设计界和 AI 界结合起来，这对一些人来说非常直观。比如，当然，如果我们与人工智能互动，我们希望有一个以人为中心的过程的界面和设计。但你对这种设计过程和设计思维在 AI 应用，包括生成式 AI 中的重要性有何看法？

**J.M.**: 是的，嗯，我在南加州西南部会议上做了一份年度报告，关于设计、技术和商业的交汇。今年叫做[设计对抗 AI](https://oreil.ly/pOZmj)，有两个含义。一个含义是设计对 AI 的抗议，另一个含义是设计与 AI 竞争。所以一个更像是，你知道的，放弃。停止。另一个是说，也许我会接受它。我认为创意人士应该与 AI 竞争，试图看到如何提升他们的技艺。许多人说这更多是关于与 AI 合作而不是竞争。话虽如此，我认为这种 AI 并不关乎图片或文本。它实际上关乎工具、功能、动作。这就是为什么在语义内核中我们说插件、规划者、角色。我听说现在人们说大型动作模型而不是仅仅大型语言模型，因为大型动作模型假设你在使用功能、插件、功能调用。我认为 AI 的这种动词方面将会是解锁比我们想象的更多价值的东西。

**A.G.**: 是的，因为它是与工具的互动。一般来说，人们担心 AI 会取代社会的一些基本功能。但有些人跳过了生成式 AI 可以作为与非常复杂的功能（如设计 3D 或分析 SQL 数据库）交互界面的部分。所以这就像一个界面。像语义内核这样的模型和工具。

**J.M.**: 我认为插件非常强大。无论你称它们为函数、工具还是你想叫什么，当你将它们与大型语言模型集成时，当然你会得到规划能力。这正是我们在语义内核中看到的。当你使用 GPT-4 时，你给它提供可以规划的插件。一旦它可以规划，它基本上就是在编写你永远无法编写的代码。它即兴编写代码。从设计角度来看，我们花费了大量时间来制作完美的用户体验。这是一件非常困难的事情。我们将构建一个旅程，带你一步步通过。然而，在现实中，通过函数调用，你不需要旅程。你只需说，我想做这个，就完成了。你不需要用户界面。这就是为什么人们称它为某种零 UI 时代，你没有旅程，你直接传送到目标。

**A.G.**: 我喜欢这个观点，因为从我的角度来看，我认为函数调用和规划部分是解释起来最困难的部分，说实话。

**J.M.**: 是的。这太难了。这是因为如果你现在是一名开发者，你只是太忙于发布常规代码。到周末结束时你都很累。你知道，周末你想休息一下，然后，比如，这个新事物，比如，嵌入？比如，你必须做语言模型的理解、测试，比如，这些都是新工具。你知道，Python 可能不是你每天都会做的事情。就像，哦，我不想，我玩过 Python，随便吧。这就是为什么我们试图让居住在.NET 或 Java 或无聊语言的企业开发者更容易使用。所以我告诉人们，Semantic Kernel 是为无聊的 AI 人准备的。

**A.G.**: 无聊的 AI 人。这是如此好的营销。

**J.M.**: 嗯，这是因为企业喜欢“无聊”。我的意思是，我们也有一个 Python 分支，但我发现 Python 的东西非常先进，实际上集成到企业中并不容易，因为它是不同的开发者。应用开发者更关注的是发布“真正的代码”。所以我们需要一个更简单的方式来做到这一点。这就是 Semantic Kernel 存在的原因。

**A.G.**: 这是一个非常聪明的定位。那么你如何定义 Semantic Kernel？你已经解释了插件、角色，但如果将 Semantic Kernel 视为一个事物，今天和未来，如果我们能在这里提前一瞥，你的愿景是什么？它是如何帮助公司的？

**J.M.**: 嗯，你知道，我认为它帮助公司最大的方式是它帮助你变得无聊，因为最新的东西就是最新的东西，但最新东西的问题就是它今天才出现。所以你只是太分心了。比如，我该怎么办？哦，我的天，它每天都在变化。所以 Semantic Kernel 是构建在中间件层上的好保险。当底层发生变化时，在中间件级别上适应它很容易。所以它就像是 AI 变化高速的保险。它基于插件，因为插件是功能调用的价值所在。我们有多种方式来做插件，使用原生代码或原生加语义代码，你知道，选择你自己的语言。规划器被设计成不仅利用插件自动调用它们，而且生成一个你可以自己阅读的脚本，不是 Python 程序，而是一个 handlebars 格式的计划。我们发现许多企业很高兴 AI 生成了计划，并且他们想冻结计划，因为他们知道它有效。他们不需要发明新的东西。所以有冻结计划。现在我们都在谈论代理，所以它也包含了代理。

**A.G.**: 代理，我们正在讨论的是与我现在不能透露的人的区别，即代理和副驾驶之间的区别。

**J.M.**: 我不知道我能否进入那个对话。这非常具有元属性，我相信。

**A.G.**: 这非常具有元属性。我认为这取决于观众。谈论代理的人可能是一个更偏向开发者的观众。

**J.M.**: 是的。很好的观点。嗯，如果你记得转向面向对象编程的变革，我记得那是一个激进的观念。就像，你怎么做？我已经习惯了以这种线性、模块化的方式编程。对象？对象是什么？面向对象编程的第一件事就是不要把所有东西都变成对象。我认为面向代理编程也是如此，有时代理是有用的，有时则不然。我认为它只是一种新的模式。

**A.G.**: 是的，完全同意。我喜欢这个例子，因为我出生在面向对象的时代。我可以看到前一个时代是什么样的，这没有意义。当你需要创建对象之间的关系时，你以线性方式做这件事。

**J.M.**: 你记得，你突然把一切变成对象，然后你就无法理解它了。你创造了一些妥协。我认为代理是一种通过迭代、通过反馈循环来提高模型输出的新方法。这是一种更聪明的提示方法。它更加模块化。但有时如果你需要一个线性工作流程，那可能就是你的应用程序所需的内容。在这种情况下，你不需要代理。在这种情况下。

**A.G.**: 有趣。从 Azure OpenAI 的角度来看，以及 Azure 中任何类型的生成式 AI，您如何看待它与语义内核之间的联系？您一般如何看待编排的作用？比如在 Copilot 中，我们谈论的是 Prometheus 和其他编排引擎。您如何理解这一点？这个领域有太多东西了。

**J.M.**: 嗯，你知道，有些人想直接调用模型，调用 API。我确信你见过像[Ollama](https://oreil.ly/Eyl-u)或[LM Studio](https://oreil.ly/qQBmG)这样的东西，它们都在适应 OpenAI API 规范。我有点感觉 OpenAI 已经成为了一种接口机构。由于 Azure OpenAI 非常紧密，快速跟进，我认为生态系统中的任何人都能够利用这一点。然后你可能想直接编排以与 API 通信，或者你想要在某一层进行通信。层就像衣服一样。基本上有各种各样的品牌。Symantec Kernel 这个特定品牌的衣服是先插插件。然后插件是基础。而且很酷的是，规划器也是插件，我们的代理、角色也是插件。我们说我们从头到尾都是插件。所以我们非常无聊。

**A.G.**: 这是一个多层架构，其中它们在相互通信，然后你有不同的选项来与这个服务和其他服务进行通信。

**J.M.**: 一切都是代码。我们不是试图创造一个魔法咒语，让你不再编程。你仍然在编程。一切都是计算单元。它是一个插件。你可以创建也是插件的计划，或者你可以创建也是插件的代理。这就像连接那些点。

**A.G.**: 太棒了。让我问一个问题。有好几个人问我同样的问题。你可以告诉我这不是一个好问题，但 Semantic Kernel 和 LangChain 之间的区别、趋同、兼容性是什么？

**J.M.**: 这是一个非常常见的问题。是的，LangChain 和 Semantic Kernel 都是开源项目。开源项目之间相互支持。我对 LangChain 只有好评，还有[Harrison](https://oreil.ly/ttbiM)这个社区。我也非常喜欢[LlamaIndex](https://oreil.ly/QZtYV)，我认为它就像是一个姐妹或表亲项目，我非常喜欢。真正的区别在于 LangChain 正在以最快的速度运行最新的 AI 想法。Semantic Kernel 并不扮演这个角色。Semantic Kernel 的角色是帮助企业利用这个大型语言模型或大型动作模型革命。它们可能会走得慢一些，需要更多的安全感和保障。因此，Semantic Kernel 的设计中包含非常少的包依赖，如果有的话。它被设计成让 CISO（首席信息安全官）喜欢，也设计成让采购部门喜欢，因为它免费，但也是微软世界的一部分。

**A.G.**: 是的。这完全有道理。我认为两者都是必要的。

**J.M.**: 是的，是的，是的。我的意思是，就像我说的，如果你想驾驶特斯拉 Model S Plaid，那么 LangChain 很有趣。如果你想驾驶丰田 Camry XLE 混合动力车，那么你就有了 Semantic Kernel。而且，有趣的是，随着 Python 分支的出现，一切都在成为 1.0。.NET 首先成为 1.0。我们正在对齐 Python 和 Java 的发布。如果你是 Python 团队，通常是一个以数据科学为导向的团队，并且使用 Semantic Kernel，所有你的 YAML 文件和一切都可以轻松转移到 App Dev。所以这是优势。

**A.G.**: 那协调的作用是什么？我知道这有点牵强，但协调在及时提供适当的信息和格式以及良好的时机以符合规定方面有什么作用？我位于西班牙的马德里，欧洲，AI Act，加拿大类似的东西，未来在美国。我觉得中间层有大量潜力来分配日志级别所需的信息。

**J.M.**: 嗯，我认为 Semantic Kernel 首先用.NET C#构建 1.0 版本是个好事，因为它在所有地方都有日志记录。它具有所有 Azure 类型的安保，安全性已经集成到其架构中。你经常听到人们喜欢 Semantic Kernel 的架构，因为它是由微软架构的。如果你还没有看到，或者如果你的读者或观众还没有看到我们如何封装插件，你会感到很惊喜，因为启用复杂插件的函数调用只需要这么少的代码。你可能会想，等等，这就是我需要的所有代码吗？然后你会说，是的，我们可以开始了。人们都喜欢这样。这是由.NET 架构传奇人物[斯蒂芬·图布](https://oreil.ly/i7kqx)设计的。我记得他曾经说过必须这样。我们说，好吧。然后他说哇，这真的很棒。真的很棒。但任何看到它的人都会觉得，代码在哪里？因为它是使用企业级语言已经提供的抽象来实现的，所以所有的代码都在那里。

**A.G.**: 学习是这个采访的目标，我知道你是一个谦逊的人，因为你没有太多谈论你的活动和背景，但你正在创建学习资源，我个人非常喜欢。这就是我写这本书的原因。这就是我们为什么创造所有这些内容的原因。我有两个例子，LinkedIn Learning 和 DeepLearning.AI。它们是关于什么的，让人们继续学习？

**J.M.**: 哦，谢谢。让我看看，我有一个[LinkedIn Learning 课程](https://oreil.ly/TXE5e)。现在我有很多，包括一个关于[AI 工程领导力](https://oreil.ly/z-nXp)的。因为 AI 工程是关于引领变革的。大多数开发者喜欢内向，但他们有时会变成管理者，他们必须领导他人。这些 AI 东西对人们来说有点可怕。理解起来也非常技术性。我还有一个全新的关于厨房主题的课程。此外，微软开发者频道有一个我们制作的新节目，叫做[梅达先生的温馨 AI 厨房](https://oreil.ly/N9oCg)。是的，我们每两周在我的厨房里烹饪 AI。我们还有嘉宾，他们尝试使用 AI。

而 [DeepLearning.AI 课程](https://oreil.ly/nxusL) 是一个与 [Andrew Ng](https://oreil.ly/CDLm-) 谈话的机会，我认为他是我们这个时代的大思想家之一。他在《华尔街日报》CIO 峰会上发表了这次演讲，有人问他这是否会改变人们的就业方式，以及围绕这一点的所有恐惧。他说了最好听的话：你应该把人工智能看作是自动化任务，而不是工作。任何一项工作都有许多任务。如果你有很多不喜欢做的人工作，这些工作对人类来说价值不高，那么用人工智能来自动化它们就很有意义，并且可以提高你的工作效率。无论是你正在编写的复杂的测试功能，你想着，“哦，所有这些情况都会很痛苦，”然后砰！它就出现了。或者像 shell 脚本那样，在每种语言中都有细微的差别。你只需要说，我需要一个 shell 脚本。就在半小时前，我就做了这件事。我需要一个 shell 脚本。然后发现，哦，这很简单。你自己也调试它。所以，这是在为我完成我不喜欢做的任务。

**A.G.**: 我真的能理解这一点。就像，就在这次讨论之后，我正在创建转录、创建行动要点和总结最重要的信息。没有人喜欢做这件事，这可能占我工作的 10%，因为我们有太多的会议。我想回到你的设计背景。看着公司和个人使用生成式 AI、LLM，他们正在学习如何评估它们、使用它们、如何从设计角度进行编排，你认为在不久的将来，从设计 UX、UI 的角度来看，会发生什么与现在截然不同的事情吗？

**J.M.**: 是的。我确实认为这场零界面革命正在发生，当机器能够发现你的意图并执行任务时，你不需要很多用户界面、用户体验或心理学。有件事叫做 [克雷顿·克里斯滕森的“要完成的任务”](https://oreil.ly/Aq12m)。几乎就像我们创建用户体验来完成一项工作，但如果机器知道你想要完成的工作，你告诉它怎么做，它就去做，你真的需要任何经验吗？

**A.G.**: 这太令人惊讶了，真是有趣。就在今天，我有一个学生问我如何定义人工智能要完成的任务。我想，我不知道，我真的不知道。

**J.M.**: 是的，因为有了工具调用和函数调用，你给它，就像在语义内核中，上周我有一个奇怪的瞬间，我给了它我写的五个插件，然后我就不必构建它们如何协同工作的逻辑了。实际上，对我来说编写逻辑太难了，规划者实际上以我无法编写的方式构建了流程。

**A.G.**: 太令人难以置信了。为了结束这个话题，既然你提到了厨房，如果你必须选择，有没有一个食谱是你认为，这是一个人在下一个采用阶段需要学习的？

**J.M.**: 哦，好问题。是的，我告诉每个人在厨房里，你必须意识到有两种 AI 模型。一种 AI 模型负责完成，另一种负责相似性。这就是所谓的嵌入模型。这被称为完成或聊天完成模型。这两个模型的结合使得这场革命变得惊人。如果你只有一个，那就没有用。如果你有聊天完成或完成，它将没有根据。它会说出没有意义的话。如果你有相似性模型，基本上是搜索，你可以找到一些东西，但你不能综合。这两个结合在一起是一对不可思议的搭档。就像一个是黄油，一个是面粉。就像在一起你可以做出美味的饼干。这是所有大型语言模型 AI 的核心食谱。你可以创建功能调用模型，可以创建复杂的聊天，可以创建供应链自动化，所有这些都可以从这两个模型中创建。但一个模型单独是不够的，你需要两个一起。

**A.G.**: 你说得对。我认为在人类的比较中，这就像 IQ 和 EQ 的结合。就像记住信息的能力，传统智力，但那种以适应听众的方式正确解释的能力。是的，我喜欢它。

## Sarah Bird：负责 LLMs 和生成式 AI 的负责任 AI

**A.G.**: 你愿意先解释一下你在组织中的角色以及你在微软的工作吗？

![图片](img/aoas_07in04.png)

**S.B.**: 是的。我是微软首席 AI 产品官。这意味着我的团队负责弄清楚我们如何将新的 AI 技术应用于实践，并确保其负责任地开发。在微软构建的许多 AI 中，我们自己正在解决这个问题。如果我们与其他组织如 OpenAI 合作，那么我们会与他们合作，确保他们在开发 AI 时发生正确的事情。但不仅仅是模型，更重要的是我们如何安全地发布一个完整的应用程序。我们采用这项新的 AI 技术，并审视我们需要遵循的整个方法，以有效地使用这项技术。

例如，对于 GPT-4 这个令人兴奋的新技术，我们第一次发布这个技术是在微软 Copilot 中，最初被称为 Bing Chat。我们的团队进去并基本上领导了负责任 AI（RAI）的开发。我们开发了新的缓解措施，开发了新的测试工具，开发了新的红队技术。我们学到的一切，我们都构建到了 Azure AI 平台上，这使得它能够为微软的所有 AI 提供动力，同时也使我们的客户在构建自己的 AI 应用时能够使用相同的最佳实践。这就是团队的任务，找出我们如何真正将 AI 付诸实践，并确保我们在微软内部使用这些最佳实践，并赋予他人这样做的能力。

**A.G.**: 这是一个很棒的任务。而且它不是一个新的任务。在微软，负责任 AI 的旅程甚至早于 GPT 模型。

**S.B.**: 是的，这是我们实际上已经做了很长时间的事情。我很幸运能成为微软第一个负责任 AI 研究团队的创始人之一，那就是[FATE 团队](https://oreil.ly/hmo69)，那是 2015 年。这是我们几乎已经做了 10 年的事情。但在这段时间里，我们已经走了很长的路。它从研究中的几个想法发展到，我们接下来成立的是负责任 AI 办公室，这实际上开始设定我们想要遵循的政策或标准。但即使在没有太多实施经验的情况下制定政策也是非常困难的。从那时起，我们的大部分旅程都是 figuring out how we really do this，在政策、工程和研究之间迭代，以真正成熟我们的实践、工具和技术。但即使有了生成式 AI，对于很多人来说，他们第一次意识到它的那一刻是 ChatGPT。但实际上，在 ChatGPT 推出之前，微软就已经发布了 GitHub Copilot，这是我们大规模生产的第一个生成式 AI 应用。我们在 Bing Chat 和其他应用中使用的大多数东西实际上最初是为 GitHub Copilot 开发的，因为那是第一个真正的实时生成式 AI 应用。[Azure AI 内容安全](https://oreil.ly/uB6d-)，我们今天在 gen AI 应用中使用的安全系统，最初也是为 GitHub Copilot 开发的。

**A.G.**: 这很有趣，因为很多人，包括我们自己，在谈论不同的 Copilot 时，往往会忘记，GitHub Copilot 实际上是零号病人，第一个，也是最初的那个。

**S.B**：对我们来说，这是一个令人耳目一新的发现，因为 GPT 技术令人兴奋，但它感觉仍然像一个玩具。然后当 GitHub 团队展示了 GitHub Copilot 的早期原型时，我们想，哇，这是真的，这真的很令人兴奋。但那时，我们并不确定，这只是这一个应用吗？这项技术有多窄？会有多少个 GitHub Copilot？然后当下一波产品推出，从 GPT-3 到 GPT-4 时，当我们看到 GPT-4 时，我们想……哦，这不再是狭窄的了。将会有更多可能的 Copilot。这种技术上的飞跃，我认为，真正解锁了许多更多的应用，但 GitHub Copilot 首先展示了这条路。

**A.G**：是的，我认为从 RAI（人工智能伦理）的角度来看，有一个定期完成的想法或采用模式，即与机器进行单一交互，然后转向与聊天相关的交互，具有记忆力和所有好处以及所有考虑因素。我认为这可能就是你所谈论的学习、工程和政策二重奏的演变。

**S.B**：是的，当然。GitHub Copilot 应用中确实有一些细微差别。我实际上非常喜欢它的设计，因为它是一个人们已经熟悉的范例，有自动建议。我们已经习惯了这样的想法……嘿，建议可能并不完美，但如果我喜欢，我可以保留它，我仍然可以去编辑它。我们都知道这使我们用自然语言更快。但后来知道这实际上对代码也有效，这一点并不明显。但我们确实不得不考虑这两个方面，即自然语言风险，如仇恨内容、暴力内容等，以及代码风险，如产生安全漏洞或代码中的已知弱点。我们必须解决这两个维度。因为只有当应用比人们实际打字速度快时，它才有用，所以对延迟的要求非常高。

现在，自从在聊天应用中转向 Bing 和 Copilot 以来，正如你所说，增加了这个多轮交互维度。现在，如果你试图观察一个交互并说“嘿，AI 系统做得对吗？”你实际上必须对多轮自然语言对话进行评分，这要困难得多。系统将要考虑的话题和交互类型更加多样化。我们从 GitHub Copilot 的坚实基础开始，但当然，有了 GPT-4 的力量和搜索引擎的力量，以及我们想要涵盖的广泛内容，我们真的必须考虑得更广泛。因此，这就是你开始讨论诸如幻觉等问题的时候，因为准确性真的很重要，或者因为搜索引擎与信息完整性的紧密联系，可能会遗漏错误信息。因此，随着该应用的发展，视野确实变得更加开阔。

**A.G.**: 那一刻我们必须意识到我们实际上需要新的指标，这一定非常有趣，因为你提到了性能，我们有了 ROC 曲线、F1 和 F2 分数用于分类话题等。然后我们到达那里，我们说，好吧，我们有一种新的应用，它基于被称为生成式人工智能的东西。我们需要测试这个应用的性能。我们有来自传统语言学的指标，比如 BLUE 和 ROUGE。那怎么样？在人工智能层面，我们现在该怎么做？

**S.B.**: 你知道，问题是我们一直都知道我们需要指标来实际解决这些风险，对吧？如果没有实际的指标，很难理解缓解措施是否有效或是否存在风险。在 RAI（负责任的人工智能）领域的一个长期重大挑战是，这些指标真的很难获得。例如，让我们回到“如何评估多轮对话”这个问题。如果你是作为一个 AI 内容安全指标来考虑“仇恨”，我们内部的指南有超过 20 页长，用于评估这样的对话，它们是为专家语言学家设计的。这意味着我们可以按风险来衡量响应，但只能非常偶尔地作为外循环。好吧，一个应用基本上准备发货了。我们可以运行一组非常手动化的测试，由人工评审员评分。如果结果看起来不错，那就太好了，我们可以发货。但这样，你实际上无法在内循环中真正创新，真正尝试不同的事情，并找出哪一种效果最好。

实际上，关于开发 Bing Chat 的早期记忆之一，当我们使用 GPT-4 时，就是意识到它实际上有潜力帮助我们自动化这些指标。我们实际上能够使用 GPT-4，通过大量的提示工程，让它评分达到那些专家人类水平。这意味着我们从“嘿，我们可能只能每月检查一次，或者是在最后，我们将能够每晚在系统更改时运行安全测试，查看分数，并迭代。”转变为每晚都可以进行。这解锁了负责任人工智能创新的新一波浪潮。这项技术显然是人工智能的一个重大突破，但它也是负责任的人工智能、安全和保障的一个重大突破，因为它是一种理解语言和上下文如此之多的惊人新技术。我们真的在我们的 AI 开发中充分利用了这一点。

**A.G.**: 你提到了像安全、保障、甚至合规、法规和负责任的人工智能这样的关键词。所有这些都在这个点上汇聚。一切都在朝着最初是道德行事方式的方向发展，比如愿意做有益的事情，朝着负责任、可问责的方向发展。我认为从技术角度来看，这是一种非常美妙的事情，一种有机的进化。

**S.B.**: 是的，我认为在生成式 AI 方面，一件既令人兴奋又坦白说具有挑战性的事情是，在我们之前进行的许多负责任 AI 工作中，只有 AI 开发者能够管理这些工作。每个人都能从中受益，但只要与像微软这样的优秀 AI 提供商合作，他们就不需要真正了解细节。但在生成式 AI 方面，我们实际上需要采取深度防御的方法来确保安全和安全，这意味着模型开发者需要做一些事情，安全系统开发者需要做一些事情，应用程序开发者需要查看元提示和基础信息，最终的应用程序开发者需要查看人类如何与之互动。这种用户体验是什么样的？

为了有效地使用这项技术，还需要做更多的事情。这并不令人惊讶，它是一种更通用、更强大的技术。这项技术已经从仅由少数负责任 AI 专家掌握，发展到如今每个组织、每个安全专业人士、每个 AI 开发者都需要考虑的事情。看到这项工作的有趣增长和支持真的很有趣，但需求的爆炸性增长意味着我们还有更多的事情要做。这真的很令人兴奋，但也具有挑战性。

**A.G.**: 这非常令人兴奋。我认为它与微软的[负责任 AI 倡议](https://oreil.ly/tCL6L)所推出的各种工具和材料非常契合，这些工具和材料既适用于技术层面也适用于组织层面。我在想[影响评估](https://oreil.ly/bJAeg)和[HAX 工具包](https://oreil.ly/AtDRJ)对于界面的应用。你最喜欢哪一个？如果你必须从对组织在负责任 AI 方面有用的材料中选择不同的部分，你会选择哪些？

**S.B.**：哦，这太难了。我喜欢所有的负责任 AI 事物。但我认为你指出的这一点非常重要，因为它涉及实践、政策和技术的混合。你必须全面审视整个范围，客户和组织都在向我们提出这样的要求。例如，我非常喜欢我们发布的[负责任 AI 标准](https://oreil.ly/j5tBY)，这实际上是我们如何整体上做这件事的指南。因此，组织可以查看它。如果那对他们有效，他们可以采用类似的东西。我们还发布它，以便我们能够获得反馈。人们可以告诉我们他们认为我们遗漏了什么，他们发现什么有效，什么无效。因此，这实际上是我们一切开始的地方。但如果你想要将其付诸实践，你首先需要从像影响评估这样的流程开始，你实际上是在映射风险。然后你需要能够有效地衡量风险。因此，我们实际上刚刚发布了[生成式 AI 的新安全评估](https://oreil.ly/GcCSo)，这是我们运行的自测，以真正衡量这些风险。这实际上就是我之前告诉你的突破。

然后，你还需要能够减轻风险。Azure AI 内容安全是我们减轻风险的一个很好的方法。这是安全系统层。HAX 工具包在应用和 UX 层上提供了很大帮助。我们还发布了提示工程指南和元提示模板，以帮助提示层。你必须全面地审视所有这些才能采用它。我们还经常被客户询问的一个问题是关于如何进行红队测试，如何进行那种最终专家验证。我们发布了[红队测试指南](https://oreil.ly/oDBO_)，但我们知道红队资源有限。因此，我们刚刚发布了[PyRIT](https://oreil.ly/azSbW)，这是一个工具，通过帮助红队人员获得更多尝试新事物的想法来提高他们的生产力，基本上是使用 AI 以与我们现在使用 AI 帮助许多其他角色相同的方式帮助他们。

我们发现人们确实需要所有这些部分。我们正在进行的大量工作都是为了确保他们理解他们将要需要的完整范围的实践、政策和工具。我们希望让每个人都能轻松地拿起这些工具并开始使用，同时根据需要对其进行定制。我们知道不同的领域和组织是不同的，所以我们不希望它只是微软的方式。我们只想让人们能够轻松地从负责任的 AI 前沿开始，然后根据他们的需求进行适配。

**A.G.**: 是的，这很有用。在我的情况下，我正在与合作伙伴、集成商、咨询公司以及寻求灵感或一些良好实践以了解如何接近负责任的人工智能的客户一起使用它。传统上，这关乎定义人工智能原则，比如我们希望负责、透明等。但现在我们在组织和技术层面如何接近这个问题上走得更远。

**S.B.**: 是的，我认为人们提出了两个问题，一个是如何进行我们提到的像红队或评估这样的实践？或者他们问，我该如何应对特定的潜在风险，比如幻觉或提示注入攻击？我们看到人们在两个维度上都在寻找指导。对于像幻觉这样的问题的答案是这样的：这里是识别风险的步骤，这里是衡量风险的步骤，如何进行红队测试，这里是缓解风险的层级。它们实际上是横向和纵向的模式，但我们听到人们以这两种方式寻求指导。

**A.G.**: 是的，确实如此。我认为你提到了 GitHub 或微软 Bing/Copilot 的经验，我认为这对所有试图创建自己的 Copilot 或任何平台，甚至竞争对手的人来说都是极具说明性的。我记得人们说……“嘿，Jordi Ribas（微软 CVP）和他的团队每周都在发布学习成果，这对现在每个人来说都非常有用。”所以这非常令人兴奋，从模型到平台的转变，以及与之相关的所有学习成果。

**S.B.**: 是的，我们现在每天都在学习，随着技术对更多人变得可访问，人们可以想到的所有令人兴奋的新用例。但我认为那些早期是非常特别的。学习的速度非常高。我们第一次将来自公司各个领域的专家召集起来工作。微软研究部门的很多人自愿全职参与其中。我们这些伟大的思想家一起工作，每天迭代。我认为对于很多人来说，那次经历也改变了他们在研究方向上的工作，因为他们真正看到了我们现在面临的真正挑战，以及技术的真正惊人潜力。那种亲身体验，你在其中学到了很多，我们都在一起学习，我认为这对我们在微软做人工智能的方式以及许多人对它的看法产生了真正的影响。所以这确实是我们一个非常特别的创新时期。

**A.G.**: 这一定很神奇。我可以想象那些日子和那些讨论，日常的工作。从消费者的角度来看，看到新闻和所有新的功能也非常令人兴奋，不仅限于模型，还有与之相关的所有东西。你对未来的展望是什么……不说两三年太难了，但就下一年而言，你对这种发展的展望，我们可能会看到什么，我们可能会面临的挑战，你认为会发生什么？

**S.B.**: 是的，我认为我们看到了一些模式。当然，其中一个就是多模态，对吧？许多应用仍然主要是文本，但当你能够理解不同模态（如图像、音频、视频等）的结合时，潜力就大得多。我们开始看到这个技术的非常令人兴奋的例子。我认为在未来一年里，会有更多多模态的应用出现，这无疑会从负责任的 AI 角度来看带来新的风险。我认为人们对下一波技术和 AI 代理非常兴奋，拥有能够执行更多动作的技术。这当然大大增加了你在负责任的 AI 方面需要考虑的事物范围，同时也提高了你需要的质量和准确性，因为如果你采取行动，错误可能会产生更大的影响。

这些是我心中想的两件大事，但在更大的图景中，凯文·斯科特（微软首席技术官）经常说，目前这项技术正处于指数曲线上，但我们只能每年或每两年看到曲线上的下一个点，当下一波技术出现时。我认为我们中的许多人都在问自己，“下一个是否真的会比 GPT-4 呈指数级更好？”如果是的话，这到底意味着什么？因为我们的思维很难在指数上思考，我们实际上是以线性方式预测的。还有一种可能，我们很快就会看到另一个极端的突破。因此，我认为，一个令人兴奋的开放问题是，下一波技术会变得多好？

**A.G.**: 是的，我认为性能将呈指数增长，你提到的那些考虑因素。就像我说的，在创建新应用的过程中，我们需要考虑多个维度。一个很好的例子是，我们看到了[OpenAI 发布 Sora](https://oreil.ly/ppSjf)并将其发布出去，展示了其好处，同时也与社区的不同部分分享，以分析潜在的考虑因素，因为我们可以用这项技术做很多事情。但这很令人兴奋。

**S.B.**: 是的，我认为作为一个技术专家，这是你的希望，但当然不是期望，你会在技术经历关键转型时仍然在，真正地跨越从令人兴奋的研究想法到真正准备好实践的门槛。因此，我每天都会提醒我的团队，我们需要享受这一刻的每一刻，因为显然我认为这项技术的影响只会增长，这也会非常令人兴奋，但没有什么能像开始那样带来如此大的变化，以及学习的速度和一切。所以，我们只是在享受这个过程，但同时也非常清楚，我们处于一个领导地位，需要引导这项技术的未来方向，我们需要帮助世界能够以有效的方式使用它，同时确保它不会被用于我认为社会不希望的方式。因此，我认为我们也非常清楚，在这个位置上所承担的责任之重，确保我们做出的决定对未来是正确的。

## Tim Ward: 数据质量对 LLM 实施的影响

**A.G.**: 当然，你是 CluedIn 的 CEO，但在公司中你的角色是什么？CluedIn 在数据管理、数据质量等方面做了些什么？

![图片](img/aoas_07in05.png)

**T.W.**: 是的，当然。我实际上是从西雅图的一家酒店房间加入你们的。我实际上就在雷德蒙德微软总部大约 200 米远的地方，所以我整个星期都在和那个团队一起工作。这和我扮演的角色有点关系。我领导着 CluedIn 团队，我是 CluedIn 的 CEO，但我来自一个非常以产品为导向的软件开发背景。我已经在架构产品和构建企业级产品一段时间了。我们在 CluedIn 所做的是为微软客户提供一些非常关键和必要的元素，那就是数据质量和主数据管理（MDM）。

数据质量可能是我们都意识到的那些方面之一，我们知道我们需要修复它。MDM 是那些神秘话题之一，我认为人们甚至可能会说它与数据质量同义。MDM 与数据质量有什么区别？在 CluedIn，我们真正看到数据质量修复和 MDM 之间有很多相似之处。我们真正做的是找到那些不同的元素或类别，这里有一个关键点：CluedIn 是一个真正针对非技术用户的工具。这是因为我们认为数据质量似乎不是那些我们总是跌倒的顽固事物之一，我们知道我们需要做这件事。我们相信的，以及我们从客户那里看到的，是我们从未能够将业务带入并让他们对此负责。通常，工具过于复杂，所以我很高兴地说，我们将这些能力带给任何在 Microsoft 生态系统中的人。他们有 Fabric，可能有 Purview，有 Azure Data Factory。但到了某个时候，他们需要考虑如何将业务带入并让他们在这个数据供应链中发挥作用。

**A.G.**: 哇，这太令人惊讶了，因为我非常确信你听到了这个初始生成式 AI 浪潮，就像……哦，我们不再需要数据了，所以我们不需要关心质量。然后发生了什么，人们说他们想要定制开发并使用自己的数据，但是等等，我们已经有一段时间没有关注数据质量了，那该怎么办？

**T.W.**: 正确。现在，这里有一种竞争条件，为了从数据中获得价值和洞察力，特别是 AI，我们可能需要 AI 帮助我们解决数据质量问题。在解决数据质量问题和真正产生 AI 价值之间，有一种相当自洽的阴阳相生相克。我认为你的类比非常准确。

**A.G.**: 是的。在我们深入探讨数据质量细节之前，因为我认为这里值得进行一些讨论，但 2023 年从生成式 AI 的角度来看，CluedIn 的情况如何？我知道你一直在忙于很多事情，包括你自己的产品。你是如何体验这一过程的？

**T.W.**: 有很多方面。首先，作为一个比微软“稍微”小一点的公司，我想我们很早就自己采用了 AI，作为业务的一部分。这始于 GitHub Copilot。然后它逐渐发展。幸运的是，由于我们与微软之间伟大的关系和合作伙伴关系，我们获得了对 Azure OpenAI 的早期访问权限，这是一个私人预览。我们立刻意识到，哇，这就是我们将在自己的产品中构建的方式。这也给了我们一些时间来了解必要的护栏。

我们都知道，Adrián，生成式 AI 形成了一些相当惊人的演示，但在数据管理空间、数据治理和数据质量方面，讨论往往转向如何确保我们的生成式 AI 倡议能够真正地经受住企业动荡的本质？它是安全的吗？它是受管理的吗？我有没有发生事件的审计跟踪？谁对使用的数据负责？关于数据主权的问题，数据在哪里？我们很早就开始内部讨论这些问题，也与我们的早期客户采用者讨论，他们表示，一旦你们开始在平台上实施 AI，请让我知道，因为似乎有如此多的机会将 AI 应用于实际的数据管理实践本身，而不仅仅是将其用作软件的最终消费部分。

**A.G.**: 从 Copilot 的角度来看，从交互、向用户界面添加内容的角度来看，我们说，MDM 或数据质量在传统上是一种技术任务，但我们希望将其带入业务，因为他们了解他们的数据，他们了解信息，因此我们可以添加这一层来注入生成式 AI，这正是你们所做，而且做得非常早。

**T.W.**: 是的，我认为这是我们一直没有能够将业务带入的最大差距，因为我们经常给他们提供这种软件，然后说，嘿，我为你买了一个很棒的 MDM 平台，你只需要把所有的数据质量规则放进去。然后有人进来问，好的，它说要放一个正则表达式。抱歉，什么是正则表达式？我已经做了 19 年的软件工程师，我仍然不知道如何构建正则表达式，但我们却要求人们做这样或那样的事情，这就是他们的角色。我认为这就是为什么这些倡议往往自然地被推回给 IT，因为这看起来像是为他们准备的。然后 IT 部门会说，“不，我们有自己的工具，我们有 Fabric，我们有 Azure Data Factory，这让我能够扮演我的角色，但它要求我非常技术化。”你可以争论，Adrián，我们不是已经尝试将业务带入 30 年了么？有什么变化？好吧，除了技术本身一直在变化之外，获取不同软件的途径越来越容易，当然，云也带来了其中的一部分。

另一方面，我们得到了一个简单易行的方式来与大型语言模型（LLMs）互动；那就是那个鸿沟，它是连接我们的桥梁，你可以告诉我你的意图，我会将其翻译成底层系统所需的内容。因为，对于在数据中检测模式，尤其是在确定性方式下，正则表达式只是我们这样做的一种方式。你需要一些底层函数来实现这一点，尤其是在成本效益和经济的方式下。目前我们做不到这一点，这也是我期待的事情之一，我们不能把大型语言模型应用到每一个问题上。实际上，我们也不应该这样做。如果我发现我的整个供应链只是运行在一个有时对有时错的模型上，我恐怕会睡不好觉。这就是那个桥梁，我如何使用一般知识来弥合这些工具仍然要求你做的技术问题，但现在这并不是那么需要技术。

**A.G.**：这些是我们与工具互动、处理信息或尝试通过使用生成式 AI 来满足某些 JSON 文件的情况，引擎本身变得更加确定。就像我们并没有给予太多创造力，因为我们试图与系统建立联系。在你的情况下，你有软件，你有包含所有数据的后端层，你与数据相连。我认为这是界面进化的一个完美例子。当比尔·盖茨说这是从命令行到 Windows，再到这种生成式 AI 界面的进化时，你怎么看待这种关系？我知道这现在不是一个答案，它可能是未来的答案，在产品路线图上的未来答案。但是，你怎么看待像 CluedIn 这样的公司，甚至 MDM 和数据质量解决方案，与 Azure OpenAI 引擎之间的当前关系？

**T.W.**: 所以我认为这种关系是某种共生关系，一个很好的例子是 Azure OpenAI 的插件架构。你可以插入像 Uber、KAYAK 或 TripAdvisor 这样的东西，而 LLM 知道。我知道当你想要一般聊天和一般知识时，但我也可以做到聪明的事情，比如说，实际上，你什么时候只想和 KAYAK 或 TripAdvisor 聊天并预订一次旅行？在数据管理方面，通过我们平台上的 CluedIn 的 copilot，发生着非常类似的事情，就像你在 Microsoft 365 或 Power BI 或新兴的 Fabric 中看到的那样。如果你有一个包含一百万条记录的大数据集，现在，实际上没有在那些数据上训练自己的模型，真的没有通过上下文窗口以经济可行的方式说出第 4 列第 464,000 行的价值。但共生之处在于，我如何将这种语言翻译成底层语言，然后以非常高效的方式执行查询？这可能是将其本地翻译成 SQL。在我们的案例中，它被翻译成类似弹性搜索查询的东西，比如说，我会构建查询，这样 LLM 实际上并没有查看一百万条记录，它是在本地环境中进行转换。

听着，我认为在某个时候，你将会有这些无限的令牌大小，你可以要么只说，我想要整个一百万行的上下文，或者可能它将是……将数据加载到模型中，你的 copilot 正在运行你的自定义模型。Azure AI Studio 是一个伟大的工具，它使得构建自己的 Llama 和 Mistral 等 copilot 变得非常容易，同时也可以处理来自各种异构文件类型的数据。从 PDF 到图像，再到 CSV、Excel、文本、视频，甚至 C#和 SQL 文件，它都能处理这些。在某个时候，你可能会达到一个点，你甚至不需要在所有情况下进行本地翻译。你实际上可以用聊天的方式与你的整个数据资产进行交流，感觉就像是在本地一样。

**A.G.**: 是的，还有与约翰·梅达博士的另一个讨论，他提到了插件的概念，一切都在互动，我们甚至根据需求构建代码。这就像函数调用，但想象一下自动函数调用，在这个基础上，模型可以实现，我需要检查我的存储或 Cosmos DB，我需要检查我所拥有的任何信息源。更进一步，如果我是在想象（我知道这次采访是关于向你提问的），但只是想象一下未来，这甚至与路线图或任何东西无关，想象一下在未来，你拥有你的数据状态，然后你使用 Purview 这样的解决方案来处理一般数据治理，然后你进入数据质量和 MDM 的细节来准备所有数据，然后有一个平滑的两击推送方式到数据存储。

**T.W.**: 我必须对此发表评论，阿德里安，因为在 OpenAI 出现之初，几乎就在几天之内，LangChain 这个概念也随之出现，我想将多个事物串联起来，当然这也是我们说必须包含在内的原因，因为通过插件架构，我们想要的是获取我们所有的员工文件，将它们导入，将它们映射到相同的概念，并为我转换列名语义。如果你有 F 名，即名字，那么它很容易就吸收了，但在许多情况下，你可能会引入一个 SAP 系统，它的列名并不明显，在许多情况下是德语缩写。而且为了让它能够理解并说“我知道你的意思”，然后将其串联起来，之后检查每一列并应用适当的数据质量检查，这正是我最喜欢的一点，那就是你可以非常灵活。你不是在规定性地要求，比如说，“请强制执行电话号码的标准”，这会有效，但你也可以非常灵活和流畅地互动。

我在数据治理领域，但说实话，我并不清楚 ISO 代码，我不知道如果那个人真的知道这些，在聚会上会有多有趣，而你希望大型语言模型——实际上它知道这些，它知道 ISO 代码，它知道它们的作用以及这些事物的串联，我认为这正是将 GenAI 的使用从节省你 5 到 10 秒的事情转变为真正节省数小时研究和试错的时间的关键。我认为关键在于将其引入产品中，我们对我们产品中 AI 的使用有一套标准或伦理规范，我们也从微软那里汲取了一些灵感，其中之一就是“你的数据是你的数据”，我们永远不会使用跨客户数据来训练这个通用模型。

但我们自己添加的一个案例是，不要为了 AI 而使用 AI，这意味着如果我们在我们平台上构建了一些东西，实际上你也许可以用旧的方式做同样的事情，可能更快或相对相同，为什么要使用 AI 呢？你知道，在聊天中声称“找到所有超过 64 岁的员工”在技术上给人留下深刻印象，但实际上当你使用我们的规则构建器时，你可能已经用与使用 AI 相同的时间手动完成了它，到那时，它就像，那里的价值在哪里？我会争论，价值并不大。有些情况下它是聪明的，例如，如果我这么说，“去找到我们所有在斯堪的纳维亚地区的客户，”我不用说我需要说“国家是丹麦还是冰岛”或这样那样。现在，你节省了 15 秒，但真正应该关注的是，我是如何为你节省复杂性的？我是如何增加简单性的？以及哪些事情为我节省了一两个小时，三天，这是我们真正在这里 CluedIn 上试图关注的。

**A.G.**: 是的，我喜欢这种端到端架构将不同功能链起来处理任何公司的数据和 AI 活动的愿景。但我看到一些案例，人们一直在使用生成式 AI 来不断重新创建聊天机器人，例如，因为我希望它是确定性的，我希望像使用知识库一样使用它，然后我有 10 个问题，10 个答案，我说这并不一定是我们可能想要用生成式 AI 做的事情。你有没有有趣的故事或见解，关于数据质量已经如何影响，无论是负面还是正面，Azure OpenAI 或任何其他技术的生成式 AI 实现？比如客户说，因为我们一直在做数据质量工作，我们已经正确地完成了数据状态，我们看到了差异。

**T.W.**: 与你的数据聊天的一个非常有趣的地方是，它比其他任何形式，比如搜索或类似的东西，更快地暴露出数据质量问题。它变得非常明显，我认为这也是因为人们对 LLM 有很高的期望，所以即使它做了点愚蠢的事情，在我的脑海中，我会想，“我非常感激这一点，这太神奇了，”就像对我的孩子一样，我会更频繁地原谅 ChatGPT，而不是不原谅它，我认为其中一个案例是你开始将你的数据投入 LLM，发生的事情是聊天界面开始清楚地暴露你的数据质量问题。

一个很好的例子是，在 HR 入职流程中，将员工的人力资源数据纳入其中，让新员工感觉他们不必去寻找，“我该找谁谈论这件事？”当然，他们有一个带有类似信息的 HR 系统，比如，这个人是一名软件工程师，他们有这些职责，但随着员工数量的增加，这种方式可能不是最好的，因此能够使用自己的自然语言的形式非常好。发生的情况是，当你输入类似“你能给我知道 Azure OpenAI 最多的人的联系方式吗？”这样的内容时，它会非常有信心地回复，“没问题，我这里有这个和这个电话号码。”当然，这里有几个挑战，首先是，你现在更困惑了，第二点是，如果没有适当的归属，你就不完全清楚 AI 是否在编造东西。

Azure AI Studio 的一个重要元素是，如果你在那个特定的地方托管你的共飞行员（copilots）以及你用自定义模型所做的任何事情，你可以在文件输入级别免费获得归属。挑战在于数据溯源并不始于那里，它始于很久以前的一个不同地方，但你可以在数据最终到达的地方获得它，因此你可以将其放入你的 AI 模型中，但实际上，该文件的溯源，包括源系统是什么，过程中发生了什么，谁改变了什么，为什么他们要改变……这些都是像 Microsoft Purview 在资产级别引入的一些溯源，CluedIn 在记录级别为我们带来的。Purview 可以说，这些四个与员工数据相关的资产被输入到了你的模型中，很好。然后 CluedIn 说，看那里的 Martin，还有那里的 Martin，我无法将这些数据拼接在一起，但我实际上已经将它们放到了同一个记录中，因此一旦你在这个更干净的数据上使用共飞行员，答案就会更加精确，也更加可靠，因为你可以看到……这是 Martin 的电话号码，哦，还有我是从哪里得到它的，这就是我决定使用它的原因，所以当你开始使用共飞行员时，你会觉得技术很棒，超级有趣，它只是凭空想出来的吗？而且你会从这些 AI 模型中知道，它们没有自我意识。它们不能让你知道它们是否编造了东西。这不是大型语言模型和我们之间的一个奇怪差异吗？比如，如果是我编造了东西，我会意识到，但 LLM（大型语言模型）不会。

**A.G.**: 这取决于。我真的很喜欢这一点，因为想象一下，如果你是一名数据科学家，你正在进行探索性数据分析。如果你对业务背景没有了解，你就无法理解你在数据中看到的东西，甚至你自己的分析，是否真正是真实的。我一直在思考这种 EDA（探索性数据分析）或探索性数据分析的概念，就像下一个障碍，因为你可能已经在你的项目中看到过它。最好的 EDA 是那些包括来自数学和技术背景的人，也包括来自业务方面的人，而通常他们（业务人士）不会进行 EDA，因为他们没有技术手段来探索数据，向数据提问。

但你提出的这个概念，即探索数据并理解某些东西是错误的，导致了一场讨论，人们谈论的是“模型幻觉”。我不喜欢这个表达，幻觉，因为它不像人类，但他们是在谈论模型，我觉得这种能力的连锁反应表明，这不仅仅关乎模型，也关乎数据。因为你可以拥有最好的模型，比如 GPT-5，或者任何其他模型，即使它非常精确，我们结合我们的信息，这在很多场景下是可行的，我们需要注意这些数据，以便 LLM 检索到好的信息。你对这些关于生成式 AI 的话题有何看法？特别是关于 CluedIn 以及未来几年的发展？你如何看待这个平台在功能层面的演变？

**T.W.**: 你知道，我意识到 LLM（大型语言模型）非常强大的那一刻，是我第一次意识到我可以将我的输入转换为有针对性的输出，我可以这样说，这是我想要的，你能实际返回这样的答案吗，就像这个 JSON 结构？就在那一刻，我回到我们团队，我说，好吧，让我们看看所有包含的功能，我希望我们真正理解，我能否在平台的每个不同部分使用 AI？你可以看看一些事情，比如当人们做出改变时，我们会引发审计跟踪，你可以想，不，那就像一个日志，AI 为什么要参与其中？然后你意识到，嗯，随着时间的推移，一些记录会发生变化很多，而不是要浏览一个巨大的变更日志，我能总结一下变更的历史吗？你几乎可以把这个应用到所有不同的地方，并且产生净正面效果。

对于我来说，愿景是最大的胜利在哪里？那些需要 2 小时而不是 20 秒就能完成的胜利在哪里？我们需要关注那些真正能节省时间的事情，并达到某种业务指标，比如增加收入、降低运营成本、降低风险、复杂性等，这样我们就可以在不总是感到压力的情况下完成任务。所以，我可以说，在某种程度上，这个 AI 领域发展得太快，以至于对于 ChatGPT 甚至 DaVinci 模型，我们还没有完全挖掘出它们的价值。你可以开始做的事情太多了，而且，当然，美妙的部分是我们可以每天醒来，思考……同样的提示，现在有了答案，而且我实际上除了改变到一个也支持该功能（如函数调用、完成或类似的东西）的模型之外，真的不需要做任何事情。对我来说，CluedIn 使用 GenAI 的愿景非常清楚，你需要 AI 以更完整的方式解决数据质量问题。你仍然会使用那种有点确定性的传统技术，我可以在晚上安心睡觉，因为每次它都会做同样的事情，但你仍然需要那些。

然后，我认为，我们在这里 CluedIn 的工作是，我需要将其带入数据管理流程，这样我们最终可以引入业务，让他们对数据质量负责，因为到目前为止，我认为这是房间里的大象，我们从未谈论过。比如为什么数据质量从未被解决？为什么从未被解决？这太难了，是的，它确实很难，但实际上，问题是，我们从未让业务介入并说，“好吧，看看这个客户列表，这些数据来自 15 个不同的地方，”所以我喜欢这样一个事实，即使在他们的 15 个系统中，它也是完美的。

当我们开始汇集数据时的问题是，尽管我们可以在世界上设置所有的治理，但有些事情会走自己的路，有人需要对此负责。IT 在这个问题中仍然会发挥作用，肯定是在像“我可以可靠地获取数据，我可以进行回滚，我们可以非常快地再次处理它，我们可以进行扩展”这样的东西上，但最终，业务部门的人会进来并说，“这是错误的，我知道，因为我每天都在处理这些数据。”作为一个工程师，我知道如何处理数据，但我不懂如何做这些事情，我不知道如何仅仅查看一条记录并检查它是否符合所有正确的模式。但我不了解这些实际上是同一家公司，如果你不解决这个问题，可能会很简单，比如把发票发送到错误的电子邮件地址，然后你不知道为什么他们不付我们钱，然后你意识到那不是付款的团队。然后你去，“哇，我现在已经逾期 30 天了，”实际上，我需要给他们发送另一张发票并等待另一个 30 天，可能造成现金流问题。你意识到这真的触及了底线，你需要了解这个现实，然后才能欣赏解决数据质量问题所付出的努力。AI 只是以一种加剧了这种需求的方式，因为一旦你使用它，它就会因为形式因素而非常明显地突出出来。

**A.G.**: 我喜欢这个讨论的部分。我在想公司中数据治理的角色和责任，即使你采用 DAMA 或任何框架，不同的角色，这是一个新的原型，这就像是 DAMA 角色的奥丁（漫威参考），就像你有一个奥丁（嗯，可能不是奥丁，让我们来一个贾维斯），一个为你工作的贾维斯，去做那些，让我们说实话，人类不做的事情，因为这是一个手动过程，我们没有时间每次、每天以正确的方式去做这些。

## Seth Juarez: 从生成式 AI 模型到完整的 LLM 平台

**A.G.**: 那么，你在微软的角色是什么？你在组织中做什么？

![](img/aoas_07in06.png)

**S.J.**: 所以，我在 Azure AI 平台工作，担任项目经理。我的工作是负责孵化和叙事。这是我拥有的两个任务。孵化意味着我们构建东西。例如，如果我们想解释某件事是如何工作的，我们会构建原型等。无论这些原型与我们的产品有何不同，我们都会将其反馈到我们的产品优先级和构建内容中，以确保叙事能够顺利进行，这引出了第二部分。我们还进行技术叙事，即解释正在发生的事情以及这些事物是如何工作的。同样，任何理想的故事与产品真相不符时，我们都会将其反馈给我们的产品团队，有时他们甚至会让我们负责某些功能。我们就像其他人一样，主要目标是孵化，构建帮助人们理解如何做到这一点的样本和东西，然后是随之而来的技术叙事。

**A.G.**: 你就像漫威的《守望者》，看到产品层面发生的所有事情，加速器、存储库、原型和新的功能。

**S.J.**: 对的。但这不仅仅是我的事。显然，我们有一群人在做这个。例如，你可能知道[Cassie](https://oreil.ly/33PBM)。她也出现在了[AI Show](https://oreil.ly/h-Fvw)上，但她和我一起做这个。

**A.G.**: 太棒了。感谢你的介绍。你已经看到了 Azure OpenAI 服务的整个演变过程，以及与 Azure AI Studio 的融合。你是如何看待一个最初只是模型，现在却成为了一个功能丰富的平台？

**S.J.**: 这是一个非常好的问题。结果证明，有很多 AI 模型，Azure AI 平台已经从事模型曝光的业务，让您能够定制这些模型，并且已经允许您创建自己的模型多年了，可能已经有半个世纪了。一个新模型的出现，它对我们来说之所以如此出色，是因为我们已经有基础设施来让这些模型发光。虽然新的 GPT 系列模型、LLMs 以及 AI 模型在基础设施和这些事物实际运行方式上可能看起来像是一件新事物，但这对我们来说并不新鲜。我们能够迅速扩大规模并交付这些模型给人们，这真是太好了，显然是在与 OpenAI 的合作下。

**A.G.**: 这是我最近几个月感到惊讶的一件事，看到这个模型作为服务。基本上，能够如此快速、如此容易地消费 API，这对任何开发者来说都几乎是魔法。

**S.J.**: 是的，而且有趣的是，它之所以看起来神奇，是因为我们像我说的一样，已经用我们的认知服务或 AI 服务做了这件事好几年了。我们一直在通过 API 提供，例如，文本到语音、语音到文本、翻译等。如果你想想，它们基本上也是模型即服务。它们只是碰巧更多地处于应用层，但实际上是同一件事。这些模型即服务是相似的。权重可能不同，模型结构也不同，但运行它们所需的东西实际上非常相似。

**A.G.**: 是的，我喜欢 AI Studio 和模型目录的这种融合。只是为了看看所有可用的模型，而不仅仅是 Azure OpenAI。您如何看待这个平台的发展，其中我们有不同的模型，一个完整的目录，部署起来非常容易，有 API 可供使用，我们只需消费它们，我们有 Llama、Mistral，然后我们还有这个提示流生态系统，我知道这是平台的一部分，所有的评估等等。发生了什么？您如何看待它？

**S.J.**: 是的，这是一个非常好的问题。结果是我们希望使人们找到、消费和改进模型的能力商品化。这正是我们想要做的事情。所以，在我看来，生成式 AI 恰好是最令人兴奋的之一。例如，如果你有一个想法并且想要添加 AI，基本步骤是去模型目录，看看是否能找到一些东西，查看我们的服务，看看是否能将其整合。我特别的观点是，就像在 2000-2005 年早期，如果你没有手机应用，一个 iPhone 应用，人们会问：你们是一家技术公司吗？

我的看法是，当涉及到应用程序中的 AI 体验时，人们会有同样的想法，他们会认为如果你不包含这些使人与计算机交互标准化的东西，他们可能会觉得你的应用可能从根本上是有缺陷的。我们正走向一个不再需要适应计算机，而是计算机通过 AI 适应我们的地方，使体验更加自然。所以我的看法是，我们需要开始思考如何添加这些细微之处，并软化我们软件的边缘，AI 如何帮助这些体验？我的看法是，我们将开始看到这些事物被大量地整合到我们做的几乎所有事情中，到 2025 年，有人会来找你，说：哇，你的应用没有 AI？也许你应该添加它，因为人们会感觉它可能从根本上是有缺陷的。

**A.G.**: 我非常喜欢这个。这与我们与约翰·梅达博士讨论语义内核以及人工智能设计的影响非常相关，以及关于 AI 仅仅带来一种新界面的反思，这种界面远远超出了我们今天所知道的视觉界面。我知道这仅仅是一个个人观点，一些你想象的东西，但你对未来一两年内会发生什么有什么看法？

**S.J.**: 两件事，它们看起来似乎是截然相反的，但它们是相互配合的。第一点是这些模型在软件中的应用的扩展和普及。你会看到这些模型被用于做各种事情，使体验更加愉悦，使体验更加以用户和客户为中心。你会看到这些模型的使用范围大幅扩大，而且我们现在已经看到了这一点。我的意思是，自从 ChatGPT 发布以来，还不到一年半的时间，现在每个人都期待它成为体验的一部分。所以，在用户数量方面，它正在变得越来越大。

但也有一些事情会变得更小。会有更多专门化的通用人工智能模型，它们会变得更小，并且将以更有针对性的方式用于完成特定的事情。就像我们现在拥有的通用人工智能模型相当通用且规模很大。然而，你可以制作小型语言模型（SLM），它们更小但更有针对性。模型越小，你需要让它完成的任务就越有针对性。你将看到小型语言模型的普及，可能在接下来的两到三年内，甚至包括在设备上。这些体验将同时进入本地原生体验以及更大的云体验，并且这些模型将共同努力，真正聚焦于解决每个任务时的客户体验，以及以一般方式解决其他语言问题。这是针对语言模型的。两件截然相反的事情，一方面是使用人数的规模会变大，另一方面是人们使用的模型会变小，我认为这两者将非常有效地结合使用。

**A.G.**: 我相信是这样的。对于你提到的第二点，这种多层或多模态架构，我们可以根据它识别的主题来部署我们的第一个模型。我们甚至可以微调第一个模型，然后使用 GPT-4 来完成一个目的，另一个模型来完成另一个目的。你怎么看待这个问题？

**S.J.**: 我认为这是一种很好的表达方式。我们将进入多模态，这意味着多个模型，以及多模态，这意味着多种模态，比如可能是语音、视觉和文本，例如。

**A.G.**: 那么结合不同提供商的模型呢？

**S.J.**: 是的，我认为那很好。在 Azure 的 Azure AI Studio 上，我们真的不在乎你带来什么模型，我们正在尝试与多个人建立合作伙伴关系。我们去年[宣布与 Meta 的合作](https://oreil.ly/ehdf3)，其中一些 Llama 2 模型已经包含在内。我们最近[宣布与 Mistral 的另一项合作](https://oreil.ly/SU0PT)，Mistral Large 直接在我们的模型目录中，其中一些模型你甚至可以进行微调。

但现实是，Azure AI 平台是建立在 Azure Machine Learning Studio 之上的，这是一个通用的机器学习、MLOps 平台，你可以用它来构建你喜欢的任何模型。从理论上讲，你可以从 PyTorch 或 TensorFlow 这样的东西开始，构建你自己的模型或进行任何编码，你可以在 Azure Machine Learning 中直接训练这些模型，并在 AI Studio 中展示它们。但现实是，我们真的不在乎你带来什么 AI 模型，无论是我们通过合作伙伴关系锻造的东西，还是你亲自制作的东西，所有这些都应该并且将在你的应用程序中可用。

**A.G.**: 即使是从 Hugging Face 精心挑选的模型，我们基本上有各种各样的好模型。

**S.J.**: 是的，Hugging Face 是一个了不起的合作伙伴。他们做了很多工作，展示了大量的功能，我们希望这些功能能够让你在应用程序中可靠地部署和使用。

**A.G.**: 是的，你提到了机器学习操作（MLOps），现在变成了 LLM 操作，我们知道这是一个新领域。我们一直在讨论负责任的 AI。但如果我们要深入到衡量模型性能的核心方面，你是如何看待这个问题的？因为这是在不断发展，变得越来越复杂，但也越来越直观。因为一年前，知道如何衡量 LLM 的性能并不容易。我认为现在这个问题已经变得清晰了。我们在这一部分将走向何方？

**S.J.**: 这是一个很好的问题。我们首先从 DevOps 开始。DevOps 不是一个老概念，但它是相当为人所知的。DevOps 是人员、流程和产品的结合，以实现价值的持续交付。MLOps 也是如此。人员、流程和产品的结合实现了价值的持续交付，但与机器学习相结合，LLMOps 与 LLMs 相同。统一这个三脚架——人员、流程和产品——的想法非常重要。因为关于 DevOps、LLMOps 和 MLOps，一个产品不能解决你的流程问题，也不能解决人员问题。如果人们不接受这个流程，那么没有任何工具能够满足这种需求。

我认为首先需要明确的是，没有一劳永逸的解决方案、灵丹妙药或产品能够解决流程问题，以及人们对于流程的认同。这是首要的事情。第二点是，一旦人们想要认同某个流程，那么在 LLMOps 中，我们应该如何确保这个流程的可靠性和实用性，尤其是在评估我们使用的提示词以及如何评估或确保生产中的事物是否正常工作方面。在 Azure AI Studio 中，我们有多种方法来实现这一点。

我认为存在两种评估方式（但显然，这是一个不断发展的领域，因此我们在这里也在学习很多）。但两种评估方式是无监督检查和监督检查。监督检查可能是最简单的。想象一下，你调用了一个 LLM，并想要确保它给出一个与你的预期相似的答案。基本上，你需要有一个输入和预期输出的数据集。对我来说，这是一个监督测试，因为你已经有了你想要的答案。你可以进行多种度量。这里有一个简单的例子：例如，你可以将真实答案投影到，比如说，一个 Ada embedding 或其他任何嵌入中，然后将 LLM 给出的答案投影到一个 LLM embedding 中，然后测量角度。也许有一个特定的容忍度可以给出语义接近度或意义。这是一种检查方式。

你还可以使用我们喜欢称之为 GPT star metrics 的方法，其中你有真实数据，一旦你获得了真实数据，你就可以将其提供给 GPT star metric，比如相似度，然后你作为语言问题向 LLM 询问，这些事物在一到五的尺度上有多相似？你给它一些少样本学习。这是一个监督学习方法的例子，一个更经验性的，另一个更随机的，因为它使用了实际的 LLM 来完成。另一个也是随机的，因为它使用了嵌入，但你有一种方法可以仅将这些事物投影出来，然后测量一个实际指标。

然后还有一些我喜欢称之为无监督的，它们关注的是实际进入提示和上下文的结构，以及答案，它衡量的是整个结构的完整性。让我给你举一个例子：扎根度，这是衡量答案在提供给 LLM 的上下文中的扎根程度的指标。例如，这是我们常用的一个典型例子，我们有一个“Contoso”户外商店，你问了一个关于帐篷的问题。注意，你有问题，然后无论答案是什么，但提示流或 LangChain 或你使用的任何内部结构都会从数据源中获取一些信息，我们知道这是真实的。对我来说，这就是上下文，它通常直接嵌入到我们称之为检索增强生成（RAG）的提示中。你得到问题，你获取一些数据，你将其放入提示中。在这个特定的 LLM 调用中，你有一个问题，你有一个答案，然后你有获取的上下文。有了这三样东西，我们将衡量一种叫做扎根度的东西，即我们获取的答案在上下文中的扎根程度，以及它从我们获取的上下文中生成的答案。这是一个正常的交互。你可能会问我一个问题，我会开始用事实和诚意回答，然后你可能会说，“不，这不是我想要的”那是完全正常的。我们希望 LLM 以这种方式扎根。

有一个衡量答案在获取的上下文和给出的问题中的扎根程度的量表，从一到五，这非常棒。结果证明，这个衡量标准是另一个 GPT 星级指标，我们给出问题/上下文/答案，然后我们说，“在一到五的量表上，答案在上下文中的扎根程度如何？”然后我们在实际的提示中进行一些少样本学习。这也是你可以控制的事情。例如，你可以改变整个扎根度提示，直接匹配你的少样本学习优先级。假设你是一家户外公司，你把这些东西放进去，它就能做到这一点。这些都是我看到即将出现的两种评估类型。一种是监督评估，你有一个真实情况，你将真实情况与答案进行衡量，然后是无监督评估，你是在衡量真实与提供的答案之间的内部一致性。

还有其他一些，比如流畅性、连贯性、相关性，这些都是 GPT 星级无监督指标，你甚至可以发明自己的。有些人发明了一些很巧妙的指标，比如道歉指标，它衡量的是道歉了多少次，我们是否希望最小化这个数值。但你现在基本上进入了一个可以按你的业务需求、你的声音，甚至可能是你的真实情况来评估这些事物的世界，如果这样理解的话。

**A.G.**: 这就是为什么平台会随着我们在平台上拥有的评估流程以及我们可以使用这些指标的能力而不断进化。顺便说一句，你比书中的解释更好。这就是为什么我想采访你，因为我知道你非常擅长解释这些术语！这太棒了。

**S.J.**: 是的。就像我说的，我记得和一些非技术人士、商业人士交谈过，他们担心使用这些 LLM，因为他们会问，我们如何确保它们做的是正确的事情？我向他们展示了，他们就像，哦，所以我可以用英语或我选择的任何语言，因为它们在多种语言中受过训练，实际上可以评估这些模型。我说，绝对可以，而且不止如此。对于那些无监督测试，请注意，你不需要真实数据。当你部署在 Azure AI Studio 时，你有一个叫做模型数据收集器的东西，它使你能够捕获输入/上下文/答案并将它们存储在你的存储中（我们看不到这些内容，我们非常重视这些）。然后即使在生产中，你也能创建查看这些数据并测量相同指标的工作，甚至当这些指标出现问题时还会提醒你。

现在我们正在进入实际的 LLMOps，它使得价值的持续交付成为可能。这就是关键所在。如果价值下降，你需要被提醒并修复它，然后让它回到流程中。通过这些无监督评估和指标，如果你选择的话，你实际上可以在你的生产数据的一个子集上运行它们，这使得这对那些担心这些事情在推理时间或生产中保持一致的人更加有利。

**A.G.**: 太棒了。我只是想看看这个方面的未来路线图，因为关于 LLMOps 有很多讨论，但显然这是一个初步的讨论。这是一个相对较新的领域。如果你必须推荐除了《AI Show》、文档以及所有来自微软的官方资源之外的资源，你有没有什么推荐给学习者以及正在听讨论的人，你认为这对他们的技能提升之旅有帮助？

**S.J.**: 是的。我要说的是，这又将是一个反直觉的观点，因为我喜欢反直觉。你是你自己的终极资源。我的感觉是，无论你阅读多少，或者观察，或者思考这些内容，真正能打败的是亲自尝试。这就是我建议你做的事情。尝试一些东西，制作一个提示，看看答案出来后会发生什么。在我的思维模型中，也许这会有所帮助：你不应该把这些“LLM 事物”看作是知识的存储库。它们不是包含信息的数据库。它们基本上是语言计算器或语言合成器。把你的提示看作是放入 LLM 中的语言算术，把响应看作是答案。

例如，这段加上这段减去这段，看起来会是什么样子？我经常使用 LLM 来这样做，甚至今天早上。我写下了一堆我想表达的想法，以便使其变得平滑，GPT-4 非常友好地建议，是的，你应该这样写。它并不完美，但它使我能够从垃圾开始，得到一些更精致的东西，现在我可以成为一个编辑。编辑比创作容易得多。将 LLM 视为语言计算器，并开始使用它们来解决任务。一旦你将其作为自己的资源，你将走得很远。这些事情并不难开始，你只需要看到终点，然后输入一个提示，就会得到一些结果。

**A.G.**: 是的，有很多笔记本的例子，人们可以玩 API，测试并看到它的反应。这个计算器的概念，我非常喜欢。它与一个人作为系统交互者的 Copilot 概念相一致，这个人将使用模型的言语能力。太令人惊叹了。

## Saurabh Tiwary: 新的微软 Copilot 时代

**A.G.**: 对于那些不了解的人来说，你能解释一下你是谁，你在微软的哪个部门担任什么角色吗？

![图片](img/aoas_07in07.png)

**S.T.**: 我领导一个名为图灵的团队，该团队一直在训练 LLM 并应用它们。这是一个应用团队，因此它将这些模型用于从 Edge 浏览器到 Bing 问答的各种产品中，或者如果你在 Outlook 中收到邮件，你会在输入时看到那些文本预测，你会看到句子被完成，所以有很多这样的功能。最近，我的团队一直在推动微软宣布的许多 Copilot 体验。大多数被广泛使用的，如 Windows Copilot、Edge Copilot、Bing，以类似的方式，甚至在企业方面。所有这些 Copilot 的后端都是相同的，有一个可扩展模型，因此我的团队正在构建这个模型。

**A.G.**: 太令人惊叹了。传说中，你创建了图灵团队，以及那套第一批 GPU，你用它们准备第一批模型。那是在很久以前。

**S.T.**: 是的，那已经是很久以前了，可能是在八九年以前，至少在产品方面。显然，微软研究院已经长期推动着技术的最前沿。但在产品方面，我买了第一批 GPU，然后搭建了第一批集群，并在其上运行软件层，这样你就可以进行一些大规模的训练（现在任何标准下都不算大规模），在那个小集群上进行一些大规模的训练，然后发展到 Azure 上运行的一批 GPU，现在我们就在这里，甚至推理 GPU 也变得非常庞大。

**A.G.**：你提到了微软 Bing Chat 和现在的 Microsoft Copilot。这个旅程是怎样的？因为我认为在 GitHub Copilot 之后，这已经成为实验和学习最好的例证；它甚至被 Jordi Ribas 和他的团队在博客上分享，看到你所做的一切真是太令人惊叹了。这个过程是怎样的？

**S.T.**：这是一个神奇的经历。显然，团队在添加功能、改进体验等方面付出了极大的努力。让我分享一下背后的故事。正如我提到的，我们过去一直在训练自己的 LLM，我们坚信对话式 AI 将是旅程的下一步。甚至在 ChatGPT 或 GPT-4 出现之前，我们就已经有了自己的对话式体验，就像聊天体验一样，我们在印度和 MSIB 国家（马来西亚、新加坡、印度尼西亚和菲律宾）以隐秘模式运行。我们为此工作了几年，可以说是在 ChatGPT 出现前两年。我们一直在迭代安全机制，比如不触及有争议的话题，如何处理越狱等问题。我们已经在更小的规模上对这些事情进行了很多实验，表面面积和交互机制也有所不同。

但是，即使在那个实验中，我们也发现用户参与度很高，我记得有一场较长的对话持续了 13 或 14 个小时。用户连续与机器人交谈了 13 到 14 个小时，我不知道，可能来回有 1,800 条消息在用户和机器人之间传递，等等。实际上，那个初始实验为我们提供了一些基准，所以当我们获得 GPT-4 的访问权限时，我们已经大致规划了路径。因此，在相对较短的时间内，我认为我们大约在 2022 年 8 月或 9 月获得了 GPT-4 的访问权限，然后在 2023 年 2 月 7 日前后四到五个月内发布了它。我们发布了被称为 Bing Chat 体验的东西，现在就是微软 Copilot 体验。

这是一段精彩的旅程，有很多个深夜。实际上，团队在感恩节和假日等时候都在工作，但这是一段非常激动人心的旅程，看到它在微软的所有不同表面上普及，无论是 Word、PowerPoint、M365、Edge、Bing，还是我们的应用家族，移动应用家族，这真是太令人惊叹了。合作伙伴关系非常出色。公司像一个人一样努力传播关于 Copilot 的信念或使命到所有这些表面上。如果你退一步想，能够做这样的事情真是太神奇了。

**A.G.**: 这是真的。从现场来看，我觉得这是一种信念，即存在一种无处不在的 Copilot 概念，与所有产品相一致。即使是 Copilot 的端到端架构，这确实很新，但也很令人兴奋。我觉得最令人难以置信的事情之一就是看到 Bing Chat、Microsoft Copilot 日复一日、夜复一夜、周复一周的进步，你所分享给行业的所有学习成果，甚至包括在博客上与竞争对手的交流，我都觉得这是“金子”！所有的改进，我都能真正感受到产品上的改进。这种创新的速度我认为是难以复制的。

**S.T.**: 我要称赞那些一直非常努力工作的团队成员，他们在微软内部共同努力，朝着这个共同目标前进，提供令人愉悦且实用的体验。这不仅仅是对话。最终，我们的使命宣言是让世界上每一个人和组织都更加高效。沿着这个特定的目标，我们不仅想要闲聊的体验。我们还希望人们能够完成事情，做事情。在这个使命中，我们如何连接所有的 Copilot，添加我们添加的这些插件和 GPT 等特性？实际上，一些即将出现的事情甚至指向了任务完成等。我们正在以非常显著的方式演进产品。

**A.G.**: 是的，还有端到端 Copilot 的概念。人们问，Copilot 究竟是什么？然后有这个 Copilot、那个 Copilot，所有产品上的 Copilot。但这个端到端 Copilot 的概念远远超出了模型……它不仅仅是模型，它是编排，是与 Copilot for 365 等的结合。所有这些架构，你是如何从能力组合的角度设计出如此庞大且有趣的东西的？

**S.T.**: 是的。Copilot 的设计原则是，它真正意义上是一个 Copilot，就像飞机上的一样。如果你在与微软的任何软件进行交互，无论是 Teams、Outlook 还是其他任何地方，Copilot 都会在你身边帮助你。显然，这不会是一个静态的体验，取决于你所在的界面，所以如果你在操作系统级别，在 Windows 级别，你可能想执行系统级命令，比如打开专注模式或更改我的蓝牙设置或打开一个应用。如果你在 Outlook 中，你可能想在进行通用对话的同时总结你的电子邮件。

我们构建它的方式是，无论你在哪里使用 Copilot，你都会得到一个略有不同的体验，这取决于你所处的表面区域。这就是我们推动这个默认的 Copilot 理念的地方，它将为你提供帮助，让你能够以比独自完成更好的体验来完成你的工作或任务或你计划要做的事情。

**A.G.**: 是的，其中一个原始任务，我的意思是，主要任务是搜索。你是如何将 LLMs 与传统的搜索相结合，重新发明了互联网搜索这一概念的？你是如何得到这个想法的？我觉得这太令人震惊了。

**S.T.**: 是的，我在搜索领域工作已经有一段时间了。我们一直在思考的一个问题是，如果你把我们当作用户，无论是我自己、你，还是其他任何人。我们为什么想要搜索？搜索实际上是对技术能为我们提供的东西的一种简化，而我们作为用户或人类已经习惯了以某种特定方式使用它，比如，在搜索中，如果你查看搜索日志，你会看到很多非常像两三个词的查询。例如，你会看到“最好的小学”这样的内容。现在，这非常抽象。人们搜索的原因，或者说，可能希望通过搜索“最好的小学”这样的查询解决的问题，可能像……我有一个孩子一直在上这所预备学校，正在寻找附近且质量好的地方，或者用户可能在计划买房，他们在想是否应该在这个特定的社区买房，等等。可能会有很多更深层次的意图，但用户并没有在搜索引擎中表达出来，因为他们已经从过去的经验中学到了这一点。

在这个领域工作很长时间的人可能还记得[Ask Jeeves](https://oreil.ly/yuhNk)，它大约在 20 到 25 年前存在。使用 Ask Jeeves，你会被告知只需用长句表达自己，它就会找到信息。当时的技术并不出色，而且大多数时候当你提出像“我正在尝试买房，你能告诉我这个特定地区有哪些好的小学吗？”等问题时，它找不到信息，这就是为什么搜索引擎训练人类输入非常具体的关键词。即使你输入了这些关键词，如果你查看用户会话或我们如何互动，发生的事情是我们尝试点击搜索结果，阅读一些内容，然后点击其他东西，然后修改查询，在这个例子中，我们可能会发现存在公立学校和私立学校的选择。我们可能会决定我们应该根据它们是否负担得起来考虑这些选择，然后你迭代等等。鉴于大型语言模型变得非常强大，我们可以尝试压缩这个复杂的工作，这是我们人类将这些工作分解成非常具体的集合。让我们发出第一个查询，查看结果，然后修改它，然后询问其他事情，然后是其他事情。最终，你可能会打开地图，然后说，那个地区在哪里，房子在哪里，距离有多远，等等。

与其那样，使用大型语言模型（LLMs）和这个 Copilot 体验，你可以输入你真正想要的内容。你可以这样说，“我对这个领域不太熟悉，我正在考虑买房，我有两个孩子，我应该在这个地区哪里找好的学校？”等等。你可以表达所有这些内容。然后，作为 Copilot，模型实际上会将其分解，因为它们知道它们可以访问搜索引擎，即模型本身。现在，它会将你的复杂场景分解成更小的子组件，发出搜索查询，查看结果，再次跟进，等等，然后提供全面的视图。不是你完成所有这些任务，而是模型在帮助你完成这些任务。这就是我们的初衷，因为我们看到我们的用户在会话中挣扎，尝试很多不同的事情，迭代，做出改变，等等。无论如何，这就是 Copilot 改进搜索体验背后的故事。

**A.G.**：我想你们最初是从模型开始的，然后是编排部分，现在我们谈论 LlamaIndex、LangChain、Semantic Kernel，但[Prometheus](https://oreil.ly/Vkgtt)已经存在了。这种编排知识和结合片段、技能等的概念。

**S.T**：是的，对于那些在玩或者尝试使用 LLM（大型语言模型）构建机器人，使用像 LangChain 这样的选项的人，最初不会出现的一个挑战，但当你开始做更复杂的事情时就会出现，那就是当你有一个数据库或者一个可以通过它拉取信息的界面时，编写提示非常容易，你可以在那里添加东西。在微软的情况下，系统可以访问许多不同的复杂事物。例如，即使是 Bing，也有一个搜索索引，这是一个接口。但我们也有我们的广告引擎，我们引入了图像创建作为一项功能，我们有 GPT4-V 用于图像理解。有很多，我们实际上引入了插件的概念，如果你想要从 KAYAK 获取实时航班信息，能够访问到它。

一旦开始添加许多这些片段，如果你开始使用基于原始提示的方法，提示就会变得极其庞大，甚至模型质量也会受到影响，因为它现在必须遵循指令，一个非常长的指令集，就像人类一样，如果你给出太多的指令，你会在页面底部对顶部写了什么感到困惑。你在这里也能看到类似的行为，即模型质量可能无法完全遵循所写内容的正确意图。因此，我们必须构建一个更复杂的编排引擎，它可以进行基于状态的提示，它可以进行动态提示，这样发送给模型的提示就会小得多。其中包含了很多复杂性，以便我们能为用户提供真正令人信服的体验。

**A.G**：完全同意。这里有模型、编排，我认为这个椅子的第三条腿是用户界面。你是如何实验那种体验的，如何适应，因为用户从传统的关键词搜索到我们将要互动并理解结果的过程有一个学习过程？那个实验是怎样的？

**S.T.**：是的，目前，有一些标准界面，许多进入这个领域的公司都已经选择了这些界面。但由于我们是第一个进入市场的，我们不得不对此进行大量设计和迭代。从我们发布产品的那一天到现在，它已经经历了很多次迭代改进。我们最早做的事情之一就是在我们的搜索引擎上引入了对话界面。问题是，大多数用户甚至不知道这个产品的存在。他们如何参与呢？因为我们可能你和我对技术更熟悉，也许我们阅读了最新的新闻，但普通用户如何与这种技术互动？他们甚至怎么知道这里有这样的东西？我们做的一个非常微妙的事情是在 Bing.com 上，你可以点击图标进入 Copilot，就像你可以点击并进入一样。但如果你滚动鼠标，你可以无缝地在对话和搜索结果之间切换。所以这提供了一种非常自然的方式，我输入这个查询，大多数时候，用户会输入查询以获取搜索结果。他们得到了搜索结果，但让我只是滚动鼠标，点击几下。你进入了对话界面，你可以进行对话。

我们还做了其他一些非常微妙的事情，例如，用于问答或天气、体育等。我们有一些后续查询，这些查询我们在 Bing 搜索页面上展示。当你点击它时，你会进入聊天界面。这就是我们试图教育用户的方式，而不是通过教程或通知栏告诉他们现在可以这样做，我们采用了这些微妙的方式，现在如果你点击这个，你会看到你进入了一个对话界面，Copilot 会回答你的后续问题，然后用户就会知道，好吧，背后还有其他一些东西，更智能、更丰富的东西，然后他们可以进一步参与其中。

**A.G.**：是的，完全以产品为导向。所以人们会直接进入一个产品，并以一种有机的方式学习如何处理这种新的功能，非常聪明。因此，由于这本书是关于 Azure OpenAI 的，那么这种过渡，这种向 Microsoft Copilot 概念的演变，我们今天所生活的这个 AI 新时代……你对未来有什么愿景？在行业或即将到来的研究主题中，你认为哪些可能值得一看？

**S.T.**: 是的，我的意思是，这是一个非常重要且具有挑战性的问题。很多人认为去年是变革性的，发生了许多事情。但鉴于我们看到的趋势线，我认为，虽然很难相信，但我认为变化的速率实际上会加速而不是减缓，这是我们相信的。我知道我们已经将 Copilot 发布到许多表面，但就我们今天看到的 Copilot 而言，我相信它将很快从这些基于对话的文本界面发展到更加丰富的体验。是的，打字是一种方式，有些地方，例如，消息应用等，已经教育我们，你可以打字，你可以进行来回的对话等。我们正在遵循这种模式。但模型变得更加强大，想想真正的多模态，就像我们人类一样。

例如，当我与你交谈时，我看到这个 Microsoft Teams 窗口，我看到你的脸，我还看到你的名字写在旁边。作为一个人类，我不会进入文本模式或图像模式，比如，我只是看着你的脸，现在我准备阅读文本等。当我看着你的屏幕时，一切对我来说都非常无缝。同样，对于 Copilot 来说，我们也将开始看到一些非常自然参与的事情。人们可以说话，模型可以生成图像。他们实际上可以插入带有文本的图像，它可能会做出回应等。非常相似，它不是通过像这样的管道，这个模型被调用，然后是文本到语音等。所以这是模型可能开始以像素级别操作的相当强大的一轴。所以，而不是一个文本模型或图像模型，它只是查看像素，其中一些像素最终成为文本，一些像素最终成为图像，这是可以的。

另一件我觉得世界正走向的方向是代理的行为。意思是，现在，我之前给出了搜索的例子，你有一个非常复杂的任务，作为用户，我们通过与搜索引擎交互，将问题分解成非常小的部分，发出查询，查看结果，我们在心中是协调者，即使我们从未明确说过我们是协调者。我认为今天我们的 Copilot 也是如此，它们在某种程度上受到限制，因为它们很大程度上是关于信息收集。我们正在尝试使用我添加的 KAYAK 参考来完成一些任务。

最终，你想要做的是，在我们 Copilot 中有一个流行的例子，“你能为我安排行程吗？”如果我正在度假，随便什么，选你最喜欢的地方。比如伦敦。它会搜索，挑选各种地方，等等。它可以创建行程，也可以推荐酒店等。但最终，你想要做的是，你只想安排这次度假。因为现在，比如，我的妻子把这个任务交给我，这非常痛苦。我需要去阅读所有评论，确保酒店好，靠近我们想去的地方，等等。我必须做很多这些事情，然后去网站，搜索酒店，进行预订，等等。

我认为这并不是一个简单的过程。它需要相当多的认知负荷，以及时间和精力。但如果你仔细想想，网络上有许多这些能力。它们是为人类设计的，因为我们可以打开浏览器，我们可以点击结果，我们可以预订东西，等等。我认为这些模型的发展方向是拥有这种代理行为或类似代理的行为，你只需告诉它们，显然还需要一些用户界面等。显然，你不能完全自主地运行它。“我想去伦敦 X 天。你能帮我安排这次旅行吗？”但这里的计划意味着真正地安排这次旅行，而不仅仅是提供一个文本界面。它会去哪里，开始进行预订，寻找航班，等等。检查天气，这也是另一件事，看天气是否好。如果不好，如果某天会下雨，你可能想在那些天安排一些不同的活动，等等。能够做到这一点，即 Copilot 代表用户开始做这些类型的事情，比如打开网页，点击东西，这些都是任意的界面。我感觉这就是世界正在走向的方向。

**A.G.**：是的，我认为是这样。这甚至不是编排。它是一个多层架构，你正在执行所有这些动作，而不是我们自己作为代理去预订所有假期、酒店和旅行等，我们有一个系统，它依赖于我们今天已有的现有接口，即前端和后端。

**S.T.**：把它想象成你自己的私人助理。如果你有一个非常了解你的私人助理，显然，这就好像你要为自己雇佣一个新的私人助理一样。最初，可能就是做一些简单的事情，等等。但到了某个时候，当信任建立起来，你知道那个人可以做到这些事情，并且他们理解我的兴趣和界限等，他们就可以代表你做更多的事情。我认为这就是我觉得这些模型会走向的方向。在零天，显然，它们什么都不会做，因为人们会感到恐慌，为什么你做出了这个特定的选择或那个特定的选择？但随着事情的发展，我认为我们正在走向那个未来。

**A.G.**: 我认为如此，未来一两年我们将看到的东西非常有希望。这就是为什么我不要求你为未来五年提供愿景，因为我知道这是不可能的。看，这非常有趣，见解非常精彩。我非常高兴你能在这里分享所有这些信息。你对我们读者有什么最后的建议，以继续探索？

**S.T.**: 我认为这个领域发展非常快，就我个人而言，因为我在这领域已经工作了 9 到 10 年，我认为很多社交网站通常是有用的，比如 Twitter，如果你关注正确的一组人等等。现在，实际上，事情已经发生了很大的变化。有一些新闻简报，实际上提供了最新的信息，并且正在使用 LLM 来简化并总结很多对话，这样你就可以获得一个综合的信息集，显然，如果你对某个东西感兴趣，你可以进一步深入。我认为这些可能是更有趣的途径。

我可以再举一个例子。通常，会议用于知识传播。现在，如果你看看深度学习领域，会议主要是为了建立联系。论文可能已经在 arXiv([arXiv](https://oreil.ly/O9tW3))上放了几个月到六个月。如果它们有用，那么在会议发生之前，它们已经被讨论到不能再讨论了。甚至研究社区也已经形成了。然后我要说的是，对我们来说也是如此。我会说，只需保持处于最前沿和最新前沿。我认为在这个世界上，事情发展得非常快。

**A.G.**: 所以很快。即使是这本 Azure OpenAI 的书也发生了很大的变化，我不知道每周迭代了多少次，只是为了保持更新和添加所有信息。

**S.T.**: 也许在出版之后，你可能还需要迭代，比如一本书指向附录或类似的东西。

**A.G.**: 是的，附录，第二版，第三版……几乎每个月都有。

# 结论

本章采访的专家提供了与生成式 AI 和 LLMs 当前状态相关的独家见解（例如，为什么数据质量对 RAG 模式很重要，新的 LLMOps 趋势用于模型性能跟踪，高级用例，以及底层云原生基础设施），同时也提供了对其未来的见解。这里有两个反复出现的话题：多模态模型用于分析不同类型的信息，以及 AI 代理的演变，作为一种将步骤自动化以完成复杂任务的组合——所有这一切都不要忘记生成式 AI 系统的负责任和安全实施。

总体来说，这一章是我将第一章到第六章的所有主题汇集在一起的方式，并且与一组令人惊叹的专业人士以高度应用的方式进行了讨论。从技术构建块和架构到组织考虑因素。从 Azure OpenAI 服务到其他能够支持您云原生生成式 AI 开发的“相关部分”。

现在，我们来到了这本书的终点。超过 200 页，充满了与生成式 AI 和 Azure OpenAI 相关的解释、示例和技术主题。但当然，这只是一个开始。公司正在采用 Azure OpenAI，微软的产品团队正在努力继续演进该平台，不仅添加新的 AI 模型，还添加与企业级部署的运营化相关的产品功能。这是一场惊人的竞赛，生成式时代才刚刚开始。这本书是对全球 AI 采用者的小小贡献，以便他们从 Azure OpenAI 服务中获得最大收益。让我们继续创新。
