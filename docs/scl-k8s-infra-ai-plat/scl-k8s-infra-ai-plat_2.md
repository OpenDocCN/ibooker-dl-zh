# 第三章\. 使训练可重复

在第二章中，你学习了定制模型的技术，包括微调，这是模型训练的一个特殊情况。一旦你完成了模型的微调或首次训练，你可能会想你已经完成了模型开发，剩下的只是评估和部署模型。

你说的对了一半。但是，由于为模型提供信息的资料很可能会随时间而变化，因此模型在其整个生命周期内必须定期重新训练，以确保它能够继续提供价值。在本章中，你将深入了解人工智能模型的生命周期，学习如何跟踪模型版本、自动化模型训练以及为模型训练管道实施 GitOps。

# 重新训练和模型开发生命周期

世界在变化。我们用来描述现实世界的资料，因此也必须变化。因此，如果资料发生变化，那么任何试图模拟现实世界问题的模型也必须发生变化。

由于生产中的模型是静态的，随着时间的推移，给定模型在生产中处理推理请求的输入数据将与模型训练时的数据不同。这种变化可能来自任何数量的来源，例如用户行为随时间的变化、数据中的季节性效应、输入数据格式的变化等。这种现象被称为*数据漂移*。

数据漂移并不是重新训练模型的唯一原因。当生产中监控的指标（如准确度、模型响应性、计算资源等）超出其最佳范围时，重新训练是一个不错的选择。

模型何时以及多久应该重新训练是两个关键考虑因素，并且它们在很大程度上取决于你的用例和训练数据。这里有两种主要选择：要么定期以某种固定的时间间隔重新训练模型，要么根据需要重新训练模型。

如果时间间隔很快或者重新训练实际上没有显示出任何改进，那么以固定时间间隔重新训练模型可能会很昂贵。这种方法假设数据会根据某种可预测的模式变化，这种模式可以在选择的重新训练时间间隔内检测到。如果重新训练没有显示出任何改进，那么可能是因为数据没有以这种方式变化，以至于无法被常规时间间隔所捕获。

另一个选择是在需要时重新训练模型。这确保了模型不会被不必要地重新训练，但它需要可靠地监控当前模型版本的性能（在第四章中讨论），以及当性能足够下降时明确定义的阈值。

因此，模型的完整生命周期看起来就像图 3-1 所示。

![](img/skia_0301.png)

###### 图 3-1\. 人工智能模型的完整生命周期

在实践中，这是一个永无止境的循环，它通常从评估和监控阶段开始重复，在这些阶段通常会发现不可接受的表现。

在图 1-1 关注模型开发周期（阶段 2）时，图 3-1 则扩展到查看整个模型的生命周期。生命周期从收集数据开始，继续通过开发训练代码，执行训练作业，评估训练好的模型，将模型推广到生产，并监控所提供的服务模型。

关键的是，这个生命周期可以在任何阶段重复（除了通常保持静态的训练代码开发），最常见的是在评估和监控阶段（4 和 6）之后。从这些阶段，通常会发现要么需要再次运行训练作业，要么需要收集更多或更高质量的数据。如果需要收集更多数据，通常可以直接使用现有的训练代码。在这种情况下，阶段 3 将跟随阶段 1。

# 跟踪模型版本

当他们在开发模型时，数据科学家将通过改变用于创建模型的 dataset、模型的架构、用于训练模型的超参数等来运行许多实验。即使在将模型最初交付到生产后，模型的未来重新训练周期也会产生新的变体。

企业需要强大的解决方案来跟踪给定模型的这些版本。虽然版本控制系统几十年来一直是传统软件项目的标准，但模型版本控制系统尽管企业对模型的重度依赖，仍处于起步阶段。

模型版本跟踪对整个企业都有益处，从解锁数据科学家重现以前实验的能力，与同事分享他们的实验，以及从以前的实验中回滚到模型，到实现模型审计和确保负责任的 AI 使用。例如，为了解释给定模型的结果及其创建方式，有必要知道在什么时间生产中使用了哪个版本的模型，以及该模型是如何创建的，包括进入模型的数据源。

越来越多的企业在整个模型的生命周期中使用集中的模型注册表，这正在迅速成为一种公认的最佳实践。在模型训练和开发期间，模型训练代码应与模型注册表集成，将每个后续版本的模型作为独立的模型工件进行注册。与模型工件一起，模型训练代码还应注册有关用于创建模型的数据和代码的元数据。模型注册表还应集成在模型部署和监控阶段，这将在第四章中讨论。

今天，许多可用的训练平台将其产品组合中的模型注册表作为其产品的一部分。选择一个具有强大模型注册表且与平台分布式训练引擎良好集成的平台非常重要。

[Kubeflow 项目](https://kubeflow.org)提供了一个强大的集成解决方案，其中 Kubeflow Training Operator、Kubeflow Pipelines、[Katib](https://oreil.ly/NgK4E)和 Kubeflow Model Registry 可以一起使用，以在中央数据库中跟踪训练结果。同样，[MLflow 项目](https://mlflow.org)提供了一个健壮的模型注册表解决方案，可以与 MLflow Runs 和 Experiments 结合使用，以简化模型版本的跟踪。

今天，适当的模型版本控制往往需要数据科学家改变行为，故意将模型版本跟踪集成到他们的训练代码和工作流程中。随着像 MLflow 和 Kubeflow 这样的项目的发展并更好地与 PyTorch 等框架集成，您可以期待模型版本跟踪功能能够无缝集成。

# 自动化模型训练

训练模型就像任何其他定期重复的计算活动一样：它必须自动化。未能这样做会导致几个负面结果：

+   由于需要手动重新运行训练而浪费人力资源

+   模型重新训练时间表的不可预测性

+   模型性能的不一致性，这是由于模型训练过程中的差异（故意或意外）造成的

因此，初始模型开发不应被视为完成，直到训练过程完全自动化。一个功能齐全的自动化训练过程至少应包括以下内容：

+   输入参数指定任何通常需要调整的变量（例如，训练代码或训练数据的版本标识符，或*超参数*——定义如何进行训练的参数——对于训练作业）

+   任何必要的数据准备或预处理，以从任何存储位置收集数据并为其训练做准备

+   获取并执行训练作业

+   将模型和相关工件存储在选择的存储端点

+   在模型注册表中注册模型和相关工件

+   评估训练模型的性能

另一个很好的功能，但并非必不可少的功能是，如果模型达到某些最低性能阈值，则自动将训练好的模型推广到生产或任何其他训练后的步骤。

###### 警告

对于许多团队来说，在没有人工监督的情况下将模型推广到生产可能不合适。在评估具有此功能的工具时，请确保权衡没有人工审查训练模型指标与保持人工参与之间的权衡。

这个过程（以及实现它的软件）通常被称为“管道”或“工作流”。这些管道通常由数据科学家、数据工程师、机器学习工程师和/或 MLOps 团队编写，Python 是首选的语言。

对于已经采用 Kubernetes 作为其模型开发和部署平台的企业，我们强烈建议采用原生 Kubernetes 的管道引擎，这样就能够利用现有的 Kubernetes 基础设施，并与使用的整体 MLOps 基础设施无缝集成。

有三个主要的开源管道引擎在社区中得到了广泛的应用，应该考虑用于您的训练基础设施：

Airflow

[Airflow](https://airflow.apache.org) 通常被数据科学家所青睐，并且通常为编写管道（或按照 Airflow 的说法，为有向无环图（DAGs））提供最干净的使用体验——但是 Airflow 并非严格的原生 Kubernetes，这在将其大规模部署到 Kubernetes 上时带来了挑战。

Kubeflow Pipelines

作为更广泛 Kubeflow 项目的组成部分，[Kubeflow Pipelines](https://oreil.ly/0bP2X) 在核心上原生支持 Kubernetes，这使得它更加可定制、可扩展，非常适合拥有大型或多个数据科学团队的企业，这些企业希望共享 Kubernetes 基础设施，或者有中央 IT/MLOps 团队管理跨团队的一致基础设施。

MLflow

[MLflow](https://mlflow.org) 在模型版本跟踪方面表现出色，使得数据科学家能够轻松地随时间跟踪其模型的多个版本。然而，MLflow 需要运维团队付出更多努力，以便在 Kubernetes 上部署和扩展。

###### 小贴士

你想看看一个连续的模型训练流程在实际操作中是什么样子吗？红帽提供了一个[MLOps 实验室练习](https://oreil.ly/l04gD)，帮助你自己构建一个。

# GitOps for Model Training Pipelines

模型训练管道就像代码一样，应该相应地对待。管道定义应该存储在源代码控制中并版本化，就像传统的应用程序代码一样。并且，就像传统的应用程序代码一样，当对定义进行更改时，管道定义的作者应该遵循稳健的同行评审流程。

因此，生产训练运行应该从这些管道的干净版本中运行，这些版本是从版本控制中定义良好的版本（如分支或标签）中拉取的。这简而言之就是[GitOps](https://oreil.ly/u9oe-)。GitOps 是传统软件操作领域的一项最新发展，其中应用程序从版本控制中干净地部署，并持续进行协调，以确保部署的应用程序与版本控制中的期望状态相匹配。当团队希望更改生产中应用程序的状态时，他们通过更改版本控制中的应用程序定义来实现。

Kubernetes 部署应用的声明式方法，以及保持 Kubernetes 应用处于期望状态的协调循环，使 Kubernetes 成为使用 GitOps 管理管道的理想平台。

对于在 Kubernetes 上管理应用，最受欢迎的项目之一是[Argo CD](https://oreil.ly/2yB2U)。Argo CD 是 Kubernetes 的持续交付工具，允许用户将 GitOps 原则融入到他们的工作流程中。虽然使用 Argo CD 部署管道定义通常需要开发自定义代码将管道定义从版本控制转换为可运行的训练作业，但这是一个快速创新的领域，特别是来自 Kubeflow 项目，以允许更简单的管道定义管理。

现在你已经学会了如何可靠地重新训练模型，跟踪其版本（以及数据和训练管道的版本），并构建更健壮的开源 MLOps 基础设施，你已经准备好进入 AI 模型生命周期的下一步：部署和监控。
