- en: 5 Graph autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 图自动编码器
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Distinguishing between discriminative and generative models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分区分性和生成性模型
- en: Applying autoencoders and variational autoencoders to graphs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动编码器和变分自动编码器应用于图
- en: Building graph autoencoders with PyTorch Geometric
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch Geometric构建图自动编码器
- en: Over-squashing and graph neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过度压缩和图神经网络
- en: Link prediction and graph generation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接预测和图生成
- en: So far, we’ve covered how classical deep learning architectures can be extended
    to work on graph-structured data. In chapter 3, we considered convolutional graph
    neural networks (GNNs), which apply the convolutional operator to identify patterns
    within the data. In chapter 4, we explored the attention mechanism and how this
    can be used to improve performance for graph-learning tasks such as node classification.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了如何将经典深度学习架构扩展到图结构数据。在第3章中，我们考虑了卷积图神经网络（GNNs），它们将卷积算子应用于数据中识别模式。在第4章中，我们探讨了注意力机制以及如何将其用于改进图学习任务（如节点分类）的性能。
- en: Both convolutional GNNs and attention GNNs are examples of *discriminative*
    *models*, as they learn to discriminate between different instances of data, such
    as whether a photo is of a cat or a dog. In this chapter, we introduce the topic
    of *generative* *models* and explore them through two of the most common architectures,
    autoencoders and variational autoencoders (VAEs). Generative models aim to learn
    the entire dataspace rather than separating boundaries *within* the dataspace,
    as do discriminative models. For example, a generative model learns how to generate
    images of cats and dogs (learning to reproduce aspects of a cat or dog, rather
    than learning just the features that separates two or more classes, such as the
    pointed ears of a cat or the long ears of a spaniel).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积GNN和注意力GNN都是*区分性* *模型*的例子，因为它们学会区分不同数据实例，例如照片是猫还是狗。在本章中，我们介绍了*生成性* *模型*的主题，并通过两种最常见架构——自动编码器和变分自动编码器（VAEs）——对其进行探讨。生成性模型旨在学习整个数据空间，而不是像区分性模型那样在数据空间内分离边界。例如，生成性模型学习如何生成猫和狗的图像（学习再现猫或狗的方面，而不是仅仅学习区分两个或多个类别的特征，如猫的尖耳朵或猎犬的长耳朵）。
- en: As we’ll discover, discriminative models learn to separate boundaries in dataspace,
    whereas generative models learn to model the dataspace itself. By approximating
    the dataspace, we can sample from a generative model to create new examples of
    our training data. In the preceding example, we can use our generative model to
    make new images of a cat or dog, or even some hybrid version that has features
    of both. This is a very powerful tool and important knowledge for both beginner
    and established data scientists. In recent years, deep generative models, generative
    models that use artificial neural networks, have shown amazing ability in many
    language and vision tasks. For example, the family of DALL-E models are able to
    generate new images from text prompts while models such as OpenAI’s GPT models
    have dramatically changed the capabilities of chatbots.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将发现，区分性模型学会在数据空间中分离边界，而生成性模型学会对数据空间本身进行建模。通过近似数据空间，我们可以从生成性模型中采样以创建训练数据的新的示例。在先前的例子中，我们可以使用我们的生成性模型来制作新的猫或狗的图像，甚至是一些具有两者特征的混合版本。这是一个非常强大的工具，对于初学者和资深数据科学家来说都是重要的知识。近年来，深度生成模型，即使用人工神经网络的生成模型，在许多语言和视觉任务上显示出惊人的能力。例如，DALL-E模型系列能够根据文本提示生成新的图像，而像OpenAI的GPT模型这样的模型已经极大地改变了聊天机器人的能力。
- en: In this chapter, you’ll learn how to extend generative architectures to act
    on graph-structured data, leading to graph autoencoders (GAEs) and variational
    graph autoencoders (VGAEs). These models are distinct from previous chapters,
    which focused on discriminative models. As we’ll see, generative models model
    the entire dataspace and can be combined with discriminative models for downstream
    machine learning tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何扩展生成式架构以作用于图结构数据，从而产生图自动编码器（GAEs）和变分图自动编码器（VGAEs）。这些模型与之前章节中的区分性模型不同。正如我们将看到的，生成式模型对整个数据空间进行建模，并且可以与区分性模型结合用于下游机器学习任务。
- en: To demonstrate the power of generative approaches to learning tasks, we return
    to the Amazon Product Co-Purchaser Network introduced in chapter 3\. However,
    in chapter 3, you learned how to predict what category an item might belong to
    given its position in the network. In this chapter, we’ll show how to predict
    where an item should be placed in the network, given its description. This is
    known as *edge* (or link) *prediction* and comes up frequently, for example, when
    designing recommendation systems. We’ll put our understanding of GAEs to work
    here to perform edge prediction, building a model that can predict when nodes
    in a graph are connected. We’ll also discuss the problems of over-squashing, a
    specific consideration for GNNs, and how we can apply a GNN to generate potential
    chemical graphs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示生成式方法在学习任务中的强大能力，我们回到第3章中介绍的亚马逊产品共同购买网络。然而，在第3章中，你学习了如何根据物品在网络中的位置预测其可能属于的类别。在本章中，我们将展示如何根据物品的描述预测其在网络中的位置。这被称为*边缘*（或链接）*预测*，在例如设计推荐系统时经常出现。我们将运用对GAEs的理解来进行边缘预测，构建一个可以预测图中节点何时连接的模型。我们还将讨论过度压缩的问题，这是GNNs的一个特定考虑因素，以及我们如何将GNN应用于生成潜在的化学图。
- en: By the end of this chapter, you should know the basics of when and where to
    use generative models of graphs (rather than discriminative ones) and how to implement
    them when we need to.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该了解何时何地使用图生成模型（而不是判别模型）的基本知识，以及当我们需要时如何实现它们。
- en: NOTE  Code from this chapter can be found in notebook form at the GitHub repository
    ([https://mng.bz/4aGQ](https://mng.bz/4aGQ)). Colab links and data from this chapter
    can be accessed in the same location.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章的代码以笔记本形式存储在GitHub仓库中（[https://mng.bz/4aGQ](https://mng.bz/4aGQ)）。本章的Colab链接和数据可以在同一位置访问。
- en: '5.1 Generative models: Learning how to generate'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 生成模型：学习如何生成
- en: A classic example of deep learning is, given a set of labeled images, how to
    train models to *learn* what label to give to new and unseen images. If we consider
    the example of a set of images of boats and airplanes, we want our model to distinguish
    between these different images. If we then pass the model a new image, we want
    our model to correctly identify this as, for example, a boat. Discriminative models
    learn to discriminate between classes based on their specific target labels. Both
    convolutional architectures (discussed in chapter 3) and attention-based architectures
    (covered in chapter 4) are typically used to create discriminative models. However,
    as we’ll see, they can also be incorporated into generative models. To understand
    this, we first have to understand the difference between discriminative and generative
    modeling approaches.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的经典例子是，给定一组标记图像，如何训练模型来*学习*为新的和未见过的图像分配什么标签。如果我们考虑一组船只和飞机的图像，我们希望我们的模型能够区分这些不同的图像。如果我们随后向模型传递一个新图像，我们希望我们的模型能够正确地将其识别为，例如，一艘船。判别模型通过学习基于其特定目标标签来区分类别。通常使用卷积架构（在第3章中讨论）和基于注意力的架构（在第4章中介绍）来创建判别模型。然而，正如我们将看到的，它们也可以被纳入生成模型。为了理解这一点，我们首先必须了解判别和生成建模方法之间的区别。
- en: 5.1.1 Generative and discriminative models
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 生成模型和判别模型
- en: As described in previous chapters, the original dataset that we use to train
    a model is referred to as our *training data,* and the labels that we seek to
    predict are our *training targets*. The unseen data is our *test data*, and we
    want to learn the *target labels* (from training) to classify the test data. Another
    way to describe this is using conditional probability. We want our models to return
    the probability of some target, Y, given an instance of data, X. We can write
    this as P(Y|X), where the vertical bar means that Y is “conditioned” on X.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所述，我们用来训练模型的原始数据集被称为我们的*训练数据*，我们试图预测的标签被称为我们的*训练目标*。未见过的数据是我们的*测试数据*，我们希望学习*目标标签*（从训练中）以对测试数据进行分类。另一种描述方式是使用条件概率。我们希望我们的模型返回给定数据实例X时某些目标Y的概率。我们可以将其写为P(Y|X)，其中竖线表示Y是“条件”于X的。
- en: As we’ve said, discriminative models learn to discriminate *between* classes.
    This is equivalent to learning the separating boundaries of the data in the dataspace.
    In contrast, generative models learn to model the dataspace itself. They capture
    the entire distribution of data in the dataspace, and, when presented with a new
    example, they tell us how likely the new example is. Using the language of probability,
    we say that they model the *joint probability* between data and targets, P(X,Y).
    A typical example of a generative model might be a model that is used to predict
    the next word in a sentence (e.g., the autocomplete feature in many modern mobile
    phones). The generative model assigns a probability to each possible next word
    and returns those words that have the highest probability. Discriminative models
    can tell you how likely a word has some specific sentiment, while a generative
    model will suggest a word to use.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说的，判别性模型学习区分**之间**的类别。这相当于在数据空间中学习数据的分离边界。相比之下，生成性模型学习建模数据空间本身。它们捕捉数据空间中数据的整个分布，并且当面对一个新的示例时，它们会告诉我们新示例的可能性有多大。使用概率语言，我们说它们建模了数据与目标之间的**联合概率**，P(X,Y)。一个典型的生成性模型可能是一个用于预测句子中下一个单词的模型（例如，许多现代智能手机中的自动完成功能）。生成性模型为每个可能的下一个单词分配一个概率，并返回那些概率最高的单词。判别性模型可以告诉你一个单词具有某种特定情感的可能性有多大，而生成性模型将建议使用哪个单词。
- en: Returning to our image example, a generative model approximates the overall
    distribution of images. This can be seen in figure 5.1, where the generative model
    has learned where the points are positioned in the dataspace (rather than how
    they are separated). This means that generative models must learn more complicated
    correlations in the data than their discriminative counterparts. For example,
    a generative model learns that “airplanes have wings” and “boats appear near water.”
    On the other hand, discriminative models just have to learn the difference between
    “boat” and “not boat.” They can do this by looking for telltale signs such as
    a mast, keel, or boom in the image. They can then largely ignore the rest of the
    image. As a result, generative models can be more computationally expensive to
    train and can require larger network architectures. (In section 5.5, we’ll describe
    over-squashing, which is a particular problem for large GNNs.)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的图像示例，生成性模型近似图像的整体分布。这可以在图5.1中看到，其中生成性模型已经学会了数据空间中点的位置（而不是它们是如何被区分的）。这意味着生成性模型必须比它们的判别性对应物学习数据中的更复杂的相关性。例如，生成性模型学习到“飞机有翅膀”和“船只出现在水中”。另一方面，判别性模型只需要学习“船”与“非船”之间的区别。它们可以通过寻找图像中的明显标志，如桅杆、龙骨或吊杆来实现。然后它们可以很大程度上忽略图像的其余部分。因此，生成性模型在训练时可能更耗费计算资源，可能需要更大的网络架构。（在第5.5节中，我们将描述过度压缩问题，这是大型GNN的一个特定问题。）
- en: '![figure](../Images/5-1.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-1.png)'
- en: Figure 5.1 Comparison of generative and discriminative tasks. On the left, the
    discriminative model learns to separate different images of boats and airplanes.
    On the right, the generative model attempts to learn the entire dataspace, which
    allows for new synthetic examples to be created such as a boat in the sky or an
    airplane on water.
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 生成性任务与判别性任务的比较。在左侧，判别性模型学习区分不同类型的船只和飞机图像。在右侧，生成性模型试图学习整个数据空间，这允许创建新的合成示例，例如天空中的船只或水上的飞机。
- en: 5.1.2 Synthetic data
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 合成数据
- en: Given that discriminative models are computationally cheaper to train and more
    robust to outliers than generative models, you might wonder why we want to use
    a generative model at all. Generative models, however, are efficient tools when
    labeling data is relatively expensive but generating datasets is easy to do. For
    example, generative models are increasingly being used in drug discovery where
    they generate new candidate drugs that might match certain properties, such as
    the ability to reduce the effects of some disease. In a sense, generative models
    attempt to learn how to create synthetic data, which allows us to create new data
    instances. For example, none of the people shown in figure 5.2 exist and were
    instead created by sampling from the dataspace, approximated using a generative
    model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于判别模型在训练上比生成模型计算成本更低，且对异常值更鲁棒，你可能会 wonder 为什么我们还要使用生成模型。然而，生成模型在数据标注相对昂贵但生成数据集相对容易的情况下是有效的工具。例如，生成模型在药物发现中越来越受欢迎，它们可以生成可能具有某些特性的新候选药物，例如减少某些疾病的影响的能力。从某种意义上说，生成模型试图学习如何创建合成数据，这使我们能够创建新的数据实例。例如，图5.2中显示的任何人都不存在，而是通过从数据空间中采样（使用生成模型近似）来创建的。
- en: '![figure](../Images/5-2.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-2.png)'
- en: 'Figure 5.2 Figure showing synthetic faces (Source: [1])'
  id: totrans-25
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 显示合成面孔的图（来源：[1]）
- en: Synthetic examples created by generative models can be used to augment a dataset,
    which is expensive to collect. Rather than taking lots of pictures of faces under
    every condition, we can use generative models to create new data examples (e.g.,
    a person wearing a hat, glasses, and a mask) to increase our dataset to contain
    tricky edge cases. These synthetic examples can then be used to further improve
    our other models (e.g., one that identifies when someone is wearing a mask). However,
    when introducing synthetic data, we must also be careful about introducing other
    biases or noise into our dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型创建的合成示例可以用来增强一个昂贵的数据集。我们不需要在每种条件下拍摄很多面部照片，而是可以使用生成模型创建新的数据示例（例如，一个人戴着帽子、眼镜和口罩），以增加我们的数据集，使其包含棘手的边缘情况。然后，这些合成示例可以用来进一步改进我们的其他模型（例如，一个识别某人是否戴着口罩的模型）。然而，在引入合成数据时，我们必须小心不要将其他偏差或噪声引入我们的数据集中。
- en: In addition, discriminative models are often used downstream of generative models.
    This is because generative models are typically trained in a “self-supervised”
    way, without relying on data labels. They learn to compress (or *encode)* complex
    high-dimensional data to lower dimensions. These low-dimensional representations
    can be used to better tease out underlying patterns within our data. This is known
    as *dimension reduction* and can be helpful in clustering data or in classification
    tasks. Later, we’ll see how generative models can separate graphs into different
    classes without ever seeing their labels. In cases where annotating each data
    point is expensive, generative models can be huge cost savers. Let’s get on to
    meeting our first generative GNN model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，判别模型通常用于生成模型之后。这是因为生成模型通常以“自监督”的方式进行训练，不依赖于数据标签。它们学习将复杂的高维数据压缩（或*编码*）到低维。这些低维表示可以用来更好地揭示我们数据中的潜在模式。这被称为*降维*，有助于数据聚类或分类任务。稍后，我们将看到生成模型如何在不看到其标签的情况下将图分离成不同的类别。在标注每个数据点成本高昂的情况下，生成模型可以节省大量成本。让我们继续了解我们的第一个生成GNN模型。
- en: 5.2 Graph autoencoders for link prediction
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 用于链接预测的图自动编码器
- en: One of the fundamental and popular models for deep generative models is the
    autoencoder. The reason the autoencoder framework is so widely used is because
    it’s incredibly adaptive. Just as the attention mechanisms in chapter 3 can be
    used to improve on many different models, autoencoders can be combined with many
    different models, including different types of GNNs. Once the autoencoder structure
    is understood, the encoder and decoder can be replaced with any type of neural
    network, including different GNNs such as the graph convolutional network (GCN)
    and GraphSAGE architectures from chapter 2\.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度生成模型的一个基本且流行的模型是自动编码器。自动编码器框架之所以被广泛使用，是因为它具有极高的适应性。正如第3章中提到的注意力机制可以用于改进许多不同的模型一样，自动编码器可以与许多不同的模型结合，包括不同类型的GNN。一旦理解了自动编码器的结构，编码器和解码器可以用任何类型的神经网络替换，包括第2章中提到的不同类型的GNN，如图卷积网络（GCN）和GraphSAGE架构。
- en: 'However, we need to take care when applying autoencoders to graph-based data.
    When reconstructing our data, we also have to reconstruct our adjacency matrix.
    In this section, we’ll look at implementing a GAE using the Amazon Products dataset
    from chapter 3 [2]. We’ll build a GAE for the task of link prediction, which is
    a common problem when working with graphs. This allows us to reconstruct the adjacency
    matrix and is especially useful when we’re dealing with a dataset that has missing
    data. We’ll follow this process:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在将自动编码器应用于基于图的数据时，我们需要小心。在重建我们的数据时，我们也必须重建我们的邻接矩阵。在本节中，我们将探讨使用第三章中的亚马逊产品数据集实现GAE的方法[2]。我们将构建一个用于链接预测任务的GAE，这是处理图时常见的问题。这允许我们重建邻接矩阵，并且在我们处理有缺失数据的数据集时特别有用。我们将遵循以下过程：
- en: 'Define the model:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型：
- en: Create both an encoder and decoder.
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个编码器和解码器。
- en: Use the encoder to create a latent space to sample from.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用编码器创建一个潜在空间进行采样。
- en: Define the training and testing loop by including a loss suitable for constructing
    a generative model.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义训练和测试循环，包括适合构建生成模型的损失函数。
- en: Prepare the data as a graph, with edge lists and node features.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据准备为图，包括边列表和节点特征。
- en: Train the model, passing the edge data to compute the loss.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型，传递边数据以计算损失。
- en: Test the model using the test dataset.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试数据集测试模型。
- en: 5.2.1 Review of the Amazon Products dataset from chapter 3
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 对第三章中亚马逊产品数据集的回顾
- en: In chapter 3, we learned about the Amazon Products dataset with co-purchaser
    information. This dataset contains information about a range of different items
    that were purchased, details about who purchased them and how, and categories
    for the items, which were the labels in chapter 3\. We’ve already learned about
    how we can turn this tabular dataset into a graph structure and, by doing so,
    make our learning algorithms more efficient and more powerful. We’ve also already
    used some dimension reduction without realizing it. Principal component analysis
    (PCA) was applied to the Amazon Products dataset to create the features. Each
    product description was converted into numerical values using the bag-of-words
    algorithm, and PCA is then applied to reduce the (now numerical) description to
    100 features.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三章中，我们学习了带有共同购买者信息的亚马逊产品数据集。这个数据集包含了关于一系列不同物品的购买信息，包括谁购买了它们以及如何购买，以及物品的分类，这些分类在第三章中作为标签。我们已经学习了如何将这个表格数据集转换为图结构，通过这样做，可以使我们的学习算法更加高效和强大。我们还已经在不经意间使用了一些降维技术。主成分分析（PCA）被应用于亚马逊产品数据集以创建特征。每个产品描述都被使用词袋算法转换为数值，然后PCA被应用于将（现在已经是数值的）描述减少到100个特征。
- en: In this chapter, we’re going to revisit the Amazon Products dataset but with
    a different aim in mind. We’re going to use our dataset to learn link predictions.
    Essentially, this means learning the *relations between* nodes in our graph. This
    has many use cases, such as predicting what movies or TV shows users would like
    to watch next, suggesting new connections on social media platforms, or even predicting
    customers who are more likely to default on credit. Here, we’re going to use it
    to predict which products in the Amazon Electronics dataset should be connected
    together, as we show in figure 5.3\. For further details about link prediction,
    check out section 5.5 at the end of this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重新审视亚马逊产品数据集，但目的是不同的。我们将使用我们的数据集来学习链接预测。本质上，这意味着学习我们图中的节点之间的*关系*。这有许多用例，例如预测用户接下来想看哪些电影或电视节目，在社交媒体平台上建议新的连接，甚至预测更有可能违约的客户。在这里，我们将用它来预测亚马逊电子产品数据集中哪些产品应该连接在一起，如图5.3所示。有关链接预测的更多详细信息，请参阅本章末尾的5.5节。
- en: '![figure](../Images/5-3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-3.png)'
- en: Figure 5.3 The Amazon Electronics dataset, where different products such as
    cameras and lenses are connected based on whether they have been bought together
    in the past
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 亚马逊电子产品数据集，其中不同的产品，如相机和镜头，根据它们是否曾经一起购买而相互连接
- en: As with all data science projects, it’s worth first taking a look at the dataset
    and understanding what the problem is. We start by loading the data, the same
    way as we did in chapter 3, which we show in listing 5.1\. The data is preprocessed
    and labeled so it can be loaded using NumPy. Further details on the dataset can
    be found in [2].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有数据科学项目一样，首先查看数据集并理解问题所在是值得的。我们首先加载数据，就像我们在第 3 章中所做的那样，这将在列表 5.1 中展示。数据已预处理并标记，因此可以使用
    NumPy 加载。有关数据集的更多详细信息，请参阅[2]。
- en: Listing 5.1 Loading the data
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.1 加载数据
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding output prints the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出打印以下内容：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With the data loaded, we can next look at some basic statistics and details
    of the data. We’re interested in edge or link prediction, so it’s worth understanding
    how many different edges exist. We might also want to know how many components
    there are and the average degree to understand how connected our graph is. We
    show the code to calculate this in the following listing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载完成后，我们可以查看一些基本统计数据和数据细节。我们感兴趣的是边缘或链接预测，因此了解存在多少不同的边缘是很有价值的。我们可能还想了解有多少个组件以及平均度，以了解我们的图有多连通。我们将在下面的列表中展示计算这些值的代码。
- en: Listing 5.2 Exploratory data analysis
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.2 探索性数据分析
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 This is only possible because the adjacency matrix is undirected.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 这只因为邻接矩阵是无向的。'
- en: '#2 Ratio of actual edges to possible edges'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 实际边与可能边的比率'
- en: We also plot the distribution of the degree to see how connections vary, as
    shown in the following listing and in figure 5.4\.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还绘制了度数的分布，以查看连接如何变化，如以下列表和图 5.4 所示。
- en: Listing 5.3 Plotting the graph
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.3 绘制图形
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 Gets row indices for each nonzero value'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 获取每个非零值对应的行索引'
- en: We find that there are 7,650 nodes, more than 143,000 edges, and an overall
    density of 0.0049\. Therefore, our graph is medium size (~10,000 nodes) but very
    sparse (density much less than 0.05). We see that the majority of nodes have a
    low degree (less than 10), but that there is a second peak of edges with a higher
    degree (around 30) and a longer tail. In total, we see very few nodes with a high
    degree, which we would expect given the low density of the graph.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现共有 7,650 个节点，超过 143,000 条边，整体密度为 0.0049。因此，我们的图是中等大小（约 10,000 个节点），但非常稀疏（密度远小于
    0.05）。我们看到大多数节点的度数较低（小于 10），但还存在一个度数较高的边的高峰（约 30）和更长的尾部。总的来说，我们看到高度数的节点非常少，这在低密度的图中是预期的。
- en: '![figure](../Images/5-4.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-4.png)'
- en: Figure 5.4 Degree distribution for the Amazon Electronics co-purchaser graph
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.4 亚马逊电子产品共同购买者图的度分布
- en: 5.2.2 Defining a graph autoencoder
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 定义图自动编码器
- en: Next, we’ll use a generative model, the autoencoder, to estimate and predict
    links in the Amazon Electronics dataset. In doing so, we’re in good company, as
    link prediction was the problem that GAEs were applied to when first published
    by Kipf and Welling in 2012 [3]. In their seminal paper, they introduced the GAE
    and its variational extension, which we’ll be discussing shortly, and then applied
    these models to three classic benchmarks in graph deep learning, the Cora dataset,
    CiteSeer, and PubMed. Today, most graph deep learning libraries make it very easy
    to create and begin training GAEs, as these have become one of the most popular
    graph-based deep generative models. We’ll look at the steps required to build
    one in more detail in this section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用生成模型，即自动编码器，来估计和预测亚马逊电子产品数据集中的链接。这样做是有先例的，因为链接预测是 Kipf 和 Welling 在
    2012 年首次发布 GAE 时应用的问题[3]。在他们开创性的论文中，他们介绍了 GAE 及其变分扩展，我们将在稍后讨论这些内容，并将这些模型应用于图深度学习的三个经典基准，即
    Cora 数据集、CiteSeer 和 PubMed。如今，大多数图深度学习库都使得创建和开始训练 GAE 非常容易，因为它们已经成为最受欢迎的基于图的深度生成模型之一。我们将在本节中更详细地查看构建一个
    GAE 所需的步骤。
- en: The GAE model is similar to a typical autoencoder. The only difference is that
    each individual layer of our network is a GNN, such as a GCN or GraphSAGE network.
    In figure 5.5, we show a schematic for a GAE’s architecture. Broadly, we’ll be
    taking our edge data and compressing it into a low-dimensional representation
    using an encoder network.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: GAE 模型类似于典型的自动编码器。唯一的区别是，我们网络中的每一层都是一个 GNN，例如 GCN 或 GraphSAGE 网络。在图 5.5 中，我们展示了
    GAE 架构的示意图。总的来说，我们将使用编码器网络将我们的边缘数据压缩成低维表示。
- en: '![figure](../Images/5-5.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-5.png)'
- en: Figure 5.5 Schematic for the GAE showing the key elements of the model, such
    as the encoder, latent space, and decoder
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.5 GAE 的示意图，展示了模型的关键元素，如编码器、潜在空间和解码器
- en: The first thing we need to define for our GAE is the encoder, which will take
    our data and transform it into a latent representation. The code snippet for implementing
    the encoder is given in listing 5.4\. We first import our libraries and then build
    a GNN where each layer is progressively smaller.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 GAE，我们需要定义的第一个东西是编码器，它将我们的数据转换成潜在表示。实现编码器的代码片段在列表 5.4 中给出。我们首先导入我们的库，然后构建一个
    GNN，其中每一层都逐渐变小。
- en: Listing 5.4 Graph encoder
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.4 图编码器
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Loads GCNConv models from PyG'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从 PyG 加载 GCNConv 模型'
- en: '#2 Defines the encoder layer and initializes it with a predefined size'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义编码器层并使用预定义的大小初始化它'
- en: '#3 Defines each of the encoder layer networks'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 定义编码器每一层的网络'
- en: '#4 Forward pass for the encoder with edge data'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用边缘数据的编码器前向传递'
- en: Note that we also have to make sure that our forward pass can return the edge
    data from our graph because we’ll be using our autoencoder to reconstruct the
    graph from the latent space. To put this another way, the autoencoder will be
    learning how to reconstruct the adjacency matrix from a low-dimensional representation
    of our feature space. This means it’s also learning to predict edges from new
    data. To do this, we need to make the autoencoder structure learn to reconstruct
    edges, specifically by changing the decoder. Here, we’ll use the inner product
    to predict edges from the latent space. This is shown in listing 5.5\. (To understand
    why we use the inner product, see the technical details in section 5.5.)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们还需要确保我们的前向传递可以从我们的图中返回边缘数据，因为我们将使用我们的自动编码器从潜在空间重建图。换句话说，自动编码器将学习如何从特征空间的一个低维表示中重建邻接矩阵。这意味着它也在学习如何从新数据中预测边缘。为了做到这一点，我们需要让自动编码器结构学习重建边缘，特别是通过改变解码器。在这里，我们将使用内积从潜在空间预测边缘。这如列表
    5.5 中所示。（要了解为什么我们使用内积，请参阅第 5.5 节的技术细节。）
- en: Listing 5.5 Graph decoder
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.5 图解码器
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Defines the decoder layer'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义解码器层'
- en: '#2 States the shape and size of the decoder (which, again, is the reverse of
    the encoder)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 说明解码器的形状和大小（这再次是编码器的反转）'
- en: '#3 Forward pass for the decoder'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 解码器的前向传递'
- en: Now we’re ready to combine both encoder and decoder together in the GAE class,
    which contains both submodels (see listing 5.6). Note that we don’t initialize
    the decoder with any input or output sizes now as this is just applying the inner
    product to the output of our encoder with the edge data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好在 GAE 类中将编码器和解码器结合起来，该类包含两个子模型（见列表 5.6）。请注意，我们现在没有用任何输入或输出大小初始化解码器，因为这只是在将编码器的输出与边缘数据应用内积。
- en: Listing 5.6 Graph autoencoder
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.6 图自动编码器
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Defines the encoder for the GAE'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义 GAE 的编码器'
- en: '#2 Defines the decoder'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义解码器'
- en: In PyTorch Geometric (PyG), the GAE model can be made even easier by just importing
    the GAE class, which automatically builds both decoder and autoencoder once passed
    to the encoder. We’ll use this functionality when we build a VGAE later in the
    chapter.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch Geometric (PyG) 中，通过仅导入 GAE 类，GAE 模型可以变得更加简单，该类在传递给编码器后自动构建解码器和自动编码器。当我们在本章后面构建
    VGAE 时，我们将使用此功能。
- en: 5.2.3 Training a graph autoencoder to perform link prediction
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 训练图自动编码器进行链接预测
- en: Having built our GAE, we can proceed to use this to perform edge prediction
    for the sub models Amazon Products dataset. The overall framework will follow
    a typical deep learning problem format, where we first load the data, prepare
    the data, and split this data into train, test, and validation datasets; define
    our training parameters; and then train and test our model. These steps are shown
    in figure 5.6\.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建了我们的 GAE 之后，我们可以继续使用它来对 Amazon Products 数据集的子模型进行边缘预测。整体框架将遵循典型的深度学习问题格式，我们首先加载数据，准备数据，并将这些数据分成训练、测试和验证数据集；定义我们的训练参数；然后训练和测试我们的模型。这些步骤在图
    5.6 中显示。
- en: '![figure](../Images/5-6.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-6.png)'
- en: Figure 5.6 Overall steps for training our model for link prediction
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.6 训练我们的模型进行链接预测的总体步骤
- en: We begin by loading the dataset and preparing it for our learning algorithms,
    which we’ve already done in listing 5.1\. For us to use the PyG models for GAE
    and VGAE, we need to construct an edge index from the adjacency matrix, which
    is easily done using one of PyG’s utility functions, `to_edge_index`, as we describe
    in the following listing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载数据集并为其学习算法做准备，这已经在列表 5.1 中完成。为了使用 PyG 模型进行 GAE 和 VGAE，我们需要从邻接矩阵中构建一个边缘索引，这可以通过使用
    PyG 的一个实用函数 `to_edge_index` 轻松完成，正如我们在以下列表中描述的那样。
- en: Listing 5.7 Construct Edge Index
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.7 构建边索引
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Loads the to_edge_index from the PyG utility libraries'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从PyG实用库中加载to_edge_index'
- en: '#2 Converts the adjacency matrix to an edge index and edge attribute vector'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将邻接矩阵转换为边索引和边属性向量'
- en: We then load the PyG libraries and convert our data into a PyG data object.
    We can also apply transformations to our dataset, where the features and adjacency
    matrix are loaded as in chapter 3\. First, we normalize our features and then
    split our dataset into training, testing, and validation sets based on the edges
    or links of the graph, as shown in listing 5.8\. This is a vital step when carrying
    out link prediction to ensure we correctly split our data. In the code, we’ve
    used 5% of the data for validation and 10% for test data, noting that our graph
    is undirected. Here, we don’t add any negative training samples.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们加载PyG库并将我们的数据转换为PyG数据对象。我们还可以对我们的数据集应用转换，其中特征和邻接矩阵的加载方式与第3章中描述的相同。首先，我们对特征进行归一化，然后根据图的边或链接将我们的数据集划分为训练集、测试集和验证集，如列表5.8所示。这是进行链接预测时的一个关键步骤，以确保我们正确地分割了数据。在代码中，我们使用了5%的数据用于验证，10%的数据用于测试数据，注意我们的图是无向的。在这里，我们没有添加任何负样本训练数据。
- en: Listing 5.8 Convert to a PyG object
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.8 转换为PyG对象
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Converts our data to a PyG data object'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将我们的数据转换为PyG数据对象'
- en: '#2 Transforms our data and splits the links into train, test, and validation
    sets'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对我们的数据进行转换并将链接划分为训练、测试和验证集'
- en: With everything in place, we can now apply GAE to the Amazon Products dataset.
    First, we define our model, as well as our optimizer and our loss. We apply the
    binary cross-entropy loss to the predicted values from the decoder and compare
    against our true edge index to see whether our model has reconstructed the adjacency
    matrix correctly, as shown in the following listing.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪后，我们现在可以将GAE应用于Amazon Products数据集。首先，我们定义我们的模型、优化器和损失函数。我们将二元交叉熵损失应用于解码器的预测值，并将其与我们的真实边索引进行比较，以查看我们的模型是否正确地重建了邻接矩阵，如以下列表所示。
- en: Listing 5.9 Define the model
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.9 定义模型
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Specifies the shape of our encoder'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 指定编码器的形状'
- en: '#2 Defines a GAE with the correct shape'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义具有正确形状的GAE'
- en: '#3 Our loss now is binary cross-entropy.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 我们现在的损失是二元交叉熵。'
- en: It’s important to use a binary cross-entropy loss because we want to calculate
    the probabilities that each edge is a true edge, where true edges correspond to
    the ones that aren’t being hidden and don’t need to be predicted (i.e., the positive
    samples). The encoder learns to compress the edge data but doesn’t change the
    number of edges, whereas the decoder learns to predict edges. In a sense, we’re
    combining both the discriminative and generative steps here. Therefore, the binary
    cross-entropy gives us a probability where there is likely to be an edge between
    these nodes. It’s binary, as either an edge should exist (label 1) or shouldn’t
    (label 0). We can compare all of those edges that have a binary cross-entropy
    probability greater than 0.5 to the actual true edges in each epoch of our training
    loop, as shown in the following listing.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二元交叉熵损失是很重要的，因为我们想计算每个边是真实边的概率，其中真实边对应于未被隐藏且不需要预测的边（即正样本）。编码器学习压缩边数据但不会改变边的数量，而解码器学习预测边。从某种意义上说，我们在这里结合了判别性和生成性步骤。因此，二元交叉熵给出了在这些节点之间可能存在边的概率。它是二元的，因为边要么应该存在（标签1），要么不应该存在（标签0）。我们可以将所有二元交叉熵概率大于0.5的边与训练循环每个epoch中的实际真实边进行比较，如以下列表所示。
- en: Listing 5.10 Training function
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.10 训练函数
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Encodes graph into latent representation'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将图编码为潜在表示'
- en: '#2 Performs a new round of negative sampling'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 执行新一轮的负采样'
- en: '#3 Combines new negative samples with the edge label index'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将新的负样本与边标签索引结合'
- en: '#4 Generates edge predictions'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 生成边预测'
- en: '#5 Combines edge labels with 0s for negative samples'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将边标签与0s结合用于负样本'
- en: '#6 Computes loss and backpropagates'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 计算损失并进行反向传播'
- en: Here, we first encoded our graph into a latent representation. We then perform
    a round of negative sampling, with new samples drawn for each epoch. Negative
    sampling takes a random subset of nonexistent labels rather than existing positive
    ones during training to account for the class imbalance between real labels and
    nonexistent ones. Once we have these new negative samples, we concatenate them
    with our original edge labels index and pass these to our decoder to get a reconstructed
    graph. Finally, we concatenate our true edge labels with the 0 labels for our
    negative edges and compute the loss between our predicted edges and our true edges.
    Note that we’re not doing batch learning here; instead, we’re choosing to train
    on all data during each epoch.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先将我们的图编码成潜在表示。然后我们进行一轮负采样，为每个epoch抽取新的样本。负采样在训练期间取一个随机子集的非存在标签，而不是现有的正标签，以解决真实标签和非存在标签之间的类别不平衡。一旦我们有了这些新的负样本，我们将它们与我们的原始边缘标签索引连接起来，并将这些传递给我们的解码器以获得一个重构的图。最后，我们将我们的真实边缘标签与负边缘的
    0 标签连接起来，并计算预测边缘和真实边缘之间的损失。请注意，我们在这里不是进行批量学习；相反，我们选择在每个epoch期间在整个数据上训练。
- en: Our test function, shown in listing 5.11, is much simpler than our training
    function as it doesn’t have to perform any negative sampling. Instead, we just
    use the true and predicted edges and return a Receiver Operating Characteristic
    (ROC)/Area Under the Curve (AUC) score to measure the accuracy of our model. Recall
    that the ROC/AUC curves will range between 0 and 1, and a perfect model, whose
    predictions are 100% correct, will have an AUC of 1.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在列表 5.11 中展示的测试函数比我们的训练函数简单得多，因为它不需要执行任何负采样。相反，我们只需使用真实和预测的边缘，并返回一个接收者操作特征（ROC）/曲线下面积（AUC）分数来衡量我们模型的准确率。回想一下，ROC/AUC
    曲线将在 0 和 1 之间变化，一个完美的模型，其预测100%正确，将有一个 AUC 为 1。
- en: Listing 5.11 Test function
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.11 测试函数
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Encodes the graph into a latent representation'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将图编码成潜在表示'
- en: '#2 Decodes the graph using the full edge label index'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用完整的边缘标签索引解码图'
- en: '#3 Calculates the overall ROC/AUC score'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算整体 ROC/AUC 分数'
- en: At each time step, we’ll calculate the overall success of a model using all
    our edge data from our validation data. After training is complete, we then use
    the test data to calculate the final test accuracy, as shown in the following
    listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间步，我们将使用我们验证数据中的所有边缘数据来计算一个模型的整体成功率。训练完成后，我们使用测试数据来计算最终的测试准确率，如下所示。
- en: Listing 5.12 Training loop
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.12 训练循环
- en: '[PRE12]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Performs a training step'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 执行训练步骤'
- en: '#2 Tests our updated model on validation data'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 在验证数据上测试我们的更新模型'
- en: '#3 Tests our final model on test data'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 在测试数据上测试我们的最终模型'
- en: We find that after 200 epochs, we achieve an accuracy of more than 83%. Even
    better, when we then use our test set to see how well our model is able to predict
    edges, we get an accuracy of 86%. We can interpret our model performance as being
    able to suggest a meaningful item to the purchaser 86% of the time, assuming that
    all future data is the same as our current dataset. This is a great result and
    demonstrates how useful GNNs are for recommender systems. We can also use our
    model to better understand how the dataset is structured or apply additional classification
    and feature engineering tasks by exploring our newly constructed latent space.
    Next, we’re going to learn about one of the most common extensions to the graph
    autoencoder model—the VGAE.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，经过200个epoch后，我们达到了超过83%的准确率。甚至更好，当我们使用测试集来查看我们的模型能够多好地预测边缘时，我们得到了86%的准确率。我们可以将我们的模型性能解释为有86%的时间可以向购买者推荐有意义的商品，假设所有未来的数据都和我们的当前数据集相同。这是一个非常好的结果，展示了图神经网络（GNNs）在推荐系统中的有用性。我们还可以通过探索我们新构建的潜在空间来更好地理解数据集的结构，或者通过执行额外的分类和特征工程任务来使用我们的模型。接下来，我们将学习图自动编码器模型最常见的扩展之一——变分图自动编码器（VGAE）。
- en: 5.3 Variational graph autoencoders
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 变分图自动编码器
- en: Autoencoders map data onto discrete points in the latent space. To sample outside
    of the training dataset and generate new synthetic data, we can interpolate between
    these discrete points. This is exactly the process that we described in figure
    5.1, where we generated unseen combinations of data such as a flying boat. However,
    autoencoders are deterministic, where each input maps to a specific point in the
    latent space. This can lead to sharp discontinuities when sampling, which can
    affect performance for data generation resulting in synthetic data that doesn’t
    reproduce the original dataset as well. To improve our generative process, we
    need to ensure that our latent space is well-structured, or *regular.* In figure
    5.7, for example, we show how to use the Kullback-Liebler divergence (KL divergence)
    to restructure the latent space to improve reconstruction.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器将数据映射到潜在空间中的离散点。为了从训练数据集之外采样并生成新的合成数据，我们可以在这些离散点之间进行插值。这正是我们在图5.1中描述的过程，我们生成了未见过的数据组合，例如飞艇。然而，自动编码器是确定性的，其中每个输入映射到潜在空间中的一个特定点。这可能导致采样时的尖锐不连续性，这可能会影响数据生成的性能，导致合成的数据不能很好地再现原始数据集。为了改进我们的生成过程，我们需要确保我们的潜在空间结构良好，即*常规*。例如，在图5.7中，我们展示了如何使用Kullback-Liebler散度（KL散度）重构潜在空间以改善重建。
- en: '![figure](../Images/5-7.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-7.png)'
- en: Figure 5.7 Regular spaces are continuous and compact, but data regions may become
    less separated. Alternatively, high reconstruction loss typically means data is
    well separated, but the latent space might be less covered leading to worse generative
    samples. Here, KL Divergence refers to the Kullback-Liebler divergence.
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7常规空间是连续和紧致的，但数据区域可能会变得不那么分离。或者，高重建损失通常意味着数据分离良好，但潜在空间可能覆盖不足，导致生成样本较差。在这里，KL散度指的是Kullback-Liebler散度。
- en: The KL divergence is a measure of how one probability distribution differs from
    another. It calculates how much “extra information” is needed to encode values
    from one distribution (the original data distribution) into another (the latent
    space). On the left, the data groups (*x*[*i*]) don’t overlap much, which means
    the KL divergence is higher. On the right, there is more overlap (similarity)
    between the different data groups, meaning the KL divergence is lower. When building
    a more regular latent space that has a high KL divergence, we can get very good
    reconstruction but poor interpolation, while we get the opposite for low KL divergence.
    More details on this are provided in section 5.5.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: KL散度是衡量一个概率分布与另一个概率分布差异的度量。它计算将一个分布（原始数据分布）中的值编码到另一个分布（潜在空间）中所需的“额外信息”量。在左侧，数据组（*x*[*i*]）重叠不多，这意味着KL散度较高。在右侧，不同数据组之间存在更多重叠（相似性），这意味着KL散度较低。当构建具有高KL散度的更常规的潜在空间时，我们可以获得非常好的重建效果，但插值效果较差，而对于低KL散度，情况则相反。更多细节请参阅第5.5节。
- en: '*Regular* means that the space fulfills two properties: continuity and compactness.
    *Continuity* means that nearby points in the latent space are decoded into approximately
    similar things, while *compactness* means that any point in the latent space should
    lead to a meaningful decoded representation. These terms, approximately similar
    and meaningful, have precise definitions, which you can read more about in *Learn
    Generative AI with PyTorch* (Manning, 2024; [https://mng.bz/AQBg](https://mng.bz/AQBg)).
    However, for this chapter, all you need to know is that these properties make
    it easier to sample from the latent space, resulting in cleaner generated samples
    and potentially higher model accuracy.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*常规*意味着空间满足两个属性：连续性和紧致性。*连续性*意味着潜在空间中邻近的点被解码成大约相似的事物，而*紧致性*意味着潜在空间中的任何一点都应导致一个有意义的解码表示。这些术语，即大约相似和有意义的，有精确的定义，你可以在*《使用PyTorch学习生成式AI》*（Manning，2024；[https://mng.bz/AQBg](https://mng.bz/AQBg)）中了解更多。然而，对于本章，你需要知道的是，这些属性使得从潜在空间中采样变得更加容易，从而产生更干净的生成样本，并可能提高模型精度。'
- en: When we regularize a latent space, we use variational methods that model the
    entire dataspace in terms of probability distributions (or densities). As we’ll
    see, the main benefit of using variational methods is that the latent space is
    well structured. However, variational methods don’t necessarily guarantee higher
    performance, so it’s often important to test both the autoencoder and the variational
    counterpart when using these types of models. This can be done by either looking
    at the reconstruction score (e.g., mean squared error) on the test dataset, applying
    some dimension reduction method to the latent encodings (e.g., t-SNE or Uniform
    Manifold Approximation and Projection [UMAP]), or using task-specific measures
    (e.g., the Inception Score for images or ROUGE/METEOR for text generation). Specifically
    for graphs, measures such as the maximum mean discrepancy (MMD), graph statistics,
    or graph kernel methods can all be used to compare against different synthetically
    generated graph copies.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对潜在空间进行正则化时，我们使用变分方法，这些方法通过概率分布（或密度）来建模整个数据空间。正如我们将看到的，使用变分方法的主要好处是潜在空间结构良好。然而，变分方法并不一定保证更高的性能，因此在使用这些类型的模型时，通常很重要的一点是要测试自动编码器和变分对应物。这可以通过查看测试数据集上的重建分数（例如，均方误差）、对潜在编码应用一些降维方法（例如，t-SNE或均匀流形近似和投影[UMAP]），或使用特定任务的度量（例如，图像的Inception
    Score或文本生成的ROUGE/METEOR）来实现。对于图而言，最大均值差异（MMD）、图统计或图核方法都可以用来比较不同合成的图副本。
- en: In the next few sections, we’ll go into more detail on what it means to model
    a dataspace as a probability density and how we can transform our graph autoencoder
    into a VGAE with just a few lines. These depend on some key probabilistic machine
    learning concepts such as the KL divergence and the reparameterization trick,
    which we give an overview of in section 5.5\. For more of a deep dive into these
    concepts, we recommend *Probabilistic Deep Learning* (Manning, 2020). Let’s build
    a VGAE architecture and apply it to the same Amazon Products dataset as before.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将更详细地介绍将数据空间建模为概率密度意味着什么，以及我们如何仅用几行代码将我们的图自动编码器转换为VGAE。这些依赖于一些关键的概率机器学习概念，如KL散度和重参数化技巧，我们将在第5.5节中概述这些概念。对于对这些概念进行更深入的了解，我们推荐阅读《概率深度学习》（Manning，2020）。让我们构建一个VGAE架构，并将其应用于之前相同的Amazon
    Products数据集。
- en: 5.3.1 Building a variational graph autoencoder
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 构建变分图自动编码器
- en: The VGAE architecture is similar to the GAE model. The main difference is that
    the output of a *variational* graph encoder is generated by sampling from a probability
    density. We can characterize density in terms of its mean and variance. Therefore,
    the output of the encoder will now be the mean and variance for each dimension
    of our previous space. The decoder then takes this sampled latent representation
    and decodes it to appear like the input data. This can be seen in figure 5.8,
    where the high-level model is that we now extend our previous autoencoder to output
    mean and variance rather than point estimates from the latent space. This allows
    our model to make probabilistic samples from the latent space.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: VGAE架构与GAE模型类似。主要区别在于，*变分*图编码器的输出是通过从概率密度中采样生成的。我们可以用其均值和方差来表征密度。因此，编码器的输出现在将是之前空间每个维度的均值和方差。然后，解码器将这个采样的潜在表示解码，使其看起来像输入数据。这可以在图5.8中看到，其中高级模型是我们现在将之前的自动编码器扩展到输出均值和方差，而不是从潜在空间中输出点估计。这允许我们的模型从潜在空间中进行概率采样。
- en: '![figure](../Images/5-8.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-8.png)'
- en: Figure 5.8 Structure of a general VAE, where we now sample from a probability
    density in the latent space rather than a point estimate as with typical autoencoders.
    VGAEs extend the VAE architecture to apply to graph-structured data.
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.8展示了通用VAE的结构，我们现在从潜在空间中的概率密度中采样，而不是像典型自动编码器那样从点估计中采样。VGAE扩展了VAE架构，使其适用于图结构数据。
- en: We have to adapt our architecture and also change our loss to include an additional
    term for regularizing the latent space. Listing 5.13 provides a code snippet for
    the VGAE. The similarities between listing 5.4 and the `VariationalGCNEncoder`
    layer in listing 5.13 include that we’ve doubled the dimensionality of our latent
    space and now return the mean and the log variance from our encoder at the end
    of our forward pass.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须调整我们的架构，并更改我们的损失以包括一个额外的项来正则化潜在空间。列表5.13提供了一个VGAE的代码片段。列表5.4和列表5.13中的`VariationalGCNEncoder`层之间的相似之处在于，我们已经将潜在空间的维度加倍，并在前向传递的末尾从编码器返回均值和对数方差。
- en: Listing 5.13 `VariationalGCNEncoder`
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.13 `VariationalGCNEncoder`
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Adds in mean and log variance variables to sample from'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 添加均值和对数方差变量以进行采样'
- en: '#2 Forward pass returns mean and log variance variables'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 前向传递返回均值和对数方差变量'
- en: When we discussed the GAE, we learned that the decoder uses the inner product
    to return the adjacency matrix, or edge list. Previously we explicitly implemented
    the inner dot product. However, in PyG, this functionality is built in. To build
    a VGAE structure, we can call the `VGAE` function, shown in the following listing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论GAE时，我们了解到解码器使用内积来返回邻接矩阵或边列表。之前我们明确实现了内积。然而，在PyG中，这个功能是内置的。为了构建VGAE结构，我们可以调用下面的`VGAE`函数。
- en: Listing 5.14 Variational graph autoencoder (`VGAE`)
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.14 变分图自动编码器（`VGAE`）
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Uses the VGAE function from the PyG library to build the autoencoder'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用PyG库中的VGAE函数构建自动编码器'
- en: This functionality makes it much simpler to build a VGAE, where the VGAE function
    in PyG takes care of the reparameterization trick. Now that we have our VGAE model,
    the next thing we need to do is amend the training and testing functions to include
    the KL divergence loss. The training function is shown in the following listing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能使得构建VGAE变得更加简单，其中PyG中的VGAE函数负责处理重新参数化技巧。现在我们有了我们的VGAE模型，接下来我们需要修改训练和测试函数以包含KL散度损失。下面的列表显示了训练函数。
- en: Listing 5.15 Training function
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.15 训练函数
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 As we are using the PyG VGAE function, we need to use the encode and decode
    methods.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 由于我们正在使用PyG的VGAE函数，我们需要使用编码和解码方法。'
- en: '#2 Adds in the regularizing term of the loss given by the KL divergence'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 在损失中添加由KL散度给出的正则化项'
- en: This is the same training loop that we used in listing 5.12 to train our GAE
    model. The only differences are that we include an additional term to our loss
    that minimizes the KL divergence and we change the `encoder` and `decoder` method
    calls to `encode` and `decode` (which we also need to update in our test function).
    Otherwise, the training remains unchanged. Note that thanks to the added PyG functionality,
    these changes are considerably less involved than when we made the changes in
    PyTorch earlier. However, going through each of those extra steps gives us more
    intuition about the underlying architecture for a GAE.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们之前在列表5.12中用于训练GAE模型的相同训练循环。唯一的区别是我们将一个额外的项添加到损失中，以最小化KL散度，并将`encoder`和`decoder`方法调用更改为`encode`和`decode`（我们还需要在我们的测试函数中更新这些）。否则，训练保持不变。请注意，多亏了PyG添加的功能，这些更改比我们在PyTorch中早期所做的更改要简单得多。然而，通过逐一完成这些额外步骤，我们可以对GAE的底层架构有更多的直观理解。
- en: We can now apply our VGAE to the Amazon Products dataset and use this to perform
    edge prediction, which yields an overall test accuracy of 88%. This is slightly
    higher than our accuracy for GAE. It’s important to note that VGAEs won’t necessarily
    give higher accuracy. As a result, you should always try a GAE as well as a VGAE
    and run careful model validation when using this architecture.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将我们的VGAE应用于Amazon Products数据集，并使用它进行边预测，这产生了88%的整体测试准确率。这略高于我们的GAE准确率。重要的是要注意，VGAEs并不一定会给出更高的准确率。因此，你应该始终尝试GAE和VGAE，并在使用此架构时进行仔细的模型验证。
- en: 5.3.2 When to use a variational graph autoencoder
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 何时使用变分图自动编码器
- en: Given that the accuracy for the VGAE was similar to the GAE, it’s important
    to realize the limitations of both methods. In general, GAEs and VGAEs are great
    models to use when you want to build a generative model or where you want to use
    one aspect of your data to learn another aspect. For example, we might want to
    make a graph-based model for pose prediction. We can use both GAE and VGAE architectures
    to predict future poses based on video footage. (We’ll see a similar example in
    later chapters.) When we do so, we’re using the GAE/VGAE to learn a graph of the
    body, conditioned on what the future positions of each body part will be. However,
    if we’re specifically interested in generating new data, such as new chemical
    graphs for drug discovery, VGAEs are often better as the latent space is more
    structured.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 VGAE 的准确度与 GAE 相似，因此认识到这两种方法的局限性是很重要的。一般来说，当你想构建一个生成模型或你想使用数据的一个方面来学习另一个方面时，GAEs
    和 VGAEs 是很好的模型。例如，我们可能想为姿态预测制作一个基于图的模型。我们可以使用 GAE 和 VGAE 架构来根据视频片段预测未来的姿态。（我们将在后面的章节中看到类似的例子。）当我们这样做时，我们正在使用
    GAE/VGAE 来学习一个基于身体的图，条件是每个身体部分的未来位置。然而，如果我们特别感兴趣于生成新数据，例如用于药物发现的新的化学图，那么 VGAEs
    通常更好，因为潜在空间更有结构。
- en: In general, GAEs are great for specific reconstruction tasks such as link prediction
    or node classification, while VGAEs are better for where the tasks require a larger
    or more diverse range of synthetic samples, such as where you want to generate
    entirely new subgraphs or small graphs. VGAEs are also often better suited for
    when the underlying dataset is noisy, compared to GAEs which are faster and more
    suitable for graph data with clear structure. Finally, note that VGAEs are less
    prone to overfitting due to their variational approach, and they may generalize
    better as a result. As always, your choice of architecture depends on the problem
    at hand.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，GAEs 对于特定的重建任务（如链接预测或节点分类）非常出色，而 VGAEs 更适合那些需要更大或更多样化合成样本的任务，例如当你想要生成全新的子图或小图时。与
    GAEs 相比，VGAEs 也更适合于当底层数据集有噪声时，因为 GAEs 更快且更适合具有清晰结构的图数据。最后，请注意，由于它们的变分方法，VGAEs
    更不容易过拟合，因此它们可能具有更好的泛化能力。像往常一样，你的架构选择取决于手头的问题。
- en: In this chapter, we’ve learned about two examples of generative models, the
    GAE and VGAE models, and how to implement these models to work with graph-structured
    data. To better understand how to use this model class, we applied our models
    to an edge prediction task. However, this is only one step in applying a generative
    model.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了两个生成模型的例子，即 GAE 和 VGAE 模型，以及如何实现这些模型以与图结构化数据一起工作。为了更好地理解如何使用这个模型类，我们将我们的模型应用于边缘预测任务。然而，这只是在应用生成模型中的一步。
- en: In many instances where we require a generative model, we use successive layers
    of autoencoders to further reduce the dimensionality of our system and increase
    our reconstruction power. In the context of drug discovery and chemical science,
    GAEs allow us to reconstruct the adjacency matrix (as we did here) as well as
    reconstruct types of molecules and even the number of molecules. GAEs are used
    frequently in many sciences and industries. Now you have the tools to try them
    out too.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多需要生成模型的情况下，我们使用连续的自动编码器层来进一步降低我们系统的维度并增加我们的重建能力。在药物发现和化学科学领域，GAEs 允许我们重建邻接矩阵（正如我们在这里所做的那样），以及重建分子类型甚至分子的数量。GAEs
    在许多科学和工业领域被频繁使用。现在你也有了尝试它们的工具。
- en: In the next section, we’ll demonstrate how to use the VGAE to generate new graphs
    with specific qualities, such as novel molecules that have a high property indicating
    usefulness as a potential drug candidate.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将演示如何使用 VGAE 生成具有特定品质的新图，例如具有高性质的新分子，这表明其作为潜在药物候选人的有用性。
- en: 5.4 Generating graphs using GNNs
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 使用 GNNs 生成图
- en: So far, we’ve considered how to use a generative model of our graph to estimate
    edges between nodes. However, sometimes we’re also interested in generating not
    just a node or an edge but the entire graph. This can be particularly important
    when trying to understand or predict graph-level data. In this example, we’ll
    do exactly that by using our GAE and VGAEs to generate new potential molecules
    to synthesize, which have certain properties.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑了如何使用我们图的生成模型来估计节点之间的边。然而，有时我们感兴趣的不仅仅是生成节点或边，而是整个图。当试图理解或预测图级数据时，这尤其重要。在这个例子中，我们将通过使用我们的
    GAE 和 VGAEs 来生成具有某些特性的新潜在分子来实现这一点，这些分子可以用来合成。
- en: One of the fields that GNNs have had the largest effect on has been drug discovery,
    especially for the identification of new molecules or potential drugs. In 2020,
    a new antibiotic was proposed that was discovered using a GNN, and, in 2021, a
    new method for identifying carcinogens in food was published that also made use
    of GNNs. Since then, there have been many other papers that use GNNs as tools
    to accelerate the drug discovery pipeline.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: GNN 对影响最大的领域之一是药物发现，特别是对新分子或潜在药物的身份识别。2020 年，一种新的抗生素被提出，它是通过使用 GNN 发现的，而在 2021
    年，一种用于识别食物中致癌物的新的方法被发表，该方法也使用了 GNN。从那时起，已经有许多其他论文使用 GNN 作为工具来加速药物发现流程。
- en: 5.4.1 Molecular graphs
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 分子图
- en: 'We’re going to be considering small molecules that have previously been screened
    for drugs, as described in the ZINC dataset of around 250,000 individual molecules.
    Each molecule in this dataset has additional data including the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑那些在 ZINC 数据集中已筛选过的药物的小分子，该数据集大约有 250,000 个单独的分子。这个数据集中的每个分子都有额外的数据，包括以下内容：
- en: '**Simplified Molecular Input Line Entry System (SMILES)* —A description of
    the molecular structure or the molecular *graph* in ASCII format.*'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化分子输入行系统（SMILES）* —分子结构或分子 *图* 的 ASCII 格式描述。*'
- en: '**   *Important properties* —Synthetic accessibility score (SAS), water-octanol
    partition coefficient (`logP`), and, most importantly, a measure of the quantitative
    estimate of druglikeness (QED), which highlights how likely this molecule could
    be as a potential drug.*'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要属性* —合成可及性分数（SAS）、水-辛醇分配系数（`logP`），最重要的是，定量估计药物相似度（QED）的度量，这突出了该分子作为潜在药物的可能性。*'
- en: '*To make this dataset usable by our GNN models, we need to convert this into
    a suitable graph structure. Here, we’re going to be using PyG for defining our
    model and running our deep learning routines. Therefore, we first download the
    data and then convert the dataset into graph objects using NetworkX. We download
    our dataset in listing 5.16, which generates the following output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了使这个数据集能够被我们的 GNN 模型使用，我们需要将其转换为合适的图结构。在这里，我们将使用 PyG 来定义我们的模型并运行我们的深度学习流程。因此，我们首先下载数据，然后使用
    NetworkX 将数据集转换为图对象。我们在列表 5.16 中下载数据集，生成了以下输出：'
- en: '[PRE16]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Listing 5.16 Create a molecular graph dataset
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.16 创建分子图数据集
- en: '[PRE17]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In listing 5.17, we define a function to convert the SMILES into small graphs,
    which we then use to create a PyG dataset. We also add some additional information
    to each object in our dataset, such as the number of heavy atoms that we can use
    for further data exploration. Here, we use the recursive SMILES depth-first search
    (DFS) toolkit (RDKit) package ([www.rdkit.org/docs/index.xhtml](http://www.rdkit.org/docs/index.xhtml)),
    which is a great open source tool for cheminformatics.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 5.17 中，我们定义了一个函数，用于将 SMILES 转换为小图，然后我们使用这些图来创建 PyG 数据集。我们还为我们数据集中的每个对象添加了一些附加信息，例如我们可以用于进一步数据探索的重原子数量。在这里，我们使用递归
    SMILES 深度优先搜索（DFS）工具包（RDKit）包（[www.rdkit.org/docs/index.xhtml](http://www.rdkit.org/docs/index.xhtml)），这是一个出色的开源化学信息学工具。
- en: Listing 5.17 Create the molecular graph dataset
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.17 创建分子图数据集
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: A random sample from our dataset is shown in figure 5.9, which highlights how
    varied our molecular graphs are and their small size, where each one has less
    than 100 nodes and edges.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据集的一个随机样本如图 5.9 所示，突出了我们的分子图的多样性及其小型化，其中每个图都少于 100 个节点和边。
- en: '![figure](../Images/5-9.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-9.png)'
- en: Figure 5.9 Example molecular graphs with quantitative estimate of druglikeness
    (QED)
  id: totrans-177
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.9 示例分子图及其药物相似度（QED）的定量估计
- en: 5.4.2 Identifying new drug candidates
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 识别新的药物候选物
- en: In figure 5.10, we start to see how QED can vary with different molecular structures.
    One of the main obstacles to drug discovery is the number of different potential
    combinations of molecules and how to know which ones to synthesize and then test
    for drug efficacy. This is far before the stage of introducing the drug to human,
    animal (in vivo), or sometimes even cellular (in vitro) trials. Even evaluating
    things such as a molecule’s solubility can be a challenge if we use the molecular
    graph alone. Here, we’re going to be focusing on predicting the molecules’ QED,
    to see which ones are most likely to have potential use as a drug. To give an
    example of how the QED can vary, see figure 5.10, which has four molecules with
    high (~0.95) and low (~0.12) QED. We can see some qualitative differences between
    these molecules, such as the increased number of strong bonds for those with low
    QED. However, estimating the QED directly from the graph is a challenge. To help
    us with this task, we’ll use a GNN to both generate and evaluate new potential
    drugs.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.10中，我们开始看到QED如何随着不同的分子结构而变化。药物发现的主要障碍之一是不同分子潜在组合的数量以及如何知道哪些分子需要合成并测试其药效。这远在将药物引入人体、动物（体内）或有时甚至细胞（体外）试验之前。即使仅使用分子图来评估分子如溶解度等问题也可能是一个挑战。在这里，我们将专注于预测分子的QED，以查看哪些分子最有可能作为药物有潜在用途。为了说明QED如何变化，请参见图5.10，其中包含四个具有高（约0.95）和低（约0.12）QED的分子。我们可以看到这些分子之间的一些定性差异，例如低QED的分子中强键的数量增加。然而，直接从图中估计QED是一个挑战。为了帮助我们完成这项任务，我们将使用GNN来生成和评估新的潜在药物。
- en: '![figure](../Images/5-10.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-10.png)'
- en: Figure 5.10 Molecules with high QED (top) and low QED (bottom)
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.10 高QED（顶部）和低QED（底部）的分子
- en: Our work will be based on two important papers that demonstrated how generative
    models can be effective tools for identifying new molecules (Gómez-Bombarelli
    et al. [4] and De Cao et al. [5]). Specifically, Gómez-Bombarelli et al. showed
    that by constructing a smooth representation of the dataspace, which is the latent
    space we described earlier in this chapter, it’s possible to optimize to find
    new candidates with specific properties of interest. This work borrows heavily
    from an equivalent implementation in the Keras library, outlined in a posting
    by Victor Basu [6]. Figure 5.11 reproduces the basic idea from [5].
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作将基于两篇重要的论文，这些论文展示了生成模型如何成为识别新分子的有效工具（Gómez-Bombarelli等人[4]和De Cao等人[5]）。具体来说，Gómez-Bombarelli等人表明，通过构建数据空间（即我们在本章前面描述的潜在空间）的平滑表示，可以优化以找到具有特定感兴趣特性的新候选者。这项工作大量借鉴了Victor
    Basu[6]帖子中概述的Keras库中的等效实现。图5.11重现了[5]中的基本思想。
- en: '![figure](../Images/5-11.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-11.png)'
- en: Figure 5.11 Example of how a graph autoencoder that is trained to re-create
    small graphs can also be used to make property predictions. The property prediction
    is applied in the latent space and creates a learned gradient of a specific graph
    property—in our case, the QED value.
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.11展示了如何将训练用于重建小图的图自动编码器也用于进行属性预测的例子。属性预测应用于潜在空间，并创建了一个特定图属性的学得梯度——在我们的案例中，是QED值。
- en: In figure 5.11, we can see that the underlying model structure is an autoencoder,
    just like the ones we’ve been discussing in this chapter. Here, we pass the SMILES
    of the molecule as input to the encoder, and this is then used to construct the
    latent space of different molecular representations. This is shown as regions
    with different colors representing different groups of molecules. Then, the decoder
    is designed to faithfully translate the latent space back into the original molecule.
    This is similar to the autoencoder structure that we showed earlier in figure
    5.5.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.11中，我们可以看到底层模型结构是一个自动编码器，就像我们在本章中讨论过的那些一样。在这里，我们将分子的SMILES作为输入传递给编码器，然后用于构建不同分子表示的潜在空间。这表现为不同颜色区域代表不同的分子组。然后，解码器被设计成忠实地将潜在空间转换回原始分子。这与我们在图5.5中展示的自动编码器结构类似。
- en: Alongside the latent space, we now also have an additional function, which is
    going to predict the property of the molecule. In figure 5.11, the property we’ll
    predict is also the property we’re optimizing for. Therefore, by learning how
    to encode both the molecule and the property, which in our case is QED, into the
    latent space, we can optimize drug discovery to generate new candidate molecules
    with a high QED.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 除了潜在空间，我们现在还有一个额外的函数，它将预测分子的属性。在图5.11中，我们将预测的属性也是我们正在优化的属性。因此，通过学习如何将分子和属性（在我们的案例中是QED）编码到潜在空间中，我们可以优化药物发现，生成具有高QED的新候选分子。
- en: 'In our example, we’ll use the VGAE. This model includes two losses: a reconstruction
    loss that measures the difference between the original input data passed to the
    encoder and the output from the decoder, as well as a measure of the structure
    of the latent space, where we use the KL divergence.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用变分自编码器（VGAE）。该模型包括两个损失：一个重构损失，用于衡量编码器接收到的原始输入数据与解码器输出之间的差异，以及一个衡量潜在空间结构的度量，我们使用KL散度。
- en: 'Along with these two loss functions, we’ll add one more function: a property
    prediction loss. The property prediction loss estimates the MSE between predicted
    and actual properties after running the latent representation through a property
    prediction model, as shown in the middle of figure 5.11\.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个损失函数，我们还将添加一个额外的函数：属性预测损失。属性预测损失在通过属性预测模型运行潜在表示后，估计预测属性和实际属性之间的均方误差（MSE），如图5.11中间所示。
- en: To train our GNN, we adapt the training loop provided earlier in listing 5.15
    to include these individual losses. This is shown in listing 5.18\. Here, we have
    the reconstruction loss as the binary cross-entropy (BCE) for the adjacency matrix,
    while the property prediction loss considers only QED and can be based on the
    MSE.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的图神经网络（GNN），我们将第5.15列中提供的早期训练循环进行修改，以包含这些单独的损失。这可以在第5.18列中看到。在这里，我们使用二元交叉熵（BCE）作为邻接矩阵的重构损失，而属性预测损失仅考虑量子电动力学（QED），可以基于均方误差（MSE）。
- en: Listing 5.18 Loss for molecule graph generation
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.18：分子图生成的损失
- en: '[PRE19]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#1 Reconstruction loss'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 重构损失'
- en: '#2 Property prediction loss'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 属性预测损失'
- en: '#3 KL divergence loss'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 KL散度损失'
- en: 5.4.3 VGAEs for generating graphs
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 用于生成图的VGAE
- en: 'Now that we have both our training data and loss, we can start to think about
    the model. Overall, this model will be similar to the ones discussed earlier in
    the chapter, both GAE and VGAE. However, we need to make some subtle changes to
    our model to ensure that it’s well applied to the problem at hand:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练数据和损失，我们可以开始考虑模型。总体而言，这个模型将与本章 earlier 讨论过的模型相似，即GAE和VGAE。然而，我们需要对我们的模型进行一些细微的调整，以确保它能很好地应用于当前的问题：
- en: Use a heterogenous GCN to account for different edge types.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异构图神经网络（GCN）来考虑不同的边类型。
- en: Train the decoder to generate the entire graph.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练解码器以生成整个图。
- en: Introduce a property prediction layer.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入一个属性预测层。
- en: Let’s look at each of these in turn.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一看看这些。
- en: Heterogeneous GCN
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 异构图神经网络
- en: The small graphs that we’re generating will have different edge types that connect
    the nodes of our graphs. Specifically, we can have a different number of bonds
    between the atoms such as a single bond, double bond, triple bond, or even *aromatic
    bonds*, which relate to molecules that are formed into a ring. Graphs with more
    than one edge type are known as heterogeneous graphs, so we’ll need to make our
    GNN applicable to heterogeneous graphs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成的图将具有不同的边类型，这些边类型连接着我们的图的节点。具体来说，原子之间可以有不同的键数，如单键、双键、三键，甚至*芳香键*，这些键与形成环状结构的分子相关。具有多个边类型的图被称为异构图，因此我们需要使我们的GNN适用于异构图。
- en: So far, all the graphs we’ve been considering have been homogenous (only one
    edge type). In listing 5.19, we show how the GCN, which we discussed in chapter
    3, can be adapted to heterogeneous graphs. Here, we explicitly map out some of
    the different features for heterogeneous graphs. However, it’s important to note
    that many GNN packages already support models for heterogeneous graphs out of
    the box. For example, PyG has a specific class of models known as `HeteroConv`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑的所有图都是同构图（只有一种边类型）。在第5.19列中，我们展示了第3章中讨论的GCN如何适应异构图。在这里，我们明确地绘制了一些异构图的不同特征。然而，需要注意的是，许多GNN包已经支持异构图模型。例如，PyG有一个名为`HeteroConv`的特定模型类。
- en: Listing 5.19 shows the code to create a heterogenous GCN. This builds off the
    message-passing class in PyG, which is fundamental to all GNN models. We also
    use the PyTorch `Parameter` class to create a new subset of parameters that are
    specific to the different edge types (relations). Finally, we also specify here
    that the aggregation operation in the message-passing framework is based on summation
    (`'add'`). If you’re interested, feel free to try other aggregation operations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.19展示了创建异构GCN的代码。这基于PyG中的消息传递类，这是所有GNN模型的基础。我们还使用PyTorch的`Parameter`类创建一个新的参数子集，这些参数针对不同的边类型（关系）是特定的。最后，我们在此处还指定，消息传递框架中的聚合操作基于求和（`'add'`）。如果您感兴趣，可以随意尝试其他聚合操作。
- en: Listing 5.19 Heterogenous GCN
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.19 异构GCN
- en: '[PRE20]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#1 "Add" aggregation'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 "添加"聚合'
- en: '#2 Parameter for weights'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 权重参数'
- en: '#3 edge_type is used to select the weights.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用edge_type来选择权重。'
- en: '#4 x_j has shape [E, in_channels], and edge_type has shape [E].'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 x_j的形状为[E, in_channels]，而edge_type的形状为[E]。'
- en: '#5 Select the corresponding weights.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 选择相应的权重。'
- en: With the preceding GNN, we can then compose our encoder as a combination of
    these individual GNN layers. This is shown in listing 5.20, where we follow the
    same logic as when we defined our edge encoder (refer to listing 5.13), except
    that we now switch out our GCN layers for the heterogeneous GCN layers. As we
    have different edge types, we must now also specify the number of different types
    (relations) as well as passing the specific edge type into the forward function
    for our graph encoder. Again, we return both log variance and mean to ensure that
    the latent space is constructed using distributions rather than point samples.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的GNN的基础上，我们可以将编码器组合为这些单独的GNN层的组合。这如图表5.20所示，其中我们遵循与定义我们的边编码器时相同的逻辑（参见图表5.13），只是我们现在用异构GCN层替换了GCN层。由于我们有不同的边类型，我们现在还必须指定不同类型（关系）的数量，以及将特定的边类型传递给图编码器的正向函数。同样，我们返回对数方差和均值，以确保潜在空间是通过分布而不是点样本来构建的。
- en: Listing 5.20 Small graph encoder
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.20 小图编码器
- en: '[PRE21]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#1 Heterogeneous GCNs'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 异构GCNs'
- en: '#2 Forward pass GCNs'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 前向传递GCNs'
- en: Graph decoders
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 图解码器
- en: In our previous examples, we used GAEs to generate and predict edges between
    nodes in a single graph. However, we’re now interested in using our autoencoder
    to generate entire graphs. Therefore, we no longer just consider the inner product
    decoder to account for the presence of an edge in the graph but instead decode
    both the adjacency matrix and feature matrix for each small molecular graph. This
    is shown in listing 5.21\.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的例子中，我们使用GAE在单个图中的节点之间生成和预测边。然而，我们现在对使用我们的自动编码器生成整个图感兴趣。因此，我们不再仅仅考虑内积解码器来考虑图中边的存在，而是解码每个小分子图的邻接矩阵和特征矩阵。这如图表5.21所示。
- en: Listing 5.21 Small graph decoder
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.21 小图解码器
- en: '[PRE22]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Generates the adjacency matrix'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 生成邻接矩阵'
- en: '#2 Symmetrizes the adjacency matrix'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对邻接矩阵进行对称化'
- en: '#3 Applies softmax'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 应用softmax'
- en: '#4 Generates features'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 生成特征'
- en: '#5 Applies softmax'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 应用softmax'
- en: The majority of this code is typical for decoder style networks. We begin with
    a small network that matches the dimension for the latent space created using
    the encoder. We then progressively increase the size of the graph through subsequent
    layers of the network. Here, we can use simple linear networks, where we include
    network dropout for performance. At the final layer, we reshape the decoder output
    into the adjacency and feature matrices. We also ensure that the adjacency matrix
    is symmetric before applying softmax. We symmetrize the adjacency matrix by adding
    it to its transpose and dividing by 2\. This ensures that node `i` is connected
    to `j` and that `j` is also connected to `i`. We then apply softmax to normalize
    the adjacency matrix, ensuring all outgoing edges from each node sum to 1\. There
    are other choices we could make here such as using the maximum value, applying
    a threshold, or using the sigmoid function instead of softmax. In general, averaging
    + softmax is a good approach.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的大部分是典型的解码器风格网络。我们从一个小的网络开始，该网络与编码器创建的潜在空间维度相匹配。然后我们通过网络的后续层逐步增加图的尺寸。在这里，我们可以使用简单的线性网络，其中我们包括网络dropout以提高性能。在最后一层，我们将解码器输出重塑为邻接矩阵和特征矩阵。我们还确保在应用softmax之前，邻接矩阵是对称的。我们通过对邻接矩阵加上其转置并除以2来对称化邻接矩阵。这确保了节点`i`连接到`j`，而`j`也连接到`i`。然后我们对邻接矩阵应用softmax进行归一化，确保每个节点发出的所有边之和为1。我们还可以在此处做出其他选择，例如使用最大值、应用阈值或使用sigmoid函数而不是softmax。一般来说，平均+
    softmax是一个好的方法。
- en: Property prediction layer
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 属性预测层
- en: All that’s left is to combine both encoder and decoder networks into a final
    model that can be used for molecular graph generation, as shown in listing 5.22\.
    Overall, this follows the same steps as in listing 5.14 earlier, where we define
    both our encoder and decoder as well as use the reparameterization trick. The
    only difference is that we also include a simple linear network to predict the
    property of the graphs, in this case, the QED. This is applied on the latent representation
    (`z`), after being reparameterized.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是将编码器和解码器网络合并成一个最终模型，该模型可用于分子图生成，如列表5.22所示。总体而言，这遵循了与列表5.14中相同的步骤，其中我们定义了编码器和解码器，并使用了重新参数化技巧。唯一的区别是，我们还包含了一个简单的线性网络来预测图的属性，在这种情况下，是QED。这应用于重新参数化后的潜在表示（`z`）。
- en: Listing 5.22 VGAE for molecular graph generation
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.22 用于分子图生成的VGAE
- en: '[PRE23]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The output for the model is then both the mean and log variance, which are passed
    to the KL divergence; the reconstructed adjacency matrix and feature matrix, passed
    to the reconstruction loss; and the predicted QED values, which are used in the
    prediction loss. Using these, we can then compute the loss for our network and
    backpropagate the loss through the network weights to refine the generated graphs
    to have specifically high QED values. Next, we show how to achieve just that in
    our training and test loops.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输出包括均值和对数方差，这些被传递到KL散度中；重构的邻接矩阵和特征矩阵，传递到重构损失中；以及预测的QED值，这些用于预测损失。使用这些，我们就可以计算我们网络的损失，并通过网络权重反向传播损失来细化生成的图，使其具有特定的、较高的QED值。接下来，我们将展示如何在我们的训练和测试循环中实现这一点。
- en: 5.4.4 Generating molecules using a GNN
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.4 使用GNN生成分子
- en: In the previous section, we discussed all the individual parts needed to use
    a GNN to generate molecules. We’ll now bring the different elements together and
    demonstrate how to use a GNN to create novel graphs that are optimized for a specific
    property. In figure 5.12, we show the steps to generate molecules with a GNN that
    have a high QED. These steps include creating suitable graphs to represent small
    molecules, passing these through our autoencoder, predicting specific molecular
    features such as QED, and then repeating those steps until we’re able to recreate
    new novel molecular graphs with specific features.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了使用GNN生成分子所需的所有单个部分。现在，我们将不同的元素组合在一起，并展示如何使用GNN创建针对特定属性优化的新图。在图5.12中，我们展示了使用GNN生成具有高QED的分子的步骤。这些步骤包括创建合适的图来表示小分子，将这些图通过我们的自编码器传递，预测特定的分子特征，如QED，然后重复这些步骤，直到我们能够重新创建具有特定特征的新颖分子图。
- en: '![figure](../Images/5-12.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-12.png)'
- en: Figure 5.12 Steps to generate molecules with a GNN
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.12 使用GNN生成分子的步骤
- en: The key element that remains is to combine our loss functions with our adapted
    VGAE model. This is shown in listing 5.23, which defines our training loop. This
    is similar to previous training loops that you’ve seen in earlier chapters and
    examples. The main idea is that our model is used to predict some property of
    the graph. However, here we’re predicting the entire graph, as defined in the
    predicted adjacency matrix (`pred_adj`) and the predicted feature matrix (`pred_feat`).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的关键要素是将我们的损失函数与适应的VGAE模型相结合。这在上面的列表5.23中展示，它定义了我们的训练循环。这与你在前面章节和示例中看到的先前训练循环类似。主要思想是我们的模型用于预测图的某些属性。然而，在这里我们预测的是整个图，如预测的邻接矩阵（`pred_adj`）和预测的特征矩阵（`pred_feat`）所定义的。
- en: The output from our model and the real data are passed to our method for calculating
    the loss, which contains the reconstruction loss, KL divergence loss, and property
    prediction loss. Finally, we compute the gradient penalty, which acts as a further
    regularizer for our model (and defined in more detail in section 5.5). With both
    loss and gradient calculated, we backpropagate through our model, step our optimizer
    forwards, and return the loss.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的输出和真实数据传递到我们的损失计算方法中，该方法包含重建损失、KL散度损失和属性预测损失。最后，我们计算梯度惩罚，它作为我们模型（在5.5节中更详细地定义）的进一步正则化器。在计算了损失和梯度之后，我们通过模型进行反向传播，将优化器向前移动一步，并返回损失。
- en: Listing 5.23 Training function for molecule graph generation
  id: totrans-238
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.23 分子图生成训练函数
- en: '[PRE24]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#1 Compute losses'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 计算损失'
- en: During training time, we find that the model loss decreases, demonstrating that
    the model is effectively learning how to reproduce novel molecules. We show some
    of these molecules in figure 5.13.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们发现模型损失下降，这表明模型正在有效地学习如何复制新型分子。我们在图5.13中展示了其中一些分子。
- en: '![figure](../Images/5-13.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-13.png)'
- en: Figure 5.13 Small molecule graphs generated using a GNN
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.13 使用GNN生成的小分子图
- en: To better understand the distribution of the predicted QED property in our latent
    space, we apply our encoder to a new subset of data and look at the first two
    axes of the data as represented in the latent space, as shown in figure 5.14\.
    Here, we can see that the latent space has been constructed to cluster molecules
    with higher QED together. Therefore, by sampling from regions around this area,
    we can identify new molecules to test. Future work will be needed to verify our
    results, but as a first step toward the discovery of new molecules, we’ve demonstrated
    that a GNN model may well be used to propose new and potentially valuable drug
    candidates.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解预测QED属性在我们潜在空间中的分布，我们将编码器应用于新的数据子集，并查看数据在潜在空间中的前两个轴，如图5.14所示。在这里，我们可以看到潜在空间已经被构建成将具有更高QED的分子聚集在一起。因此，通过从这个区域周围的区域进行采样，我们可以识别出新的分子进行测试。未来的工作将需要验证我们的结果，但作为发现新分子的第一步，我们已经证明GNN模型可能被用来提出新的、可能具有价值的药物候选者。
- en: '![figure](../Images/5-14.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-14.png)'
- en: Figure 5.14 Latent space of drug molecules
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.14 药物分子的潜在空间
- en: In this chapter, we’ve focused on generative tasks rather than classical discriminative
    models. We’ve shown generative models, such as GAEs and VGAEs, can be used for
    edge prediction, learning to identify connections between nodes where information
    is potentially not available. We then went on to show that generative GNNs can
    be used to discover not just unknown parts of a graph, such as a node or edge,
    but also entirely new and complicated graphs, when we applied our GNNs to generate
    new small molecules with a high QED. These results highlight that GNNs are vital
    tools for those working in chemistry, life sciences, and many other disciplines
    that deal with many individual graphs.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关注的是生成任务而不是经典判别模型。我们展示了生成模型，如GAEs和VGAEs，可以用于边缘预测，学习识别节点之间的连接，这些节点可能没有可用信息。然后我们继续展示，当我们应用我们的GNN生成具有高QED的新小分子时，生成式GNN可以用来发现图的不知名部分，如节点或边，甚至可以生成全新的、复杂的图。这些结果强调了GNN对于在化学、生命科学以及许多处理大量单个图的学科领域工作的研究人员来说是至关重要的工具。
- en: Moreover, we’ve learned that GNNs are extremely useful for both discriminative
    and generative tasks. Here, we consider the topic of small molecule graphs, but
    GNNs have also been applied to knowledge graphs and small social clusters. In
    the next chapter, we’ll look at how we can learn to generate graphs that are consistent
    over time by combining generative GNNs with temporal encodings. In that spirit,
    we take a further step forward and learn how GNNs can be taught how to walk.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们已经了解到GNNs在判别性和生成性任务中都非常有用。在这里，我们考虑小分子图的主题，但GNNs也已被应用于知识图和小型社交集群。在下一章中，我们将探讨如何通过结合生成性GNN和时间编码来学习生成随时间一致性的图。在这种精神下，我们进一步前进，学习如何教会GNN如何行走。
- en: 5.5 Under the hood
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 内部结构
- en: Deep generative models use artificial neural networks to model the dataspace.
    One of the classic examples of a deep generative model is the autoencoder. Autoencoders
    contain two key components, the encoder and the decoder, both represented by neural
    networks. They learn how to take data and encode (compress) it into a low dimensional
    representation as well as decode (uncompress) it again. Figure 5.15 shows a basic
    autoencoder taking an image as input and compressing it (step 1). This results
    in the low dimensional representation, or latent space (step 2). The autoencoder
    then reconstructs the image (step 3), and the process is repeated until the reconstruction
    error between input image (x) and output image (x*) is as small as possible. The
    autoencoder is the basic idea behind GAEs and VGAEs.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 深度生成模型使用人工神经网络来建模数据空间。深度生成模型的经典例子之一是自动编码器。自动编码器包含两个关键组件，编码器和解码器，都由神经网络表示。它们学习如何将数据编码（压缩）成低维表示，以及如何解码（解压缩）它。图5.15显示了一个基本的自动编码器，它以图像作为输入并压缩它（步骤1）。这导致低维表示，或潜在空间（步骤2）。然后自动编码器重建图像（步骤3），这个过程会重复进行，直到输入图像（x）和输出图像（x*）之间的重建误差尽可能小。自动编码器是GAEs和VGAEs背后的基本思想。
- en: '![figure](../Images/5-15.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-15.png)'
- en: Figure 5.15 Structure of an autoencoder [9]
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.15 自动编码器的结构 [9]
- en: 5.5.1 Understanding link prediction tasks
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 理解链接预测任务
- en: Link prediction is a common problem in graph-based learning, especially in situations
    where we have incomplete knowledge of our data. This might be because the graph
    changes over time, for example, where we expect new customers to use an e-commerce
    service, and we want a model that can give the best suggested products to buy
    at that time. Alternatively, it may be costly to acquire this knowledge, for example,
    if we want our model to predict which combinations of drugs lead to specific disease
    outcomes. Finally, our data may contain incorrect or purposefully hidden details,
    such as fake accounts on a social media platform. Link prediction allows us to
    infer relations *between* nodes in our graph. Essentially, this means creating
    a model that predicts when and how nodes are connected, as shown in figure 5.16\.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 链接预测是图学习中的常见问题，尤其是在我们对我们数据的不完整知识有所了解的情况下。这可能是由于图随时间变化，例如，我们预计新客户将使用电子商务服务，我们希望有一个模型可以在那时提供最佳建议产品。或者，获取这种知识可能成本高昂，例如，如果我们希望我们的模型预测哪些药物组合会导致特定的疾病结果。最后，我们的数据可能包含错误或故意隐藏的细节，例如社交媒体平台上的虚假账户。链接预测使我们能够推断图中节点之间的**关系**。本质上，这意味着创建一个模型来预测节点何时以及如何连接，如图5.16所示。
- en: '![figure](../Images/5-16.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-16.png)'
- en: Figure 5.16 Schematic explaining how link prediction is performed in practice.
    Subsections of the input graph (subgraphs) are passed to the GNN with different
    links missing, and the model learns to predict when to recreate a link.
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.16 实际中如何进行链接预测的示意图。输入图的子图（子图）被传递给GNN，其中缺少不同的链接，模型学习预测何时重新创建链接。
- en: For link prediction, a model will take pairs of nodes as input and predict whether
    these nodes are connected (whether they should be *linked)*. To train a model,
    we’ll also need ground-truth targets. We generate these by hiding a subset of
    links within the graph. These hidden links become the missing data that we’ll
    learn to infer, which are known as *negative samples*. However, we also need a
    way to encode the information about pairs of nodes. Both of these parts can be
    solved simultaneously using GAEs, as autoencoders both encode information about
    the edge as well as predict whether an edge exists.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 对于链接预测，模型将接受节点对作为输入，并预测这些节点是否连接（是否应该*链接*）。为了训练模型，我们还需要真实的目标。我们通过在图中隐藏一部分链接来生成这些目标。这些隐藏的链接成为我们将学习推断的缺失数据，被称为*负样本*。然而，我们还需要一种方法来编码节点对的信息。这两个部分都可以通过GAEs同时解决，因为自动编码器既编码关于边的信息，又预测边是否存在。
- en: 5.5.2 The inner product decoder
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.2 内积解码器
- en: Inner product decoders are used for graphs because we want to reconstruct the
    adjacency matrix from the latent representation of our feature data. The GAE learns
    how to rebuild a graph (to infer the edges) given a latent representation of the
    nodes. The inner product in high dimensional space calculates the distance between
    two positions. We use the inner product, rescaled by the sigmoid function, to
    gain a probability for an edge between nodes. Essentially, we use the distance
    between points in the latent space as a probability that a node will be connected
    when decoded. This allows us to build a decoder that takes samples from our latent
    space and returns probabilities of whether an edge exists, namely, to perform
    edge prediction, as shown in figure 5.17.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 内积解码器在图中被使用，因为我们希望从特征数据的潜在表示中重建邻接矩阵。GAE学习如何根据节点的潜在表示重建图（推断边）。在高维空间中的内积计算两个位置之间的距离。我们使用内积，通过sigmoid函数进行缩放，来获得节点之间边的概率。本质上，我们使用潜在空间中点之间的距离作为解码时节点连接的概率。这使我们能够构建一个解码器，它从我们的潜在空间中抽取样本，并返回边的存在概率，即执行边预测，如图5.17所示。
- en: '![figure](../Images/5-17.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-17.png)'
- en: Figure 5.17 Overall steps for training our model for link prediction
  id: totrans-261
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.17 链接预测模型训练的整体步骤
- en: The inner product decoder works by taking the latent representation of our data
    and applying the inner product of this data using the passed edge index of our
    data. We then apply the sigmoid function to this value, which returns a matrix
    where each value represents the probability that there is an edge between the
    two nodes.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 内积解码器通过取我们数据的潜在表示并使用我们数据的传递边索引来计算这个数据的内积来工作。然后我们应用sigmoid函数到这个值上，这会返回一个矩阵，其中每个值代表两个节点之间存在边的概率。
- en: Regularizing the latent space
  id: totrans-263
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 正则化潜在空间
- en: Put plainly, the KL divergence tells us how much worse we would be doing if
    we used the wrong probability density when estimating a probability of something.
    Suppose we have two coins and want to guess how well one coin (which we know is
    fair) matches the other coin (which we don’t know is fair). We’re trying to use
    the coin with the known probability to predict the probability for the coin with
    unknown probability. If it’s a good predictor (the unknown coin actually is fair),
    then the KL divergence will be zero. The probability densities of both coins are
    the same; however, if we find that the coin is a bad predictor, then the KL divergence
    will be large. This is because the two probability densities will be far from
    each other. In figure 5.18, we can see this explicitly. We’re trying to model
    the unknown probability density Q(z) using the conditional probability density
    P(Z|X). As the densities overlap, the KL divergence here will be low.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，KL散度告诉我们，如果我们使用错误的概率密度来估计某物的概率，我们会做得有多糟糕。假设我们有两个硬币，并想要猜测一个硬币（我们知道它是公平的）与另一个硬币（我们不知道它是否公平）匹配得有多好。我们试图使用具有已知概率的硬币来预测具有未知概率的硬币的概率。如果它是一个好的预测器（未知的硬币实际上是公平的），那么KL散度将为零。两个硬币的概率密度相同；然而，如果我们发现这个硬币是一个坏的预测器，那么KL散度将很大。这是因为两个概率密度将相距甚远。在图5.18中，我们可以明确地看到这一点。我们试图使用条件概率密度P(Z|X)来建模未知的概率密度Q(z)。随着密度的重叠，这里的KL散度将很低。
- en: '![figure](../Images/5-18.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5-18.png)'
- en: Figure 5.18 KL divergence calculates the degree to which two probability densities
    are distinct. High KL divergence means that they are well separated, whereas low
    KL divergence means they are not.
  id: totrans-266
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.18 KL散度计算两个概率密度之间的差异程度。高KL散度意味着它们很好地分离，而低KL散度意味着它们没有分离。
- en: Practically, we convert an autoencoder to a VGAE by introducing the KL divergence
    in the loss. Our intention here is to both minimize the discrepancy between our
    encoder and decoder as in the autoencoder loss, as well as minimize the difference
    between the probability distribution given by our encoder and the “true” distribution
    that was used to generate our data. This is done by adding the KL divergence to
    the loss. For many standard VGAE, this is given by
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们通过在损失中引入KL散度将自编码器转换为VGAE。我们的意图是既最小化编码器和解码器之间的差异，就像在自编码器损失中那样，也最小化由我们的编码器给出的概率分布与用于生成我们数据的“真实”分布之间的差异。这是通过将KL散度添加到损失中实现的。对于许多标准的VGAE，这由以下给出
- en: (5.1)
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: (5.1)
- en: '![figure](../Images/2.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/2.png)'
- en: where (*p*||*q*) denotes the divergence of probability *p* with respect to probability
    *q*. The term *m* is the mean value of the latent features, and log(var) is the
    logarithm of the variance. We use this in the loss function whenever we build
    a VGAE, ensuring that the forward pass returns both the mean and variance to our
    decoder.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 (*p*||*q*) 表示概率 *p* 相对于概率 *q* 的散度。术语 *m* 是潜在特征的均值，log(var) 是方差的对数。我们在构建VGAE时，在损失函数中使用这个值，确保正向传递返回均值和方差给我们的解码器。
- en: Over-squashing
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 过度压缩
- en: We’ve discussed how GNNs can be used to find out information about a node by
    propagating node and edge representations through message passing. These are used
    to make embeddings of individual nodes or edges, which help guide the model to
    perform some specific tasks. In this chapter, we discussed how to construct a
    model that constructs latent representations by propagating all of the embeddings
    created by the message-passing layers into a latent space. Both perform dimension
    reduction and representation learning of graph-specific data.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了如何通过消息传递传播节点和边表示来使用GNN找出有关节点的信息。这些用于创建单个节点或边的嵌入，有助于引导模型执行某些特定任务。在本章中，我们讨论了如何构建一个模型，通过将消息传递层创建的所有嵌入传播到潜在空间来构建潜在表示。两者都执行图特定数据的降维和表示学习。
- en: However, GNNs have a specific limitation in how much information they can use
    to make representations. GNNs suffer from something known as *over-squashing*,
    which refers to how information that is spread many hops across the graph (i.e.,
    message passing) causes a considerable drop in performance. This is because the
    neighborhood that each node receives information from, also known as its receptive
    field, grows exponentially with the number of layers of the GNN. As more information
    is aggregated through message passing across these layers, the important signals
    from distant nodes become diluted compared to the information coming from nearer
    nodes. This causes the node representations to become similar or more homogenous,
    and eventually to converge to the same representations, also known as over-smoothing,
    which we discussed in chapter 4\.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GNNs在如何使用信息来表示方面存在一个特定的限制。GNNs遭受一种被称为*过度压缩*的问题，这指的是在图中传播许多跳（即消息传递）的信息如何导致性能的显著下降。这是因为每个节点接收信息来自的邻域，也称为其感受野，随着GNN层数的增加而呈指数增长。随着通过这些层进行消息传递而聚合的信息越来越多，来自远端节点的信号与来自近端节点的信息相比变得稀释。这导致节点表示变得相似或更均匀，最终收敛到相同的表示，也称为过度平滑，这在第4章中已讨论过。
- en: 'Empirical evidence has shown that this can start to occur with as few as three
    or four layers [7], as you can see in figure 5.19\. This highlights one of the
    key differences between GNNs and other deep learning architectures: we rarely
    want to make a very deep model with many layers stacked on top of each other.
    For models with many layers, other methods are often also introduced to ensure
    long-range information is included such as skip connections or attention mechanisms.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 实证证据表明，这可能在只有三到四层时就开始发生[7]，如图5.19所示。这突出了GNN与其他深度学习架构之间的一个关键区别：我们很少希望构建一个非常深的模型，其中有很多层堆叠在一起。对于具有许多层的模型，通常也会引入其他方法来确保包括长距离信息，例如跳跃连接或注意力机制。
- en: '![figure](../Images/5-19.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/5-19.png)'
- en: 'Figure 5.19 Visualization of over-squashing (Source: Alon and Yahav [7])'
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.19过度压缩的可视化（来源：Alon和Yahav [7]）
- en: In the previous example in this chapter, we spoke about using GNNs for drug
    discovery. Here, we considered an example where the graphs were relatively small.
    However, when graphs become larger, there is an increasing risk that long-range
    interactions become important. This is particularly true in chemistry and biology,
    where nodes at extreme ends of a graph can have an outsized influence on the overall
    properties of the graph. In the context of chemistry, these might be two atoms
    that are either ends of a large molecule and which decide the overall properties
    of the molecule such as its toxicity. The range of interactions or information
    flow that we need to consider to effectively model a problem is known as the *problem
    radius*. When designing a GNN, we need to make sure that the number of layers
    is at least as large as the problem radius.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面的例子中，我们讨论了使用GNNs进行药物发现。在这里，我们考虑了一个图相对较小的例子。然而，当图变得更大时，长程相互作用变得重要的风险会增加。这在化学和生物学中尤其如此，图中极端端的节点可能对图的总体性质有不成比例的影响。在化学的背景下，这些可能是一对位于大分子两端的原子，它们决定了分子的总体性质，如毒性。我们需要考虑以有效建模问题的相互作用范围或信息流被称为*问题半径*。在设计GNN时，我们需要确保层数至少与问题半径一样大。
- en: 'In general, there are several methods for addressing over-squashing for GNNs:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有几种方法可以解决GNNs的过度压缩问题：
- en: Ensure that not too many layers are stacked together.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保不要堆叠太多的层。
- en: Add in new “fake” edges between nodes that are very far/many hops apart or introduce
    a single node that is attached to all other nodes so that the problem radius is
    reduced to 2\.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在节点之间添加新的“虚假”边，这些节点相隔很远/跳数很多，或者引入一个连接到所有其他节点的单个节点，这样问题半径就减少到2。
- en: Use sampling, such as GraphSAGE, which samples from the neighborhood or introduces
    skip connections, which similarly skip some local neighbors. For sampling methods,
    it’s important to balance the loss of local information with the gain of more
    long-range information.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用采样，如GraphSAGE，它从邻域中采样或引入跳跃连接，这些连接类似地跳过一些局部邻居。对于采样方法，重要的是在损失局部信息与获得更多长程信息之间取得平衡。
- en: All of these methods are highly problem specific, and you should think carefully
    about the type of interactions between nodes in your graph when deciding whether
    long-range interactions are important. For example, in the next chapter, we consider
    motion prediction where the head has likely little influence on the foot compared
    to the knee. Alternatively, molecular graphs as described in this chapter will
    likely have large influences from more distant nodes. Therefore, the most important
    part in resolving problems such as over-squashing is making sure you have a solid
    understanding of both your problem and data.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都非常特定于问题，当决定长程相互作用是否重要时，你应该仔细思考你图中节点之间的交互类型。例如，在下一章中，我们考虑了运动预测，其中头部相对于膝盖对脚的影响可能很小。或者，正如本章所描述的分子图，可能来自更远节点的较大影响。因此，解决过度压缩等问题最重要的部分是确保你对问题和数据都有扎实的理解。
- en: Summary
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Discriminative models learn to separate data classes, while generative models
    learn to model the entire dataspace.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别模型学习区分数据类别，而生成模型学习模拟整个数据空间。
- en: Generative models are often used to perform dimension reduction. Principal component
    analysis (PCA) is a form of linear dimension reduction.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型通常用于执行降维。主成分分析（PCA）是一种线性降维方法。
- en: Autoencoders contain two key components, the encoder and the decoder, both represented
    by neural networks. They learn how to take data and encode (compress) it into
    a low dimensional representation as well as decode (uncompress) it again. For
    autoencoders, the low dimensional representation is known as the latent space.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动编码器包含两个关键组件，编码器和解码器，都由神经网络表示。它们学习如何将数据编码（压缩）成低维表示，以及如何解码（解压缩）它。对于自动编码器，低维表示被称为潜在空间。
- en: VAEs extend autoencoders to have a regularizing term in the loss. This regularizing
    term is typically the Kullback-Liebler (KL) divergence, which measures the difference
    between two distributions—the learned latent distribution and a prior distribution.
    The latent space of VAEs is more structured and continuous, where each point represents
    a probability density rather than a fixed-point encoding.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAEs将自动编码器扩展到损失中包含正则化项。这个正则化项通常是Kullback-Liebler（KL）散度，它衡量两个分布之间的差异——学习到的潜在分布和先验分布。VAEs的潜在空间更加结构化和连续，其中每个点代表一个概率密度，而不是固定的点编码。
- en: Autoencoders and variational autoencoders (VAEs) can also be applied to graphs.
    These are, respectively, graph autoencoders (GAE) and variational graph autoencoders
    (VGAE). They are similar to typical autoencoders and VAEs, but the decoder element
    is typically the dot product applied to the edge list.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动编码器和变分自动编码器（VAEs）也可以应用于图。它们分别是图自动编码器（GAE）和变分图自动编码器（VGAE）。它们与典型的自动编码器和VAEs类似，但解码器元素通常是应用于边列表的点积。
- en: GAEs and VGAEs are useful for edge prediction tasks. They can help us predict
    where there might be hidden edges in our graph.*
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAEs和VGAEs在边缘预测任务中非常有用。它们可以帮助我们预测图中可能存在的隐藏边。
