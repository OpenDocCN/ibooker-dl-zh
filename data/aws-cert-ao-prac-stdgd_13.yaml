- en: Appendix B. Answer Key
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录B. 答案关键
- en: Chapter 2 Answer Key
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 答案关键
- en: 'B: While AWS is responsible for securing the underlying infrastructure and
    its physical security, customers are accountable for securing their applications,
    configuring security settings, and managing their cloud environments.'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 虽然AWS负责保护底层基础设施及其物理安全，但客户负责保护其应用程序、配置安全设置和管理其云环境。'
- en: 'B: AWS Lambda is a serverless computing service. Amazon EC2 is an IaaS offering
    due to its provision of virtualized compute resources. Amazon RDS is a PaaS due
    to its managed database capabilities. Amazon Chime is a SaaS application for communications.'
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: AWS Lambda是一种无服务器计算服务。亚马逊EC2由于其提供虚拟化计算资源而成为IaaS服务。亚马逊RDS由于其托管数据库功能而成为PaaS服务。亚马逊Chime是一个用于通信的SaaS应用程序。'
- en: 'C: Amazon RDS is a managed relational database service, Amazon S3 provides
    storage capabilities, Amazon EC2 offers scalable virtual machines in the cloud,
    and AWS Glue is utilized for data preparation and transformation.'
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 亚马逊RDS是一个托管的关系数据库服务，亚马逊S3提供存储能力，亚马逊EC2在云中提供可扩展的虚拟机，而AWS Glue用于数据准备和转换。'
- en: 'B: Public cloud environments do not offer full control over infrastructure
    or operate on a multi-tenant model to achieve cost savings through shared resources.
    While public cloud providers implement robust security, no system is entirely
    immune to cyber threats.'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 公共云环境不提供对基础设施的完全控制，或基于多租户模型通过共享资源实现成本节约。虽然公共云提供商实施强大的安全措施，但没有系统是完全免疫于网络威胁的。'
- en: 'B: Cloud computing eliminates the need for companies to purchase and manage
    physical servers, provides on-demand access to IT resources such as storage and
    computing power, is distinct from on-premises environments like private data centers,
    and while it can support AI applications, its overall definition is much broader.'
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 云计算消除了公司购买和管理物理服务器的需求，提供对存储和计算能力等IT资源的按需访问，与私有数据中心等本地环境不同，虽然它可以支持AI应用，但其整体定义要广泛得多。'
- en: 'B: IAM is responsible for managing permissions, roles, and policies to secure
    AWS resources, but not for direct encryption. In contrast, AWS CloudWatch and
    AWS CloudTrail are dedicated to monitoring and logging activities within AWS,
    while AWS Backup is the specific service designed for automated backup processes.'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: IAM负责管理权限、角色和策略以保护AWS资源，但不负责直接加密。相比之下，AWS CloudWatch和AWS CloudTrail专注于监控和记录AWS内的活动，而AWS
    Backup是专门为自动化备份过程设计的特定服务。'
- en: Chapter 3 Answer Key
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 答案关键
- en: 'A: Feature engineering transforms raw data to improve model accuracy and performance.
    Although it can aid in bias reduction, it is not the sole determinant of fairness
    in models. Model training involves an algorithm that learns patterns from data.
    Model evaluation assesses performance post-training.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 特征工程将原始数据转换为提高模型准确性和性能。尽管它可以帮助减少偏差，但它不是模型公平性的唯一决定因素。模型训练涉及一个从数据中学习模式的算法。模型评估在训练后评估性能。'
- en: 'B: Supervised learning involves models learning from labeled examples, whereas
    reinforcement learning trains models through trial and error with rewards and
    penalties. Additionally, anomaly detection typically employs unsupervised learning,
    while dimensionality reduction aims to decrease the number of input features.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 监督学习涉及模型从标记的示例中学习，而强化学习通过试错、奖励和惩罚来训练模型。此外，异常检测通常采用无监督学习，而降维旨在减少输入特征的数量。'
- en: 'D: SageMaker simplifies and automates ML workflows, allowing users to train,
    tune, and deploy models efficiently. It also reduces manual intervention through
    automation. It provides both pretrained and customizable models.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: SageMaker简化并自动化了机器学习工作流程，使用户能够高效地训练、调整和部署模型。它还通过自动化减少了人工干预。它提供预训练和可定制的模型。'
- en: 'C: Supervised learning requires labeled data to learn patterns and can be used
    for classification and regression tasks. In contrast, unsupervised learning identifies
    structures and patterns in unlabeled data, primarily for clustering and dimensionality
    reduction, and reinforcement learning is a distinct paradigm separate from both.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 监督学习需要标记数据来学习模式，可用于分类和回归任务。相比之下，无监督学习在未标记数据中识别结构和模式，主要用于聚类和降维，而强化学习是一个与两者都不同的独立范式。'
- en: 'C: Unsupervised learning is used for clustering and finding patterns in data
    without predefined labels, making it suitable for customer segmentation. Reinforcement
    learning is for sequential decision-making and not clustering. Supervised learning
    is unsuitable for this task as it requires labeled data, which is typically unavailable
    for segmentation. Semisupervised learning is a hybrid approach not necessary for
    this task.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 无监督学习用于在数据中聚类和寻找模式，而不需要预定义的标签，这使得它适用于客户细分。强化学习用于顺序决策，而不是聚类。监督学习不适合这项任务，因为它需要标记数据，而这通常在细分中不可用。半监督学习是一种混合方法，对于这项任务不是必要的。'
- en: 'B: The main purpose of model monitoring is to track performance over time,
    identify issues like data drift, and ensure consistent accuracy in real-world
    applications. It helps determine when retraining is necessary but does not eliminate
    the need for it, as no ML model can guarantee 100% accuracy in all scenarios.
    And although reducing features can improve generalization, it’s not the primary
    goal of monitoring.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 模型监控的主要目的是跟踪性能随时间的变化，识别数据漂移等问题，并确保在现实世界应用中的准确度一致。它有助于确定何时需要重新训练，但并不消除重新训练的需求，因为没有任何机器学习模型可以在所有场景中保证100%的准确率。尽管减少特征可以提高泛化能力，但这并不是监控的主要目标。'
- en: Chapter 4 Answer Key
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 答案关键
- en: 'C: Generative Adversarial Networks (GANs) employ two competing neural networks—a
    generator and a discriminator—to produce realistic content. VAE utilizes a complex
    probabilistic system for encoding and decoding data, while the Transformer model
    leverages attention mechanisms to comprehend intricate patterns. Lastly, diffusion
    models create realistic content, such as images, through a process of adding and
    removing noise.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 生成对抗网络（GANs）采用两个相互竞争的神经网络——生成器和判别器——来生成逼真的内容。VAE利用复杂的概率系统进行数据的编码和解码，而转换器模型利用注意力机制来理解复杂的模式。最后，扩散模型通过添加和去除噪声的过程创建逼真的内容，如图像。'
- en: 'B: Positional encoding is crucial in models utilizing attention mechanisms,
    as it reorders words that become out of sequence after attention is applied. It
    does not enhance GPU reliability or reduce the cost of an AI model. Backpropagation
    is the mechanism by which a deep learning model refines its results.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 位置编码在利用注意力机制的模式中至关重要，因为它重新排列了在应用注意力后变得无序的单词。它不会增强GPU的可靠性或降低AI模型的成本。反向传播是深度学习模型改进其结果的一种机制。'
- en: 'D: A key advantage of RAG is its ability to search data from an external vector
    database, which eliminates the need to modify the internal weights of the model.
    While RAG generally uses less computational power, this is not considered its
    primary advantage. RAG might actually increase response latency due to data processing.
    And although RAG can help reduce bias, it will not eliminate it entirely.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: RAG的关键优势在于其能够从外部向量数据库中搜索数据，从而消除了修改模型内部权重的需求。虽然RAG通常使用较少的计算能力，但这并不是其主要优势。RAG可能会因为数据处理而增加响应延迟。尽管RAG可以帮助减少偏差，但它并不能完全消除偏差。'
- en: 'B: A key advantage of transformer models, due to attention mechanisms, is their
    ability to process large datasets in parallel, whereas RNNs process data sequentially.
    Both transformer and RNN models can utilize labeled data. RNNs are designed for
    text processing, and transformers typically require training with substantial
    amounts of data.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 由于注意力机制，转换器模型的一个关键优势是能够并行处理大量数据集，而循环神经网络（RNNs）则是按顺序处理数据。转换器和RNN模型都可以利用标记数据。RNNs是为文本处理而设计的，而转换器通常需要大量数据进行训练。'
- en: 'A: The transformer model’s use of complex probability systems with large datasets
    can sometimes result in false or misleading responses. GPUs, while crucial for
    AI, are not unpredictable. The presence of labeled data in model training does
    not inherently lead to hallucinations. Hallucinations are not exclusive to large
    models but can occur across small and medium size models.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 转换器模型使用复杂概率系统处理大量数据集有时会导致错误或误导性的响应。虽然GPU对于AI至关重要，但并非不可预测。模型训练中存在标记数据并不必然导致幻觉。幻觉并非仅限于大型模型，也可能发生在小型和中型模型中。'
- en: 'C: The hidden layer is where weights are applied to inputs, which enables the
    model to detect patterns. The input layer receives the raw data and the output
    layer produces the network’s response. There is no activation layer in a neural
    network.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 隐藏层是应用权重到输入的地方，这使得模型能够检测模式。输入层接收原始数据，输出层产生网络的响应。神经网络中没有激活层。'
- en: Chapter 5 Answer Key
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 答案关键
- en: 'C: NLP is a broader field used for various language-related applications like
    translation and sentiment analysis, whereas IDP is a more specialized subset of
    NLP. IDP primarily focuses on automating the processing of business documents,
    extracting and classifying information from both structured and unstructured formats.
    While NLP can handle spoken data, IDP’s main scope is document-based input, although
    both can process various forms of input beyond just handwritten or printed language.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: NLP是一个更广泛的领域，用于各种与语言相关的应用，如翻译和情感分析，而IDP是NLP的一个更专业的子集。IDP主要专注于自动化处理业务文档，从结构化和非结构化格式中提取和分类信息。虽然NLP可以处理语音数据，但IDP的主要范围是文档输入，尽管两者都可以处理各种形式的输入，而不仅仅是手写或印刷语言。'
- en: 'C: Amazon Translate provides capabilities for translating text between various
    languages. Amazon Comprehend is designed for NLP tasks like sentiment analysis
    and entity recognition. Amazon Polly specializes in converting text into lifelike
    speech. Amazon Textract is used for extracting text from images and documents.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 亚马逊翻译服务提供在多种语言之间翻译文本的能力。亚马逊理解服务旨在进行NLP任务，如情感分析和实体识别。亚马逊Polly专注于将文本转换为逼真的语音。亚马逊Textract用于从图像和文档中提取文本。'
- en: 'D: Amazon Kendra is an AI-powered search service that utilizes natural language
    queries; it is not a financial analysis tool. Amazon Translate is used for translating
    foreign languages, while Amazon Polly provides text-to-speech conversion services.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 亚马逊Kendra是一个利用自然语言查询的AI搜索服务；它不是一个财务分析工具。亚马逊翻译服务用于翻译外语，而亚马逊Polly提供文本到语音的转换服务。'
- en: 'C: Kendra’s use of RAG allows it to produce more relevant and context-aware
    search results. Kendra does not use a quantum database and linear regression is
    not central to Kendra’s advanced capabilities. While keyword matching is a fundamental
    search approach, it’s not an AI feature.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: Kendra使用RAG技术，使其能够生成更相关和上下文感知的搜索结果。Kendra不使用量子数据库，线性回归也不是Kendra高级功能的核心。虽然关键词匹配是一种基本的搜索方法，但它不是AI功能。'
- en: 'A: Amazon Transcribe converts audio into written text. Amazon Translate converts
    text into another language. Amazon Comprehend can be used to extract various information
    from a document for sentiment analysis.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 亚马逊转录服务将音频转换为书面文本。亚马逊翻译服务将文本转换为其他语言。亚马逊理解服务可用于从文档中提取各种信息以进行情感分析。'
- en: 'D: Amazon Polly provides the capability to generate human-sounding speech from
    text. Amazon Transcribe converts speech to text, Amazon Translate can translate
    text into other languages, and Amazon Comprehend is used to extract insights and
    perform data analytics.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 亚马逊Polly提供从文本生成类似人类语音的能力。亚马逊转录服务将语音转换为文本，亚马逊翻译服务可以将文本翻译成其他语言，而亚马逊理解服务用于提取洞察力和执行数据分析。'
- en: Chapter 6 Answer Key
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章 答案关键
- en: 'B: Although the model will continue to work, combining both can lead to unpredictable
    responses and is not generally recommended. Using both does not guarantee accuracy
    and does not necessarily mean the responses will be deterministic.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 虽然模型将继续工作，但结合两者可能会导致不可预测的响应，通常不推荐这样做。同时使用两者并不能保证准确性，也不一定意味着响应将是确定性的。'
- en: 'C: A negative prompt is used to exclude unwanted elements (e.g., blurry, cartoon).
    It does not change the colors of an image or impact the size of the image. Temperature
    is used for text responses.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 负面提示用于排除不需要的元素（例如，模糊的、卡通的）。它不会改变图像的颜色或影响图像的大小。温度用于文本响应。'
- en: 'D: Modality refers to the input and output types for a model, such as text,
    image, audio, and multimodal. Modality is distinct from the model’s license type,
    language support, or whether it can be deployed serverlessly.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 模态性指的是模型的输入和输出类型，例如文本、图像、音频和多模态。模态性与模型的许可类型、语言支持或是否可以无服务器部署无关。'
- en: 'C: A higher temperature will make the content more creative. A higher temperature
    encourages less deterministic content and is also less effective for tasks like
    summarization, since the content will be more random and creative. Temperature
    is not used for creating videos.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 较高的温度会使内容更具创意。较高的温度鼓励更不确定的内容，并且对于像摘要这样的任务也效果较差，因为内容将更加随机和具有创意。温度不用于创建视频。'
- en: 'B: A model profile in Amazon Bedrock includes more than just the license information,
    such as the version, release date, deployment type, modalities, and model ID.
    It will not include information about GPU usage or datasets.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 亚马逊Bedrock中的模型配置文件不仅包括许可信息，还包括版本、发布日期、部署类型、模态性和模型ID等信息。它不会包括关于GPU使用或数据集的信息。'
- en: 'B: Users must submit a form with details such as company name, use case, and
    intended users. Provisioned mode is related to model inference, not access. A
    certification exam is not required to use the models. Models cannot be directly
    downloaded from Bedrock.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 用户必须提交包含公司名称、用例和预期用户等详细信息的表格。配置模式与模型推理相关，而不是访问。使用模型不需要通过认证考试。模型不能直接从Bedrock下载。'
- en: Chapter 7 Answer Key
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 答案关键
- en: 'C: Instruction is required. Without it, the model won’t know what to do. Context
    is helpful but not required. Input data is only needed when you want the model
    to analyze something specific. The output indicator is for formatting but is not
    essential.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 需要指令。没有指令，模型将不知道该做什么。上下文有帮助但不是必需的。当您希望模型分析特定内容时才需要输入数据。输出指示器用于格式化，但不是必需的。'
- en: 'B: The output indicator instructs the model on what the response should look
    like, say as a table or CSV format. The output indicator does not provide examples
    of how to write better prompts. The context component provides background information
    for the task. Prompting is not the same as training.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 输出指示器指导模型响应的外观，例如表格或CSV格式。输出指示器不提供如何编写更好的提示的示例。上下文组件提供任务的背景信息。提示与训练不同。'
- en: 'B: Context improves the model’s ability to understand the task, by providing
    relevant background information. The input data component supplies relevant input
    data. The output indicator specifies the output format. While context can include
    past interactions, it’s not used to summarize them.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 上下文通过提供相关背景信息，提高了模型理解任务的能力。输入数据组件提供相关输入数据。输出指示器指定输出格式。虽然上下文可以包括过去的交互，但它不是用来总结它们的。'
- en: 'C: Delimiters improve prompt clarity by showing where the input begins. They
    do not reduce token count. They are not intended to separate formatting options
    and they only affect the current prompt.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 分隔符通过显示输入开始的位置来提高提示的清晰度。它们不会减少令牌计数。它们不是用来分隔格式化选项的，而且它们只影响当前提示。'
- en: 'B: Defining the user’s role helps shape the LLM’s understanding and tone.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 定义用户的角色有助于塑造LLM的理解和语气。'
- en: 'C: Few-shot prompting is where you provide examples to guide the model..'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 少样本提示是在你提供示例来引导模型的情况下。'
- en: Chapter 8 Answer Key
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 答案关键
- en: 'C: Early stopping prevents the model from memorizing the training data. Increasing
    the complexity of the model usually increases the risk of overfitting. Noisy data
    increases variance and reduces performance. Tuning hyperparameters is important
    to balance bias and variance.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 提前停止可以防止模型记住训练数据。增加模型的复杂性通常会增加过拟合的风险。噪声数据会增加方差并降低性能。调整超参数对于平衡偏差和方差很重要。'
- en: 'D: Licensing agreements—like OpenAI’s deal with News Corp—are being used to
    address IP concerns. Removing all public data is impractical and not a standard
    solution. Restricting access doesn’t solve IP ownership issues. Internal limits
    will reduce exposure, but this doesn’t fully resolve IP problems.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 许可协议——如OpenAI与新闻集团的交易——被用来解决知识产权问题。移除所有公共数据是不切实际的，也不是标准解决方案。限制访问并不能解决知识产权所有权问题。内部限制会减少曝光，但这并不能完全解决知识产权问题。'
- en: 'A: Without accuracy, models can be unsafe or untrustworthy. However, even accurate
    models require regular retraining. Cost savings may result from accuracy but aren’t
    the core reason it’s important for responsible AI. And accuracy is important across
    all model types, not just visual ones.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 没有准确性，模型可能不安全或不值得信赖。然而，即使是准确的模型也需要定期重新训练。准确性可能带来成本节约，但这并不是它对负责任的人工智能至关重要的核心原因。而且准确性对所有模型类型都很重要，而不仅仅是视觉模型。'
- en: 'D: Fairness means AI decisions should be impartial and nondiscriminatory. It
    is unrelated to model sophistication and it focuses on equity, not speed. Personalization
    may actually introduce bias if not managed carefully.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 公平意味着人工智能决策应该是无偏见的和非歧视性的。它与模型复杂性无关，它关注的是公平性，而不是速度。如果管理不当，个性化实际上可能会引入偏差。'
- en: 'B: Explainability helps users understand specific outputs, whereas transparency
    is about system-wide openness. These concepts are closely related but not interchangeable.
    User interface design is unrelated to the core concept of explainability. Transparency
    is encouraged in all systems, not just open source models.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 可解释性帮助用户理解特定的输出，而透明度是关于系统级开放性的。这些概念密切相关但不可互换。用户界面设计与可解释性的核心概念无关。透明度在所有系统中都应得到鼓励，而不仅仅是开源模型。'
- en: 'C: Privacy and security are about protecting individual data and user rights.
    Model weights and parameters are technical aspects, not user-focused. Transparency
    relates to openness, not data protection. While IP is important, it’s not the
    focus of privacy and security.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 隐私和安全是关于保护个人数据和用户权利的。模型权重和参数是技术方面，不是以用户为中心的。透明度与开放性相关，而不是数据保护。虽然知识产权很重要，但它不是隐私和安全的焦点。'
- en: Chapter 9 Answer Key
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章答案关键
- en: 'C: Governance provides a structure for wise decision making and innovation
    management, while compliance ensures rules and standards are consistently followed.
    Governance is not about enforcing laws. Protecting data is part of security, and
    ethical development is shared across functions. Governance is essential for organizational
    success and is not optional.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 管理为明智的决策和创新管理提供了一个结构，而合规性确保规则和标准得到持续遵循。管理不是关于强制执行法律。保护数据是安全的一部分，道德发展是跨职能共享的。管理对于组织成功至关重要，不是可选项。'
- en: 'D: Defense in depth means layering defenses so there are multiple safeguards.
    It assumes no single control is sufficient on its own. Although multiple, layered
    security measures are partially correct, this doesn’t fully explain the idea of
    backup controls stepping in. Automation of pipelines is important but not part
    of defense in depth.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 深度防御意味着分层防御，以确保有多个安全措施。它假定没有任何单一的控制措施本身足够。尽管多层安全措施部分正确，但这并不能完全解释备份控制介入的概念。管道自动化的自动化很重要，但不是深度防御的一部分。'
- en: 'C: AWS Shield mitigates DoS attacks, and Amazon Cognito securely handles user
    authentication and federation. GuardDuty detects threats, and Private CA manages
    certificates. AWS KMS and AWS ACM both help encrypt data and manage certificates.
    Amazon VPC and AWS WAF help with network and web layer protection.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: AWS Shield 缓解 DoS 攻击，Amazon Cognito 安全处理用户身份验证和联合。GuardDuty 检测威胁，Private
    CA 管理证书。AWS KMS 和 AWS ACM 都有助于加密数据和管理证书。Amazon VPC 和 AWS WAF 帮助进行网络和 Web 层保护。'
- en: 'A: PrivateLink enables private connectivity between VPCs and AWS services without
    public internet exposure. Security Hub aggregates security alerts. Amazon VPC
    creates private networks but does not specifically handle private routing across
    services. GuardDuty detects suspicious activity.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: PrivateLink 允许 VPC 和 AWS 服务之间进行私有连接，无需暴露公共互联网。Security Hub 聚合安全警报。Amazon
    VPC 创建私有网络，但并不专门处理服务间的私有路由。GuardDuty 检测可疑活动。'
- en: 'C: Governance policies include clear standards for sourcing data, training
    models, evaluating results, and approving deployments. Human oversight is critical
    in AI governance to ensure ethical use. Public datasets still require privacy
    and bias evaluations. Unrestricted deployment increases legal, ethical, and operational
    risks.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 管理政策包括对数据来源、模型训练、结果评估和部署批准的明确标准。在人工智能治理中，人工监督至关重要，以确保道德使用。公共数据集仍需进行隐私和偏差评估。无限制的部署会增加法律、道德和运营风险。'
- en: 'B: HIPAA governs the security and privacy of protected health information (PHI)
    in the US. PCI DSS focuses on protecting payment card information; GDPR is about
    personal data privacy for EU residents; and ENISA focuses on cybersecurity standards
    for the EU.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: HIPAA 管理美国受保护健康信息（PHI）的安全和隐私。PCI DSS 专注于保护支付卡信息；GDPR 是关于欧盟居民的个人信息隐私；而 ENISA
    专注于欧盟的网络安全标准。'
- en: Practice Exam Answer Key
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践考试答案关键
- en: 'B: AZs provide redundancy and fault tolerance within AWS regions. An AZ consists
    of multiple data centers but is not itself a single data center. Security groups
    control access but do not define infrastructure zones. AWS regions are separate
    from AZs, and neither span multiple continents. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: AZ 提供了 AWS 区域内的冗余和容错。一个 AZ 由多个数据中心组成，但本身不是一个单一的数据中心。安全组控制访问，但不定义基础设施区域。AWS
    区域与 AZ 分开，并且都不跨越多个大陆。参见[第 2 章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'C: SaaS delivers fully managed applications. IaaS provides virtualized hardware,
    PaaS offers tools for developers, but neither of these include fully managed applications.
    VaaS is not a standard cloud computing model. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: SaaS 提供完全管理的应用程序。IaaS 提供虚拟化硬件，PaaS 为开发者提供工具，但这两者都不包括完全管理的应用程序。VaaS 不是一个标准的云计算模型。参见[第
    2 章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'B: Hybrid cloud integrates both private and public cloud environments for flexibility
    and lower costs. Hybrid cloud allows data and applications to be shared between
    cloud environments, rather than relying solely on on-premises systems. Multitenancy
    is a feature of public clouds. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 混合云将私有和公有云环境集成在一起，以实现灵活性和降低成本。混合云允许在云环境之间共享数据和应用程序，而不是仅仅依赖本地系统。多租户是公有云的一个特性。请参阅[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'B: AWS regions help meet compliance needs by allowing users to store data in
    specific geographic locations. They contain multiple AZs; they do not replace
    them. AWS regions are available worldwide. Computing power is not unlimited, and
    redundancy is a core AWS feature. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: AWS区域通过允许用户在特定地理位置存储数据来帮助满足合规性需求。它们包含多个可用区（AZ），但并不取代它们。AWS区域遍布全球。计算能力并非无限，冗余是AWS的核心特性。请参阅[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'B: AWS Lambda is a serverless compute service that runs code without managing
    infrastructure. Amazon EC2 requires users to manage server instances. Amazon RDS
    is a database service. Amazon CloudFront is a content delivery network (CDN).
    See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: AWS Lambda是一种无服务器计算服务，可以在不管理基础设施的情况下运行代码。Amazon EC2要求用户管理服务器实例。Amazon RDS是一种数据库服务。Amazon
    CloudFront是一种内容分发网络（CDN）。请参阅[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'B: Amazon S3 is designed for object storage, offering scalability, durability,
    and availability. It is not a relational database. Amazon EC2 provides compute
    services. Amazon CloudFront is AWS’s CDN service for delivering content faster.
    See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: Amazon S3是为对象存储而设计的，提供可伸缩性、持久性和可用性。它不是一个关系型数据库。Amazon EC2提供计算服务。Amazon CloudFront是AWS的CDN服务，用于更快地交付内容。请参阅[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)。'
- en: 'B: A confusion matrix helps in evaluating a classification model by showing
    how many predictions were correct and incorrect, specifically analyzing false
    positives and false negatives. It does not track model training time. The number
    of data points used is separate from model evaluation. Additional metrics like
    precision, recall, and F1-score are still needed. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 混淆矩阵有助于通过显示正确和错误的预测数量来评估分类模型，特别是分析假阳性和假阴性。它不跟踪模型训练时间。使用的数据点的数量与模型评估是分开的。还需要额外的指标，如精确度、召回率和F1分数。请参阅[第3章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'C: Real-time inference processes data instantly, making it ideal for fraud
    detection where immediate action is required. Batch inference is used for processing
    large datasets at scheduled intervals. Asynchronous inference is suitable for
    large payloads but not for real-time needs. On-demand inference is for infrequent
    queries rather than continuous fraud monitoring. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 实时推理可以即时处理数据，这使得它在需要立即采取行动的欺诈检测中非常理想。批量推理用于在预定时间间隔处理大量数据集。异步推理适用于大型负载，但不适用于实时需求。按需推理适用于不频繁的查询，而不是持续的欺诈监控。请参阅[第3章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'B: High-dimensional data can lead to increased processing time, memory usage,
    and model overfitting, making it harder to extract meaningful insights. More dimensions
    often require additional tuning to prevent overfitting, and they typically make
    interpretation more difficult, not easier. More features do not always lead to
    higher accuracy. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 高维数据可能导致处理时间增加、内存使用增加以及模型过拟合，这使得提取有意义的见解变得更加困难。更多的维度通常需要额外的调整来防止过拟合，并且它们通常使解释更加困难，而不是更容易。更多的特征并不总是导致更高的准确性。请参阅[第3章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'D: Data drift occurs when the statistical properties of incoming data change
    over time, reducing the model’s accuracy. Overfitting happens when a model performs
    well on training data but poorly on new data, not necessarily due to long-term
    changes. Hyperparameter tuning optimizes a model but does not address changes
    in data distribution over time. Feature engineering errors occur during data preprocessing.
    See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 当输入数据的统计属性随时间变化时，会发生数据漂移，这会降低模型的准确性。当模型在训练数据上表现良好但在新数据上表现不佳时，就会发生过拟合，这不一定是因为长期变化。超参数调整优化模型，但不会解决数据分布随时间变化的问题。特征工程错误发生在数据预处理过程中。见[第
    3 章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'C: SageMaker Model Monitor tracks deployed ML models and alerts users to changes
    in data distribution or concept drift. It does not speed up training. Deployment
    is managed separately in SageMaker, not specifically through Model Monitor. Fine-tuning
    pretrained models is a different ML task and is not the purpose of Model Monitor.
    See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: SageMaker Model Monitor 跟踪已部署的机器学习（ML）模型，并提醒用户注意数据分布或概念漂移的变化。它不会加速训练。在 SageMaker
    中独立管理部署，而不是通过 Model Monitor 进行。微调预训练模型是不同的机器学习任务，并非 Model Monitor 的目的。见[第 3 章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'C: SageMaker Data Wrangler helps automate data preprocessing, feature engineering,
    and transformation for machine learning (ML) models. Amazon Rekognition is for
    image and video analysis. Amazon Textract extracts text from documents. AWS Glue
    is an extract, transform, load (ETL) service. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: SageMaker Data Wrangler 帮助自动化机器学习（ML）模型的数据预处理、特征工程和转换。Amazon Rekognition
    用于图像和视频分析。Amazon Textract 从文档中提取文本。AWS Glue 是一种提取、转换、加载（ETL）服务。见[第 3 章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'B: Amazon Comprehend provides NLP capabilities, including sentiment analysis.
    Amazon Textract extracts text from scanned documents but does not analyze sentiment.
    Lambda is used for serverless computing. SageMaker Feature Store is for storing
    machine learning (ML) model features. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: Amazon Comprehend 提供自然语言处理（NLP）能力，包括情感分析。Amazon Textract 从扫描的文档中提取文本，但不分析情感。Lambda
    用于无服务器计算。SageMaker Feature Store 用于存储机器学习（ML）模型特征。见[第 3 章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'B: Hyperparameter tuning optimizes model performance by adjusting parameters
    such as the learning rate and batch size. It does not generate new data. Data
    preprocessing, not hyperparameter tuning, converts categorical data. Tuning may
    increase training time rather than speed it up. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 超参数调整通过调整学习率、批量大小等参数来优化模型性能。它不会生成新数据。数据预处理，而不是超参数调整，将分类数据转换为其他形式。调整可能会增加训练时间，而不是加快速度。见[第
    3 章](ch03.html#chapter_three_ai_and_machine_learning)。'
- en: 'A: Diffusion models create realistic content by gradually adding and then removing
    noise. They create images, not text or sound. GANs, not diffusion models, use
    competing neural networks. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 扩散模型通过逐渐添加和移除噪声来创建逼真的内容。它们创建图像，而不是文本或声音。GANs，而不是扩散模型，使用竞争性神经网络。见[第 4 章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'B: With fine-tuning, you will change an FM’s parameters based on a proprietary
    dataset, which allows it to be more specialized for a particular domain. Fine-tuning
    actually makes a model more specialized, and does not impact the latency. See
    [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 通过微调，您将根据专有数据集更改 FM 的参数，使其能够针对特定领域进行更专业化的定制。微调实际上使模型更加专业化，并且不会影响延迟。见[第 4
    章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'D: The encoder processes input data into the transformer. It helps to find
    the contextual patterns and relationships. An AI model, not an encoder, creates
    synthetic data. Fine-tuning hyperparameters is a technique to improve the performance
    of a model. You can use benchmarks, not an encoder, to evaluate a model. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 编码器将输入数据处理为转换器。它有助于找到上下文模式和关系。不是编码器，而是 AI 模型创建合成数据。微调超参数是一种提高模型性能的技术。您可以使用基准测试来评估模型，而不是编码器。见[第
    4 章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'C: LLMs have context windows. These fix the amount of text it can process at
    a time. Overfitting is where the model is not able to adequately generalize about
    something. Bias is generally about issues with the underlying dataset. The discriminator
    is a component in a GAN. It does not impact how much data can be processed in
    a large language model. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 大型语言模型（LLM）有上下文窗口。这些窗口固定了它一次可以处理的文本量。过拟合是指模型无法充分泛化关于某事物的情况。偏差通常与底层数据集的问题有关。判别器是GAN中的一个组件。它不会影响大型语言模型中可以处理的数据量。见[第4章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'A: RLHF is focused on improving the responses of a generative AI model by incorporating
    human preferences and feedback. It does not impact the speed of the model and
    it may increase training costs. Deep learning models are usually the core of the
    transformer model, which is when RLHF is used. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: RLHF专注于通过结合人类偏好和反馈来改进生成式AI模型的响应。它不会影响模型的速度，并且可能会增加训练成本。深度学习模型通常是转换器模型的核心，这时会使用RLHF。见[第4章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'B: Multimodal models allow for processing different types of data, such as
    text, images and videos. They usually require large amounts of data. They aren’t
    necessarily more explainable than text-based models. GPUs are critical for multimodal
    FMs because of the need to handle large amounts of data. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 多模态模型允许处理不同类型的数据，如文本、图像和视频。它们通常需要大量的数据。它们并不一定比基于文本的模型更具可解释性。由于需要处理大量数据，GPU对于多模态FM至关重要。见[第4章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'C: The number of parameters in LLMs are usually massive and this means having
    to use sophisticated systems—like GPUs—to handle the processing. RAG does consume
    compute resources, but this is a small part of the overall LLM. LLMs use complex
    linear algebra, but this is not a key reason for the heavy use of compute resources.
    Human feedback and evaluation is a small part of the process for developing an
    LLM. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: LLM中的参数数量通常非常庞大，这意味着需要使用复杂的系统——如GPU——来处理处理。RAG确实会消耗计算资源，但这只是LLM整体中的一部分。LLM使用复杂的线性代数，但这并不是大量使用计算资源的关键原因。人类反馈和评估是开发LLM过程中的一个较小部分。见[第4章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'B: RAG will search a vector database, which has proprietary documents. These
    help to increase the accuracy of the responses. An AI model may have guardrails,
    but this isn’t what RAG does. RAG also doesn’t impact the probability algorithms
    in the transformer model, or rely solely on human supervision. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: RAG将搜索一个包含专有文档的向量数据库。这些有助于提高响应的准确性。AI模型可能有护栏，但这不是RAG所做的事情。RAG也不会影响转换器模型中的概率算法，也不完全依赖于人类监督。见[第4章](ch04.html#chapter_four_understanding_generative_a)。'
- en: 'C: Amazon Lex provides chatbot interactions through the use of intents and
    slot filling. You can use Amazon Fraud Detector for fraud detection, Amazon Rekognition
    for video analysis, and Amazon Textract to extract text from scanned documents.
    See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 亚马逊Lex通过使用意图和槽填充提供聊天机器人交互。您可以使用亚马逊欺诈检测器进行欺诈检测，亚马逊Rekognition进行视频分析，以及亚马逊Textract从扫描的文档中提取文本。见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'A: Amazon Comprehend allows you to analyze text and extract key information.
    Amazon Transcribe converts audio to text, Amazon Polly converts text to speech,
    and Amazon Translate provides language translation. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 亚马逊Comprehend允许您分析文本并提取关键信息。亚马逊Transcribe将音频转换为文本，亚马逊Polly将文本转换为语音，亚马逊Translate提供语言翻译。见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'D: Amazon Rekognition is for analyzing images and videos. Amazon Transcribe
    allows for speech-to-text conversion. OCR is a core feature of Amazon Textract.
    You can create AI chatbots with Amazon Lex. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 亚马逊Rekognition用于分析图像和视频。亚马逊Transcribe允许语音转文本转换。OCR是亚马逊Textract的核心功能。您可以使用亚马逊Lex创建AI聊天机器人。见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'C: Lemmatization is an NLP technique for preprocessing that helps AI models
    understand words more effectively. NLP models usually do not automatically correct
    grammar. Translation is not a preprocessing step in NLP. Deepfake detection is
    used for media verification. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 词形还原是自然语言处理（NLP）预处理技术之一，有助于AI模型更有效地理解词语。NLP模型通常不会自动纠正语法。翻译不是NLP中的预处理步骤。深度伪造检测用于媒体验证。参见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'D: Stopword removal eliminates words that have little meaning. Uncommon words
    are often more informative than stopwords, so NLP will often focus more on them.
    Stopwords are not removed to reduce text length. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 停用词去除法消除了那些意义不大的词。不常见的词通常比停用词更有信息量，因此自然语言处理（NLP）通常会更多地关注它们。停用词不会被去除以减少文本长度。参见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'D: If a task can be handled with traditional software, using AI may be unnecessary
    and expensive. AI can work quite well in cloud environments. And while human oversight
    is important, AI can function independently in many cases. AI can also handle
    complex tasks, not just simple automation. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 如果一个任务可以用传统软件处理，使用AI可能是不必要的且昂贵的。AI在云环境中可以非常有效地工作。虽然人类监督很重要，但在许多情况下AI可以独立运行。AI还可以处理复杂任务，而不仅仅是简单的自动化。参见[第5章](ch05.html#chapter_five_real_world_ai_applications)。'
- en: 'D: This feature allows you to evaluate the responses of two different models,
    but it does not combine text and image responses or responses from two models.
    It also does not impact the length of the responses. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 此功能允许你评估两个不同模型的响应，但它不会结合文本和图像响应或来自两个模型的响应。它也不会影响响应的长度。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'C: Fine-tuning customizes a model for specialized use cases using labeled data.
    Fine-tuning may actually increase compute costs because of the extra training
    required, and it will not improve latency. You would not use fine-tuning in Bedrock
    for images. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 微调使用标记数据定制模型以用于特定用例。由于需要额外的训练，微调实际上可能会增加计算成本，并且不会改善延迟。你不会在Bedrock中为图像使用微调。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'C: Open source models provide access to the code, allowing for customization.
    There is also the benefit of innovation from a community of contributors. Bedrock
    will still charge for hosting the model on AWS. You can specify real-time inference
    but it is not set by default. While the codebase may be available, this may not
    be the case for the datasets. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 开源模型提供了访问代码的权限，允许进行定制。还有来自贡献者社区的创新优势。Bedrock仍然会为在AWS上托管模型收费。你可以指定实时推理，但默认情况下并未设置。虽然代码库可能可用，但数据集可能并非如此。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'A: This type of model uses less power and has a smaller footprint, which makes
    it better for edge devices. The context window would likely be smaller as the
    model is smaller. This type of model does not mean that the responses will be
    more creative. The accuracy of larger models will likely be higher. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 此类模型功耗更低，占用空间更小，更适合边缘设备。由于模型较小，上下文窗口可能也会更小。这种类型的模型并不意味着响应会更加有创意。较大模型的准确性可能更高。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'C: Each agent specializes in a certain area, which helps improve the responses.
    You can use any type of AI model in Bedrock. Because generative AI is based on
    probabilities, there is no guarantee of 100% accuracy. Multiagent collaboration
    is not about editing model weights and biases. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 每个代理都专注于某个特定领域，这有助于提高响应质量。你可以在Bedrock中使用任何类型的AI模型。因为生成式AI基于概率，所以不能保证100%的准确性。多代理协作并不是关于编辑模型权重和偏差。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'D: The cost advantages can be considerable, up to 50% compared to on-demand
    processing, but latency is usually high. Batch processing is not related to the
    context window and it will not impact accuracy rates of the model. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 成本优势可能相当可观，与按需处理相比，高达50%，但延迟通常很高。批量处理与上下文窗口无关，它不会影响模型的准确率。参见[第6章](ch06.html#chapter_six_building_with_amazon_bedroc)。'
- en: 'D: Prompt templates provide reusable structures that promote clarity and efficiency.
    Few-shot prompting means a prompt has had examples added. Zero-shot prompting
    is quick but often less consistent. Chain-of-thought prompting helps with reasoning,
    but not consistency across prompts. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 提示模板提供可重用的结构，以促进清晰和效率。少样本提示意味着提示中已添加示例。零样本提示快速但通常一致性较差。思维链提示有助于推理，但不会影响提示的一致性。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'C: CoT prompting breaks down reasoning into smaller steps. Few-shot prompting
    specifies which examples to use. Output length limits the response of the LLM.
    Prompting doesn’t adjust model parameters. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 思维链提示将推理分解成更小的步骤。少样本提示指定要使用哪些示例。输出长度限制了LLM的响应。提示不会调整模型参数。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'C: Few-shot prompting provides examples so the model can learn the patterns.
    Zero-shot prompting uses no examples. CoT prompting focuses on step-by-step logic.
    Template prompting structures the prompt, but doesn’t necessarily include examples.
    See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 少样本提示提供示例，以便模型可以学习模式。零样本提示不使用示例。思维链提示关注逐步逻辑。模板提示结构化提示，但不一定包括示例。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'B: Model poisoning is where an attacker maliciously alters training data to
    produce unethical or harmful outputs. Data exposure allows a model to process
    personal health data. Licensing is a legal issue. Conflicting instructions can
    confuse a model, but this isn’t considered poisoning. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 模型中毒是指攻击者恶意篡改训练数据以产生不道德或有害的输出。数据暴露允许模型处理个人健康数据。许可是一个法律问题。冲突的指令可能会使模型困惑，但这不被视为中毒。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'C: Exposure is when confidential or regulated information is leaked because
    it was part of the training data. Public use may carry risks but is not exposure
    by itself. The loss of GPU performance during training is a hardware issue. The
    failure to generate output within token limits is unrelated to privacy or data
    security. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 暴露是指由于训练数据的一部分是机密或受监管的信息而泄露。公共使用可能存在风险，但本身并不构成暴露。训练过程中GPU性能的损失是硬件问题。在令牌限制内无法生成输出与隐私或数据安全无关。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'D: Jailbreaking uses indirect or tricky prompts to override model guardrails.
    Hardware limitations are not related to jailbreaking. Resetting a model’s API
    token is an API access issue. Models don’t retain session history unless designed
    for it. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 解锁使用间接或复杂的提示来绕过模型的安全防护。硬件限制与解锁无关。重置模型的API令牌是API访问问题。除非设计用于保留会话历史，否则模型不会保留会话历史。参见[第7章](ch07.html#chapter_seven_a_guide_to_prompt_enginee)。'
- en: 'B: Governance ensures responsible AI practices through policy and oversight.
    AI governance is not about marketing or IP concerns, and it is not a technical
    methodology. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 管理确保通过政策和监督实施负责任的AI实践。AI管理不涉及营销或知识产权问题，也不是一种技术方法。参见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'C: Controllability ensures AI can be guided and monitored by humans. Cost is
    not a key issue in controllability and speed is unrelated to human control. See
    [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 可控性确保AI可以被人类指导和监控。成本不是可控性的关键问题，速度与人类控制无关。参见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'A: Responsible AI builds trust and boosts brand image, which can lead to improved
    user engagement. Data collection is still essential. Responsible AI aims to improve
    automation and reduce risk, although it cannot eliminate all errors. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 负责任的人工智能建立信任并提升品牌形象，这可以导致用户参与度的提高。数据收集仍然是必不可少的。负责任的人工智能旨在提高自动化并降低风险，尽管它不能消除所有错误。见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'C: SageMaker Clarify highlights bias and helps explain model decisions. It
    does not scan for URLs and is not designed for cost management. Data encryption
    is handled by other AWS tools. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: SageMaker Clarify 突出显示偏差并帮助解释模型决策。它不扫描URL，也不是为成本管理而设计的。数据加密由其他AWS工具处理。见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'D: It supports human review in tasks like content moderation and translation.
    It is not focused on model training speed and does not generate data. GPU management
    is outside the scope of Amazon A2I. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 它支持在内容审核和翻译等任务中进行人工审查。它不关注模型训练速度，也不生成数据。GPU管理不在Amazon A2I的范围内。见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'C: RLHF uses human input to guide AI behavior in complex scenarios. It supplements,
    but doesn’t replace, model updates. RLHF helps systems adapt, not stay static.
    It still involves some form of labeling or feedback. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: RLHF 使用人类输入来引导AI在复杂场景中的行为。它补充但不取代模型更新。RLHF帮助系统适应，而不是保持静态。它仍然涉及某种形式的标记或反馈。见[第8章](ch08.html#chapter_eight_a_framework_for_responsib)。'
- en: 'B: Emergent capabilities are unexpected behaviors that can create new compliance
    risks. They don’t involve strict feature following. AI systems do not autonomously
    handle regulatory reporting. Human oversight remains essential for compliant AI
    operations. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 意外能力是指可能产生新的合规风险的不预期行为。它们不涉及严格遵循功能。AI系统不会自主处理监管报告。人类监督对于合规的AI操作仍然是必不可少的。见[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'D: Regulated workloads must comply with legal, industry, or safety standards.
    They typically involve fields like healthcare, finance, or aerospace—not gaming.
    They prioritize safety, security, and accountability, not just speed. Compliance
    involves much more than encryption; it covers processes, oversight, and decision
    making. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 受监管的工作负载必须遵守法律、行业或安全标准。它们通常涉及医疗保健、金融或航空航天等领域——而不是游戏。它们优先考虑安全、安全和问责制，而不仅仅是速度。合规性远不止加密；它涵盖了流程、监督和决策。见[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'B: Logging provides critical information for tracing, auditing, and improving
    model performance. Data logging is separate from data residency. Logs support
    diagnosis and improvement, but they cannot guarantee perfect accuracy. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'B: 记录提供用于跟踪、审计和改进模型性能的关键信息。数据记录与数据驻留分开。日志支持诊断和改进，但它们不能保证完美的准确性。见[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'A: AWS Config tracks resource setups over time and helps audit changes. AWS
    Trusted Advisor offers recommendations. Amazon Inspector focuses on vulnerability
    scanning. AWS Artifact provides compliance documents. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: AWS Config 跟踪资源设置随时间的变化并帮助审计变更。AWS Trusted Advisor 提供建议。Amazon Inspector
    专注于漏洞扫描。AWS Artifact 提供合规性文件。见[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'D: Scope 1 refers to using public generative AI tools like ChatGPT without
    backend access. Pretrained models involve building apps with existing models,
    not just using public tools. Fine-tuned models require adapting a model with your
    own data, not simple usage. Self-trained models involve building everything from
    scratch. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 范围1指的是使用ChatGPT等公共生成式AI工具而不需要后端访问。预训练模型涉及使用现有模型构建应用程序，而不仅仅是使用公共工具。微调模型需要使用自己的数据调整模型，而不仅仅是简单使用。自训练模型涉及从头开始构建一切。见[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'C: Amazon Macie uses ML to identify and classify sensitive data like PII and
    PHI. Verified Permissions helps implement fine-grained access control. Shield
    Advanced focuses on protecting against DDoS attacks. SageMaker Role Manager assists
    in setting IAM roles for ML projects. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 亚马逊Macie利用机器学习来识别和分类敏感数据，如PII和PHI。已验证权限有助于实现细粒度访问控制。Shield Advanced专注于防止DDoS攻击。SageMaker角色管理器协助为ML项目设置IAM角色。请参阅[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'C: Model cards provide a structured summary of a model’s data origins, usage
    guidelines, risks, and limitations. They don’t trigger retraining. Managing access
    controls is a separate function handled by IAM or similar services. Compute optimization
    is unrelated to the purpose of model documentation. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'C: 模型卡提供了模型数据来源、使用指南、风险和限制的结构化摘要。它们不会触发重新训练。管理访问控制是IAM或类似服务处理的独立功能。计算优化与模型文档的目的无关。请参阅[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
- en: 'D: Customers and end users always retain control over the data they input into
    the system. Application providers may control other types of data, but not user
    inputs. The cloud provider hosts infrastructure but doesn’t control user data.
    Data annotation teams label training data but don’t control user-generated inputs.
    See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'D: 客户和最终用户始终对其输入系统的数据进行控制。应用提供商可能控制其他类型的数据，但不能控制用户输入。云服务提供商托管基础设施，但不控制用户数据。数据标注团队对训练数据进行标注，但不控制用户生成的内容。请参阅[第9章](ch09.html#chapter_nine_securitycomma_complianceco)。'
