- en: Chapter 3\. Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。分类
- en: In [Chapter 1](ch01.html#landscape_chapter) I mentioned that the most common
    supervised learning tasks are regression (predicting values) and classification
    (predicting classes). In [Chapter 2](ch02.html#project_chapter) we explored a
    regression task, predicting housing values, using various algorithms such as linear
    regression, decision trees, and random forests (which will be explained in further
    detail in later chapters). Now we will turn our attention to classification systems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.html#landscape_chapter)中，我提到最常见的监督学习任务是回归（预测值）和分类（预测类）。在[第2章](ch02.html#project_chapter)中，我们探讨了一个回归任务，使用各种算法（如线性回归、决策树和随机森林）来预测房屋价值（这将在后面的章节中进一步详细解释）。现在我们将把注意力转向分类系统。
- en: MNIST
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST
- en: 'In this chapter we will be using the MNIST dataset, which is a set of 70,000
    small images of digits handwritten by high school students and employees of the
    US Census Bureau. Each image is labeled with the digit it represents. This set
    has been studied so much that it is often called the “hello world” of machine
    learning: whenever people come up with a new classification algorithm they are
    curious to see how it will perform on MNIST, and anyone who learns machine learning
    tackles this dataset sooner or later.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用MNIST数据集，这是由美国人口普查局的高中学生和员工手写的70,000张小数字图像集。每个图像都带有它代表的数字标签。这个数据集已经被研究了很多次，通常被称为机器学习的“hello
    world”：每当人们提出一个新的分类算法时，他们都很好奇它在MNIST上的表现如何，任何学习机器学习的人迟早都会处理这个数据集。
- en: Scikit-Learn provides many helper functions to download popular datasets. MNIST
    is one of them. The following code fetches the MNIST dataset from OpenML.org:⁠^([1](ch03.html#idm45720235827040))
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn提供许多辅助函数来下载流行的数据集。MNIST就是其中之一。以下代码从OpenML.org获取MNIST数据集：^([1](ch03.html#idm45720235827040))
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `sklearn.datasets` package contains mostly three types of functions: `fetch_*`
    functions such as `fetch_openml()` to download real-life datasets, `load_*` functions
    to load small toy datasets bundled with Scikit-Learn (so they don’t need to be
    downloaded over the internet), and `make_*` functions to generate fake datasets,
    useful for tests. Generated datasets are usually returned as an `(X, y)` tuple
    containing the input data and the targets, both as NumPy arrays. Other datasets
    are returned as `sklearn.utils.Bunch` objects, which are dictionaries whose entries
    can also be accessed as attributes. They generally contain the following entries:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.datasets`包主要包含三种类型的函数：`fetch_*`函数，如`fetch_openml()`用于下载真实数据集，`load_*`函数用于加载与Scikit-Learn捆绑的小型玩具数据集（因此不需要通过互联网下载），以及`make_*`函数用于生成虚假数据集，对测试很有用。生成的数据集通常作为包含输入数据和目标的`(X,
    y)`元组返回，都作为NumPy数组。其他数据集作为`sklearn.utils.Bunch`对象返回，这些对象是字典，其条目也可以作为属性访问。它们通常包含以下条目：'
- en: '`"DESCR"`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “DESCR”
- en: A description of the dataset
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集描述
- en: '`"data"`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “数据”
- en: The input data, usually as a 2D NumPy array
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据，通常作为2D NumPy数组
- en: '`"target"`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “目标”
- en: The labels, usually as a 1D NumPy array
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 标签，通常作为1D NumPy数组
- en: 'The `fetch_openml()` function is a bit unusual since by default it returns
    the inputs as a Pandas DataFrame and the labels as a Pandas Series (unless the
    dataset is sparse). But the MNIST dataset contains images, and DataFrames aren’t
    ideal for that, so it’s preferable to set `as_frame=False` to get the data as
    NumPy arrays instead. Let’s look at these arrays:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`fetch_openml()`函数有点不同，因为默认情况下它将输入返回为Pandas DataFrame，将标签返回为Pandas Series（除非数据集是稀疏的）。但是MNIST数据集包含图像，而DataFrame并不理想，因此最好设置`as_frame=False`以将数据作为NumPy数组获取。让我们看看这些数组：'
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There are 70,000 images, and each image has 784 features. This is because each
    image is 28 × 28 pixels, and each feature simply represents one pixel’s intensity,
    from 0 (white) to 255 (black). Let’s take a peek at one digit from the dataset
    ([Figure 3-1](#some_digit_plot)). All we need to do is grab an instance’s feature
    vector, reshape it to a 28 × 28 array, and display it using Matplotlib’s `imshow()`
    function. We use `cmap="binary"` to get a grayscale color map where 0 is white
    and 255 is black:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 共有70,000张图像，每张图像有784个特征。这是因为每个图像是28×28像素，每个特征只是表示一个像素的强度，从0（白色）到255（黑色）。让我们看一下数据集中的一个数字（[图3-1](#some_digit_plot)）。我们只需要获取一个实例的特征向量，将其重塑为28×28数组，并使用Matplotlib的`imshow()`函数显示它。我们使用`cmap="binary"`来获取一个灰度色图，其中0是白色，255是黑色：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![mls3 0301](assets/mls3_0301.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0301](assets/mls3_0301.png)'
- en: Figure 3-1\. Example of an MNIST image
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1。MNIST图像示例
- en: 'This looks like a 5, and indeed that’s what the label tells us:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像一个5，事实上标签告诉我们是这样的：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To give you a feel for the complexity of the classification task, [Figure 3-2](#more_digits_plot)
    shows a few more images from the MNIST dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让您感受分类任务的复杂性，[图3-2](#more_digits_plot)显示了MNIST数据集中的更多图像。
- en: But wait! You should always create a test set and set it aside before inspecting
    the data closely. The MNIST dataset returned by `fetch_openml()` is actually already
    split into a training set (the first 60,000 images) and a test set (the last 10,000
    images):^([2](ch03.html#idm45720239036336))
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但是！在仔细检查数据之前，您应该始终创建一个测试集并将其放在一边。`fetch_openml()`返回的MNIST数据集实际上已经分为训练集（前60,000张图像）和测试集（最后10,000张图像）：^([2](ch03.html#idm45720239036336))
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The training set is already shuffled for us, which is good because this guarantees
    that all cross-validation folds will be similar (we don’t want one fold to be
    missing some digits). Moreover, some learning algorithms are sensitive to the
    order of the training instances, and they perform poorly if they get many similar
    instances in a row. Shuffling the dataset ensures that this won’t happen.⁠^([3](ch03.html#idm45720238991712))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集已经为我们洗牌，这很好，因为这保证了所有交叉验证折叠将是相似的（我们不希望一个折叠缺少一些数字）。此外，一些学习算法对训练实例的顺序敏感，如果它们连续获得许多相似实例，则表现会很差。洗牌数据集确保这种情况不会发生。^([3](ch03.html#idm45720238991712))
- en: '![mls3 0302](assets/mls3_0302.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0302](assets/mls3_0302.png)'
- en: Figure 3-2\. Digits from the MNIST dataset
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2。来自MNIST数据集的数字
- en: Training a Binary Classifier
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练二元分类器
- en: 'Let’s simplify the problem for now and only try to identify one digit—for example,
    the number 5\. This “5-detector” will be an example of a *binary classifier*,
    capable of distinguishing between just two classes, 5 and non-5\. First we’ll
    create the target vectors for this classification task:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们简化问题，只尝试识别一个数字，例如数字5。这个“5检测器”将是一个*二元分类器*的示例，能够区分只有两个类别的5和非5。首先，我们将为这个分类任务创建目标向量：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now let’s pick a classifier and train it. A good place to start is with a *stochastic
    gradient descent* (SGD, or stochastic GD) classifier, using Scikit-Learn’s `SGDClassifier`
    class. This classifier is capable of handling very large datasets efficiently.
    This is in part because SGD deals with training instances independently, one at
    a time, which also makes SGD well suited for online learning, as you will see
    later. Let’s create an `SGDClassifier` and train it on the whole training set:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们选择一个分类器并对其进行训练。一个很好的开始地方是使用*随机梯度下降*（SGD，或随机GD）分类器，使用Scikit-Learn的`SGDClassifier`类。这个分类器能够高效处理非常大的数据集。部分原因是因为SGD独立处理训练实例，一次一个，这也使得SGD非常适合在线学习，稍后您将看到。让我们创建一个`SGDClassifier`并在整个训练集上对其进行训练：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can use it to detect images of the number 5:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用它来检测数字5的图像：
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The classifier guesses that this image represents a 5 (`True`). Looks like it
    guessed right in this particular case! Now, let’s evaluate this model’s performance.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器猜测这幅图像代表数字5（“True”）。在这种特殊情况下，看起来它猜对了！现在，让我们评估这个模型的性能。
- en: Performance Measures
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能指标
- en: Evaluating a classifier is often significantly trickier than evaluating a regressor,
    so we will spend a large part of this chapter on this topic. There are many performance
    measures available, so grab another coffee and get ready to learn a bunch of new
    concepts and acronyms!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分类器通常比评估回归器要困难得多，因此我们将在本章的大部分时间中讨论这个主题。有许多性能指标可用，所以抓杯咖啡，准备学习一堆新概念和首字母缩略词！
- en: Measuring Accuracy Using Cross-Validation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用交叉验证测量准确率
- en: 'A good way to evaluate a model is to use cross-validation, just as you did
    in [Chapter 2](ch02.html#project_chapter). Let’s use the `cross_val_score()` function
    to evaluate our `SGDClassifier` model, using *k*-fold cross-validation with three
    folds. Remember that *k*-fold cross-validation means splitting the training set
    into *k* folds (in this case, three), then training the model *k* times, holding
    out a different fold each time for evaluation (see [Chapter 2](ch02.html#project_chapter)):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型的一个好方法是使用交叉验证，就像您在[第2章](ch02.html#project_chapter)中所做的那样。让我们使用`cross_val_score()`函数来评估我们的`SGDClassifier`模型，使用三折交叉验证。请记住，*k*-fold交叉验证意味着将训练集分成*k*折（在本例中为三折），然后训练模型*k*次，每次保留一个不同的折叠用于评估（参见[第2章](ch02.html#project_chapter)）：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Wow! Above 95% accuracy (ratio of correct predictions) on all cross-validation
    folds? This looks amazing, doesn’t it? Well, before you get too excited, let’s
    look at a dummy classifier that just classifies every single image in the most
    frequent class, which in this case is the negative class (i.e., *non* 5):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！在所有交叉验证折叠中超过95％的准确率（正确预测的比例）？看起来很惊人，不是吗？好吧，在你太兴奋之前，让我们看一个只将每个图像分类为最频繁类别的虚拟分类器，这种情况下是负类别（即*非*
    5）：
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Can you guess this model’s accuracy? Let’s find out:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您能猜到这个模型的准确率吗？让我们找出来：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: That’s right, it has over 90% accuracy! This is simply because only about 10%
    of the images are 5s, so if you always guess that an image is *not* a 5, you will
    be right about 90% of the time. Beats Nostradamus.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 没错，它的准确率超过90％！这仅仅是因为大约10％的图像是5，所以如果您总是猜测一幅图像*不*是5，您将有90％的准确率。胜过诺斯特拉达姆。
- en: This demonstrates why accuracy is generally not the preferred performance measure
    for classifiers, especially when you are dealing with *skewed datasets* (i.e.,
    when some classes are much more frequent than others). A much better way to evaluate
    the performance of a classifier is to look at the *confusion matrix* (CM).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明为什么准确率通常不是分类器的首选性能指标，特别是当您处理*倾斜数据集*（即某些类别比其他类别更频繁时）。评估分类器性能的一个更好方法是查看*混淆矩阵*（CM）。
- en: Confusion Matrices
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'The general idea of a confusion matrix is to count the number of times instances
    of class A are classified as class B, for all A/B pairs. For example, to know
    the number of times the classifier confused images of 8s with 0s, you would look
    at row #8, column #0 of the confusion matrix.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的一般思想是计算类A的实例被分类为类B的次数，对于所有A/B对。例如，要知道分类器将8的图像误判为0的次数，您将查看混淆矩阵的第8行，第0列。
- en: 'To compute the confusion matrix, you first need to have a set of predictions
    so that they can be compared to the actual targets. You could make predictions
    on the test set, but it’s best to keep that untouched for now (remember that you
    want to use the test set only at the very end of your project, once you have a
    classifier that you are ready to launch). Instead, you can use the `cross_val_predict()`
    function:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 计算混淆矩阵，首先需要一组预测结果，以便与实际目标进行比较。您可以对测试集进行预测，但最好现在保持不变（记住，您只想在项目的最后阶段使用测试集，一旦您准备启动分类器）。相反，您可以使用`cross_val_predict()`函数：
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Just like the `cross_val_score()` function, `cross_val_predict()` performs
    *k*-fold cross-validation, but instead of returning the evaluation scores, it
    returns the predictions made on each test fold. This means that you get a clean
    prediction for each instance in the training set (by “clean” I mean “out-of-sample”:
    the model makes predictions on data that it never saw during training).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`cross_val_score()`函数一样，`cross_val_predict()`执行*k*-fold交叉验证，但不返回评估分数，而是返回在每个测试折叠上做出的预测。这意味着您可以获得训练集中每个实例的干净预测（“干净”是指“样本外”：模型对训练期间从未见过的数据进行预测）。
- en: 'Now you are ready to get the confusion matrix using the `confusion_matrix()`
    function. Just pass it the target classes (`y_train_5`) and the predicted classes
    (`y_train_pred`):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好使用`confusion_matrix()`函数获取混淆矩阵。只需将目标类（`y_train_5`）和预测类（`y_train_pred`）传递给它：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Each row in a confusion matrix represents an *actual class*, while each column
    represents a *predicted class*. The first row of this matrix considers non-5 images
    (the *negative class*): 53,892 of them were correctly classified as non-5s (they
    are called *true negatives*), while the remaining 687 were wrongly classified
    as 5s (*false positives*, also called *type I errors*). The second row considers
    the images of 5s (the *positive class*): 1,891 were wrongly classified as non-5s
    (*false negatives*, also called *type II errors*), while the remaining 3,530 were
    correctly classified as 5s (*true positives*). A perfect classifier would only
    have true positives and true negatives, so its confusion matrix would have nonzero
    values only on its main diagonal (top left to bottom right):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵中的每一行代表一个*实际类别*，而每一列代表一个*预测类别*。该矩阵的第一行考虑了非5的图像（*负类*）：其中53,892个被正确分类为非5（称为*真负例*），而剩下的687个被错误分类为5（*假正例*，也称为*类型I错误*）。第二行考虑了5的图像（*正类*）：其中1,891个被错误分类为非5（*假阴性*，也称为*类型II错误*），而剩下的3,530个被正确分类为5（*真正例*）。一个完美的分类器只会有真正例和真负例，因此其混淆矩阵只会在其主对角线上有非零值（从左上到右下）：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The confusion matrix gives you a lot of information, but sometimes you may prefer
    a more concise metric. An interesting one to look at is the accuracy of the positive
    predictions; this is called the *precision* of the classifier ([Equation 3-1](#equation_three_one)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵提供了很多信息，但有时您可能更喜欢一个更简洁的指标。一个有趣的指标是正预测的准确率；这被称为分类器的*精度*（[方程3-1](#equation_three_one)）。
- en: Equation 3-1\. Precision
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程3-1。精度
- en: <math display="block"><mrow><mtext>precision</mtext> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow></math>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mtext>精度</mtext> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow></math>
- en: '*TP* is the number of true positives, and *FP* is the number of false positives.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*TP*是真正例的数量，*FP*是假正例的数量。'
- en: 'A trivial way to have perfect precision is to create a classifier that always
    makes negative predictions, except for one single positive prediction on the instance
    it’s most confident about. If this one prediction is correct, then the classifier
    has 100% precision (precision = 1/1 = 100%). Obviously, such a classifier would
    not be very useful, since it would ignore all but one positive instance. So, precision
    is typically used along with another metric named *recall*, also called *sensitivity*
    or the *true positive rate* (TPR): this is the ratio of positive instances that
    are correctly detected by the classifier ([Equation 3-2](#equation_three_two)).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 实现完美精度的一个微不足道的方法是创建一个分类器，总是做出负预测，除了在它最有信心的实例上做出一个单一的正预测。如果这一个预测是正确的，那么分类器的精度就是100%（精度=1/1=100%）。显然，这样的分类器不会很有用，因为它会忽略除了一个正实例之外的所有实例。因此，精度通常与另一个指标一起使用，该指标称为*召回率*，也称为*敏感度*或*真正例率*（TPR）：这是分类器正确检测到的正实例的比率（[方程3-2](#equation_three_two)）。
- en: Equation 3-2\. Recall
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程3-2。回想一下
- en: <math display="block"><mrow><mtext>recall</mtext> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></math>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mtext>召回率</mtext> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow></math>
- en: '*FN* is, of course, the number of false negatives.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*FN*，当然，是假阴性的数量。'
- en: If you are confused about the confusion matrix, [Figure 3-3](#confusion_matrix_diagram)
    may help.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对混淆矩阵感到困惑，[图3-3](#confusion_matrix_diagram)可能会有所帮助。
- en: '![mls3 0303](assets/mls3_0303.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0303](assets/mls3_0303.png)'
- en: Figure 3-3\. An illustrated confusion matrix showing examples of true negatives
    (top left), false positives (top right), false negatives (lower left), and true
    positives (lower right)
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3。一个说明混淆矩阵的示例，显示真负例（左上）、假正例（右上）、假阴性（左下）和真正例（右下）
- en: Precision and Recall
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精度和召回率
- en: 'Scikit-Learn provides several functions to compute classifier metrics, including
    precision and recall:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn提供了几个函数来计算分类器的指标，包括精度和召回率：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now our 5-detector does not look as shiny as it did when we looked at its accuracy.
    When it claims an image represents a 5, it is correct only 83.7% of the time.
    Moreover, it only detects 65.1% of the 5s.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的5检测器看起来并不像我们在查看其准确性时那么出色。当它声称一幅图像代表5时，它只有83.7%的时间是正确的。此外，它只能检测到65.1%的5。
- en: It is often convenient to combine precision and recall into a single metric
    called the *F[1] score*, especially when you need a single metric to compare two
    classifiers. The F[1] score is the *harmonic mean* of precision and recall ([Equation
    3-3](#equation_three_three)). Whereas the regular mean treats all values equally,
    the harmonic mean gives much more weight to low values. As a result, the classifier
    will only get a high F[1] score if both recall and precision are high.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通常方便将精度和召回率结合成一个称为*F[1]分数*的单一指标，特别是当您需要一个单一指标来比较两个分类器时。 F[1]分数是精度和召回率的*调和平均*（[方程3-3](#equation_three_three)）。而普通平均值对所有值都一视同仁，调和平均值更加重视低值。因此，只有当召回率和精度都很高时，分类器才会获得高的F[1]分数。
- en: Equation 3-3\. F[1] score
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程3-3。F[1]分数
- en: <math display="block"><mrow><msub><mi mathvariant="italic">F</mi> <mn>1</mn></msub>
    <mo>=</mo> <mfrac><mn>2</mn> <mrow><mfrac><mn>1</mn> <mtext>precision</mtext></mfrac><mo>+</mo><mfrac><mn>1</mn>
    <mtext>recall</mtext></mfrac></mrow></mfrac> <mo>=</mo> <mn>2</mn> <mo>×</mo>
    <mfrac><mrow><mtext>precision</mtext><mo>×</mo><mtext>recall</mtext></mrow> <mrow><mtext>precision</mtext><mo>+</mo><mtext>recall</mtext></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mfrac><mrow><mi>F</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow>
    <mn>2</mn></mfrac></mrow></mfrac></mrow></math>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><msub><mi mathvariant="italic">F</mi> <mn>1</mn></msub>
    <mo>=</mo> <mfrac><mn>2</mn> <mrow><mfrac><mn>1</mn> <mtext>精度</mtext></mfrac><mo>+</mo><mfrac><mn>1</mn>
    <mtext>召回率</mtext></mfrac></mrow></mfrac> <mo>=</mo> <mn>2</mn> <mo>×</mo> <mfrac><mrow><mtext>精度</mtext><mo>×</mo><mtext>召回率</mtext></mrow>
    <mrow><mtext>精度</mtext><mo>+</mo><mtext>召回率</mtext></mrow></mfrac> <mo>=</mo>
    <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mfrac><mrow><mi>F</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow>
    <mn>2</mn></mfrac></mrow></mfrac></mrow></math>
- en: 'To compute the F[1] score, simply call the `f1_score()` function:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算F[1]分数，只需调用`f1_score()`函数：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The F[1] score favors classifiers that have similar precision and recall. This
    is not always what you want: in some contexts you mostly care about precision,
    and in other contexts you really care about recall. For example, if you trained
    a classifier to detect videos that are safe for kids, you would probably prefer
    a classifier that rejects many good videos (low recall) but keeps only safe ones
    (high precision), rather than a classifier that has a much higher recall but lets
    a few really bad videos show up in your product (in such cases, you may even want
    to add a human pipeline to check the classifier’s video selection). On the other
    hand, suppose you train a classifier to detect shoplifters in surveillance images:
    it is probably fine if your classifier only has 30% precision as long as it has
    99% recall (sure, the security guards will get a few false alerts, but almost
    all shoplifters will get caught).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: F[1]分数偏向于具有类似精度和召回率的分类器。这并不总是你想要的：在某些情境下，你更关心精度，而在其他情境下，你真的很在意召回率。例如，如果你训练一个用于检测适合儿童观看的视频的分类器，你可能更喜欢一个拒绝许多好视频（低召回率）但仅保留安全视频（高精度）的分类器，而不是一个召回率更高但让一些非常糟糕的视频出现在你的产品中的分类器（在这种情况下，你甚至可能想添加一个人工流水线来检查分类器的视频选择）。另一方面，假设你训练一个用于在监控图像中检测扒手的分类器：如果你的分类器只有30%的精度，只要召回率达到99%就可以了（当然，保安人员会收到一些错误警报，但几乎所有扒手都会被抓住）。
- en: 'Unfortunately, you can’t have it both ways: increasing precision reduces recall,
    and vice versa. This is called the *precision/recall trade-off*.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，你不能两全其美：提高精度会降低召回率，反之亦然。这被称为*精度/召回率权衡*。
- en: The Precision/Recall Trade-off
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精度/召回率权衡
- en: 'To understand this trade-off, let’s look at how the `SGDClassifier` makes its
    classification decisions. For each instance, it computes a score based on a *decision
    function*. If that score is greater than a threshold, it assigns the instance
    to the positive class; otherwise it assigns it to the negative class. [Figure 3-4](#decision_threshold_diagram)
    shows a few digits positioned from the lowest score on the left to the highest
    score on the right. Suppose the *decision threshold* is positioned at the central
    arrow (between the two 5s): you will find 4 true positives (actual 5s) on the
    right of that threshold, and 1 false positive (actually a 6). Therefore, with
    that threshold, the precision is 80% (4 out of 5). But out of 6 actual 5s, the
    classifier only detects 4, so the recall is 67% (4 out of 6). If you raise the
    threshold (move it to the arrow on the right), the false positive (the 6) becomes
    a true negative, thereby increasing the precision (up to 100% in this case), but
    one true positive becomes a false negative, decreasing recall down to 50%. Conversely,
    lowering the threshold increases recall and reduces precision.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这种权衡，让我们看看`SGDClassifier`是如何做出分类决策的。对于每个实例，它根据*决策函数*计算得分。如果该得分大于阈值，则将实例分配给正类；否则将其分配给负类。[图3-4](#decision_threshold_diagram)显示了一些数字，从最低得分的左侧到最高得分的右侧。假设*决策阈值*位于中间箭头处（两个5之间）：你会发现在该阈值右侧有4个真正例（实际为5），以及1个假正例（实际上是6）。因此，使用该阈值，精度为80%（5个中的4个）。但在6个实际为5的情况下，分类器只检测到4个，因此召回率为67%（6个中的4个）。如果提高阈值（将其移动到右侧的箭头处），假正例（6）变为真负例，从而增加精度（在这种情况下最高可达100%），但一个真正例变为假负例，将召回率降低到50%。相反，降低阈值会增加召回率并降低精度。
- en: '![mls3 0304](assets/mls3_0304.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0304](assets/mls3_0304.png)'
- en: 'Figure 3-4\. The precision/recall trade-off: images are ranked by their classifier
    score, and those above the chosen decision threshold are considered positive;
    the higher the threshold, the lower the recall, but (in general) the higher the
    precision'
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-4。精度/召回率权衡：图像按其分类器得分排名，高于所选决策阈值的图像被视为正例；阈值越高，召回率越低，但（一般而言）精度越高
- en: 'Scikit-Learn does not let you set the threshold directly, but it does give
    you access to the decision scores that it uses to make predictions. Instead of
    calling the classifier’s `predict()` method, you can call its `decision_function()`
    method, which returns a score for each instance, and then use any threshold you
    want to make predictions based on those scores:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn不允许直接设置阈值，但它确实让您访问它用于做出预测的决策得分。您可以调用分类器的`decision_function()`方法，而不是调用`predict()`方法，该方法返回每个实例的得分，然后根据这些得分使用任何阈值进行预测：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `SGDClassifier` uses a threshold equal to 0, so the preceding code returns
    the same result as the `predict()` method (i.e., `True`). Let’s raise the threshold:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`SGDClassifier`使用阈值等于0，因此前面的代码返回与`predict()`方法相同的结果（即`True`）。让我们提高阈值：'
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This confirms that raising the threshold decreases recall. The image actually
    represents a 5, and the classifier detects it when the threshold is 0, but it
    misses it when the threshold is increased to 3,000.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这证实了提高阈值会降低召回率。图像实际上代表一个5，当阈值为0时分类器检测到它，但当阈值增加到3,000时却错过了它。
- en: 'How do you decide which threshold to use? First, use the `cross_val_predict()`
    function to get the scores of all instances in the training set, but this time
    specify that you want to return decision scores instead of predictions:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如何决定使用哪个阈值？首先，使用`cross_val_predict()`函数获取训练集中所有实例的分数，但是这次指定要返回决策分数而不是预测：
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'With these scores, use the `precision_recall_curve()` function to compute precision
    and recall for all possible thresholds (the function adds a last precision of
    0 and a last recall of 1, corresponding to an infinite threshold):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些分数，使用`precision_recall_curve()`函数计算所有可能阈值的精度和召回率（该函数添加最后一个精度为0和最后一个召回率为1，对应于无限阈值）：
- en: '[PRE19]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, use Matplotlib to plot precision and recall as functions of the threshold
    value ([Figure 3-5](#precision_recall_vs_threshold_plot)). Let’s show the threshold
    of 3,000 we selected:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用Matplotlib绘制精度和召回率作为阈值值的函数（[图3-5](#precision_recall_vs_threshold_plot)）。让我们展示我们选择的3,000的阈值：
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![mls3 0305](assets/mls3_0305.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0305](assets/mls3_0305.png)'
- en: Figure 3-5\. Precision and recall versus the decision threshold
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-5. 精度和召回率与决策阈值
- en: Note
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'You may wonder why the precision curve is bumpier than the recall curve in
    [Figure 3-5](#precision_recall_vs_threshold_plot). The reason is that precision
    may sometimes go down when you raise the threshold (although in general it will
    go up). To understand why, look back at [Figure 3-4](#decision_threshold_diagram)
    and notice what happens when you start from the central threshold and move it
    just one digit to the right: precision goes from 4/5 (80%) down to 3/4 (75%).
    On the other hand, recall can only go down when the threshold is increased, which
    explains why its curve looks smooth.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么[图3-5](#precision_recall_vs_threshold_plot)中的精度曲线比召回率曲线更加崎岖。原因是当你提高阈值时，精度有时会下降（尽管通常会上升）。要理解原因，请回顾[图3-4](#decision_threshold_diagram)，注意当你从中心阈值开始，将其向右移动一个数字时会发生什么：精度从4/5（80%）下降到3/4（75%）。另一方面，当增加阈值时，召回率只能下降，这解释了为什么其曲线看起来平滑。
- en: 'At this threshold value, precision is near 90% and recall is around 50%. Another
    way to select a good precision/recall trade-off is to plot precision directly
    against recall, as shown in [Figure 3-6](#precision_vs_recall_plot) (the same
    threshold is shown):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阈值下，精度接近90%，召回率约为50%。选择一个良好的精度/召回率折衷的另一种方法是直接绘制精度与召回率的图表，如[图3-6](#precision_vs_recall_plot)所示（显示相同的阈值）：
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![mls3 0306](assets/mls3_0306.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0306](assets/mls3_0306.png)'
- en: Figure 3-6\. Precision versus recall
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-6. 精度与召回率
- en: You can see that precision really starts to fall sharply at around 80% recall.
    You will probably want to select a precision/recall trade-off just before that
    drop—for example, at around 60% recall. But of course, the choice depends on your
    project.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到精度在约80%的召回率处开始急剧下降。你可能希望在该下降之前选择一个精度/召回率折衷，例如在约60%的召回率处。但是，选择取决于你的项目。
- en: 'Suppose you decide to aim for 90% precision. You could use the first plot to
    find the threshold you need to use, but that’s not very precise. Alternatively,
    you can search for the lowest threshold that gives you at least 90% precision.
    For this, you can use the NumPy array’s `argmax()` method. This returns the first
    index of the maximum value, which in this case means the first `True` value:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你决定追求90%的精度。你可以使用第一个图表找到需要使用的阈值，但这不太精确。或者，你可以搜索给出至少90%精度的最低阈值。为此，你可以使用NumPy数组的`argmax()`方法。这将返回最大值的第一个索引，这在这种情况下意味着第一个`True`值：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To make predictions (on the training set for now), instead of calling the classifier’s
    `predict()` method, you can run this code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行预测（目前只是在训练集上），而不是调用分类器的`predict()`方法，你可以运行这段代码：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s check these predictions’ precision and recall:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这些预测的精度和召回率：
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Great, you have a 90% precision classifier! As you can see, it is fairly easy
    to create a classifier with virtually any precision you want: just set a high
    enough threshold, and you’re done. But wait, not so fast–a high-precision classifier
    is not very useful if its recall is too low! For many applications, 48% recall
    wouldn’t be great at all.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了，你有一个90%的精度分类器！正如你所看到的，几乎可以轻松地创建一个任意精度的分类器：只需设置足够高的阈值，就可以了。但是等等，不要那么快——如果召回率太低，高精度的分类器就不太有用！对于许多应用程序来说，48%的召回率根本不好。
- en: Tip
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If someone says, “Let’s reach 99% precision”, you should ask, “At what recall?”
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人说：“让我们达到99%的精度”，你应该问：“召回率是多少？”
- en: The ROC Curve
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ROC曲线
- en: The *receiver operating characteristic* (ROC) curve is another common tool used
    with binary classifiers. It is very similar to the precision/recall curve, but
    instead of plotting precision versus recall, the ROC curve plots the *true positive
    rate* (another name for recall) against the *false positive rate* (FPR). The FPR
    (also called the *fall-out*) is the ratio of negative instances that are incorrectly
    classified as positive. It is equal to 1 – the *true negative rate* (TNR), which
    is the ratio of negative instances that are correctly classified as negative.
    The TNR is also called *specificity*. Hence, the ROC curve plots *sensitivity*
    (recall) versus 1 – *specificity*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*接收者操作特征*（ROC）曲线是与二元分类器一起使用的另一个常见工具。它与精度/召回率曲线非常相似，但是ROC曲线不是绘制精度与召回率，而是绘制*真正例率*（召回率的另一个名称）与*假正例率*（FPR）。FPR（也称为*误报率*）是被错误分类为正例的负实例的比率。它等于1减去*真负例率*（TNR），即被正确分类为负例的负实例的比率。TNR也称为*特异性*。因此，ROC曲线绘制*灵敏度*（召回率）与1-*特异性*。'
- en: 'To plot the ROC curve, you first use the `roc_curve()` function to compute
    the TPR and FPR for various threshold values:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制ROC曲线，首先使用`roc_curve()`函数计算各种阈值的TPR和FPR：
- en: '[PRE25]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then you can plot the FPR against the TPR using Matplotlib. The following code
    produces the plot in [Figure 3-7](#roc_curve_plot). To find the point that corresponds
    to 90% precision, we need to look for the index of the desired threshold. Since
    thresholds are listed in decreasing order in this case, we use `<=` instead of
    `>=` on the first line:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用Matplotlib绘制FPR与TPR。以下代码生成[图3-7](#roc_curve_plot)中的图。要找到对应于90%精确度的点，我们需要查找所需阈值的索引。由于在这种情况下，阈值按降序列出，因此我们在第一行上使用`<=`而不是`>=`：
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![mls3 0307](assets/mls3_0307.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0307](assets/mls3_0307.png)'
- en: Figure 3-7\. A ROC curve plotting the false positive rate against the true positive
    rate for all possible thresholds; the black circle highlights the chosen ratio
    (at 90% precision and 48% recall)
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-7。ROC曲线绘制了所有可能阈值的假阳性率与真阳性率之间的关系；黑色圆圈突出显示了选择的比率（在90%精确度和48%召回率处）
- en: 'Once again there is a trade-off: the higher the recall (TPR), the more false
    positives (FPR) the classifier produces. The dotted line represents the ROC curve
    of a purely random classifier; a good classifier stays as far away from that line
    as possible (toward the top-left corner).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 再次存在权衡：召回率（TPR）越高，分类器产生的假阳性（FPR）就越多。虚线代表纯随机分类器的ROC曲线；一个好的分类器尽可能远离该线（朝向左上角）。
- en: 'One way to compare classifiers is to measure the *area under the curve* (AUC).
    A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier
    will have a ROC AUC equal to 0.5\. Scikit-Learn provides a function to estimate
    the ROC AUC:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 比较分类器的一种方法是测量*曲线下面积*（AUC）。完美的分类器的ROC AUC等于1，而纯随机分类器的ROC AUC等于0.5。Scikit-Learn提供了一个估计ROC
    AUC的函数：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Tip
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Since the ROC curve is so similar to the precision/recall (PR) curve, you may
    wonder how to decide which one to use. As a rule of thumb, you should prefer the
    PR curve whenever the positive class is rare or when you care more about the false
    positives than the false negatives. Otherwise, use the ROC curve. For example,
    looking at the previous ROC curve (and the ROC AUC score), you may think that
    the classifier is really good. But this is mostly because there are few positives
    (5s) compared to the negatives (non-5s). In contrast, the PR curve makes it clear
    that the classifier has room for improvement: the curve could really be closer
    to the top-right corner (see [Figure 3-6](#precision_vs_recall_plot) again).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ROC曲线与精确率/召回率（PR）曲线非常相似，您可能想知道如何决定使用哪个。作为经验法则，当正类别很少或您更关心假阳性而不是假阴性时，应优先选择PR曲线。否则，请使用ROC曲线。例如，查看先前的ROC曲线（以及ROC
    AUC分数），您可能会认为分类器非常好。但这主要是因为与负例（非5）相比，正例（5）很少。相比之下，PR曲线清楚地表明分类器有改进的空间：曲线实际上可以更接近右上角（再次参见[图3-6](#precision_vs_recall_plot)）。
- en: 'Let’s now create a `RandomForestClassifier`, whose PR curve and F[1] score
    we can compare to those of the `SGDClassifier`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个`RandomForestClassifier`，我们可以将其PR曲线和F[1]分数与`SGDClassifier`的进行比较：
- en: '[PRE28]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `precision_recall_curve()` function expects labels and scores for each
    instance, so we need to train the random forest classifier and make it assign
    a score to each instance. But the `RandomForestClassifier` class does not have
    a `decision_function()` method, due to the way it works (we will cover this in
    [Chapter 7](ch07.html#ensembles_chapter)). Luckily, it has a `predict_proba()`
    method that returns class probabilities for each instance, and we can just use
    the probability of the positive class as a score, so it will work fine.^([4](ch03.html#idm45720237468928))
    We can call the `cross_val_predict()` function to train the `RandomForestClassifier`
    using cross-validation and make it predict class probabilities for every image
    as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`precision_recall_curve()`函数期望每个实例的标签和分数，因此我们需要训练随机森林分类器并使其为每个实例分配一个分数。但是，由于`RandomForestClassifier`类的工作方式（我们将在[第7章](ch07.html#ensembles_chapter)中介绍），它没有`decision_function()`方法。幸运的是，它有一个`predict_proba()`方法，为每个实例返回类概率，并且我们可以将正类别的概率作为分数，因此它将正常工作。^([4](ch03.html#idm45720237468928))我们可以调用`cross_val_predict()`函数，使用交叉验证训练`RandomForestClassifier`，并使其为每个图像预测类概率，如下所示：'
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s look at the class probabilities for the first two images in the training
    set:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看训练集中前两个图像的类概率：
- en: '[PRE30]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The model predicts that the first image is positive with 89% probability, and
    it predicts that the second image is negative with 99% probability. Since each
    image is either positive or negative, the probabilities in each row add up to
    100%.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测第一幅图像为正面的概率为89%，并且预测第二幅图像为负面的概率为99%。由于每幅图像要么是正面要么是负面，因此每行中的概率总和为100%。
- en: Warning
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: These are *estimated* probabilities, not actual probabilities. For example,
    if you look at all the images that the model classified as positive with an estimated
    probability between 50% and 60%, roughly 94% of them are actually positive. So,
    the model’s estimated probabilities were much too low in this case—but models
    can be overconfident as well. The `sklearn.calibration` package contains tools
    to calibrate the estimated probabilities and make them much closer to actual probabilities.
    See the extra material section in [this chapter’s notebook](https://homl.info/colab3)
    for more details.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是*估计*概率，而不是实际概率。例如，如果您查看模型将其分类为正面的所有图像，其估计概率在50%到60%之间，大约94%实际上是正面的。因此，在这种情况下，模型的估计概率要低得多，但模型也可能过于自信。`sklearn.calibration`包含工具，可以校准估计的概率，使其更接近实际概率。有关更多详细信息，请参阅[本章笔记本](https://homl.info/colab3)中的额外材料部分。
- en: 'The second column contains the estimated probabilities for the positive class,
    so let’s pass them to the `precision_recall_curve()` function:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 第二列包含正类别的估计概率，因此让我们将它们传递给`precision_recall_curve()`函数：
- en: '[PRE31]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we’re ready to plot the PR curve. It is useful to plot the first PR curve
    as well to see how they compare ([Figure 3-8](#pr_curve_comparison_plot)):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们准备绘制PR曲线。为了查看它们的比较，也有必要绘制第一个PR曲线（[图3-8](#pr_curve_comparison_plot)）： '
- en: '[PRE32]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![mls3 0308](assets/mls3_0308.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0308](assets/mls3_0308.png)'
- en: 'Figure 3-8\. Comparing PR curves: the random forest classifier is superior
    to the SGD classifier because its PR curve is much closer to the top-right corner,
    and it has a greater AUC'
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-8。比较PR曲线：随机森林分类器优于SGD分类器，因为其PR曲线更接近右上角，并且具有更大的AUC
- en: 'As you can see in [Figure 3-8](#pr_curve_comparison_plot), the `RandomForestClassifier`’s
    PR curve looks much better than the `SGDClassifier`’s: it comes much closer to
    the top-right corner. Its F[1] score and ROC AUC score are also significantly
    better:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在[图3-8](#pr_curve_comparison_plot)中所看到的，`RandomForestClassifier`的PR曲线看起来比`SGDClassifier`的要好得多：它更接近右上角。它的F[1]分数和ROC
    AUC分数也显著更好：
- en: '[PRE33]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Try measuring the precision and recall scores: you should find about 99.1%
    precision and 86.6% recall. Not too bad!'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试测量精确度和召回率得分：您应该会发现大约99.1%的精确度和86.6%的召回率。还不错！
- en: You now know how to train binary classifiers, choose the appropriate metric
    for your task, evaluate your classifiers using cross-validation, select the precision/recall
    trade-off that fits your needs, and use several metrics and curves to compare
    various models. You’re ready to try to detect more than just the 5s.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在知道如何训练二元分类器，选择适合您任务的适当度量标准，使用交叉验证评估您的分类器，选择适合您需求的精确度/召回率折衷，并使用多种指标和曲线比较各种模型。您已经准备好尝试检测不仅仅是数字5了。
- en: Multiclass Classification
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类分类
- en: Whereas binary classifiers distinguish between two classes, *multiclass classifiers*
    (also called *multinomial classifiers*) can distinguish between more than two
    classes.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 而二元分类器区分两个类别，*多类分类器*（也称为*多项分类器*）可以区分两个以上的类别。
- en: Some Scikit-Learn classifiers (e.g., `LogisticRegression`, `RandomForestClassifier`,
    and `GaussianNB`) are capable of handling multiple classes natively. Others are
    strictly binary classifiers (e.g., `SGDClassifier` and `SVC`). However, there
    are various strategies that you can use to perform multiclass classification with
    multiple binary classifiers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一些Scikit-Learn分类器（例如`LogisticRegression`、`RandomForestClassifier`和`GaussianNB`）能够本地处理多个类别。其他严格的二元分类器（例如`SGDClassifier`和`SVC`）。然而，有各种策略可用于使用多个二元分类器执行多类分类。
- en: One way to create a system that can classify the digit images into 10 classes
    (from 0 to 9) is to train 10 binary classifiers, one for each digit (a 0-detector,
    a 1-detector, a 2-detector, and so on). Then when you want to classify an image,
    you get the decision score from each classifier for that image and you select
    the class whose classifier outputs the highest score. This is called the *one-versus-the-rest*
    (OvR) strategy, or sometimes *one-versus-all* (OvA).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个能够将数字图像分类为10个类别（从0到9）的系统的一种方法是训练10个二元分类器，每个数字一个（一个0检测器，一个1检测器，一个2检测器，依此类推）。然后，当您想要对一幅图像进行分类时，您会从每个分类器中获取该图像的决策分数，并选择输出最高分数的类别。这被称为*一对剩余*（OvR）策略，有时也称为*一对所有*（OvA）。
- en: 'Another strategy is to train a binary classifier for every pair of digits:
    one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s
    and 2s, and so on. This is called the *one-versus-one* (OvO) strategy. If there
    are *N* classes, you need to train *N* × (*N* – 1) / 2 classifiers. For the MNIST
    problem, this means training 45 binary classifiers! When you want to classify
    an image, you have to run the image through all 45 classifiers and see which class
    wins the most duels. The main advantage of OvO is that each classifier only needs
    to be trained on the part of the training set containing the two classes that
    it must distinguish.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种策略是为每对数字训练一个二元分类器：一个用于区分0和1，另一个用于区分0和2，另一个用于1和2，依此类推。这被称为*一对一*（OvO）策略。如果有*N*个类别，您需要训练*N*×（*N*
    - 1）/ 2个分类器。对于MNIST问题，这意味着训练45个二元分类器！当您想要对一幅图像进行分类时，您必须通过所有45个分类器并查看哪个类别赢得了最多的决斗。OvO的主要优势在于每个分类器只需要在包含它必须区分的两个类别的训练集部分上进行训练。
- en: Some algorithms (such as support vector machine classifiers) scale poorly with
    the size of the training set. For these algorithms OvO is preferred because it
    is faster to train many classifiers on small training sets than to train few classifiers
    on large training sets. For most binary classification algorithms, however, OvR
    is preferred.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一些算法（如支持向量机分类器）随着训练集的大小而扩展得很差。对于这些算法，OvO更受青睐，因为在小训练集上训练许多分类器比在大训练集上训练少数分类器要快。然而，对于大多数二元分类算法，OvR更受青睐。
- en: 'Scikit-Learn detects when you try to use a binary classification algorithm
    for a multiclass classification task, and it automatically runs OvR or OvO, depending
    on the algorithm. Let’s try this with a support vector machine classifier using
    the `sklearn.svm.SVC` class (see [Chapter 5](ch05.html#svm_chapter)). We’ll only
    train on the first 2,000 images, or else it will take a very long time:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn会检测到您尝试将二元分类算法用于多类分类任务时，并根据算法自动运行OvR或OvO。让我们尝试使用`sklearn.svm.SVC`类中的支持向量机分类器（参见[第5章](ch05.html#svm_chapter)）。我们只会在前2,000幅图像上进行训练，否则会花费很长时间：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'That was easy! We trained the `SVC` using the original target classes from
    0 to 9 (`y_train`), instead of the 5-versus-the-rest target classes (`y_train_5`).
    Since there are 10 classes (i.e., more than 2), Scikit-Learn used the OvO strategy
    and trained 45 binary classifiers. Now let’s make a prediction on an image:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这很容易！我们使用原始目标类别从0到9（`y_train`）来训练`SVC`，而不是使用5对剩余目标类别（`y_train_5`）。由于有10个类别（即超过2个），Scikit-Learn使用了OvO策略并训练了45个二元分类器。现在让我们对一幅图像进行预测：
- en: '[PRE35]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'That’s correct! This code actually made 45 predictions—one per pair of classes—and
    it selected the class that won the most duels. If you call the `decision_function()`
    method, you will see that it returns 10 scores per instance: one per class. Each
    class gets a score equal to the number of won duels plus or minus a small tweak
    (max ±0.33) to break ties, based on the classifier scores:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是正确的！这段代码实际上进行了45次预测——每对类别一次——并选择了赢得最多决斗的类别。如果调用`decision_function()`方法，您会看到它为每个实例返回10个分数：每个类别一个。每个类别得分等于赢得的决斗数加上或减去一个小调整（最大±0.33）以打破平局，基于分类器的分数：
- en: '[PRE36]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The highest score is 9.3, and it’s indeed the one corresponding to class 5:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最高分是9.3，确实对应于类别5：
- en: '[PRE37]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'When a classifier is trained, it stores the list of target classes in its `classes_`
    attribute, ordered by value. In the case of MNIST, the index of each class in
    the `classes_` array conveniently matches the class itself (e.g., the class at
    index 5 happens to be class `''5''`), but in general you won’t be so lucky; you
    will need to look up the class label like this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当分类器训练完成时，它会将目标类别列表存储在其`classes_`属性中，按值排序。在MNIST的情况下，`classes_`数组中每个类别的索引恰好与类别本身匹配（例如，索引为5的类在数组中是类`'5'`），但通常您不会那么幸运；您需要像这样查找类标签：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If you want to force Scikit-Learn to use one-versus-one or one-versus-the-rest,
    you can use the `OneVsOneClassifier` or `OneVsRestClassifier` classes. Simply
    create an instance and pass a classifier to its constructor (it doesn’t even have
    to be a binary classifier). For example, this code creates a multiclass classifier
    using the OvR strategy, based on an `SVC`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想强制Scikit-Learn使用一对一或一对多，您可以使用`OneVsOneClassifier`或`OneVsRestClassifier`类。只需创建一个实例并将分类器传递给其构造函数（甚至不必是二元分类器）。例如，此代码使用OvR策略基于`SVC`创建一个多类分类器：
- en: '[PRE39]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s make a prediction, and check the number of trained classifiers:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行预测，并检查训练过的分类器数量：
- en: '[PRE40]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Training an `SGDClassifier` on a multiclass dataset and using it to make predictions
    is just as easy:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类数据集上训练`SGDClassifier`并使用它进行预测同样简单：
- en: '[PRE41]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Oops, that’s incorrect. Prediction errors do happen! This time Scikit-Learn
    used the OvR strategy under the hood: since there are 10 classes, it trained 10
    binary classifiers. The `decision_function()` method now returns one value per
    class. Let’s look at the scores that the SGD classifier assigned to each class:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀，那是错误的。预测错误确实会发生！这次Scikit-Learn在幕后使用了OvR策略：由于有10个类别，它训练了10个二元分类器。`decision_function()`方法现在返回每个类别的一个值。让我们看看SGD分类器为每个类别分配的分数：
- en: '[PRE42]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You can see that the classifier is not very confident about its prediction:
    almost all scores are very negative, while class 3 has a score of +1,824, and
    class 5 is not too far behind at –1,386\. Of course, you’ll want to evaluate this
    classifier on more than one image. Since there are roughly the same number of
    images in each class, the accuracy metric is fine. As usual, you can use the `cross_val_score()`
    function to evaluate the model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到分类器对其预测并不是很自信：几乎所有分数都非常负面，而类别3的分数为+1,824，类别5也不远处为-1,386。当然，您会希望对这个分类器进行多个图像的评估。由于每个类别中的图像数量大致相同，准确度指标是可以接受的。通常情况下，您可以使用`cross_val_score()`函数来评估模型：
- en: '[PRE43]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'It gets over 85.8% on all test folds. If you used a random classifier, you
    would get 10% accuracy, so this is not such a bad score, but you can still do
    much better. Simply scaling the inputs (as discussed in [Chapter 2](ch02.html#project_chapter))
    increases accuracy above 89.1%:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 它在所有测试折叠上都超过了85.8%。如果使用随机分类器，您将获得10%的准确率，因此这并不是一个很差的分数，但您仍然可以做得更好。简单地缩放输入（如[第2章](ch02.html#project_chapter)中讨论的）可以将准确率提高到89.1%以上：
- en: '[PRE44]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Error Analysis
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误分析
- en: If this were a real project, you would now follow the steps in your machine
    learning project checklist (see [Appendix A](app01.html#project_checklist_appendix)).
    You’d explore data preparation options, try out multiple models, shortlist the
    best ones, fine-tune their hyperparameters using `GridSearchCV`, and automate
    as much as possible. Here, we will assume that you have found a promising model
    and you want to find ways to improve it. One way to do this is to analyze the
    types of errors it makes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个真实的项目，您现在将按照机器学习项目清单中的步骤进行操作（请参阅[附录A](app01.html#project_checklist_appendix)）。您将探索数据准备选项，尝试多个模型，列出最佳模型，使用`GridSearchCV`微调其超参数，并尽可能自动化。在这里，我们假设您已经找到了一个有希望的模型，并且想要找到改进它的方法。其中一种方法是分析它所犯的错误类型。
- en: First, look at the confusion matrix. For this, you first need to make predictions
    using the `cross_val_predict()` function; then you can pass the labels and predictions
    to the `confusion_matrix()` function, just like you did earlier. However, since
    there are now 10 classes instead of 2, the confusion matrix will contain quite
    a lot of numbers, and it may be hard to read.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，看一下混淆矩阵。为此，您首先需要使用`cross_val_predict()`函数进行预测；然后您可以将标签和预测传递给`confusion_matrix()`函数，就像您之前所做的那样。然而，由于现在有10个类别而不是2个，混淆矩阵将包含相当多的数字，可能很难阅读。
- en: 'A colored diagram of the confusion matrix is much easier to analyze. To plot
    such a diagram, use the `ConfusionMatrixDisplay.from_predictions()` function like
    this:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 彩色混淆矩阵图表更容易分析。要绘制这样的图表，请使用`ConfusionMatrixDisplay.from_predictions()`函数，如下所示：
- en: '[PRE45]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This produces the left diagram in [Figure 3-9](#confusion_matrix_plot_1). This
    confusion matrix looks pretty good: most images are on the main diagonal, which
    means that they were classified correctly. Notice that the cell on the diagonal
    in row #5 and column #5 looks slightly darker than the other digits. This could
    be because the model made more errors on 5s, or because there are fewer 5s in
    the dataset than the other digits. That’s why it’s important to normalize the
    confusion matrix by dividing each value by the total number of images in the corresponding
    (true) class (i.e., divide by the row’s sum). This can be done simply by setting
    `normalize="true"`. We can also specify the `values_format=".0%"` argument to
    show percentages with no decimals. The following code produces the diagram on
    the right in [Figure 3-9](#confusion_matrix_plot_1):'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成[图3-9](#confusion_matrix_plot_1)中的左侧图。这个混淆矩阵看起来相当不错：大多数图像都在主对角线上，这意味着它们被正确分类了。请注意，对角线上的第5行和第5列的单元格看起来比其他数字稍暗。这可能是因为模型在5上犯了更多错误，或者因为数据集中的5比其他数字少。这就是通过将每个值除以相应（真实）类别中图像的总数（即除以行的总和）来对混淆矩阵进行归一化的重要性。这可以通过简单地设置`normalize="true"`来完成。我们还可以指定`values_format=".0%"`参数以显示没有小数的百分比。以下代码生成[图3-9](#confusion_matrix_plot_1)中右侧的图表：
- en: '[PRE46]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now we can easily see that only 82% of the images of 5s were classified correctly.
    The most common error the model made with images of 5s was to misclassify them
    as 8s: this happened for 10% of all 5s. But only 2% of 8s got misclassified as
    5s; confusion matrices are generally not symmetrical! If you look carefully, you
    will notice that many digits have been misclassified as 8s, but this is not immediately
    obvious from this diagram. If you want to make the errors stand out more, you
    can try putting zero weight on the correct predictions. The following code does
    just that and produces the diagram on the left in [Figure 3-10](#confusion_matrix_plot_2):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以很容易地看到，只有82%的5的图像被正确分类。模型在5的图像中最常见的错误是将它们错误分类为8：这发生在所有5的10%中。但只有2%的8被错误分类为5；混淆矩阵通常不是对称的！如果你仔细观察，你会注意到许多数字被错误分类为8，但从这个图表中并不立即明显。如果你想让错误更加突出，你可以尝试在正确预测上设置零权重。以下代码就是这样做的，并生成了[图3-10](#confusion_matrix_plot_2)中左边的图表：
- en: '[PRE47]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![mls3 0309](assets/mls3_0309.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0309](assets/mls3_0309.png)'
- en: Figure 3-9\. Confusion matrix (left) and the same CM normalized by row (right)
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-9。混淆矩阵（左）和相同的通过行归一化的CM（右）
- en: '![mls3 0310](assets/mls3_0310.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0310](assets/mls3_0310.png)'
- en: Figure 3-10\. Confusion matrix with errors only, normalized by row (left) and
    by column (right)
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-10。仅显示错误的混淆矩阵，通过行归一化（左）和通过列归一化（右）
- en: 'Now you can see much more clearly the kinds of errors the classifier makes.
    The column for class 8 is now really bright, which confirms that many images got
    misclassified as 8s. In fact this is the most common misclassification for almost
    all classes. But be careful how you interpret the percentages in this diagram:
    remember that we’ve excluded the correct predictions. For example, the 36% in
    row #7, column #9 does *not* mean that 36% of all images of 7s were misclassified
    as 9s. It means that 36% of the *errors* the model made on images of 7s were misclassifications
    as 9s. In reality, only 3% of images of 7s were misclassified as 9s, as you can
    see in the diagram on the right in [Figure 3-9](#confusion_matrix_plot_1).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以更清楚地看到分类器所犯的错误类型。类别8的列现在非常亮，这证实了许多图像被错误分类为8。事实上，这是几乎所有类别中最常见的错误分类。但要注意如何解释这个图表中的百分比：记住我们已经排除了正确的预测。例如，第7行第9列的36%
    *不*意味着36%的所有7的图像被错误分类为9。它意味着36%的模型在7的图像上犯的*错误*被错误分类为9。实际上，只有3%的7的图像被错误分类为9，你可以在右边的图表中看到[图3-9](#confusion_matrix_plot_1)。
- en: 'It is also possible to normalize the confusion matrix by column rather than
    by row: if you set `normalize="pred"`, you get the diagram on the right in [Figure 3-10](#confusion_matrix_plot_2).
    For example, you can see that 56% of misclassified 7s are actually 9s.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过列而不是通过行对混淆矩阵进行归一化：如果设置`normalize="pred"`，你会得到[图3-10](#confusion_matrix_plot_2)中右边的图表。例如，你可以看到56%的错误分类的7实际上是9。
- en: Analyzing the confusion matrix often gives you insights into ways to improve
    your classifier. Looking at these plots, it seems that your efforts should be
    spent on reducing the false 8s. For example, you could try to gather more training
    data for digits that look like 8s (but are not) so that the classifier can learn
    to distinguish them from real 8s. Or you could engineer new features that would
    help the classifier—for example, writing an algorithm to count the number of closed
    loops (e.g., 8 has two, 6 has one, 5 has none). Or you could preprocess the images
    (e.g., using Scikit-Image, Pillow, or OpenCV) to make some patterns, such as closed
    loops, stand out more.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 分析混淆矩阵通常可以让你了解如何改进你的分类器。从这些图表中看，你的努力应该花在减少错误的8上。例如，你可以尝试收集更多看起来像8的（但实际上不是）数字的训练数据，这样分类器就可以学会区分它们和真正的8。或者你可以设计新的特征来帮助分类器，例如，编写一个算法来计算闭环的数量（例如，8有两个，6有一个，5没有）。或者你可以预处理图像（例如，使用Scikit-Image、Pillow或OpenCV）使一些模式，如闭环，更加突出。
- en: 'Analyzing individual errors can also be a good way to gain insights into what
    your classifier is doing and why it is failing. For example, let’s plot examples
    of 3s and 5s in a confusion matrix style ([Figure 3-11](#error_analysis_digits_plot)):'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 分析单个错误也是了解你的分类器在做什么以及为什么失败的好方法。例如，让我们以混淆矩阵样式绘制3和5的示例（[图3-11](#error_analysis_digits_plot)）：
- en: '[PRE48]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '![mls3 0311](assets/mls3_0311.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0311](assets/mls3_0311.png)'
- en: Figure 3-11\. Some images of 3s and 5s organized like a confusion matrix
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-11。一些3和5的图像以混淆矩阵的方式组织
- en: 'As you can see, some of the digits that the classifier gets wrong (i.e., in
    the bottom-left and top-right blocks) are so badly written that even a human would
    have trouble classifying them. However, most misclassified images seem like obvious
    errors to us. It may be hard to understand why the classifier made the mistakes
    it did, but remember that the human brain is a fantastic pattern recognition system,
    and our visual system does a lot of complex preprocessing before any information
    even reaches our consciousness. So, the fact that this task feels simple does
    not mean that it is. Recall that we used a simple `SGDClassifier`, which is just
    a linear model: all it does is assign a weight per class to each pixel, and when
    it sees a new image it just sums up the weighted pixel intensities to get a score
    for each class. Since 3s and 5s differ by only a few pixels, this model will easily
    confuse them.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，分类器错误分类的一些数字（即，左下角和右上角的块）写得非常糟糕，即使是人类也会难以分类。然而，大多数错误分类的图像对我们来说似乎是明显的错误。理解分类器为什么犯错可能很困难，但请记住，人类大脑是一个出色的模式识别系统，我们的视觉系统在任何信息到达我们的意识之前都进行了大量复杂的预处理。因此，这个任务看起来简单并不意味着它是简单的。回想一下，我们使用了一个简单的`SGDClassifier`，它只是一个线性模型：它只是为每个像素分配一个类别权重，当它看到一个新的图像时，它只是将加权像素强度相加以获得每个类别的得分。由于3和5之间只相差几个像素，这个模型很容易混淆它们。
- en: The main difference between 3s and 5s is the position of the small line that
    joins the top line to the bottom arc. If you draw a 3 with the junction slightly
    shifted to the left, the classifier might classify it as a 5, and vice versa.
    In other words, this classifier is quite sensitive to image shifting and rotation.
    One way to reduce the 3/5 confusion is to preprocess the images to ensure that
    they are well centered and not too rotated. However, this may not be easy since
    it requires predicting the correct rotation of each image. A much simpler approach
    consists of augmenting the training set with slightly shifted and rotated variants
    of the training images. This will force the model to learn to be more tolerant
    to such variations. This is called *data augmentation* (we’ll cover this in [Chapter 14](ch14.html#cnn_chapter);
    also see exercise 2 at the end of this chapter).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 3s和5s之间的主要区别是连接顶线和底部弧线的小线的位置。如果你画一个3，连接处稍微向左移动，分类器可能会将其分类为5，反之亦然。换句话说，这个分类器对图像的移动和旋转非常敏感。减少3/5混淆的一种方法是预处理图像，确保它们居中且旋转不太多。然而，这可能并不容易，因为它需要预测每个图像的正确旋转。一个更简单的方法是通过增加训练集中略微移动和旋转的变体来增强训练集。这将迫使模型学会更容忍这些变化。这被称为*数据增强*（我们将在[第14章](ch14.html#cnn_chapter)中介绍；也请参见本章末尾的练习2）。
- en: Multilabel Classification
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多标签分类
- en: 'Until now, each instance has always been assigned to just one class. But in
    some cases you may want your classifier to output multiple classes for each instance.
    Consider a face-recognition classifier: what should it do if it recognizes several
    people in the same picture? It should attach one tag per person it recognizes.
    Say the classifier has been trained to recognize three faces: Alice, Bob, and
    Charlie. Then when the classifier is shown a picture of Alice and Charlie, it
    should output `[True, False, True]` (meaning “Alice yes, Bob no, Charlie yes”).
    Such a classification system that outputs multiple binary tags is called a *multilabel
    classification* system.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，每个实例总是被分配到一个类。但在某些情况下，您可能希望您的分类器为每个实例输出多个类。考虑一个人脸识别分类器：如果它在同一张图片中识别出几个人，它应该做什么？它应该为它识别出的每个人附上一个标签。假设分类器已经训练好了识别三张脸：Alice、Bob和Charlie。那么当分类器看到Alice和Charlie的图片时，它应该输出`[True,
    False, True]`（意思是“Alice是，Bob不是，Charlie是”）。这样一个输出多个二进制标签的分类系统被称为*多标签分类*系统。
- en: 'We won’t go into face recognition just yet, but let’s look at a simpler example,
    just for illustration purposes:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们暂时不会讨论人脸识别，但让我们看一个更简单的例子，仅供说明目的：
- en: '[PRE49]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'This code creates a `y_multilabel` array containing two target labels for each
    digit image: the first indicates whether or not the digit is large (7, 8, or 9),
    and the second indicates whether or not it is odd. Then the code creates a `KNeighborsClassifier`
    instance, which supports multilabel classification (not all classifiers do), and
    trains this model using the multiple targets array. Now you can make a prediction,
    and notice that it outputs two labels:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建一个包含每个数字图像两个目标标签的`y_multilabel`数组：第一个指示数字是否大（7、8或9），第二个指示数字是否奇数。然后代码创建一个`KNeighborsClassifier`实例，支持多标签分类（并非所有分类器都支持），并使用多目标数组训练这个模型。现在您可以进行预测，并注意到它输出了两个标签：
- en: '[PRE50]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: And it gets it right! The digit 5 is indeed not large (`False`) and odd (`True`).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 而且它预测正确了！数字5确实不是大的（`False`）且是奇数（`True`）。
- en: 'There are many ways to evaluate a multilabel classifier, and selecting the
    right metric really depends on your project. One approach is to measure the F[1]
    score for each individual label (or any other binary classifier metric discussed
    earlier), then simply compute the average score. The following code computes the
    average F[1] score across all labels:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以评估多标签分类器，选择正确的度量标准取决于您的项目。一种方法是测量每个单独标签的F[1]分数（或之前讨论过的任何其他二元分类器度量标准），然后简单地计算平均分数。以下代码计算所有标签的平均F[1]分数：
- en: '[PRE51]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This approach assumes that all labels are equally important, which may not be
    the case. In particular, if you have many more pictures of Alice than of Bob or
    Charlie, you may want to give more weight to the classifier’s score on pictures
    of Alice. One simple option is to give each label a weight equal to its *support*
    (i.e., the number of instances with that target label). To do this, simply set
    `average="weighted"` when calling the `f1_score()` function.⁠^([5](ch03.html#idm45720217874768))
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法假设所有标签都同等重要，但这可能并非总是如此。特别是，如果您有比Bob或Charlie更多的Alice图片，您可能希望在Alice图片上给分类器的分数更多的权重。一个简单的选择是为每个标签赋予一个权重，等于其*支持*（即具有该目标标签的实例数）。要做到这一点，只需在调用`f1_score()`函数时设置`average="weighted"`。⁠^([5](ch03.html#idm45720217874768))
- en: 'If you wish to use a classifier that does not natively support multilabel classification,
    such as `SVC`, one possible strategy is to train one model per label. However,
    this strategy may have a hard time capturing the dependencies between the labels.
    For example, a large digit (7, 8, or 9) is twice more likely to be odd than even,
    but the classifier for the “odd” label does not know what the classifier for the
    “large” label predicted. To solve this issue, the models can be organized in a
    chain: when a model makes a prediction, it uses the input features plus all the
    predictions of the models that come before it in the chain.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望使用不原生支持多标签分类的分类器，比如`SVC`，一种可能的策略是为每个标签训练一个模型。然而，这种策略可能难以捕捉标签之间的依赖关系。例如，一个大数字（7、8或9）是奇数的可能性是偶数的两倍，但“奇数”标签的分类器不知道“大”标签的分类器预测了什么。为了解决这个问题，模型可以被组织成一个链：当一个模型做出预测时，它使用输入特征加上链中之前所有模型的预测。
- en: 'The good news is that Scikit-Learn has a class called `ChainClassifier` that
    does just that! By default it will use the true labels for training, feeding each
    model the appropriate labels depending on their position in the chain. But if
    you set the `cv` hyperparameter, it will use cross-validation to get “clean” (out-of-sample)
    predictions from each trained model for every instance in the training set, and
    these predictions will then be used to train all the models later in the chain.
    Here’s an example showing how to create and train a `ChainClassifier` using the
    cross-validation strategy. As earlier, we’ll just use the first 2,000 images in
    the training set to speed things up:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，Scikit-Learn有一个名为`ChainClassifier`的类，它就是做这个的！默认情况下，它将使用真实标签进行训练，根据它们在链中的位置为每个模型提供适当的标签。但是，如果设置`cv`超参数，它将使用交叉验证为训练集中的每个实例获取“干净”（样本外）预测，并且这些预测将用于以后在链中训练所有模型。以下是一个示例，展示如何使用交叉验证策略创建和训练`ChainClassifier`。与之前一样，我们将只使用训练集中的前2,000幅图像以加快速度：
- en: '[PRE52]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now we can use this `ChainClassifier` to make predictions:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这个`ChainClassifier`进行预测：
- en: '[PRE53]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Multioutput Classification
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多输出分类
- en: The last type of classification task we’ll discuss here is called *multioutput–multiclass
    classification* (or just *multioutput classification*). It is a generalization
    of multilabel classification where each label can be multiclass (i.e., it can
    have more than two possible values).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里讨论的最后一种分类任务类型称为*多输出-多类别分类*（或*多输出分类*）。这是多标签分类的一种泛化，其中每个标签可以是多类别的（即，它可以有两个以上的可能值）。
- en: To illustrate this, let’s build a system that removes noise from images. It
    will take as input a noisy digit image, and it will (hopefully) output a clean
    digit image, represented as an array of pixel intensities, just like the MNIST
    images. Notice that the classifier’s output is multilabel (one label per pixel)
    and each label can have multiple values (pixel intensity ranges from 0 to 255).
    This is thus an example of a multioutput classification system.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们构建一个从图像中去除噪声的系统。它将以嘈杂的数字图像作为输入，然后（希望）输出一个干净的数字图像，表示为像MNIST图像一样的像素强度数组。请注意，分类器的输出是多标签的（每个像素一个标签），每个标签可以有多个值（像素强度范围从0到255）。因此，这是一个多输出分类系统的示例。
- en: Note
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The line between classification and regression is sometimes blurry, such as
    in this example. Arguably, predicting pixel intensity is more akin to regression
    than to classification. Moreover, multioutput systems are not limited to classification
    tasks; you could even have a system that outputs multiple labels per instance,
    including both class labels and value labels.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 分类和回归之间的界限有时是模糊的，比如在这个例子中。可以说，预测像素强度更类似于回归而不是分类。此外，多输出系统不仅限于分类任务；您甚至可以拥有一个系统，它为每个实例输出多个标签，包括类标签和值标签。
- en: 'Let’s start by creating the training and test sets by taking the MNIST images
    and adding noise to their pixel intensities with NumPy’s `randint()` function.
    The target images will be the original images:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用NumPy的`randint()`函数向MNIST图像添加噪声来创建训练集和测试集。目标图像将是原始图像：
- en: '[PRE54]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Let’s take a peek at the first image from the test set ([Figure 3-12](#noisy_digit_example_plot)).
    Yes, we’re snooping on the test data, so you should be frowning right now.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下测试集中的第一幅图像（[图3-12](#noisy_digit_example_plot)）。是的，我们正在窥探测试数据，所以您现在应该皱起眉头。
- en: '![mls3 0312](assets/mls3_0312.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0312](assets/mls3_0312.png)'
- en: Figure 3-12\. A noisy image (left) and the target clean image (right)
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-12\. 一幅嘈杂的图像（左）和目标干净图像（右）
- en: 'On the left is the noisy input image, and on the right is the clean target
    image. Now let’s train the classifier and make it clean up this image ([Figure 3-13](#cleaned_digit_example_plot)):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 左边是嘈杂的输入图像，右边是干净的目标图像。现在让我们训练分类器，让它清理这幅图像（[图3-13](#cleaned_digit_example_plot)）：
- en: '[PRE55]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![mls3 0313](assets/mls3_0313.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![mls3 0313](assets/mls3_0313.png)'
- en: Figure 3-13\. The cleaned-up image
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-13\. 清理后的图像
- en: Looks close enough to the target! This concludes our tour of classification.
    You now know how to select good metrics for classification tasks, pick the appropriate
    precision/recall trade-off, compare classifiers, and more generally build good
    classification systems for a variety of tasks. In the next chapters, you’ll learn
    how all these machine learning models you’ve been using actually work.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来接近目标了！这结束了我们的分类之旅。您现在知道如何为分类任务选择良好的度量标准，选择适当的精确度/召回率折衷，比较分类器，以及更一般地构建各种任务的良好分类系统。在接下来的章节中，您将了解您一直在使用的所有这些机器学习模型实际上是如何工作的。
- en: Exercises
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Try to build a classifier for the MNIST dataset that achieves over 97% accuracy
    on the test set. Hint: the `KNeighborsClassifier` works quite well for this task;
    you just need to find good hyperparameter values (try a grid search on the `weights`
    and `n_neighbors` hyperparameters).'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试为MNIST数据集构建一个分类器，在测试集上实现超过97%的准确率。提示：`KNeighborsClassifier`对这个任务效果很好；您只需要找到好的超参数值（尝试在`weights`和`n_neighbors`超参数上进行网格搜索）。
- en: Write a function that can shift an MNIST image in any direction (left, right,
    up, or down) by one pixel.⁠^([6](ch03.html#idm45720217595248)) Then, for each
    image in the training set, create four shifted copies (one per direction) and
    add them to the training set. Finally, train your best model on this expanded
    training set and measure its accuracy on the test set. You should observe that
    your model performs even better now! This technique of artificially growing the
    training set is called *data augmentation* or *training set expansion*.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个函数，可以将MNIST图像向任何方向（左、右、上或下）移动一个像素。然后，对于训练集中的每个图像，创建四个移位副本（每个方向一个）并将它们添加到训练集中。最后，在这个扩展的训练集上训练您最好的模型，并在测试集上测量其准确率。您应该观察到您的模型现在表现得更好了！这种人为扩展训练集的技术称为*数据增强*或*训练集扩展*。
- en: Tackle the Titanic dataset. A great place to start is on [Kaggle](https://kaggle.com/c/titanic).
    Alternatively, you can download the data from [*https://homl.info/titanic.tgz*](https://homl.info/titanic.tgz)
    and unzip this tarball like you did for the housing data in [Chapter 2](ch02.html#project_chapter).
    This will give you two CSV files, *train.csv* and *test.csv*, which you can load
    using `pandas.read_csv()`. The goal is to train a classifier that can predict
    the `Survived` column based on the other columns.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解决泰坦尼克号数据集。一个很好的开始地方是[Kaggle](https://kaggle.com/c/titanic)。或者，您可以从[*https://homl.info/titanic.tgz*](https://homl.info/titanic.tgz)下载数据并解压缩这个tarball，就像您在[第2章](ch02.html#project_chapter)中为房屋数据所做的那样。这将给您两个CSV文件，*train.csv*和*test.csv*，您可以使用`pandas.read_csv()`加载。目标是训练一个分类器，可以根据其他列预测`Survived`列。
- en: 'Build a spam classifier (a more challenging exercise):'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个垃圾邮件分类器（一个更具挑战性的练习）：
- en: Download examples of spam and ham from [Apache SpamAssassin’s public datasets](https://homl.info/spamassassin).
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[Apache SpamAssassin的公共数据集](https://homl.info/spamassassin)下载垃圾邮件和正常邮件的示例。
- en: Unzip the datasets and familiarize yourself with the data format.
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压数据集并熟悉数据格式。
- en: Split the data into a training set and a test set.
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割为训练集和测试集。
- en: Write a data preparation pipeline to convert each email into a feature vector.
    Your preparation pipeline should transform an email into a (sparse) vector that
    indicates the presence or absence of each possible word. For example, if all emails
    only ever contain four words, “Hello”, “how”, “are”, “you”, then the email “Hello
    you Hello Hello you” would be converted into a vector [1, 0, 0, 1] (meaning [“Hello”
    is present, “how” is absent, “are” is absent, “you” is present]), or [3, 0, 0,
    2] if you prefer to count the number of occurrences of each word.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个数据准备流水线，将每封电子邮件转换为特征向量。您的准备流水线应该将一封电子邮件转换为一个（稀疏）向量，指示每个可能单词的存在或不存在。例如，如果所有电子邮件只包含四个单词，“Hello”、“how”、“are”、“you”，那么电子邮件“Hello
    you Hello Hello you”将被转换为向量[1, 0, 0, 1]（表示[“Hello”存在，“how”不存在，“are”不存在，“you”存在]），或者如果您更喜欢计算每个单词出现的次数，则为[3,
    0, 0, 2]。
- en: You may want to add hyperparameters to your preparation pipeline to control
    whether or not to strip off email headers, convert each email to lowercase, remove
    punctuation, replace all URLs with “URL”, replace all numbers with “NUMBER”, or
    even perform *stemming* (i.e., trim off word endings; there are Python libraries
    available to do this).
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可能希望在准备流水线中添加超参数，以控制是否剥离电子邮件头部，将每封电子邮件转换为小写，删除标点符号，用“URL”替换所有URL，用“NUMBER”替换所有数字，甚至执行*词干提取*（即修剪单词结尾；有Python库可用于执行此操作）。
- en: Finally, try out several classifiers and see if you can build a great spam classifier,
    with both high recall and high precision.
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，尝试几种分类器，看看是否可以构建一个既具有高召回率又具有高精度的垃圾邮件分类器。
- en: Solutions to these exercises are available at the end of this chapter’s notebook,
    at [*https://homl.info/colab3*](https://homl.info/colab3).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解决方案可以在本章笔记本的末尾找到，网址为[*https://homl.info/colab3*](https://homl.info/colab3)。
- en: ^([1](ch03.html#idm45720235827040-marker)) By default Scikit-Learn caches downloaded
    datasets in a directory called *scikit_learn_data* in your home directory.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#idm45720235827040-marker)) 默认情况下，Scikit-Learn会将下载的数据集缓存到名为*scikit_learn_data*的目录中，该目录位于您的主目录中。
- en: ^([2](ch03.html#idm45720239036336-marker)) Datasets returned by `fetch_openml()`
    are not always shuffled or split.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch03.html#idm45720239036336-marker)) `fetch_openml()`返回的数据集并不总是被洗牌或分割。
- en: ^([3](ch03.html#idm45720238991712-marker)) Shuffling may be a bad idea in some
    contexts—for example, if you are working on time series data (such as stock market
    prices or weather conditions). We will explore this in [Chapter 15](ch15.html#rnn_chapter).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch03.html#idm45720238991712-marker)) 在某些情况下，洗牌可能不是一个好主意——例如，如果您正在处理时间序列数据（如股票市场价格或天气状况）。我们将在[第15章](ch15.html#rnn_chapter)中探讨这个问题。
- en: ^([4](ch03.html#idm45720237468928-marker)) Scikit-Learn classifiers always have
    either a `decision_function()` method or a `predict_proba()` method, or sometimes
    both.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch03.html#idm45720237468928-marker)) Scikit-Learn分类器总是具有`decision_function()`方法或`predict_proba()`方法，有时两者都有。
- en: ^([5](ch03.html#idm45720217874768-marker)) Scikit-Learn offers a few other averaging
    options and multilabel classifier metrics; see the documentation for more details.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch03.html#idm45720217874768-marker)) Scikit-Learn提供了一些其他平均选项和多标签分类器指标；更多细节请参阅文档。
- en: ^([6](ch03.html#idm45720217595248-marker)) You can use the `shift()` function
    from the `scipy.ndimage.interpolation` module. For example, `shift(image, [2,
    1], cval=0)` shifts the image two pixels down and one pixel to the right.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch03.html#idm45720217595248-marker)) 您可以使用`scipy.ndimage.interpolation`模块中的`shift()`函数。例如，`shift(image,
    [2, 1], cval=0)`将图像向下移动两个像素，向右移动一个像素。
