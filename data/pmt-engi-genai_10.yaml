- en: Chapter 10\. Building AI-Powered Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章\. 构建AI驱动应用程序
- en: In this chapter, you’ll apply the five principles of prompting to an end-to-end
    AI workflow for content writing. The service will write blog posts based on the
    user’s responses to interview questions, in the style of the user’s writing. This
    system was first documented on the [Saxifrage blog](https://oreil.ly/saxifrage).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将应用提示的五个原则到内容写作的端到端AI工作流程中。该服务将根据用户对访谈问题的回答，以用户的写作风格撰写博客文章。这个系统最初在[Saxifrage博客](https://oreil.ly/saxifrage)上进行了记录。
- en: AI Blog Writing
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI博客写作
- en: The naive approach to creating a blog writing service using AI would be to prompt
    ChatGPT with `Write a blog post on {blogPostTopic}`. The resulting content would
    be of reasonable quality but wouldn’t likely contain any valuable opinions or
    unique experiences on the topic. The content would also likely be short and generic
    and therefore unlikely to rank on Google.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI创建博客写作服务的天真方法是将`Write a blog post on {blogPostTopic}`提示给ChatGPT。生成的内容质量可能合理，但不太可能包含关于该主题的有价值意见或独特经验。内容也可能很短且通用，因此不太可能排在谷歌搜索结果的前列。
- en: A more sophisticated approach might be to build up a longer prompt with further
    instructions. Detail on the prescribed writing tone, architecture of the blog
    post, and keywords to include could be added. An example of a common blog post
    [writing prompt](https://oreil.ly/uMfZa) can be seen here.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更复杂的方法可能是构建一个更长的提示，并添加进一步的指令。可以添加关于规定的写作风格、博客文章的结构和要包含的关键词的详细信息。一个常见的博客文章[写作提示](https://oreil.ly/uMfZa)的例子可以在这里看到。
- en: 'Input:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This longer, more sophisticated prompt is likely to result in better quality
    content. However, let’s run through the five principles of prompting as a checklist:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更长、更复杂的提示可能会产生更好的内容质量。然而，让我们通过提示的五个原则作为清单来运行一下：
- en: Direction
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 方向
- en: There are some instructions provided, such as the tone, using transition words,
    and an active voice. However, the content is still likely to sound like AI, and
    not like the user.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一些指令，例如语气、使用过渡词和主动语态。然而，内容仍然可能听起来像AI，而不是用户的声音。
- en: Format
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 格式
- en: Although there are some mentions of structure, including dictating nine sections
    of two paragraphs, it’s likely these instructions will be ignored. ChatGPT is
    bad at math and is often unable to follow instructions dictating a number of sections
    or words.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有一些关于结构的提及，包括指示九个两段的内容，但这些指令很可能会被忽略。ChatGPT在数学方面表现不佳，通常无法遵循指示多个部分或单词的数量。
- en: Examples
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: There are no samples of how to do the task given, which is likely to harm the
    reliability of running this prompt across multiple topics or even multiple times
    on the same topic. Even providing one example (a one-shot prompt) could radically
    help improve quality.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有提供如何执行任务的示例，这可能会损害在多个主题或甚至在同一主题上多次运行此提示的可靠性。即使提供一个示例（一次性提示）也可能极大地帮助提高质量。
- en: Evaluation
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 评估
- en: This is an example of *blind prompting* (adding instructions to a prompt [without
    testing them](https://oreil.ly/r7sXi)). It’s likely some of these instructions
    make no difference to quality (unnecessarily costing tokens) or might even degrade
    quality.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*盲目提示*（在不测试的情况下将指令添加到提示中）的例子。[without testing them](https://oreil.ly/r7sXi)。这些指令中的一些可能对质量没有影响（不必要地消耗令牌），甚至可能降低质量。
- en: Division
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 分解
- en: The entire task is attempted with just one prompt, which is likely to harm performance.
    Without breaking the task into subtasks, it’s hard to understand which part of
    the process is suceeding or failing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 整个任务仅用一个提示尝试完成，这可能会损害性能。如果不将任务分解为子任务，就很难理解哪个部分的过程是成功的或失败的。
- en: Through this chapter, you’ll create multiple LLM chain components. Each chain
    will be implemented in LangChain to make it more maintainable and to give easy
    logging for monitoring and optimization. The resulting system will help you generate
    *human-sounding* content based on the unique opinions and experiences of the user.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，你将创建多个LLM链组件。每个链将在LangChain中实现，使其更易于维护，并便于监控和优化时的日志记录。这个系统将帮助你根据用户的独特观点和经验生成*听起来像人*的内容。
- en: It’s crucial that you first prepare your workspace with the necessary tools.
    Therefore, let’s shift our focus toward topic research and start setting up your
    programming environment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先准备好你的工作空间，配备必要的工具至关重要。因此，让我们将重点转向主题研究，并开始设置你的编程环境。
- en: Topic Research
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题研究
- en: 'You will need to install several Python packages to effectively use LangChain’s
    document loaders, including the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要安装几个Python包才能有效地使用LangChain的文档加载器，包括以下包：
- en: google-searchresults
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: google-searchresults
- en: A Python library designed to scrape and process Google search results.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于抓取和处理Google搜索结果的Python库。
- en: pandas
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: pandas
- en: This offers data structures and operations for manipulating numerical tables
    and time series data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了操作数值表和时间序列数据的数据结构和操作。
- en: html2text
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: html2text
- en: This tool converts HTML from files or web pages into markdown (*.md*) files
    or text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具将文件或网页中的HTML转换为markdown (*.md*) 文件或文本。
- en: pytest-playwright
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: pytest-playwright
- en: This package enables end-to-end testing with Playwright.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此包使您可以使用Playwright进行端到端测试。
- en: chromadb
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: chromadb
- en: ChromaDB is an open source vector database.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ChromaDB是一个开源向量数据库。
- en: nest_asyncio
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: nest_asyncio
- en: This extends the Python standard `asyncio` to patch and render it compatible
    with Jupyter Notebooks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这扩展了Python标准的`asyncio`，使其与Jupyter Notebooks兼容。
- en: 'Installation of these packages can be achieved easily with this command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此命令可以轻松安装这些包：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Additionally, you’ll be using LangChain’s document loaders that require Playwright.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还将使用需要Playwright的LangChain文档加载器。
- en: 'Type this command on your terminal: **playwright install**.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的终端上输入此命令：**playwright install**。
- en: 'Additionally, you’ll need to choose a `TOPIC` and set environment variables
    for both `SERPAPI_API_KEY` and `STABILITY_API_KEY`. If you’re running the script
    without Jupyter Notebook, then you won’t need to use any of the `nest_asyncio`
    code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还需要选择一个`TOPIC`并为`SERPAPI_API_KEY`和`STABILITY_API_KEY`设置环境变量。如果您在没有Jupyter
    Notebook的情况下运行脚本，那么您不需要使用任何`nest_asyncio`代码：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, you’ll focus on summarizing web content efficiently:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将专注于高效地总结网络内容：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, import the required tools and then fetch the web page content related
    to your `TOPIC`. After setting up your `ChatOpenAI` model, you’ll utilize a `text_splitter`
    to manage text chunks. The splitter ensures no snippet is too long, while maintaining
    context with overlap. Then create the `PydanticOutputParser` to handle and structure
    the summaries. By feeding the extracted documents through a dedicated summarization
    function, the LLM produces concise summaries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入所需的工具，然后获取与您的`TOPIC`相关的网页内容。在设置好`ChatOpenAI`模型后，您将使用`text_splitter`来管理文本块。分割器确保没有片段过长，同时保持上下文重叠。然后创建`PydanticOutputParser`来处理和结构化摘要。通过将提取的文档通过专门的摘要函数，LLM产生简洁的摘要。
- en: If you would like to dive deeper into the `create_all_summaries` function, check
    [*custom_summarize_chain.py*](https://oreil.ly/KyKjS).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解`create_all_summaries`函数，请查看[*custom_summarize_chain.py*](https://oreil.ly/KyKjS)。
- en: 'Some key points to highlight are that you can *subclass* most classes within
    LangChain. For example, you can overide the default `ChromiumLoader` to be asynchronous:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一些需要强调的关键点包括，您可以在LangChain中的大多数类中进行*子类化*。例如，您可以覆盖默认的`ChromiumLoader`以使其异步：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By subclassing `ChromiumLoader`, you can easily create a custom implementation
    to *asynchronously scrape content* from multiple URLs using the Chrome browser.
    `get_html_content_from_urls` fetches HTML content from a list of URLs, ensuring
    no duplicates and handling potential errors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过子类化`ChromiumLoader`，您可以轻松创建一个自定义实现，使用Chrome浏览器从多个URL异步*抓取内容*。`get_html_content_from_urls`从URL列表中获取HTML内容，确保没有重复并处理潜在的错误。
- en: Expert Interview
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专家访谈
- en: 'Now that you’ve successfully extracted the summaries from Google for the top
    three results, you’ll conduct an interview with an LLM, generating relevant questions
    to make sure that your article has a unique perspective using an `InterviewChain`
    class:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经成功从Google提取了前三条结果摘要，您将进行一次与LLM的访谈，生成相关问题，以确保您的文章使用`InterviewChain`类具有独特的视角：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: InterviewChain instantiation
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: InterviewChain实例化
- en: With your topic and obtained summaries in hand, create an instance of `InterviewChain`,
    tailoring it to your data’s unique context.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有您的话题和获得的摘要后，创建一个`InterviewChain`实例，根据您数据独特的上下文进行定制。
- en: Generating questions
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 生成问题
- en: By simply calling the `interview_chain`, you kickstart the process of generating
    a series of probing questions derived from your summaries.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单地调用`interview_chain`，您就可以启动从您的摘要中生成一系列探究性问题的过程。
- en: Interactive Q&A session
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 互动问答环节
- en: Dive into an engaging loop where each derived question is printed, prompting
    you for an answer with `input()`. Your response is then saved back to the Pydantic
    object.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 进入一个引人入胜的循环，其中每个派生问题都会打印出来，并使用`input()`提示你回答。然后你的回答会被保存回Pydantic对象。
- en: Give Direction
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给出方向
- en: Giving an LLM unique answers provides unique context, and this allows an LLM
    to generate richer, more nuanced responses, ensuring your article offers a fresh
    and in-depth perspective.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为LLM提供独特的答案提供了独特的上下文，这允许LLM生成更丰富、更细腻的回复，确保你的文章提供新颖且深入的视角。
- en: 'All of the code for `InterviewChain` is in *[expert_interview_chain.py](https://oreil.ly/0d5Hi)*.
    It has two significant components:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`InterviewChain`的所有代码都在*[expert_interview_chain.py](https://oreil.ly/0d5Hi)*中。它有两个显著组件：'
- en: A custom `System` message
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一个定制的`System`消息
- en: 'This prompt includes role prompting, previously generated summaries, the topic,
    and format instructions (for the output parser):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示包括角色提示、之前生成的摘要、主题和格式说明（用于输出解析器）：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Output parsers
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出解析器
- en: 'Diving deeper into the class, you encounter the `PydanticOutputParser`. This
    parser actively structures the LLMs responses into parsable, Pydantic `InterviewQuestions`
    objects:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 深入了解该类，你会遇到`PydanticOutputParser`。这个解析器将LLM的回复主动结构化为可解析的、Pydantic的`InterviewQuestions`对象：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In essence, you’re orchestrating a conversation with the AI and instructing
    it to conceive potent questions that amplify content insights, all the while making
    customization a breeze.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，你正在与AI进行对话，并指导它构思出能够增强内容洞察力的强大问题，同时使定制变得轻而易举。
- en: Generate Outline
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成大纲
- en: 'Including the previous interview and research, you can generate an outline
    for the post with `BlogOutlineGenerator`. The `TOPIC`, `question_answers`, and
    Google `summaries` are passed to provide additional context:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 包括之前的访谈和研究，你可以使用`BlogOutlineGenerator`生成文章的大纲。将`TOPIC`、`question_answers`和Google的`summaries`传递进去，以提供额外的上下文：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s explore the `BlogOutlineGenerator` class in detail:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细探索`BlogOutlineGenerator`类：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A `BlogOutline` Pydantic object is created that contains `title` and `sub_headings`
    keys. Also, the outline chain is set up using LangChain expression language (LCEL)
    that passes the prompt into the chat model and then finally into the output parser:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含`title`和`sub_headings`键的`BlogOutline` Pydantic对象。同时，使用LangChain表达式语言（LCEL）设置大纲链条，将提示传递到聊天模型，然后最终传递到输出解析器：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: By using a Pydantic output parser, the chain will return a `BlogOutline` Pydantic
    object that will be used in future chains.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Pydantic输出解析器，链条将返回一个用于未来链条的`BlogOutline` Pydantic对象。
- en: Text Generation
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本生成
- en: 'After obtaining a summary, interview questions, and a blog post outline, it’s
    time to start generating the text. The `ContentGenerator` class integrates SEO
    expertise with several LLM techniques, which include the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得摘要、访谈问题和博客文章大纲后，是时候开始生成文本了。`ContentGenerator`类将SEO专业知识与几种LLM技术相结合，包括以下内容：
- en: Embeddings and retrieval
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入和检索
- en: This efficiently splits and vectorizes original web pages, storing them in the
    Chroma database and retrieving relevent web page text while writing each section.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这有效地将原始网页分割和矢量化，存储在Chroma数据库中，并在撰写每个部分时检索相关网页文本。
- en: Custom memory
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 定制记忆
- en: While crafting each blog section, it uses memory to avoid repeating the same
    information, while also summarizing the conversation if it becomes too long.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写每个博客部分时，它使用记忆来避免重复相同的信息，同时如果对话变得过长，还会总结对话。
- en: Bespoke context
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 定制上下文
- en: 'The LLM has a mixture of information, including your previous interview insights,
    what has been said before, and snippets of relevant web page text from Google:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLM包含混合信息，包括你之前的访谈洞察、之前所说的话以及来自Google的相关网页文本片段：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: All of the source code is within *[article_generation.py](https://oreil.ly/0IFyI)*,
    but let’s specifically focus on three components that are key to this chain.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所有源代码都在*[article_generation.py](https://oreil.ly/0IFyI)*中，但让我们特别关注这个链条中的三个关键组件。
- en: 'The `OnlyStoreAIMemory` class is a customized subclass of `ConversationSummary​BufferMemory`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`OnlyStoreAIMemory`类是`ConversationSummaryBufferMemory`的定制子类：'
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It’s tailored to ensure that the chat messages memory remains concise and relevant
    by *exclusively storing AI-generated messages*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 它专门设计用来确保聊天消息的记忆保持简洁且相关，通过*仅存储AI生成的消息*。
- en: This deliberate choice bypasses storing retrieved documents that are used within
    the generation step, preventing memory bloat. Furthermore, the memory mechanism
    ensures the AI remains aware of its prior writings, enabling it to offer condensed
    summaries if the accumulated context surpasses set limits.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个故意的选择绕过了存储在生成步骤中使用的检索到的文档，防止了内存膨胀。此外，内存机制确保AI对其先前的写作保持意识，使其能够在累积的上下文超过设定限制时提供简化的摘要。
- en: 'The `generate_blog_post` function loops through all of the subheadings and
    tries to retrieve as many relevant documents as possible while fitting in the
    current context length:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate_blog_post`函数遍历所有子标题，并尝试在当前上下文长度内检索尽可能多的相关文档：'
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This function, `generate_blog_post`, iterates over each subheading. It attempts
    to fetch up to five relevant documents. If there’s an issue fetching the documents,
    it smartly decreases the number and tries again. If all attempts fail, it gracefully
    defaults to no documents.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数，`generate_blog_post`，会遍历每个子标题。它尝试获取最多五篇相关文档。如果获取文档出现问题时，它会智能地减少数量并再次尝试。如果所有尝试都失败，它会优雅地默认为没有文档。
- en: 'Finally, the prompt for generating each section is very context rich:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，生成每个部分的提示非常丰富：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `section_prompt` elegantly sets the stage by announcing the specific section
    you’re working on, using `{subheading.title}`. But it doesn’t stop there. By feeding
    the LLM with `{relevant_documents}`, it offers background and depth, while explicitly
    cautioning against plagiarism. Moreover, by including insights from your interview
    via `{self.questions_and_answers}`, the prompt ensures that valuable information
    is front and center. Finally, it sets clear expectations on the format, the inclusion
    of certain features, and the topic at hand. This makes the LLM not just a tool
    but an informed coauthor, working diligently alongside you to create content.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`section_prompt`通过宣布你正在工作的特定部分，使用`{subheading.title}`，巧妙地设置了场景。但它并没有就此停止。通过向LLM提供`{relevant_documents}`，它提供了背景和深度，同时明确警告不要抄袭。此外，通过包含通过`{self.questions_and_answers}`的你的访谈洞察，提示确保了有价值的信息处于最前沿。最后，它对格式、某些功能的包含以及当前的主题设定了明确的期望。这使得LLM不仅仅是一个工具，而是一个信息丰富的合著者，与你一起勤奋地工作，共同创造内容。'
- en: Writing Style
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写作风格
- en: Now that the article is written, we can go a step further in terms of making
    it sound uniquely human, by rewriting the content in a specific writing style.
    This will go a long way in making the content less detectable as obviously AI
    (though ethically you should still declare any AI assistance) and decreasing the
    amount of time you spend editing the final draft before publishing.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在文章已经写好，我们可以更进一步，使其听起来更像是人类所写，通过以特定的写作风格重写内容。这将大大减少内容被明显识别为AI（尽管从伦理上讲，你应该仍然声明任何AI辅助）的机会，并减少你在发布前编辑最终草稿所花费的时间。
- en: Before rewriting, you need to know what writing style you want to emulate, be
    it your own or someone else’s. One common approach is to ask ChatGPT to summarize
    the writing style of someone who is famous, or at least popular enough in your
    industry to appear in ChatGPT’s training data. Commonly the model will want to
    respond with the name of the author and examples of writing, so adding instructions
    not to and ending the prompt with a bullet point (or an `-` character in this
    case) will give you the format you need.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在重写之前，你需要知道你想要模仿的写作风格，无论是你自己的还是别人的。一种常见的方法是要求ChatGPT总结某个著名人物或至少在你所在行业足够流行，以至于出现在ChatGPT的训练数据中的写作风格。通常模型会想要以作者的名字和写作示例作为回应，所以添加不要这样做的说明，并以一个项目符号（或在这个情况下是`-`字符）结束提示，将为你提供所需的格式。
- en: 'Input:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Often provided only a single sample of text, ChatGPT can generate a reasonable
    writing style guide, which can then be used for rewriting. Once the writing style
    is defined, elements can be mixed and matched to arrive at a more ideal style.
    The following example takes elements from both Mike Taylor’s writing style and
    Harry Dry’s writing style from the previous example. This is another example of
    meme unbundling, as discussed in [“Meme Unbundling”](ch08.html#vector_databases_08):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通常只提供一个文本样本，ChatGPT可以生成一个合理的写作风格指南，然后可以用于重写。一旦定义了写作风格，就可以混合匹配元素，以达到更理想的风
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In practice this part of the AI writing process is the most difficult to get
    right, and it’s the only one that requires the larger and more expensive GPT-4
    model to get passable results. If this part of the process isn’t right, the user
    can be left doing a lot of manual editing to get the writing in the house style.
    Given the strategic importance of this prompt, it makes sense to do a round of
    [prompt optimization](https://oreil.ly/H3VtJ), trying multiple approaches.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这个AI写作过程的部分是最难做对的，也是唯一需要更大、更昂贵的GPT-4模型才能得到可接受结果的部分。如果这个过程的部分不正确，用户可能需要做大量的手动编辑才能使写作符合公司风格。鉴于这个提示的战略重要性，进行一轮[提示优化](https://oreil.ly/H3VtJ)，尝试多种方法是有意义的。
- en: 'When optimizing prompts you can run the same prompt multiple times and check
    the average performance against an evaluation metric. As an example, here are
    the results of testing five different prompt approaches against an evaluation
    metric of embedding distance. The lower the score, the closer the embeddings of
    the response were to a reference answer (the text as rewritten manually is in
    the correct style). The prompts tested were as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化提示时，您可以多次运行相同的提示并检查其对评估指标的总体表现。例如，以下是测试五种不同的提示方法对嵌入距离评估指标的结果。分数越低，响应的嵌入与参考答案（手动重写的文本，风格正确）的嵌入越接近。测试的提示如下：
- en: A
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: A
- en: Control—the standard prompt as detailed in the preceding example.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 控制——如前例中详细说明的标准提示。
- en: B
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: B
- en: One-shot writing sample—we provided one sample of text, and asked GPT-4 to describe
    the writing style.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一份写作样本——我们提供了一份文本样本，并要求GPT-4描述其写作风格。
- en: C
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: C
- en: Three-shot rewriting example—we gave three samples of the input text to GPT-4
    and the rewritten version and asked it to describe the writing style.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 三份重写示例——我们向GPT-4提供了三个输入文本样本及其重写版本，并要求它描述写作风格。
- en: D
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: D
- en: Three-shot writing sample—same as previous, except without the input text, only
    the final samples of Mike’s writing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 三份写作样本——与之前相同，只是没有输入文本，只有迈克写作的最终样本。
- en: 'These prompts were [tested in an experiment we ran](https://oreil.ly/vRRYO)
    against three test cases—memetics, skyscraper technique, and value-based pricing—which
    were snippets of text that were first generated by ChatGPT on a topic, for example:
    *explain value-based pricing*. We then manually rewrote the text in the style
    we desired to make reference texts for comparison. The embedding distance was
    calculated by getting the embeddings for the reference text (from OpenAI’s `text-embedding-ada-002`)
    and comparing them to the embeddings for the output from the prompt, using *cosine
    similarity* (a method for calculating the distance between two sets of numbers),
    as detailed in [LangChain’s embedding evaluator](https://oreil.ly/400gJ) ([Figure 10-1](#figure-10-1)).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些提示在三个测试案例中进行了测试，这些案例是我们在实验中进行的——[我们进行的实验](https://oreil.ly/vRRYO)——包括遗传学、摩天大楼技术和基于价值的定价，这些是ChatGPT在一个主题上生成的文本片段，例如：*解释基于价值的定价*。然后我们手动重写了文本，以形成我们想要的参考文本进行比较。通过获取参考文本的嵌入（来自OpenAI的`text-embedding-ada-002`）并将其与提示输出的嵌入进行比较，使用*余弦相似度*（一种计算两组数字之间距离的方法）来计算嵌入距离，具体细节请参阅[LangChain的嵌入评估器](https://oreil.ly/400gJ)
    ([图10-1](#figure-10-1))。
- en: '![pega 1001](assets/pega_1001.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1001](assets/pega_1001.png)'
- en: Figure 10-1\. Test results from prompt optimization
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1\. 提示优化测试结果
- en: 'As you can see from the results in [Figure 10-1](#figure-10-1), some prompts
    work better than others, and some cases are easier for the AI to deliver on. It’s
    important to test across multiple cases, with 10 or more runs per case, to get
    a realistic result for each prompt. Otherwise, the nondeterministic nature of
    the responses might mean you’ll think the performance was better or worse than
    you can actually expect when scaling up usage of a prompt. Here was the final
    resulting prompt that performed best:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从[图10-1](#figure-10-1)的结果中可以看到，一些提示的效果比其他提示好，有些案例对AI来说更容易实现。进行多案例测试，每个案例10次或更多，以获得每个提示的实际情况。否则，响应的非确定性可能意味着您在扩大提示使用时，对性能的期望可能比实际更好或更差。以下是表现最佳的最终结果提示：
- en: '[PRE18]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Evaluate Quality
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估质量
- en: Without testing the writing style, it would be hard to guess which prompting
    strategy would win. With a small amount of testing, you can be more confident
    this is the correct approach. Testing doesn’t have to be highly organized or systematized,
    and the builders of many successful AI products like [GitHub Copilot](https://oreil.ly/vu0IU)
    admit their eval process was haphazard and messy (but it got the job done!).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 不测试写作风格，很难猜测哪种提示策略会获胜。通过少量测试，你可以更有信心这是正确的方法。测试不需要高度组织或系统化，许多成功AI产品的构建者，如[GitHub
    Copilot](https://oreil.ly/vu0IU)，承认他们的评估过程是杂乱无章的（但完成了工作！）。
- en: In this project we’ll use this well-tested example, but you may take this opportunity
    to try to beat this score. The repository with the reference texts and code is
    [publicly available on GitHub](https://oreil.ly/O6RdB), and please feel free to
    contribute to the repository if you find a better approach. One potential path
    to try is fine-tuning, which may get you better results in matching the writing
    style if you have enough samples ([OpenAI recommends at least 50](https://oreil.ly/OMMKi)).
    Even if you don’t perform an A/B test (comparing two versions of a prompt to see
    which one performs better) on this prompt, these results should convince you of
    the value of testing your prompts in general.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们将使用这个经过良好测试的示例，但你也可以利用这个机会尝试提高这个分数。包含参考文本和代码的仓库在GitHub上[公开可用](https://oreil.ly/O6RdB)，如果你发现了一个更好的方法，请随时向仓库贡献。一个可以尝试的潜在路径是微调，如果你有足够的样本（[OpenAI建议至少50个](https://oreil.ly/OMMKi)），这可能会在匹配写作风格时得到更好的结果。即使你不对这个提示进行A/B测试（比较两个提示版本以查看哪个表现更好），这些结果也应该让你相信测试你的提示在一般情况下是有价值的。
- en: Title Optimization
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标题优化
- en: You can optimize the content’s title by generating various options, testing
    them through A/B prompts, and gauging their effectiveness with a thumbs-up/thumbs-down
    rating system, as shown in [Figure 10-2](#figure-10-2).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过生成各种选项，通过A/B提示测试它们，并使用点赞/踩不点赞的评分系统来衡量它们的有效性来优化内容的标题，如图10-2所示。
- en: '![pega 1002](assets/pega_1002.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1002](assets/pega_1002.png)'
- en: Figure 10-2\. A simple thumbs-up and thumbs-down rating system
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-2. 简单的点赞/踩不点赞评分系统
- en: After evaluating all the prompts, you’ll be able to see which prompt had the
    highest average score and the token usage ([Figure 10-3](#figure-10-3)).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估所有提示后，你将能够看到哪个提示的平均分数最高，以及令牌使用情况（图10-3）。
- en: '![pega 1003](assets/pega_1003.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1003](assets/pega_1003.png)'
- en: Figure 10-3\. Example A/B test results after manually evaluating a prompt
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3. 手动评估提示后的A/B测试结果示例
- en: If you still aren’t getting the level of quality you need from this prompt,
    or the rest of the chain, this is a good time to experiment with a prompt optimization
    framework like [DSPy](https://oreil.ly/dspy). Upon defining an evaluation metric,
    DSPy tests different combinations of instructions and few-shot examples in your
    prompts, selecting the best-performing combination automatically. [See their documentation
    for examples](https://oreil.ly/vercel).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然从这个提示或整个链中得不到你需要的质量水平，这是一个尝试使用像[DSPy](https://oreil.ly/dspy)这样的提示优化框架的好时机。在定义一个评估指标后，DSPy会在你的提示中测试不同的指令和少量示例的不同组合，自动选择表现最佳的组合。[查看他们的文档中的示例](https://oreil.ly/vercel)。
- en: AI Blog Images
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI博客图片
- en: One thing you can do to make your blog look more professional is to add custom
    illustrations to your blog posts, with a consistent style. At its maximum this
    may mean training a Dreambooth model, as covered in [Chapter 9](ch09.html#advanced_image_09),
    on your brand style guide or a mood board of images with a certain visual consistency
    or aesthetic quality you value. In many cases, however, training a custom model
    is not necessary, because a style can be replicated well using simple prompting.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以采取的一个让你的博客看起来更专业的做法是，给你的博客文章添加具有一致风格的定制插图。在最极端的情况下，这可能意味着训练一个如[第9章](ch09.html#advanced_image_09)所述的Dreambooth模型，用于你的品牌风格指南或一系列具有特定视觉一致性或你珍视的美学质量的图片板。然而，在许多情况下，训练一个定制模型并不是必要的，因为可以通过简单的提示很好地复制这种风格。
- en: One popular visual style among business-to-business (B2B) companies, [Corporate
    Memphis](https://oreil.ly/3UHQs), is characterized by its vibrant color palettes,
    bold and asymmetric shapes, and a mix of both organic and geometric forms. This
    style arose as a [costly signaling technique](https://oreil.ly/haoTZ), showing
    that the company could afford to commission custom illustrations from a designer
    and therefore was serious enough to be trusted. You can replicate this style with
    AI, saving yourself the cost of custom illustrations, while benefiting from the
    prior associations formed in consumers’ minds. [Figure 10-4](#figure-10-4) shows
    an example of Corporate Memphis style generated by Stable Diffusion, via the Stability
    AI API.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在商业对商业（B2B）公司中，一种流行的视觉风格是[Corporate Memphis](https://oreil.ly/3UHQs)，其特点是有活力的色彩搭配、大胆且不对称的形状，以及有机和几何形式的混合。这种风格作为一种[昂贵信号技术](https://oreil.ly/haoTZ)出现，表明公司有能力委托设计师进行定制插图，因此足够认真，值得信赖。你可以用AI复制这种风格，同时节省定制插图的成本，并从消费者心中形成的先验关联中受益。[图10-4](#figure-10-4)显示了Stable
    Diffusion通过Stability AI API生成的Corporate Memphis风格示例。
- en: 'Input:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[Figure 10-4](#figure-10-4) shows the output.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-4](#figure-10-4)显示了输出。'
- en: '![pega 1004](assets/pega_1004.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1004](assets/pega_1004.png)'
- en: 'Figure 10-4\. Corporate Memphis: “websites being linked together”'
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-4. Corporate Memphis：“网站相互链接”
- en: Give Direction
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给出指示
- en: Stable Diffusion is trained on many different styles, including obscure or niche
    styles like Corporate Memphis. If you know the name of a style, often that’s all
    that’s needed to guide the model toward the desired image. You can find a variety
    of art styles within this [visual prompt builder](https://oreil.ly/nxEzu).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion在许多不同的风格上进行了训练，包括像Corporate Memphis这样的不为人知或小众风格。如果你知道一个风格的名字，通常这就是引导模型向期望的图像迈进所需的所有。你可以在这个[视觉提示构建器](https://oreil.ly/nxEzu)中找到各种艺术风格。
- en: In our blog writing project we could ask the user for an idea of what image
    they want to accompany the blog post, but let’s make it easier for them and automate
    this step. You can make an API call to ChatGPT and get back an idea for what could
    go in the image. When you get that response, it can form the basis of your prompt
    to Stability AI, a technique called *meta-prompting*, where one AI model writes
    the prompt for another AI model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的博客写作项目中，我们可以要求用户提出他们想要与博客文章一起使用的图像的想法，但让我们让这个过程更简单，并自动化这一步。你可以调用ChatGPT的API并获取一个关于图像可能包含的内容的想法。当你得到这个响应时，它可以成为你向Stability
    AI发送提示的基础，这是一种称为*元提示*的技术，其中一个AI模型为另一个AI模型编写提示。
- en: 'Input:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Stability AI hosts Stable Diffusion, including the latest models like Stable
    Diffusion XL, in their DreamStudio platform. You can also call them [via API](https://oreil.ly/XD_jQ)
    or via the Stability AI SDK (a library that simplifies the process of making the
    API call). In the following example, we’ll create a function for calling Stability
    AI with our prompt.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Stability AI在其DreamStudio平台上托管Stable Diffusion，包括最新的Stable Diffusion XL模型。你也可以通过API（[https://oreil.ly/XD_jQ](https://oreil.ly/XD_jQ)）或通过Stability
    AI SDK（一个简化API调用过程的库）来调用它们。在下面的例子中，我们将创建一个用于调用Stability AI的函数，使用我们的提示。
- en: 'Input:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[Figure 10-5](#figure-10-5) shows the output.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-5](#figure-10-5)显示了输出。'
- en: '![pega 1005](assets/pega_1005.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1005](assets/pega_1005.png)'
- en: Figure 10-5\. A seamless collage or mosaic of diverse cultural elements from
    around the world
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-5. 来自世界各地的各种文化元素的无缝拼贴或马赛克
- en: 'To encapsulate the whole system for image generation, you can bring the call
    to ChatGPT and the resulting call to Stability AI together in one function that
    uses the `outline_result.title`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了封装整个图像生成系统，你可以将调用ChatGPT和随后调用Stability AI的过程合并到一个使用`outline_result.title`的函数中：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `create_image` function in *[image_generation_chain.py](https://oreil.ly/cWpXH)*
    utilizes Stable Diffusion to create an image based on a generated title from GPT-4:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`[image_generation_chain.py](https://oreil.ly/cWpXH)`中的`create_image`函数利用Stable
    Diffusion根据GPT-4生成的标题创建图像：'
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here’s the high-level process:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是高级流程：
- en: With the `ChatOpenAI` model, you’ll craft an image prompt for your given `title`.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ChatOpenAI`模型，你将为给定的`title`制作一个图像提示。
- en: Using the Stability AI API, you’ll send this prompt to generate an image with
    precise styling instructions.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Stability AI API，你将发送这个提示以生成具有精确风格说明的图像。
- en: Then you’ll decode and save this image locally using a unique filename and return
    its path.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后你将使用一个唯一的文件名解码并保存此图像到本地，并返回其路径。
- en: With these steps, you’re not just prompting the AI to create textual content,
    but you’re directing it to bring your prompts to life visually.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，您不仅是在提示 AI 创建文本内容，而且是在指导它将您的提示以视觉形式呈现出来。
- en: This system is flexible based on whatever style you decide to use for blog images.
    Parameters can be adjusted as needed, and perhaps this API call can be replaced
    in future with a call to a custom fine-tuned Dreambooth model of your own. In
    the meantime, however, you have a quick and easy way to generate a custom image
    for each blog post, without requiring any further input from the user, in a consistent
    visual style.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统根据您为博客图片选择的任何样式都是灵活的。参数可以根据需要调整，也许将来可以用您自己的定制微调 Dreambooth 模型的调用来替换这个 API
    调用。然而，在此期间，您有一个快速简单的方法为每篇博客生成自定义图片，无需用户进一步输入，保持一致的视觉风格。
- en: User Interface
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户界面
- en: Now that you have your script working end to end, you probably want to make
    it a little easier to work with, and maybe even get it into the hands of people
    who can give you feedback. The frontend of many AI tools in production is typically
    built using JavaScript, specifically the [NextJS](https://nextjs.org) framework
    based on React. This is usually paired with a CSS library such as [Tailwind CSS](https://tailwindcss.com),
    which makes rapid prototyping of design elements easier.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的脚本已经从头到尾运行正常，您可能希望让它更容易使用，甚至可能希望将其交给可以提供反馈的人。生产中的许多 AI 工具的前端通常使用 JavaScript
    构建，特别是基于 React 的 [NextJS](https://nextjs.org) 框架。这通常与一个 CSS 库如 [Tailwind CSS](https://tailwindcss.com)
    配对，这使得设计元素的快速原型设计变得更容易。
- en: However, most of your AI code is likely in Python at this stage, and switching
    programming languages and development environments can be a daunting challenge.
    As well as learning JavaScript, NextJS, and Tailwind, you may also run into a
    series of issues getting a server running for your Python code, and a database
    live for your application and user data, and then integrating all of that with
    a frontend web design.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前您的大部分 AI 代码可能都是用 Python 编写的，切换编程语言和开发环境可能是一个令人畏惧的挑战。除了学习 JavaScript、NextJS
    和 Tailwind，您还可能遇到一系列问题，比如为您的 Python 代码启动服务器，为您的应用程序和用户数据保持数据库活跃，然后将所有这些与前端网页设计集成。
- en: Instead of spending a lot of time spinning up servers, building databases, and
    adjusting button colors, it might make sense to create a simple prototype frontend
    to get early feedback, before investing too much at this stage in an unproven
    idea. Once you have built and tested a simple interface, you’ll have a better
    understanding of what to build when you do need to get your app production-ready.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 与其花费大量时间启动服务器、构建数据库和调整按钮颜色，不如创建一个简单的原型前端来获取早期反馈，在投入太多资源于这个阶段的未经证实的想法之前。一旦您构建并测试了一个简单的界面，您将更好地了解在需要将您的应用程序投入生产时需要构建什么。
- en: For launching simple user interfaces for AI-based prototypes, there are several
    popular open source interfaces, including [gradio](https://www.gradio.app) and
    [Streamlit](https://streamlit.io). Gradio was acquired by HuggingFace and powers
    the web user interface for many interactive demos of open source AI models, famously
    including the [AUTOMATIC1111](https://oreil.ly/GlwJT) Stable Diffusion Web UI.
    You can quickly build a Gradio interface to make it easier to run your code locally,
    as well as sharing the prototype to get feedback.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于启动基于 AI 的原型的简单用户界面，有几个流行的开源界面，包括 [gradio](https://www.gradio.app) 和 [Streamlit](https://streamlit.io)。Gradio
    被HuggingFace 收购，为许多开源 AI 模型的交互式演示提供了网络用户界面，其中包括著名的 [AUTOMATIC1111](https://oreil.ly/GlwJT)
    稳定扩散 Web UI。您可以快速构建一个 Gradio 界面，使其更容易在本地运行代码，以及分享原型以获取反馈。
- en: We’ve created an interface that allows you to automate the entire process within
    two steps. You can get access to the [gradio source code here](https://oreil.ly/HNqVX).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个界面，允许您在两步内自动化整个流程。您可以通过[这里](https://oreil.ly/HNqVX)获取 gradio 源代码。
- en: Then run the gradio application by going into the [chapter_10 folder](https://oreil.ly/chapter10)
    within your terminal and running `python3 gradio_code_example.py`. The script
    will ask you to enter a `SERPAPI_API_KEY` and a `STABILITY_API_KEY` in your terminal.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在您的终端中进入[chapter_10 文件夹](https://oreil.ly/chapter10)，并运行 `python3 gradio_code_example.py`
    来运行 gradio 应用程序。脚本会要求您在终端中输入 `SERPAPI_API_KEY` 和 `STABILITY_API_KEY`。
- en: Then you can access the gradio interface as shown in [Figure 10-6](#figure-10-6).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以访问如图 [10-6](#figure-10-6) 所示的 gradio 界面。
- en: '![pega 1006](assets/pega_1006.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![pega 1006](assets/pega_1006.png)'
- en: Figure 10-6\. Gradio user interface
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. Gradio 用户界面
- en: When you run gradio, you get an inline interface you can use directly or a URL
    that you can click to open the web interface in your browser. If you run gradio
    with the parameter `share=True`, for example `demo.launch(share=True)`, you get
    a publicly accessible link to share with friends, coworkers, or early users to
    get feedback on your prototype.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 gradio 时，你会得到一个可以直接使用的内联界面，或者一个你可以点击以在浏览器中打开网页界面的 URL。例如，如果你使用 `share=True`
    参数运行 gradio，比如 `demo.launch(share=True)`，你将获得一个公开可访问的链接，可以与朋友、同事或早期用户分享，以获取对您原型的反馈。
- en: After initializing the interface, input a topic by clicking the Summarize and
    Generate Questions button. This will then collect and summarize the Google results
    as well as generate interview questions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化界面后，通过点击“总结和生成问题”按钮输入一个主题。这将收集并总结 Google 结果，并生成面试问题。
- en: You’ll then need to fill in the answers for each question. Finally, click the
    Generate Blog Post & Image button, which will take all the questions, answers,
    and summaries and will create an entire blog post and image using GPT-4!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要填写每个问题的答案。最后，点击“生成博客文章和图像”按钮，这将使用 GPT-4 创建整个博客文章和图像，包括所有问题、答案和总结！
- en: Evaluate Quality
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估质量
- en: The most valuable evaluation data in AI is human feedback, as it has been the
    key to many AI alignment breakthroughs, including those that power ChatGPT. Asking
    for feedback from users via a user interface, or even building feedback mechanisms
    into your product, helps you identify and fix edge cases.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 中，最有价值的评估数据是人类反馈，因为它一直是许多 AI 对齐突破的关键，包括那些为 ChatGPT 提供动力的突破。通过用户界面请求用户反馈，或者甚至将反馈机制构建到你的产品中，有助于你识别和修复边缘情况。
- en: If you are building for research purposes or want to contribute to the open
    source community, consider sharing your gradio demo on Hugging Face Spaces. Hugging
    Face Spaces allows anyone to host their gradio demos freely, and uploading your
    project only takes a few minutes. New spaces can be created via the [Hugging Face
    website](https://oreil.ly/pSrP3), or done programmatically using the Hugging Face
    API.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是为了研究目的构建，或者想要为开源社区做出贡献，考虑在 Hugging Face Spaces 上分享你的 gradio 示例。Hugging Face
    Spaces 允许任何人免费托管他们的 gradio 示例，上传你的项目只需几分钟。可以通过 [Hugging Face 网站](https://oreil.ly/pSrP3)
    创建新空间，或者通过 Hugging Face API 以编程方式完成。
- en: Summary
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Congratulations! You’ve journeyed through the comprehensive world of prompt
    engineering for generative AI. You started with learning the prompt engineering
    principles and explored the historical context of LLMs, gaining awareness of their
    capabilities and the privacy concerns they pose.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经穿越了生成式 AI 提示工程的全面世界。你从学习提示工程原则开始，探索了 LLM 的历史背景，了解了它们的性能和它们带来的隐私问题。
- en: You learned how to extract structured data, apply best practices of prompt engineering,
    and familiarize yourself with an LLM package called LangChain. Then you discovered
    vector databases for storing and querying text based on similarity and ventured
    into the world of autonomous agents.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了如何提取结构化数据，应用提示工程的最佳实践，并熟悉了一个名为 LangChain 的 LLM 包。然后你发现了基于相似性存储和查询文本的向量数据库，并进入了自主代理的世界。
- en: Also, you immersed yourself in image generation techniques using diffusion models,
    learning how to navigate through this latent space. Your journey covered everything
    from format modifiers and art-style replication to inpainting and outpainting
    techniques. Moreover, you explored more advanced usage cases such as prompt expansion,
    meme mapping, and CLIP Interrogator, alongside many others.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你沉浸在扩散模型驱动的图像生成技术中，学习了如何导航这个潜在空间。你的旅程涵盖了从格式修饰符和艺术风格复制到修复和扩展技术的一切。此外，你还探索了更多高级用法案例，如提示扩展、模因映射和
    CLIP 询问器，以及其他许多案例。
- en: Finally, you transitioned toward utilizing prompt engineering for content writing.
    You learned about creating a blog writing service that generates posts based on
    user responses, mimicking their writing styles, along with topic research strategies.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你转向利用提示工程进行内容创作。你学习了如何创建一个基于用户响应生成帖子并模仿其写作风格的博客写作服务，以及主题研究策略。
- en: Overall, this journey not only enriched your knowledge but also equipped you
    with practical skills, setting you up to work professionally in the field of prompt
    engineering.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这次旅程不仅丰富了你的知识，还为你提供了实际技能，使你能够在这个提示工程领域专业工作。
- en: It’s been our pleasure to guide you through the wide domain of prompt engineering
    for generative AI. Thank you for staying with us to the end of this book. We trust
    it will become a useful tool in all your future work with AI.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 指导您穿越生成式AI的广泛领域一直是我们的荣幸。感谢您陪伴我们走到这本书的结尾。我们相信它将成为您未来所有与AI相关工作中的一项有用工具。
- en: We would also greatly appreciate hearing your thoughts about the book, as well
    as any remarkable projects you create using the techniques we’ve discussed.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也非常期待听到您对这本书的看法，以及您使用我们讨论的技术所创造的任何引人注目的项目。
- en: Please feel free to share your feedback or showcase your work by emailing us
    at [hi@brightpool.dev](mailto:hi@brightpool.dev). Once again, thank you! Your
    curiosity and perseverance are what shapes the future of this exciting field,
    and we can’t wait to see what you contribute.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 请随时通过发送电子邮件至[hi@brightpool.dev](mailto:hi@brightpool.dev)与我们分享您的反馈或展示您的作品。再次感谢！您的求知欲和毅力正是塑造这个激动人心的领域未来的关键，我们迫不及待地想看看您将做出怎样的贡献。
- en: Happy prompting!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 快乐地提示！
