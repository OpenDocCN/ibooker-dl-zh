- en: 7 Interpreting query intent through semantic search
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 通过语义搜索解释查询意图
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The mechanics of query interpretation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询解释的机制
- en: Implementing an end-to-end query intent pipeline to parse, enrich, transform,
    and search
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个端到端查询意图管道以解析、丰富、转换和搜索
- en: Tagging and classifying query terms and phrases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记和分类查询术语和短语
- en: Augmenting queries using knowledge graph traversals
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用知识图谱遍历增强查询
- en: Interpreting the semantics of domain-specific query patterns
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释特定领域查询模式的语义
- en: In chapters 5 and 6, we used content and signals to interpret the domain-specific
    meaning of incoming user queries. We discussed phrase identification, misspelling
    detection, synonym discovery, query intent classification, related-terms expansion,
    and even query-sense disambiguation. We mostly discussed these techniques in isolation
    to demonstrate how they each work independently.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5章和第6章中，我们使用内容和信号来解释传入用户查询的特定领域含义。我们讨论了短语识别、拼写错误检测、同义词发现、查询意图分类、相关术语扩展，甚至查询意义消歧。我们主要独立讨论了这些技术，以展示它们各自如何独立工作。
- en: In this chapter, we’ll put all those techniques into practice, integrating them
    into a unified query interpretation framework. We’ll show an example search interface
    that accepts real queries, interprets them, rewrites them to better express the
    end user’s intent, and then returns ranked results.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将所有这些技术付诸实践，将它们整合到一个统一的查询解释框架中。我们将展示一个示例搜索界面，该界面接受真实查询，解释它们，将它们重写以更好地表达最终用户的意图，然后返回排序后的结果。
- en: We should note that multiple paradigms have evolved for implementing semantic
    search, including embedding-based query interpretation and question answering
    (returning extracted or generated answers instead of documents) using large language
    models (LLMs) and pretrained Transformers. These typically involve encoding queries
    into vectors, searching for an approximate nearest neighborhood of vectors, and
    then performing a vector similarity calculation to rank documents. The ranked
    documents are often then analyzed to summarize, extract, or generate answers.
    We’ll cover these LLM-based approaches for semantic search and question answering
    in chapters 13–15\.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该注意，为了实现语义搜索，已经发展出多种范式，包括基于嵌入的查询解释和问答（返回提取或生成的答案而不是文档）使用大型语言模型（LLMs）和预训练的Transformers。这些通常涉及将查询编码为向量，搜索向量的近似最近邻，然后执行向量相似度计算以对文档进行排序。排序后的文档通常随后进行分析以总结、提取或生成答案。我们将涵盖第13-15章中基于LLM的语义搜索和问答方法。
- en: 'We’ll focus in this chapter on the mechanics of integrating each of the AI-powered
    search strategies you’ve already learned to deliver an end-to-end semantic query
    pipeline. We’ll implement the pipeline in four phases:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于将您已经学到的每个AI驱动的搜索策略整合到端到端语义查询管道中。我们将分四个阶段实现该管道：
- en: '*Parsing* the user’s query'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*解析*用户的查询'
- en: '*Enriching* the parsed query with improved context'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*丰富*解析查询以改进上下文'
- en: '*Transforming* the query to optimize for relevance in our target search engine'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转换*查询以优化我们目标搜索引擎的相关性'
- en: '*Searching* using the optimized query'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*搜索*使用优化的查询'
- en: These steps don’t have to be implemented linearly (sometimes they repeat, and
    sometimes steps can be skipped), and they can also be broken down further (for
    example, searching could be broken down into matching, ranking, and reranking).
    Having this consistent framework through which we can integrate any combination
    of AI-powered search techniques will nevertheless be invaluable as you mix and
    match approaches in your own search applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤不必线性实现（有时它们会重复，有时可以跳过步骤），并且还可以进一步分解（例如，搜索可以分解为匹配、排序和重新排序）。然而，通过这个一致的框架，我们可以整合任何组合的AI驱动的搜索技术，这将非常有价值，因为您可以在自己的搜索应用中混合和匹配方法。
- en: 7.1 The mechanics of query interpretation
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 查询解释的机制
- en: 'There is no one “right way” to build a query interpretation framework. Every
    organization building an intelligent search platform is likely to build something
    a bit different, depending on their business needs and the expertise of their
    search team. There are, however, some consistent themes across implementations
    worth exploring:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种“正确”的方式来构建查询解释框架。每个构建智能搜索平台的公司都可能构建出略有不同的事物，这取决于他们的业务需求和搜索团队的专长。然而，在实现中存在一些一致的主题值得探索：
- en: '*Pipelines*—Both when indexing documents and processing queries, it’s useful
    to model all of the necessary parsing, interpretation, and ranking logic as modular
    stages in a workflow. This allows for easy experimentation by swapping out, rearranging,
    or adding processing stages within the pipeline at any time.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**——在索引文档和处理查询时，将所有必要的解析、解释和排名逻辑建模为工作流程中的模块化阶段是有用的。这允许在任何时候通过交换、重新排列或添加管道中的处理阶段来轻松进行实验。'
- en: '*Models*—Whether you are fine-tuning a complex deep-learning-based LLM (chapters
    13–14), a learning-to-rank model (chapters 10–12), a signals-boosting or personalization
    model (chapters 8–9), or a knowledge graph containing synonyms, misspellings,
    and related terms (chapters 5–6), proper query interpretation requires plugging
    in the right models in the right order within the indexing and query pipelines.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**——无论你是微调一个基于复杂深度学习的LLM（第13-14章）、一个学习排序模型（第10-12章）、一个信号增强或个性化模型（第8-9章），还是包含同义词、拼写错误和相关术语的知识图谱（第5-6章），适当的查询解释需要在索引和查询管道中按正确顺序插入正确的模型。'
- en: '*Conditional fallbacks*—You’ll never be able to interpret every query perfectly.
    You could have many models helping interpret one query, while having no clue what
    another query means. It’s usually best to start with a base or “fallback” model
    (usually keyword-based) that can handle any query imperfectly, and to layer in
    more sophisticated models on top, to enhance precision of interpretation. Additionally,
    if no results are found, it might be useful to return recommendations to ensure
    the searcher sees *something* that might be useful, even if it is not exactly
    what they were seeking.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件回退**——你永远无法完美地解释每个查询。你可能有很多模型帮助解释一个查询，而对另一个查询的含义却一无所知。通常最好从一个基础或“回退”模型（通常是基于关键词的）开始，它可以不完美地处理任何查询，并在其上分层更复杂的模型，以提高解释的精确度。此外，如果没有找到结果，返回推荐可能是有用的，以确保搜索者看到一些可能有用的东西，即使它不是他们所寻求的精确内容。'
- en: Figure 7.1 shows an example query pipeline demonstrating each of these themes
    of combining pipeline stages, models, and conditional fallbacks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1展示了一个示例查询管道，演示了这些主题：结合管道阶段、模型和条件回退。
- en: '![figure](../Images/CH07_F01_Grainger.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F01_Grainger.png)'
- en: Figure 7.1 An example query interpretation pipeline
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.1示例查询解释管道
- en: Figure 7.1 takes in the query `bbq near atlanta` and begins with a parse-query
    stage that performs entity extraction on known keywords, locations, or other known
    terms from the query. It then hits a signals-boosting stage, which checks with
    a signals-boosting model (which was introduced in chapter 4 and will be covered
    in much greater detail in chapter 8) to boost the most popular documents for the
    given query.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1接收查询`bbq near atlanta`，并从对查询中已知关键词、位置或其他已知术语进行实体提取的解析查询阶段开始。然后进入信号增强阶段，该阶段会检查一个信号增强模型（在第4章中介绍，将在第8章中详细讨论）以增强给定查询中最受欢迎的文档。
- en: 'Three different, but complementary, approaches are commonly used to interpret
    individual keywords and relate them to each other, all of which are included in
    the example pipeline:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 常常使用三种不同但互补的方法来解释单个关键词并将它们相互关联，所有这些方法都包含在示例管道中：
- en: '*Lexical search*, such as BM25 ranking on Boolean query matches in an inverted
    index'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词汇搜索**，例如在倒排索引中对布尔查询匹配进行BM25排名'
- en: '*Knowledge graph search*, such as ranking the entities found within a query
    and their relationships with the most similar entities in your index using a semantic
    knowledge graph (SKG) or explicitly built knowledge graph'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识图谱搜索**，例如使用语义知识图谱（SKG）或显式构建的知识图谱对查询中找到的实体及其与索引中最相似实体的关系进行排序'
- en: '*Dense vector search*, such as cosine similarity of vectors found with an approximate
    nearest neighborhood of embeddings'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密集向量搜索**，例如使用嵌入的近似最近邻的向量余弦相似度'
- en: Of the three, the most common “default” matching layer tends to be lexical search
    on an inverted index, as this approach allows matching on *any* term that exists
    in the corpus of documents, whether that term is understood or not. The knowledge
    graph and dense vector approaches both rely on being able to relate the terms
    in each query to concepts or entities, and this simply can’t be done in all cases.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这三个中，最常见的“默认”匹配层往往是基于倒排索引的词汇搜索，因为这种方法允许匹配文档集中存在的任何术语，无论该术语是否被理解。知识图谱和密集向量方法都依赖于能够将每个查询中的术语与概念或实体相关联，但这在所有情况下都做不到。
- en: In fact, BM25 ranking often outperforms dense vector approaches on embeddings
    even from state-of-the-art LLMs unless those language models are initially trained
    or fine-tuned on domain-specific content (this may change over time, as pretrained
    LLMs continue to become more robust). We’ll dive into using LLMs starting in chapters
    9 and 13 for personalized search and semantic search, and we’ll spend time fine-tuning
    and using LLMs for more advanced search functionality like question answering
    and generative search in chapters 14 and 15\. We’ll keep our focus in this chapter
    primarily on demonstrating the mechanics of integrating lexical search and knowledge
    graphs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，BM25 排名在嵌入中通常优于密集向量方法，即使是从最先进的 LLMs 中提取的，除非这些语言模型最初是在特定领域内容上训练或微调的（这可能会随时间变化，因为预训练的
    LLMs 继续变得更加健壮）。我们将在第 9 章和第 13 章开始深入探讨使用 LLMs 进行个性化搜索和语义搜索，我们将在第 14 章和第 15 章中花费时间微调和使用
    LLMs 进行更高级的搜索功能，如问答和生成搜索。我们将在本章中主要关注演示将词汇搜索和知识图谱集成的机制。
- en: The figure 7.1 pipeline ends with a backfill/fallback stage, which can be useful
    for inserting additional results in the case that none of the previous stages
    were able to return a full result set. This can be as simple as returning recommendations
    instead of search results (covered in chapter 9), or it could involve returning
    a partially matched query with lower precision.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 管道以一个回填/回退阶段结束，这在之前阶段都无法返回完整结果集的情况下插入额外结果可能很有用。这可以简单到返回推荐而不是搜索结果（在第 9
    章中介绍），或者可能涉及返回部分匹配的查询，精度较低。
- en: The final results of all pipeline stages are then combined and reranked as needed
    to yield a final set of relevance-ranked search results. The reranking stage can
    be simple, but it will often be implemented using *machine-learned ranking* through
    a ranking classifier. We’ll dive into building and automating the training of
    learning to rank models in chapters 10–12\.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将所有管道阶段的最终结果组合并按需重新排序，以产生一组最终的相关性排序搜索结果。重新排序阶段可能很简单，但通常将通过使用 *机器学习排名* 通过排名分类器来实现。我们将在第
    10 章至第 12 章深入探讨构建和自动化学习排名模型的训练。
- en: While the example pipeline in this section may provide good results in many
    cases, the specific logic of a pipeline should always depend on the needs of your
    application. In the next section, we’ll set up an application to search local
    business reviews, and then we’ll implement a unified pipeline capable of semantic
    search over this domain.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本节中的示例管道在许多情况下可能提供良好的结果，但管道的具体逻辑应始终取决于您应用程序的需求。在下一节中，我们将设置一个用于搜索本地商业评论的应用程序，然后我们将实现一个能够在这个领域进行语义搜索的统一管道。
- en: 7.2 Indexing and searching on a local reviews dataset
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 在本地评论数据集上索引和搜索
- en: We’re going to create a search engine that aggregates product and business reviews
    from across the web. If a business has a physical location (restaurant, store,
    etc.), we want to find all of the reviews associated with the business and make
    them available for searching.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个搜索引擎，从整个网络中聚合产品和商业评论。如果一家企业有一个实体位置（餐厅、商店等），我们希望找到与该企业相关的所有评论，并使它们可供搜索。
- en: The following listing shows the ingestion of our crawled local reviews data
    into the search engine.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了我们的爬取的本地评论数据被导入搜索引擎的过程。
- en: Listing 7.1 Loading and indexing the reviews dataset
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.1 加载和索引评论数据集
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The data model for a review can be seen in the listing’s output. Each review
    has the business name, location information, review content, review rating (number
    of stars from 1 to 5), and categories of the type of entity being reviewed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在列表输出中看到评论的数据模型。每条评论包含业务名称、位置信息、评论内容、评论评分（1到5颗星的数量）以及被评论实体的类别。
- en: Once the data has been ingested, we can run a search. In this chapter, we provide
    a more interactive application than in prior chapters, launching a web server
    to power a dynamic search interface. Running listing 7.2 will launch the web server.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被导入，我们就可以运行搜索。在本章中，我们提供了一个比之前章节更互动的应用程序，启动一个 Web 服务器来驱动动态搜索界面。运行列表 7.2 将启动
    Web 服务器。
- en: Listing 7.2 Launching the web server and loading the search page
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.2 启动 Web 服务器和加载搜索页面
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Figure 7.2 shows the loaded search interface from listing 7.2\. You can run
    the embedded search page from the Jupyter notebook, but if you’re running on your
    local computer on port `2345`, you can also just navigate to http://localhost:2345/search
    in your web browser to get a better experience.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2显示了从列表7.2加载的搜索界面。你可以从Jupyter笔记本中运行嵌入的搜索页面，但如果你在自己的电脑上运行，端口为`2345`，你还可以在网页浏览器中导航到`http://localhost:2345/search`以获得更好的体验。
- en: '![figure](../Images/CH07_F02_Grainger.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F02_Grainger.png)'
- en: Figure 7.2 Visiting the review search page from a local web browser
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.2 从本地网络浏览器访问评论搜索页面
- en: Let’s first try a simple query for `bbq near charlotte`. For now, let’s pretend
    you haven’t gone through the knowledge graph learning process (chapter 6) and
    don’t yet know how to apply an SKG (chapter 5) to your query interpretation. In
    this case, we’re just doing out-of-the-box lexical keyword matching. Figure 7.3
    shows the top lexical search result for the query `bbq near charlotte`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先尝试一个简单的查询`bbq near charlotte`。目前，让我们假设你没有完成知识图谱学习过程（第6章）并且还不知道如何将SKG（第5章）应用于你的查询解释。在这种情况下，我们只是在做标准化的词汇关键词匹配。图7.3显示了查询`bbq
    near charlotte`的顶级词汇搜索结果。
- en: '![figure](../Images/CH07_F03_Grainger.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F03_Grainger.png)'
- en: Figure 7.3 Basic lexical keyword search for `bbq near charlotte`, only matching
    keywords
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.3对`bbq near charlotte`的基本词汇关键词搜索，仅匹配关键词
- en: In our reviews dataset, this is the only review that matches our query, even
    though multiple BBQ (also known as barbecue) restaurants exist in or near the
    city of Charlotte, NC, USA. The reason only this result is returned is that it’s
    the only document containing all three terms (`bbq`, `near`, and `charlotte`).
    If you look at the review, it is not even for a restaurant that serves barbecue—it’s
    actually for a festival whose review just happens to reference another festival
    with “BBQ” in the name!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的评论数据集中，这是唯一与我们的查询匹配的评论，尽管在北卡罗来纳州夏洛特市及其附近存在多个烧烤（也称烧烤）餐厅。只有这个结果被返回的原因是它是唯一包含所有三个术语（`bbq`、`near`和`charlotte`）的文档。如果你查看评论，它甚至不是一家提供烧烤的餐厅——实际上它是一场节庆活动的评论，恰好提到了另一个名为“BBQ”的节庆活动！
- en: The main problem here is that most relevant restaurants do not contain the word
    `near`. Figure 7.4 shows that more results do exist if we take out the word `near`
    and search instead for `bbq charlotte`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里主要的问题是大多数相关的餐厅名称中不包含单词`near`。图7.4显示，如果我们去掉单词`near`并搜索`bbq charlotte`，会有更多结果出现。
- en: '![figure](../Images/CH07_F04_Grainger.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F04_Grainger.png)'
- en: Figure 7.4 Basic lexical keyword search for `bbq` `charlotte`. More results
    matching with the word “near” removed.
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.4对`bbq` `charlotte`进行的基本词汇关键词搜索。移除“near”单词后，有更多匹配的结果。
- en: Both of the top results contain the term “bbq”, but the first one has a low
    (1-star) rating, and the second one mentions “bbq chicken” (chicken with barbecue
    sauce on it) but not “bbq” (barbecue), which would typically refer more to smoked
    meat like pulled pork, pulled chicken, rib, or brisket. Additionally, while the
    results are all in the city Charlotte, NC, this is only because they match the
    keyword `charlotte` in the review text, which means many good results are missing
    that didn’t reference the city by name in the review. It is clear from the results
    that the search engine hasn’t properly interpreted the user’s query intent.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个结果都包含“bbq”这个术语，但第一个有一个很低的（1星）评分，第二个提到了“bbq chicken”（带有烧烤酱的鸡肉），但没有提到“bbq”（烧烤），这通常指的是像拉猪肉、拉鸡肉、排骨或牛腩这样的烟熏肉类。此外，虽然所有结果都在夏洛特市，NC，但这仅仅是因为它们在评论文本中匹配了关键词`charlotte`，这意味着许多没有在评论中提及城市的名称的好结果被遗漏了。从结果来看，搜索引擎并没有正确地解释用户的查询意图。
- en: We can do so much better than this! You’ve already learned how to extract domain-specific
    knowledge and how to classify queries (for example, `bbq` implies a restaurant),
    so we just need to integrate these techniques and learned models end-to-end.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做得比这更好！你已经学会了如何提取特定领域的知识以及如何对查询进行分类（例如，`bbq`意味着餐厅），所以我们只需要将这些技术和学习模型端到端地整合。
- en: 7.3 An end-to-end semantic search example
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 一个端到端语义搜索示例
- en: 'The last section showed the shortcomings of relying on pure keyword search.
    How might we improve upon the search engine’s ability to interpret queries? Figure
    7.5 demonstrates the results of a reasonably specific query that traditional keyword
    search would struggle to correctly interpret: `top kimchi near charlotte`.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节展示了仅依赖纯关键词搜索的不足。我们如何提高搜索引擎解释查询的能力？图7.5展示了传统关键词搜索难以正确解释的相对具体查询的结果：`top kimchi
    near charlotte`。
- en: '![figure](../Images/CH07_F05_Grainger.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F05_Grainger.png)'
- en: Figure 7.5 Semantic search for the query `top kimchi near charlotte`
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.5 查询`top kimchi near charlotte`的语义搜索
- en: This query is interesting, because only one keyword (“kimchi”) actually contains
    a traditional keyword for relevance ranking purposes. The keyword “top” really
    means “most popular” or “highest rated”, and the phrase “near charlotte” indicates
    a geographical filter to apply to search results. You can see in the figure that
    the original query is parsed as `{top}` `kimchi` `{near}` `{charlotte}`. We’re
    using this curly-brace syntax to indicate that the terms “top”, “near”, and “charlotte”
    were all identified from our knowledge graph, whereas “kimchi” was not tagged
    and is, therefore, an unknown.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询很有趣，因为只有一个关键词（“kimchi”）实际上包含了一个用于相关性排名的传统关键词。关键词“top”实际上意味着“最受欢迎”或“评分最高”，而短语“near
    charlotte”表示应用于搜索结果的地理过滤器。您可以在图中看到，原始查询被解析为 `{top}` `kimchi` `{near}` `{charlotte}`。我们使用这种花括号语法来表示“top”、“near”和“charlotte”这些术语都是从我们的知识图谱中识别出来的，而“kimchi”没有被标记，因此是一个未知项。
- en: 'After these keywords and phrases are parsed, you can see that they are enriched
    and transformed into the following search-engine-specific syntax (Solr):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析这些关键词和短语之后，您可以看到它们被丰富并转换成了以下搜索引擎特定的语法（Solr）：
- en: '*top*: `+{!func v="mul(if(stars_rating,stars_rating,0),20)"}`. This syntax
    will boost all documents based on their reviews (1 to 5 stars), multiplying by
    20 to generate a score between 0 and 100\.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*top*: `+{!func v="mul(if(stars_rating,stars_rating,0),20)"}`。这个语法将根据其评论（1到5星）对所有文档进行提升，乘以20以生成介于0到100之间的分数。'
- en: '*kimchi*: `+{!edismax v="kimchi^0.9193 korean^0.7069` `banchan^0.6593 +doc_type:\"Korean\""}`.
    This is an expansion of the unknown term “kimchi” using the SKG expansion approach
    from chapter 5\. The SKG, in this case, identifies “Korean” as the category in
    which to filter results, and the top related terms to “kimchi” are “korean” and
    “banchan”.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kimchi*: `+{!edismax v="kimchi^0.9193 korean^0.7069` `banchan^0.6593 +doc_type:\"Korean\""}`。这是使用第5章中提到的SKG扩展方法对未知术语“kimchi”进行扩展。在这种情况下，SKG确定“Korean”是过滤结果的类别，与“kimchi”最相关的术语是“korean”和“banchan”。'
- en: '*near charlotte*: `+{!geofilt d=50 sfield="location_coordinates" pt="35.22709,-80.84313"}`.
    This geographical filter limits results to documents only within a 50 km radius
    of the latitude/longitude of Charlotte, NC, USA.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*near charlotte*: `+{!geofilt d=50 sfield="location_coordinates" pt="35.22709,-80.84313"}`。这个地理过滤器将结果限制在距离美国北卡罗来纳州夏洛特纬度/经度50公里范围内的文档。'
- en: Had the original query been executed as a traditional lexical search *without*
    the query interpretation layer, no results would have matched, as shown in figure
    7.6.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果原始查询像传统词汇搜索那样*没有*查询解释层，则不会有任何结果匹配，如图7.6所示。
- en: '![figure](../Images/CH07_F06_Grainger.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F06_Grainger.png)'
- en: Figure 7.6 Traditional lexical search returns no results due to no documents
    containing all keywords
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.6 传统词汇搜索由于没有包含所有关键词的文档而返回无结果
- en: However, figure 7.7 demonstrates the results after executing the semantically
    parsed and enriched version.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，图7.7展示了执行语义解析和丰富后的结果。
- en: '![figure](../Images/CH07_F07_Grainger.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F07_Grainger.png)'
- en: Figure 7.7 Semantic search example returns relevant results by better interpreting
    and executing the query
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.7 语义搜索示例通过更好地解释和执行查询返回相关结果
- en: The results look quite good! You’ll notice that
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来相当不错！您会注意到
- en: There are many results (instead of zero).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多结果（而不是零）。
- en: All results have *top* ratings (5 stars).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有结果都有*top*评分（5星）。
- en: All results are in *Charlotte*.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有结果都在*夏洛特*。
- en: '**   Some results match even without having the main keyword (“kimchi”), and
    they are clearly for Korean restaurants that would serve kimchi because similar
    terms were used in the review.*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**   即使没有包含主要关键词（“kimchi”），也有一些结果匹配，并且它们显然是为提供kimchi的韩国餐厅准备的，因为评论中使用了类似的术语。**'
- en: '*We’ll spend the remainder of the chapter walking through how we can implement
    this level of semantic query interpretation, starting with a high-level query
    interpretation pipeline.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们将在本章剩余部分介绍如何实现这种语义查询解释级别，从高级查询解释管道开始。'
- en: 7.4 Query interpretation pipelines
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 查询解释管道
- en: 'While we often need to integrate multiple models and diverse query-understanding
    approaches in a query pipeline, most query pipelines share a similar set of high-level
    phases:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们通常需要在查询管道中集成多个模型和不同的查询理解方法，但大多数查询管道都共享一组类似的高级阶段：
- en: '*Parsing*—Extracting key entities and their logical relationships from the
    query'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*解析*——从查询中提取关键实体及其逻辑关系'
- en: '*Enriching*—Generating an understanding of the query context, queried entities,
    and their semantic relationships'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*丰富*——生成对查询上下文、查询实体及其语义关系的理解'
- en: '*Transforming*—Rewriting the user’s query for the search engine to optimize
    recall and ranking'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*转换*——重写用户的查询以优化搜索引擎的召回率和排名'
- en: '*Searching*—Executing the transformed query and returning ranked results'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*搜索*——执行转换后的查询并返回排名结果'
- en: You can think of each phase as a different type of pipeline stage. As in the
    example pipeline in section 7.1, some pipelines may invoke multiple stages to
    parse or enrich a query, and some pipelines may even run multiple conditional
    searches and merge results.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将每个阶段视为不同类型的管道阶段。正如7.1节中的示例管道所示，某些管道可能需要调用多个阶段来解析或丰富查询，而某些管道甚至可能运行多个条件搜索并合并结果。
- en: In the coming subsections, we’ll implement each phase to demonstrate the inner
    workings of our end-to-end semantic search example from section 7.3.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将实现每个阶段，以展示我们从7.3节中得到的端到端语义搜索示例的内部工作原理。
- en: 7.4.1 Parsing a query for semantic search
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 解析查询以进行语义搜索
- en: As you saw in section 3.2.5, most keyword search engines perform some form of
    Boolean parsing on incoming queries by default. The query `statue` `of` `liberty`
    thus becomes a query for `statue` `AND` `of` `AND` `liberty`, where any document
    containing all three words (“statue”, “of”, “liberty”) will match, assuming a
    default query operator of `AND`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在3.2.5节中看到的，大多数关键字搜索引擎默认会对传入的查询执行某种形式的布尔解析。因此，查询`statue` `of` `liberty`变成了对`statue`
    `AND` `of` `AND` `liberty`的查询，其中任何包含所有三个单词（“statue”，“of”，“liberty”）的文档都将匹配，假设默认查询操作符为`AND`。
- en: This Boolean matching alone does not yield great results, but when paired with
    BM25 ranking (discussed in section 3.2.1), it can yield great results for a naive
    algorithm that doesn’t have any true understanding of the terms within the domain.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用布尔匹配本身并不能产生很好的结果，但当与BM25排名（在第3.2.1节中讨论）结合使用时，它可以对没有真正理解领域内术语的朴素算法产生很好的结果。
- en: In contrast to this Boolean parsing, it’s also possible to convert an entire
    query into a numerical vector embedding, as discussed in section 3.1.1\. We’ll
    cover dense vector search using LLMs and embeddings later in chapters 13–14\.
    One benefit of using LLMs and embedding-based query interpretation is that these
    techniques provide a better representation of the query as one unit of meaning.
    The logical structure of the query can sometimes be lost using this approach,
    though, so it may not work well for scenarios where your Boolean logic must be
    preserved or you must ensure certain keywords appear in the search results.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 与这种布尔解析相反，还可以将整个查询转换为一个数值向量嵌入，如3.1.1节中所述。我们将在第13-14章中介绍使用LLMs和嵌入的密集向量搜索。使用LLMs和基于嵌入的查询解释的一个好处是，这些技术提供了对查询作为意义单元的更好表示。使用这种方法，查询的逻辑结构有时可能会丢失，因此它可能不适合需要保留布尔逻辑或确保某些关键词出现在搜索结果中的场景。
- en: A final way to parse a query is by extracting the known terms and phrases from
    a knowledge graph. We took this approach in our end-to-end example in section
    7.3\. One benefit of this approach is that, in addition to offering fine-grained
    control over known vocabulary, it also allows for the interpretation of specific
    phrases and trigger words (`top`, `in`, `near`) to be modeled explicitly, to reflect
    their functional meaning instead of just keyword matching. The downside of this
    approach is that any terms or phrases *not* existing in the knowledge graph can’t
    be as easily extracted and interpreted.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 解析查询的另一种方法是从知识图中提取已知的术语和短语。我们在第 7.3 节的端到端示例中采用了这种方法。这种方法的一个优点是，除了提供对已知词汇的精细控制外，它还允许显式地建模特定的短语和触发词（`top`、`in`、`near`），以反映其功能意义，而不仅仅是关键词匹配。这种方法的一个缺点是，知识图中不存在任何术语或短语*无法*被轻松提取和解释。
- en: Since we’ll dive into LLMs in later chapters, we’ll focus in this chapter on
    explicit query parsing using a knowledge graph, as explicit parsing enables significant
    customization for a domain, it’s cheap to implement, and it enables us to incorporate
    all the other AI techniques we’ve already learned.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在后面的章节中深入研究大型语言模型（LLMs），因此在本章中，我们将专注于使用知识图进行显式查询解析，因为显式解析可以为特定领域提供显著的定制化，实现成本低，并使我们能够结合我们已学到的所有其他人工智能技术。
- en: Implementing a semantic query parser
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实现语义查询解析器
- en: The first step when semantically interpreting a query is identifying the terms
    and phrases in the query (the *parsing* phase). In chapter 6, we walked through
    how to identify important domain-specific terms and phrases from our content and
    user behavioral signals. These can be used as the known entities list for powering
    entity extraction on incoming queries.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在语义解释查询的第一步是识别查询中的术语和短语（*解析*阶段）。在第 6 章中，我们介绍了如何从我们的内容和用户行为信号中识别重要的特定领域术语和短语。这些可以作为已知实体列表，用于在传入查询上启用实体提取。
- en: Because there can be potentially millions of entities in the known phrases list,
    an efficient structure such as a *finite state transducer* (FST) makes it possible
    to perform entity extraction at this scale in just milliseconds. We won’t get
    into the nuances of how FSTs work here, but they enable very compact compression
    of many term sequences and very quick lookups on those term sequences, enabling
    lightning-fast entity extraction.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 由于已知短语列表中可能存在数百万个实体，因此一个高效的结构，如*有限状态转换器*（FST），使得在毫秒内仅用这种规模进行实体提取成为可能。我们不会在这里深入探讨
    FST 的工作原理，但它们能够非常紧凑地压缩许多术语序列，并在这些术语序列上快速查找，从而实现闪电般的实体提取。
- en: Our example search engine, Apache Solr, implements a *text tagger* request handler,
    which is purpose-built for fast entity extraction. It enables you to index any
    number of terms into a lookup index, so you can build that index into an FST and
    extract terms from that index on any incoming stream of text.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例搜索引擎 Apache Solr 实现了一个*文本标记器*请求处理器，它是专门为快速实体提取而构建的。它允许您将任意数量的术语索引到一个查找索引中，因此您可以将该索引构建到
    FST 中，并在任何传入的文本流中从该索引中提取术语。
- en: In chapter 6, we generated lists of domain-specific phrases, which also included
    alternative spellings. We can map all these terms into a specially configured
    `entities` collection, along with any spelling variations, to enable seamless
    entity extraction from incoming queries. The following listing explores several
    types of entity data within our `entities` collection.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 6 章中，我们生成了特定领域短语的列表，这些列表还包括了变体拼写。我们可以将这些术语映射到一个特别配置的`entities`集合中，包括任何拼写变体，以实现从传入查询中无缝提取实体。以下列表探讨了`entities`集合中几种类型的实体数据。
- en: Listing 7.3 Entity data used for tagging and extraction
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.3 用于标记和提取的实体数据
- en: '[PRE3]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The fields represented within the table for entities in listing 7.3 include
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.3 中表示的实体字段包括
- en: '`surface_form`—The specific text of any spelling variation we want to match
    on future queries.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`surface_form`—我们希望在未来的查询中匹配的任何拼写变体的特定文本。'
- en: '`canonical_form`—The “official” version of any term that may have potentially
    multiple surface forms.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`canonical_form`—任何可能具有多个表面形式的术语的“官方”版本。'
- en: '`type`—A classification (category) for the term within our domain.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`—我们领域内术语的分类（类别）。'
- en: '`popularity`—Used to prioritize different meanings of the same surface form.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`popularity`—用于优先考虑相同表面形式的不同含义。'
- en: '`semantic_function`—Only present for entities of type “semantic_function”.
    This is used to inject programmatic handling of special combinations of keywords.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`semantic_function`——仅对类型为“semantic_function”的实体存在。这用于注入对特殊关键词组合的程序性处理。'
- en: In most cases, the `surface_form` and `canonical_form` will be the same, but
    our entity extractor will always match on a `surface_form` and map it to a `canonical_form`,
    so this mechanism is used to map multiple variations of an entity’s spelling to
    one official or “canonical” version. This can be used to handle misspellings (“amin”
    ⇒ “admin”), acronyms and initialisms (“cto” ⇒ “chief technology officer”), ambiguous
    terms (“cto” ⇒ “chief technology officer” versus “cto” ⇒ “cancelled-to-order”),
    or even mapping terms to specific interpretation logic (semantic functions) like
    “near” ⇒ `{location_ distance}`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，`surface_form`和`canonical_form`将是相同的，但我们的实体提取器将始终匹配`surface_form`并将其映射到`canonical_form`，因此使用此机制将实体的拼写多个变体映射到一个官方或“规范”版本。这可以用来处理拼写错误（“amin”⇒“admin”），首字母缩略词和缩写（“cto”⇒“首席技术官”），模糊术语（“cto”⇒“首席技术官”与“cto”⇒“已取消订单”），甚至将术语映射到特定的解释逻辑（语义函数）如“附近”⇒`{location_distance}`。
- en: The “semantic_function” type is a special type that we’ll explore in section
    7.4.2; it enables nonlinear, conditional query parsing rules. For example, “if
    the word *near* is followed by an entity that has a *geographical location*, interpret
    that section of the query as a geography filter”.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: “语义函数”类型是一个特殊类型，我们将在第7.4.2节中探讨；它允许非线性、条件查询解析规则。例如，“如果单词*near*后面跟着一个具有*地理位置*的实体，则将查询的这一部分解释为地理过滤器”。
- en: In the event of an ambiguous term, multiple entries will exist containing the
    same surface form mapped to different canonical forms. In this case, the `popularity`
    field will specify a relative value indicating which meaning is more common (the
    higher, the more popular).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在出现模糊术语的情况下，将存在多个条目，包含相同的外部形式，但映射到不同的规范形式。在这种情况下，`popularity`字段将指定一个相对值，表示哪种含义更常见（值越高，越流行）。
- en: This format is also extensible—you can add a `vector` field representing the
    semantic meaning of a canonical form, or a `related_terms` field that contains
    other terms with similar meanings. This would enable caching a static representation
    of the meaning of the `canonical_form`, which can be much more efficient at query
    time than referencing external models or knowledge graphs for known terms on every
    request.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此格式也是可扩展的——您可以添加一个表示规范形式语义意义的`vector`字段，或者一个包含具有相似意义的其他术语的`related_terms`字段。这将使缓存`canonical_form`的静态意义表示成为可能，这在查询时可能比引用外部模型或知识图上的已知术语更有效。
- en: Invoking the entity extractor
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调用实体提取器
- en: In addition to the `reviews` collection created in listing 7.1, we also need
    to create an `entities` collection containing the known entities to be extracted.
    This collection will serve as an explicit knowledge graph containing all of the
    entities from listing 7.3, as well as a list of all major cities in the world.
    The next listing configures and populates the `entities` collection.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在列表7.1中创建的`reviews`集合外，我们还需要创建一个包含要提取的已知实体的`entities`集合。此集合将作为显式知识图，包含列表7.3中的所有实体，以及世界上所有主要城市的列表。下一个列表配置并填充了`entities`集合。
- en: Listing 7.4 Creating the `entities` collection
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.4 创建`entities`集合
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Creates the entities collection and configures it to hold our explicit knowledge
    graph of entities to extract from queries'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建实体集合并配置它以存储从查询中提取的显式知识图实体'
- en: '#2 Explicit entities and city entities are indexed to the entities collection
    to be used for entity extraction.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 明确实体和城市实体被索引到实体集合中，用于实体提取。'
- en: 'Output:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE6]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'One configuration point we should highlight is the setting up of entity extraction,
    which occurs within `engine.create_collection("entities")`. In the default case
    where Solr is being used to serve the explicit knowledge graph for entity extraction
    from queries, Solr’s text tagger functionality is enabled by internally making
    the following configuration changes:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该强调的一个配置点是设置实体提取，它发生在`engine.create_collection("entities")`内部。在默认情况下，如果使用Solr来为从查询中提取实体提取显式知识图，Solr的文本标记功能将通过内部进行以下配置更改来启用：
- en: Adding an `/entities/tag` endpoint using the `TaggerRequestHandler` in Solr.
    We can pass queries to this endpoint to perform entity extraction of any entities
    found in the `entities` collection.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Solr 中的 `TaggerRequestHandler` 添加 `/entities/tag` 端点。我们可以向此端点传递查询以执行 `entities`
    集合中找到的任何实体的实体提取。
- en: Adding a `tags` field type in the schema that is configured to use an in-memory
    FST, enabling compact and fast tagging from a collection of potentially millions
    of entities in milliseconds.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模式中添加一个配置为使用内存中 FST 的 `tags` 字段类型，从而实现从可能包含数百万个实体的集合中以毫秒级的速度进行紧凑且快速的标记。
- en: Adding a `name_tag` field that the `surface_form` field is copied into. The
    `name_tag` field is a `tags` field type and is used by the `/entities/tag` endpoint
    to match entities from the query.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加一个 `name_tag` 字段，该字段将 `surface_form` 字段复制进去。`name_tag` 字段是 `tags` 字段类型，并由
    `/entities/tag` 端点用于匹配来自查询的实体。
- en: If your search engine has native text tagging capabilities, the configuration
    will differ, but the following listing shows the code corresponding to these changes
    for the default implementation of the text tagger using Apache Solr.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的搜索引擎具有本机文本标记功能，则配置将有所不同，但以下列表显示了针对默认文本标记器实现（使用 Apache Solr）的这些更改的代码。
- en: Listing 7.5 Configuring the Solr text tagger for entity extraction
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.5 配置 Solr 文本标记器以进行实体提取
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 The tag field type is configured using the Lucene FST50 index format, enabling
    fast in-memory matching using an FST.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 标签字段类型使用 Lucene FST50 索引格式进行配置，这允许使用 FST 进行快速内存匹配。'
- en: '#2 The ConcatenateGraphFilter is a special filter used by the text tagger to
    facilitate entity extraction.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 ConcatenateGraphFilter 是文本标记器用于促进实体提取的特殊过滤器。'
- en: '#3 We add the name_tag field, which we’ll use to tag queries against the index.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 我们添加了 `name_tag` 字段，我们将使用它来对索引进行查询标记。'
- en: '#4 The name_tag field is populated using the surface_form value.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用表面形式值填充 `name_tag` 字段。'
- en: '#5 A /tag request handler is configured to use values indexed in the name_tag
    field as entities to extract from incoming queries.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 配置了一个 /tag 请求处理器，用于使用在 `name_tag` 字段中索引的值作为从传入查询中提取的实体。'
- en: '#6 If multiple entities match (polysemy), return the most popular one by default.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 如果多个实体匹配（多义性），则默认返回最流行的一个。'
- en: With the `entities` collection created, the text tagger configured, and the
    entities all indexed, we’re now ready to perform entity extraction on a query.
    In the following listing, we run a query for `top kimchi near charlotte`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了 `entities` 集合、配置了文本标签器并将所有实体索引后，我们现在可以开始对查询进行实体提取。在下面的列表中，我们运行了一个针对 `top
    kimchi near charlotte` 的查询。
- en: Listing 7.6 Extracting entities for a given query
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.6 提取给定查询的实体
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Output:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The response includes three key sections:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 响应包括三个关键部分：
- en: '`query`—The query that has been tagged'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query`—已标记的查询'
- en: '`tags`—A list of text phrases found within the incoming query, along with the
    character offsets within the text (start and end positions) and a list of all
    possible entity matches (canonical forms) for each tag (surface form)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags`—在传入查询中找到的文本短语的列表，包括文本中的字符偏移量（起始和结束位置）以及每个标签（表面形式）的所有可能的实体匹配（规范形式）的列表'
- en: '`entities`—The list of doc IDs for matching entities that may correspond with
    one of the matched tags'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`entities`—匹配实体的文档 ID 列表，这些实体可能与匹配的标签之一相对应'
- en: 'We’ve previously described ambiguous terms, where one surface form can map
    to multiple canonical forms. In our example, the first tag is `{''startOffset'':`
    `0,` `''endOffset'':` `3,` `''matchText'':` `''top'',` `''ids'':` `[''7'']}`.
    This states that the text “top” was matched starting at position `0` and ending
    at position `3` in the input `top kimchi near charlotte`. It also lists only one
    entry in the `ids`, meaning that there is only one possible meaning (canonical
    representation). For the other two tags, however, multiple `ids` are listed, making
    them ambiguous tags:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前描述了模糊术语，其中一种表面形式可以映射到多个规范形式。在我们的例子中，第一个标签是 `{'startOffset':` `0,` `'endOffset':`
    `3,` `'matchText':` `'top',` `'ids':` `['7']}`。这表示文本 “top” 在输入 `top kimchi near
    charlotte` 中的起始位置为 `0`，结束位置为 `3`。它还只在 `ids` 中列出一条记录，这意味着只有一个可能的意义（规范表示）。然而，对于其他两个标签，列出了多个
    `ids`，使它们成为模糊标签：
- en: '`{"startOffset":` `11,` `"endOffset":` `15,` `"matchText":` `"near",` `"ids":`
    `["1", "5"]}`'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{"startOffset":` `11,` `"endOffset":` `15,` `"matchText":` `"near",` `"ids":`
    `["1", "5"]}`'
- en: '`{"startOffset":` `16,` `"endOffset":` `25,` `"matchText":` `"charlotte",`
    `"ids": ["4460243", "4612828", "4680560", "4988584", "5234793"]}`'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{"startOffset":` `16,` `"endOffset":` `25,` `"matchText":` `"charlotte",`
    `"ids": ["4460243", "4612828", "4680560", "4988584", "5234793"]}`'
- en: This means that there were two canonical forms (two `ids` listed) for the surface
    form “near” and five canonical forms for the surface form “charlotte”. In the
    `entities` section, we can also see all of the different entity records associated
    with the lists of `ids` in the tags.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着对于表面形式“near”有两个规范形式（列出两个`ids`），对于表面形式“charlotte”有五个规范形式。在`entities`部分，我们还可以看到与标签中的`ids`列表相关联的所有不同实体记录。
- en: In this chapter, we’ll keep things simple by always using the canonical form
    with the highest `popularity`. For cities, we supplied the city’s population in
    the `popularity` field, which means that the “charlotte” selected is Charlotte,
    NC, USA (the most populated Charlotte in the world). For our other entities, the
    popularity was specified manually in entities.csv from listing 7.3\. You can alternatively
    specify the popularity using the signals-boosting value (if you derived your entities
    from signals, which will be covered in detail in chapter 8) or using the count
    of documents containing the entity in your index as a proxy for popularity.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将保持简单，始终使用具有最高`popularity`的规范形式。对于城市，我们在`popularity`字段中提供了城市的人口，这意味着所选的“charlotte”是北卡罗来纳州的夏洛特（世界上人口最多的夏洛特）。对于我们的其他实体，其流行度在列表7.3中的entities.csv中手动指定。你也可以使用信号增强值（如果你从信号中导出实体，这将在第8章中详细介绍）或使用包含实体的索引中文档的数量作为流行度的代理来指定流行度。
- en: You may also find it beneficial to use user-specific context or query-specific
    context to choose the most appropriate entity. For example, if you are disambiguating
    locations, you could boost the popularity with a geographical distance calculation
    so locations closer to the user receive a higher weight. If the entity is a keyword
    phrase, you can alternatively use an SKG to classify the query or load a term
    vector and boost the canonical form that is a better conceptual match for the
    overall query.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现使用用户特定的上下文或查询特定的上下文来选择最合适的实体是有益的。例如，如果你正在消除地点歧义，你可以通过地理距离计算来提高流行度，使靠近用户的地点获得更高的权重。如果实体是一个关键词短语，你可以使用SKG来分类查询或加载一个术语向量，并提高与整体查询更好的概念匹配的规范形式。
- en: With our `query_entities` available from the knowledge graph, we can now generate
    a user-friendly version of the original query with the tagged entities identified.
    The following listing implements this `generate_tagged_query` function.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有从知识图谱中可用的`query_entities`，我们现在可以生成一个带有标记实体的用户友好版本的原始查询。以下列表实现了这个`generate_tagged_query`函数。
- en: Listing 7.7 Generating a tagged query
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.7 生成标记查询
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Reconstructs the query with tagged entities'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用标记实体重构查询'
- en: '#2 Wraps known entities in braces to offset them from regular keywords'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将已知实体用大括号括起来，以使其与常规关键词区分开来'
- en: 'Output:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE11]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From this tagged query, we can now see that the keywords “top”, “near”, and
    “charlotte” map to known entities, while “kimchi” is an unknown keyword. This
    format is a useful user-friendly representation of the query, but it is too simple
    to represent the metadata associated with each entity. Because we need to process
    the entities and their semantic interactions programmatically to enrich the query,
    we will also implement a more structured representation of the semantically parsed
    query, which we’ll call a `query_tree`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个标记查询中，我们现在可以看到关键词“top”、“near”和“charlotte”映射到已知实体，而“kimchi”是一个未知关键词。这种格式是查询的有用、用户友好的表示，但它太简单了，无法表示与每个实体关联的元数据。因为我们需要以编程方式处理实体及其语义交互来丰富查询，我们将实现一个更结构化的语义解析查询表示，我们将其称为`query_tree`。
- en: Instead of a pure text query, this `query_tree` is a structure of strongly typed
    nodes within the query represented as JSON objects. Listing 7.8 demonstrates the
    `generate_query_tree` function, which returns a query tree from the incoming entity
    extraction data (`query_entities`).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 与纯文本查询不同，这个`query_tree`是查询中作为JSON对象表示的强类型节点结构。列表7.8展示了`generate_query_tree`函数，该函数从传入的实体提取数据（`query_entities`）返回查询树。
- en: Listing 7.8 Generating a typed query tree from a user query
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.8 从用户查询生成类型化查询树
- en: '[PRE12]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Creates a mapping of entity IDs to entities'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建实体ID到实体的映射'
- en: '#2 Chooses the most popular canonical form for the entity by default'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 默认选择实体的最流行规范形式'
- en: '#3 Assigns a keyword type to any untagged text as a fallback'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将任何未标记的文本分配一个关键字类型作为后备'
- en: '#4 Adds the entity object to the query tree in the appropriate position in
    the query'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将实体对象添加到查询树中的适当位置'
- en: '#5 Any text after the last tagged entity will also be considered a keyword.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 最后一个标记实体之后的任何文本也将被视为关键词。'
- en: 'Output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We now have multiple representations of the query and tagged entities:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有查询和标记实体的多种表示：
- en: '`tagger_data`—Output of listing 7.6'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tagger_data`—第 7.6 节的输出'
- en: '`tagged_query`—Output of listing 7.7'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tagged_query`—第 7.7 节的输出'
- en: '`parsed_query`—Output of listing 7.8'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parsed_query`—第 7.8 节的输出'
- en: The `parsed_query` output is a serialization of the underlying `query_tree`
    object, fully representing all keywords and entities along with their associated
    metadata. At this point, the initial *parsing* phase that maps the query into
    typed entities is complete, and we can begin to use the relationships between
    the entities to better enrich the query.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`parsed_query` 输出是底层 `query_tree` 对象的序列化，完整地表示了所有关键词和实体及其关联的元数据。在此阶段，将查询映射到类型化实体的初始
    *解析* 阶段已经完成，我们可以开始利用实体之间的关系来更好地丰富查询。'
- en: 7.4.2 Enriching a query for semantic search
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 为语义搜索丰富查询
- en: The *enriching* phase of our query interpretation pipeline focuses on understanding
    the relationships between entities in a query and how to best interpret and represent
    them for optimal search results relevance.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们查询解释管道的 *丰富* 阶段专注于理解查询中实体之间的关系以及如何最佳地解释和表示它们以优化搜索结果的相关性。
- en: Much of this book has already been, and will continue to be, focused on the
    enriching phase. Chapter 4 introduced crowdsourced relevance, which is a way to
    enrich specific keyword phrases with information about which documents are the
    most relevant, based on prior user interactions. Chapter 5 focused on knowledge
    graphs, which provide a way to enrich specific keyword phrases with topic classifications
    and to find other terms that are highly related. In chapter 6, we implemented
    algorithms to find synonyms, misspellings, and related terms that can be used
    to enrich queries by augmenting or replacing parsed terms with better, learned
    versions. Upcoming chapters on signals boosting, personalization, and dense vector
    search on embeddings will likewise introduce new ways to interpret parsed entities
    and enrich queries to optimize relevance.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的大部分内容已经集中，并将继续集中在丰富阶段。第 4 章介绍了众包相关性，这是一种通过基于先前用户交互的信息来丰富特定关键词短语的方法。第 5 章专注于知识图谱，它提供了一种通过主题分类丰富特定关键词短语并找到其他高度相关术语的方法。在第
    6 章中，我们实现了查找同义词、拼写错误和相关术语的算法，这些算法可以通过增强或替换解析术语以更好的学习版本来丰富查询。即将到来的关于信号增强、个性化以及嵌入上的密集向量搜索的章节也将介绍新的方法来解释解析实体并丰富查询以优化相关性。
- en: 'These techniques are all tools in your toolbox, but the best way to combine
    them for any specific implementation will be domain-specific, so we’ll avoid overly
    generalizing in our examples. Instead, we’ll focus on a simple end-to-end implementation
    to tie things together in a way that other models can be easily plugged into.
    Our simple implementation will consist of two components:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术都是你的工具箱中的工具，但将它们结合到任何特定实现的最佳方式将是领域特定的，因此我们将在示例中避免过度泛化。相反，我们将专注于一个简单的端到端实现，以便将其他模型轻松地插入其中。我们的简单实现将包括两个组件：
- en: A *semantic function* implementation that enables dynamic and nonlinear semantic
    rules to be injected for each domain
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种 *语义函数* 实现，它允许为每个领域注入动态和非线性的语义规则
- en: An SKG to find related terms for unknown keywords and query classifications
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 SKG 来寻找未知关键词和查询分类的相关术语
- en: You already have the tools you need to extend the query-parsing framework to
    handle other enrichment types from previous chapters. For example, you can use
    the mappings from surface form to canonical form to handle all alternate representations
    learned in chapter 6\. Likewise, by adding additional fields to each entity in
    the `entities` collection, you can inject signals boosts, related terms, query
    classifications, or vectors, making them available for use as soon as queries
    are parsed.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经有了扩展查询解析框架以处理来自先前章节的其他丰富类型的工具。例如，你可以使用从表面形式到规范形式的映射来处理第 6 章中学到的所有替代表示。同样，通过向
    `entities` 集合中的每个实体添加额外的字段，你可以注入信号提升、相关术语、查询分类或向量，使它们在查询解析后即可使用。
- en: Let’s kick off our enrichment implementation with a discussion of semantic functions.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过讨论语义函数来启动我们的丰富实现。
- en: Implementing semantic functions
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实现语义函数
- en: 'A *semantic function* is a nonlinear function that can be applied during query
    parsing and enrichment to better interpret the meaning of the surrounding terms.
    Our previous example of `top kimchi near charlotte` contains two terms that map
    to semantic functions: “top” and “near”. The term “top” has a very domain-specific
    meaning: prioritize documents with the highest rating (number of stars on the
    review). Likewise, the term “near” isn’t a keyword that should be matched; instead,
    it modifies the meaning of the succeeding terms to attempt to marshal them into
    a geographic location. From listing 7.3, you will see the following entities referencing
    semantic functions:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '*语义函数* 是一个非线性函数，可以在查询解析和丰富过程中应用，以更好地解释周围术语的含义。我们之前的例子 `top kimchi near charlotte`
    包含两个映射到语义函数的术语：“top”和“near”。术语“top”具有非常特定的领域含义：优先考虑评分最高的文档（评论中的星级数量）。同样，术语“near”不是一个应该匹配的关键词；相反，它修改了后续术语的含义，试图将它们组合成一个地理位置。从列表
    7.3 中，你会看到以下实体引用了语义函数：'
- en: '[PRE14]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You’ll note that the surface forms “top”, “popular”, “good”, and “best” all
    map to the `{popularity}` canonical form, which is represented by the `popularity(query,
    position)` semantic function in the following listing.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到表面形式“top”、“popular”、“good”和“best”都映射到 `{popularity}` 规范化形式，在下一列表中由 `popularity(query,
    position)` 语义函数表示。
- en: Listing 7.9 A semantic function that accounts for popularity
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.9 考虑流行度的语义函数
- en: '[PRE15]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 Another query tree node must follow the popularity node (“top mountain”
    and not “mountain top”).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 另一个查询树节点必须跟随流行度节点（“top mountain”而不是“mountain top”）。'
- en: '#2 Replace the {popularity} node in the query tree with a new node that represents
    a relevance boost for popularity.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将查询树中的 `{popularity}` 节点替换为一个新的节点，该节点表示对流行度的相关性提升。'
- en: '#3 Returns whether the semantic function was triggered. If False, then another
    overlapping function with lower precedence could be attempted.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 返回语义函数是否被触发。如果为 False，则可以尝试另一个优先级较低的覆盖函数。'
- en: This popularity function allows us to apply semantic interpretation logic to
    manipulate the query tree. Had the query tree ended with the keyword “top”, the
    function would have returned `False` and no adjustments would have been made.
    Likewise, if another function had been assigned higher precedence (as specified
    in the `entities` collection), it might have removed the `{popularity}` entity
    before its function was even executed.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此流行度函数使我们能够应用语义解释逻辑来操纵查询树。如果查询树以关键词“top”结束，则函数将返回 `False` 并不会进行任何调整。同样，如果另一个函数被分配了更高的优先级（如
    `entities` 集合中指定），则它可能在执行其函数之前就移除了 `{popularity}` 实体。
- en: The `location_distance` function is a bit more involved, as shown in the next
    listing.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`location_distance` 函数稍微复杂一些，如下一列表所示。'
- en: Listing 7.10 A semantic function that accounts for location
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.10 考虑位置的语义函数
- en: '[PRE16]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#1 The function must modify the next entity to succeed.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 函数必须修改下一个实体以成功执行。'
- en: '#2 The next entity must be of a location type (city).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 下一个实体必须是位置类型（城市）。'
- en: '#3 Remove the next entity, since it is a location that will now be replaced
    by a radius-based filter.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 移除下一个实体，因为它是一个将被半径过滤替换的位置。'
- en: '#4 Add in the replacement entity with the radius filter.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 添加具有半径过滤器的替换实体。'
- en: '#5 If the next entity was not a city, then don’t apply the function.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 如果下一个实体不是城市，则不要应用该函数。'
- en: As you can see, our implementation of semantic functions allows for any arbitrary
    logic to be conditionally applied when interpreting queries. If you want, you
    can even call external knowledge graphs or other data sources to pull in additional
    information to better interpret the query.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们实现的语义函数允许在解释查询时条件性地应用任何任意逻辑。如果你想，甚至可以调用外部知识图谱或其他数据源来拉取更多信息以更好地解释查询。
- en: You may have noticed that the surface forms “near”, “in”, and “by” all map to
    the `{location_distance}` canonical form, which is represented by the `location_
    distance(query,` `position)` function. This function works well if one of those
    terms is followed by a location, but what if someone searches for `chief` `near`
    `officer`? In this context, the end user may have meant “find the term *chief*
    close to the term *officer* within a document”—essentially an edit distance search.
    Note that there is also an entity mapping “near” ⇒ `{text_distance}` that can
    be invoked conditionally for this fallback use case if the `{location_distance}`
    entity’s semantic function returns `False`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，“near”、“in”和“by”这些表面形式都映射到 `{location_distance}` 规范化形式，该形式由 `location_distance(query,
    position)` 函数表示。如果这些术语之一后面跟着一个位置，这个函数工作得很好，但如果是有人搜索 `chief near officer` 呢？在这种情况下，最终用户可能是指“在文档中找到与术语
    *chief* 靠近的术语 *officer*”——本质上是一个编辑距离搜索。请注意，还有一个实体映射“near” ⇒ `{text_distance}`，可以在
    `{location_distance}` 实体的语义函数返回 `False` 的情况下有条件地调用此回退用例。
- en: Semantic functions can be implemented in many different ways, but our example
    implementation provides a highly configurable way to code dynamic semantic patterns
    into your query interpretation pipeline to best tie into the many different AI-powered
    search approaches available to your search application. We show this implementation
    in the `process_semantic_functions` function in the following listing, which loops
    through the query tree to invoke all matched semantic functions.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 语义函数可以以许多不同的方式实现，但我们的示例实现提供了一种高度可配置的方法，将动态语义模式编码到查询解释管道中，以最佳地连接到您的搜索应用可用的许多不同的AI驱动搜索方法。我们将在下面的列表中展示这个实现，该列表通过循环查询树来调用所有匹配的语义函数。
- en: Listing 7.11 Processing all semantic functions within the query tree
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.11 处理查询树中的所有语义函数
- en: '[PRE17]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 The query and position variables are passed to the semantic function on
    eval.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在评估时，将查询和位置变量传递给语义函数。'
- en: '#2 Iterates through all items in the query tree, searching for semantic functions
    to execute'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 遍历查询树中的所有项，寻找要执行的语义函数'
- en: '#3 Dynamically evaluates semantic functions, which augment the query tree'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 动态评估语义函数，这些函数增强了查询树'
- en: '#4 Updates the type of any unsuccessful semantic functions'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 更新任何失败的语义函数的类型'
- en: Since the semantic functions are stored as part of their entity from the `entities`
    collection, we perform late binding on these functions (using Python’s `eval`
    function). This allows you to plug new semantic functions into the `entities`
    collection at any time without needing to modify the application code.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语义函数存储为 `entities` 集合中其实体的一部分，我们对这些函数执行后期绑定（使用Python的 `eval` 函数）。这允许你随时将新的语义函数插入到
    `entities` 集合中，而无需修改应用程序代码。
- en: Because semantic functions may or may not succeed depending on the surrounding
    context nodes, each semantic function must return `True` or `False` to allow the
    processing logic to determine how to proceed with the rest of the query tree.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语义函数可能成功或失败取决于周围上下文节点，每个语义函数都必须返回 `True` 或 `False`，以便处理逻辑确定如何处理查询树的其余部分。
- en: Integrating an SKG
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 集成SKG
- en: In this section, we’ll integrate an SKG (discussed in chapter 5) into our query
    enrichment process.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将集成一个SKG（在第5章中讨论）到我们的查询丰富过程中。
- en: Your `entities` collection is likely to contain many learned entities using
    the techniques from chapter 6\. You may also use an SKG or other approach to classify
    known entities or to generate lists of related terms. If you do, we recommend
    adding the classifications and related terms as additional fields in the `entities`
    collection to cache the responses for quicker lookup at query time.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 `entities` 集合可能包含许多使用第6章中技术学习到的实体。你也可以使用SKG或其他方法来分类已知实体或生成相关术语列表。如果你这样做，我们建议将分类和相关术语作为额外的字段添加到
    `entities` 集合中，以便在查询时缓存响应以加快查找速度。
- en: For our implementation, we’ll invoke an SKG in real time to enrich *unknown*
    terms. This approach injects related keywords for all unknown keyword phrases
    in a query, which can generate a lot of false positives. You’ll likely want to
    be more conservative in any production implementation, but implementing this is
    useful for learning and experimentation purposes. The following listing demonstrates
    how to look up keyword phrases and traverse our reviews collection as an SKG.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实现中，我们将实时调用 SKG 来增强 *未知* 术语。这种方法为查询中的所有未知关键词短语注入相关关键词，可能会产生大量的误报。你可能会希望在生产实现中更加保守，但实施这一点对于学习和实验目的是有用的。以下列表演示了如何查找关键词短语并遍历我们的评论集合作为
    SKG。
- en: Listing 7.12 Getting related terms and categories from the SKG
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.12 从 SKG 获取相关术语和类别
- en: '[PRE18]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#1 The starting node for the SKG traversal is a query for the passed-in keyword
    in the content field.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 SKG 遍历的起始节点是针对传入关键词在内容字段中的查询。'
- en: '#2 Returns the top 4 related terms for the keyword'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 返回关键词的前 4 个相关术语'
- en: '#3 Returns the top 1 doc_type (category) for the keyword'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 返回关键词的顶级 1 个 doc_type（类别）'
- en: '#4 Returns empty when no enrichments are found'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 未找到增强项时返回空'
- en: '#5 Returns discovered categories from the traversal'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 返回遍历中发现的类别'
- en: '#6 Constructs a boosted query from discovered related terms boosted by their
    relatedness'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 从发现的与相关术语相关的增强项中构建一个增强查询'
- en: '#7 Gets enrichments for the keyword “kimchi”'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 为关键词“kimchi”获取增强项'
- en: 'The output of listing 7.12 for the keyword “kimchi” is as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.12 对于关键词“kimchi”的输出如下：
- en: '[PRE19]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here are some sample SKG outputs for other potential keywords:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些其他潜在关键词的样本 SKG 输出：
- en: '*bb**q*:'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*bb**q*:'
- en: '[PRE20]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*korean bb**q*:'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*korean bb**q*:'
- en: '[PRE21]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*lasagna*:'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*lasagna*:'
- en: '[PRE22]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*karaok**e*:'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*karaok**e*:'
- en: '[PRE23]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*drive through*:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*drive through*:'
- en: '[PRE24]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: To complete our *enriching* phase, we need to apply the `get_enrichments` function
    and the previously discussed `process_semantic_functions` function to our query
    tree.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成我们的 *增强* 阶段，我们需要将 `get_enrichments` 函数和之前讨论的 `process_semantic_functions`
    函数应用于我们的查询树。
- en: Listing 7.13 Enriching the query tree nodes
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.13 增强查询树节点
- en: '[PRE25]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#1 Loops through the query tree and processes all semantic functions'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 遍历查询树并处理所有语义函数'
- en: '#2 Takes all unknown keyword phrases, and looks them up in the SKG'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 获取所有未知关键词短语，并在 SKG 中查找它们'
- en: '#3 If enrichments are found, apply them to the node.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 如果找到增强项，则将其应用于节点。'
- en: This `enrich` function encompasses the entire enrichment phase, processing all
    semantic functions and then enriching all the remaining unknown keywords using
    the SKG. Before we move on to the transformation phase, however, let’s quickly
    look at an alternative approach to the SKG-based keyword expansion we’ve implemented.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `enrich` 函数涵盖了整个增强阶段，处理所有语义函数，然后使用 SKG 增强所有剩余的未知关键词。然而，在我们进入转换阶段之前，让我们快速看一下我们已实现的基于
    SKG 的关键词扩展的替代方法。
- en: 7.4.3 Sparse lexical and expansion models
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.3 稀疏词汇和扩展模型
- en: 'We’ve covered two main approaches to search so far in this book: *lexical search*—matching
    and ranking based on specific terms or attributes in a query—and *semantic search*—matching
    and ranking based on the meaning of the query. You’ve also been introduced to
    two main approaches for representing queries: as sparse vectors (vectors with
    very few nonzero values) and dense vectors (vectors with mostly nonzero values).
    Lexical keyword search is usually implemented using an inverted index, which holds
    a sparse vector representation of every document with a dimension for every term
    in the index. Semantic search is likewise usually implemented using a dense vector
    representation searching on embeddings.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们至今已介绍了两种主要的搜索方法：*词汇搜索*——基于查询中特定术语或属性的匹配和排名，以及*语义搜索*——基于查询意义的匹配和排名。你还被介绍了两种主要的查询表示方法：作为稀疏向量（具有非常少非零值的向量）和稠密向量（具有大部分非零值的向量）。词汇关键词搜索通常使用倒排索引实现，该索引存储了每个文档的稀疏向量表示，每个索引中的术语都有一个维度。语义搜索同样通常使用基于嵌入的稠密向量表示进行搜索。
- en: Sparse vector vs. dense vector vs. lexical search vs. semantic search
  id: totrans-242
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 稀疏向量 vs. 稠密向量 vs. 词汇搜索 vs. 语义搜索
- en: Due to computational cost, dense vector representations usually have a limited
    number of dimensions (hundreds to thousands) that densely compress a semantic
    representation of the data, whereas sparse vector representations can easily have
    hundreds of thousands to tens of millions of dimensions that represent more identifiable
    terms or attributes. Lexical keyword search is usually implemented using an inverted
    index, which holds a sparse vector representation of every document with a dimension
    for every term in the index. Semantic search is likewise usually implemented using
    a dense vector representation searching on embeddings. Due to these trends, many
    people mistakenly treat the term “semantic search” as synonymous with dense vector
    search on embeddings, but this throws away the rich history of much more explainable
    and flexible sparse-vector and graph-based semantic search approaches. This chapter
    highlights some of those approaches, with chapters 13–15 covering the dense vector
    search techniques in more depth.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算成本，密集向量表示通常具有有限的维度数（数百到数千），这些维度密集压缩数据的语义表示，而稀疏向量表示可以轻松地具有数十万到数千万的维度，这些维度代表更可识别的术语或属性。词汇关键词搜索通常使用倒排索引实现，该索引包含每个文档的稀疏向量表示，每个索引中的术语都有一个维度。同样，语义搜索通常使用密集向量表示在嵌入上进行搜索。由于这些趋势，许多人错误地将“语义搜索”一词与密集向量嵌入搜索等同起来，但这忽略了更多可解释和灵活的基于稀疏向量和图语义搜索方法的丰富历史。本章重点介绍了一些这些方法，第13-15章将更深入地介绍密集向量搜索技术。
- en: As you’ve seen already in this chapter, however, semantic search can also be
    implemented using sparse vectors, and within the context of typical lexical queries.
    While we’ve implemented semantic query parsing that operates directly on user
    queries, we’ve also generated query expansions using an SKG to generate sparse
    vectors of terms and weights to power semantic search.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如您在本章中已经看到的，语义搜索也可以使用稀疏向量在典型的词汇查询上下文中实现。虽然我们已经实现了直接在用户查询上操作的语义查询解析，但我们还使用SKG生成术语和权重的稀疏向量来支持语义搜索。
- en: Other techniques exist for this kind of query expansion, such as SPLADE (Sparse
    Lexical and Expansion). Instead of using an inverted index as its language model,
    the SPLADE approach ([https://arxiv.org/pdf/2107.05720](https://arxiv.org/pdf/2107.05720))
    uses a prebuilt language model to generate contextualized tokens. We won’t use
    SPLADE (or SPLADE V2 or subsequent versions) because it wasn’t released under
    a license enabling commercial use, but listing 7.14 demonstrates sample output
    from an alternative open source implementation (SPLADE++) for the same example
    queries we just tested with the SKG approach in section 7.4.2.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种查询扩展，存在其他技术，例如SPLADE（稀疏词汇和扩展）。SPLADE方法（[https://arxiv.org/pdf/2107.05720](https://arxiv.org/pdf/2107.05720)）不是使用倒排索引作为其语言模型，而是使用预先构建的语言模型来生成上下文化的标记。我们不会使用SPLADE（或SPLADE
    V2或后续版本），因为它没有在允许商业使用的许可下发布，但列表7.14展示了与我们在第7.4.2节中用SKG方法测试的相同示例查询的替代开源实现（SPLADE++）的样本输出。
- en: Listing 7.14 Expanding queries with SPLADE++
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.14 使用SPLADE++扩展查询
- en: '[PRE26]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#1 Specifies the SPLADE++ model name and maximum sequence length'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 指定SPLADE++模型名称和最大序列长度'
- en: '#2 Generates the sparse lexical vector'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 生成稀疏词汇向量'
- en: '#3 Returns token labels (strings) instead of token IDs (integers)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 返回标记标签（字符串）而不是标记ID（整数）'
- en: 'Here are the outputs from the SPLADE++ expansion:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是SPLADE++扩展的输出：
- en: '*kimchi*:'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*泡菜**：'
- en: '[PRE27]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*bb**q*:'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*泡菜**烤肉**：'
- en: '[PRE28]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*korean bb**q*:'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*韩国泡菜**烤肉**：'
- en: '[PRE29]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '*lasagna*:'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*千层面**：'
- en: '[PRE30]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '*karaok**e*:'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*卡拉OK**：'
- en: '[PRE31]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*drive through*:'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*驾车通过**：'
- en: '[PRE32]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note that the `outputformat=lucene` parameter results in the tokens (keywords
    or partial keywords) being returned instead of the integer IDs of the tokens,
    because seeing the tokens helps us better interpret the results.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`outputformat=lucene`参数会导致返回的是标记（关键词或部分关键词）而不是标记的整数ID，因为看到标记有助于我们更好地解释结果。
- en: 'When comparing this output with the previously shown SKG output for the same
    queries, you may notice the following differences:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当将此输出与之前显示的相同查询的SKG输出进行比较时，您可能会注意到以下差异：
- en: The SKG output returns actual terms in the index, whereas the SPLADE-style output
    returns tokens from the LLM. This means that you can use the SKG output (“lasagna”,
    “alfredo”, “pasta”) directly to search on the fields on your documents, whereas
    the SPLADE tokens (`las`, `##ag`, `na##`) will need to be generated from SPLADE
    for all documents and indexed in order for a SPLADE-style query to match on the
    right tokens at query time.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SKG的输出返回索引中的实际术语，而SPLADE风格的输出返回LLM的标记。这意味着您可以直接使用SKG输出（“lasagna”，“alfredo”，“pasta”）在您的文档字段上搜索，而SPLADE标记（`las`，`##ag`，`na##`）则需要从SPLADE生成并索引到所有文档中，以便在查询时匹配正确的标记。
- en: 'The SKG sparse vectors tend to look cleaner and more relevant to the dataset
    (restaurant reviews) for in-domain terms. For example, for the query `bbq`, the
    SKG returns `{"bbq":` `0.9191,` `"ribs":0.6186,` `"pork":0.5991,` `"brisket" :0.569}`,
    whereas SPLADE returns `{''bb'': 2.78,` `''grill'':` `1.85,` `''barbecue'':` `1.36,`
    `''dinner'':` `0.91,` `''##q'':` `0.78,` `''dish'':` `0.77,` `''restaurant'':
    0.65,` `''sport'':` `0.46,` `''food'':` `0.34,` `…}`. This underperformance of
    the SPLADE model relative to the SKG model is mostly due to SPLADE not being trained
    on the data in the search index, whereas the SKG uses the data in the search index
    directly as its language model. Fine-tuning the SPLADE-based model would help
    to close this gap.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SKG稀疏向量在域内术语上往往看起来更干净、更与数据集（餐厅评论）相关。例如，对于查询`bbq`，SKG返回`{"bbq": 0.9191, "ribs":
    0.6186, "pork": 0.5991, "brisket" : 0.569}`，而SPLADE返回`{''bb'': 2.78, ''grill'':
    1.85, ''barbecue'': 1.36, ''dinner'': 0.91, ''##q'': 0.78, ''dish'': 0.77, ''restaurant'':
    0.65, ''sport'': 0.46, ''food'': 0.34, `…}`。与SKG模型相比，SPLADE模型的这种表现不足主要是由于SPLADE没有在搜索索引中的数据上训练，而SKG直接使用搜索索引中的数据作为其语言模型。微调基于SPLADE的模型将有助于缩小这一差距。'
- en: The SKG model is more flexible, as it can return relationships across multiple
    dimensions. Notice in the last section that we not only returned the sparse vector
    of related terms, but also a classification of the query.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SKG模型更灵活，因为它可以返回多个维度的关系。注意在上一节中，我们不仅返回了相关术语的稀疏向量，还返回了查询的分类。
- en: Both the SPLADE and SKG models are context-aware. SPLADE natively weights each
    token based on the entire context of the query (or document) being encoded, and
    the SKG request can likewise (optionally) use any passed-in context for the query
    or document to contextualize the weights of its tokens. SPLADE-based models tend
    to shine more with longer well-known contexts (like general documents), whereas
    the SKG model is more optimized for shorter, domain-specific contexts (like in-domain
    queries), but they both work and represent novel techniques for sparse-vector-based
    or lexically oriented semantic search.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SPLADE和SKG模型都是上下文感知的。SPLADE基于整个查询（或文档）编码的上下文对每个标记进行加权，而SKG请求同样（可选）可以使用传递给查询或文档的任何上下文来上下文化其标记的权重。基于SPLADE的模型在较长的已知上下文中（如一般文档）表现更出色，而SKG模型则更优化于较短、特定领域的上下文（如域内查询），但它们都有效，并且代表了基于稀疏向量或基于词汇的语义搜索的新技术。
- en: We’ve chosen to use an SKG-based approach instead of SPLADE in this chapter
    due to its ability to also classify queries and further contextualize queries
    for query sense disambiguation, but similar concepts apply for implementing sparse-vector-based
    semantic search regardless of which model you choose, so it’s good to be familiar
    with multiple techniques.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择在本章中使用基于SKG的方法而不是SPLADE，因为它还具有分类查询和进一步对查询进行上下文化的能力，以便进行查询意义消歧，但无论选择哪种模型，实现基于稀疏向量的语义搜索的类似概念都适用，因此熟悉多种技术是好的。
- en: In the next section, we’ll walk through the transformation of the enriched query
    tree into a search-engine-specific query syntax for sending to the search engine.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍如何将富查询树转换为搜索引擎特定的查询语法，以便发送给搜索引擎。
- en: 7.4.4 Transforming a query for semantic search
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.4 对语义搜索查询进行转换
- en: With the user’s query now parsed and enriched, it’s time to transform the query
    tree into an appropriate search-engine-specific syntax.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在用户的查询已经解析并丰富，是时候将查询树转换为适当的搜索引擎特定语法了。
- en: During this *transforming* phase, we invoke an adapter to convert the query
    tree to the most useful engine-specific representation of the query—Solr in our
    default implementation. In the case of our semantic functions (the `popularity`
    and `location_distance` functions), we already injected this engine-specific syntax
    (`{"type":"transformed",` `"syntax":"solr"}`) directly into the enriched nodes
    in the query tree. We could have alternatively abstracted this a bit by creating
    a generic intermediate representation of each semantic function’s output and then
    waiting until the transforming phase to convert to engine-specific syntax (Solr,
    OpenSearch, etc.), but we chose to avoid the intermediate representations to keep
    the examples simpler. If you run the code using a different engine (as explained
    in appendix B), you’ll see the syntax for that engine in the transformed nodes
    instead.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 *转换* 阶段，我们调用一个适配器将查询树转换为查询的最有用的引擎特定表示——在我们的默认实现中是 Solr。在我们的语义函数（`popularity`
    和 `location_distance` 函数）的情况下，我们已经在查询树的丰富节点中直接注入了这种引擎特定的语法（`{"type":"transformed",`
    `"syntax":"solr"}`）。我们本可以稍微抽象一下，通过创建每个语义函数输出的通用中间表示，然后在转换阶段将其转换为引擎特定的语法（Solr、OpenSearch
    等），但我们选择避免中间表示以使示例更简单。如果你使用不同的引擎（如附录 B 中所述）运行代码，你将在转换节点中看到该引擎的语法。
- en: The following listing shows a `transform_query` function that takes an enriched
    query tree and transforms each of its nodes into search-engine-specific nodes.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了一个 `transform_query` 函数，它接受一个丰富的查询树并将其每个节点转换为搜索引擎特定的节点。
- en: Listing 7.15 Transforming a query tree into engine-specific syntax
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.15 将查询树转换为引擎特定的语法
- en: '[PRE33]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '#1 If a query tree element has already been transformed to search-engine-specific
    syntax, there is no need to process it further.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 如果查询树元素已经被转换成搜索引擎特定的语法，则无需进一步处理。'
- en: '#2 Generates an enriched query for enriched nodes'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 为丰富节点生成丰富的查询'
- en: '#3 Handles the transformation of other potential query-tree elements with custom
    type-handling logic'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用自定义类型处理逻辑处理其他潜在的查询树元素的转换'
- en: '#4 For all other types without custom transformation logic, just search on
    their surface form.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 对于所有其他没有自定义转换逻辑的类型，只需在其表面形式上搜索。'
- en: '#5 Denotes each transformed query tree node with the engine-specific syntax
    and query'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 使用搜索引擎特定的语法和查询表示每个转换后的查询树节点'
- en: 'Output:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE34]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'At this point, all nodes in the query tree have been transformed into `{''type'':
    ''transformed'',` `''syntax'':` `engine}` nodes, which means they internally contain
    the search-engine-specific syntax needed to generate a final query to the configured
    engine. We’re now ready to convert the query tree into a string and send the request
    to the search engine.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '到目前为止，查询树中的所有节点都已转换为 `{''type'': ''transformed'',` `''syntax'':` `engine}`
    节点，这意味着它们内部包含生成最终查询到配置的搜索引擎所需的搜索引擎特定语法。我们现在准备好将查询树转换为字符串并发送请求到搜索引擎。'
- en: 7.4.5 Searching with a semantically enhanced query
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.5 使用语义增强的查询进行搜索
- en: The final step of our semantic search process is the *searching* phase. We convert
    the fully transformed `query_tree` to a query, run the query against the search
    engine, and return the results to the end user.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们语义搜索过程的最后一步是 *搜索* 阶段。我们将完全转换后的 `query_tree` 转换为查询，对搜索引擎运行查询，并将结果返回给最终用户。
- en: Listing 7.16 Running the query
  id: totrans-288
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.16 运行查询
- en: '[PRE35]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The search results for our query `top kimchi near charlotte` will return exactly
    what was shown in our end-to-end example in section 7.3\. Since we know we can
    now handle variations of semantic functions (“in” versus “near” for locations,
    “good” versus “popular” versus “top” for popularity), we’ll show the output for
    a slightly modified query: `good` `kimchi` `in` `charlotte`. If you contrast the
    output for this variant, shown in figure 7.8, with the output for the original
    query of `top` `kimchi` `near` `charlotte`, you’ll see that they yield the exact
    same transformed query and final set of search results as figures 7.5 and 7.7
    earlier in the chapter.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的查询 `top kimchi near charlotte` 的搜索结果将返回第 7.3 节中展示的端到端示例中的内容。由于我们知道现在可以处理语义函数的变体（对于位置，“in”与“near”的区别，对于流行度，“good”与“popular”与“top”的区别），我们将展示一个略微修改后的查询的输出：`good`
    `kimchi` `in` `charlotte`。如果你对比这个变体的输出（如图 7.8 所示）与原始查询 `top` `kimchi` `near` `charlotte`
    的输出，你会发现它们产生了与第 7.5 和 7.7 节中较早的章节中相同的转换查询和最终的搜索结果集。
- en: '![figure](../Images/CH07_F08_Grainger.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F08_Grainger.png)'
- en: Figure 7.8 Search results for `good kimchi in charlotte`, interpreted as semantically
    identical to the results for the `top` `kimchi` `near` `charlotte` end-to-end
    example
  id: totrans-292
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.8为`good kimchi in charlotte`的搜索结果，解释为与`top` `kimchi` `near` `charlotte`端到端示例的语义相同
- en: Congratulations, you’ve now implemented an end-to-end semantic search pipeline
    that can semantically parse, enrich, transform, and run searches. This chapter
    didn’t introduce any fancy new machine-learning algorithms but instead provided
    a concrete implementation of how the many models, algorithms, and other techniques
    you’ve learned throughout the book can be integrated into an end-to-end system.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你现在已经实现了一个端到端语义搜索管道，它可以对内容进行语义解析、丰富、转换，并执行搜索。本章没有介绍任何新的机器学习算法，而是提供了一个具体的实现，说明你在这本书中学到的许多模型、算法和其他技术如何集成到一个端到端系统中。
- en: Throughout the remainder of the book, we’ll continue to explore more advanced
    approaches that can plug into this framework to enhance relevance ranking and
    improve query intent understanding.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，我们将继续探索更多高级方法，这些方法可以插入到这个框架中，以增强相关性排名并改善查询意图理解。
- en: Summary
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Query interpretation requires appropriately mixing query pipelines with learned
    models while ensuring an adequate fallback model for matching unknown keywords.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询解释需要适当地混合查询管道与学习模型，同时确保有足够的后备模型来匹配未知关键词。
- en: Matching only on keywords can sometimes work, but it results in poor matches
    when the intent expressed by connecting words isn’t understood (`top`, `near`,
    etc.). One way to solve this is by implementing domain-specific semantic functions
    to overcome those limitations.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅匹配关键词有时可能有效，但当连接词（如`top`、`near`等）所表达的意思未被理解时，会导致匹配效果不佳。解决这一问题的方法之一是通过实现特定领域的语义函数来克服这些限制。
- en: A semantic query parser, which is aware of known terms and phrases learned within
    your domain, allows you to move from a keyword-based search to a semantic search
    on entities and their relationships.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个了解你领域内已知术语和短语的语义查询解析器，允许你从基于关键词的搜索过渡到对实体及其关系的语义搜索。
- en: Extracting known entities enables the seamless integration of models into your
    query interpretation pipeline, using mappings between surface forms of keywords
    to canonical representations of entities generated from your learned models (signals
    boosts, alternative spellings, related terms, and other knowledge graph data).
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取已知实体使得模型能够无缝集成到你的查询解释管道中，通过将关键词的表面形式映射到由你的学习模型生成的实体的规范表示（信号增强、替代拼写、相关术语以及其他知识图谱数据）。
- en: Semantic search involves *parsing* known entities, *enriching* with learned
    models, *transforming* the query to optimize matching and relevance for the target
    search engine, and then *searching* and returning results to the end user. We’ll
    continue to explore more advanced techniques to plug into these phases in the
    coming chapters.*
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义搜索涉及*解析*已知实体，*丰富*使用学习模型，*转换*查询以优化目标搜索引擎的匹配和相关性，然后*搜索*并将结果返回给最终用户。我们将在接下来的章节中继续探索更多高级技术，以将这些阶段插入到这些阶段中。*
