- en: Chapter 11\. Testing AI Services
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章\. 测试人工智能服务
- en: In this chapter, you’ll learn the importance of testing and its challenges when
    building GenAI services. You’ll also learn about key concepts such as test plans,
    the verification and validation models, the testing pyramid, and the role of testing
    data, environments, and boundaries.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解在构建生成人工智能服务时测试的重要性及其挑战。您还将了解关键概念，如测试计划、验证和验证模型、测试金字塔以及测试数据、环境和边界的作用。
- en: To practice testing, you will use `pytest`, a popular testing framework with
    features such as test fixtures, scopes, markers, and fixture parameterization.
    You’ll also learn about the `pytest-mock` plug-in for patching functions and using
    stubs, mocks, and spy objects to simulate and control external dependencies during
    tests.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习测试，您将使用`pytest`，这是一个具有测试固定、作用域、标记和固定参数化等功能的流行测试框架。您还将了解`pytest-mock`插件，用于修补函数和使用存根、模拟和间谍对象在测试期间模拟和控制外部依赖项。
- en: Since mocking can make tests brittle, we’ll also explore dependency injection,
    allowing you to inject mock or stub dependencies directly into the components
    being tested, avoiding runtime code modifications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模拟可能会使测试变得脆弱，因此我们还将探讨依赖注入，允许您直接将模拟或存根依赖项注入到正在测试的组件中，从而避免运行时代码修改。
- en: We’ll discuss the role of isolation and idempotency in tests, when to use mocks,
    and how to test both deterministic and probabilistic GenAI code. By the end of
    this chapter, you’ll be confident in writing comprehensive test suites including
    unit, integration, end-to-end, and behavioral tests for your own services.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论隔离性和幂等性在测试中的作用，何时使用模拟，以及如何测试确定性和概率性生成人工智能代码。到本章结束时，您将自信地编写包括单元、集成、端到端和行为测试在内的全面测试套件，用于您自己的服务。
- en: Before we dive into writing tests, let’s explore the foundational concepts of
    traditional software testing and how to approach testing GenAI services, which
    can prove challenging due to the probabilistic nature of AI models.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入编写测试之前，让我们探讨传统软件测试的基础概念以及如何测试生成人工智能服务，这可能会由于人工智能模型的概率性质而具有挑战性。
- en: The Importance of Testing
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试的重要性
- en: In theory, everyone agrees that testing is necessary when building software.
    You write tests to give you confidence in the functionality and performance of
    your systems, especially when they interact with one another. But realistically,
    projects may skip implementing manual or automated tests due to various constraints
    including budget, time, or associated labor costs related to maintaining tests.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，每个人都同意在构建软件时进行测试是必要的。您编写测试以增强对系统功能和性能的信心，尤其是在它们相互交互时。但现实中，由于预算、时间或与维护测试相关的劳动力成本等限制，项目可能会跳过实施手动或自动化测试。
- en: The projects that skip testing, partially or entirely, end up approaching software
    problems reactively instead of proactively. This is when *technical debt* builds
    up, which you’ll then have to pay back in labor and server costs, with interest,
    to settle up.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 部分或完全跳过测试的项目最终会采取被动而不是主动的方法来处理软件问题。这就是当*技术债务*积累起来时，您随后将不得不以劳动力和服务器成本，加上利息，来偿还。
- en: The problem of when to test is challenging to solve. If you’re just experimenting
    and hacking a prototype together in fast iterations, you won’t need to worry about
    testing as much, realistically. However, as soon as you have a minimum sellable
    product, a system that interfaces with sensitive data and processes user payments,
    then you must seriously consider testing plans.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 解决何时进行测试的问题具有挑战性。如果您只是在快速迭代中实验和构建原型，那么实际上您不必过多担心测试。然而，一旦您拥有一个最低可销售产品，一个与敏感数据交互并处理用户支付的系统，那么您就必须认真考虑测试计划。
- en: Earlier in my career, I was building a learning management system for a client.
    I wrote a webhook endpoint to interface with Stripe’s payment systems and my own
    home-brewed authentication solution that would only register users on successful
    first payment. The system had to charge and process subscription payments of both
    new and existing customers and send confirmation emails while tracking user records,
    subscriptions, payments, checkout sessions, and invoices. The logic of that webhook
    ended up so convoluted and complex that it led to a monstrosity that became a
    1,000-line function. The function was checking unordered received events of various
    types, with multiple round-trips to the database.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的职业生涯早期，我为一位客户构建了一个学习管理系统。我编写了一个webhook端点，用于与Stripe的支付系统以及我自己的自制身份验证解决方案进行接口，该解决方案只会注册在成功首次支付的用户。该系统必须对新的和现有的客户收取和处理订阅支付，同时跟踪用户记录、订阅、支付、结账会话和发票。那个webhook的逻辑最终变得如此复杂，以至于它导致了一个成为1,000行函数的怪物。该函数正在检查各种类型的未排序接收事件，并多次往返数据库。
- en: The whole solution had to be scrapped at the end since the webhook’s behavior
    was so *flaky*, returning nonconsistent responses to the same set of inputs. Users
    couldn’t register even after successful payments. This flakiness made it unbearable
    to debug that webhook, which forced me to rewrite the payment system integration
    from scratch. If I had only slowed down to plan and modularized the logic and
    wrote tests early on, I could have saved myself from so much headache.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于webhook的行为如此*不可靠*，对同一组输入返回不一致的响应，整个解决方案最终不得不被废弃。即使在成功支付后，用户也无法注册。这种不可靠性使得调试那个webhook变得难以忍受，迫使我不得不从头开始重新编写支付系统集成。如果我当时只是放慢速度来规划和模块化逻辑，并早期编写测试，我就可以避免这么多头疼的问题。
- en: When you slow down to plan and test your services, you’re trading off time and
    effort in exchange for confidence in your code.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当你放慢速度来规划和测试你的服务时，你正在权衡时间和精力以换取对代码的信心。
- en: 'A few other times you should consider implementing tests are when:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在以下几种情况下考虑实现测试：
- en: Multiple contributors add changes over time
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个贡献者随着时间的推移添加了更改
- en: Maintainers change external dependencies
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护者更改外部依赖项
- en: You increase the number of components and dependencies in your services
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你在服务中增加了组件和依赖项的数量
- en: You suddenly spot too many bugs appearing
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你突然发现出现了太多的错误
- en: There is too much at stake if things go wrong—my experience fell into this bucket
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果事情出错，风险太大——我的经验就属于这一类
- en: You should now understand how testing will benefit your project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该了解测试将如何使你的项目受益。
- en: Software Testing
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件测试
- en: Now that you’re familiar with the challenges and potential approaches to testing
    GenAI services, let’s review software testing concepts to understand their relevance
    to GenAI use cases and common pitfalls to avoid.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经熟悉了测试GenAI服务的挑战和潜在方法，让我们回顾软件测试概念，以了解它们对GenAI用例的相关性和需要避免的常见陷阱。
- en: Types of Tests
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试类型
- en: 'There are three common types of tests in software testing, which, ordered by
    increasing size and complexity, are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 软件测试中有三种常见的测试类型，按大小和复杂度递增的顺序如下：
- en: Unit tests
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试
- en: Focus on testing individual components or functions in isolation across a discrete
    set of inputs and edge cases to validate functionality at singular component level.
    Unit tests are atomic with the smallest scope and often don’t rely on external
    systems or dependencies.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于测试离散输入集和边缘情况下的单个组件或函数，以验证单个组件级别的功能。单元测试具有最小的范围，通常不依赖于外部系统或依赖项。
- en: Integration tests
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试
- en: Check the interaction between various components or systems to verify they function
    together as intended. Integration tests often capture issues with application
    behavior at a subsystem level, validating data flows and interface contracts,
    (i.e., specifications) between various components.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 检查各个组件或系统之间的交互，以验证它们是否按预期一起工作。集成测试通常捕获子系统级别的应用程序行为问题，验证各种组件之间的数据流和接口合同（即规范）。
- en: End-to-end (E2E) tests
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端（E2E）测试
- en: Verify the functionalities of the application at the highest system level from
    start to finish by simulating real usage scenarios. E2E tests give you the highest
    levels of confidence in your application functionality and performance but are
    the most challenging tests to design, develop, and maintain.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模拟真实使用场景，从开始到结束验证应用程序在最高系统级别的功能。端到端测试为你提供了对应用程序功能和性能的最高信心水平，但它们是设计、开发和维护最具挑战性的测试。
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: E2E tests and integration tests share similarities that make them hard to distinguish
    from one another. If a test is big and sometimes flaky, you may be working on
    an E2E test.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端测试和集成测试具有相似之处，使得它们难以区分。如果一个测试很大，有时不可靠，你可能正在处理一个端到端测试。
- en: Integration tests normally check a subset of systems and interactions, not the
    whole system or a long chain of subsystems.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试通常检查系统的一部分和交互，而不是整个系统或长链子系统。
- en: '[Figure 11-1](#test_types) demonstrates the scope of each test type. Unit tests
    shown on the left focus on isolated components, while integration tests check
    pairwise interactions of multiple components, including with external services.
    Lastly, E2E tests cover the entire user journey and data flow within the application
    to confirm the intended functionality.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-1](#test_types)展示了每种测试类型的范围。左侧显示的单元测试专注于隔离的组件，而集成测试则检查多个组件之间的成对交互，包括与外部服务的交互。最后，端到端测试覆盖了应用程序中的整个用户旅程和数据流，以确认预期的功能。'
- en: '![bgai 1101](assets/bgai_1101.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1101](assets/bgai_1101.png)'
- en: Figure 11-1\. Types of tests in software testing
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1\. 软件测试中的测试类型
- en: Before implementing any of the aforementioned tests, you can also use *static
    code checks* with tools like `mypy` to catch syntax and type errors. As you write
    code, static checks can also help you catch code style violations, misuse of functions
    and dependencies, security vulnerabilities, dead or unused code, data flow issues,
    and potential bugs in your system components.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施上述任何测试之前，你还可以使用像`mypy`这样的工具进行*静态代码检查*来捕获语法和类型错误。当你编写代码时，静态检查还可以帮助你捕获代码风格违规、函数和依赖项的误用、安全漏洞、死代码或未使用代码、数据流问题以及系统组件中的潜在错误。
- en: As you progress from static checks and unit tests to integration and then to
    E2E tests, your test cases become more valuable but also more complex, expensive,
    and slower. More important, since E2E tests have broader scope with multiple components
    interacting, they’ll become more brittle and likely to fail, requiring frequent
    updates to stay aligned with changes in your code.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你从静态检查和单元测试进展到集成测试，再到端到端测试，你的测试用例变得更加有价值，但也更加复杂、昂贵和缓慢。更重要的是，由于端到端测试具有更广泛的范围，涉及多个组件的交互，它们将变得更加脆弱，更容易失败，需要频繁更新以保持与代码变化的同步。
- en: 'E2E tests are also complex and flaky/nondeterministic. According to Martin
    Fowler,^([1](ch11.html#id1148)) these are the main reasons for the nondeterminism:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端测试也复杂且不可靠/非确定性。根据马丁·福勒的说法^([1](ch11.html#id1148))，这些是非确定性的主要原因：
- en: '*Lack of isolation* causes components to interfere with each other, leading
    to unpredictable results.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*隔离不足*会导致组件之间相互干扰，从而导致不可预测的结果。'
- en: '*Asynchronous behavior* with operations that occur out of sequence or at unpredictable
    times can lead to nondeterministic outcomes.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*异步行为*，即操作在非顺序或不可预测的时间发生，可能导致非确定性结果。'
- en: '*Remote services* can introduce variability due to network latency, service
    availability, or differing responses.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*远程服务*可能会由于网络延迟、服务可用性或不同的响应而引入可变性。'
- en: '*Resource leaks*, if not properly managed, can lead to inconsistent system
    behavior. Affected resources include memory, file handles, or connections to databases,
    clients, etc.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*资源泄露*，如果管理不当，可能导致系统行为不一致。受影响的资源包括内存、文件句柄或与数据库、客户端等的连接。'
- en: Finally, due to the brittleness of E2E tests, refactors and changes in functionality
    can cause them to fail. Therefore, there is a trade-off between the level of confidence
    you gain from E2E tests and the flexibility to make changes to your systems.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于端到端测试的脆弱性，重构和功能变更可能导致它们失败。因此，你在端到端测试中获得的可信度水平与对系统进行更改的灵活性之间存在权衡。
- en: The Biggest Challenge in Testing Software
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试软件的最大挑战
- en: The biggest challenge in testing services is identifying what to test and to
    what detail. As part of this, you need to decide what to mock, fake, or keep real
    alongside configuring a host of testing tools and environments.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 测试服务中最大的挑战是确定要测试什么以及测试到什么程度。作为其中的一部分，你需要决定要模拟、伪造还是保持真实，同时配置一系列的测试工具和环境。
- en: To overcome this challenge, you can plan your tests in advance, identifying
    breaking points in your system and narrowing down issues to individual components
    and interactions. Then, imagine who the user is and list the steps they’ll take
    when interacting with the problematic systems. Finally, you can translate that
    lists of steps into individual tests and automate them.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个挑战，你可以提前规划你的测试，确定系统中的断裂点，并将问题缩小到单个组件和交互。然后，想象一下用户是谁，并列出他们与有问题的系统交互时将采取的步骤。最后，你可以将这些步骤列表转换为单个测试并自动化它们。
- en: Another challenge with testing that causes so much frustration is having to
    rewrite your tests whenever you refactor the code they’re testing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与测试相关的挑战，导致大量挫败感的是，每当重构被测试的代码时，不得不重写你的测试。
- en: Since code refactors don’t change the functional behavior but implementation
    details, it can be a sign that you’re not testing the right things. For example,
    if you’re testing the internal string processing logic of the `count_tokens(text)`
    function rather than just its final output (i.e., the token count), using an external
    library to replace the string manipulation logic can cause your tests to fail.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码重构不会改变功能行为但会改变实现细节，这可能是一个迹象，表明你没有测试正确的事情。例如，如果你测试的是`count_tokens(text)`函数的内部字符串处理逻辑，而不是仅仅测试其最终输出（即令牌计数），使用外部库替换字符串处理逻辑可能会导致你的测试失败。
- en: A telltale sign that you might be testing implementation details is when your
    tests fail as you refactor the code (i.e., false positives), or pass even when
    you introduce breaking changes to your code (i.e., false negatives). You can use
    techniques such as *black-box testing* to test your system by providing inputs
    and observing outputs, without considering the implementation details.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的迹象表明你可能正在测试实现细节是，当你重构代码时（即假阳性），或者即使你引入了破坏性的代码更改（即假阴性），你的测试也会失败。你可以使用诸如*黑盒测试*等技术，通过提供输入并观察输出来测试你的系统，而不考虑实现细节。
- en: If you plan your tests in advance, you can avoid these testing challenges.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你提前规划你的测试，你可以避免这些测试挑战。
- en: Planning Tests
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试规划
- en: To identify the tests you need during planning, you can use the *verification
    and validation* (V&V) process.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划阶段确定所需的测试时，你可以使用*验证和验证*（V&V）过程。
- en: Following this process, you first confirm possession of the right requirements
    (validation) and then leverage tests to verify all requirements are met (verification).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 按照此流程，你首先确认拥有正确的需求（验证），然后利用测试来验证所有需求都得到满足（验证）。
- en: Warning
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Having 100% code coverage with passing tests will complete only the verification
    process, not validation. You still need to make sure that your services implement
    the right functions (i.e., validation).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有100%的代码覆盖率并且测试通过，也仅完成了验证过程，而不是验证。你仍然需要确保你的服务实现了正确的功能（即验证）。
- en: The V&V process can be visualized as a V-shaped model as per [Figure 11-2](#vv).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: V&V过程可以按照[图11-2](#vv)所示，可视化为V形模型。
- en: When you go down the V model, you define software requirements and design the
    solution before implementing it as code. Afterward, you come back up the “V” by
    running progressive tests (unit, integration, E2E, etc.) to validate that your
    solution meets the business needs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当你遵循V模型时，你首先定义软件需求，然后设计解决方案，在将其作为代码实现之前。之后，通过运行渐进式测试（单元、集成、端到端等）回到“V”的顶部，以验证你的解决方案是否符合业务需求。
- en: '![bgai 1102](assets/bgai_1102.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1102](assets/bgai_1102.png)'
- en: Figure 11-2\. Verification and validation model
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 验证和验证模型
- en: As discussed earlier, validation tests can be challenging to identify. Exactly
    what progressive tests should you implement?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，验证测试可能难以识别。你应该实施哪些渐进式测试？
- en: When you struggle with identifying what to test, you can write tests based on
    issues and bugs that you find in your application. This approach is *reactive*
    since you’re writing tests only when issues arise, which can help you overcome
    the challenges of not knowing what to test. However, testing to resolve issues
    later in the *software development lifecycle* (SDLC) requires significant testing
    efforts as you’ll be dealing with a more complex system with many moving parts
    to test.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在识别要测试的内容时遇到困难，你可以根据在应用程序中发现的错误和问题编写测试。这种方法是*反应性的*，因为你只有在问题出现时才编写测试，这可以帮助你克服不知道要测试什么的挑战。然而，在*软件开发生命周期*（SDLC）的后期解决问题的测试需要大量的测试工作，因为你将处理一个更复杂的系统，有许多移动部件需要测试。
- en: That’s why movements such as *shift-left testing* are advocating for *preventative*
    testing practices that are planned in advance and written during development to
    reduce the testing efforts. [Figure 11-3](#shift_left) demonstrates how moving
    testing efforts earlier on the SLDC can reduce the overall burden.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，像*左移测试*这样的运动正在倡导*预防性*测试实践，这些实践是在开发过程中提前计划和编写的，以减少测试工作量。[图 11-3](#shift_left)
    展示了在 SDLC 早期移动测试工作量如何减少总体负担。
- en: '![bgai 1103](assets/bgai_1103.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1103](assets/bgai_1103.png)'
- en: Figure 11-3\. Shift-left software testing
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. 左移软件测试
- en: A common approach in shift-left testing is *test-driven development* (TDD),
    as shown in [Figure 11-4](#tdd).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在左移测试中，一个常见的做法是*测试驱动开发*（TDD），如图 11-4 所示。
- en: '![bgai 1104](assets/bgai_1104.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1104](assets/bgai_1104.png)'
- en: Figure 11-4\. TDD
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-4\. TDD
- en: In the TDD approach, you write the tests before the actual code. This is an
    iterative process where written tests will fail at first, but your aim will be
    to write the minimal amount of code for tests to pass. Once passing, you refactor
    the code to optimize the system while keeping the tests passing to finish the
    iterative TDD process.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TDD 方法中，你会在实际代码之前编写测试。这是一个迭代的过程，其中编写的测试最初会失败，但你的目标将是编写最少的代码以使测试通过。一旦通过，你将重构代码以优化系统，同时保持测试通过以完成迭代的
    TDD 过程。
- en: Tip
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: A great example of where TDD practices are useful in testing GenAI services
    is during *prompt engineering*. Write a set of tests first, and then keep iterating
    over the prompt design until all your tests pass.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: TDD 实践在测试 GenAI 服务中非常有用的一个例子是在*提示工程*期间。首先编写一组测试，然后不断迭代提示设计，直到所有测试通过。
- en: Using the same test cases, you can check for any signs of regression and whether
    switching models will reduce the performance of your services.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的测试用例，你可以检查任何回归的迹象，以及切换模型是否会降低你服务的性能。
- en: As you can see, the overall aim of TDD is to reduce the testing efforts by improving
    your code quality, solution design, and early detection of issues.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，TDD 的总体目标是通过对代码质量、解决方案设计和问题早期检测的改进来减少测试工作量。
- en: Test Dimensions
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试维度
- en: 'Additionally, during planning, you normally have to decide on various test
    dimensions including testing *scope*, *coverage*, and *comprehensiveness*:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在规划过程中，你通常需要决定包括测试*范围*、*覆盖率*和*全面性*在内的各种测试维度：
- en: Scope
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 范围
- en: Defines what components, systems, and usage scenarios you’ll be testing. As
    part of scope definition, you’ll also be drawing *testing boundaries* to clarify
    what will and won’t be tested.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 定义你将测试的组件、系统和使用场景。作为范围定义的一部分，你还将绘制*测试边界*以明确什么将被测试，什么不会被测试。
- en: Coverage or testing surface area
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖率或测试表面积
- en: Measures how much of the system or codebase you’ll be testing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量你将测试的系统或代码库的多少。
- en: Comprehensiveness
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 全面性
- en: Indicates how detailed, in-depth, and complete your tests will be within the
    defined scope and coverage. For example, you’ll decide whether you’ll be testing
    every potential usage, success and failure scenarios, and edge cases for every
    component, system, and interaction.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表示在定义的范围内和覆盖范围内你的测试将有多详细、深入和完整。例如，你将决定是否要测试每个组件、系统和交互的每个潜在使用情况、成功和失败场景以及边缘情况。
- en: You can also think of testing scope, coverage, and comprehensiveness as testing
    *space/volume*, *surface area*, and *depth*. Volume/space defines the boundaries
    and dimensions of what is being tested; surface area measures the spread of tests;
    and depth implies detail, depth, and completeness of test cases.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以将测试范围、覆盖率和全面性视为测试的*空间/体积*、*表面积*和*深度*。体积/空间定义了测试的边界和维度；表面积衡量测试的分布；深度意味着测试用例的详细程度、深度和完整性。
- en: Test Data
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试数据
- en: 'To achieve higher test coverage and comprehensiveness, you can leverage four
    different types of test data:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现更高的测试覆盖率和全面性，你可以利用四种不同类型的测试数据：
- en: Valid data
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有效数据
- en: Inputs to the system within the valid and expected range under normal conditions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常条件下，系统内的有效和预期范围内的输入。
- en: Invalid data
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 无效数据
- en: Inputs that are unexpected, wrong, NULL, or outside the valid range. You can
    use negative data to test how the system behaves when it’s misused.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 预期之外、错误、NULL或超出有效范围的输入。你可以使用负数据来测试系统被误用时会如何表现。
- en: Boundary data
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 边界数据
- en: Test data at boundaries of acceptable input ranges, whether at the upper or
    lower limit.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在可接受输入范围的边界处的测试数据，无论是上限还是下限。
- en: Huge data
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 大量数据
- en: Used for performance and stress testing the system to measure its limits.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 用于性能和压力测试系统以测量其极限。
- en: Test Phases
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试阶段
- en: 'It doesn’t matter if you’re implementing a unit, integration, or E2E test,
    you can structure tests in several distinct phases using the *given-when-then*
    (GWT) model, as outlined here:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是在实现单元测试、集成测试还是端到端测试，你都可以使用**给定-当-然后**（GWT）模型来结构化测试，如下所述：
- en: '*Given (preconditions)*: Before any given test, you can set up test conditions
    and predefined states or data (i.e., *fixtures*).'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**给定（前提条件）**：在执行任何给定测试之前，你可以设置测试条件和预定义的状态或数据（即**固定值**）。'
- en: '*When (test steps)*: During the test, you perform a set of action steps that
    you’ll like to test. This is where you’ll pass your test fixtures to the *system
    under test* (SUT), which, depending on the test scope, can be a singular function
    or your whole service.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**当（测试步骤）**：在测试过程中，你执行一系列你想要测试的操作步骤。这是你将测试固定值传递给**系统单元**（SUT）的地方，根据测试范围，它可以是单个函数或整个服务。'
- en: '*Then (expected results)*: After executing the SUT with fixtures, you’ll check
    the outputs against your expectations in this phase using a set of assert statements.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**然后（预期结果）**：在执行了固定值之后，你将在这一阶段使用一系列断言语句来检查输出是否符合你的预期。'
- en: '*Cleanup*: Once done, you can clean up test artifacts within an optional *cleanup/tear-down*
    phase.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**清理**：一旦完成，你可以在可选的**清理/拆卸**阶段清理测试工件。'
- en: '`pytest` recommends structuring tests using the *arrange-act-assert-cleanup*
    model, which directly corresponds to the GWT model with an optional cleanup phase.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest`建议使用**安排-执行-断言-清理**模型来结构化测试，这直接对应于GWT模型，并包含一个可选的清理阶段。'
- en: Test Environments
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试环境
- en: When planning tests, you should also consider various *testing environments*
    covering compile time, build time, and runtime environments.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划测试时，你也应该考虑涵盖编译时间、构建时间和运行时环境的各种**测试环境**。
- en: In many programming languages, *compile time* is when the source code is translated
    into executable code. For instance, if you’re writing code in C++, the compilation
    process involves a comprehensive type check across the entire codebase. If type
    errors are found, the compilation process will fail. Once all checks pass, the
    C++ compiler translates the code into an executable binaries.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多编程语言中，**编译时间**是指源代码被转换为可执行代码的时候。例如，如果你正在用C++编写代码，编译过程涉及在整个代码库中进行全面的类型检查。如果发现类型错误，编译过程将失败。一旦所有检查都通过，C++编译器将代码转换为可执行的二进制文件。
- en: Note
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 备注
- en: The strong typing in C++ was designed to improve error detection, code robustness,
    and support developer tooling in larger and complex codebases that change frequently.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: C++中的强类型设计是为了提高错误检测、代码健壮性，并在频繁变更的大型和复杂代码库中支持开发者工具。
- en: Since Python is an interpreted language, it doesn’t have a traditional compile
    time like C++. Instead, Python converts code into bytecode for execution.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python是一种解释型语言，它没有像C++那样的传统编译时间。相反，Python将代码转换为字节码以执行。
- en: During inspections, static code checkers like `mypy` can identify basic issues
    in your code, serving as an initial verification layer in your testing efforts.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查过程中，静态代码检查器如`mypy`可以识别代码中的基本问题，作为测试努力的初步验证层。
- en: Warning
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Since Python is a dynamically typed language, it doesn’t enforce typing by default.
    However, static type checkers like `mypy` can provide significant value if you
    use type hints in your Python code.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python是一种动态类型语言，它默认不强制执行类型。然而，如果你在Python代码中使用类型提示，静态类型检查器如`mypy`可以提供显著的价值。
- en: While static checks are great for catching basic code issues at compile time,
    unit, integration, and E2E tests can verify the system functionality at *runtime*
    when you execute application code. During runtime, tools like Pydantic can perform
    data validation checks to catch unexpected data structures.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然静态检查在编译时能够很好地捕捉基本的代码问题，但单元测试、集成测试和端到端测试可以在执行应用程序代码时的*运行时*验证系统功能。在运行时，像Pydantic这样的工具可以执行数据验证检查，以捕捉意外的数据结构。
- en: Your GenAI services may also require additional setup and build steps such as
    downloading weights and preloading models, before executing any application code.
    The environment in which build steps, setups, and dependency installations are
    completed is referred to as *build time*, which you can also test.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你的GenAI服务在执行任何应用程序代码之前可能还需要额外的设置和构建步骤，例如下载权重和预加载模型。完成构建步骤、设置和依赖项安装的环境被称为*构建时间*，你也可以对其进行测试。
- en: Testing Strategies
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试策略
- en: Within the software landscape, various experts have developed strategies for
    balancing the distribution of tests in projects, which are based on years of software
    testing experience from the developers that popularized them.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件领域，各种专家已经根据多年的软件测试经验开发了平衡项目测试分布的策略，这些策略是基于那些推广它们的开发者的经验。
- en: The most widely adopted strategy is the *testing pyramid*, as shown in [Figure 11-5](#testing_pyramid),
    which promotes writing more unit tests.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最广泛采用的策略是*测试金字塔*，如图[图11-5](#testing_pyramid)所示，它促进了编写更多的单元测试。
- en: '![bgai 1105](assets/bgai_1105.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1105](assets/bgai_1105.png)'
- en: Figure 11-5\. Testing pyramid
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-5\. 测试金字塔
- en: '[Table 11-1](#testing_pyramid_example) outlines the purpose of each layer in
    the testing pyramid alongside a concrete example in the context of a GenAI service.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-1](#testing_pyramid_example)概述了测试金字塔中每一层的目的，以及在一个GenAI服务上下文中的具体示例。'
- en: Table 11-1\. Testing pyramid in real world
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-1\. 真实世界中的测试金字塔
- en: '| Layer | Purpose | Example |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 层 | 目的 | 示例 |'
- en: '| --- | --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| End-to-end tests | Validate the entire application flow from start to finish
    | Testing user login, generating text based on a prompt, and saving the generated
    content |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 端到端测试 | 验证从开始到结束的整个应用程序流程 | 测试用户登录，根据提示生成文本，以及保存生成的内容 |'
- en: '| Integration tests | Verify various modules or services work together correctly
    | Testing the interactions between the text generation API and the database storing
    user prompts and generated texts |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 集成测试 | 验证各个模块或服务是否正确协同工作 | 测试文本生成API与存储用户提示和生成文本的数据库之间的交互 |'
- en: '| Unit tests | Verify individual components or functions in isolation | Testing
    various utility functions that process inputs to the model, for instance, to remove
    inappropriate content |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 单元测试 | 验证独立组件或函数 | 测试处理模型输入的各种实用函数，例如，移除不适当的内容 |'
- en: The issue with the pyramid model is that while unit tests improve code coverage,
    they do not necessarily enhance “business coverage” since project requirements
    and use cases might not be thoroughly tested. As a result, relying only on unit
    tests can create a false sense of security, potentially overlooking testing essential
    business logic and user workflows. On the other hand, integration tests allow
    you to cover more ground and business-driven tests.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 测试金字塔模型的问题在于，虽然单元测试可以提高代码覆盖率，但它们并不一定增强“业务覆盖率”，因为项目需求和用例可能没有得到彻底的测试。因此，仅依赖单元测试可能会产生虚假的安全感，可能会忽略测试关键的业务逻辑和用户工作流程。另一方面，集成测试允许你覆盖更广泛的范围和以业务为导向的测试。
- en: Warning
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Software testing experts have also identified a few strategies as *anti-patterns*
    that are counterproductive.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 软件测试专家还识别出一些作为*反模式*的策略，这些策略是反生产力的。
- en: If you follow them, you’ll spend an excessive amount of time setting up the
    tests, implement overly specific and tightly coupled tests, and end up with tests
    that exhibit nondeterministic flaky behavior.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遵循它们，你将花费过多的时间设置测试，实现过于具体且紧密耦合的测试，最终得到的测试可能表现出非确定性的不稳定行为。
- en: '[Table 11-2](#testing_antipatterns) and [Figure 11-6](#testing_antipatterns_viz)
    show a list of software testing anti-patterns.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-2](#testing_antipatterns)和[图11-6](#testing_antipatterns_viz)展示了一组软件测试反模式。'
- en: Table 11-2\. Software testing anti-patterns
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-2\. 软件测试反模式
- en: '| Strategy | Test distribution | Comments |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | 测试分布 | 备注 |'
- en: '| --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Testing ice-cream cone | Small number of unit tests with a large number of
    integration and E2E tests, followed by manual testing. | Avoid. Considered an
    anti-pattern due to inefficiency of implementing manual tests and high costs of
    maintaining integration and E2E tests. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 测试冰淇淋锥形 | 单元测试数量少，集成和端到端测试数量多，之后是手动测试。 | 应避免。被认为是一种反模式，因为手动测试的实施效率低下，维护集成和端到端测试的成本高昂。
    |'
- en: '| Testing cupcake | Similar to the ice-cream cone; has a small number of automated
    unit and integration tests, a moderate number of automated E2E/GUI tests, and
    a large number of manual tests.Each test type is performed by a different team.
    | Avoid. Considered an anti-pattern because it can lead to slow feedback cycles,
    communication overheads between teams, and brittle tests with high maintenance
    costs. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 测试纸杯蛋糕 | 与冰淇淋锥形相似；有少量自动化的单元和集成测试，中等数量的自动化的端到端/GUI测试，以及大量的手动测试。每种测试类型由不同的团队执行。
    | 应避免。被认为是一种反模式，因为它可能导致反馈周期缓慢，团队间的沟通开销，以及维护成本高昂的脆弱测试。 |'
- en: '| Testing hourglass | Large number of unit tests at the base and E2E tests
    at the top, but significantly fewer integration tests in the middle. | Avoid.
    Considered an anti-pattern. Not as bad as the ice-cream cone, but still results
    in too many test failures, that medium-scope tests could’ve covered. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 测试沙漏 | 底部有大量的单元测试，顶部有端到端测试，但中间的集成测试显著较少。 | 应避免。被认为是一种反模式。虽然不如冰淇淋锥形糟糕，但仍然会导致过多的测试失败，这些中等范围的测试本来可以覆盖。
    |'
- en: '![bgai 1106](assets/bgai_1106.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1106](assets/bgai_1106.png)'
- en: Figure 11-6\. Visualization of testing anti-patterns
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-6. 测试反模式的可视化
- en: '[Table 11-3](#testing_strategies) and [Figure 11-7](#testing_strategies_viz)
    compare software testing strategies.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-3](#testing_strategies) 和 [图11-7](#testing_strategies_viz) 比较了软件测试策略。'
- en: Table 11-3\. Comparison of testing strategies
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-3. 测试策略比较
- en: '| Strategy | Test distribution | Comments |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | 测试分布 | 评论 |'
- en: '| --- | --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Testing pyramid**(Mike Cohn) | Large number of unit tests at the base,
    fewer integration tests in the middle, and even fewer E2E tests at the top. |
    It’s a widely accepted strategy. However, the pyramid can be perceived as a physical
    concept to promote building the bottom layer of unit tests first, then constructing
    the next layer, and so on, until reaching the top. This approach is ineffective
    when applied to legacy applications with a large codebase. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **测试金字塔**(Mike Cohn) | 底部有大量的单元测试，中间较少的集成测试，顶部更少的端到端测试。 | 这是一个被广泛接受的策略。然而，金字塔可以被看作是一个物理概念，用来促进首先构建单元测试的底层，然后构建下一层，以此类推，直到达到顶部。当应用于拥有大量代码库的遗留应用程序时，这种方法可能无效。
    |'
- en: '| **Testing trophy**(Kent C. Dodds) | Focuses on having a strong foundation
    of static checks, then unit tests, followed by integration tests, and a smaller
    number of E2E tests at the top. | The rationale for this is that E2E and integration
    tests are the most valuable. However, E2E tests are slow and expensive. Integration
    tests strike a balance between both worlds. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **测试奖杯**(Kent C. Dodds) | 侧重于拥有强大的静态检查基础，然后是单元测试，接着是集成测试，顶部有较少的端到端测试。 | 这种策略的依据是端到端和集成测试最有价值。然而，端到端测试速度慢且成本高。集成测试在两者之间取得平衡。
    |'
- en: '| **Testing honeycomb**(Stephen H. Fishman) | Represents a balanced approach
    with equal emphasis on unit, integration, E2E, and other types of tests (performance,
    security, etc.). | It can be less efficient if not managed properly and may not
    be optimal for every project. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **测试蜂巢**(Stephen H. Fishman) | 代表了一种平衡的方法，对单元、集成、端到端和其他类型的测试（性能、安全等）给予同等重视。
    | 如果管理不当，可能会效率较低，并且可能不是每个项目的最佳选择。 |'
- en: '![bgai 1107](assets/bgai_1107.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1107](assets/bgai_1107.png)'
- en: Figure 11-7\. Visualization of testing strategies
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-7. 测试策略的可视化
- en: For GenAI services, which often involve complex integrations and performance
    considerations, the trophy testing strategy might be the most suitable. The trophy
    strategy consists of a strong foundation of static checks, powered by tools such
    as `mypy` and Pydantic, alongside mostly integration tests that strike a balance
    between value, confidence, and testing costs.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及复杂集成和性能考虑的GenAI服务，奖杯测试策略可能是最合适的。奖杯策略包括强大的静态检查基础，由`mypy`和Pydantic等工具提供支持，以及主要是集成测试，这些测试在价值、信心和测试成本之间取得平衡。
- en: If your GenAI services must be comprehensively tested with various test types,
    including performance and exploratory tests, then the honeycomb model may be more
    suitable for your project since it can equalize testing efforts.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的GenAI服务必须使用包括性能和探索性测试在内的各种测试类型进行全面测试，那么蜂巢模型可能更适合你的项目，因为它可以平衡测试工作量。
- en: You should now feel more comfortable in identifying what tests you need and
    how to plan your tests.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该更自在地识别你需要哪些测试以及如何规划你的测试。
- en: Now that you’re familiar with software testing concepts, let’s review the challenges
    and potential approaches to testing GenAI services.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经熟悉了软件测试的概念，让我们回顾一下测试GenAI服务的挑战和潜在方法。
- en: Challenges of Testing GenAI Services
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试GenAI服务的挑战
- en: If you’ve decided to test your GenAI services, you will face several challenges.
    Testing services that leverage probabilistic GenAI models require a more comprehensive
    approach than traditional software.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经决定测试你的GenAI服务，你将面临几个挑战。利用概率GenAI模型的服务的测试需要比传统软件更全面的方法。
- en: Let’s take a look at a few reasons why testing GenAI services will be challenging.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看为什么测试GenAI服务将具有挑战性的几个原因。
- en: Variability of Outputs (Flakiness)
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出可变性（不可靠性）
- en: Given the same set of inputs and implementation code, GenAI services often produce
    different outputs. The outputs are varied because these models use probabilistic
    techniques such as sampling from a distribution rather than relying on deterministic
    functions. Of course, the variability you experience on outputs can be model dependent,
    and adjusting configurations, such as temperature values, can reduce this variance.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同的输入集和实现代码下，GenAI服务通常会产生不同的输出。这些输出之所以多样化，是因为这些模型使用概率技术，如从分布中进行采样，而不是依赖于确定性函数。当然，你在输出上体验到的可变性可能取决于模型，调整配置，如温度值，可以减少这种可变性。
- en: The variability of outputs from GenAI models can also explode the number of
    potential test cases you can write (i.e., the *testing area/scope*) to cover every
    possibility. Because of this, you can’t fully rely on deterministic tests. Your
    tests will perform inconsistently and will be too *flaky* to run reliably within
    a CI/CD pipeline.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI模型的输出可变性也可能导致你可以编写的潜在测试用例数量激增（即，*测试区域/范围*），以覆盖所有可能性。正因为如此，你不能完全依赖确定性测试。你的测试将表现不一致，并且会在CI/CD管道中运行时过于*不可靠*。
- en: Instead, you should approach the GenAI testing problem from a statistical and
    probabilistic perspective. Take several samples based on valid assumptions from
    a *legitimate distribution of inputs* to verify the quality of your model’s product
    outputs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你应该从统计和概率的角度来处理GenAI测试问题。根据从*合法输入分布*的有效假设中抽取的几个样本来验证你模型产品输出的质量。
- en: Note
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: By *legitimate distribution of inputs*, I mean selecting inputs that are aligned
    with the model’s purpose, representative of real-world scenarios, and relevant
    to the problem you’re trying to solve with the model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我所说的*合法输入分布*是指选择与模型目的相符、代表现实场景并与你试图用模型解决的问题相关的输入。
- en: A more involved approach is to use discriminator models to score your service’s
    variable outputs as long as you set expectations of a certain tolerance or threshold.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的方法是使用判别模型来评估你的服务变量输出的分数，只要你设定了某种容忍度或阈值。
- en: You’ll see examples of how to do this later in the chapter.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本章后面看到如何做到这一点的示例。
- en: Performance and Resource Constraints (Slow and Expensive)
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能和资源限制（慢且昂贵）
- en: Since testing GenAI services requires a more statistical and/or multimodel approach,
    you will also face latency, usage, and hosting problems.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 由于测试GenAI服务需要更统计和/或多模型的方法，你还将面临延迟、使用和托管问题。
- en: Your tests can’t run fast enough and reliably to run continually within a traditional
    CI/CD pipeline. You will end up with excessive token usage costs with multiple
    model API calls and slow-running and complex multimodel tests. These challenges
    remain unless you make several assumptions to simplify the testing scope, reduce
    model testing frequency, and use efficient testing techniques such as mocking
    and patching, dependency injection, and statistical hypothesis tests. You can
    also investigate the use of small fine-tuned discriminator models to reduce latency
    and improve performance.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你的测试无法足够快且可靠地持续在传统的 CI/CD 管道中运行。你最终会因多次模型 API 调用和运行缓慢且复杂的多模型测试而产生过度的令牌使用成本。除非你做出几个假设来简化测试范围、减少模型测试频率，并使用高效的测试技术，如模拟和修补、依赖注入和统计假设检验，否则这些挑战将依然存在。你也可以调查使用小型微调判别器模型以减少延迟并提高性能的用途。
- en: Regression
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归
- en: '*Regression testing* is another type of test to plan for when working with
    GenAI models.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归测试* 是在处理 GenAI 模型时计划的一种另一种测试类型。'
- en: 'A [research paper published in 2023](https://oreil.ly/1oLQG) that compared
    ChatGPT’s behavior over time found that:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇于 2023 年发表的 [研究论文](https://oreil.ly/1oLQG) 比较了 ChatGPT 随时间的行为，发现：
- en: The performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over
    time. For example, GPT-4 (March 2023) was reasonable at identifying prime vs.
    composite numbers (84% accuracy), but GPT-4 (June 2023) was poor on these same
    questions (51% accuracy). GPT-4 became less willing to answer sensitive questions
    and opinion survey questions in June than in March. In addition, both GPT-4 and
    GPT-3.5 had more formatting mistakes in code generation in June than in March.
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-3.5 和 GPT-4 的性能和行为会随时间有很大的变化。例如，GPT-4（2023 年 3 月）在识别质数与合数方面表现合理（84% 准确率），但
    GPT-4（2023 年 6 月）在这些相同的问题上表现较差（51% 准确率）。与 3 月相比，GPT-4 在 6 月更不愿意回答敏感问题和意见调查问题。此外，GPT-4
    和 GPT-3.5 在 6 月的代码生成中比 3 月有更多的格式错误。
- en: According to this study, the behavior of the “same” LLM service can change substantially
    in a relatively short amount of time, highlighting the need for continuous monitoring
    of LLMs (and any GenAI services). Based on this finding, you can assume the performance
    of your GenAI services may degrade over time due to model fine-tuning or retraining,
    shifts in user interaction patterns, and the changes in its training data or operating
    environment.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这项研究，即使是“相同”的 LLM 服务，其行为也可能在相对较短的时间内发生显著变化，这突出了对 LLM（以及任何 GenAI 服务）进行持续监控的必要性。基于这一发现，你可以假设你的
    GenAI 服务的性能可能会随着时间的推移而下降，这可能是由于模型微调或重新训练、用户交互模式的转变以及其训练数据或运行环境的变化。
- en: To elaborate further, probabilistic AI models can experience *model drift*,
    a performance degradation over time attributable to their underlying training
    data. Fine-tuning on additional data can have unexpected side effects on model’s
    behavior in other tasks.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步来说，概率 AI 模型可能会经历 *模型漂移*，这是一种随着时间的推移导致的性能下降，归因于其底层训练数据。在额外数据上微调可能会对模型在其他任务中的行为产生意外的副作用。
- en: As time passes, the original training data can drift away from reality. Trends
    change, new historical events happen, languages evolve, and human knowledge expands
    or mutates to take new forms that won’t be captured if the training data is not
    continually updated. This phenomenon that causes model drift is referred to as
    *concept drift*, which occurs when the statistical properties of the target variable
    that the model is trying to predict change over time. Concept drift can lead to
    a model’s performance degrading because the relationships and patterns the model
    learned during training no longer apply.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，原始训练数据可能会与现实脱节。趋势会变化，新的历史事件会发生，语言会演变，人类知识会扩展或变异成新的形式，如果训练数据不持续更新，这些新形式将不会被捕捉到。这种导致模型漂移的现象被称为
    *概念漂移*，它发生在模型试图预测的目标变量的统计属性随时间变化时。概念漂移可能导致模型性能下降，因为模型在训练期间学习到的关系和模式不再适用。
- en: Furthermore, *data drift*, which involves changes in the distribution of the
    input features within the training data, can also lead to model drift.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，涉及训练数据中输入特征分布变化的 *数据漂移* 也可能导致模型漂移。
- en: This type of drift is often due to changes in the sampling methods, population
    distribution and data collection, seasonality changes and temporal effects in
    the data, external changes in data sources, or quality issues in the processing
    pipelines.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移通常是由于采样方法、人口分布和数据收集的变化、数据中的季节性变化和时间效应、数据源的外部变化或处理管道中的质量问题所引起的。
- en: Regression testing and monitoring (in particular if you rely on external model
    providers such as OpenAI) can help you detect model drift issues on your specific
    tasks and use cases. Any potential drifts can then be addressed at the application
    layer via data validation or by using techniques such as RAG or at the model layer
    via retraining and model fine-tuning to reduce regression issues.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 回归测试和监控（特别是如果你依赖于外部模型提供商，如OpenAI）可以帮助你检测特定任务和用例中的模型漂移问题。任何潜在的漂移都可以通过数据验证或使用RAG等技术，在应用层解决，或者通过重新训练和模型微调，在模型层解决，以减少回归问题。
- en: Bias
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差
- en: Another grand challenge in testing GenAI services is detecting model bias before
    going to production. Often, bias is investigated during the data exploration process
    by data scientists and ML engineers responsible for producing the models. However,
    with large foundation GenAI models, there’s always a possibility that some form
    of bias may be introduced through incorrect evaluation, sampling methods, data
    processing, training algorithms, or hidden bias in the data itself.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试GenAI服务时，另一个重大挑战是在投入生产之前检测模型偏差。通常，数据科学家和负责生成模型的ML工程师在数据探索过程中调查偏差。然而，对于大型基础GenAI模型，总有可能通过错误的评估、采样方法、数据处理、训练算法或数据本身的隐藏偏差引入某种形式的偏差。
- en: For example, if a language model is trained on a dataset that mostly contains
    text related to a specific demographic, it may generate outputs biased toward
    that demographic, potentially excluding other groups. Similarly, if an image recognition
    model is trained mostly on images of men in professions like doctors and engineers,
    it may learn to generate images with a gender bias.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一个语言模型是在主要包含与特定人口统计数据相关的文本的数据集上训练的，它可能会生成偏向该人口统计数据的输出，从而可能排除其他群体。同样，如果一个图像识别模型主要是在医生和工程师等职业的男性图像上训练的，它可能会学会生成具有性别偏差的图像。
- en: The bias becomes particularly serious in scenarios where you want to use LLMs
    as a judge, such as AI marking tools or interview assessors.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在你希望使用LLM作为裁判的场景中，这种偏差变得尤为严重，例如AI评分工具或面试评估者。
- en: Bias can manifest in various forms such as gender bias, racial bias, age bias,
    etc., and each type requires specific tests and metrics to detect. Without knowing
    what to test for, you can’t confidently verify if your GenAI services are 100%
    bias-free.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差可以以各种形式表现出来，如性别偏差、种族偏差、年龄偏差等，每种类型都需要特定的测试和指标来检测。如果没有知道要测试什么，你就无法自信地验证你的GenAI服务是否100%无偏差。
- en: A possible solution to this problem is leveraging model self-checks and AI discriminators
    where a secondary model identifies or measures the presence of any bias. There
    is often a trade-off between latency and usage quotas when detecting bias during
    service runtime.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的可能方案是利用模型自我检查和AI判别器，其中次要模型识别或测量任何偏差的存在。在服务运行时检测偏差时，通常需要在延迟和配额使用之间做出权衡。
- en: Adversarial Attacks
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性攻击
- en: Public-facing GenAI services can be vulnerable to adversarial attacks such as
    token manipulation, insecure data handling, jailbreak prompting or prompt injection,
    sensitive information disclosure, data poisoning, model theft, denial of service,
    excessive agency, and general misuse and abuse. Therefore, any GenAI services
    exposed to the internet will need to include safeguarding layers.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 公开的GenAI服务可能容易受到对抗性攻击，如令牌操纵、不安全的数据处理、越狱提示或提示注入、敏感信息泄露、数据中毒、模型盗窃、拒绝服务、过度代理以及一般滥用和误用。因此，任何暴露于互联网的GenAI服务都需要包括安全层。
- en: Resources and checklists such as [OWASP’s top 10 for LLM application](https://genai.owasp.org)
    provide a starting point for adding safeguards to your GenAI services.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 资源和清单，如[OWASP的LLM应用前10名](https://genai.owasp.org)，为向你的GenAI服务添加安全措施提供了一个起点。
- en: However, building safeguarding mechanisms can be challenging because current
    methods, at the time of writing, rely on classification and discriminatory models
    to detect adversarial attacks and harmful content. These safeguarding models often
    require hundreds of megabytes of dependencies, which can bloat your application,
    significantly slow down your service’s throughput, and still may not catch every
    potential attack scenario.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，构建安全机制可能具有挑战性，因为截至写作时，当前的方法依赖于分类和歧视模型来检测对抗性攻击和有害内容。这些安全模型通常需要数百兆字节的依赖项，这可能会膨胀你的应用程序，显著降低你的服务吞吐量，并且仍然可能无法捕捉到每个潜在的攻击场景。
- en: Adversarial tests ensure you have enough safeguarding in place to protect your
    services and reputation. As part of adversarial tests, you should also verify
    the performance of your authentication and authorization guards.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性测试确保你已实施足够的防护措施来保护你的服务和声誉。作为对抗性测试的一部分，你还应验证你的身份验证和授权保护器的性能。
- en: '[Chapter 9](ch09.html#ch09) goes into more detail on implementing these safeguarding
    layers and evaluation techniques to protect your models against such attacks.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.html#ch09)更详细地介绍了实施这些防护层和评估技术以保护你的模型免受此类攻击的方法。'
- en: Unbound Testing Coverage
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未绑定测试覆盖率
- en: The latent space of GenAI models is so vast that you can’t rely on unit tests
    to achieve 100% coverage of every usage scenario.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI模型的潜在空间非常庞大，以至于你不能依赖于单元测试来实现每个使用场景的100%覆盖率。
- en: Since there are an infinite number of inputs and responses, no matter how much
    you test your models, there will be hidden edge cases that slip through your tests.
    Therefore, instead of relying on predefining every scenario, you can implement
    *behavioral testing*, which focuses on properties of responses instead of the
    exact outputs.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在无限数量的输入和响应，无论你测试你的模型多少次，总会存在一些隐藏的边缘情况会从你的测试中漏出。因此，而不是依赖于预先定义每个场景，你可以实施*行为测试*，它关注的是响应的性质而不是确切的输出。
- en: Examples of behavioral properties you can measure include *coherence* of generated
    data structures, *relevance* of outputs to inputs, *toxicity*, *correctness*,
    and *faithfulness* (i.e., faithful adherence to your policies and ethical guidelines).
    You can also add a human in the loop as an additional testing layer for catching
    unexpected responses.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以衡量的行为属性示例包括生成数据结构的*一致性*、输出与输入的*相关性*、*毒性*、*正确性*和*忠实性*（即忠实遵守你的政策和道德指南）。你还可以添加一个人类作为额外的测试层，以捕捉意外的响应。
- en: Warning
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: If you’re building a RAG or agentic application with multiple models and external
    dependencies, behavioral testing becomes even more practical. Testing a fixed
    set of examples may miss edge cases, unexpected interactions between components,
    and variability in responses due to external factors.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在构建一个具有多个模型和外部依赖关系的RAG或代理应用程序，行为测试变得更加实用。测试一组固定的示例可能会错过边缘情况、组件之间的意外交互以及由于外部因素引起的响应变化。
- en: In the next section, you’ll learn how to implement your own unit, integration,
    E2E, and behavioral tests by following a hands-on project.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何通过跟随一个动手项目来实施你自己的单元、集成、端到端和行为的测试。
- en: 'Project: Implementing Tests for a RAG System'
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目：实现RAG系统的测试
- en: In the hands-on project, you will be writing a test suite for the RAG module
    that you implemented in [Chapter 5](ch05.html#ch05). The RAG system you will be
    testing has interfaces with an LLM, a vector database, and the server’s filesystem
    via asynchronous methods, so it provides a perfect opportunity to understand the
    testing principles discussed so far.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在动手项目中，你将为[第5章](ch05.html#ch05)中实现的RAG模块编写测试套件。你将要测试的RAG系统与LLM、向量数据库和服务器文件系统通过异步方法接口，因此它提供了一个理解迄今为止讨论的测试原则的绝佳机会。
- en: By following along with the code examples, you’ll learn the best practices for
    implementing unit, integration, and E2E tests for your GenAI services, as well
    as their differences.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过跟随代码示例，你将学习为你的GenAI服务实施单元、集成和端到端测试的最佳实践，以及它们之间的区别。
- en: Unit Tests
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单元测试
- en: You can start testing your GenAI services with unit tests. The purpose of a
    unit test is to verify that an isolated part of your code, usually a single function
    or method, performs as intended.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用单元测试开始测试你的GenAI服务。单元测试的目的是验证你的代码的独立部分，通常是一个单独的函数或方法，是否按预期执行。
- en: Prior to writing tests, it’s important to plan the test cases you will be implementing.
    For a typical RAG system, you can write unit tests on the data loading, transformation,
    retrieval, and generation pipelines.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写测试之前，规划你将要实施的测试用例非常重要。对于一个典型的RAG系统，你可以在数据加载、转换、检索和生成管道上编写单元测试。
- en: '[Figure 11-8](#unit_boundaries) visualizes the testing boundaries of these
    potential unit tests on a data pipeline diagram.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-8](#unit_boundaries)在数据管道图中可视化了这些潜在单元测试的测试边界。'
- en: '![bgai 1108](assets/bgai_1108.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1108](assets/bgai_1108.png)'
- en: Figure 11-8\. Unit test boundaries visualized on the RAG data pipeline diagram
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-8\. 在RAG数据管道图中可视化的单元测试边界
- en: Notice how the testing boundaries end at the start and end of each data processing
    pipeline function. This is because the purpose of these unit tests is to test
    only the data processing pipeline code and not the database, filesystem, LLM model,
    or any associated interfaces.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注意测试边界在每个数据处理管道函数的开始和结束处结束。这是因为这些单元测试的目的仅是测试数据处理管道代码，而不是数据库、文件系统、LLM模型或任何相关接口。
- en: In these unit tests, you’ll be assuming that these external systems will return
    what you expect and focus your unit tests only on what your data processing code
    will be doing.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些单元测试中，您将假设这些外部系统会返回您期望的结果，并将单元测试的重点仅放在数据处理代码上。
- en: For brevity, we won’t be testing every component of the system, but by following
    a handful of upcoming examples, you should feel comfortable implementing follow-on
    tests to achieve full coverage.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们不会测试系统的每个组件，但通过遵循即将出现的几个示例，您应该能够轻松实现后续测试以实现全面覆盖。
- en: Installing and configuring pytest
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装和配置pytest
- en: For this project, you’ll be using the `pytest` package, which has built-in components
    for handling test fixtures, parameters, async code, test collections, and a rich
    ecosystem of plug-ins. `pytest` is more powerful, flexible, and extensible compared
    to `unittest`, Python’s built-in testing package often used for simple testing
    scenarios.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，您将使用`pytest`包，它具有处理测试固定值、参数、异步代码、测试收集和丰富插件生态系统的内置组件。与Python内置的用于简单测试场景的`unittest`包相比，`pytest`更强大、更灵活且可扩展。
- en: 'You can install `pytest` using the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令安装`pytest`：
- en: '[PRE0]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, create a `tests` directory at the root of your project where you can create
    Python modules following the *test_xxx.py* pattern.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在项目的根目录下创建一个`tests`目录，您可以在其中创建遵循*test_xxx.py*模式的Python模块。
- en: '`pytest`’s test collector can then traverse your `tests` directory and find
    every test module, class, and function contained within:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest`的测试收集器可以遍历您的`tests`目录，找到其中的每个测试模块、类和函数：'
- en: '[PRE1]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Inside each test file, you can add your test functions that always contain
    at least one `assert` statement. If no exception is raised in these `assert` statements,
    then your tests will get `PASSED`. Otherwise, `pytest` will mark them as `FAILED`
    alongside a reason/trace of why `assert` statements have failed:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个测试文件中，您可以添加包含至少一个`assert`语句的测试函数。如果这些`assert`语句中没有抛出异常，则您的测试将获得`PASSED`。否则，`pytest`将标记它们为`FAILED`，并显示为什么`assert`语句失败的原因/跟踪：
- en: '[PRE2]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s assume you’ve written two test functions in each test module:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您在每个测试模块中编写了两个测试函数：
- en: You can then execute your tests via the `pytest <test_dirt_path>` command.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过`pytest <test_dir_path>`命令执行您的测试。
- en: '[PRE3]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Warning
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Avoid writing large tests, as they become increasingly difficult to understand
    and implement correctly.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 避免编写大型测试，因为它们变得越来越难以理解和正确实现。
- en: When writing unit tests, you care only about an isolated component of your system
    such as a single function in your code. Other components fall outside the boundary
    of unit test. Thus, you’ll be testing only whether a single component behaves
    as you expect given a set of test data as inputs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 编写单元测试时，您只关心系统的一个独立组件，例如代码中的一个单独函数。其他组件超出了单元测试的边界。因此，您将测试的是，在给定的测试数据输入下，单个组件是否按预期行为。
- en: As an example, you can test whether your chunking function is splitting a document
    into chunks as you’d expect. Maybe you want to experiment with different or complex
    chunking strategies for your RAG pipeline and want to make sure that any input
    text is chunked correctly. Unit tests with predefined test data or *fixtures*
    can give you some confidence in your chunking function.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以测试您的分块函数是否按预期将文档分割成块。也许您想为您的RAG管道尝试不同的或复杂的分块策略，并确保任何输入文本都能正确分块。使用预定义测试数据或*固定值*的单元测试可以增强您对分块函数的信心。
- en: '[Example 11-1](#unit_test) demonstrates an example unit test for your chunking
    function.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例11-1](#unit_test)演示了您的分块函数的一个示例单元测试。'
- en: Example 11-1\. Example unit test for a token chunking function
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例11-1. 分块函数的示例单元测试
- en: '[PRE4]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO1-1)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO1-1)'
- en: Chunk an integer token list into smaller lists of a specified `chunk_size`.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 将整数标记列表分块成指定大小的更小列表。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO1-2)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO1-2)'
- en: Specify the test data in the *GIVEN (preconditions)* part of the test.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试的*给定（先决条件）*部分指定测试数据。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO1-3)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_testing_ai_services_CO1-3)'
- en: Run the test steps in the *WHEN* part of the test that include passing the test
    data to the system under test.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试的*WHEN*部分运行测试步骤，包括将测试数据传递给被测试的系统。
- en: '[![4](assets/4.png)](#co_testing_ai_services_CO1-4)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_testing_ai_services_CO1-4)'
- en: Check the results against the expected outputs in the *THEN* part of the test.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试的*THEN*部分检查结果与预期输出是否一致。
- en: Fixtures and scope
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 固定装置和作用域
- en: 'The input data you defined in [Example 11-1](#unit_test) for testing is also
    called a *fixture*, as its value remains fixed across each test run. There are
    two types of fixtures:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 您在[示例11-1](#unit_test)中为测试定义的输入数据也称为**固定装置**，因为其值在每次测试运行中保持不变。固定装置有两种类型：
- en: Fresh fixture
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 新固定装置
- en: You define it inside each test, which then Python garbage collects (i.e., discards)
    after the test. [Example 11-1](#unit_test) used a fresh fixture.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在每个测试内部定义它，然后Python在测试结束后进行垃圾回收（即丢弃）。[示例11-1](#unit_test)使用了一个新的固定装置。
- en: Shared fixture
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 共享固定装置
- en: You can reuse it across multiple tests to avoid repeating the same fixture over
    and over for each new test.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在多个测试中重用它，以避免为每个新测试重复相同的固定装置。
- en: You can declare a shared fixture outside the test functions as a global variable
    of the test module, but it’s considered an anti-pattern, as you can inadvertently
    modify them.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将共享固定装置作为测试模块的全局变量声明在测试函数外部，但这被认为是一种反模式，因为您可能会意外地修改它们。
- en: Warning
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Shared fixtures must be *immutable*. Otherwise, a test can change the fixture,
    creating a side effect rippling through other tests. A major cause of flaky tests
    is mutable fixtures.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 共享固定装置必须是**不可变的**。否则，测试可能会更改固定装置，从而在其它测试中产生副作用。可变固定装置是导致测试不稳定的主要原因。
- en: Instead of being responsible for managing the state of shared fixtures yourself,
    you can rely on `pytest`’s dependency injection system through the use of *fixture
    functions*, as shown in [Example 11-2](#fixture_function).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 您不必自己负责管理共享固定装置的状态，您可以通过使用*固定装置函数*依赖注入系统，如[示例11-2](#fixture_function)所示。
- en: Example 11-2\. `pytest` fixture function
  id: totrans-240
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例11-2. `pytest`固定装置函数
- en: '[PRE5]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO2-1)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO2-1)'
- en: Declare the `input_text` function as a `pytest` fixture that can be shared across
    the module as specified by `scope="module"`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 将`input_text`函数声明为`pytest`固定装置，它可以按照`scope="module"`在模块间共享。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO2-2)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO2-2)'
- en: Use the `pytest` dependency injection to inject a shared fixture into different
    tests.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pytest`依赖注入将共享固定装置注入到不同的测试中。
- en: You can declare a function as a `pytest` fixture using the `@pytest.fixture(scope)`
    decorator. The `scope` parameter specifies the lifespan of the shared fixture
    within a testing session.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`@pytest.fixture(scope)`装饰器将函数声明为`pytest`固定装置。`scope`参数指定了共享固定装置在测试会话中的生命周期。
- en: Based on the `scope`’s value, `pytest` creates and destroys fixtures once per
    test function, `class`, `module`, `package`, or the entire testing `session`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 根据`scope`的值，`pytest`在每个测试函数、`class`、`module`、`package`或整个测试`session`中创建和销毁固定装置一次。
- en: Tip
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: A scenario where you might need a shared fixture to persist across modules or
    the entire testing session is when you fetch the fixture from an external API
    and want to avoid making requests repeatedly.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从外部API获取固定装置并希望避免重复请求时，您可能需要一个共享固定装置在模块或整个测试会话中持续存在的情况。
- en: Using fixtures, you can implement several tests with various inputs covering
    valid, invalid, and boundary values to verify the robustness of each component.
    However, you’ll need to separate test functions for each set of inputs and expected
    outputs. To avoid rewriting the same test, `pytest` has a *parameterization* feature
    that you can leverage.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 使用固定装置，您可以实现具有各种输入的多个测试，包括有效、无效和边界值，以验证每个组件的健壮性。然而，您需要为每组输入和预期输出分别编写测试函数。为了避免重写相同的测试，`pytest`有一个*参数化*功能，您可以利用它。
- en: Parameterization
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数化
- en: With `pytest` parameterization, you can iterate over various test data and expected
    outputs to avoid duplicating tests, as you can see in [Example 11-3](#pytest_params).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pytest`参数化，您可以遍历各种测试数据和预期输出，以避免重复测试，正如您可以在[示例11-3](#pytest_params)中看到的那样。
- en: Example 11-3\. `pytest` parameterization
  id: totrans-253
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例11-3. `pytest`参数化
- en: '[PRE6]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO3-1)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO3-1)'
- en: Use the `@pytest.mark.parametrize` decorator function to specify multiple test
    arguments and expected outputs. The test arguments cover valid, empty, invalid,
    boundary ranges, and large values to verify the robustness of the token chunking
    function.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `@pytest.mark.parametrize` 装饰器函数来指定多个测试参数和预期输出。测试参数包括有效、空、无效、边界范围和大值，以验证标记分块函数的健壮性。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO3-2)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[(#co_testing_ai_services_CO3-2)]'
- en: Inject the test parameters into the test function, and if the expected output
    is a `ValueError`, use `pytest.raises` to verify that a `ValueError` exception
    has been raise. Otherwise, run the assertion check instead.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试参数注入测试函数中，如果预期输出是 `ValueError`，则使用 `pytest.raises` 验证是否已引发 `ValueError` 异常。否则，运行断言检查。
- en: You can also store the test data inside JSON files and load them as fixtures
    to inject into parameterized test functions, as shown in [Example 11-4](#pytest_params_json).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将测试数据存储在 JSON 文件中，并将它们作为夹具加载到参数化测试函数中，如示例 11-4 所示。
- en: Example 11-4\. JSON fixtures in parameterized `pytest` tests
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-4\. 参数化 `pytest` 测试中的 JSON 夹具
- en: '[PRE7]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO4-1)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[(#co_testing_ai_services_CO4-1)]'
- en: The JSON file contains a list of test cases as dictionaries.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 文件包含一个测试用例列表，作为字典。
- en: As you can see, fixtures and the parameterization technique are extremely powerful
    tools to help you verify the robustness of each function in your code.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，夹具和参数化技术是极其强大的工具，可以帮助你验证代码中每个函数的健壮性。
- en: When writing tests, you’ll probably want to specify setup code, configurations,
    and global fixtures to be shared across test files. Luckily, you can achieve this
    in the `pytest`’s global configuration file called *conftest.py*.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写测试时，你可能希望指定设置代码、配置和要在测试文件之间共享的全局夹具。幸运的是，你可以在 `pytest` 的全局配置文件 *conftest.py*
    中实现这一点。
- en: Conftest module
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Conftest 模块
- en: If you want your entire test modules to have access to fixtures and global configurations,
    you can add a *conftest.py* module to your `tests` directory. Any fixtures, setup
    code, and configurations defined in the conftest module will be shared with other
    test modules. See [Example 11-5](#conftest_fixture).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望整个测试模块都能访问夹具和全局配置，你可以在 `tests` 目录中添加一个 *conftest.py* 模块。在 conftest 模块中定义的任何夹具、设置代码和配置都将与其他测试模块共享。参见
    [示例 11-5](#conftest_fixture)。
- en: Example 11-5\. Add a shared fixture across every module
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-5\. 在每个模块中添加一个共享的测试夹具
- en: '[PRE8]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO5-1)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[(#co_testing_ai_services_CO5-1)]'
- en: Define a shared fixture in *conftest.py* to be used across every test module.
    Otherwise, the fixture would be scoped only to a single module.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *conftest.py* 中定义一个共享夹具，以便在所有测试模块中使用。否则，夹具的作用域将仅限于单个模块。
- en: You’ve now learned about writing basic tests using the `pytest` framework following
    the GWT model. Next, let’s look at how to perform setup and cleanup operations
    before and after tests.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经了解了按照 GWT 模型使用 `pytest` 框架编写基本测试的方法。接下来，让我们看看如何在测试前后执行设置和清理操作。
- en: Setup and teardown
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置和拆卸
- en: When implementing tests, you may also need to configure a testing environment
    beforehand and perform teardown or cleanup operations afterward. You can use the
    `yield` keyword in shared fixtures to implement setup and teardown operations
    that must consistently happen for each test.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现测试时，你可能还需要事先配置测试环境，并在之后执行拆卸或清理操作。你可以在共享夹具中使用 `yield` 关键字来实现每个测试必须一致发生的设置和拆卸操作。
- en: For instance, you may need to use this feature when setting up and cleaning
    up a database session, as demonstrated in [Example 11-6](#setup_teardown).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能需要在设置和清理数据库会话时使用此功能，如示例 11-6 所示。
- en: Example 11-6\. Set up and tear down a database session in a shared fixture
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-6\. 在共享夹具中设置和拆卸数据库会话
- en: '[PRE9]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO6-1)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[(#co_testing_ai_services_CO6-1)]'
- en: Create a global shared fixture in *conftest.py* that is created and destroyed
    once per test function.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *conftest.py* 中创建一个全局共享夹具，该夹具在每个测试函数中创建和销毁一次。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO6-2)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[(#co_testing_ai_services_CO6-2)]'
- en: Instantiate the `qdrant` database client and then create and configure a test
    collection with an upserted data point as part of the test setup phase.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化 `qdrant` 数据库客户端，然后在测试设置阶段创建和配置一个包含更新数据的测试集合。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO6-5)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[(#co_testing_ai_services_CO6-5)]'
- en: Yield the database client to the test function as part of the main testing phase.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据库客户端作为主要测试阶段的一部分传递给测试函数。
- en: '[![4](assets/4.png)](#co_testing_ai_services_CO6-6)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_testing_ai_services_CO6-6)'
- en: Clean up after each test by closing the client connection to the database. The
    teardown code after the `yield` keyword is executed once the yield operation completes.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次测试后清理，通过关闭到数据库的客户端连接。在`yield`关键字执行完成后，执行`yield`关键字后的拆卸代码。
- en: '[![5](assets/5.png)](#co_testing_ai_services_CO6-7)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_testing_ai_services_CO6-7)'
- en: Inject the preconfigured database client to each test function after the test
    setup is complete. Query the database for the document inserted and assert that
    a data point has been fetched. Once the assertion step is complete, run the teardown
    process as part of the `db_client` fixture function.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试设置完成后，将预配置的数据库客户端注入到每个测试函数中。查询数据库以获取插入的文档，并断言已获取到数据点。一旦断言步骤完成，作为`db_client`固定函数的一部分运行拆卸过程。
- en: Following the example in [Example 11-6](#setup_teardown), you can also create
    fixtures with setup and teardown steps for your API test client or any other external
    services.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 按照示例11-6中的示例[Example 11-6](#setup_teardown)，您也可以为API测试客户端或任何其他外部服务创建具有设置和拆卸步骤的固定函数。
- en: Also, you may have noticed that [Example 11-6](#setup_teardown) used a synchronous
    client instead of an asynchronous one. This is because handling asynchronous tests
    can be tricky, flaky, and error-prone and because it requires installation of
    additional `pytest` plug-ins for handling test event loops.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可能已经注意到[Example 11-6](#setup_teardown)使用了同步客户端而不是异步客户端。这是因为处理异步测试可能很棘手、不可靠且容易出错，并且因为它需要安装额外的`pytest`插件来处理测试事件循环。
- en: To avoid flaky unit tests, you should use mocks to isolate functional components
    from external services. We do this because the scope and testing boundary of unit
    tests don’t include external dependencies and interfaces. Instead, testing external
    dependencies and interfaces such as database interactions will fall within the
    remit of integration tests.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免不可靠的单元测试，您应该使用模拟来隔离功能组件与外部服务。我们这样做是因为单元测试的范围和测试边界不包括外部依赖和接口。相反，测试外部依赖和接口，如数据库交互，将属于集成测试的范围。
- en: You’ll learn about handling asynchronous tests and mocking/patching techniques
    next.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 您将学习如何处理异步测试以及模拟/修补技术。
- en: Handling asynchronous tests
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理异步测试
- en: 'To execute async tests, you can use plug-ins such as `pytest-asyncio` to integrate
    `pytest` with Python’s `asyncio`:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行异步测试，可以使用`pytest-asyncio`等插件将`pytest`与Python的`asyncio`集成：
- en: '[PRE10]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once you install the plug-in, you can follow [Example 11-7](#async_tests) to
    write and execute an async test.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了插件，您就可以按照[Example 11-7](#async_tests)编写和执行异步测试。
- en: Example 11-7\. Writing asynchronous tests
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例11-7. 编写异步测试
- en: '[PRE11]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO7-1)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO7-1)'
- en: Explicitly mark the async test with an `asyncio` decorator to run the test within
    an event loop.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`asyncio`装饰器显式标记异步测试，以便在事件循环中运行测试。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO7-2)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO7-2)'
- en: This assumes you’ve replaced the synchronous database client with async one
    in *conftest.py*.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这假设您已经在*conftest.py*中将同步数据库客户端替换为异步客户端。
- en: 'When you run the `pytest` command, it searches the project directory tree to
    discover tests using *collectors* for each level of the directory hierarchy: functions,
    classes, modules, packages, or session. The `pytest-asyncio` plug-in provides
    an asyncio event loop for each of these collectors. By default, tests marked with
    `@pytest.mark.asyncio` run in the event loop provided by the *function collector*,
    to narrow the event loop scope and maximize the isolation between tests.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行`pytest`命令时，它会搜索项目目录树以使用*collectors*发现每个目录层次级别的测试：函数、类、模块、包或会话。`pytest-asyncio`插件为每个收集器提供异步事件循环。默认情况下，标记为`@pytest.mark.asyncio`的测试在由*函数收集器*提供的事件循环中运行，以缩小事件循环的范围并最大化测试之间的隔离。
- en: But why is this isolation important?
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么这种隔离很重要？
- en: The biggest source of frustration for developers when testing software is flaky
    tests. These are tests that randomly fail when you consecutively run the test
    suite without changing any code or configurations.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者在测试软件时最大的挫折来源是不可靠的测试。这些测试在连续运行测试套件而未更改任何代码或配置的情况下随机失败。
- en: 'Often when you investigate the cause of the flaky test behavior, you’ll find
    that there is a central fixture or dependency that is changed by one of the tests,
    violating a core principle of testing: *test isolation*. The purpose of this isolation
    is to achieve *idempotency* in tests where repeated execution would produce the
    same results every time regardless of how many times you run the test suite.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你调查不可靠测试行为的原因时，你会发现有一个中心固定或依赖项被其中一个测试更改，违反了测试的核心原则：*测试隔离*。这种隔离的目的是在测试中实现*幂等性*，即重复执行会产生相同的结果，无论你运行测试套件多少次。
- en: Without isolation, tests can create side effects on each other, invalidating
    core assumptions, leading to fluctuations in their outcome/behavior, and random
    failures. In addition, interdependent and order-dependent tests often fail together,
    preventing you from getting valuable feedback on failures.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 没有隔离，测试可能会相互产生副作用，从而违反核心假设，导致结果/行为波动，以及随机失败。此外，相互依赖和顺序依赖的测试通常一起失败，阻止你从失败中获得有价值的反馈。
- en: But how is flaky behavior related to asynchronous tests?
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 但不可靠行为如何与异步测试相关？
- en: As discussed in [Chapter 5](ch05.html#ch05), asynchronous code is leveraging
    Python’s built-in scheduler, an event loop, to switch tasks when faced with a
    blocking I/O operation. This task switching in a testing environment can make
    asynchronous tests challenging to implement correctly because async operations
    may not complete immediately and can be executed out of order.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第5章](ch05.html#ch05)所述，异步代码利用Python内置的调度器，即事件循环，在遇到阻塞I/O操作时切换任务。在测试环境中，这种任务切换可能会使异步测试难以正确实现，因为异步操作可能不会立即完成，并且可能以错误的顺序执行。
- en: Async tests often interface with external dependencies like databases or filesystems
    executing I/O blocking operations that can take a long time to run. This is a
    major issue for unit tests that must run very quickly so that you can execute
    them frequently.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 异步测试通常与外部依赖（如数据库或文件系统）接口，执行可能需要很长时间运行的I/O阻塞操作。这对于必须非常快速运行的单元测试来说是一个主要问题，这样你就可以频繁地执行它们。
- en: Unlike synchronous code where operations are executed in a predictable and linear
    sequence, async code also introduces variability in timing, execution order, and
    fixture state, reducing the consistency of the outcomes across tests. Additionally,
    response times from external dependencies can fluctuate, leading to side effects
    that violate the test isolation principle.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 与操作以可预测和线性顺序执行的同步代码不同，异步代码也引入了时间、执行顺序和固定状态的可变性，这降低了测试结果的一致性。此外，外部依赖的响应时间可能会波动，导致违反测试隔离原则的副作用。
- en: 'To mitigate the risk of side effects and flaky behavior, you’ll need to correctly
    handle async tests by:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解副作用和不可靠行为的风险，你需要通过以下方式正确处理异步测试：
- en: Awaiting blocking I/O operations
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待阻塞I/O操作
- en: Avoiding unintentional use of blocking synchronous I/O operations inside async
    tests
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在异步测试中无意中使用阻塞同步I/O操作
- en: Using correct timeouts for managing delays
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正确的超时来管理延迟
- en: Explicitly controlling the sequence of operations, especially when running async
    tests in parallel
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确控制操作顺序，尤其是在并行运行异步测试时
- en: Perhaps, the best mitigation is to write synchronous tests by mocking external
    dependencies, which will decouple your functions from I/O blocking dependencies.
    Using mocks, you can then run fast and reliable tests without having to wait for
    I/O operations to complete in the order you need.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 也许，最好的缓解方法是通过对外部依赖进行模拟来编写同步测试，这将使你的函数与I/O阻塞依赖解耦。使用模拟，你可以运行快速且可靠的测试，而无需等待I/O操作按你需要的方式完成。
- en: Tip
  id: totrans-317
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Async tests can still be useful with real dependencies when locally testing
    a replicated production environment.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地测试复制的生产环境时，即使有真实依赖，异步测试仍然有用。
- en: Next, let’s see how to mock external dependencies in unit tests so that you
    can write synchronous tests in replacement of slow async ones.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何在单元测试中模拟外部依赖，以便你可以用同步测试代替缓慢的异步测试。
- en: Mocking and patching
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模拟和修补
- en: When writing unit tests, you need to isolate your components from external dependencies
    to avoid slow-running tests and consuming unnecessary resources. For instance,
    you don’t want to call your GenAI model every time you run the test suite, which
    is going to be frequent, as that’ll be compute-intensive and possibly expensive.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 当编写单元测试时，你需要将你的组件从外部依赖项中隔离出来，以避免运行缓慢的测试和消耗不必要的资源。例如，你不想在每次运行测试套件时都调用你的 GenAI
    模型，因为这将非常频繁，这将非常计算密集且可能昂贵。
- en: Instead, you can use *test doubles* to simulate real dependencies in your unit
    tests without having to rely on external dependencies in your tests. In essence,
    they pretend to be the real thing, just like stunt doubles in action movies that
    pretend to be the main actors. Isolated unit tests that use test doubles can verify
    the component state changes or behavior as it interacts with external dependencies
    like an LLM API.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你可以在单元测试中使用 *测试双* 来模拟真实依赖项，而无需在测试中依赖外部依赖项。本质上，它们假装是真实的东西，就像动作电影中的替身演员假装是主要演员一样。使用测试双的隔离单元测试可以验证组件在与外部依赖项（如
    LLM API）交互时的状态变化或行为。
- en: Warning
  id: totrans-323
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Be careful not to replace any component behavior you’re trying to test with
    test doubles.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 小心不要用测试双替换你试图测试的任何组件行为。
- en: For example, if you have a `ChatBot` class that uses an LLM API and performs
    content filtering on the responses, replace only the LLM API calls with test doubles,
    not the content filtering logic. Otherwise, you’ll be testing your own test double.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一个使用 LLM API 并对响应进行内容过滤的 `ChatBot` 类，只需替换 LLM API 调用为测试双，而不是内容过滤逻辑。否则，你将测试自己的测试双。
- en: There are five types of test doubles that you can use in your unit tests, as
    shown in [Figure 11-9](#test_doubles).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在单元测试中使用五种类型的测试双，如图 11-9 所示。
- en: '![bgai 1109](assets/bgai_1109.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1109](assets/bgai_1109.png)'
- en: Figure 11-9\. Test doubles
  id: totrans-328
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-9\. 测试双
- en: 'These include the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包括以下内容：
- en: Fake
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 假冒
- en: A simplified implementation of a dependency for testing purposes
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 用于测试目的的依赖项的简化实现
- en: Dummy
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 假
- en: A placeholder used for when an argument needs to be filled in
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要填充参数时使用的占位符
- en: Stub
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 存根
- en: Provides fake data to the system under test that is using it
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 向正在使用它的系统测试提供假冒数据
- en: Spy
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 间谍
- en: Keeps track of dependency usage for later verification
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪依赖项的使用情况以供后续验证
- en: Mock
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟
- en: Checks how the dependency will be used and causes failure if the expectation
    isn’t met
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 检查依赖项将如何被使用，如果期望未满足则导致失败
- en: Except mocks that verify component behavior, the rest of these doubles can be
    used to verify state changes. Mocks have an entirely different setup and verification
    logic but work exactly like the other doubles in making the component being tested
    believe that it’s interacting with the real dependencies.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用于验证组件行为的模拟之外，其余这些双可以用来验证状态变化。模拟有完全不同的设置和验证逻辑，但与其他双在使被测试的组件相信它正在与真实依赖项交互方面工作方式完全相同。
- en: Let’s see each double in action to understand their similarities and differences.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个双的作用，以了解它们的相似之处和不同之处。
- en: Fakes
  id: totrans-342
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假冒
- en: '*Fake* objects are fully functional but simplified versions of the real dependency,
    possibly taking shortcuts. An example would be a database client that uses an
    in-memory database during tests instead of an actual database server; or an LLM
    client that fetches cached responses from a local testing server instead of an
    actual LLM.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '*假冒*对象是真实依赖项的完全功能但简化的版本，可能采取了捷径。一个例子是数据库客户端在测试期间使用内存数据库而不是实际的数据库服务器；或者 LLM
    客户端从本地测试服务器获取缓存的响应而不是实际的 LLM。'
- en: '[Example 11-8](#test_fakes) demonstrates what a fake LLM client looks like.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-8](#test_fakes) 展示了一个假冒 LLM 客户端的外观。'
- en: Example 11-8\. Fake test double
  id: totrans-345
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-8\. 假冒测试双
- en: '[PRE12]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO8-1)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO8-1)'
- en: A fully functional and simplified version LLM client that mimics the behavior
    of the real one by interacting with a local testing server.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 一个完全功能且简化的 LLM 客户端，通过与本地测试服务器交互来模拟真实客户端的行为。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO8-2)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO8-2)'
- en: Return cached responses if repeated prompts are used.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用重复提示，则返回缓存的响应。
- en: Dummies
  id: totrans-351
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假
- en: '*Dummies* are objects that aren’t used in tests, but you pass around to satisfy
    parameter requirements of functions. An example would be passing a fake authentication
    token to an API client to prevent errors, even though the token isn’t used for
    authentication during the test.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '*替身（dummies）* 是在测试中未使用的对象，但你将其传递以满足函数的参数要求。一个例子是将一个假的认证令牌传递给 API 客户端以防止错误，即使在该测试期间该令牌没有被用于认证。'
- en: '[Example 11-9](#test_dummies) shows how dummies can be used as test doubles.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-9](#test_dummies) 展示了如何使用替身（dummies）作为测试替身（test doubles）。'
- en: Example 11-9\. Dummy test double
  id: totrans-354
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-9\. 替身测试替身
- en: '[PRE13]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO9-1)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO9-1)'
- en: Notice the `token` is not being used but is required to satisfy the `.invoke(query,
    token)` function signature.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `token` 没有被使用，但它是必需的，以满足 `.invoke(query, token)` 函数签名。
- en: Stubs
  id: totrans-358
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 存根（Stubs）
- en: '*Stubs* are simplified versions of fakes. They don’t have fully functional
    implementations and instead return canned responses to method calls. As an example,
    a stub LLM client will return a predefined fixture string when called without
    making any actual model requests.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '*存根（stubs）* 是假（fakes）的简化版本。它们没有完全功能性的实现，而是对方法调用返回预定义的响应。例如，一个存根 LLM 客户端在调用时将返回一个预定义的固定字符串，而不会进行任何实际的模型请求。'
- en: '[Example 11-10](#test_stubs) shows what a stub looks like. Can you spot the
    differences when comparing this example with [Example 11-8](#test_fakes)?'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-10](#test_stubs) 展示了存根（stub）的外观。你能在将此示例与 [示例 11-8](#test_fakes) 进行比较时发现差异吗？'
- en: Example 11-10\. Stub test double
  id: totrans-361
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-10\. 存根测试替身
- en: '[PRE14]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO10-1)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO10-1)'
- en: Return a canned response on a given condition.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定条件下返回预定义的响应。
- en: Spies
  id: totrans-365
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 间谍（Spies）
- en: '*Spies* are like stubs but also record method calls and interactions. They’re
    extremely useful when you need to verify how a complex component interacts with
    a dependency. For example, with a spy LLM client, you can verify the number of
    times it was invoked by the component under test.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '*间谍（spies）* 类似于存根，但也会记录方法调用和交互。当需要验证一个复杂组件如何与依赖项交互时，它们非常有用。例如，使用间谍 LLM 客户端，你可以验证它被测试组件调用的次数。'
- en: '[Example 11-11](#test_spies) shows a spy test double in action.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-11](#test_spies) 展示了间谍测试替身的作用。'
- en: Example 11-11\. Spy test double
  id: totrans-368
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-11\. 间谍测试替身
- en: '[PRE15]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO11-1)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO11-1)'
- en: Keep track of function calls and arguments passed in.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪函数调用和传入的参数。
- en: Mocks
  id: totrans-372
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟（Mocks）
- en: A mock is a smarter stub. If you know in advance how many times a dependency
    is called and how (i.e., you have expectations of interaction), you can implement
    a *mock*. A mock can verify whether the dependency has been called correctly with
    the right parameters to confirm the component being tested has behaved correctly.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟（Mock）是一种更智能的存根。如果你事先知道一个依赖项被调用的次数以及如何调用（即，你有交互的预期），你可以实现一个模拟（mock）。模拟可以验证依赖项是否以正确的参数正确调用，以确认被测试的组件表现正确。
- en: How you set up mocks and perform checks with them is different to other doubles,
    as you can see in [Example 11-12](#test_mocks).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 你设置模拟并使用它们进行检查的方式与其他替身不同，正如你在 [示例 11-12](#test_mocks) 中可以看到的那样。
- en: Note
  id: totrans-375
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'For this example, you need to install the `pytest-mocks` plug-in, which is
    a thin wrapper over Python’s built-in mocks library to simplify mocking implementation.
    Use the following command to install `pytest-mocks`:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此示例，你需要安装 `pytest-mocks` 插件，这是一个 Python 内置模拟库的薄包装，用于简化模拟实现。使用以下命令安装 `pytest-mocks`：
- en: '[PRE16]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Example 11-12\. Mock test double
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-12\. 模拟测试替身
- en: '[PRE17]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO12-1)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO12-1)'
- en: Create and configure a mock to act as an LLM client tracking function calls
    and arguments passed in. It will also return any canned responses we want.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 创建并配置一个模拟以充当 LLM 客户端，跟踪传入的函数调用和参数。它还将返回我们想要的任何预定义响应。
- en: Using mocks, as shown in [Example 11-12](#test_mocks), will be useful to check
    the mocked component’s behavior in highly nested and complex application logic
    such as checking how a mocked function like `llm_client.invoke()` is called several
    levels deep within a higher order function such as `process_query()`.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模拟，如 [示例 11-12](#test_mocks) 所示，将有助于检查模拟组件在高度嵌套和复杂的应用逻辑中的行为，例如检查一个模拟函数如 `llm_client.invoke()`
    在一个高阶函数如 `process_query()` 中被调用的情况。
- en: Now that you’re more familiar with implementing various test doubles from scratch,
    let’s see how an external package such as `pytest-mock` can simplify using test
    doubles.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您对从头开始实现各种测试替身有了更多的了解，让我们看看外部包如`pytest-mock`如何简化测试替身的使用。
- en: Implementing test doubles with pytest-mock
  id: totrans-384
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用pytest-mock实现测试替身
- en: The five aforementioned test doubles can also be implemented with `pytest-mock`,
    as shown in [Example 11-13](#test_double_pytest_mock).
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的五种测试替身也可以使用`pytest-mock`实现，如[示例11-13](#test_double_pytest_mock)所示。
- en: Example 11-13\. Test doubles with `pytest-mock`
  id: totrans-386
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例11-13\. 使用`pytest-mock`的测试替身
- en: '[PRE18]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO13-1)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO13-1)'
- en: Fake simulates real behavior.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟器模拟真实行为。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO13-3)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO13-3)'
- en: Stub returns a fixed value.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟器返回一个固定值。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO13-4)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_testing_ai_services_CO13-4)'
- en: Spy tracks calls.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 间谍跟踪调用。
- en: '[![4](assets/4.png)](#co_testing_ai_services_CO13-5)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_testing_ai_services_CO13-5)'
- en: Checks dependency behavior and fails if expectation isn’t met.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 检查依赖行为，如果期望未满足则失败。
- en: You can now use any of the mentioned test doubles to isolate your unit tests,
    run them faster while covering various hard-to-test edge cases, and bypass dependencies
    that introduce nondeterminism in your tests. But bear in mind, having too many
    mocked tests is an anti-pattern as these tests may give you false confidence and
    become a maintenance overhead due to their brittleness. They can also mask integration
    issues since they’re not testing real dependencies and overusing them can lead
    to complex test implementations that are hard to understand.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以使用所提到的任何测试替身来隔离单元测试，更快地运行它们，同时覆盖各种难以测试的边缘情况，并绕过引入测试非确定性的依赖项。但请记住，拥有过多的模拟测试是一种反模式，因为这些测试可能会给您带来虚假的信心，并且由于它们的脆弱性，可能会成为维护的负担。它们也可能掩盖集成问题，因为它们不是测试真实依赖项，过度使用它们可能导致复杂的测试实现，难以理解。
- en: In such cases, you should rely on simple mocks only when necessary and in unit
    tests. Furthermore, you should complement any mocked tests with integration tests
    that use real dependencies to avoid missing any production issues.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您应该仅在必要时且在单元测试中使用简单的模拟。此外，您应该用使用真实依赖项的集成测试来补充任何模拟测试，以避免错过任何生产问题。
- en: In the next section, you’ll learn how to implement an integration test for your
    RAG pipeline.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何实现您的RAG管道的集成测试。
- en: Integration Testing
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成测试
- en: Up until this point, you’ve been practicing with writing isolated unit tests.
    But as soon as you want to test a component interacting with another component
    or a real dependency, you’ll be implementing integration tests.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您一直在练习编写隔离的单元测试。但一旦您想要测试与另一个组件或真实依赖项交互的组件，您将实现集成测试。
- en: The testing boundary of integration tests should include two components, and
    the scope of these tests must focus on checking the functionality of their interface
    and the communication contract between them.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试的测试边界应包括两个组件，这些测试的范围必须专注于检查它们的接口功能以及它们之间的通信合约。
- en: As an example, you can see potential integration tests you can implement for
    your RAG pipeline in [Figure 11-10](#integration_boundaries).
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以在[图11-10](#integration_boundaries)中看到您可以为您的RAG管道实现的潜在集成测试。
- en: '![bgai 1110](assets/bgai_1110.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1110](assets/bgai_1110.png)'
- en: Figure 11-10\. Integration test boundaries visualized on the RAG data pipeline
    diagram
  id: totrans-404
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-10\. 在RAG数据管道图上可视化的集成测试边界
- en: Compared to unit test boundaries you saw in [Figure 11-8](#unit_boundaries),
    you can see that each integration is only concerned about verifying the interaction
    behavior between two or maximum three components at a time.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 与您在[图11-8](#unit_boundaries)中看到的单元测试边界相比，您可以看到每个集成测试只关注验证两个或最多三个组件之间的交互行为。
- en: To practice, we’ll implement an integration test for the document retrieval
    interface with the vector database in the RAG pipeline. In this test, you’ll be
    querying the real vector database to verify whether the relevant documents are
    being fetched in relation to the query.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习，我们将实现一个针对RAG管道中向量数据库的文档检索接口的集成测试。在这个测试中，您将查询真实的向量数据库，以验证相关文档是否与查询相关地被检索。
- en: The tests will leverage RAG-related retrieval metrics such as context precision
    and context recall to measure the effectiveness of the retrieval system with the
    real vector database.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 测试将利用与 RAG 相关的检索指标，如上下文精确度和上下文召回率，以衡量检索系统在真实向量数据库中的有效性。
- en: Context precision and recall
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文精确度和召回率
- en: Both context precision and recall are evaluation metrics specifically designed
    for measuring the quality of the document retrieval system from the vector database
    in a RAG pipeline.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文精确度和召回率是专门设计用于衡量 RAG 管道中从向量数据库中检索到的文档检索系统质量的评估指标。
- en: While *context precision* focuses on the signal-to-noise ratio (i.e., quality),
    of the retrieved information from the vector database, *context recall* measures
    whether all information relevant for responding to the user query has been retrieved
    from the database.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 *上下文精确度* 关注从向量数据库检索到的信息的信噪比（即质量），而 *上下文召回率* 则衡量是否已从数据库中检索到所有与响应用户查询相关的信息。
- en: You can calculate context precision and recall using [Example 11-14](#context_precision_recall).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 [示例 11-14](#context_precision_recall) 计算上下文精确度和召回率。
- en: Example 11-14\. Calculating context precision and recall
  id: totrans-412
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-14\. 计算上下文精确度和召回率
- en: '[PRE19]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO14-1)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_testing_ai_services_CO14-1)'
- en: Count of correct documents retrieved/count of expected documents.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 正确检索到的文档数/预期文档数。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO14-2)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_testing_ai_services_CO14-2)'
- en: Count of correct documents retrieved/count of retrieved documents.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 正确检索到的文档数/检索到的文档数。
- en: Here, we’re assuming that each document will contain all the relevant contextual
    information to respond to a given query, so asserting that certain documents are
    fetched will suffice.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设每个文档都将包含所有与响应给定查询相关的上下文信息，因此断言某些文档被检索到就足够了。
- en: Open source libraries such as `deep-eval` and `ragas` can help you automate
    the computation of these metrics considering the relevant context is scattered
    across documents, but for simplicity, we will be implementing our integration
    tests without relying on such libraries.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 开源库如 `deep-eval` 和 `ragas` 可以帮助您自动化这些指标的计算，考虑到相关上下文分散在文档中，但为了简单起见，我们将不依赖此类库来实现我们的集成测试。
- en: With precision and recall metrics, the integration test for the document retrieval
    system will look like [Example 11-15](#integration_retrieval).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 使用精确度和召回率指标，文档检索系统的集成测试将类似于 [示例 11-15](#integration_retrieval)。
- en: Example 11-15\. Document retrieval system integration test
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-15\. 文档检索系统集成测试
- en: '[PRE20]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO15-1)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_testing_ai_services_CO15-1)'
- en: Specify parameterized test data that covers various cases.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 指定参数化测试数据，以涵盖各种情况。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO15-2)'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_testing_ai_services_CO15-2)'
- en: Set up the qdrant client within *conftest.py* with correct setup and teardown
    implementation to start the test with a prepopulated database of documents.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *conftest.py* 中设置 qdrant 客户端，并使用正确的设置和拆卸实现，以启动带有预先填充文档数据库的测试。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO15-4)'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_testing_ai_services_CO15-4)'
- en: Calculate the precision and recall for each test case to ensure they’re above
    a reasonable threshold. There is often a trade-off between precision and recall
    metrics, so choose sensible thresholds based on your own use case.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个测试案例的精确度和召回率，以确保它们高于合理的阈值。通常在精确度和召回率指标之间存在权衡，因此请根据您的实际使用情况选择合理的阈值。
- en: While [Example 11-15](#integration_retrieval) checks the document retrieval
    system, you can also implement an integration test for your generation subsystem
    using the LLM. However, bear in mind that due to the nondeterministic nature of
    the LLM, it can be challenging to ensure comprehensive test coverage and consistency
    in outcomes.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 [示例 11-15](#integration_retrieval) 检查文档检索系统，您还可以使用 LLM 实现生成子系统的集成测试。然而，请记住，由于
    LLM 的非确定性，确保全面的测试覆盖率和结果一致性可能具有挑战性。
- en: If you’ve prompted your LLM to return JSON responses, you can write integration
    tests with equality assertions to verify the structure and value of the JSON responses.
    An example where you may follow this approach is in *function calling* or *agentic
    workflows* where the LLM has to select the right tool or specialized LLM agent
    to use for addressing the query.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已提示LLM返回JSON响应，您可以使用相等断言编写集成测试来验证JSON响应的结构和值。您可能遵循此方法的示例包括*函数调用*或*代理工作流程*，其中LLM必须选择用于回答查询的正确工具或专门的LLM代理。
- en: A test such as this could look like [Example 11-16](#integration_llm_json).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的测试可能看起来像[示例 11-16](#integration_llm_json)。
- en: Example 11-16\. LLM JSON response generation system integration test
  id: totrans-432
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-16\. LLM JSON响应生成系统集成测试
- en: '[PRE21]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO16-1)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_testing_ai_services_CO16-1]'
- en: Iterate over various test cases covering various user queries. Ensure test cases
    cover a balanced distribution of categories.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历各种测试案例，涵盖各种用户查询。确保测试案例涵盖平衡的分类分布。
- en: Given the model may make mistakes and you may not be able to test every possible
    case, you’ll want to run this test enough times (maybe up to 100 times) to visualize
    the distribution patterns in LLM responses. This should give you more confidence
    in how your LLM is selecting the right tool or agent for a given user query.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型可能会出错，您可能无法测试所有可能的案例，因此您需要多次运行此测试（可能多达100次）以可视化LLM响应中的分布模式。这应该会增加您对LLM如何为特定用户查询选择正确工具或代理的信心。
- en: If your models are returning structured outputs, integration tests can be straightforward
    to implement, as you saw in [Example 11-16](#integration_llm_json). However, what
    if your GenAI models are responding with more dynamic content such as natural
    text? How can you test the quality of your model responses then?
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的模型返回结构化输出，则集成测试可以很容易地实现，正如您在[示例 11-16](#integration_llm_json)中看到的那样。然而，如果您的GenAI模型以更动态的内容（如自然文本）响应，您如何测试模型响应的质量呢？
- en: In this case, you can measure properties and metrics related to the model’s
    output. In the case of LLMs, measure model generation properties such as *context
    relevancy*, *hallucination rates*, *toxicity*, etc., to verify the correctness
    and quality of responses based on the prompt context.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您可以测量与模型输出相关的属性和指标。在LLM的情况下，测量模型生成属性，如*上下文相关性*、*幻觉率*、*毒性*等，以验证基于提示上下文的响应的正确性和质量。
- en: This approach is referred to as *behavioral testing*, which we’ll look at next.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法被称为*行为测试*，我们将在下一节中探讨。
- en: Behavioral testing
  id: totrans-440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 行为测试
- en: Writing tests for models that return dynamic content can be challenging since
    outputs are often varied, creative, and challenging to evaluate using direct equality
    checks. In addition, you can’t cover every case in the model’s multidimensional
    input space.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 为返回动态内容的模型编写测试可能具有挑战性，因为输出通常是多样化的、创造性的，并且难以使用直接相等检查进行评估。此外，您无法覆盖模型多维输入空间中的每个案例。
- en: Instead, you’ll want to treat the model as a black box and check the model behavior
    plus output characteristics using a range of inputs that reflect potential usage
    patterns.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，您应该将模型视为一个黑盒，并使用一系列反映潜在使用模式的输入来检查模型的行为和输出特征。
- en: Tip
  id: totrans-443
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Please bear in mind that when testing GenAI models, you can’t achieve full coverage
    on the entire input distribution. Instead, you can aim for the statistical confidence
    that your model behaves as intended by testing it on a representative sample of
    the input distribution.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在测试GenAI模型时，您无法在整个输入分布上实现全面覆盖。相反，您可以通过在输入分布的代表样本上测试来达到统计上对模型按预期行为的信心。
- en: '*Behavior/property-based testing* helps you overcome these challenges by verifying
    key attributes in the model’s output, rather than focusing on the exact output
    content.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '*行为/属性测试*通过验证模型输出的关键属性来帮助您克服这些挑战，而不是关注确切的输出内容。'
- en: 'The following are examples of property-based tests you can implement for an
    LLM:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为LLM可以实施的属性测试的示例：
- en: Checking sentiment of the output
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查输出的情感
- en: Verifying the response length
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证响应长度
- en: Checking readability scores of a generated text
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查生成的文本的可读性分数
- en: Factual checks to verify the model is returning “I don’t know” responses if
    a user query can’t be answered based on the given context
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际检查以验证当用户查询无法根据给定上下文回答时，模型是否返回“我不知道”的响应。
- en: Beyond the given list, there are several other behavioral properties you can
    check.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 除了给定的列表之外，还有其他几个你可以检查的行为属性。
- en: Tip
  id: totrans-452
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Using TDD with behavioral tests is an excellent way to optimize your model prompts
    and input settings like temperature, top-p, etc., by experimenting with various
    parameters that satisfy your functional requirements.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TDD 与行为测试相结合是优化你的模型提示和输入设置（如温度、top-p 等）的绝佳方法，通过实验各种满足你的功能要求的参数。
- en: 'A [landmark paper](https://oreil.ly/6ZnQj) on this topic breaks down behavioral
    testing into three categories:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的一篇[里程碑论文](https://oreil.ly/6ZnQj)将行为测试分为三个类别：
- en: Minimum functionality tests (MFTs)
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小功能测试（MFTs）
- en: Invariance tests (ITs)
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不变性测试（ITs）
- en: Directional expectation tests (DETs)
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方向预期测试（DETs）
- en: Let’s break down each type of behavioral test to understand the purpose of each
    in verifying model performance.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析每种行为测试类型，以了解每种测试在验证模型性能方面的目的。
- en: Minimum functionality tests (MFTs)
  id: totrans-459
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最小功能测试（MFTs）
- en: '*Minimum functionality tests* check that the system provides at least basic,
    correct behavior on simple, well-defined inputs. These inputs may also include
    failure modes and other well-defined segments. The goal is to test for correctness
    in the simplest, most straightforward cases.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '*最小功能测试* 检查系统在简单、定义良好的输入上至少提供基本、正确的行为。这些输入也可能包括故障模式和定义良好的其他部分。目标是测试在最简单、最直接的情况下的正确性。'
- en: Example MFTs include checking for correctness of grammar, commonly well-known
    facts, zero toxicity, reject clearly inappropriate inputs, exhibit empathy, and
    produce readable and professional outputs.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: MFTs 的例子包括检查语法正确性、众所周知的事实、零毒性、拒绝明显不合适的输入、表现出同理心以及生成可读且专业的输出。
- en: '[Example 11-17](#mft_test) demonstrates implementation of an MFT for checking
    readability. For this example, you will need to install the `textstat` library:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-17](#mft_test) 展示了用于检查可读性的 MFT 的实现。对于这个例子，你需要安装 `textstat` 库：'
- en: '[PRE22]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Example 11-17\. Minimum functionality test for readability
  id: totrans-464
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-17\. 可读性最小功能测试
- en: '[PRE23]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO17-1)'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO17-1)'
- en: Iterate over various examples checking the readability score even when a user
    asks for simple explanations.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历各种示例，检查即使在用户请求简单解释时，可读性分数是否仍然有效。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO17-2)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO17-2)'
- en: Use the Flesch formula for assessing the readability score. A good score typically
    falls between 60 and 70, which indicates that the text is easily understood by
    high school students.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Flesch 公式来评估可读性分数。一个好的分数通常在 60 到 70 之间，这意味着文本对高中生来说很容易理解。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO17-3)'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_testing_ai_services_CO17-3)'
- en: Verify that the readability score is above the expected values but also not
    too high. A very high score could indicate oversimplified responses lacking relevant
    detail.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 确保可读性分数高于预期值，但也不太高。一个非常高的分数可能表明响应过于简化，缺乏相关细节。
- en: The readability test shown in [Example 11-17](#mft_test) should now give you
    an idea on how to write your own MFTs. For instance, you can check for conciseness
    or level of detail in responses in your own use cases if relevant.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 11-17 中展示的可读性测试现在应该让你对如何编写自己的 MFTs 有一个概念。例如，如果你适用，你可以在自己的用例中检查响应的简洁性或详细程度。
- en: Invariance tests (ITs)
  id: totrans-473
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不变性测试（ITs）
- en: '*Invariance tests* check whether a model’s predictions remain consistent when
    irrelevant changes are made to the inputs. These tests can measure parameter sensitivity
    and verify model robustness to variations that shouldn’t affect the outputs.'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '*不变性测试* 检查当对输入进行无关更改时，模型的预测是否保持一致。这些测试可以测量参数敏感性并验证模型对不应影响输出的变化的鲁棒性。'
- en: 'Examples of ITs include checking for no change in model responses if you adjust
    the prompts by:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: ITs 的例子包括检查在调整提示时模型响应是否没有变化：
- en: Changing the case sensitivity
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改变大小写敏感性
- en: Injecting whitespace, escape, and special characters
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注入空白字符、转义字符和特殊字符
- en: Including typos or grammatical mistakes
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含拼写错误或语法错误
- en: Replacing words with synonyms
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用同义词替换单词
- en: Switching number formats (between digits and words)
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切换数字格式（在数字和单词之间）
- en: Reordering text/context chunks in the prompt
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示中重新排序文本/上下文块
- en: There are also many other types of checks that could be made through invariance
    testing.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 通过不变性测试还可以进行许多其他类型的检查。
- en: '[Example 11-18](#it_test) shows a simple invariance test.'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-18](#it_test) 展示了一个简单的变性测试。'
- en: Example 11-18\. Invariance tests
  id: totrans-484
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-18\. 不变性测试
- en: '[PRE24]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As you see, most of these tests slightly adjust the inputs with the expectation
    that outputs remain mostly similar. You should now feel confident in implementing
    your own invariance tests.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这些测试大多数都会稍微调整输入，期望输出保持大致相似。你现在应该有信心实施自己的不变性测试。
- en: Directional expectation tests (DETs)
  id: totrans-487
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 方向性期望测试 (DETs)
- en: '*Directional expectation tests* check whether the model behaves logically and
    the outputs change in the right direction as inputs change.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '*方向性期望测试* 检查模型是否按逻辑行事，以及随着输入的变化，输出是否按正确方向变化。'
- en: Examples of DETs include checking for the right adjustments in the sentiment
    between the prompt and response or for specificity of answers to specific questions.
    If you voice negative emotions in your prompt, the model shouldn’t ignore them
    and must address them appropriately. Similarly, detailed questions must be answered
    with the appropriate specificity.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: DETs 的例子包括检查提示和响应之间的情感调整是否正确，或者检查对特定问题的答案的特定性。如果你在提示中表达负面情绪，模型不应忽略它们，而必须适当地处理它们。同样，详细的问题必须用适当的特定性来回答。
- en: As you can see in [Example 11-19](#det_test), we expect and test for a positive
    correlation between the prompt and the response on both length and complexity.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [示例 11-19](#det_test) 所示，我们期望并测试提示和响应在长度和复杂性上的正相关关系。
- en: Example 11-19\. Directional expectation test for checking response length
  id: totrans-491
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-19\. 检查响应长度的方向性期望测试
- en: '[PRE25]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO18-1)'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO18-1)'
- en: Iterate over various prompts where one is a complex variant of another.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历各种提示，其中一个是另一个的复杂变体。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO18-2)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO18-2)'
- en: Use response text length as a proxy metric for checking relative answer complexity
    with the assumption that the more complex the prompt, the lengthier (and more
    complex) the answer. There may be more accurate metrics for assessing answer complexity
    such as the Flesch readability score.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 使用响应文本长度作为检查相对答案复杂性的代理指标，假设提示越复杂，答案就越长（且越复杂）。评估答案复杂性的更准确指标可能包括 Flesch 可读性分数。
- en: MFTs, ITs, and DETs aren’t the only types of tests you can implement to check
    the behavior of your models. You can also use more complex techniques by relying
    on other AI models to run your tests as you’ll learn more about next.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: MFTs、ITs 和 DETs 不是检查模型行为的唯一测试类型。你也可以通过依赖其他 AI 模型来运行测试，从而使用更复杂的技术，你将在下一部分学到更多。
- en: Auto-evaluation tests
  id: totrans-498
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动评估测试
- en: Another technique for checking the behavior of GenAI models is to rely on other
    AI models during tests, a process referred to as *auto-evaluation*.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 GenAI 模型行为的一种技术是在测试期间依赖其他 AI 模型，这个过程被称为 *自动评估*。
- en: '*Auto-evaluation tests* use a discriminator/evaluator model to verify the quality
    of outputs on various metrics such as hallucination rates, toxicity, correctness,
    answer relevancy, etc. For LLM outputs, you can use an LLM or a classification
    model as the evaluator, as shown in [Example 11-20](#self_evaluation_test).'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动评估测试* 使用判别器/评估器模型来验证在各种指标上的输出质量，例如幻觉率、毒性、正确性、答案相关性等。对于 LLM 输出，你可以使用 LLM
    或分类模型作为评估器，如 [示例 11-20](#self_evaluation_test) 所示。'
- en: Example 11-20\. Auto-evaluation LLM self-check for measuring toxicity
  id: totrans-501
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-20\. 用于测量毒性的自动评估 LLM 自我检查
- en: '[PRE26]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO19-1)'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO19-1)'
- en: Construct an evaluation system prompt for the LLM, describing how to perform
    the evaluation task.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 为 LLM 构建一个评估系统提示，描述如何执行评估任务。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO19-3)'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO19-3)'
- en: Request responses to be returned in structured format for simple parsing. You
    can also ask for measurements instead of Boolean assessments.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 请求以结构化格式返回响应，以便简单解析。你也可以要求测量值而不是布尔评估。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO19-4)'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_testing_ai_services_CO19-4)'
- en: Gracefully get the `is_toxic` value and fail assertion if a `False` value can’t
    be obtained.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅地获取 `is_toxic` 值，如果无法获得 `False` 值则断言失败。
- en: The core idea in [Example 11-20](#self_evaluation_test) is to have the LLM “evaluate
    itself” or to implement tests that check its performance based on predefined criteria,
    properties, or behaviors.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-20](#self_evaluation_test) 的核心思想是让大型语言模型（LLM）“自我评估”或实施基于预定义标准、属性或行为的测试来检查其性能。'
- en: Auto-evaluation tests are powerful techniques for assessing the quality of responses
    across various metrics, but they rely on other models and additional API calls,
    which can increase your costs.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 自动评估测试是评估响应质量跨各种指标的有效技术，但它们依赖于其他模型和额外的 API 调用，这可能会增加您的成本。
- en: With these testing techniques, you should now have all the tools necessary to
    check the performance of your GenAI models, whether you’re interfacing with an
    LLM or other types of generators.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些测试技术，您现在应该拥有检查您的 GenAI 模型性能所需的所有工具，无论您是使用 LLM 还是其他类型的生成器。
- en: The next step after implementing several integration tests is to test your whole
    system using E2E testing. The next section will cover E2E in more detail.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施几个集成测试之后，下一步是使用端到端测试来测试您的整个系统。下一节将更详细地介绍端到端测试。
- en: End-to-End Testing
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 端到端测试
- en: Up until this point, you’ve been working on unit and integration tests for your
    GenAI services. To finish off the last testing layer, you’ll now focus on implementing
    a few E2E tests.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您一直在为您的 GenAI 服务编写单元和集成测试。为了完成最后的测试层，您现在将专注于实现一些端到端测试。
- en: In [Chapter 5](ch05.html#ch05), you implemented a web scraper and a RAG module
    in your FastAPI service. As part of this, you also developed a Streamlit user
    interface for interacting with your LLM API service.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 5 章](ch05.html#ch05) 中，您在您的 FastAPI 服务中实现了一个网络爬虫和一个 RAG 模块。作为这部分工作的一部分，您还开发了一个
    Streamlit 用户界面，用于与您的 LLM API 服务交互。
- en: When you tested your application by uploading documents or providing URLs through
    the Streamlit UI, you were performing *manual* E2E tests on the entire RAG and
    the web scraper pipelines, each containing more than two components.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 当您通过 Streamlit UI 上传文档或提供 URL 来测试您的应用程序时，您正在进行整个 RAG 和网络爬虫管道的 *手动* 端到端测试，每个都包含超过两个组件。
- en: '[Figure 11-11](#e2e_boundaries) shows the E2E tests you performed and their
    boundaries.'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-11](#e2e_boundaries) 展示了您执行的端到端测试及其边界。'
- en: '![bgai 1111](assets/bgai_1111.png)'
  id: totrans-518
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1111](assets/bgai_1111.png)'
- en: Figure 11-11\. E2E test boundaries visualized on the RAG data pipeline diagram
  id: totrans-519
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-11\. 在 RAG 数据管道图上可视化的端到端测试边界
- en: As shown in [Figure 11-11](#e2e_boundaries), a sign that you’re working on an
    E2E test is having a test boundary that covers multiple components and external
    services.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 11-11](#e2e_boundaries) 所示，您正在进行端到端测试的迹象是有覆盖多个组件和外部服务的测试边界。
- en: Tip
  id: totrans-521
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can combine multiple E2E tests into a larger, more complex, but slower test.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将多个端到端测试组合成一个更大、更复杂但更慢的测试。
- en: Larger tests tend to be more fragile, flakier, and as a result frustrating to
    maintain. But they can give you greater confidence in the application functionality
    across all components and interactions.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的测试往往更脆弱、更不可靠，因此维护起来可能很令人沮丧。但它们可以增强您对应用程序功能跨所有组件和交互的信心。
- en: While you manually performed these E2E tests via the UI, you could’ve also automated
    them using test frameworks with an API test client or headless browsers to reduce
    the manual workload. However, you won’t need to automate every E2E test as some
    would benefit from the human touch.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 当您通过 UI 手动执行这些端到端测试时，您也可以使用具有 API 测试客户端或无头浏览器的测试框架来自动化它们，以减少手动工作量。然而，您不需要自动化每个端到端测试，因为其中一些将受益于人工干预。
- en: Manual E2E tests can still help you uncover issues that may go unnoticed with
    your automated tests. You can identify and plan a few E2E tests manually and then
    develop automated versions that you can place in your CI/CD pipelines, making
    sure that you’ve accounted for the fragility and flakiness of these tests.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 手动端到端测试仍然可以帮助您发现自动化测试中可能被忽视的问题。您可以手动识别和规划一些端到端测试，然后开发自动化版本，将它们放入您的 CI/CD 管道中，确保您已经考虑了这些测试的脆弱性和不可靠性。
- en: If an E2E test fails, it means one or several of your unit or integration tests
    could also be failing. Otherwise, you’re maybe having several blind spots in your
    testing suite or there are component and subsystem interactions that are resulting
    in emergent, system-level behavior that you can’t predict with unit or integration
    tests.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 如果端到端测试失败，这意味着您的一个或多个单元测试或集成测试也可能失败。否则，您可能在测试套件中存在几个盲点，或者有组件和子系统交互导致出现您无法通过单元测试或集成测试预测的涌现性、系统级行为。
- en: Tip
  id: totrans-527
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Unlike unit or integration tests, you don’t want to run E2E as frequently.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 与单元测试或集成测试不同，您不需要频繁运行端到端测试。
- en: Furthermore, you don’t necessarily need a UI to perform E2E tests. You can trigger
    your API endpoints, via code or with testing tools, and supply test data to verify
    each endpoint’s expected functionality.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，执行端到端测试不一定需要用户界面。您可以通过代码或测试工具触发API端点，并供应测试数据以验证每个端点的预期功能。
- en: Warning
  id: totrans-530
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Testing an endpoint through invocation isn’t considered a unit or an integration
    test, but rather an E2E test. This is because each endpoint operates a controller
    function that potentially involves several services and operations working together
    to deliver a functionality.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用测试端点进行测试不被视为单元测试或集成测试，而是一种端到端测试。这是因为每个端点都运行一个控制器函数，该函数可能涉及几个服务和操作协同工作以提供功能。
- en: By definition, integration tests would only be scoped to checking an interface
    of two components.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，集成测试只会限于检查两个组件的接口。
- en: 'You’ll soon learn to automate the manual E2E tests using `pytest` and an API
    test client via *vertical* and *horizontal* testing:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 您将很快学会使用`pytest`和API测试客户端通过*垂直*和*水平*测试自动化手动端到端测试：
- en: Vertical E2E tests
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直端到端测试
- en: Verify functionality for a specific feature or workflow, across multiple layers
    of the application—for instance, from the UI to the database
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 验证特定功能或工作流程的功能，跨越应用程序的多个层次——例如，从用户界面到数据库
- en: Horizontal E2E tests
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 水平端到端测试
- en: Verify functionality for various user scenarios, typically across multiple integrated
    systems and services
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 验证各种用户场景的功能，通常跨越多个集成系统和服务
- en: Let’s review vertical E2E testing in more detail before covering horizontal
    E2E tests.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍水平端到端测试之前，让我们更详细地回顾垂直端到端测试。
- en: Vertical E2E tests
  id: totrans-539
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 垂直端到端测试
- en: Going back to [Figure 11-11](#e2e_boundaries), the left E2E test that verifies
    file upload functionality, content extraction, transformation, and storage in
    a database, is a vertical E2E test. Similarly, the second test is also considered
    vertical as it verifies the content retrieval logic from the database when given
    a query and then uses the LLM model for text generation in a Q&A context. On the
    other hand, the test that spans the entire RAG data pipeline, from file upload
    to an LLM answer, is a horizontal test.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 回到[图 11-11](#e2e_boundaries)，验证文件上传功能、内容提取、转换和数据库存储的左侧端到端测试是一个垂直端到端测试。同样，第二个测试也被认为是垂直的，因为它在给定查询时验证从数据库检索内容逻辑，然后使用LLM模型在问答环境中进行文本生成。另一方面，跨越整个RAG数据管道的测试，从文件上传到LLM答案，是一个水平测试。
- en: The main distinction here is that horizontal tests are broader, testing entire
    user scenarios, while vertical tests are more focused, testing a specific workflow
    or feature across the layers.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要区别在于，水平测试更广泛，测试整个用户场景，而垂直测试更专注于测试特定的工作流程或功能，跨越多个层次。
- en: Tip
  id: totrans-542
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: In an application with layered/onion architecture, vertical tests are essentially
    “navigating the onion” and checking the data flows and interactions across layers
    to confirm they’re well-integrated and function as intended.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有分层/洋葱架构的应用程序中，垂直测试基本上是“导航洋葱”，并检查跨层的数据流和交互，以确认它们很好地集成并按预期工作。
- en: Before implementing any E2E tests, let’s create a global fixture initializing
    a FastAPI test client, as shown in [Example 11-21](#test_client). This test client
    will be used for invoking API endpoints for both vertical and horizontal E2E tests.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现任何端到端测试之前，让我们创建一个全局固定装置，初始化FastAPI测试客户端，如[示例 11-21](#test_client)所示。此测试客户端将用于调用垂直和水平端到端测试的API端点。
- en: Example 11-21\. Implementing a test client fixture
  id: totrans-545
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-21\. 实现测试客户端固定装置
- en: '[PRE27]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With the test client, you can now perform both vertical and horizontal E2E tests
    starting with the vertical tests covering the file upload and storage functionality,
    as demonstrated in [Example 11-22](#test_vertical).
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试客户端，您现在可以执行垂直和水平端到端测试，从覆盖文件上传和存储功能的垂直测试开始，如[示例 11-22](#test_vertical)所示。
- en: Example 11-22\. Implementing a vertical E2E to verify the upload and storage
    workflow functionality
  id: totrans-548
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-22\. 实现垂直端到端（E2E）以验证上传和存储工作流程的功能
- en: '[PRE28]'
  id: totrans-549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO20-1)'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_testing_ai_services_CO20-1]'
- en: Use the qdrant vector database client fixture you created earlier during the
    integration tests.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您在集成测试中创建的qdrant向量数据库客户端固定装置。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO20-2)'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_testing_ai_services_CO20-2]'
- en: Upload a file using the test client and check for successful API response.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试客户端上传文件并检查API响应是否成功。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO20-3)'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[#co_testing_ai_services_CO20-3]'
- en: Check that searching the database returns the vector containing the file content
    to verify the functionality of the `/upload` endpoint.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 检查搜索数据库是否返回包含文件内容的向量，以验证`/upload`端点的功能。
- en: Tip
  id: totrans-556
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: '[Example 11-22](#test_vertical) could also be implemented with a mock `db_client`
    fixture to avoid depending on an external dependency. Instead of checking the
    returned results from the database, you would check if the database client has
    been called to store a correct file and content.'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-22](#test_vertical)也可以使用模拟的`db_client`固定装置来实现，以避免依赖于外部依赖。您不会检查数据库返回的结果，而是检查数据库客户端是否被调用以存储正确的文件和内容。'
- en: Bear in mind, using a mock would only verify that the database client was called
    with the expected parameters, but it would not test the actual database storage
    or retrieval functionality.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，使用模拟器只能验证数据库客户端是否以预期的参数被调用，但它不会测试实际的数据库存储或检索功能。
- en: As you saw in [Example 11-22](#test_vertical), vertical E2E tests check the
    functionality of an application layer by layer—typically working in a linear,
    hierarchical order. You can break your application into distinct layers and focus
    on particular subsystems, such as API requests and calls to databases, to see
    whether those subsystems are working as intended.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[示例 11-22](#test_vertical)中看到的那样，垂直端到端测试按层检查应用程序的功能——通常是按线性、层次顺序工作。您可以将应用程序分解成不同的层，并专注于特定的子系统，例如API请求和对数据库的调用，以查看这些子系统是否按预期工作。
- en: Horizontal E2E tests
  id: totrans-560
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 水平端到端测试
- en: On the other hand, with the horizontal E2E tests, you assume the perspective
    of a user navigating through the functionalities and workflows of the application
    to look for errors, bugs, and other issues. These tests cover the entire application,
    so it’s crucial to have well-constructed and clearly defined workflows to execute
    them effectively. For example, a horizontal E2E test might involve testing the
    user interface, database, and integration with an LLM to verify the functionality
    of a RAG-enabled chatbot from end to end.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，进行水平端到端测试时，您假设用户正在浏览应用程序的功能和工作流程，以寻找错误、缺陷和其他问题。这些测试覆盖整个应用程序，因此拥有良好构建和明确定义的工作流程对于有效地执行它们至关重要。例如，水平端到端测试可能涉及测试用户界面、数据库以及与LLM的集成，以验证RAG启用聊天机器人从端到端的功能。
- en: '[Example 11-23](#test_horizontal) shows what a horizontal test could look like.'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11-23](#test_horizontal)展示了水平测试可能的样子。'
- en: Example 11-23\. Implementing a horizontal E2E to verify the entire RAG Q&A user
    workflow functionality
  id: totrans-563
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-23\. 实现水平端到端测试以验证整个RAG问答用户工作流程功能
- en: '[PRE29]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO21-1)'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_testing_ai_services_CO21-1]'
- en: Verify the file has been uploaded and stored in the database successfully without
    errors.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 验证文件已成功上传并存储在数据库中，且没有错误。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO21-2)'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_testing_ai_services_CO21-2]'
- en: Verify the LLM response to the test question is based on the uploaded file content.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 验证LLM对测试问题的回应是基于上传的文件内容。
- en: Tip
  id: totrans-569
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can write a separate horizontal test to verify that the LLM isn’t referring
    to its internal knowledge or hallucinating. For instance, before uploading the
    file in [Example 11-23](#test_horizontal), the LLM should only respond with “I
    don’t know” if the user asks who “Ali Parandeh” is.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以编写一个单独的水平测试来验证LLM没有引用其内部知识或产生幻觉。例如，在[示例 11-23](#test_horizontal)中上传文件之前，如果用户询问“Ali
    Parandeh”是谁，LLM应该只回应“我不知道”。
- en: Any other results may indicate that the LLM is hallucinating or is using its
    internal knowledge. Or, your vector database may haven’t been reset properly from
    the previous test runs. Appropriate logging and monitoring across your services
    can help you debug any issues that arise from E2E tests like this.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 任何其他结果都可能表明LLM在产生幻觉或使用其内部知识。或者，您的向量数据库可能没有从之前的测试运行中正确重置。在您的服务中适当记录和监控可以帮助您调试此类端到端测试中出现的任何问题。
- en: As you saw in [Example 11-23](#test_horizontal), testing user workflows may
    involve calls to one or multiple endpoints in a sequence and checking for expected
    side effects and results.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[示例 11-23](#test_horizontal)中看到的那样，测试用户工作流程可能涉及按顺序调用一个或多个端点，并检查预期的副作用和结果。
- en: Examples [11-22](#test_vertical) and [11-23](#test_horizontal) should have given
    you more clarity on the purpose of E2E tests, whether vertical or horizontal;
    why they differ from integration tests; and how to design and implement them.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 [11-22](#test_vertical) 和 [11-23](#test_horizontal) 应该已经为你提供了更多关于端到端测试（无论是垂直还是水平）的目的、它们与集成测试的区别、以及如何设计和实现它们的清晰度。
- en: Summary
  id: totrans-574
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered testing AI services in great detail. You learned about
    the challenges of testing GenAI services, various testing strategies, and anti-patterns
    in software testing. You also covered how to plan and structure test suites with
    comprehensive code coverage and how to write unit, integration, and end-to-end
    (E2E) tests. Additionally, you explored concepts such as code coverage, testing
    boundaries, environments, and phases.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细介绍了人工智能服务的测试。你学习了测试GenAI服务的挑战、各种测试策略和软件测试的反模式。你还涵盖了如何规划和组织测试套件以实现全面的代码覆盖率，以及如何编写单元、集成和端到端（E2E）测试。此外，你探讨了代码覆盖率、测试边界、环境和阶段等概念。
- en: You also learned about common testing mistakes, handling asynchronous tests,
    and avoiding flaky tests. You practiced developing test fixtures with setup and
    teardown processes and leveraged parameterization in the `pytest` framework to
    run tests with multiple inputs to verify the robustness of your code. Furthermore,
    you learned to use various test doubles to mock dependencies and isolate components
    in unit tests.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 你还学习了常见的测试错误、处理异步测试以及避免不可靠测试。你练习了使用设置和清理过程开发测试固定装置，并在`pytest`框架中利用参数化运行多个输入的测试，以验证代码的健壮性。此外，你学习了使用各种测试替身来模拟依赖关系并在单元测试中隔离组件。
- en: Later, you were introduced to integration tests and how they verify the interaction
    between pairs of components in your services. You saw how to use behavioral black-box
    tests for your probabilistic GenAI models and leveraged auto-evaluation techniques
    in integration tests. Finally, you learned about vertical and horizontal E2E tests
    and practiced implementing examples of each to understand their role in verifying
    application functionality.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，你了解了集成测试以及它们如何验证服务中组件对之间的交互。你看到了如何为概率性GenAI模型使用行为黑盒测试，并在集成测试中利用自动评估技术。最后，你学习了垂直和水平端到端（E2E）测试，并练习了实现每种测试的示例，以了解它们在验证应用程序功能中的作用。
- en: As mentioned earlier, identifying and implementing tests correctly for AI service
    can be tough. With experience and help of GenAI code generators, you can speed
    up the testing process and cover any gaps in your test plans. If you want to learn
    more, I recommend checking out [Martin Fowler’s blog](https://martinfowler.com)
    and reading tutorials on how to test machine learning models, as concepts covered
    may still be applicable to testing GenAI services.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，为人工智能服务正确识别和实施测试可能很困难。通过经验和GenAI代码生成器的帮助，你可以加快测试过程并填补测试计划中的任何空白。如果你想了解更多，我建议查看[马丁·福勒的博客](https://martinfowler.com)并阅读有关如何测试机器学习模型的教程，因为涉及的概念可能仍然适用于测试GenAI服务。
- en: In the next chapter, you will learn about securing AI services to moderate usage
    and protect them from abuse. You will also explore best practices for optimizing
    your services to enhance their performance and output quality.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何确保人工智能服务的安全性，以规范使用并防止滥用。你还将探索优化服务以提升性能和输出质量的最佳实践。
- en: '^([1](ch11.html#id1148-marker)) Author of *Refactoring: Improving the Design
    of Existing Code* (Addison Wesley, 2018), *Patterns of Enterprise Application
    Architecture* (Addison Wesley, 2002), and many other software engineering books.'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch11.html#id1148-marker)) 《重构：改善既有代码的设计》（Addison Wesley，2018年），《企业应用架构模式》（Addison
    Wesley，2002年）以及许多其他软件工程书籍的作者。
