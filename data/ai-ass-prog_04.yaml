- en: Chapter 3\. Prompt Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章. 提示工程
- en: '*Prompt engineering* is a subfield of machine learning and *natural language
    processing*, which is the study of enabling computers to understand and interpret
    human language. The main goal is to figure out how to talk to *large language
    models*, sophisticated AI systems designed to process and generate human-like
    language responses, in just the right way so they generate the answer we’re looking
    for.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示工程*是机器学习和*自然语言处理*的一个子领域，这是研究使计算机能够理解和解释人类语言的技术。主要目标是找出如何与*大型语言模型*进行交流，这些是设计用来处理和生成类似人类语言响应的复杂AI系统，以正确的方式交流，以便它们生成我们想要的答案。'
- en: 'Think of it like this: You know how when you ask someone for advice, you’ve
    got to give them a bit of context and be clear about what you need? It’s like
    that with LLMs. You’ve got to craft your question or prompt carefully. Sometimes,
    you might even drop some hints or extra information in your question to make sure
    the LLM gets what you’re asking.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：当你向某人寻求建议时，你必须提供一些背景信息，并清楚地说明你需要什么？与LLM交流也是如此。你必须精心构思你的问题或提示。有时，你甚至可以在你的问题中放入一些提示或额外信息，以确保LLM明白你的要求。
- en: This is not just about asking one-off questions either. Sometimes it’s like
    having a whole conversation with the LLM, going back and forth, tweaking your
    questions until you get that golden nugget of information you need.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅仅关乎提出一次性的问题。有时，它就像与LLM进行一场完整的对话，来回交流，调整你的问题，直到你得到所需的那颗黄金信息珍珠。
- en: For instance, let’s say you’re using an AI-assisted programming tool to develop
    a web application. You start by asking how to create a simple user login system
    in JavaScript. The initial response might cover the basics, but then you realize
    you need more advanced features. So, you follow up with more specific prompts,
    asking about incorporating password encryption and connecting to a database securely.
    Each interaction with the AI hones its response, gradually shaping it to fit your
    project’s specific needs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在使用一个AI辅助编程工具来开发一个网络应用程序。你首先询问如何用JavaScript创建一个简单的用户登录系统。最初的回应可能只涉及基础知识，但随后你意识到你需要更高级的功能。因此，你继续提出更具体的提示，询问如何集成密码加密和如何安全地连接到数据库。每次与AI的互动都会使其回应更加精确，逐渐适应你项目的特定需求。
- en: Keep in mind that prompt engineering has become a red-hot job category. According
    to data from [Willis Towers Watson](https://oreil.ly/Qy9Zi), the average yearly
    earnings of a prompt engineer hover around $130,000, though this figure might
    be on the conservative side. To lure top talent, companies often sweeten the deal
    by offering enticing equity packages and bonuses.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，提示工程已经成为一个热门的职业类别。根据[Willis Towers Watson](https://oreil.ly/Qy9Zi)的数据，提示工程师的平均年收入约为130,000美元，尽管这个数字可能有些保守。为了吸引顶尖人才，公司通常会提供有吸引力的股权包和奖金。
- en: In this chapter, we’ll dive deep into the world of prompt engineering and unpack
    helpful strategies and tricks of the trade.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨提示工程的世界，并揭示一些实用的策略和技巧。
- en: Art and Science
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 艺术与科学
- en: Prompt engineering is a mix of art and science. On one hand, you’ve got to choose
    the right words and tone to get the AI to respond the way you want. It’s about
    guiding the conversation in a certain direction. It takes a bit of intuition and
    a creative touch to guide the conversation in a certain direction and refine your
    language, teasing out detailed and nuanced replies.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是艺术与科学的结合。一方面，你必须选择合适的词语和语气，让AI以你想要的方式回应。这是关于引导对话走向特定方向。需要一点直觉和创造力来引导对话走向特定方向，并精炼你的语言，挖掘详细和细微的回复。
- en: Yes, this can be tricky, especially for software developers. Normally, you follow
    a set of rules to write your code, and it either works or the compiler tells you
    what you did wrong. It’s logical and predictable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这可能会有些棘手，尤其是对于软件开发者来说。通常，你遵循一系列规则来编写你的代码，要么它就会工作，要么编译器会告诉你哪里出了错。它是逻辑和可预测的。
- en: But prompt engineering? Not so much. It’s more freeform and unpredictable.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但提示工程？并不那么简单。它更加自由和不可预测。
- en: Then again, there is also quite a bit of science to prompt engineering. You
    need to understand the nuts and bolts of how AI models work, as we discussed in
    [Chapter 2](ch02.html#how_ai_coding_technology_works). Along with creativity,
    you need precision, predictability, and the ability to replicate your results.
    Often this means you’ve got to experiment, try out different prompts, analyze
    the results, and tweak things until you get the right response.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，提示工程也有相当多的科学原理。你需要理解人工智能模型的工作原理的细节，正如我们在[第 2 章](ch02.html#how_ai_coding_technology_works)中讨论的那样。除了创造力，你还需要精确性、可预测性和复制结果的能力。通常这意味着你必须进行实验，尝试不同的提示，分析结果，并调整直到得到正确的响应。
- en: With prompt engineering, don’t expect to find any magic solutions that work
    every time. Sure, there are plenty of courses, videos, and books that claim to
    have all the “secrets” of prompt engineering. But take them with a grain of salt,
    or you might be disappointed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程中，不要期望找到任何每次都有效的神奇解决方案。当然，有很多课程、视频和书籍声称拥有提示工程的“所有秘密”。但请带着怀疑的态度看待它们，否则你可能会感到失望。
- en: Plus, the world of AI and machine learning is always changing, with new models
    and techniques popping up all the time. So, the idea of having one definitive
    technique for prompt engineering? That’s a moving target.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，人工智能和机器学习的世界总是在不断变化，新的模型和技术层出不穷。因此，有一个明确的提示工程技术？这是一个不断变化的目标。
- en: Challenges
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战
- en: Prompt engineering can be frustrating. Even the tiniest change in how you phrase
    your prompt can make a huge difference in what the LLM spits out. This is because
    of the advanced technology under the hood, which is based on probabilistic frameworks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程可能会让人感到沮丧。即使你如何措辞的微小变化也可能在LLM输出的内容上产生巨大的差异。这是因为底层的高级技术是基于概率框架的。
- en: 'Here are some of the challenges with prompt engineering:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是提示工程中的一些挑战：
- en: Wordiness
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇冗长
- en: LLMs can be chatterboxes. Give them a prompt, and they might just run with it,
    giving you a wordy response when all you wanted was a quick answer. They have
    a tendency to throw in a bunch of related ideas or facts, making the response
    longer than necessary. If you’d like an LLM to get straight to the point, just
    ask it to be “concise.”
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可能会成为话唠。给他们一个提示，他们可能会就此展开，给出冗长的响应，而你只想得到一个简短的答案。他们有在响应中加入大量相关想法或事实的倾向，使得响应比必要的更长。如果你想让LLM直接切入要点，只需要求它“简洁”即可。
- en: Non-transferability
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不可迁移性
- en: This means that a prompt that works nicely with one LLM might not be as effective
    with another. In other words, if you’re switching from ChatGPT to Gemini or GitHub
    Copilot, you might need to tweak your prompts due to the unique training, design,
    and specialization of each LLM. Different models are trained on different datasets
    and algorithms, leading to distinct understandings and interpretations of prompts.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着一个与某个LLM配合得很好的提示可能对另一个LLM的效果不佳。换句话说，如果你从ChatGPT切换到Gemini或GitHub Copilot，你可能需要根据每个LLM独特的训练、设计和专业调整你的提示。不同的模型在不同的数据集和算法上训练，导致对提示的理解和解释存在差异。
- en: Length sensitivity
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 长度敏感性
- en: LLMs can get overwhelmed by long prompts and start to overlook or misinterpret
    parts of your input. It’s as if the LLM’s attention span falters and its responses
    become somewhat distracted. This is why you should avoid providing detailed requirements
    in your prompts; keep a prompt to less than a page.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 长提示可能会让大型语言模型（LLM）感到不知所措，开始忽略或误解你的输入的一部分。这就像LLM的注意力范围减弱，其响应变得有些分心。这就是为什么你应该避免在提示中提供详细要求；将提示保持在一页以内。
- en: Ambiguity
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊性
- en: If your prompt is unclear, the LLM might get confused and serve up responses
    that are way off base or just plain make-believe. Clarity is key.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的提示不清晰，LLM可能会感到困惑，并给出离题甚远或纯粹是虚构的响应。清晰是关键。
- en: Despite all this, there are ways to improve the results. And we’ll cover these
    approaches in the rest of this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，还是有方法可以提高结果。我们将在本章的剩余部分介绍这些方法。
- en: The Prompt
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示
- en: You can think of a prompt as having four main components, which you can see
    in [Figure 3-1](#a_prompt_has_four_main_componentsdot).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将提示视为包含四个主要组成部分，你可以在[图 3-1](#a_prompt_has_four_main_componentsdot)中看到。
- en: '![](assets/aiap_0301.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aiap_0301.png)'
- en: Figure 3-1\. A prompt has four main components
  id: totrans-29
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 提示包含四个主要组成部分
- en: First, the *context* specifies the persona or role for the LLM to take when
    providing a response. Next, there are the *instructions*, such as to summarize,
    translate, or classify. Then there is the *input of content* if you want the LLM
    to process information to create a better response. Finally, you can show how
    you want the output *formatted*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，*上下文*指定了LLM在提供回答时应扮演的角色或角色。接下来是*指令*，例如摘要、翻译或分类。然后是*内容输入*，如果你想让LLM处理信息以创建更好的回答。最后，你可以展示你希望输出的*格式*。
- en: Keep in mind that you do not need all of these components. In fact, you might
    need just one to get a good response. But as a general rule, it’s better to provide
    the LLM with more concrete details.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，你不需要所有这些组件。事实上，你可能只需要一个就能得到一个好的回答。但作为一般规则，向LLM提供更多具体细节会更好。
- en: Let’s now look at each of the components.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来看看每个组成部分。
- en: Context
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文
- en: You’ll often begin your prompt with a sentence or two that provide context.
    Often, you’ll specify the role or persona you want the AI to take on when providing
    the response. This leads to responses that are not only more accurate but also
    contextually relevant, ensuring a more meaningful result.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常会以一句或两句提供上下文的句子开始你的提示。通常，你会指定AI在提供回答时想要扮演的角色或人格。这会导致不仅更准确，而且与上下文相关的回答，从而确保结果更有意义。
- en: 'For instance, if you want to debug a piece of code, you might use this as the
    context:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你想调试一段代码，你可能使用以下作为上下文：
- en: '*Prompt:* You are an experienced software engineer specializing in debugging
    Java applications.'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你是一位经验丰富的软件工程师，专长于调试Java应用程序。'
- en: 'Or suppose you want to learn about optimization techniques for a particular
    algorithm. You could set the stage by stating:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 或者假设你想了解特定算法的优化技术。你可以通过以下方式设定场景：
- en: '*Prompt:* You are a senior software developer with expertise in algorithm optimization.'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你是一位在算法优化方面有专长的资深软件开发者。'
- en: Adding context helps the LLM approach your prompt with the right mindset.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 添加上下文有助于LLM以正确的思维方式来处理你的提示。
- en: Instructions
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指令
- en: Your prompt should include at least one clear instruction. There’s nothing stopping
    you from adding more instructions, but you need to be careful. Loading up your
    prompt with a bunch of queries can throw the LLM for a loop and make it harder
    to get the answer you’re looking for.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你的提示应该至少包含一个明确的指令。没有阻止你添加更多指令，但你需要小心。如果你的提示中包含大量查询，可能会让LLM感到困惑，并使你更难得到你想要的答案。
- en: Let’s break down why that happens. First off, when you have multiple instructions,
    things can get a bit fuzzy. If they’re not clear or if they seem to clash with
    each other, the LLM might get confused about which one to focus on or how to balance
    them all out.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下为什么会这样。首先，当你有多个指令时，事情可能会变得有些模糊。如果它们不清楚或似乎相互冲突，LLM可能会对应该关注哪个指令或如何平衡它们感到困惑。
- en: Next, having more instructions means more for the LLM to juggle. It’s got to
    process and understand each part of your prompt and then figure out how to weave
    all the parts into a coherent response. That’s a lot of mental gymnastics, and
    sometimes it can lead to mistakes or answers that are off.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，更多的指令意味着LLM需要处理的内容更多。它必须处理并理解你的提示的每一部分，然后找出如何将这些部分编织成一个连贯的回答。这是一项大量的心智体操，有时可能会导致错误或偏离正确答案的回答。
- en: And don’t forget, LLMs go through instructions one at a time, in order. So,
    the way you line up those queries can influence how they’re interpreted and what
    kind of answer you get back.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记，LLMs是按顺序逐条处理指令的。因此，你排列查询的方式可能会影响它们的解释以及你得到的答案类型。
- en: Given all this, a pro tip is to keep it simple. Instead of throwing a whole
    list of questions at the LLM all at once, try breaking them down into a series
    of smaller prompts. It’s like having a back-and-forth chat instead of delivering
    a monologue.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，一个专业的小贴士是保持简单。不要一次性向LLM抛出一大堆问题，试着将它们分解成一系列较小的提示。这就像进行一场对话而不是发表独白。
- en: There are also numerous types of instructions for a prompt. In the next few
    sections, we’ll discuss some of the main instructions used in software development.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于提示，也有许多种类的指令。在接下来的几节中，我们将讨论软件开发中使用的某些主要指令。
- en: Summarization
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Summarization can condense a longer piece of text into a shorter version while
    keeping the main ideas and points intact. This is useful for quickly getting a
    handle on lengthy documents. For a software developer, summarization can be an
    especially handy tool in the scenarios listed in [Table 3-1](#summarization_prompts_for_coding_tasks).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总结可以将较长的文本压缩成更短的形式，同时保持主要思想和观点不变。这对于快速了解冗长的文档非常有用。对于软件开发者来说，总结可以在[表 3-1](#summarization_prompts_for_coding_tasks)中列出的场景中特别有用。
- en: Table 3-1\. Summarization prompts for coding tasks
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. 编码任务的总结提示
- en: '| Use case | Description | Example prompt |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 用例 | 描述 | 示例提示 |'
- en: '| --- | --- | --- |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Code documentation | Provides a concise overview of extensive documentation
    highlighting key functionalities, dependencies, and structures. | “Summarize the
    main points of the following documentation to provide a quick overview of the
    codebase.” |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 代码文档 | 提供对大量文档的简洁概述，突出关键功能、依赖和结构。| “总结以下文档的主要观点，以快速了解代码库。”|'
- en: '| Bug reports | Quickly identifies the main issues reported by users in numerous
    or lengthy bug reports. | “Summarize the common issues reported in the following
    bug reports to identify the main problems to be addressed.” |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 缺陷报告 | 快速识别用户在大量或冗长的缺陷报告中报告的主要问题。| “总结以下缺陷报告中报告的常见问题，以确定要解决的主要问题。”|'
- en: '| Research papers | Extracts succinct insights from lengthy research papers
    or technical articles to update the user on the latest research or technologies.
    | “Provide a summary of the key findings and technologies discussed in the following
    research paper.” |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 研究论文 | 从冗长的研究论文或技术文章中提取简洁的见解，以更新用户对最新研究或技术的了解。| “提供以下研究论文中讨论的关键发现和技术的总结。”|'
- en: '| Change logs | Enables an understanding of the key changes in a new version
    of a software library or tool from lengthy change logs. | “Summarize the key changes
    in the following change log of version 1.1.2.” |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 变更日志 | 通过变更日志理解软件库或工具新版本中的关键变更。| “总结以下1.1.2版本变更日志中的关键变更。”|'
- en: '| Email threads | Extracts the key points of discussions or decisions from
    long email threads. | “Summarize the main points of discussion from the following
    email thread.” |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 邮件线程 | 从长篇邮件线程中提取讨论或决策的关键点。| “总结以下邮件线程中的主要讨论要点。”|'
- en: 'Another type of summarization is *topic modeling*, in which a statistical model
    discovers the abstract “topics” that occur in a collection of documents. Here
    are some topic-modeling prompts for developers:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种类型的总结是 *主题建模*，其中统计模型发现文档集合中出现的抽象“主题”。以下是一些为开发者提供的主题建模提示：
- en: '*Prompt:* Identify the main topics discussed in the following text: {text}'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 识别以下文本中讨论的主要主题：{文本}'
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Extract the keywords from the following text to infer the main topics:
    {text}'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 从以下文本中提取关键词，以推断主要主题：{文本}'
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Suggest tags for the following text based on its content: {text}'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 根据以下文本的内容建议标签：{文本}'
- en: Text Classification
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本分类
- en: '*Text classification* involves giving a computer a bunch of text that it learns
    to tag with labels. A flavor of this is *sentiment analysis*, such as when you
    have a list of social media posts and the LLM figures out which have a positive
    or negative connotation. For developers, sentiment analysis can be a useful tool
    to gauge user feedback about an application.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*文本分类* 涉及向计算机提供大量文本，使其学会用标签进行标记。其中一种类型是 *情感分析*，例如当你有一系列社交媒体帖子，LLM 确定哪些具有正面或负面含义时。对于开发者来说，情感分析可以是一个有用的工具，以衡量用户对应用程序的反馈。'
- en: 'Some sample prompts include:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一些示例提示包括：
- en: '*Prompt:* Can you analyze these customer reviews and tell me if the sentiment
    is generally positive, negative, or neutral? {text}'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你能分析这些客户评论并告诉我整体情绪是正面、负面还是中性吗？{文本}'
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Here’s a thread from our user forum discussing the latest update.
    Could you summarize the overall sentiment for me? {text}'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 这里是我们用户论坛上关于最新更新的一个讨论线程。你能为我总结一下整体情绪吗？{文本}'
- en: ''
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* I’ve compiled a list of feedback from our app store page. Can you
    categorize the comments by sentiment? {text}'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 我已经整理了我们应用商店页面上的反馈列表。你能根据情感对评论进行分类吗？{文本}'
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Evaluate the sentiment of these blog post comments regarding our
    product announcement. What’s the consensus? {text}'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 评估这些关于我们产品发布的博客评论的情感，共识是什么？{文本}'
- en: Recommendation
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐
- en: You can instruct an LLM to provide recommendations. Developers can use such
    feedback to improve the caliber of responses for activities like squashing bugs,
    refining code, or using APIs more effectively.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以指示大型语言模型提供建议。开发者可以使用这样的反馈来提高诸如修复错误、改进代码或更有效地使用 API 等活动的响应质量。
- en: 'Check out these example prompts you might use:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下你可能使用的示例提示：
- en: '*Prompt:* The following code snippet is throwing a NullPointerException when
    I try to call <*Method()*>. Can you help identify the potential cause and suggest
    a fix?'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 当我尝试调用 <*Method()*> 时，以下代码片段抛出 NullPointerException。你能帮助识别潜在的原因并提出修复建议吗？'
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Here is a function I wrote to sort a list of integers. Can you recommend
    any optimizations to make it run faster or be more readable?'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 这里有一个我编写的用于排序整数列表的函数。你能推荐任何优化使其运行更快或更易读的建议吗？'
- en: LLM recommendations can be a powerful accelerator for your work, greatly saving
    time and providing ideas you may not have thought about. This technique is particularly
    beneficial when dealing with intricate or nuanced tasks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）的建议可以成为你工作的强大加速器，大大节省时间并提供你可能没有考虑过的想法。这种技术在处理复杂或微妙任务时尤其有益。
- en: But there are downsides. One potential hitch is that the LLM might boil down
    the responses too much and miss the nuances. Also, keep in mind that the model’s
    knowledge is frozen at a certain point in time, so it might not be up-to-date
    with the latest information or trends.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 但也存在一些缺点。一个潜在的问题是大型语言模型可能会过度简化响应并错过细微差别。此外，请记住，该模型的知识在某个时间点被冻结，因此可能无法跟上最新的信息或趋势。
- en: If anything, recommendations are a way to kick things off. But you’ll want to
    dive in and do some more digging on your own to get the full picture.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有什么的话，建议是一种开始的方式。但你会想深入挖掘并自己做一些更多的工作，以获得完整的画面。
- en: Translation
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻译
- en: '*Localization* is essentially attuning the software to the linguistic and cultural
    norms of a specific area. It allows your software to speak the local lingo and
    understand regional quirks, an ability that is key to broadening your market and
    cultivating a closer connection with your audience. This can lead to a ripple
    effect of benefits: users are happier because the software feels tailor-made for
    them, and happy users can mean a healthier bottom line for your business.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*本地化* 实质上是指调整软件以适应特定地区的语言和文化规范。它使你的软件能够说当地的语言并理解地区的特殊之处，这种能力对于扩大市场和与受众建立更紧密的联系至关重要。这可以带来一系列的连锁反应：用户因为软件感觉是为他们量身定做的而感到高兴，而快乐的用户可能意味着你的业务有更健康的财务状况。'
- en: In competitive markets, localization can give you an edge when alternatives
    fall short or simply don’t exist. Plus, by aligning your software with the local
    ways, including compliance with regional regulations, you’re not just making your
    software one option but often the only option for a market.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在竞争激烈的市场中，当替代品不足或根本不存在时，本地化可以为你提供优势。此外，通过使你的软件与当地方式一致，包括遵守地区法规，你不仅是在提供一个软件选项，而且往往是市场唯一的选择。
- en: On the flip side, localization is not without its challenges. It can be both
    expensive and time intensive. It requires meticulous quality assurance to maintain
    the software’s integrity in different languages. Additionally, software development
    doesn’t stand still. It’s a continuous cycle of updates and new features, each
    of which may require its own set of localization efforts. This ongoing process
    adds layers of complexity and additional costs to the project.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，本地化并非没有挑战。它可能既昂贵又耗时。它需要细致的质量保证，以保持软件在不同语言中的完整性。此外，软件开发不会停滞不前。它是一个不断更新和新功能出现的循环，每个新功能可能都需要自己的本地化工作。这个持续的过程增加了项目的复杂性和额外的成本。
- en: This is where LLMs can come to the rescue. Advanced systems are capable of translating
    between numerous languages. They can serve as a powerful tool in a developer’s
    toolkit. [Table 3-2](#examples_of_prompts_for_language_transla) shows some prompts
    you might use for localization.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是大型语言模型可以大显身手的地方。高级系统能够翻译多种语言之间的内容。它们可以作为开发者工具箱中的强大工具。[表 3-2](#examples_of_prompts_for_language_transla)
    展示了一些你可能用于本地化的提示。
- en: Table 3-2\. Examples of prompts for language translation
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-2\. 语言翻译的提示示例
- en: '| Task type | Description | Sample prompt |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 任务类型 | 描述 | 样本提示 |'
- en: '| --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| UI text translation | Translates buttons, menu items, error messages, dialog
    boxes, etc. | “Translate the following UI text into French: Save, Exit, File,
    Edit, Help.” |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| UI文本翻译 | 翻译按钮、菜单项、错误消息、对话框等 | “将以下UI文本翻译成法语：保存、退出、文件、编辑、帮助。” |'
- en: '| Documentation translation | Translates user guides, help files, and other
    documentation. | “Translate the following user manual paragraph into Spanish.”
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 文档翻译 | 翻译用户指南、帮助文件和其他文档。 | “将以下用户手册段落翻译成西班牙语。” |'
- en: '| Error message translation | Translates error messages that the software might
    generate. | “Translate the following error messages into German: File not found,
    Access denied, Network connection lost.” |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 错误消息翻译 | 翻译软件可能生成的错误消息。 | “将以下错误消息翻译成德语：文件未找到、访问被拒绝、网络连接丢失。” |'
- en: '| Tooltip translation | Translates tooltips that provide additional information
    when a user hovers over an item. | “Translate the following tooltips into Japanese:
    Click to save, Click to open a new file, Click to print.” |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 工具提示翻译 | 翻译当用户将鼠标悬停在项目上时提供额外信息的工具提示。 | “将以下工具提示翻译成日语：点击保存、点击打开新文件、点击打印。”
    |'
- en: Even so, it’s crucial to approach the multilingual capabilities of LLMs with
    a degree of caution. They aren’t foolproof. These models may sometimes miss the
    subtleties, idiomatic expressions, and cultural contexts unique to a language.
    The nuances of language are complex, and getting them right is about more than
    just direct translation—it’s about conveying the right meaning in the right way.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 即使如此，以一定程度的谨慎来处理LLM的多语言能力是至关重要的。它们并非万无一失。这些模型有时可能会错过语言特有的细微差别、惯用语和文化背景。语言的细微差别很复杂，正确传达不仅仅是直接翻译——它还关乎以正确的方式传达正确的意义。
- en: Handling specific terms or names can be tricky, especially when there isn’t
    a neat equivalent in another language. Then there’s the challenge of getting the
    tone and style right. It’s not just about the words but how you say them, and
    this can change a lot from one language or culture to the next.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 处理特定的术语或名称可能很棘手，尤其是在另一种语言中没有合适的对应词时。然后还有正确把握语气和风格挑战。这不仅仅是关于单词，还关乎你如何表达，这可能会因语言或文化而大相径庭。
- en: Having a language specialist take a look at the output could save you some headaches
    down the line.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让语言专家检查输出可能会在将来节省你一些麻烦。
- en: Input of Content
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内容输入
- en: When crafting prompts, it’s helpful to use special symbols like `###` or `"""`
    to clearly separate your instructions from the content or information you want
    the LLM to work on. These symbols act like boundaries or markers, making it clear
    where the instructions end and where the content begins.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建提示时，使用特殊符号如`###`或`"""`来清楚地分隔你的指令和LLM需要处理的内容或信息是有帮助的。这些符号就像边界或标记，清楚地表明指令在哪里结束，内容在哪里开始。
- en: 'Consider a scenario in which a software developer needs help summarizing key
    points from a lengthy piece of documentation regarding a new API they are integrating.
    Here’s how you could structure the prompt:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个场景，其中软件开发者需要帮助总结关于他们正在集成的新的API的详细文档中的关键点。以下是如何构建提示的示例：
- en: '*Prompt:* Extract the key implementation steps for the API from the text below:'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 从以下文本中提取API的关键实现步骤：'
- en: ''
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Documentation: `"""`'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文档：`""`
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '{API documentation text here}'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{API文档文本在这里}'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`"""`'
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`""`'
- en: Using the `"""` delimiters is a neat way to split the instruction from the API
    documentation text. It gives the LLM a clearer picture of what needs to be done
    and increases the chances of getting a crisp summary of the main steps. Plus,
    these delimiters tidy up the prompt, making it easier to read, which is a real
    lifesaver for longer or more complex text inputs.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`"""`分隔符是一种巧妙的方式来将指令与API文档文本分开。这给LLM一个更清晰的了解需要做什么，并增加了获得清晰总结主要步骤的机会。此外，这些分隔符使提示更加整洁，便于阅读，这对于较长的或更复杂的文本输入来说真是一个救星。
- en: Format
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 格式
- en: 'In your prompt, you can tell the LLM how to format the output. Here’s an example:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的提示中，你可以告诉LLM如何格式化输出。以下是一个示例：
- en: '*Prompt:* Create a Python function that takes a list of user objects (each
    object containing a user’s ID and name) and returns a JSON object that maps user
    IDs to names. Format the output as JSON.'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 编写一个Python函数，该函数接受一个用户对象列表（每个对象包含一个用户的ID和姓名）并返回一个将用户ID映射到姓名的JSON对象。以JSON格式输出。'
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*ChatGPT:*'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ChatGPT:*'
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There are other ways you can format the output. [Table 3-3](#prompts_for_formatting_output)
    shows some options.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以用其他方式格式化输出。[表3-3](#prompts_for_formatting_output)显示了某些选项。
- en: Table 3-3\. Prompts for formatting output
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-3\. 格式化输出的提示
- en: '| Format type | Sample prompt |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 格式类型 | 样本提示 |'
- en: '| --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Table | “Create a table comparing the syntax, performance, and use cases
    of Python, Java, and C++.” |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 表格 | “创建一个比较 Python、Java 和 C++ 语法、性能和用例的表格。” |'
- en: '| List | “List the steps to troubleshoot a slow-loading web page.” |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 列表 | “列出解决加载缓慢的网页的步骤。” |'
- en: '| Markdown/HTML | “Explain the differences between GET and POST HTTP methods
    in Markdown.” |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Markdown/HTML | “用 Markdown 解释 GET 和 POST HTTP 方法之间的区别。” |'
- en: '| Text hierarchy | “Provide a structured outline of the software development
    life cycle (SDLC), including its phases and key activities in each phase.” |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 文本层次结构 | “提供一个软件开发生命周期（SDLC）的结构化大纲，包括其各个阶段和每个阶段的关键活动。” |'
- en: '| LaTeX formatting | “Express the time complexity of the binary search algorithm
    in LaTeX notation.” |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| LaTeX 格式化 | “用 LaTeX 符号表示二分搜索算法的时间复杂度。” |'
- en: With a prompt, you can also specify the length of the response. You could guide
    the LLM with an instruction such as “Provide a brief summary” or “Write a detailed
    explanation.” Or you could be more specific, such as by saying that the response
    should be no more than 300 words. The LLM may exceed the word limit you provide,
    but it will at least be in the general vicinity.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提示，你还可以指定响应的长度。你可以用指令如“提供一个简短的摘要”或“写一个详细的解释”来引导 LLM。或者你可以更加具体，比如说响应不应超过 300
    个单词。LLM 可能会超过你提供的字数限制，但至少会在大致范围内。
- en: Best Practices
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳实践
- en: We’ll next take a look at some of the best practices for cooking up prompts
    that will help get the answers you want. But don’t take these as gospel. These
    suggestions are more like general advice—which can be somewhat subjective—than
    hard-and-fast rules. As you spend more time chatting with LLMs, you’ll probably
    stumble upon your own helpful ways of asking questions that work for you. It’s
    all part of the journey of prompt engineering.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来将探讨一些制作提示的最佳实践，这些提示将有助于获得你想要的答案。但不要把这些当作圣旨。这些建议更像是普遍的建议——可能有些主观——而不是铁的规则。随着你与大型语言模型（LLM）聊天时间的增加，你可能会偶然发现对你自己有帮助的提问方式。这都是提示工程旅程的一部分。
- en: Be Specific
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具体化
- en: Crafting the right prompts can be like finding the sweet spot in a good conversation,
    and it’s maybe the most crucial step to hitting it off with these text-generating
    systems. The more details, the better. You also need to be clear. Otherwise, the
    LLM may make assumptions or even hallucinate.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 构建正确的提示就像在良好对话中找到甜点，这可能是与这些文本生成系统建立联系的最关键步骤。细节越多越好。你还需要清晰。否则，LLM 可能会做出假设，甚至产生幻觉。
- en: First, let’s take a look at some prompts that are too vague.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看一些过于模糊的提示。
- en: '*Prompt:* Develop a feature to enhance data security.'
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 开发一个增强数据安全性的功能。'
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Can you build a tool to automate the process?'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你能构建一个自动化此过程的工具吗？'
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Optimize the code.'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 优化代码。'
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* We need a function to process transactions.'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 我们需要一个处理交易的功能。'
- en: 'The following are much more detailed and should get better results:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容更为详细，应该能获得更好的结果：
- en: '*Prompt:* Develop a Python function to parse dates from strings. The function
    should be able to handle the formats YYYY-MM-DD, MM/DD/YYYY, and Month DD, YYYY.
    It should return a datetime object. Provide a script that demonstrates the function
    handling at least three examples of each format correctly, along with a document
    explaining any dependencies, the logic used in the function, and instructions
    on how to run the script.'
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 开发一个 Python 函数，从字符串中解析日期。该函数应能够处理 YYYY-MM-DD、MM/DD/YYYY 和 月 DD, YYYY
    的格式。它应返回一个 datetime 对象。提供一个脚本，演示该函数正确处理至少三种格式的三个示例，以及一个文档，解释任何依赖项、函数中使用的逻辑以及如何运行脚本的说明。'
- en: ''
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Prompt:* Develop a SQL query to retrieve from our database a list of customers
    who made purchases above $500 in the last quarter of 2023\. The query should return
    the customer’s full name, their email address, the total amount spent, and the
    date of their last purchase. The results should be sorted by the total amount
    spent in descending order. Please ensure that the query is optimized for performance.'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 编写一个 SQL 查询，从我们的数据库中检索出在 2023 年最后一个季度购买金额超过 500 美元的客户列表。查询应返回客户的完整姓名、他们的电子邮件地址、总消费金额以及他们最后一次购买日期。结果应按总消费金额降序排序。请确保查询已针对性能进行优化。'
- en: Acronyms and Technical Terms
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩写和技术术语
- en: It’s crucial to be clear with technical terms and acronyms while drafting a
    prompt. This jargon often means different things in different contexts and can
    lead to unhelpful responses. Thus, it’s a good idea to spell out acronyms and
    give clear definitions or explanations of any technical terms used.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写提示时，对技术术语和缩写词要清晰明确。这些术语在不同的上下文中可能有不同的含义，可能导致不恰当的回应。因此，最好将缩写词拼写出来，并对任何使用的术语给出清晰的定义或解释。
- en: 'For example, suppose you are using ChatGPT to help resolve a database connection
    issue. A poorly crafted prompt might be:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在使用 ChatGPT 帮助解决数据库连接问题。一个制作不佳的提示可能是：
- en: '*Prompt:* Having DB connection issues. How to fix it?'
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 存在数据库连接问题。如何修复它？'
- en: In this prompt, “DB” is ambiguous as it might refer to different database systems
    like MySQL, PostgreSQL, or others, and the nature of the connection issue is not
    clarified.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个提示中，“DB”是模糊的，因为它可能指代不同的数据库系统，如 MySQL、PostgreSQL 或其他，并且连接问题的性质没有明确说明。
- en: 'A more effective prompt would be:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更有效的提示会是：
- en: '*Prompt:* I am encountering a connection timeout issue while trying to connect
    to my PostgreSQL database using JDBC. How can I resolve this?'
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 我在尝试使用 JDBC 连接到我的 PostgreSQL 数据库时遇到了连接超时问题。我该如何解决这个问题？'
- en: This prompt clearly spells out the database system in use, the method of connection,
    and the specific issue encountered.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示清楚地说明了正在使用的数据库系统、连接方法以及遇到的具体问题。
- en: Note
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Mark Twain once [wrote](https://oreil.ly/ZL9d6), “The difference between the
    almost right word and the right word is really a large matter. ’Tis the difference
    between the lightning bug and the lightning.” In a way, the same thing can be
    said about writing a prompt.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 马克·吐温曾经 [写道](https://oreil.ly/ZL9d6)，“几乎正确的词和正确的词之间的区别真的是一个很大的问题。那就是萤火虫和闪电之间的区别。”在某种程度上，同样的话也可以用来描述编写提示。
- en: Zero- and Few-Shot Learning
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本和少样本学习
- en: With *zero-shot learning*, you provide one prompt and get the answer you want.
    Often, this works fine. But given the complexities of programming languages and
    frameworks, there are times when you need to nudge the LLM.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *零样本学习* 中，你提供一个提示并得到你想要的答案。通常这很有效。但考虑到编程语言和框架的复杂性，有时你需要稍微推动一下 LLM。
- en: You can do this with *few-shot learning*. This refers to an LLM’s capability
    to understand and perform a task with very few examples or training data. This
    is a significant advantage over traditional machine learning models, which may
    require a large amount of training data to perform adequately on a task. The LLM’s
    capability is primarily due to the extensive pretraining on a diverse range of
    internet text that the LLM undergoes before it is fine-tuned for a specific task.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用 *少样本学习* 来做到这一点。这指的是 LLM 在非常少的示例或训练数据的情况下理解和执行任务的能力。这比传统机器学习模型在执行任务时需要大量训练数据具有显著优势。LLM
    的这种能力主要归因于在特定任务微调之前，LLM 在广泛多样的互联网文本上的大量预训练。
- en: Let’s take a look at an example of few-shot learning. Consider a scenario in
    which we want to generate a function that normalizes a given list of numbers.
    It will scale the values in the list to a range of [0, 1]. In the instructions,
    we include a list of a few examples of the inputs and normalized outputs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看少样本学习的一个例子。考虑一个场景，我们想要生成一个函数，该函数将给定的数字列表归一化。它将列表中的值缩放到[0, 1]的范围。在说明中，我们包括了一些输入和归一化输出的示例列表。
- en: '*Prompt:* Based on the following examples of normalizing a list of numbers
    to a range of [0, 1]:'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 基于以下将数字列表归一化到[0, 1]范围的示例：'
- en: ''
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '1\. Input: [2, 4, 6, 8] Output: [0, 0.3333, 0.6667, 1]'
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1. 输入：[2, 4, 6, 8] 输出：[0, 0.3333, 0.6667, 1]
- en: ''
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. Input: [5, 10, 15] Output: [0, 0.5, 1]'
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2. 输入：[5, 10, 15] 输出：[0, 0.5, 1]
- en: ''
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. Input: [1, 3, 2] Output: [0, 1, 0.5]'
  id: totrans-161
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3. 输入：[1, 3, 2] 输出：[0, 1, 0.5]
- en: ''
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Generate a function in Python that takes a list of numbers as input and returns
    a list of normalized numbers.
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 Python 中生成一个函数，该函数接受一个数字列表作为输入，并返回一个归一化数字列表。
- en: 'ChatGPT will “learn” from the data and come up with some code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 将“学习”数据并生成一些代码：
- en: '*ChatGPT:*'
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ChatGPT:*'
- en: ''
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Leading Words
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引导词
- en: 'The concept of *leading words* refers to specific keywords or phrases that
    can guide an LLM toward creating a particular kind of output. Sometimes you can
    achieve the desired result using just one code word. Here’s an example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*引导词*的概念指的是可以引导一个 LLM 生成特定类型输出的特定关键词或短语。有时只需一个代码词就能达到预期的结果。以下是一个例子：'
- en: '*Prompt:*'
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:*'
- en: ''
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Create a simple Python function that
  id: totrans-172
  prefs:
  - PREF_BQ
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个简单的 Python 函数，
- en: ''
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 1\. Prompts me for a temperature in Fahrenheit
  id: totrans-174
  prefs:
  - PREF_BQ
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 询问华氏温度
- en: ''
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. Converts Fahrenheit to Celsius
  id: totrans-176
  prefs:
  - PREF_BQ
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 将华氏温度转换为摄氏度
- en: ''
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: def
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: def
- en: Using the word *def* as a leading word informs the model that it should begin
    writing a Python function. [Table 3-4](#examples_of_leadinghyphenword_prompts)
    gives more examples of leading words.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单词*def*作为领先词通知模型它应该开始编写Python函数。[表 3-4](#examples_of_leadinghyphenword_prompts)提供了更多领先词的例子。
- en: Table 3-4\. Examples of leading-word prompts
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-4\. 领先词提示示例
- en: '| Context | Leading word |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 上下文 | 领先词 |'
- en: '| --- | --- |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| JavaScript function | Function |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript 函数 | 函数 |'
- en: '| HTML element | <button |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| HTML 元素 | <button |'
- en: '| CSS styling | P { |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| CSS 样式 | P { |'
- en: '| SQL insert query | INSERT INTO |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| SQL 插入查询 | INSERT INTO |'
- en: '| Java method creation | public |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| Java 方法创建 | public |'
- en: Chain of Thought (CoT) Prompting
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链（CoT）提示
- en: In 2022, some Google researchers introduced *chain-of-thought (CoT) prompting*
    in their paper [“Chain-of-Thought Prompting Elicits Reasoning in Large Language
    Models”](https://arxiv.org/abs/2201.11903). This approach enhances the reasoning
    abilities of LLMs by breaking down a complex problem into different steps. It’s
    actually similar to few-shot learning, which allows for nudging the model.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年，一些谷歌研究人员在他们的论文[“Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models”](https://arxiv.org/abs/2201.11903)中介绍了*思维链（CoT）提示*。这种方法通过将复杂问题分解为不同的步骤来增强LLM的推理能力。实际上，这与少样本学习类似，它允许引导模型。
- en: CoT prompting can be very useful in software code generation tasks. Let’s look
    at an example. Suppose you want to create a web application with a user registration
    and login functionality using Flask, a Python web framework. [Table 3-5](#chainhyphenofhyphenthought_prompt_exampl)
    shows the CoT prompting steps.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: CoT提示在软件代码生成任务中非常有用。让我们看看一个例子。假设你想使用Flask，一个Python网络框架，创建一个具有用户注册和登录功能的网络应用程序。[表
    3-5](#chainhyphenofhyphenthought_prompt_exampl)显示了CoT提示步骤。
- en: Table 3-5\. Chain-of-thought prompt examples
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-5\. 思维链提示示例
- en: '| Action description | Prompt |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 动作描述 | 提示 |'
- en: '| --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Understand the requirement | “I need to create a web application using Flask.
    The application should have a user registration and login functionality. Where
    should I start?” |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 理解需求 | “我需要使用Flask创建一个网络应用程序。该应用程序应具有用户注册和登录功能。我应该从哪里开始？” |'
- en: '| Set up Flask application | “Let’s begin by setting up a basic Flask application.
    How can I do that?” |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 设置Flask应用程序 | “让我们从设置一个基本的Flask应用程序开始。我该如何做？” |'
- en: '| Create user model | “Now that the Flask application is set up, I need to
    create a user model for handling registration and login. How should I structure
    this model?” |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 创建用户模型 | “现在Flask应用程序已经设置好了，我需要创建一个用户模型来处理注册和登录。这个模型应该如何构建？” |'
- en: '| Implement registration | “With the user model in place, how can I implement
    a registration page with the necessary fields?” |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 实现注册 | “用户模型已经就位，我如何实现一个包含必要字段的注册页面？” |'
- en: '| Implement login | “Now let’s move on to creating a login page. How can I
    ensure secure login?” |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 实现登录 | “现在让我们继续创建登录页面。我如何确保登录的安全性？” |'
- en: '| Session management | “After a user logs in, how should I manage user sessions
    to keep users logged in as they navigate through the app?” |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 会话管理 | “用户登录后，我应该如何管理用户会话，以保持用户在浏览应用时的登录状态？” |'
- en: '| Logout implementation | “Finally, how can I implement a logout function to
    securely log users out of the application?” |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 注销实现 | “最后，我如何实现一个安全注销功能，让用户能够安全地从应用程序中注销？” |'
- en: Leading Questions
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 领先问题
- en: Leading questions in a prompt can often fetch wonky responses from the LLM.
    It’s better to stay neutral and unbiased. Also, it’s good practice to avoid making
    assumptions; spell things out instead.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 提示中的领先问题往往会从LLM那里获取古怪的回答。保持中立和无偏见更好。此外，避免做出假设也是良好的实践；把事情说清楚。
- en: 'This prompt is a leading question:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示是一个领先问题：
- en: '*Prompt:* Isn’t it true that migrating to a microservices architecture will
    always improve system scalability?'
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 迁移到微服务架构是否会始终提高系统可扩展性？'
- en: 'A more balanced prompt would be:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更平衡的提示可能是：
- en: '*Prompt:* What are the advantages and potential challenges of migrating to
    a microservices architecture in terms of system scalability?'
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 迁移到微服务架构在系统可扩展性方面有哪些优势和潜在挑战？'
- en: Ask for Examples and Analogies
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 请求示例和类比
- en: 'Suppose you don’t know the concept of inheritance in object-oriented programming.
    You go to ChatGPT and enter this prompt:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你不知道面向对象编程中继承的概念。你前往ChatGPT并输入这个提示：
- en: '*Prompt:* Explain inheritance that is used in object-oriented programming.'
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Prompt:* Explain inheritance that is used in object-oriented programming.'
- en: 'You will get a detailed response. But you may want to get something that’s
    easier to understand. A good way to do this is by asking the LLM for an analogy:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'You will get a detailed response. But you may want to get something that’s
    easier to understand. A good way to do this is by asking the LLM for an analogy:'
- en: '*Prompt:* Explain inheritance that is used in object-oriented programming by
    using an analogy.'
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Prompt:* Explain inheritance that is used in object-oriented programming by
    using an analogy.'
- en: ''
  id: totrans-212
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*ChatGPT:* Think of inheritance like a family tree, where children inherit
    certain traits and properties from their parents and, potentially, grandparents.'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ChatGPT:* Think of inheritance like a family tree, where children inherit
    certain traits and properties from their parents and, potentially, grandparents.'
- en: From there, ChatGPT provides more detail, which proceeds from the analogy, to
    explain the key elements of inheritance.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: From there, ChatGPT provides more detail, which proceeds from the analogy, to
    explain the key elements of inheritance.
- en: Reducing Hallucinations
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Reducing Hallucinations
- en: In [Chapter 2](ch02.html#how_ai_coding_technology_works), we learned that prompting
    an LLM can lead to a response that is a *hallucination*, such that the content
    generated is false or misleading but the LLM expresses the response as if it were
    true. Hallucinations can be particularly challenging for software development,
    which requires accuracy.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: In [Chapter 2](ch02.html#how_ai_coding_technology_works), we learned that prompting
    an LLM can lead to a response that is a *hallucination*, such that the content
    generated is false or misleading but the LLM expresses the response as if it were
    true. Hallucinations can be particularly challenging for software development,
    which requires accuracy.
- en: 'No doubt, applying the lessons in this chapter can mitigate this issue, but
    even a well-crafted prompt can spin up hallucinations. There are numerous reasons
    for this:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 'No doubt, applying the lessons in this chapter can mitigate this issue, but
    even a well-crafted prompt can spin up hallucinations. There are numerous reasons
    for this:'
- en: Lack of ground truth verification
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Lack of ground truth verification
- en: LLMs generate responses based on patterns learned from training data without
    the ability to verify the accuracy or reality of the information.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs generate responses based on patterns learned from training data without
    the ability to verify the accuracy or reality of the information.
- en: Overfitting and memorization
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Overfitting and memorization
- en: LLMs might memorize incorrect or misleading information in their training datasets,
    especially if such data is repetitive or common.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs might memorize incorrect or misleading information in their training datasets,
    especially if such data is repetitive or common.
- en: Bias in training data
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Bias in training data
- en: If the training data contains biases, inaccuracies, or falsehoods, the model
    will likely replicate these in its outputs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: If the training data contains biases, inaccuracies, or falsehoods, the model
    will likely replicate these in its outputs.
- en: Extrapolation and speculation
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Extrapolation and speculation
- en: Sometimes, LLMs might extrapolate from the patterns they’ve seen in the data
    to generate information about topics or questions that were not adequately covered
    in the training data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Sometimes, LLMs might extrapolate from the patterns they’ve seen in the data
    to generate information about topics or questions that were not adequately covered
    in the training data.
- en: Lack of context or misinterpretation
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Lack of context or misinterpretation
- en: LLMs can misinterpret or lack the necessary context to accurately respond to
    certain prompts. They may not fully understand the nuances or implications of
    certain queries.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs may misinterpret or lack the necessary context to accurately respond to
    certain prompts. They may not fully understand the nuances or implications of
    certain queries.
- en: Slang and idioms
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Slang and idioms
- en: Such language can create ambiguity that may lead the model to misinterpret the
    intended meaning, especially if it hasn’t seen enough examples of the slang or
    idiom in context during training.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Such language can create ambiguity that may lead the model to misinterpret the
    intended meaning, especially if it hasn’t seen enough examples of the slang or
    idiom in context during training.
- en: 'Then how to reduce hallucinations? For one thing, it’s important to avoid asking
    open-ended questions like this:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 'Then how to reduce hallucinations? For one thing, it’s important to avoid asking
    open-ended questions like this:'
- en: '*Prompt:* What are the different ways to optimize a database?'
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Prompt:* What are the different ways to optimize a database?'
- en: This type of prompt encourages the LLM to resort to speculation or overgeneralization.
    The model may also misinterpret the intent of the question or the desired format
    of the answer, leading to responses that veer off-topic or contain fabricated
    information. There may actually be a cascade of hallucinations.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: This type of prompt encourages the LLM to resort to speculation or overgeneralization.
    The model may also misinterpret the intent of the question or the desired format
    of the answer, leading to responses that veer off-topic or contain fabricated
    information. There may actually be a cascade of hallucinations.
- en: 'One effective technique is to provide a set of predefined options and ask the
    AI to choose from them. For example, the preceding prompt could be rephrased as
    follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 'One effective technique is to provide a set of predefined options and ask the
    AI to choose from them. For example, the preceding prompt could be rephrased as
    follows:'
- en: '*Prompt:* Which of the following is a method to optimize a database: indexing,
    defragmenting, or compressing?'
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 以下哪项是优化数据库的方法：索引、碎片整理或压缩？'
- en: 'As another example, consider asking the LLM for a certain type of conclusion.
    Here is an effective prompt:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，考虑要求LLM提供某种类型的结论。以下是一个有效的提示：
- en: '*Prompt:* Is the following syntax correct for initializing an array in Java?
    Provide a “yes” or “no” response.'
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 以下语法是否正确用于在Java中初始化数组？请提供“是”或“否”的回复。'
- en: 'Or you can include multiple steps in the prompt to better guide the model through
    a structured process and narrow down the possibilities for straying off course:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 或者你可以在提示中包含多个步骤，以更好地引导模型通过结构化流程，并缩小偏离轨道的可能性：
- en: '*Prompt:*'
  id: totrans-238
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：*'
- en: ''
  id: totrans-239
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 1: Create a Fibonacci sequence generator.'
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第1步：创建一个斐波那契数列生成器。
- en: ''
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 2: Use the iterative method.'
  id: totrans-242
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第2步：使用迭代方法。
- en: ''
  id: totrans-243
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 3: Write a Python function named generate_fibonacci that takes an integer
    n as an argument.'
  id: totrans-244
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第3步：编写一个名为generate_fibonacci的Python函数，该函数接受一个整数n作为参数。
- en: ''
  id: totrans-245
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 4: The function returns the first n numbers in the Fibonacci sequence
    as a list.'
  id: totrans-246
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第4步：该函数返回斐波那契数列中的前n个数字列表。
- en: Security and Privacy
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全和隐私
- en: 'Being watchful about security and privacy while crafting prompts is key. In
    fact, the duty to take appropriate precautions should be in the company rulebook.
    It’s crucial to steer clear of any sensitive or personal information, such as
    personally identifiable information (PII) in your prompts. Here’s an example of
    a prompt that contains identifying information:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在制作提示时关注安全和隐私是关键。事实上，采取适当预防措施的职责应该在公司的规则手册中。避免在提示中包含任何敏感或个人信息，如个人身份信息（PII）是至关重要的。以下是一个包含识别信息的提示示例：
- en: '*Prompt:* How would you fix a login issue reported by John Doe at john.doe@example.com?'
  id: totrans-249
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 你会如何修复John Doe在john.doe@example.com报告的登录问题？'
- en: 'It’s wiser to go with something like:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 更明智的做法是选择如下：
- en: '*Prompt:* How would you tackle a login issue reported by a user?'
  id: totrans-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 你会如何处理用户报告的登录问题？'
- en: This keeps private information private.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以保护私人信息不被泄露。
- en: 'It’s also smart to steer clear of spilling any sensitive system details in
    the prompts. Avoid this:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 也要注意不要在提示中泄露任何敏感的系统细节。避免这样做：
- en: '*Prompt:* How to fix a database connection error on our production server at
    IP 192.168.1.1?'
  id: totrans-254
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 如何修复我们生产服务器上IP 192.168.1.1上的数据库连接错误？'
- en: 'Instead, it’s safer to use a more generic question:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 而使用一个更通用的提问会更安全：
- en: '*Prompt:* How to fix a generic database connection error?'
  id: totrans-256
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 如何修复通用的数据库连接错误？'
- en: 'Moreover, make sure your prompts don’t accidentally nudge folks toward shady
    practices. A prompt like this is fine from a security viewpoint:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，确保你的提示不会无意中引导人们走向可疑的做法。从安全角度来看，这样的提示是可行的：
- en: '*Prompt:* How to detect and prevent SQL injection?'
  id: totrans-258
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 如何检测和预防SQL注入？'
- en: 'But not this one, which might stir up some bad intentions:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个可能激起一些不良意图：
- en: '*Prompt:* How to exploit SQL vulnerabilities in a website?'
  id: totrans-260
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示：* 如何利用网站中的SQL漏洞？'
- en: Besides sticking to security and privacy rules, embracing diversity and inclusion
    when making prompts is important. Getting a solid grasp on bias, which often reflects
    the training data, is key. It’s a good call to use neutral and inclusive language
    to avoid any discriminatory or exclusionary phrases in the prompts. Also, getting
    feedback from a diverse group of people on your prompt crafting can help. This
    not only improves fairness and inclusivity when interacting with the LLM but also
    helps get a more accurate and well-rounded understanding of the topics at hand.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 除了遵守安全和隐私规则外，在制作提示时拥抱多样性和包容性也很重要。掌握偏见，这通常反映了训练数据，是关键。使用中性和包容性的语言来避免在提示中出现任何歧视性或排他性短语是个明智的选择。此外，从多样化的群体中获得关于你的提示制作的反馈可以帮助。这不仅有助于在交互LLM时提高公平性和包容性，还有助于获得更准确和全面的关于手头主题的理解。
- en: Autonomous AI Agents
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自主AI代理
- en: We’ve seen how you can nudge LLMs to map out the steps for a process. That’s
    at the heart of code generation.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何引导LLM规划一个过程的步骤。这是代码生成的核心。
- en: But AI agents can crank it up a notch. They don’t just follow prompts. They
    get creative with LLMs to figure out a game plan for whatever goal you toss at
    them, and they tap into specialized databases like Pinecone and Chroma DB. They
    handle complex word embeddings, which the models understand.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 但AI代理可以更进一步。它们不仅仅遵循提示。它们利用大型语言模型（LLM）的创造力，为你抛出的任何目标制定一个游戏计划，并且它们可以访问像Pinecone和Chroma
    DB这样的专业数据库。它们处理复杂的词嵌入，这些模型能够理解。
- en: 'Autonomous AI agents are based on academic research and are usually part of
    open source projects. Their real power is automation. To see how this works, let’s
    take an example. Suppose you set the objective as follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 自主人工智能代理基于学术研究，通常是开源项目的一部分。它们的真正力量在于自动化。为了了解这是如何工作的，让我们举一个例子。假设你设定的目标如下：
- en: '*Prompt:* Create a basic weather application with a user login system.'
  id: totrans-266
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 创建一个基本的天气应用程序，具有用户登录系统。'
- en: '[Table 3-6](#process_for_an_autonomous_agent) shows a process that an autonomous
    agent may go through.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-6](#process_for_an_autonomous_agent)显示了自主代理可能经历的过程。'
- en: Table 3-6\. Process for an autonomous agent
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-6\. 自主代理的过程
- en: '| Phase | Tasks |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | 任务 |'
- en: '| --- | --- |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Creation tasks | Design the user interface (UI). Sketch the basic layout
    of the dashboard.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '| 创建任务 | 设计用户界面（UI）。绘制仪表板的基本布局。 |'
- en: Select color schemes and fonts.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 选择配色方案和字体。
- en: Design icons and other graphic elements. |
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 设计图标和其他图形元素。 |
- en: '| API integration for weather data | Search the internet for reliable weather
    data APIs. Determine the data points to be displayed.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '| 天气数据API集成 | 在互联网上搜索可靠的天气数据API。确定要显示的数据点。 |'
- en: Write code to fetch and update weather data. |
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码以获取和更新天气数据。 |
- en: '| Location selection functionality | Create a search bar or dropdown for users
    to select their location. Connect this to the API code. |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 位置选择功能 | 创建一个搜索栏或下拉菜单，让用户选择他们的位置。将其连接到API代码。 |'
- en: '| Error handling | Handle errors like failed API calls or invalid location
    entries. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 错误处理 | 处理如失败的API调用或无效的位置输入等错误。 |'
- en: '| Prioritizing tasks | Prioritize setting up the API integration. Focus on
    the UI.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '| 优先级排序任务 | 优先设置API集成。专注于UI。'
- en: Work on location selection functionality and error handling. |
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于位置选择功能性和错误处理。 |
- en: '| Iteration | Review the generated code and the current state of the weather
    dashboard. Identify any remaining tasks or new tasks that have arisen during execution.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '| 迭代 | 审查生成的代码和天气仪表板的当前状态。确定在执行过程中剩余的任务或新出现的任务。'
- en: Repeat the create and prioritize steps. |
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 重复创建和优先级排序步骤。 |
- en: 'This technology is at the forefront and holds much promise. However, it’s not
    without its fair share of hurdles:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术处于前沿，并拥有巨大的潜力。然而，它并非没有其固有的挑战：
- en: Being resource hogs
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 资源消耗量大
- en: Agents can guzzle down large amounts of compute power. This can put the squeeze
    on your processors and databases, leading to more wait time, less reliability,
    and a slump in how things run as time goes on.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可以消耗大量的计算能力。这可能会对你的处理器和数据库造成压力，导致等待时间更长、可靠性降低，随着时间的推移，运行效率下降。
- en: Getting stuck in infinite loops
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 卡在无限循环中
- en: Sometimes agents just run in circles, thanks to a lack of progression or a repetitive
    reward system.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于缺乏进展或重复的奖励系统，代理只是原地打转。
- en: Being experimental
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 具有实验性
- en: Agents can be rough around the edges. They might come with a few bugs or unexpected
    behaviors and might not be quite ready for the big leagues, depending on what
    you need them for.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可能边缘粗糙。它们可能带有一些错误或意外的行为，并且可能并不完全准备好进入主流市场，这取决于你需要它们做什么。
- en: Having amnesia
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 出现健忘症
- en: Agents may simply forget certain steps or instructions.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可能简单地忘记某些步骤或指令。
- en: Having difficulty handling a large number of tasks
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大量任务时遇到困难
- en: Got a whole laundry list of tasks? That might trip up these agents.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个长长的任务清单？这可能会让这些代理陷入困境。
- en: Getting distracted by extraneous details
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 被无关紧要的细节分散注意力
- en: Agents might get sidetracked by the little things that don’t matter, which could
    send them down the wrong path when picking tools to use.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可能会被一些不重要的小事情分心，这可能会在挑选使用工具时将它们引向错误的方向。
- en: Another innovation that bolsters LLMs is retrieval augmented generation (RAG).
    With RAG, a generative AI application—say written in a framework like LangChain—accesses
    external sources of data, usually vector databases. They provide more grounding
    of the model in specific knowledge, which should enhance the LLM’s responses.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项加强LLMs的创新是检索增强生成（RAG）。使用RAG，一个生成式AI应用——比如用LangChain这样的框架编写——访问外部数据源，通常是向量数据库。它们为模型在特定知识上提供了更多的基础，这应该会增强LLM的响应。
- en: 'RAG can be particularly useful when handling complex software development tasks,
    such as in these scenarios:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: RAG在处理复杂的软件开发任务时特别有用，例如在这些场景中：
- en: Tackling bugs and glitches
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 解决错误和故障
- en: When developers encounter bugs or errors, RAG digs up fixes and workarounds
    from all around the web, looking in places like forums or bug databases. It can
    whip up some tailor-made solutions or code patches that fit your problem.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发者遇到错误或问题时，RAG会从网络上的各个角落挖掘出修复方案和解决方案，比如在论坛或错误数据库中查找。它能够迅速提供一些量身定制的解决方案或代码补丁，以解决你的问题。
- en: Spicing up code reviews
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 丰富代码审查
- en: RAG can pull in all the coding best practices, standards, and must-follow rules
    from a company’s internal resources. This means it can help streamline your code
    reviews, dishing out tips and tricks to make your code shine.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: RAG可以从公司的内部资源中提取所有编码最佳实践、标准和必须遵守的规则。这意味着它可以帮助简化你的代码审查，提供技巧和窍门让你的代码更加出色。
- en: Revving up testing
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 加速测试
- en: When it’s time to put your code through its paces, RAG can be your pit crew.
    It finds all sorts of test scenarios and patterns, tweaks them to suit your project’s
    needs, and helps you roll out test cases or scripts faster.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要对你的代码进行测试时，RAG可以成为你的维修团队。它会找到各种测试场景和模式，调整它们以适应你的项目需求，并帮助你更快地推出测试案例或脚本。
- en: Note
  id: totrans-303
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'In some cases, an LLM will indicate that there’s an issue with your prompt.
    For example, suppose you write this:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，LLM会指出你的提示存在问题。例如，假设你写下这样：
- en: '*Prompt:* Write a REST API using assembler.'
  id: totrans-305
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 使用汇编语言编写REST API。'
- en: 'This is how ChatGPT responded:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ChatGPT的回应：
- en: '*ChatGPT:* Creating a REST API using an assembler language is highly unconventional
    and complex due to the low-level nature of assembler languages. These languages
    are usually used for tasks that require fine-grained control over hardware, or
    for scenarios where performance is a critical concern.'
  id: totrans-307
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ChatGPT:* 使用汇编语言创建REST API非常不寻常且复杂，因为汇编语言的低级特性。这些语言通常用于需要精细控制硬件的任务，或者在性能是关键关注点的场景中。'
- en: Conclusion
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Again, crafting the perfect prompt involves mixing science with a splash of
    creativity. It’s all about finding the right ingredients—some creativity, a bit
    of gut feeling, and a structured approach—to cook up prompts that get LLMs to
    serve up what you want. No magic recipe exists, but if you’re clear, throw in
    a few examples, and lay out your prompts well, you’re on track for better answers.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，制作完美的提示需要将科学和一点创意相结合。这完全关乎找到正确的配料——一些创意，一点直觉，以及一种结构化的方法——来制作出能够引导LLM提供你所需要内容的提示。没有魔法配方，但如果你表达清晰，加入一些例子，并且很好地布局你的提示，你就能获得更好的答案。
- en: It’s a process, really. You try something, see how it goes, tweak it, and try
    again. And as with any skill, you get better the more you work on it with different
    topics and tasks.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是一个过程。你尝试一些东西，看看效果如何，然后调整它，再试一次。并且与任何技能一样，你通过在不同主题和任务上不断练习，会变得越来越熟练。
