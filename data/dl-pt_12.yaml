- en: 11 Training a classification model to detect suspected tumors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 训练一个分类模型以检测可疑肿瘤
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using PyTorch `DataLoader`s to load data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch的`DataLoader`加载数据
- en: Implementing a model that performs classification on our CT data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个在我们的CT数据上执行分类的模型
- en: Setting up the basic skeleton for our application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置我们应用程序的基本框架
- en: Logging and displaying metrics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录和显示指标
- en: In the previous chapters, we set the stage for our cancer-detection project.
    We covered medical details of lung cancer, took a look at the main data sources
    we will use for our project, and transformed our raw CT scans into a PyTorch `Dataset`
    instance. Now that we have a dataset, we can easily consume our training data.
    So let’s do that!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们为我们的癌症检测项目做好了准备。我们涵盖了肺癌的医学细节，查看了我们项目将使用的主要数据来源，并将原始CT扫描转换为PyTorch `Dataset`实例。现在我们有了数据集，我们可以轻松地使用我们的训练数据。所以让我们开始吧！
- en: 11.1 A foundational model and training loop
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 一个基础模型和训练循环
- en: We’re going to do two main things in this chapter. We’ll start by building the
    nodule classification model and training loop that will be the foundation that
    the rest of part 2 uses to explore the larger project. To do that, we’ll use the
    `Ct` and `LunaDataset` classes we implemented in chapter 10 to feed `DataLoader`
    instances. Those instances, in turn, will feed our classification model with data
    via training and validation loops.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将做两件主要的事情。我们将首先构建结节分类模型和训练循环，这将是第2部分探索更大项目的基础。为此，我们将使用我们在第10章实现的`Ct`和`LunaDataset`类来提供`DataLoader`实例。这些实例将通过训练和验证循环向我们的分类模型提供数据。
- en: 'We’ll finish the chapter by using the results from running that training loop
    to introduce one of the hardest challenges in this part of the book: how to get
    high-quality results from messy, limited data. In later chapters, we’ll explore
    the specific ways in which our data is limited, as well as mitigate those limitations.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过运行训练循环的结果来结束本章，引入本书这一部分中最困难的挑战之一：如何从混乱、有限的数据中获得高质量的结果。在后续章节中，我们将探讨我们的数据受限的具体方式，并减轻这些限制。
- en: 'Let’s recall our high-level roadmap from chapter 9, shown here in figure 11.1\.
    Right now, we’ll work on producing a model capable of performing step 4: classification.
    As a reminder, we will classify candidates as nodules or non-nodules (we’ll build
    another classifier to attempt to tell malignant nodules from benign ones in chapter
    14). That means we’re going to assign a single, specific label to each sample
    that we present to the model. In this case, those labels are “nodule” and “non-nodule,”
    since each sample represents a single candidate.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下第9章的高层路线图，如图11.1所示。现在，我们将致力于生成一个能够执行第4步分类的模型。作为提醒，我们将候选者分类为结节或非结节（我们将在第14章构建另一个分类器，试图区分恶性结节和良性结节）。这意味着我们将为呈现给模型的每个样本分配一个单一特定的标签。在这种情况下，这些标签是“结节”和“非结节”，因为每个样本代表一个候选者。
- en: '![](../Images/CH11_F01_Stevens2_GS.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F01_Stevens2_GS.png)'
- en: 'FIgure 11.1 Our end-to-end project to detect lung cancer, with a focus on this
    chapter’s topic: step 4, classification'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 我们的端到端项目，用于检测肺癌，重点是本章的主题：第4步，分类
- en: Getting an early end-to-end version of a meaningful part of your project is
    a great milestone to reach. Having something that works well enough for the results
    to be evaluated analytically let’s you move forward with future changes, confident
    that you are improving your results with each change--or at least that you’re
    able to set aside any changes and experiments that don’t work out! Expect to have
    to do a lot of experimentation when working on your own projects. Getting the
    best results will usually require considerable tinkering and tweaking.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 获得项目中一个有意义部分的早期端到端版本是一个重要的里程碑。拥有一个足够好使得结果可以进行分析评估的东西，让你可以有信心进行未来的改变，确信你正在通过每一次改变来改进你的结果，或者至少你能够搁置任何不起作用的改变和实验！在自己的项目中进行大量的实验是必须的。获得最佳结果通常需要进行大量的调试和微调。
- en: 'But before we can get to the experimental phase, we must lay our foundation.
    Let’s see what our part 2 training loop looks like in figure 11.2: it should seem
    generally familiar, given that we saw a similar set of core steps in chapter 5\.
    Here we will also use a validation set to evaluate our training progress, as discussed
    in section 5.5.3.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们进入实验阶段之前，我们必须打下基础。让我们看看我们第2部分训练循环的样子，如图11.2所示：鉴于我们在第5章看到了一组类似的核心步骤，这应该会让人感到熟悉。在这里，我们还将使用验证集来评估我们的训练进展，如第5.5.3节所讨论的那样。
- en: '![](../Images/CH11_F02_Stevens2_GS.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F02_Stevens2_GS.png)'
- en: FIgure 11.2 The training and validation script we will implement in this chapter
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 我们将在本章实现的训练和验��脚本
- en: 'The basic structure of what we’re going to implement is as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要实现的基本结构如下：
- en: Initialize our model and data loading.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化我们的模型和数据加载。
- en: Loop over a semi-arbitrarily chosen number of epochs.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环遍历一个半随机选择的epoch数。
- en: Loop over each batch of training data returned by `LunaDataset`.
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环遍历`LunaDataset`返回的每个训练数据批次。
- en: The data-loader worker process loads the relevant batch of data in the background.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载器工作进程在后台加载相关批次的数据。
- en: Pass the batch into our classification model to get results.
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将批次传入我们的分类模型以获得结果。
- en: Calculate our loss based on the difference between our predicted results and
    our ground-truth data.
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据我们预测结果与地面真实数据之间的差异来计算我们的损失。
- en: Record metrics about our model’s performance into a temporary data structure.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录关于我们模型性能的指标到一个临时数据结构中。
- en: Update the model weights via backpropagation of the error.
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过误差的反向传播更新模型权重。
- en: Loop over each batch of validation data (in a manner very similar to the training
    loop).
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环遍历每个验证数据批次（与训练循环非常相似的方式）。
- en: Load the relevant batch of validation data (again, in the background worker
    process).
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载相关的验证数据批次（同样，在后台工作进程中）。
- en: Classify the batch, and compute the loss.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对批次进行分类，并计算损失。
- en: Record information about how well the model performed on the validation data.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录模型在验证数据上的表现信息。
- en: Print out progress and performance information for this epoch.
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印出本轮的进展和性能信息。
- en: As we go through the code for the chapter, keep an eye out for two main differences
    between the code we’re producing here and what we used for a training loop in
    part 1\. First, we’ll put more structure around our program, since the project
    as a whole is quite a bit more complicated than what we did in earlier chapters.
    Without that extra structure, the code can get messy quickly. And for this project,
    we will have our main training application use a number of well-contained functions,
    and we will further separate code for things like our dataset into self-contained
    Python modules.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们阅读本章的代码时，请注意我们正在生成的代码与第一部分中用于训练循环的代码之间的两个主要区别。首先，我们将在程序周围放置更多结构，因为整个项目比我们在早期章节中做的要复杂得多。没有额外的结构，代码很快就会变得混乱。对于这个项目，我们将使我们的主要训练应用程序使用许多良好封装的函数，并进一步将像数据集这样的代码分离为独立的
    Python 模块。
- en: Make sure that for your own projects, you match the level of structure and design
    to the complexity level of your project. Too little structure, and it will become
    difficult to perform experiments cleanly, troubleshoot problems, or even describe
    what you’re doing! Conversely, too *much* structure means you’re wasting time
    writing infrastructure that you don’t need and most likely slowing yourself down
    by having to conform to it after all that plumbing is in place. Plus it can be
    tempting to spend time on infrastructure as a procrastination tactic, rather than
    digging into the hard work of making actual progress on your project. Don’t fall
    into that trap!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 确保对于您自己的项目，您将结构和设计水平与项目的复杂性水平匹配。结构太少，将难以进行实验、排除问题，甚至描述您正在做的事情！相反，结构太*多*意味着您正在浪费时间编写您不需要的基础设施，并且在所有管道都就位后，您可能会因为不得不遵守它而减慢自己的速度。此外，花时间在基础设施上很容易成为一种拖延策略，而不是投入艰苦工作来实际推进项目。不要陷入这种陷阱！
- en: The other big difference between this chapter’s code and part 1 will be a focus
    on collecting a variety of metrics about how training is progressing. Being able
    to accurately determine the impact of changes on training is impossible without
    having good metrics logging. Without spoiling the next chapter, we’ll also see
    how important it is to collect not just metrics, but the *right metrics for the
    job*. We’ll lay the infrastructure for tracking those metrics in this chapter,
    and we’ll exercise that infrastructure by collecting and displaying the loss and
    percent of samples correctly classified, both overall and per class. That’s enough
    to get us started, but we’ll cover a more realistic set of metrics in chapter
    12\.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本章代码与第一部分的另一个重大区别将是专注于收集有关训练进展的各种指标。如果没有良好的指标记录，准确确定变化对训练的影响是不可能的。在不透露下一章内容的情况下，我们还将看到收集不仅仅是指标，而是*适合工作的正确指标*是多么重要。我们将在本章中建立跟踪这些指标的基础设施，并通过收集和显示损失和正确分类的样本百分比来运用该基础设施，无论是总体还是每个类别。这足以让我们开始，但我们将在第
    12 章中涵盖一组更现实的指标。
- en: 11.2 The main entry point for our application
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 我们应用程序的主要入口点
- en: One of the big structural differences from earlier training work we’ve done
    in this book is that part 2 wraps our work in a fully fledged command-line application.
    It will parse command-line arguments, have a full-featured `--help` command, and
    be easy to run in a wide variety of environments. All this will allow us to easily
    invoke the training routines from both Jupyter and a Bash shell.[¹](#pgfId-1012226)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中与之前训练工作的一个重大结构性差异是，第二部分将我们的工作封装在一个完整的命令行应用程序中。它将解析命令行参数，具有完整功能的 `--help`
    命令，并且可以在各种环境中轻松运行。所有这些都将使我们能够轻松地从 Jupyter 和 Bash shell 中调用训练例程。[¹](#pgfId-1012226)
- en: Our application’s functionality will be implemented via a class so that we can
    instantiate the application and pass it around if we feel the need. This can make
    testing, debugging, or invocation from other Python programs easier. We can invoke
    the application without needing to spin up a second OS-level process (we won’t
    do explicit unit testing in this book, but the structure we create can be helpful
    for real projects where that kind of testing is appropriate).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用功能将通过一个类来实现，以便我们可以实例化应用程序并在需要时传递它。这可以使测试、调试或从其他 Python 程序调用更容易。我们可以调用应用程序而无需启动第二个
    OS 级别的进程（在本书中我们不会进行显式单元测试，但我们创建的结构对于需要进行这种测试的真实项目可能会有所帮助）。
- en: One way to take advantage of being able to invoke our training by either function
    call or OS-level process is to wrap the function invocations into a Jupyter Notebook
    so the code can easily be called from either the native CLI or the browser.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 利用能够通过函数调用或 OS 级别进程调用我们的训练的方式之一是将函数调用封装到 Jupyter Notebook 中，以便代码可以轻松地从本机 CLI
    或浏览器中调用。
- en: Listing 11.1 code/p2_run_everything.ipynb
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单 11.1 code/p2_run_everything.ipynb
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ We assume you have a four-core, eight-thread CPU. Change the 4 if needed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们假设您有一台四核八线程 CPU。如有需要，请更改 4。
- en: ❷ This is a slightly cleaner call to __import__.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 这是一个稍微更干净的 __import__ 调用。
- en: '*Note* The training here assumes that you’re on a workstation that has a four-core,
    eight-thread CPU, 16 GB of RAM, and a GPU with 8 GB of RAM. Reduce `--batch-size`
    if your GPU has less RAM, and `--num-workers` if you have fewer CPU cores, or
    less CPU RAM.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 这里的训练假设您使用的是一台四核八线程 CPU、16 GB RAM 和一块具有 8 GB RAM 的 GPU 的工作站。如果您的 GPU RAM
    较少，请减小 `--batch-size`，如果 CPU 核心较少或 CPU RAM 较少，请减小 `--num-workers`。'
- en: Let’s get some semistandard boilerplate code out of the way. We’ll start at
    the end of the file with a pretty standard `if main` stanza that instantiates
    the application object and invokes the `main` method.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先把一些半标准的样板代���搞定。我们将从文件末尾开始，使用一个相当标准的 `if main` 语句块，实例化应用对象并调用 `main` 方法。
- en: Listing 11.2 training.py:386
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单 11.2 training.py:386
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: From there, we can jump back to the top of the file and have a look at the application
    class and the two functions we just called, `__init__` and `main`. We’ll want
    to be able to accept command-line arguments, so we’ll use the standard `argparse`
    library ([https://docs .python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html))
    in the application’s `__init__` function. Note that we can pass in custom arguments
    to the initializer, should we wish to do so. The `main` method will be the primary
    entry point for the core logic of the application.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，我们可以跳回文件顶部，查看应用程序类和我们刚刚调用的两个函数，`__init__`和`main`。我们希望能够接受命令行参数，因此我们将在应用程序的`__init__`函数中使用标准的`argparse`库（[https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html)）。请注意，如果需要，我们可以向初始化程序传递自定义参数。`main`方法将是应用程序核心逻辑的主要入口点。
- en: Listing 11.3 training.py:31, `class` `LunaTrainingApp`
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.3 training.py:31，`class` `LunaTrainingApp`
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ If the caller doesn’t provide arguments, we get them from the command line.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果调用者没有提供参数，我们会从命令行获取参数。
- en: ❷ We’ll use the timestamp to help identify training runs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们将使用时间戳来帮助识别训练运行。
- en: This structure is pretty general and could be reused for future projects. In
    particular, parsing arguments in `__init__` allows us to configure the application
    separately from invoking it.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结构非常通用，可以在未来的项目中重复使用。特别是在`__init__`中解析参数允许我们将应用程序的配置与调用分开。
- en: If you check the code for this chapter on the book’s website or GitHub, you
    might notice some extra lines mentioning `TensorBoard`. Ignore those for now;
    we’ll discuss them in detail later in the chapter, in section 11.9\.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在本书网站或GitHub上检查本章的代码，您可能会注意到一些额外的提到`TensorBoard`的行。现在请忽略这些；我们将在本章后面的第11.9节中详细讨论它们。
- en: 11.3 Pretraining setup and initialization
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 预训练设置和初始化
- en: Before we can begin iterating over each batch in our epoch, some initialization
    work needs to happen. After all, we can’t train a model if we haven’t even instantiated
    one yet! We need to do two main things, as we can see in figure 11.3\. The first,
    as we just mentioned, is to initialize our model and optimizer; and the second
    is to initialize our `Dataset` and `DataLoader` instances. `LunaDataset` will
    define the randomized set of samples that will make up our training epoch, and
    our `DataLoader` instance will perform the work of loading the data out of our
    dataset and providing it to our application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始迭代每个epoch中的每个批次之前，需要进行一些初始化工作。毕竟，如果我们还没有实例化模型，我们就无法训练模型！正如我们在图11.3中所看到的，我们需要做两件主要的事情。第一，正如我们刚才提到的，是初始化我们的模型和优化器；第二是初始化我们的`Dataset`和`DataLoader`实例。`LunaDataset`将定义组成我们训练epoch的随机样本集，而我们的`DataLoader`实例将负责从我们的数据集中加载数据并将其提供给我们的应用程序。
- en: '![](../Images/CH11_F03_Stevens2_GS.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F03_Stevens2_GS.png)'
- en: FIgure 11.3 The training and validation script we will implement in this chapter,
    with a focus on the preloop variable initialization
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 我们将在本章实现的训练和验证脚本，重点放在预循环变量初始化上
- en: 11.3.1 Initializing the model and optimizer
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 初始化模型和优化器
- en: For this section, we are treating the details of `LunaModel` as a black box.
    In section 11.4, we will detail the internal workings. You are welcome to explore
    changes to the implementation to better meet our goals for the model, although
    that’s probably best done after finishing at least chapter 12.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一部分，我们将`LunaModel`的细节视为黑匣子。在第11.4节中，我们将详细介绍内部工作原理。您可以探索对实现进行更改，以更好地满足我们对模型的目标，尽管最好是在至少完成第12章之后再进行。
- en: Let’s see what our starting point looks like.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的起点是什么样的。
- en: Listing 11.4 training.py:31, `class` `LunaTrainingApp`
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.4 training.py:31，`class` `LunaTrainingApp`
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Detects multiple GPUs
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检测多个GPU
- en: ❷ Wraps the model
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 包装模型
- en: ❸ Sends model parameters to the GPU
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将模型参数发送到GPU。
- en: If the system used for training has more than one GPU, we will use the `nn.DataParallel`
    class to distribute the work between all of the GPUs in the system and then collect
    and resync parameter updates and so on. This is almost entirely transparent in
    terms of both the model implementation and the code that uses that model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用于训练的系统有多个GPU，我们将使用`nn.DataParallel`类在系统中的所有GPU之间分发工作，然后收集和重新同步参数更新等。就模型实现和使用该模型的代码而言，这几乎是完全透明的。
- en: DataParallel vs. DistributedDataParallel
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: DataParallel vs. DistributedDataParallel
- en: In this book, we use `DataParallel` to handle utilizing multiple GPUs. We chose
    `DataParallel` because it’s a simple drop-in wrapper around our existing models.
    It is not the best-performing solution for using multiple GPUs, however, and it
    is limited to working with the hardware available in a single machine.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们使用`DataParallel`来处理利用多个GPU。我们选择`DataParallel`，因为它是我们现有模型的简单插入包装器。然而，它并不是使用多个GPU的性能最佳解决方案，并且它仅限于与单台机器上可用的硬件一起使用。
- en: 'PyTorch also provides `DistributedDataParallel`, which is the recommended wrapper
    class to use when you need to spread work between more than one GPU or machine.
    Since the proper setup and configuration are nontrivial, and we suspect that the
    vast majority of our readers won’t see any benefit from the complexity, we won’t
    cover `DistributedDataParallel` in this book. If you wish to learn more, we suggest
    reading the official documentation: [https://pytorch.org/tutorials/intermediate/
    ddp_tutorial.html](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch还提供`DistributedDataParallel`，这是在需要在多个GPU或机器之间分配工作时推荐使用的包装类。由于正确的设置和配置并不简单，而且我们怀疑绝大多数读者不会从复杂性中获益，因此我们不会在本书中涵盖`DistributedDataParallel`。如果您希望了解更多，请阅读官方文档：[https://pytorch.org/tutorials/intermediate/ddp_tutorial.html](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)。
- en: Assuming that `self.use_cuda` is true, the call `self.model.to(device)` moves
    the model parameters to the GPU, setting up the various convolutions and other
    calculations to use the GPU for the heavy numerical lifting. It’s important to
    do so before constructing the optimizer, since, otherwise, the optimizer would
    be left looking at the CPU-based parameter objects rather than those copied to
    the GPU.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设`self.use_cuda`为真，则调用`self.model.to(device)`将模型参数移至GPU，设置各种卷积和其他计算以使用GPU进行繁重的数值计算。在构建优化器之前这样做很重要，否则优化器将只查看基于CPU的参数对象，而不是复制到GPU的参数对象。
- en: For our optimizer, we’ll use basic stochastic gradient descent (SGD; [https://pytorch.org/docs/stable/optim.html#torch.optim.SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD))
    with momentum. We first saw this optimizer in chapter 5\. Recall from part 1 that
    many different optimizers are available in PyTorch; while we won’t cover most
    of them in any detail, the official documentation ([https://pytorch.org/docs/stable/optim.html#algorithms](https://pytorch.org/docs/stable/optim.html#algorithms))
    does a good job of linking to the relevant papers.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的优化器，我们将使用基本的随机梯度下降（SGD；[https://pytorch.org/docs/stable/optim.html#torch.optim.SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)）与动量。我们在第5章中首次看到了这个优化器。回想第1部分，PyTorch中提供了许多不同的优化器；虽然我们不会详细介绍大部分优化器，但官方文档([https://pytorch.org/docs/stable/optim.html#algorithms](https://pytorch.org/docs/stable/optim.html#algorithms))很好地链接到相关论文。
- en: Using SGD is generally considered a safe place to start when it comes to picking
    an optimizer; there are some problems that might not work well with SGD, but they’re
    relatively rare. Similarly, a learning rate of 0.001 and a momentum of 0.9 are
    pretty safe choices. Empirically, SGD with those values has worked reasonably
    well for a wide range of projects, and it’s easy to try a learning rate of 0.01
    or 0.0001 if things aren’t working well right out of the box.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择优化器时，使用SGD通常被认为是一个安全的起点；有一些问题可能不适合SGD，但它们相对较少。同样，学习率为0.001，动量为0.9是相当安全的选择。从经验上看，SGD与这些值一起在各种项目中表现得���当不错，如果一开始效果不佳，可以尝试学习率为0.01或0.0001。
- en: That’s not to say any of those values is the best for our use case, but trying
    to find better ones is getting ahead of ourselves. Systematically trying different
    values for learning rate, momentum, network size, and other similar configuration
    settings is called a *hyperparameter search*. There are other, more glaring issues
    we need to address first in the coming chapters. Once we address those, we can
    begin to fine-tune these values. As we mentioned in the section “Testing other
    optimizers” in chapter 5, there are also other, more exotic optimizers we might
    choose; but other than perhaps swapping `torch.optim.SGD` for `torch.optim.Adam`,
    understanding the trade-offs involved is a topic too advanced for this book.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着这些值中的任何一个对我们的用例是最佳的，但试图找到更好的值是在超前。系统地尝试不同的学习率、动量、网络大小和其他类似配置设置的值被称为*超参数搜索*。在接下来的章节中，我们需要先解决其他更为突出的问题。一旦我们解决了这些问题，我们就可以开始微调这些值。正如我们在第5章的“测试其他优化器”部分中提到的，我们还可以选择其他更为奇特的优化器；但除了可能将`torch.optim.SGD`替换为`torch.optim.Adam`之外，理解所涉及的权衡是本书所讨论的范围之外的一个过于高级的主题。
- en: 11.3.2 Care and feeding of data loaders
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 数据加载器的照料和喂养
- en: 'The `LunaDataset` class that we built in the last chapter acts as the bridge
    between whatever Wild West data we have and the somewhat more structured world
    of tensors that the PyTorch building blocks expect. For example, `torch.nn.Conv3d`
    ([https:// pytorch.org/docs/stable/nn.html#conv3d](https://pytorch.org/docs/stable/nn.html#conv3d))
    expects five-dimensional input: (*N*, *C*, *D*, *H*, *W*): number of samples,
    channels per sample, depth, height, and width. Quite different from the native
    3D our CT provides!'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中构建的`LunaDataset`类充当着我们拥有的任何“荒野数据”与PyTorch构建模块期望的更加结构化的张量世界之间的桥梁。例如，`torch.nn.Conv3d`
    ([https:// pytorch.org/docs/stable/nn.html#conv3d](https://pytorch.org/docs/stable/nn.html#conv3d))
    期望五维输入：(*N*, *C*, *D*, *H*, *W*)：样本数量，每个样本的通道数，深度，高度和宽度。这与我们的CT提供的本机3D非常不同！
- en: You may recall the `ct_t.unsqueeze(0)` call in `LunaDataset.__getitem__` from
    the last chapter; it provides the fourth dimension, a “channel” for our data.
    Recall from chapter 4 that an RGB image has three channels, one each for red,
    green, and blue. Astronomical data could have dozens, one each for various slices
    of the electromagnetic spectrum--gamma rays, X-rays, ultraviolet light, visible
    light, infrared, microwaves, and/or radio waves. Since CT scans are single-intensity,
    our channel dimension is only size 1.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得上一章中`LunaDataset.__getitem__`中的`ct_t.unsqueeze(0)`调用；它提供了第四维，即我们数据的“通道”。回想一下第4章，RGB图像有三个通道，分别用于红色、绿色和蓝色。天文数据可能有几十个通道，每个通道代表电磁波谱的各个切片--伽马射线、X射线、紫外线、可见光、红外线、微波和/或无线电波。由于CT扫描是单一强度的，我们的通道维度只有大小1。
- en: Also recall from part 1 that training on single samples at a time is typically
    an inefficient use of computing resources, because most processing platforms are
    capable of more parallel calculations than are required by a model to process
    a single training or validation sample. The solution is to group sample tuples
    together into a batch tuple, as in figure 11.4, allowing multiple samples to be
    processed at the same time. The fifth dimension (*N*) differentiates multiple
    samples in the same batch.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 还要回顾第1部分，一次训练单个样本通常是对计算资源的低效利用，因为大多数处理平台能够进行更多的并行计算，而模型处理单个训练或验证样本所需的计算量要少。解决方案是将样本元组组合成批元组，如图11.4所示，允许同时处理多个样本。第五维度(*N*)区分了同一批中的多个样本。
- en: '![](../Images/CH11_F04_Stevens2_GS.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F04_Stevens2_GS.png)'
- en: FIgure 11.4 Sample tuples being collated into a single batch tuple inside a
    data loader
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 将样本元组整合到数据加载器中的单个批元组中
- en: 'Conveniently, we don’t have to implement any of this batching: the PyTorch
    `DataLoader` class will handle all of the collation work for us. We’ve already
    built the bridge from the CT scans to PyTorch tensors with our `LunaDataset` class,
    so all that remains is to plug our dataset into a data loader.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 方便的是，我们不必实现任何批处理：PyTorch的`DataLoader`类将处理所有的整理工作。我们已经通过`LunaDataset`类将CT扫描转换为PyTorch张量，所以唯一剩下的就是将我们的数据集插入数据加载器中。
- en: Listing 11.5 training.py:89, `LunaTrainingApp.initTrainDl`
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.5 training.py:89，`LunaTrainingApp.initTrainDl`
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Our custom dataset
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们的自定义数据集
- en: ❷ An off-the-shelf class
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一个现成的类
- en: ❸ Batching is done automatically.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 批处理是自动完成的。
- en: ❹ Pinned memory transfers to GPU quickly.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 固定内存传输到GPU快速。
- en: ❺ The validation data loader is very similar to training.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 验证数据加载器与训练非常相似。
- en: In addition to batching individual samples, data loaders can also provide parallel
    loading of data by using separate processes and shared memory. All we need to
    do is specify `num_workers=...` when instantiating the data loader, and the rest
    is taken care of behind the scenes. Each worker process produces complete batches
    as in figure 11.4\. This helps make sure hungry GPUs are well fed with data. Our
    `validation_ds` and `validation_dl` instances look similar, except for the obvious
    `isValSet_bool=True`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对单个样本进行分批处理外，数据加载器还可以通过使用单独的进程和共享内存提供数据的并行加载。我们只需在实例化数据加载器时指定`num_workers=...`，其余工作都在幕后处理。每个工作进程生成完整的批次，如图11.4所示。这有助于确保饥饿的GPU得到充分的数据供应。我们的`validation_ds`和`validation_dl`实例看起来很相似，除了明显的`isValSet_bool=True`。
- en: When we iterate, like `for batch_tup in self.train_dl:`, we won’t have to wait
    for each `Ct` to be loaded, samples to be taken and batched, and so on. Instead,
    we’ll get the already loaded `batch_tup` immediately, and a worker process will
    be freed up in the background to begin loading another batch to use on a later
    iteration. Using the data-loading features of PyTorch can help speed up most projects,
    because we can overlap data loading and processing with GPU calculation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们迭代时，比如`for batch_tup in self.train_dl:`，我们不必等待每个`Ct`被加载、样本被取出和分批处理等。相反，我们将立即获得已加载的`batch_tup`，并且后台的工作进程将被释放以开始加载另一个批次，以便在以后的迭代中使用。使用PyTorch的数据加载功能可以加快大多数项目的速度，因为我们可以将数据加载和处理与GPU计算重叠。
- en: 11.4 Our first-pass neural network design
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 我们的第一次神经网络设计
- en: The possible design space for a convolutional neural network capable of detecting
    tumors is effectively infinite. Luckily, considerable effort has been spent over
    the past decade or so investigating effective models for image recognition. While
    these have largely focused on 2D images, the general architecture ideas transfer
    well to 3D, so there are many tested designs that we can use as a starting point.
    This helps because although our first network architecture is unlikely to be our
    best option, right now we are only aiming for “good enough to get us going.”
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 能够检测肿瘤的卷积神经网络的设计空间实际上是无限的。幸运的是，在过去的十年左右，已经付出了相当大的努力来研究有效的图像识别模型。虽然这些模型主要集中在2D图像上，但一般的架构思想也很适用于3D，因此有许多经过测试的设计可以作为起点。这有助于我们，因为尽管我们的第一个网络架构不太可能是最佳选择，但现在我们只是追求“足够好以让我们开始”。
- en: We will base the network design on what we used in chapter 8\. We will have
    to update the model somewhat because our input data is 3D, and we will add some
    complicating details, but the overall structure shown in figure 11.5 should feel
    familiar. Similarly, the work we do for this project will be a good base for your
    future projects, although the further you get from classification or segmentation
    projects, the more you’ll have to adapt this base to fit. Let’s dissect this architecture,
    starting with the four repeated blocks that make up the bulk of the network.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于第8章中使用的内容设计网络。我们将不得不稍微更新模型，因为我们的输入��据是3D的，并且我们将添加一些复杂的细节，但图11.5中显示的整体结构应该感觉熟悉。同样，我们为这个项目所做的工作将是您未来项目的良好基础，尽管您离开分类或分割项目越远，就越需要调整这个基础以适应。让我们从组成网络大部分的四个重复块开始剖析这个架构。
- en: '![](../Images/CH11_F05_Stevens2_GS.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F05_Stevens2_GS.png)'
- en: FIgure 11.5 The architecture of the `LunaModel` class consisting of a batch-normalization
    tail, a four-block backbone, and a head comprised of a linear layer followed by
    softmax
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 `LunaModel`类的架构由批量归一化尾部、四个块的主干和由线性层后跟softmax组成的头部。
- en: 11.4.1 The core convolutions
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.1 核心卷积
- en: Classification models often have a structure that consists of a tail, a backbone
    (or body), and a head. The *tail* is the first few layers that process the input
    to the network. These early layers often have a different structure or organization
    than the rest of the network, as they must adapt the input to the form expected
    by the backbone. Here we use a simple batch normalization layer, though often
    the tail contains convolutional layers as well. Such convolutional layers are
    often used to aggressively downsample the size of the image; since our image size
    is already small, we don’t need to do that here.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型通常由尾部、主干（或身体）和头部组成。*尾部*是处理网络输入的前几层。这些早期层通常具有与网络其余部分不同的结构或组织，因为它们必须将输入调整为主干所期望的形式。在这里，我们使用简单的批量归一化层，尽管通常尾部也包含卷积层。这些卷积层通常用于大幅度降低图像的大小；由于我们的图像尺寸已经很小，所以这里不需要这样做。
- en: Next, the *backbone* of the network typically contains the bulk of the layers,
    which are usually arranged in series of *blocks*. Each block has the same (or
    at least a similar) set of layers, though often the size of the expected input
    and the number of filters changes from block to block. We will use a block that
    consists of two 3 × 3 convolutions, each followed by an activation, with a max-pooling
    operation at the end of the block. We can see this in the expanded view of figure
    11.5 labeled `Block[block1]`. Here’s what the implementation of the block looks
    like in code.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，网络的*骨干*通常包含大部分层，这些层通常按*块*的系列排列。每个块具有相同（或至少类似）的层集，尽管通常从一个块到另一个块，预期输入的大小和滤波器数量会发生变化。我们将使用一个由两个3
    × 3卷积组成的块，每个卷积后跟一个激活函数，并在块末尾进行最大池化操作。我们可以在图11.5的扩展视图中看到标记为`Block[block1]`的块的实现。以下是代码中块的实现。
- en: Listing 11.6 model.py:67, `class` `LunaBlock`
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单11.6 model.py:67，`class` `LunaBlock`
- en: '[PRE5]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ These could be implemented as calls to the functional API instead.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些可以作为对功能API的调用来实现。
- en: Finally, the *head* of the network takes the output from the backbone and converts
    it into the desired output form. For convolutional networks, this often involves
    flattening the intermediate output and passing it to a fully connected layer.
    For some networks, it makes sense to also include a second fully connected layer,
    although that is usually more appropriate for classification problems in which
    the imaged objects have more structure (think about cars versus trucks having
    wheels, lights, grill, doors, and so on) and for projects with a large number
    of classes. Since we are only doing binary classification, and we don’t seem to
    need the additional complexity, we have only a single flattening layer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，网络的*头部*接收来自骨干的输出，并将其转换为所需的输出形式。对于卷积网络，这通常涉及将中间输出展平并传递给全连接层。对于一些网络，也可以考虑包括第二个全连接层，尽管这通常更适用于具有更多结构的分类问题（比如想想汽车与卡车有轮子、灯、格栅、门等）和具有大量类别的项目。由于我们只进行二元分类，并且似乎不需要额外的复杂性，我们只有一个展平层。
- en: Using a structure like this can be a good first building block for a convolutional
    network. There are more complicated designs out there, but for many projects they’re
    overkill in terms of both implementation complexity and computational demands.
    It’s a good idea to start simple and add complexity only when there’s a demonstrable
    need for it.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的结构可以作为卷积网络的良好第一构建块。虽然存在更复杂的设计，但对于许多项目来说，它们在实现复杂性和��算需求方面都过于复杂。最好从简单开始，只有在确实需要时才增加复杂性。
- en: We can see the convolutions of our block represented in 2D in figure 11.6\.
    Since this is a small portion of a larger image, we ignore padding here. (Note
    that the ReLU activation function is not shown, as applying it does not change
    the image sizes.)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图11.6中看到我们块的卷积在2D中表示。由于这是较大图像的一小部分，我们在这里忽略填充。（请注意，未显示ReLU激活函数，因为应用它不会改变图像大小。）
- en: Let’s walk through the information flow between our input voxels and a single
    voxel of output. We want to have a strong sense of how our output will respond
    when the inputs change. It might be a good idea to review chapter 8, particularly
    sections 8.1 through 8.3, just to make sure you’re 100% solid on the basic mechanics
    of convolutions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解输入体素和单个输出体素之间的信息流。当输入发生变化时，我们希望对输出如何响应有一个清晰的认识。最好回顾第8章，特别是第8.1至8.3节，以确保您对卷积的基本机制完全掌握。
- en: '![](../Images/CH11_F06_Stevens2_GS.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F06_Stevens2_GS.png)'
- en: FIgure 11.6 The convolutional architecture of a `LunaModel` block consisting
    of two 3 × 3 convolutions followed by a max pool. The final pixel has a receptive
    field of 6 × 6.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 `LunaModel`块的卷积架构由两个3 × 3卷积和一个最大池组成。最终像素具有6 × 6的感受野。
- en: We’re using 3 × 3 × 3 convolutions in our block. A single 3 × 3 × 3 convolution
    has a receptive field of 3 × 3 × 3, which is almost tautological. Twenty-seven
    voxels are fed in, and one comes out.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的块中使用3 × 3 × 3卷积。单个3 × 3 × 3卷积具有3 × 3 × 3的感受野，这几乎是显而易见的。输入了27个体素，输出一个体素。
- en: It gets interesting when we use two 3 × 3 × 3 convolutions stacked back to back.
    Stacking convolutional layers allows the final output voxel (or pixel) to be influenced
    by an input further away than the size of the convolutional kernel suggests. If
    that output voxel is fed into another 3 × 3 × 3 kernel as one of the edge voxels,
    then some of the inputs to the first layer will be outside of the 3 × 3 × 3 area
    of input to the second. The final output of those two stacked layers has an *effective
    receptive field* of 5 × 5 × 5\. That means that when taken together, the stacked
    layers act as similar to a single convolutional layer with a larger size.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用两个连续的3 × 3 × 3卷积时，情况变得有趣。堆叠卷积层允许最终输出的体素（或像素）受到比卷积核大小所示的更远的输入的影响。如果将该输出体素作为边缘体素之一输入到另一个3
    × 3 × 3卷积核中，则第一层的一些输入将位于第二层的输入3 × 3 × 3区域之外。这两个堆叠层的最终输出具有5 × 5 × 5的*有效感受野*。这意味着当两者一起考虑时，堆叠层的作用类似于具有更大尺寸的单个卷积层。
- en: Put another way, each 3 × 3 × 3 convolutional layer adds an additional one-voxel-per-edge
    border to the receptive field. We can see this if we trace the arrows in fig-ure
    11.6 backward; our 2 × 2 output has a receptive field of 4 × 4, which in turn
    has a receptive field of 6 × 6\. Two stacked 3 × 3 × 3 layers uses fewer parameters
    than a full 5 × 5 × 5 convolution would (and so is also faster to compute).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，每个3 × 3 × 3卷积层为感受野添加了额外的一像素边界。如果我们在图11.6中向后跟踪箭头，我们可以看到这一点；我们的2 × 2输出具有4
    × 4的感受野，进而具有6 × 6的感受野。两个堆叠的3 × 3 × 3层比完整的5 × 5 × 5卷积使用更少的参数（因此计算速度更快）。
- en: The output of our two stacked convolutions is fed into a 2 × 2 × 2 max pool,
    which means we’re taking a 6 × 6 × 6 effective field, throwing away seven-eighths
    of the data, and going with the one 5 × 5 × 5 field that produced the largest
    value.[²](#pgfId-1038110) Now, those “discarded” input voxels still have a chance
    to contribute, since the max pool that’s one output voxel over has an overlapping
    input field, so it’s possible they’ll influence the final output that way.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们两个堆叠的卷积的输出被送入一个2×2×2的最大池，这意味着我们正在取一个6×6×6的有效区域，丢弃了七分之八的数据，并选择了产生最大值的一个5×5×5区域。现在，那些“被丢弃”的输入体素仍然有机会贡献，因为距离一个输出体素的最大池还有一个重叠的输入区域，所以它们可能以这种方式影响最终输出。
- en: Note that while we show the receptive field shrinking with each convolutional
    layer, we’re using *padded* convolutions, which add a virtual one-pixel border
    around the image. Doing so keeps our input and output image sizes the same.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然我们展示了每个卷积层的感受野随着每个卷积层的缩小而缩小，但我们使用了*填充*卷积，它在图像周围添加了一个虚拟的一像素边框。这样做可以保持输入和输出图像的大小不变。
- en: The `nn.ReLU` layers are the same as the ones we looked at in chapter 6\. Outputs
    greater than 0.0 will be left unchanged, and outputs less than 0.0 will be clamped
    to zero.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.ReLU` 层与我们在第6章中看到的层相同。大于0.0的输出将保持不变，小于0.0的输出将被截断为零。'
- en: This block will be repeated multiple times to form our model’s backbone.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这个块将被多次重复以形成我们模型的主干。
- en: 11.4.2 The full model
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.2 完整模型
- en: Let’s take a look at the full model implementation. We’ll skip the block definition,
    since we just saw that in listing 11.6.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下完整模型的实现。我们将跳过块的定义，因为我们刚刚在代码清单11.6中看到了。
- en: Listing 11.7 model.py:13, `class` `LunaModel`
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单11.7 model.py:13，`class` `LunaModel`
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Tail
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 尾部
- en: ❷ Backbone
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 主干
- en: ❸ Head
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 头部
- en: Here, our tail is relatively simple. We are going to normalize our input using
    `nn.BatchNorm3d`, which, as we saw in chapter 8, will shift and scale our input
    so that it has a mean of 0 and a standard deviation of 1\. Thus, the somewhat
    odd Hounsfield unit (HU) scale that our input is in won’t really be visible to
    the rest of the network. This is a somewhat arbitrary choice; we know what our
    input units are, and we know the expected values of the relevant tissues, so we
    could probably implement a fixed normalization scheme pretty easily. It’s not
    clear which approach would be better.[³](#pgfId-1038477)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的尾部相对简单。我们将使用`nn.BatchNorm3d`对输入进行归一化，正如我们在第8章中看到的那样，它将移动和缩放我们的输入，使其具有均值为0和标准差为1。因此，我们的输入单位处于的有点奇怪的汉斯菲尔德单位（HU）尺度对网络的其余部分来说并不明显。这是一个有点武断的选择；我们知道我们的输入单位是什么，我们知道相关组织的预期值，所以我们可能很容易地实现一个固定的归一化方案。目前尚不清楚哪种方法更好。
- en: Our backbone is four repeated blocks, with the block implementation pulled out
    into the separate `nn.Module` subclass we saw earlier in listing 11.6\. Since
    each block ends with a 2 × 2 × 2 max-pool operation, after 4 layers we will have
    decreased the resolution of the image 16 times in each dimension. Recall from
    chapter 10 that our data is returned in chunks that are 32 × 48 × 48, which will
    become 2 × 3 × 3 by the end of the backbone.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主干是四个重复的块，块的实现被提取到我们之前在代码清单11.6中看到的单独的`nn.Module`子类中。由于每个块以2×2×2的最大池操作结束，经过4层后，我们将在每个维度上将图像的分辨率降低16倍。回想一下第10章，我们的数据以32×48×48的块返回，最终将变为2×3×3。
- en: 'Finally, our tail is just a fully connected layer followed by a call to `nn.Softmax`.
    Softmax is a useful function for single-label classification tasks and has a few
    nice properties: it bounds the output between 0 and 1, it’s relatively insensitive
    to the absolute range of the inputs (only the *relative* values of the inputs
    matter), and it allows our model to express the degree of certainty it has in
    an answer.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们的尾部只是一个全连接层，然后调用`nn.Softmax`。Softmax是用于单标签分类任务的有用函数，并具有一些不错的特性：它将输出限制在0到1之间，对输入的绝对范围相对不敏感（只有输入的*相对*值重要），并且允许我们的模型表达对答案的确定程度。
- en: 'The function itself is relatively simple. Every value from the input is used
    to exponentiate `e`, and the resulting series of values is then divided by the
    sum of all the results of exponentiation. Here’s what it looks like implemented
    in a simple fashion as a nonoptimized softmax implementation in pure Python:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 函数本身相对简单。输入的每个值都用于求幂`e`，然后得到的一系列值除以所有求幂结果的总和。以下是一个简单的非优化softmax实现的Python代码示例：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Of course, we use the PyTorch version of `nn.Softmax` for our model, as it natively
    understands batches and tensors and will perform autograd quickly and as expected.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们在模型中使用PyTorch版本的`nn.Softmax`，因为它本身就能理解批处理和张量，并且会快速且如预期地执行自动梯度。
- en: 'Complication: Converting from convolution to linear'
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 复杂性：从卷积转换为线性
- en: Continuing on with our model definition, we come to a complication. We can’t
    just feed the output of `self.block4` into a fully connected layer, since that
    output is a per-sample 2 × 3 × 3 image with 64 channels, and fully connected layers
    expect a 1D vector as input (well, technically they expect a *batch* of 1D vectors,
    which is a 2D array, but the mismatch remains either way). Let’s take a look at
    the `forward` method.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们的模型定义，我们遇到了一个复杂性。我们不能简单地将`self.block4`的输出馈送到全连接层，因为该输出是每个样本的64通道的2×3×3图像，而全连接层期望一个1D向量作为输入（技术上说，它们期望一个*批量*的1D向量，这是一个2D数组，但无论如何不匹配）。让我们看一下`forward`方法。
- en: Listing 11.8 model.py:50, `LunaModel.forward`
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单11.8 model.py:50，`LunaModel.forward`
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ The batch size
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 批处理大小
- en: Note that before we pass data into a fully connected layer, we must flatten
    it using the `view` function. Since that operation is stateless (it has no parameters
    that govern its behavior), we can simply perform the operation in the `forward`
    function. This is somewhat similar to the functional interfaces we discussed in
    chapter 8\. Almost every model that uses convolution and produces classifications,
    regressions, or other non-image outputs will have a similar component in the head
    of the network.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在将数据传递到全连接层之前，我们必须使用`view`函数对其进行展平。由于该操作是无状态的（没有控制其行为的参数），我们可以简单地在`forward`函数中执行该操作。这在某种程度上类似于我们在第8章讨论的功能接口。几乎每个使用卷积并产生分类、回归或其他非图像输出的模型都会在网络头部具有类似的组件。
- en: 'For the return value of the `forward` method, we return both the raw *logits*
    and the softmax-produced probabilities. We first hinted at logits in section 7.2.6:
    they are the numerical values produced by the network prior to being normalized
    into probabilities by the softmax layer. That might sound a bit complicated, but
    logits are really just the raw input to the softmax layer. They can have any real-valued
    input, and the softmax will squash them to the range 0-1.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`forward`方法的返回值，我们同时返回原始*logits*和softmax生成的概率。我们在第7.2.6节中首次提到了logits：它们是网络在被softmax层归一化之前产生的数值。这可能听起来有点复杂，但logits实际上只是softmax层的原始输入。它们可以有任何实值输入，softmax会将它们压缩到0-1的范围内。
- en: We’ll use the logits when we calculate the `nn.CrossEntropyLoss` during training,[⁴](#pgfId-1038986)
    and we’ll use the probabilities for when we want to actually classify the samples.
    This kind of slight difference between what’s used for training and what’s used
    in production is fairly common, especially when the difference between the two
    outputs is a simple, stateless function like softmax.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练时，我们将使用logits来计算`nn.CrossEntropyLoss`，[⁴](#pgfId-1038986)而在实际对样本进行分类时，我们将使用概率。在训练和生产中使用的输出之间存在这种轻微差异是相当常见的，特别是当两个输出之间的差异是像softmax这样简单、无状态的函数时。
- en: Initialization
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 初始化
- en: Finally, let’s talk about initializing our network’s parameters. In order to
    get well-behaved performance out of our model, the network’s weights, biases,
    and other parameters need to exhibit certain properties. Let’s imagine a degenerate
    case, where all of the network’s weights are greater than 1 (and we do not have
    residual connections). In that case, repeated multiplication by those weights
    would result in layer outputs that became very large as data flowed through the
    layers of the network. Similarly, weights less than 1 would cause all layer outputs
    to become smaller and vanish. Similar considerations apply to the gradients in
    the backward pass.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们谈谈初始化网络参数。为了使我们的模型表现良好，网络的权重、偏置和其他参数需要表现出一定的特性。让我们想象一个退化的情况，即网络的所有权重都大于1（且没有残差连接）。在这种情况下，重复乘以这些权重会导致数据通过网络层时层输出变得非常大。类似地，小于1的权重会导致所有层输出变得更小并消失。类似的考虑也适用于反向传播中的梯度。
- en: Many normalization techniques can be used to keep layer outputs well behaved,
    but one of the simplest is to just make sure the network’s weights are initialized
    such that intermediate values and gradients become neither unreasonably small
    nor unreasonably large. As we discussed in chapter 8, PyTorch does not help us
    as much as it should here, so we need to do some initialization ourselves. We
    can treat the following `_init_weights` function as boilerplate, as the exact
    details aren’t particularly important.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 许多规范化技术可以用来保持层输出的良好行为，但其中最简单的一种是确保网络的权重初始化得当，使得中间值和梯度既不过小也不过大。正如我们在第8章讨论的那样，PyTorch在这里没有给予我们足够的帮助，因此我们需要自己进行一些初始化。我们可以将以下`_init_weights`函数视为样板，因为确切的细节并不特别重要。
- en: Listing 11.9 model.py:30, `LunaModel._init_weights`
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.9 model.py:30，`LunaModel._init_weights`
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 11.5 Training and validating the model
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.5 训练和验证模型
- en: Now it’s time to take the various pieces we’ve been working with and assemble
    them into something we can actually execute. This training loop should be familiar--we
    saw loops like figure 11.7 in chapter 5.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将我们一直在处理的各种部分组装起来，以便我们实际执行。这个训练循环应该很熟悉--我们在第5章看到了类似图11.7的循环。
- en: '![](../Images/CH11_F07_Stevens2_GS.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F07_Stevens2_GS.png)'
- en: FIgure 11.7 The training and validation script we will implement in this chapter,
    with a focus on the nested loops over each epoch and batches in the epoch
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 我们将在本章实现的训练和验证脚本，重点是在每个时期和时期中的批次上进行嵌套循环
- en: The code is relatively compact (the `doTraining` function is only 12 statements;
    it’s longer here due to line-length limitations).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相对紧凑（`doTraining`函数仅有12个语句；由于行长限制，这里较长）。
- en: Listing 11.10 training.py:137, `LunaTrainingApp.main`
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.10 training.py:137，`LunaTrainingApp.main`
- en: '[PRE10]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Initializes an empty metrics array
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化一个空的指标数组
- en: ❷ Sets up our batch looping with time estimate
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 设置我们的批次循环和时间估计
- en: ❸ Frees any leftover gradient tensors
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 释放任何剩余的梯度张量
- en: ❹ We’ll discuss this method in detail in the next section.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们将在下一节详细讨论这种方法。
- en: ❺ Actually updates the model weights
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 实际更新模型权重
- en: 'The main differences that we see from the training loops in earlier chapters
    are as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从前几章的训练循环中看到的主要区别如下：
- en: The `trnMetrics_g` tensor collects detailed per-class metrics during training.
    For larger projects like ours, this kind of insight can be very nice to have.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trnMetrics_g`张量在训练过程中收集了详细的每类指标。对于像我们这样的大型项目，这种洞察力可能非常有用。'
- en: We don’t directly iterate over the `train_dl` data loader. We use `enumerateWithEstimate`
    to provide an estimated time of completion. This isn’t crucial; it’s just a stylistic
    choice.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不直接遍历`train_dl`数据加载器。我们使用`enumerateWithEstimate`来提供预计完成时间。这并不是必要的；这只是一种风格上的选择。
- en: The actual loss computation is pushed into the `computeBatchLoss` method. Again,
    this isn’t strictly necessary, but code reuse is typically a plus.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际的损失计算被推入`computeBatchLoss`方法中。再次强调，这并不是绝对必要的，但代码重用通常是一个优点。
- en: We’ll discuss why we’ve wrapped `enumerate` with additional functionality in
    section 11.7.2; for now, assume it’s the same as `enumerate(train_dl)`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第11.7.2节讨论为什么我们在`enumerate`周围包装了额外的功能；目前，假设它与`enumerate(train_dl)`相同。
- en: The purpose of the `trnMetrics_g` tensor is to transport information about how
    the model is behaving on a per-sample basis from the `computeBatchLoss` function
    to the `logMetrics` function. Let’s take a look at `computeBatchLoss` next. We’ll
    cover `logMetrics` after we’re done with the rest of the main training loop.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`trnMetrics_g`张量的目的是将有关模型在每个样本基础上的行为信息从`computeBatchLoss`函数��输到`logMetrics`函数。让我们接下来看一下`computeBatchLoss`。在完成主要训练循环的其余部分后，我们将讨论`logMetrics`。'
- en: 11.5.1 The computeBatchLoss function
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.1 `computeBatchLoss`函数
- en: The `computeBatchLoss` function is called by both the training and validation
    loops. As the name suggests, it computes the loss over a batch of samples. In
    addition, the function also computes and records per-sample information about
    the output the model is producing. This lets us compute things like the percentage
    of correct answers per class, which allows us to hone in on areas where our model
    is having difficulty.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`computeBatchLoss`函数被训练和验证循环调用。顾名思义，它计算一批样本的损失。此外，该函数还计算并记录模型产生的每个样本信息。这使我们能够计算每个类别的正确答案百分比，从而让我们专注于模型遇到困难的领域。'
- en: Of course, the function’s core functionality is around feeding the batch into
    the model and computing the per-batch loss. We’re using `CrossEntropyLoss` ([https://
    pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)),
    just like in chapter 7\. Unpacking the batch tuple, moving the tensors to the
    GPU, and invoking the model should all feel familiar after that earlier training
    work.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，函数的核心功能是将批次输入模型并计算每个批次的损失。我们使用`CrossEntropyLoss` ([https:// pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss))，就像在第7章中一样。解包批次元组，将张量移动到GPU，并调用模型应该在之前的训练工作后都感到熟悉。
- en: Listing 11.11 training.py:225, `.computeBatchLoss`
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.11 training.py:225，`.computeBatchLoss`
- en: '[PRE11]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ reduction=‘none’ gives the loss per sample.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `reduction=‘none’`给出每个样本的损失。
- en: ❷ Index of the one-hot-encoded class
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ one-hot编码类别的索引
- en: ❸ Recombines the loss per sample into a single value
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将每个样本的损失重新组合为单个值
- en: Here we are *not* using the default behavior to get a loss value averaged over
    the batch. Instead, we get a tensor of loss values, one per sample. This lets
    us track the individual losses, which means we can aggregate them as we wish (per
    class, for example). We’ll see that in action in just a moment. For now, we’ll
    return the mean of those per-sample losses, which is equivalent to the batch loss.
    In situations where you don’t want to keep statistics per sample, using the loss
    averaged over the batch is perfectly fine. Whether that’s the case is highly dependent
    on your project and goals.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们*不*使用默认行为来获得平均批次的损失值。相反，我们得到一个损失值的张量，每个样本一个。这使我们能够跟踪各个损失，这意味着我们可以按照自己的意愿进行聚合（例如，按类别）。我们马上就会看到这一点。目前，我们将返回这些每个样本损失的均值，这等同于批次损失。在不想保留每个样本统计信息的情况下，使用批次平均损失是完全可以的。是否这样取决于您的项目和目标。
- en: Once that’s done, we’ve fulfilled our obligations to the calling function in
    terms of what’s required to do backpropagation and weight updates. Before we do
    that, however, we also want to record our per-sample stats for posterity (and
    later analysis). We’ll use the `metrics_g` parameter passed in to accomplish this.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成了这些，我们就完成了对调用函数的义务，就backpropagation和权重更新而言，需要做的事情。然而，在这之前，我们还想要记录我们每个样本的统计数据以供后人（和后续分析）使用。我们将使用传入的`metrics_g`参数来实现这一点。
- en: Listing 11.12 training.py:26
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.12 training.py:26
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ These named array indexes are declared at module-level scope
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些命名的数组索引在模块级别范围内声明
- en: ❷ We use detach since none of our metrics need to hold on to gradients.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们使用`detach`，因为我们的指标都不需要保留梯度。
- en: ❸ Again, this is the loss over the entire batch.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 再次，这是整个批次的损失。
- en: By recording the label, prediction, and loss for each and every training (and
    later, validation) sample, we have a wealth of detailed information we can use
    to investigate the behavior of our model. For now, we’re going to focus on compiling
    per-class statistics, but we could easily use this information to find the sample
    that is classified the most wrongly and start to investigate why. Again, for some
    projects, this kind of information will be less interesting, but it’s good to
    remember that you have these kinds of options available.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 通过记录每个训练（以及后续的验证）样本的标签、预测和损失，我们拥有大量详细信息，可以用来研究我们模型的行为。目前，我们将专注于编译每个类别的统计数据，但我们也可以轻松地使用这些信息找到被错误分类最多的样本，并开始调查原因。同样，对于一些项目，这种信息可能不那么有趣，但记住你有这些选项是很好的。
- en: 11.5.2 The validation loop is similar
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.2 验证循环类似
- en: The validation loop in figure 11.8 looks very similar to training but is somewhat
    simplified. The key difference is that validation is read-only. Specifically,
    the loss value returned is not used, and the weights are not updated.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8中的验证循环看起来与训练很相似，但有些简化。关键区别在于验证是只读的。具体来说，返回的损失值不会被使用，权重也不会被更新。
- en: '![](../Images/CH11_F08_Stevens2_GS.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F08_Stevens2_GS.png)'
- en: FIgure 11.8 The training and validation script we will implement in this chapter,
    with a focus on the per-epoch validation loop
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 我们将在本章实现的训练和验证脚本，重点放在每个epoch的验证循环上
- en: Nothing about the model should have changed between the start and end of the
    function call. In addition, it’s quite a bit faster due to the `with torch.no_grad()`
    context manager explicitly informing PyTorch that no gradients need to be computed.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数调用的开始和结束之间，模型的任何内容都不应该发生变化。此外，由于`with torch.no_grad()`上下文管理器明确告知PyTorch不需要计算梯度，因此速度要快得多。
- en: Listing 11.13 training.py:137, `LunaTrainingApp.main`
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `LunaTrainingApp.main` 中的 `training.py:137`，代码清单 11.13
- en: '[PRE13]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Turns off training-time behavior
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 关闭训练时的行为
- en: Without needing to update network weights (recall that doing so would violate
    the entire premise of the validation set; something we never want to do!), we
    don’t need to use the loss returned from `computeBatchLoss`, nor do we need to
    reference the optimizer. All that’s left inside the loop is the call to `computeBatchLoss`.
    Note that we are still collecting metrics in `valMetrics_g` as a side effect of
    the call, even though we aren’t using the overall per-batch loss returned by `computeBatchLoss`
    for anything.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在不需要更新网络权重的情况下（回想一下，这样做会违反验证集的整个前提；我们绝不希望这样做！），我们不需要使用`computeBatchLoss`返回的损失，也不需要引用优化器。
    在循环内部剩下的只有对`computeBatchLoss`的调用。请注意，尽管我们不使用`computeBatchLoss`返回的每批损失来做任何事情，但我们仍然在`valMetrics_g`中收集指标作为调用的副作用。
- en: 11.6 Outputting performance metrics
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.6 输出性能指标
- en: The last thing we do per epoch is log our performance metrics for this epoch.
    As shown in figure 11.9, once we’ve logged metrics, we return to the training
    loop for the next epoch of training. Logging results and progress as we go is
    important, since if training goes off the rails (“does not converge” in the parlance
    of deep learning), we want to notice this is happening and stop spending time
    training a model that’s not working out. In less catastrophic cases, it’s good
    to be able to keep an eye on how your model behaves.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 每个时期我们做的最后一件事是记录本时期的性能指标。如图11.9所示，一旦我们记录了指标，我们就会返回到下一个训练时期的训练循环中。在训练过程中随着进展记录结果是很重要的，因为如果训练出现问题（在深度学习术语中称为“不收敛”），我们希望能够注意到这一点，并停止花费时间训练一个不起作用的模型。在较小的情况下，能够监视模型行为是很有帮助的。
- en: '![](../Images/CH11_F09_Stevens2_GS.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F09_Stevens2_GS.png)'
- en: FIgure 11.9 The training and validation script we will implement in this chapter,
    with a focus on the metrics logging at the end of each epoch
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9 我们将在本章实现的训练和验证脚本，重点放在每个时期结束时的指标记录上
- en: Earlier, we were collecting results in `trnMetrics_g` and `valMetrics_g` for
    logging progress per epoch. Each of these two tensors now contains everything
    we need to compute our percent correct and average loss per class for our training
    and validation runs. Doing this per epoch is a common choice, though somewhat
    arbitrary. In future chapters, we’ll see how to manipulate the size of our epochs
    such that we get feedback about training progress at a reasonable rate.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们在`trnMetrics_g`和`valMetrics_g`中收集结果以记录每个时期的进展。这两个张量现在包含了我们计算每个训练和验证运行的每类百分比正确和平均损失所需的一切。每个时期执行此操作是一个常见选择，尽管有些是任意的。在未来的章节中，我们将看到如何调整我们的时期大小，以便以合理的速率获得有关训练进度的反馈。
- en: 11.6.1 The logMetrics function
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.6.1 logMetrics函数
- en: Let’s talk about the high-level structure of the `logMetrics` function. The
    signature looks like this.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈`logMetrics`函数的高级结构。签名看起来像这样。
- en: Listing 11.14 training.py:251, `LunaTrainingApp.logMetrics`
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `LunaTrainingApp.logMetrics` 中的 `training.py:251`，代码清单 11.14
- en: '[PRE14]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We use `epoch_ndx` purely for display while logging our results. The `mode_str`
    argument tells us whether the metrics are for training or validation.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅使用`epoch_ndx`来在记录结果时显示。`mode_str`参数告诉我们指标是用于训练还是验证。
- en: We consume either `trnMetrics_t` or `valMetrics_t`, which is passed in as the
    `metrics _t` parameter. Recall that both of those inputs are tensors of floating-point
    values that we filled with data during `computeBatchLoss` and then transferred
    back to the CPU right before we returned them from `doTraining` and `doValidation`.
    Both tensors have three rows and as many columns as we have samples (training
    samples or validation samples, depending). As a reminder, those three rows correspond
    to the following constants.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要么使用传入的`metrics_t`参数中的`trnMetrics_t`或`valMetrics_t`。回想一下，这两个输入都是浮点值的张量，在`computeBatchLoss`期间我们填充了数据，然后在我们从`doTraining`和`doValidation`返回它们之前将它们转移到CPU。这两个张量都有三行，以及我们有样本数（训练样本或验证样本，取决于）的列数。作为提醒，这三行对应以下常量。
- en: Listing 11.15 training.py:26
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `training.py:26`，代码清单 11.15
- en: '[PRE15]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ These are declared at module-level scope.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些在模块级别范围内声明。
- en: Tensor masking and Boolean indexing
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 张量掩码和布尔索引
- en: Masked tensors are a common usage pattern that might be opaque if you have not
    encountered them before. You may be familiar with the NumPy concept called masked
    arrays; tensor and array masks behave the same way.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码张量是一种常见的使用模式，如果您以前没有遇到过，可能会感到不透明。您可能熟悉NumPy概念称为掩码数组；张量和数组掩码的行为方式相同。
- en: If you aren’t familiar with masked arrays, an excellent page in the NumPy documentation
    ([http://mng.bz/XPra](http://mng.bz/XPra)) describes the behavior well. PyTorch
    purposely uses the same syntax and semantics as NumPy.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对掩码数组不熟悉，NumPy文档中的一个优秀页面（[http://mng.bz/XPra](http://mng.bz/XPra)）很好地描述了其行为。
    PyTorch故意使用与NumPy相同的语法和语义。
- en: Constructing masks
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建掩码
- en: Next, we’re going to construct masks that will let us limit our metrics to only
    the nodule or non-nodule (aka positive or negative) samples. We will also count
    the total samples per class, as well as the number of samples we classified correctly.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建掩码，以便仅将指标限制为结节或非结节（也称为阳性或阴性）样本。我们还将计算每个类别的总样本数，以及我们正确分类的样本数。
- en: Listing 11.16 training.py:264, `LunaTrainingApp.logMetrics`
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `LunaTrainingApp.logMetrics` 中的 `training.py:264`，代码清单 11.16
- en: '[PRE16]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: While we don’t `assert` it here, we know that all of the values stored in `metrics
    _t[METRICS_LABEL_NDX]` belong to the set `{0.0, 1.0}` since we know that our nodule
    status labels are simply `True` or `False`. By comparing to `classificationThreshold`,
    which defaults to 0.5, we get an array of binary values where a `True` value corresponds
    to a non-nodule (aka negative) label for the sample in question.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在这里没有`assert`，但我们知道存储在`metrics _t[METRICS_LABEL_NDX]`中的所有值属于集合`{0.0, 1.0}`，因为我们知道我们的结节状态标签只是`True`或`False`。通过与默认值为0.5的`classificationThreshold`进行比较，我们得到一个二进制值数组，其中`True`值对应于所讨论样本的非结节（也称为负）标签。
- en: We do a similar comparison to create the `negPred_mask`, but we must remember
    that the `METRICS_PRED_NDX` values are the *positive predictions produced by our
    model and can be any floating-point value between 0.0 and 1.0, inclusive*. That
    doesn’t change our comparison, but it does mean the actual value can be close
    to 0.5\. The positive masks are simply the inverse of the negative masks.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行类似的比较以创建`negPred_mask`，但我们必须记住`METRICS_PRED_NDX`值是我们模型产生的*正预测，可以是介于0.0和1.0之间的任意浮点值*。这并不改变我们的比较，但这意味着实际值可能接近0.5。正掩模只是负掩模的反向。
- en: '*Note* While other projects can utilize similar approaches, it’s important
    to realize that we’re taking some shortcuts that are allowed because this is a
    binary classification problem. If your next project has more than two classes
    or has samples that belong to multiple classes at the same time, you’ll have to
    use more complicated logic to build similar masks.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 虽然其他项目可以利用类似的方法，但重要的是要意识到，我们正在采取一些捷径，这是因为这是一个二元分类问题。如果您的下一个项目有超过两个类别或样本同时属于多个类别，您将需要使用更复杂的逻辑来构建类似的掩模。'
- en: Next, we use those masks to compute some per-label statistics and store them
    in a dictionary, `metrics_dict`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用这些掩模计算一些每个标签的统计数据，并将其存储在字典`metrics_dict`中。
- en: Listing 11.17 training.py:270, `LunaTrainingApp.logMetrics`
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单 11.17 training.py:270，`LunaTrainingApp.logMetrics`
- en: '[PRE17]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Converts to a normal Python integer
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 转换为普通的Python整数
- en: ❷ Avoids integer division by converting to np.float32
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 避免整数除法，转换为np.float32
- en: First we compute the average loss over the entire epoch. Since the loss is the
    single metric that is being minimized during training, we always want to be able
    to keep track of it. Then we limit the loss averaging to only those samples with
    a negative label using the `negLabel_mask` we just made. We do the same with the
    positive loss. Computing a per-class loss like this can be useful if one class
    is persistently harder to classify than another, since that knowledge can help
    drive investigation and improvements.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们计算整个时期的平均损失。由于损失是训练过程中要最小化的单一指标，我们始终希望能够跟踪它。然后，我们将损失平均限制为仅使用我们刚刚制作的`negLabel_mask`的那些带有负标签的样本。我们对正损失也是一样的。像这样计算每类损失在某种情况下是有用的，如果一个���别比另一个类别更难分类，那么这种知识可以帮助推动调查和改进。
- en: We’ll close out the calculations with determining the fraction of samples we
    classified correctly, as well as the fraction correct from each label. Since we
    will display these numbers as percentages in a moment, we also multiply the values
    by 100\. Similar to the loss, we can use these numbers to help guide our efforts
    when making improvements. After the calculations, we then log our results with
    three calls to `log.info`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过确定我们正确分类的样本比例以及每个标签的正确比例来结束计算，因为我们将在稍后将这些数字显示为百分比，所以我们还将这些值乘以100。与损失类似，我们可以使用这些数字来帮助指导我们在进行改进时的努力。计算完成后，我们通过三次调用`log.info`记录我们的结果。
- en: Listing 11.18 training.py:289, `LunaTrainingApp.logMetrics`
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单 11.18 training.py:289，`LunaTrainingApp.logMetrics`
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ The ‘pos’ logging is similar to the ‘neg’ logging earlier.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ “pos”日志与之前的“neg”日志类似。
- en: The first log has values computed from all of our samples and is tagged `/all`,
    while the negative (non-nodule) and positive (nodule) values are tagged `/neg`
    and `/pos`, respectively. We don’t show the third logging statement for positive
    values here; it’s identical to the second except for swapping *neg* for *pos*
    in all cases.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个日志包含从所有样本计算得出的值，并标记为`/all`，而负（非结节）和正（结节）值分别标记为`/neg`和`/pos`。我们这里不显示正值的第三个日志声明；它与第二个相同，只是在所有情况下将*neg*替换为*pos*。
- en: 11.7 Running the training script
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.7 运行训练脚本
- en: Now that we’ve completed the core of the training.py script, we’ll actually
    start running it. This will initialize and train our model and print statistics
    about how well the training is going. The idea is to get this kicked off to run
    in the background while we’re covering the model implementation in detail. Hopefully
    we’ll have results to look at once we’re done.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了training.py脚本的核心部分，我们将开始实际运行它。这将初始化和训练我们的模型，并打印关于训练进展情况的统计信息。我们的想法是在我们详细介绍模型实现的同时，将其启动在后台运行。希望我们完成后能够查看结果。
- en: 'We’re running this script from the main code directory; it should have subdirectories
    called p2ch11, util, and so on. The `python` environment used should have all
    the libraries listed in requirements.txt installed. Once those libraries are ready,
    we can run:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从主代码目录运行此脚本；它应该有名为p2ch11、util等的子目录。所使用的`python`环境应该安装了requirements.txt中列出的所有库。一旦这些库准备就绪，我们就可以运行：
- en: '[PRE19]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ This is the command line for Linux/Bash. Windows users will probably need
    to invoke Python differently, depending on the install method used.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这是Linux/Bash的命令行。Windows用户可能需要根据所使用的安装方法以不同方式调用Python。
- en: As a reminder, we also provide a Jupyter Notebook that contains invocations
    of the training application.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们还提供了一个包含训练应用程序调用的Jupyter笔记本。
- en: Listing 11.19 code/p2_run_everything.ipynb
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单 11.19 code/p2_run_everything.ipynb
- en: '[PRE20]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If the first epoch seems to be taking a very long time (more than 10 or 20 minutes),
    it might be related to needing to prepare the cached data required by `LunaDataset`.
    See section 10.5.1 for details about the caching. The exercises for chapter 10
    included writing a script to pre-stuff the cache in an efficient manner. We also
    provide the prepcache.py file to do the same thing; it can be invoked with `python
    -m p2ch11 .prepcache`. Since we repeat our dsets.py files per chapter, the caching
    will need to be repeated for every chapter. This is somewhat space and time inefficient,
    but it means we can keep the code for each chapter much more well contained. For
    your future projects, we recommend reusing your cache more heavily.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一个时代似乎需要很长时间（超过 10 或 20 分钟），这可能与需要准备 `LunaDataset` 需要的缓存数据有关。有关缓存的详细信息，请参阅第10.5.1节。第10章的练习包括编写一个脚本以有效地预先填充缓存。我们还提供了
    prepcache.py 文件来执行相同的操作；可以使用 `python -m p2ch11 .prepcache` 调用它。由于我们每章都重复我们的 dsets.py
    文件，因此缓存需要为每一章重复。这在一定程度上是空间和时间上的低效，但这意味着我们可以更好地保持每一章的代码更加完整。对于您未来的项目，我们建议更多地重用您的缓存。
- en: 'Once training is underway, we want to make sure we’re using the computing resources
    at hand the way we expect. An easy way to tell if the bottleneck is data loading
    or computation is to wait a few moments after the script starts to train (look
    for output like `E1 Training 16/7750, done at...`) and then check both `top` and
    `nvidia-smi`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练开始，我们要确保我们正在按照预期使用手头的计算资源。判断瓶颈是数据加载还是计算的一个简单方法是在脚本开始训练后等待几分钟（查看类似 `E1 Training
    16/7750, done at...` 的输出），然后同时检查 `top` 和 `nvidia-smi`：
- en: If the eight Python worker processes are consuming >80% CPU, then the cache
    probably needs to be prepared (we know this here because the authors have made
    sure there aren’t CPU bottlenecks in this project’s implementation; this won’t
    be generally true).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果八个 Python 工作进程消耗了 >80% 的 CPU，那么缓存可能需要准备（我们知道这一点是因为作者已经确保在这个项目的实现中没有 CPU 瓶颈；这不会是普遍的情况）。
- en: If `nvidia-smi` reports that `GPU-Util` is >80%, then you’re saturating your
    GPU. We’ll discuss some strategies for efficient waiting in section 11.7.2.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `nvidia-smi` 报告 `GPU-Util` >80%，那么你的 GPU 已经饱和了。我们将在第11.7.2节讨论一些有效等待的策略。
- en: The intent is that the GPU is saturated; we want to use as much of that computing
    power as we can to complete epochs quickly. A single NVIDIA GTX 1080 Ti should
    complete an epoch in under 15 minutes. Since our model is relatively simple, it
    doesn’t take a lot of CPU preprocessing for the CPU to be the bottleneck. When
    working with models with greater depth (or more needed calculations in general),
    processing each batch will take longer, which will increase the amount of CPU
    processing we can do before the GPU runs out of work before the next batch of
    input is ready.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的意图是 GPU 饱和；我们希望尽可能多地利用计算能力来快速完成时代。一块 NVIDIA GTX 1080 Ti 应该在 15 分钟内完成一个时代。由于我们的模型相对简单，CPU
    不需要太多的预处理才能成为瓶颈。当处理更深的模型（或者总体需要更多计算的模型）时，处理每个批次将需要更长的时间，这将增加 CPU 处理的数量，以便在 GPU
    在下一批输入准备好之前耗尽工作之前。
- en: 11.7.1 Needed data for training
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.7.1 训练所需的数据
- en: If the number of samples is less than 495,958 for training or 55,107 for validation,
    it might make sense to do some sanity checking to be sure the full data is present
    and accounted for. For your future projects, make sure your dataset returns the
    number of samples that you expect.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如果训练样本数量少于 495,958 个，验证样本数量少于 55,107 个，可能有必要进行一些合理性检查，以确保完整的数据已经准备就绪。对于您未来的项目，请确保您的数据集返回您期望的样本数量。
- en: 'First, let’s take a look at the basic directory structure of our data-unversioned/
    part2/luna directory:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下我们的 data-unversioned/ part2/luna 目录的基本目录结构：
- en: '[PRE21]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Next, let’s make sure we have one .mhd file and one .raw file for each series
    UID
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们确保每个系列 UID 都有一个 .mhd 文件和一个 .raw 文件
- en: '[PRE22]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'and that we have the overall correct number of files:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 以及我们是否有正确数量的文件：
- en: '[PRE23]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If all of these seem right but things still aren’t working, ask on Manning LiveBook
    ([https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-11](https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-11))
    and hopefully someone can help get things sorted out.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有这些看起来都正确，但事情仍然不顺利，请在 Manning LiveBook 上提问（[https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-11](https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-11)），希望有人可以帮助解决问题。
- en: '11.7.2 Interlude: The enumerateWithEstimate function'
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.7.2 插曲：enumerateWithEstimate 函数
- en: Working with deep learning involves a lot of waiting. We’re talking about real-world,
    sitting around, glancing at the clock on the wall, a watched pot never boils (but
    you could fry an egg on the GPU), straight up *boredom*.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习涉及大量的等待。我们谈论的是现实世界中坐在那里，看着墙上的时钟，一个看着的壶永远不会煮开（但你可以在 GPU 上煎蛋），纯粹的 *无聊*。
- en: 'The only thing worse than sitting and staring at a blinking cursor that hasn’t
    moved for over an hour is flooding your screen with this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一比坐在那里盯着一个一个小时都没有移动的闪烁光标更糟糕的是，让您的屏幕充斥着这些：
- en: '[PRE24]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: At least the quietly blinking cursor doesn’t blow out your scrollback buffer!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 至少安静闪烁的光标不会让你的滚动缓冲区溢出！
- en: Fundamentally, while doing all this waiting, we want to answer the question
    “Do I have time to go refill my water glass?” along with follow-up questions about
    having time to
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上说，在所有这些等待的过程中，我们想要回答“我有时间去倒满水杯吗？”这个问题，以及关于是否有时间的后续问题
- en: Brew a cup of coffee
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 冲一杯咖啡
- en: Grab dinner
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 准备晚餐
- en: Grab dinner in Paris[⁵](#pgfId-1074805)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在巴黎吃晚餐[⁵](#pgfId-1074805)
- en: 'To answer these pressing questions, we’re going to use our `enumerateWithEstimate`
    function. Usage looks like the following:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这些紧迫的问题，我们将使用我们的 `enumerateWithEstimate` 函数。使用方法如下：
- en: '[PRE25]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: That’s 8 lines of output for over 200 iterations lasting about 2 minutes. Even
    given the wide variance of `random.random()`, the function had a pretty decent
    estimate after 16 iterations (in less than 10 seconds). For loop bodies with more
    constant timing, the estimates stabilize even more quickly.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是超过200次迭代的8行输出。即使考虑到`random.random()`的广泛变化，该函数在16次迭代后（不到10秒）就有了相当不错的估计。对于具有更稳定时间的循环体，估计会更快地稳定下来。
- en: In terms of behavior, `enumerateWithEstimate` is almost identical to the standard
    `enumerate` (the differences are things like the fact that our function returns
    a generator, whereas `enumerate` returns a specialized `<enumerate object at 0x...>`).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 就行为而言，`enumerateWithEstimate`与标准的`enumerate`几乎完全相同（差异在于我们的函数返回一个生成器，而`enumerate`返回一个专门的`<enumerate
    object at 0x...>`）。
- en: Listing 11.20 util.py:143, `def` `enumerateWithEstimate`
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.20 util.py:143，`def` `enumerateWithEstimate`
- en: '[PRE26]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: However, the side effects (logging, specifically) are what make the function
    interesting. Rather than get lost in the weeds trying to cover every detail of
    the implementation, if you’re interested, you can consult the function docstring
    ([https://github .com/deep-learning-with-pytorch/dlwpt-code/blob/master/util/util.py#L143](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/util/util.py#L143))
    to get information about the function parameters and desk-check the implementation.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，副作用（特别是日志记录）才是使函数变得有趣的地方。与其陷入细节中试图覆盖实现的每个细节，如果您感兴趣，可以查阅函数文档字符串（[https://github
    .com/deep-learning-with-pytorch/dlwpt-code/blob/master/util/util.py#L143](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/util/util.py#L143)）以获取有关函数参数的信息并对实现进行桌面检查。
- en: Deep learning projects can be very time intensive. Knowing when something is
    expected to finish means you can use your time until then wisely, and it can also
    clue you in that something isn’t working properly (or an approach is unworkable)
    if the expected time to completion is much larger than expected.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习项目可能非常耗时。知道何时预计完成意味着您可以明智地利用这段时间，它还可以提示您某些地方出了问题（或者某种方法行不通），如果预计完成时间远远超出预期。
- en: '11.8 Evaluating the model: Getting 99.7% correct means we’re done, right?'
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.8 评估模型：达到99.7%的正确率意味着我们完成了，对吧？
- en: 'Let’s take a look at some (abridged) output from our training script. As a
    reminder, we’ve run this with the command line `python -m p2ch11.training`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下我们训练脚本的一些（缩减的）输出。作为提醒，我们使用命令行`python -m p2ch11.training`运行了这个脚本：
- en: '[PRE27]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: After one epoch of training, both the training and validation set show at least
    99.7% correct results. That’s an A+! Time for a round of high-fives, or at least
    a satisfied nod and smile. We just solved cancer! ... Right?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一轮训练，训练集和验证集都显示至少99.7%的正确结果。这是A+！是时候来一轮高五，或者至少满意地点点头微笑了。我们刚刚解决了癌症！...对吧？
- en: Well, no.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，不是。
- en: 'Let’s take a closer (less-abridged) look at that epoch 1 output:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地（不那么缩减地）看一下第1个时代的输出：
- en: '[PRE28]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: On the validation set, we’re getting non-nodules 100% correct, but the actual
    nodules are 100% wrong. The network is just classifying everything as not-a-nodule!
    The value 99.7% just means only approximately 0.3% of the samples are nodules.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证集上，我们对非结节的分类100%正确，但实际结节却100%错误。网络只是将所有东西都分类为非结节！数值99.7%只意味着大约0.3%的样本是结节。
- en: 'After 10 epochs, the situation is only marginally better:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 经过10个时代，情况只是稍微好转：
- en: '[PRE29]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The classification output remains the same--none of the nodule (aka positive)
    samples are correctly identified. It’s interesting that we’re starting to see
    some decrease in the `val_pos` loss, however, while not seeing a corresponding
    increase in the `val_neg` loss. This implies that the network *is* learning something.
    Unfortunately, it’s learning very, very slowly.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 分类输出保持不变--没有一个结节（也称为阳性）样本被正确识别。有趣的是，我们开始看到`val_pos`损失有所减少，然而，`val_neg`损失并没有相应增加。这意味着网络*正在*学习。不幸的是，它学习得非常，非常慢。
- en: Even worse, this particular failure mode is the most dangerous in the real world!
    We want to avoid the situation where we classify a tumor as an innocuous structure,
    because that would not facilitate a patient getting the evaluation and eventual
    treatment they might need. It’s important to understand the consequences for misclassification
    for all your projects, as that can have a large impact on how you design, train,
    and evaluate your model. We’ll discuss this more in the next chapter.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，这种特定的失败模式在现实世界中是最危险的！我们希望避免将肿瘤误分类为无害的结构，因为这不会促使患者接受可能需要的评估和最终治疗。了解所有项目的误分类后果很重要，因为这可能会对您设计、训练和评估模型的方式产生很大影响。我们将在下一章中更详细地讨论这个问题。
- en: Before we get to that, however, we need to upgrade our tooling to make the results
    easier to understand. We’re sure you love to squint at columns of numbers as much
    as anyone, but pictures are worth a thousand words. Let’s graph some of these
    metrics.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在此之前，我们需要升级我们的工具，使结果更易于理解。我们相信您和任何人一样喜欢盯着数字列，但图片价值千言。让我们绘制一些这些指标的图表。
- en: 11.9 Graphing training metrics with TensorBoard
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.9 使用TensorBoard绘制训练指标图表
- en: We’re going to use a tool called TensorBoard as a quick and easy way to get
    our training metrics out of our training loop and into some pretty graphs. This
    will allow us to follow the *trends* of those metrics, rather than only look at
    the instantaneous values per epoch. It gets much, much easier to know whether
    a value is an outlier or just the latest in a trend when you’re looking at a visual
    representation.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个名为TensorBoard的工具，作为一种快速简便的方式，将我们的训练指标从训练循环中提取出来，并呈现为一些漂��的图表。这将使我们能够跟踪这些指标的*趋势*，而不仅仅查看每个时代的瞬时值。当您查看可视化表示时，要知道一个值是异常值还是趋势的最新值就容易得多。
- en: “Hey, wait,” you might be thinking, “isn’t TensorBoard part of the TensorFlow
    project? What’s it doing here in my PyTorch book?”
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: “嘿，等等”，您可能会想，“TensorBoard不是TensorFlow项目的一部分吗？它在我的PyTorch书中做什么？”
- en: Well, yes, it is part of another deep learning framework, but our philosophy
    is “use what works.” There’s no reason to restrict ourselves by not using a tool
    just because it’s bundled with another project we’re not using. Both the PyTorch
    and TensorBoard devs agree, because they collaborated to add official support
    for TensorBoard into PyTorch. TensorBoard is great, and it’s got some easy-to-use
    PyTorch APIs that let us hook data from just about anywhere into it for quick
    and easy display. If you stick with deep learning, you’ll probably be seeing (and
    using) a *lot* of TensorBoard.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，是的，它是另一个深度��习框架的一部分，但我们的理念是“使用有效的工具”。没有理由限制自己不使用一个工具，只因为它捆绑在我们不使用的另一个项目中。PyTorch
    和 TensorBoard 的开发人员都同意，因为他们合作将 TensorBoard 的官方支持添加到 PyTorch 中。TensorBoard 很棒，它有一些易于使用的
    PyTorch API，让我们可以将数据从几乎任何地方连接到其中进行快速简单的显示。如果您坚持深度学习，您可能会看到（并使用）*很多* TensorBoard。
- en: In fact, if you’ve been running the chapter examples, you should already have
    some data on disk ready and waiting to be displayed. Let’s see how to run TensorBoard,
    and look at what it can show us.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果您一直在运行本章的示例，您应该已经有一些准备好并等待显示的数据在磁盘上。让我们看看如何运行 TensorBoard，并查看它可以向我们展示什么。
- en: 11.9.1 Running TensorBoard
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.9.1 运行 TensorBoard
- en: 'By default, our training script will write metrics data to the runs/ subdirectory.
    If you list the directory content, you might see something like this during your
    Bash shell session:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们的训练脚本将指标数据写入 runs/ 子目录。如果在 Bash shell 会话期间列出目录内容，您可能会看到类似于以下内容：
- en: '[PRE30]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ The single-epoch run from earlier
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 之前的单次运行
- en: ❷ The more recent 10-epoch training run
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 最近的 10 次训练运行
- en: To get the `tensorboard` program, install the `tensorflow` ([https://pypi.org/project/
    tensorflow](https://pypi.org/project/tensorflow)) Python package. Since we’re
    not actually going to use TensorFlow proper, it’s fine if you install the default
    CPU-only package. If you have another version of TensorBoard installed already,
    using that is fine too. Either make sure the appropriate directory is on your
    path, or invoke it with `../path/to/tensorboard --logdir runs/`. It doesn’t really
    matter where you invoke it from, as long as you use the `--logdir` argument to
    point it at where your data is stored. It’s a good idea to segregate your data
    into separate folders, as TensorBoard can get a bit unwieldy once you get over
    10 or 20 experiments. You’ll have to decide the best way to do that for each project
    as you go. Don’t be afraid to move data around after the fact if you need to.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取 `tensorboard` 程序，请安装 `tensorflow` ([https://pypi.org/project/tensorflow](https://pypi.org/project/tensorflow))
    Python 包。由于我们实际上不会使用 TensorFlow 本身，所以如果您安装默认的仅 CPU 包也是可以的。如果您已经安装了另一个版本的 TensorBoard，那也没问题。确保适当的目录在您的路径上，或者使用
    `../path/to/tensorboard --logdir runs/` 来调用它。从哪里调用它并不重要，只要您使用 `--logdir` 参数将其指向存储数据的位置即可。最好将数据分隔到单独的文件夹中，因为一旦进行了
    10 或 20 次实验，TensorBoard 可能会变得有些难以管理。您将不得不在每个项目中决定最佳的做法。如果需要，随时移动数据也是个好主意。
- en: 'Let’s start TensorBoard now:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始 TensorBoard 吧：
- en: '[PRE31]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ These messages might be different or not present for you; that’s fine.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些消息可能对您来说是不同的或不存在的；这没关系。
- en: Once that’s done, you should be able to point your browser at http://localhost:6006
    and see the main dashboard.[⁶](#pgfId-1075803) Figure 11.10 shows us what that
    looks like.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您应该能够将浏览器指向 http://localhost:6006 并查看主仪表板。图 11.10 展示了这是什么样子。
- en: '![](../Images/CH11_F10_Stevens2_GS.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F10_Stevens2_GS.png)'
- en: FIgure 11.10 The main TensorBoard UI, showing a paired set of training and validation
    runs
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 主要的 TensorBoard 用户界面，显示了一对训练和验证运行
- en: 'Along the top of the browser window, you should see the orange header. The
    right side of the header has the typical widgets for settings, a link to the GitHub
    repository, and the like. We can ignore those for now. The left side of the header
    has items for the data types we’ve provided. You should have at least the following:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器窗口的顶部，您应该看到橙色的标题。标题的右侧有用于设置的典型小部件，一个指向 GitHub 存储库的链接等。我们现在可以忽略这些。标题的左侧有我们提供的数据类型的项目。您至少应该有以下内容：
- en: Scalars (the default tab)
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标量（默认选项卡）
- en: Histograms
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直方图
- en: Precision-Recall Curves (shown as PR Curves)
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确-召回曲线（显示为 PR 曲线）
- en: You might see Distributions as well as the second UI tab (to the right of Scalars
    in figure 11.10). We won’t use or discuss those here. Make sure you’ve selected
    Scalars by clicking it.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还会看到分布，以及图 11.10 中标量右侧的第二个 UI 选项卡。我们这里不会使用或讨论这些。确保您已经通过单击选择了标量。
- en: On the left is a set of controls for display options, as well as a list of runs
    that are present. The smoothing option can be useful if you have particularly
    noisy data; it will calm things down so that you can pick out the overall trend.
    The original non-smoothed data will still be visible in the background as a faded
    line in the same color. Figure 11.11 shows this, although it might be difficult
    to discern when printed in black and white.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧是一组用于显示选项的控件，以及当前存在的运行列表。如果您的数据特别嘈杂，平滑选项可能会很有用；它会使事情变得平静，这样您就可以找出整体趋势。原始的非平滑数据仍然以相同颜色的淡线的形式显示在背景中。图
    11.11 展示了这一点，尽管在黑白打印时可能难以辨认。
- en: '![](../Images/CH11_F11_Stevens2_GS.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F11_Stevens2_GS.png)'
- en: FIgure 11.11 The TensorBoard sidebar with Smoothing set to 0.6 and two runs
    selected for display
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 带有平滑设置为 0.6 和选择了两个运行以显示的 TensorBoard 侧边栏
- en: Depending on how many times you’ve run the training script, you might have multiple
    runs to select from. With too many runs being rendered, the graphs can get overly
    noisy, so don’t hesitate to deselect runs that aren’t of interest at the moment.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您运行训练脚本的次数，您可能有多个运行可供选择。如果呈现的运行太多，图表可能会变得过于嘈杂，所以不要犹豫在目前不感兴趣的情况下取消选择运行。
- en: 'If you want to permanently remove a run, the data can be deleted from disk
    while TensorBoard is running. You can do this to get rid of experiments that crashed,
    had bugs, didn’t converge, or are so old they’re no longer interesting. The number
    of runs can grow pretty quickly, so it can be helpful to prune it often and to
    rename runs or move runs that are particularly interesting to a more permanent
    directory so they don’t get deleted by accident. To remove both the `train` and
    `validation` runs, execute the following (after changing the chapter, date, and
    time to match the run you want to remove):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想永久删除一个运行，可以在TensorBoard运行时从磁盘中删除数据。您可以这样做来摆脱崩溃、有错误、不收敛或太旧不再有趣的实验。运行的数量可能会增长得相当快，因此经常修剪并重命名运行或将特别有趣的运行移动到更永久的目录以避免意外删除是有帮助的。要删除`train`和`validation`运行，执行以下���作（在更改章节、日期和时间以匹配要删除的运行之后）：
- en: '[PRE32]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Keep in mind that removing runs will cause the runs that are later in the list
    to move up, which will result in them being assigned new colors.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，删除运行将导致列表中后面的运行向上移动，这将导致它们被分配新的颜色。
- en: 'OK, let’s get to the point of TensorBoard: the pretty graphs! The main part
    of the screen should be filled with data from gathering training and validation
    metrics, as shown in figure 11.12.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们来谈谈TensorBoard的要点：漂亮的图表！屏幕的主要部分应该填满了从收集训练和验证指标中得到的数据，如图11.12所示。
- en: '![](../Images/CH11_F12_Stevens2_GS.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F12_Stevens2_GS.png)'
- en: FIgure 11.12 The main TensorBoard data display area showing us that our results
    on actual nodules are downright awful
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 主要的TensorBoard数据显示区域向我们展示了我们在实际结节上的结果非常糟糕
- en: That’s much easier to parse and absorb than `E1 trn_pos 924.34 loss, 0.2% correct
    (3 of 1215)`! Although we’re going to save discussion of what these graphs are
    telling us for section 11.10, now would be a good time to make sure it’s clear
    what these numbers correspond to from our training program. Take a moment to cross-reference
    the numbers you get by mousing over the lines with the numbers spit out by training.py
    during the same training run. You should see a direct correspondence between the
    Value column of the tooltip and the values printed during training. Once you’re
    comfortable and confident that you understand exactly what TensorBoard is showing
    you, let’s move on and discuss how to get these numbers to appear in the first
    place.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 比起`E1 trn_pos 924.34 loss, 0.2% correct (3 of 1215)`，这样解析和吸收起来要容易得多！虽然我们将把讨论这些图表告诉我们的内容保存到第11.10节，现在是一个好时机确保清楚这些数字对应我们的训练程序中的内容。花点时间交叉参考你通过鼠标悬停在线条上得到的数字和训练.py在同一训练运行期间输出的数字。你应该看到工具提示的值列和训练期间打印的值之间有直接对应关系。一旦你对TensorBoard显示的内容感到舒适和自信，让我们继续讨论如何让这些数字首次出现。
- en: 11.9.2 Adding TensorBoard support to the metrics logging function
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.9.2 将TensorBoard支持添加到度量记录函数
- en: We are going to use the `torch.utils.tensorboard` module to write data in a
    format that TensorBoard will consume. This will allow us to write metrics for
    this and any other project quickly and easily. TensorBoard supports a mix of NumPy
    arrays and PyTorch tensors, but since we don’t have any reason to put our data
    into NumPy arrays, we’ll use PyTorch tensors exclusively.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`torch.utils.tensorboard`模块以TensorBoard可消费的格式编写数据。这将使我们能够快速轻松地为此项目和任何其他项目编写指标。TensorBoard支持NumPy数组和PyTorch张量的混合使用，但由于我们没有将数据放入NumPy数组的理由，我们将专门使用PyTorch张量。
- en: The first thing we need do is to create our `SummaryWriter` objects (which we
    imported from `torch.utils.tensorboard`). The only parameter we’re going to pass
    in is `log_dir`, which we will initialize to something like `runs/p2ch11/2020-01-01_12
    .55.27-trn-dlwpt`. We can add a comment argument to our training script to change
    `dlwpt` to something more informative; use `python -m p2ch11.training --help`
    for more information.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是创建我们的`SummaryWriter`对象（我们从`torch.utils.tensorboard`导入）。我们将传入的唯一参数初始化为类似`runs/p2ch11/2020-01-01_12
    .55.27-trn-dlwpt`的内容。我们可以在我们的训练脚本中添加一个注释参数，将`dlwpt`更改为更具信息性的内容；使用`python -m p2ch11.training
    --help`获取更多信息。
- en: We create two writers, one each for the training and validation runs. Those
    writers will be reused for every epoch. When the `SummaryWriter` class gets initialized,
    it also creates the `log_dir` directories as a side effect. These directories
    show up in TensorBoard and can clutter the UI with empty runs if the training
    script crashes before any data gets written, which can be common when you’re experimenting
    with something. To avoid writing too many empty junk runs, we wait to instantiate
    the `SummaryWriter` objects until we’re ready to write data for the first time.
    This function is called from `logMetrics()`.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建两个写入器，一个用于训练运行，一个用于验证运行。这些写入器将在每个时代重复使用。当`SummaryWriter`类被初始化时，它还会作为副作用创建`log_dir`目录。如果训练脚本在写入任何数据之前崩溃，这些目录将显示在TensorBoard中，并且可能会用空运行杂乱UI，这在你尝试某些东西时很常见。为了避免写入太多空的垃圾运行，我们等到准备好第一次写入数据时才实例化`SummaryWriter`对象。这个函数从`logMetrics()`中调用。
- en: Listing 11.21 training.py:127, `.initTensorboardWriters`
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.21 training.py:127，`.initTensorboardWriters`
- en: '[PRE33]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: If you recall, the first epoch is kind of a mess, with the early output in the
    training loop being essentially random. When we save the metrics from that first
    batch, those random results end up skewing things a bit. Recall from figure 11.11
    that TensorBoard has smoothing to remove noise from the trend lines, which helps
    somewhat.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回忆起来，第一个时代有点混乱，训练循环中的早期输出基本上是随机的。当我们保存来自第一批次的指标时，这些随机结果最终会使事情有点偏斜。从图11.11中可以看出，TensorBoard具有平滑功能，可以消除趋势线上的噪音，这在一定程度上有所帮助。
- en: Another approach could be to skip metrics entirely for the first epoch’s training
    data, although our model trains quickly enough that it’s still useful to see the
    first epoch’s results. Feel free to change this behavior as you see fit; the rest
    of part 2 will continue with this pattern of including the first, noisy training
    epoch.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是在第一个epoch的训练数据中完全跳过指标，尽管我们的模型训练速度足够快，仍然有必要查看第一个epoch的结果。随意根据需要更改此行为；第2部分的其余部分将继续采用包括第一个嘈杂训练epoch的模式。
- en: '*tip* If you end up doing a lot of experiments that result in exceptions or
    killing the training script relatively quickly, you might be left with a number
    of junk runs cluttering up your runs/ directory. Don’t be afraid to clean those
    out!'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示* 如果你最终进行了许多实验，导致异常或相对快速终止训练脚本，你可能会留下许多垃圾运行，混乱了你的runs/目录���不要害怕清理它们！'
- en: Writing scalars to TensorBoard
  id: totrans-311
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向TensorBoard写入标量
- en: Writing scalars is straightforward. We can take the `metrics_dict` we’ve already
    constructed and pass in each key/value pair to the `writer.add_scalar` method.
    The `torch.utils.tensorboard.SummaryWriter` class has the `add_scalar` method
    ([http:// mng.bz/RAqj](http://mng.bz/RAqj)) with the following signature.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 写入标量很简单。我们可以取出已经构建的`metrics_dict`，并将每个键值对传递给`writer.add_scalar`方法。`torch.utils.tensorboard.SummaryWriter`类具有`add_scalar`方法（[http://
    mng.bz/RAqj](http://mng.bz/RAqj)），具有以下签名。
- en: Listing 11.22 PyTorch torch/utils/tensorboard/writer.py:267
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单11.22 PyTorch torch/utils/tensorboard/writer.py:267
- en: '[PRE34]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `tag` parameter tells TensorBoard which graph we’re adding values to, and
    the `scalar_value` parameter is our data point’s Y-axis value. The `global_step`
    parameter acts as the X-axis value.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`tag`参数告诉TensorBoard我们要向哪个图形添加值，`scalar_value`参数是我们数据点的Y轴值。`global_step`参数充当X轴值。'
- en: Recall that we updated the `totalTrainingSamples_count` variable inside the
    `doTraining` function. We’ll use `totalTrainingSamples_count` as the X-axis of
    our TensorBoard plots by passing it in as the `global_step` parameter. Here’s
    what that looks like in our code.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们在`doTraining`函数内更新了`totalTrainingSamples_count`变量。我们将通过将其作为`global_step`参数传入来将`totalTrainingSamples_count`用作我们TensorBoard图表的X轴。以下是我们代码中的示例。
- en: Listing 11.23 training.py:323, `LunaTrainingApp.logMetrics`
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 代码清单11.23 training.py:323，`LunaTrainingApp.logMetrics`
- en: '[PRE35]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note that the slashes in our key names (such as `'loss/all'`) result in TensorBoard
    grouping the charts by the substring before the `'/'`.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们键名中的斜杠（例如`'loss/all'`）导致TensorBoard通过斜杠前的子字符串对图表进行分组。
- en: The documentation suggests that we should be passing in the epoch number as
    the `global_step` parameter, but that results in some complications. By using
    the number of training samples presented to the network, we can do things like
    change the number of samples per epoch and still be able to compare those future
    graphs to the ones we’re creating now. Saying that a model trains in half the
    number of epochs is meaningless if each epoch takes four times as long! Keep in
    mind that this might not be standard practice, however; expect to see a variety
    of values used for the global step.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 文档建议我们应该将epoch数作为`global_step`参数传入，但这会导致一些复杂性。通过使用向网络呈现的训练样本数，我们可以做一些事情，比如改变每个epoch的样本数，仍然能够将未来的图形与我们现在创建的图形进行比较。如果每个epoch花费的时间是四倍长，那么说一个模型在一半的epoch中训练是没有意义的！请记住，这可能不是标准做法；然而，预计会看到各种值用于全局步骤。
- en: 11.10 Why isn’t the model learning to detect nodules?
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.10 为什么模型无法学习检测结节？
- en: Our model is clearly learning *something*--the loss trend lines are consistent
    as epochs increase, and the results are repeatable. There is a disconnect, however,
    between what the model is learning and what we *want* it to learn. What’s going
    on? Let’s use a quick metaphor to illustrate the problem.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型显然在学习*某些东西*--随着epoch增加，损失趋势线是一致的，结果是可重复的。然而，模型正在学习的内容与我们*希望*它学习的内容之间存在分歧。发生了什么？让我们用一个简单的比喻来说明问题。
- en: Imagine that a professor gives students a final exam consisting of 100 True/False
    questions. The students have access to previous versions of this professor’s tests
    going back 30 years, and every time there are only *one or two* questions with
    a True answer. The other 98 or 99 are False, every time.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一位教授给学生一份包含100个真/假问题的期末考试。学生可以查阅这位教授过去30年的考试版本，每次只有*一个或两个*问题的答案是True。其他98或99个问题每次都是False。
- en: 'Assuming that the grades aren’t on a curve and instead have a typical scale
    of 90% correct or better being an A, and so on, it is trivial to get an A+: just
    mark every question as False! Let’s imagine that this year, there is only one
    True answer. A student like the one on the left in figure 11.13 who mindlessly
    marked every answer as False would get a 99% on the final but wouldn’t really
    demonstrate that they had learned anything (beyond how to cram from old tests,
    of course). That’s basically what our model is doing right now.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 假设分数不是按曲线划分的，而是有一个典型的90%正确或更高为A的等级刻度，便很容易获得A+：只需将每个问题标记为False！让我们想象今年只有一个True答案。像图11.13中左侧的学生那样毫无头绪地将每个答案标记为False的学生会在期末考试中得到99%的分数，但实际上并没有证明他们学到了什么（除了如何从旧测试中临时抱佛脚）。这基本上就是我们的模型目前正在做的事情。
- en: '![](../Images/CH11_F13_Stevens2_GS.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F13_Stevens2_GS.png)'
- en: FIgure 11.13 A professor giving two students the same grade, despite different
    levels of knowledge. Question 9 is the only question with an answer of True.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 一位教授给予两名学生相同的分数，尽管知识水平不同。问题9是唯一一个答案为True的问题。
- en: Contrast that with a student like the one on the right who also got 99% of the
    questions correct, but did so by answering two questions with True. Intuition
    tells us that the student on the right in figure 11.13 probably has a much better
    grasp of the material than the all-False student. Finding the one True question
    while only getting one answer wrong is pretty difficult! Unfortunately, neither
    our students’ grades nor our model’s grading scheme reflect this gut feeling.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 将其与右侧学生进行对比，右侧学生也回答了99%的问题，但是通过回答两个问题为True来实现。直觉告诉我们，图11.13中右侧的学生可能比所有回答为False的学生更好地掌握了材料。在只有一个错误答案的情况下找到一个正确答案是相当困难的！不幸的是，我们的学生分数和我们模型的评分方案都没有反映这种直觉。
- en: We have a similar situation, where 99.7% of the answers to “Is this candidate
    a nodule?” are “Nope.” Our model is taking the easy way out and answering False
    on every question.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个类似的情况，99.7%的“这个候选人是结节吗？”的答案是“不是”。我们的模型正在采取简单的方式，对每个问题都回答False。
- en: Still, if we look back at our model’s numbers more closely, the loss on the
    training and validation sets *is* decreasing! The fact that we’re getting any
    traction at all on the cancer-detection problem should give us hope. It will be
    the work of the next chapter to realize this potential. We’ll start chapter 12
    by introducing some new, relevant terminology, and then we’ll come up with a better
    grading scheme that doesn’t lend itself to being gamed quite as easily as what
    we’ve done so far.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们更仔细地查看模型的数字，训练集和验证集上的损失*是*在减少！我们在癌症检测问题上取得任何进展都应该给我们带来希望。下一章的工作将是实现这一潜力。我们将在第12章开始时介绍一些新的相关术语，然后我们将提出一个更好的评分方案，不像我们迄今为止所做的那样容易被操纵。
- en: 11.11 Conclusion
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.11 结论
- en: We’ve come a long way this chapter--we now have a model and a training loop,
    and are able to consume the data we produced in the last chapter. Our metrics
    are being logged to the console as well as graphed visually.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们走了很长的路--我们现在有了一个模型和一个训练循环，并且能够使用我们在上一章中生成的数据。我们的指标不仅被记录在控制台上，还以图形方式呈现。
- en: While our results aren’t usable yet, we’re actually closer than it might seem.
    In chapter 12, we will improve the metrics we’re using to track our progress,
    and use them to inform the changes we need to make to get our model producing
    reasonable results.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们的结果还不能使用，但实际上我们比看起来更接近。在第12章中，我们将改进用于跟踪进度的指标，并利用它们来指导我们需要做出的改变，以使我们的模型产生合理的结果。
- en: 11.12 Exercises
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.12 练习
- en: Implement a program that iterates through a `LunaDataset` instance by wrapping
    it in a `DataLoader` instance, while timing how long it takes to do so. Compare
    these times to the times from the exercises in chapter 10\. Be aware of the state
    of the cache when running the script.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个程序，通过将`LunaDataset`实例包装在`DataLoader`实例中来迭代，同时计时完成此操作所需的时间。将这些时间与第10章练习中的时间进行比较。在运行脚本时要注意缓存的状态。
- en: What impact does setting `num_workers=...` to 0, 1, and 2 have?
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`num_workers=...`设置为0、1和2会产生什么影响？
- en: What are the highest values your machine will support for a given combination
    of `batch_size=...` and `num_workers=...` without running out of memory?
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定`batch_size=...`和`num_workers=...`组合下，您的机器支持的最高值是多少，而不会耗尽内存？
- en: Reverse the sort order of `noduleInfo_list`. How does that change the behavior
    of the model after one epoch of training?
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 颠倒`noduleInfo_list`的排序顺序。在训练一个周期后，模型的行为会如何改变？
- en: Change `logMetrics` to alter the naming scheme of the runs and keys that are
    used in TensorBoard.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`logMetrics`更改为修改在TensorBoard中使用的运行和键的命名方案。
- en: Experiment with different forward-slash placement for keys passed in to `writer.add_scalar`.
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试不同的斜杠放置方式，将键传递给`writer.add_scalar`。
- en: Have both training and validation runs use the same writer, and add the `trn`
    or `val` string to the name of the key.
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让训练和验证运行使用相同的写入器，并在键的名称中添加`trn`或`val`字符串。
- en: Customize the naming of the log directory and keys to suit your taste.
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自定义日志目录和键���命名以适应您的口味。
- en: 11.13 Summary
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.13 总结
- en: Data loaders can be used to load data from arbitrary datasets in multiple processes.
    This allows otherwise-idle CPU resources to be devoted to preparing data to feed
    to the GPU.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载器可以在多个进程中从任意数据集加载数据。这使得否则空闲的CPU资源可以用于准备数据以供GPU使用。
- en: Data loaders load multiple samples from a dataset and collate them into a batch.
    PyTorch models expect to process batches of data, not individual samples.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载器从数据集中加载多个样本并将它们整理成一个批次。PyTorch模型期望处理数据批次，而不是单个样本。
- en: Data loaders can be used to manipulate arbitrary datasets by changing the relative
    frequency of individual samples. This allows for “after-market” tweaks to a dataset,
    though it might make more sense to change the dataset implementation directly.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载器可以通过改变个别样本的相对频率来操作任意数据集。这允许对数据集进行“售后”调整，尽管直接更改数据集实现可能更合理。
- en: We will use PyTorch’s `torch.optim.SGD` (stochastic gradient descent) optimizer
    with a learning rate of 0.001 and a momentum of 0.99 for the majority of part
    2\. These values are also reasonable defaults for many deep learning projects.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在第二部分中使用PyTorch的`torch.optim.SGD`（随机梯度下降）优化器，学习率为0.001，动量为0.99。这些值也是许多深度学习项目的合理默认值。
- en: Our initial model for classification will be very similar to the model we used
    in chapter 8\. This lets us get started with a model that we have reason to believe
    will be effective. We can revisit the model design if we think it’s the thing
    preventing our project from performing better.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们用于分类的初始模型将与第8章中使用的模型非常相似。这让我们可以开始使用一个我们有理由相信会有效的模型。如果我们认为模型设计是阻止项目表现更好的原因，我们可以重新审视模型设计。
- en: The choice of metrics that we monitor during training is important. It is easy
    to accidentally pick metrics that are misleading about how the model is performing.
    Using the overall percentage of samples classified correctly is not useful for
    our data. Chapter 12 will detail how to evaluate and choose better metrics.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练过程中监控的指标选择很重要。很容易不小心选择那些对模型表现误导性的指标。使用样本分类正确的整体百分比对我们的数据没有用处。第12章将详细介绍如何评估和选择更好的指标。
- en: TensorBoard can be used to display a wide range of metrics visually. This makes
    it much easier to consume certain forms of information (particularly trend data)
    as they change per epoch of training.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard可以用来直观显示各种指标。这使得消化某些形式的信息（特别是趋势数据）在每个训练周期中发生变化时更容易。
- en: '* * *'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)Any shell, really, but if you’re using a non-Bash shell, you already knew
    that.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1.)任何shell都可以，但如果你使用的是非Bash shell，你已经知道这一点。
- en: ^(2.)Remember that we’re actually working in 3D, despite the 2D figure.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ^(2.)请记住，尽管是2D图，但我们实际上是在3D中工作。
- en: ^(3.)Which is why there’s an exercise to experiment with both in the next chapter!
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ^(3.)这就是为什么下一章有一个练习来尝试两者的原因！
- en: ^(4.)There are numerical stability benefits for doing so. Propagating gradients
    accurately through an exponential calculated using 32-bit floating-point numbers
    can be problematic.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ^(4.)这样做有数值稳定性的好处。通过使用32位浮点数计算的指数来准确传播梯度可能会有问题。
- en: ^(5.)If getting dinner in France doesn’t involve an airport, feel free to substitute
    “Paris, Texas” to make the joke work; [https://en.wikipedia.org/wiki/Paris_(disambiguation)](https://en.wikipedia.org/wiki/Paris_(disambiguation)).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ^(5.)如果在法国吃晚餐不涉及机场，可以随意用“Texas的巴黎”来制造笑话；[https://en.wikipedia.org/wiki/Paris_(disambiguation)](https://en.wikipedia.org/wiki/Paris_(disambiguation))。
- en: ^(6.)If you’re running training on a different computer from your browser, you’ll
    need to replace *localhost* with the appropriate hostname or IP address.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ^(6.)如果你在不同的计算机上运行训练，你需要用适当的主机名或IP地址替换*localhost*。
