- en: Conclusions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 原文：[https://deeplearningwithpython.io/chapters/chapter20_conclusion](https://deeplearningwithpython.io/chapters/chapter20_conclusion)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://deeplearningwithpython.io/chapters/chapter20_conclusion](https://deeplearningwithpython.io/chapters/chapter20_conclusion)
- en: We’ll start with a bird’s-eye view of what you should take away from this book.
    This should refresh your memory regarding some of the concepts you’ve learned.
    Then we’ll give you a short list of resources and strategies for learning further
    about machine learning and staying up to date with new advances.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这本书应该吸取的总体观点开始。这应该会刷新你对所学的一些概念的记忆。然后，我们将为你提供一份关于进一步学习机器学习和跟上新技术进展的资源与策略的简要列表。
- en: Becoming an effective AI practitioner is a journey, and finishing this book
    is merely your first step on it. I want to make sure you realize this and are
    properly equipped to take the next steps of this journey on your own.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 成为有效的AI实践者是一个旅程，完成这本书只是你在这个旅程上的第一步。我想确保你意识到这一点，并准备好独立迈出下一步。
- en: Key concepts in review
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复习中的关键概念
- en: This section briefly synthesizes key takeaways from this book. If you ever need
    a quick refresher to help you recall what you’ve learned, you can read these few
    pages.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要总结了本书的关键要点。如果你需要快速复习以帮助回忆所学内容，可以阅读这几页。
- en: Various approaches to artificial intelligence
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能的多种方法
- en: 'First, deep learning isn’t synonymous with artificial intelligence (AI), or
    even with machine learning:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，深度学习并不等同于人工智能（AI），甚至也不等同于机器学习：
- en: '*Artificial intelligence* (AI) is an ancient, broad field that can generally
    be understood as “all attempts to automate human cognitive processes.” This can
    range from the very basic, such as an Excel spreadsheet, to the very advanced,
    like a humanoid robot that can walk and talk.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能*（AI）是一个古老而广泛的领域，通常可以理解为“所有尝试自动化人类认知过程”的尝试。这可以从非常基础的，如Excel电子表格，到非常高级的，如能够行走和说话的人形机器人。'
- en: '*Machine learning* is a specific subfield of AI that aims at automatically
    developing programs (called *models*) purely from exposure to training data. This
    process of turning data into a program is called *learning*. Although machine
    learning has been around for a long time, it only started to take off in the 1990s,
    before becoming the dominant form of AI in the 2000s.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习* 是人工智能的一个特定子领域，旨在通过仅从训练数据中接触来自动开发程序（称为 *模型*）。将数据转化为程序的过程称为 *学习*。尽管机器学习已经存在很长时间了，但它直到20世纪90年代才开始起飞，并在21世纪初成为人工智能的主导形式。'
- en: '*Deep learning* is one of many branches of machine learning, where the models
    are long chains of geometric transformations, applied one after the other. These
    operations are structured into modules called *layers*: deep learning models are
    typically stacks of layers — or, more generally, graphs of layers. These layers
    are parameterized by *weights*, which are the parameters learned during training.
    The *knowledge* of a model is stored in its weights, and the process of learning
    consists of finding “good values” for these weights — values that minimize a *loss
    function*. Because the chain of geometric transformations considered is differentiable,
    updating the weights to minimize the loss function is done efficiently via *gradient
    descent*.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习* 是机器学习众多分支之一，其中的模型是几何变换的长链，依次应用。这些操作被组织成称为 *层* 的模块：深度学习模型通常是层的堆叠——或者更普遍地说，是层的图。这些层由
    *权重* 参数化，这些权重是在训练期间学习的参数。模型的 *知识* 存储在其权重中，学习过程包括找到这些权重的“良好值”——这些值最小化 *损失函数*。因为考虑的几何变换链是可微分的，所以通过
    *梯度下降* 高效地更新权重以最小化损失函数。'
- en: '*Generative AI* is a specific subset of deep learning, where models are capable
    of generating text, images, videos, or sound. These models tend to be very large
    — billions of parameters. They’re trained in a self-supervised manner; that is,
    they’re trained to reconstruct artificially missing or corrupted parts of an input
    — for instance, denoising images, predicting the next word in a sentence, and
    so on. This learning process enables the models to learn sophisticated “maps”
    (embedding manifolds) of their input space, which can be used for sampling new
    inputs. These models have launched AI into its “consumer” era with the rise of
    products like ChatGPT or Midjourney.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生成式AI* 是深度学习的一个特定子集，其中的模型能够生成文本、图像、视频或声音。这些模型通常非常大——拥有数十亿个参数。它们以自监督的方式进行训练；也就是说，它们被训练来重建输入中人工缺失或损坏的部分——例如，去噪图像、预测句子中的下一个单词等。这个过程使得模型能够学习其输入空间的复杂“映射”（嵌入流形），这些映射可以用于采样新的输入。这些模型随着ChatGPT或Midjourney等产品的兴起，将AI带入了“消费者”时代。'
- en: Even though deep learning is just one among many approaches to machine learning,
    it isn’t on an equal footing with the others. Deep learning is a breakout success.
    Here’s why.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习只是机器学习众多方法中的一种，但它并不与其他方法处于同等地位。深度学习是一次突破性的成功。原因如下。
- en: What makes deep learning special within the field of machine learning
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习在机器学习领域中的特殊性
- en: 'In the span of only a few years, deep learning has achieved tremendous breakthroughs
    across a wide range of tasks that have been historically perceived as extremely
    difficult for computers, especially in the area of machine perception: extracting
    useful information from images, videos, sound, and more. Given sufficient training
    data (in particular, training data appropriately labeled by humans), deep learning
    makes it possible to extract from perceptual data almost anything a human could.
    Hence, it’s sometimes said that deep learning has “solved perception” — although
    that’s true only for a fairly narrow definition of perception.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在短短几年内，深度学习在一系列历史上被认为对计算机来说极其困难的任务上取得了巨大的突破，尤其是在机器感知领域：从图像、视频、声音中提取有用信息等。在提供足够的训练数据（特别是由人类适当标注的训练数据）的情况下，深度学习使得从感知数据中提取几乎任何人类能够提取的内容成为可能。因此，有时人们会说深度学习“解决了感知”问题——尽管这仅适用于对感知的狭义定义。
- en: 'Due to its unprecedented technical successes, deep learning has singlehandedly
    brought about the third and by far the largest *AI summer*: a period of intense
    interest, investment, and hype in the field of AI. As this book is being written,
    we’re in the middle of it. Whether this period will end in the near future and
    what happens after it ends are topics of debate. One thing is certain: in stark
    contrast with previous AI summers, deep learning has provided enormous business
    value to both large and small technology companies and has become a huge consumer
    success, enabling human-level speech recognition, chatbot assistants, photorealistic
    image generation, human-level machine translation, and more. The hype may (and
    likely will) recede, but the sustained economic and technological impact of deep
    learning will remain. In that sense, deep learning could be analogous to the internet:
    it may be overly hyped up for a few years, but in the longer term, it will still
    be a major revolution that will transform our economy and our lives.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其前所未有的技术成功，深度学习独自引发了第三次，也是迄今为止最大的*AI夏天*：一个对AI领域充满兴趣、投资和炒作的时期。当这本书正在撰写时，我们正处于这个时期。这个时期是否会在近期结束，以及结束之后会发生什么，是人们争论的话题。有一点是肯定的：与之前的AI夏天形成鲜明对比的是，深度学习为大大小小的科技公司带来了巨大的商业价值，并成为巨大的消费者成功，实现了人类水平的语音识别、聊天机器人助手、逼真的图像生成、人类水平的机器翻译等。炒作可能会（并且很可能）消退，但深度学习持续的经济和技术影响将保持。从这个意义上说，深度学习可以与互联网相提并论：它可能在几年内过度炒作，但从长远来看，它仍将是一场重大的革命，将改变我们的经济和我们的生活。
- en: One reason I’m particularly optimistic about deep learning is that even if we
    were to make no further technological progress in the next decade, deploying existing
    algorithms to every applicable problem would be a game changer for most industries.
    Deep learning is nothing short of a revolution, and progress is currently happening
    at an incredibly fast rate due to an exponential investment in resources and headcount.
    From where we stand, the future looks bright, although short-term expectations
    are somewhat overoptimistic; deploying deep learning to the full extent of its
    potential will likely take multiple decades.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我对深度学习特别乐观的一个原因是，即使在未来十年内我们不再取得任何技术进步，将现有的算法应用于每一个适用的问题也将对大多数行业产生颠覆性的影响。深度学习无异于一场革命，由于资源投入和人力投入的指数级增长，进展正在以惊人的速度发生。从目前的情况来看，未来看起来光明，尽管短期预期有些过于乐观；将深度学习发挥到其潜能的极致可能需要数十年的时间。
- en: How to think about deep learning
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何思考深度学习
- en: The most surprising thing about deep learning is how simple it is. Fifteen years
    ago, no one expected that we would achieve such amazing results on machine-perception
    and natural language processing problems by using simple parametric models trained
    with gradient descent. Now it turns out that all you need is sufficiently large
    parametric models trained with gradient descent on sufficiently many examples.
    As Feynman once said about the universe, “It’s not complicated, it’s just a lot
    of it.”^([[1]](#footnote-1))
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习最令人惊讶的事情是它的简单性。十五年前，没有人预料到我们会通过使用简单的参数模型，并通过梯度下降进行训练，在机器感知和自然语言处理问题上取得如此惊人的成果。现在看来，你所需要的只是足够大的参数模型，在足够多的例子上用梯度下降进行训练。正如费曼曾经关于宇宙所说，“它并不复杂，只是有很多。”^([[1]](#footnote-1))
- en: In deep learning, everything is a vector; that is, everything is a *point* in
    a *geometric space*. Model inputs (text, images, and so on) and targets are first
    *vectorized* — turned into an initial input vector space and target vector space.
    Each layer in a deep learning model operates one simple geometric transformation
    on the data that goes through it. Together, the chain of layers in the model forms
    one complex geometric transformation, broken down into a series of simple ones.
    This complex transformation attempts to map the input space to the target space,
    one point at a time. This transformation is parameterized by the weights of the
    layers, which are iteratively updated based on how well the model is currently
    performing. A key characteristic of this geometric transformation is that it must
    be *differentiable*, which is required for us to be able to learn its parameters
    via gradient descent. Intuitively, this means the geometric morphing from inputs
    to outputs must be smooth and continuous — a significant constraint.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，一切都是向量；也就是说，一切都是几何空间中的一个*点*。模型输入（文本、图像等）和目标首先被*向量化*——转换成初始输入向量空间和目标向量空间。深度学习模型中的每一层都对通过它的数据进行一次简单的几何变换。模型中层的链式操作形成了一个复杂的几何变换，分解成一系列简单的变换。这个复杂变换试图将输入空间映射到目标空间，一次映射一个点。这个变换由层的权重参数化，这些权重根据模型当前的表现进行迭代更新。这个几何变换的一个关键特性是它必须是*可微分的*，这对于我们通过梯度下降学习其参数是必要的。直观地说，这意味着从输入到输出的几何变形必须是平滑和连续的——这是一个重要的约束。
- en: 'The entire process of applying this complex geometric transformation to the
    input data can be visualized in 3D by imagining a person trying to uncrumple a
    paper ball: the crumpled paper ball is the manifold of the input data that the
    model starts with. Each movement operated by the person on the paper ball is similar
    to a simple geometric transformation operated by one layer. The full uncrumpling
    gesture sequence is the complex transformation of the entire model. Deep learning
    models are mathematical machines for uncrumpling complicated manifolds of high-dimensional
    data.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 将这种复杂的几何变换应用于输入数据的过程可以通过想象一个人试图展开一个纸团来在3D中进行可视化：皱巴巴的纸团是模型开始时的输入数据流形。人对纸团进行的每一次操作都类似于一层简单几何变换的操作。完整的展开动作序列是整个模型的复杂变换。深度学习模型是用于展开高维数据复杂流形的数学机器。
- en: That’s the magic of deep learning — turning meaning into vectors, into geometric
    spaces, and then incrementally learning complex geometric transformations that
    map one space to another. All you need are spaces of sufficiently high dimensionality
    to capture the full scope of the relationships found in the original data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是深度学习的魔力——将意义转化为向量，转化为几何空间，然后逐步学习复杂的几何变换，将一个空间映射到另一个空间。你所需要的只是足够高维度的空间来捕捉原始数据中找到的所有关系范围。
- en: 'The whole thing hinges on two core ideas: that *meaning is derived from the
    pairwise relationship between things* (between words in a language, between pixels
    in an image, and so on) and that *these relationships can be captured by a distance
    function*. But note that whether the brain implements meaning via geometric spaces
    is an entirely separate question. Vector spaces are efficient to work with from
    a computational standpoint, but different data structures for intelligence can
    easily be envisioned — in particular, graphs. Neural networks initially emerged
    from the idea of using graphs as a way to encode meaning, which is why they’re
    named *neural networks*; the surrounding field of research used to be called *connectionism*.
    Nowadays, the name *neural network* exists purely for historical reasons — it’s
    an extremely misleading name because they’re neither neural nor networks. In particular,
    neural networks have hardly anything to do with the brain. A more appropriate
    name would have been *layered representations learning* or *hierarchical representations
    learning*, or maybe even deep *differentiable models* or *chained geometric transforms*,
    to emphasize the fact that continuous geometric space manipulation is at their
    core.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 整个事情的关键在于两个核心思想：即*意义来源于事物之间的成对关系*（在语言中的单词之间、在图像中的像素之间等等）以及*这些关系可以通过距离函数来捕捉*。但请注意，大脑是否通过几何空间来实现意义是一个完全独立的问题。从计算的角度来看，向量空间是高效的，但可以很容易地设想出用于智能的不同数据结构——特别是图。神经网络最初是从使用图作为编码意义的方式这一想法中产生的，这就是为什么它们被称为*神经网络*；周围的研究领域曾经被称为*联结主义*。如今，“神经网络”这个名字纯粹是出于历史原因——这是一个极其误导性的名字，因为它们既不是神经的，也不是网络的。特别是，神经网络几乎与大脑没有什么关系。一个更合适的名字可能是*层次表示学习*或*分层表示学习*，或者甚至可以是深度*可微模型*或*链式几何变换*，以强调连续几何空间操作是其核心。
- en: Key enabling technologies
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键使能技术
- en: 'The technological revolution that’s currently unfolding didn’t start with any
    single breakthrough invention. Rather, like any other revolution, it’s the product
    of a vast accumulation of enabling factors — slowly at first, and then suddenly.
    In the case of deep learning, we can point out the following key factors:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当前正在展开的技术革命并非始于任何单一的重大突破发明。相反，就像任何其他革命一样，它是大量使能因素积累的结果——最初缓慢，然后突然。在深度学习的情况下，我们可以指出以下关键因素：
- en: Incremental algorithmic innovations, first spread over two decades (starting
    with backpropagation) and then happening increasingly faster as more research
    effort was poured into deep learning after 2012\. One major such breakthrough
    was the Transformer architecture in 2017.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法创新的逐步发展，最初持续了二十年（从反向传播开始），然后在2012年之后，随着更多研究努力投入到深度学习中，发生得越来越快。2017年，Transformer架构是一个重大的突破。
- en: The availability of large amounts of image, video, and text data, which is a
    requirement to realize that sufficiently large models trained on sufficiently
    large data are all we need. This is, in turn, a by-product of the rise of the
    consumer internet and Moore’s law applied to storage media. Today, state-of-the-art
    language models are trained on a large fraction of the entire internet.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量图像、视频和文本数据的可用性，这是实现足够大的模型在足够大的数据上训练所必需的。这反过来又是消费互联网的兴起和摩尔定律应用于存储媒体的产物。如今，最先进的语言模型是在整个互联网的大部分数据上训练的。
- en: The availability of fast, highly parallel computation hardware at a low price,
    especially the GPUs produced by NVIDIA — first gaming GPUs and then chips designed
    from the ground up for deep learning. Early on, NVIDIA CEO Jensen Huang took note
    of the deep learning boom and decided to bet the company’s future on it, which
    paid off in a big way.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速、高度并行计算硬件的可用性，尤其是NVIDIA生产的GPU——首先是游戏GPU，然后是专为深度学习从头设计的芯片。早期，NVIDIA首席执行官黄仁勋注意到了深度学习的兴起，并决定将公司的未来押宝在其上，这带来了巨大的回报。
- en: 'A complex stack of software layers that makes this computational power available
    to humans: the CUDA language, frameworks like TensorFlow, JAX, and PyTorch that
    do automatic differentiation, and Keras, which makes deep learning accessible
    to most people.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列复杂的软件层，使得这种计算能力对人类可用：CUDA语言，以及像TensorFlow、JAX和PyTorch这样的框架，它们执行自动微分，还有Keras，它使得深度学习对大多数人变得容易。
- en: 'In the future, deep learning will not be used only by specialists such as researchers,
    graduate students, and engineers with an academic profile; it will be a tool in
    the toolbox of every developer, much like web technology today. Everyone needs
    to build intelligent apps: just as every business today needs a website, every
    product will need to intelligently make sense of user-generated data. Bringing
    about this future will require us to build tools that make deep learning radically
    easy to use and accessible to anyone with basic coding abilities. Keras has been
    the first major step in that direction.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，深度学习将不仅被研究人员、研究生和具有学术背景的工程师等专业人士使用；它将成为每个开发者的工具箱中的工具，就像今天的网络技术一样。每个人都需要构建智能应用：就像今天每个企业都需要一个网站一样，每个产品都需要智能地理解用户生成数据。实现这一未来将需要我们构建使深度学习极其容易使用且对任何具有基本编码能力的人可用的工具。Keras已经是在这个方向上的第一步。
- en: The universal machine learning workflow
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通用机器学习工作流程
- en: 'Having access to an extremely powerful tool for creating models that map any
    input space to any target space is great, but the difficult part of the machine
    learning workflow is often everything that comes before designing and training
    such models (and, for production models, what comes after, as well). Understanding
    the problem domain to be able to determine what to attempt to predict, given what
    data, and how to measure success is a prerequisite for any successful application
    of machine learning, and it isn’t something that advanced tools like Keras and
    TensorFlow can help you with. As a reminder, here’s a quick summary of the typical
    machine learning workflow as described in chapter 6:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 能够访问一个极其强大的工具，用于创建将任何输入空间映射到任何目标空间的模型，这很好，但机器学习工作流程中的难点通常是在设计和训练这些模型之前（以及对于生产模型，之后）的所有事情。理解问题域，以便确定要尝试预测什么，给定什么数据，以及如何衡量成功，是任何成功应用机器学习的先决条件，这不是像Keras和TensorFlow这样的高级工具能帮你的。作为提醒，以下是第6章中描述的典型机器学习工作流程的简要总结：
- en: '*Define the problem.* What data is available, and what are you trying to predict?
    Will you need to collect more data or hire people to manually label a dataset?'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义问题。* 可用哪些数据，你试图预测什么？你需要收集更多数据或雇佣人员手动标记数据集吗？'
- en: '*Identify a way to reliably measure success on your goal.* For simple tasks,
    this may be prediction accuracy, but in many cases, it will require sophisticated,
    domain-specific metrics.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*确定一种可靠地衡量你目标成功的方法。* 对于简单任务，这可能只是预测精度，但在许多情况下，它将需要复杂、特定领域的指标。'
- en: '*Prepare the validation process that you’ll use to evaluate your models.* In
    particular, you should define a training set, a validation set, and a test set.
    The validation-set and test-set labels shouldn’t leak into the training data:
    for instance, with temporal prediction, the validation and test data should be
    posterior to the training data.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准备你将用于评估你的模型的验证过程。* 特别是，你应该定义一个训练集、一个验证集和一个测试集。验证集和测试集的标签不应泄露到训练数据中：例如，在时间预测中，验证数据和测试数据应在训练数据之后。'
- en: '*Vectorize the data by turning it into vectors and preprocessing it in a way
    that makes it more easily approachable by a neural network (normalization and
    so on).*'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过将其转换为向量和进行预处理（如归一化等）使数据向量化，以便更容易地由神经网络接近。*'
- en: '*Develop a first model that beats a trivial common-sense baseline, thus demonstrating
    that machine learning can work on your problem.* This may not always be the case!'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发一个能够击败平凡常识基线的第一个模型，从而证明机器学习可以在你的问题上工作。* 这可能并不总是如此！'
- en: '*Gradually refine your model architecture by tuning hyperparameters and adding
    regularization.* Make changes based on performance on the validation data only,
    not the test data or the training data. Remember that you should get your model
    to overfit (thus identifying a model capacity level that’s greater than you need)
    and only then begin to add regularization or downsize your model. Beware of validation-set
    overfitting when tuning hyperparameters — the fact that your hyperparameters may
    end up being overspecialized to the validation set. Avoiding this is the purpose
    of having a separate test set!'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过调整超参数和添加正则化来逐步细化你的模型架构。仅基于验证数据上的性能进行更改，而不是测试数据或训练数据。记住，你应该让你的模型过度拟合（从而确定一个比所需更大的模型容量级别），然后才开始添加正则化或缩小模型。在调整超参数时要警惕验证集过度拟合——你的超参数可能最终会过度专门化到验证集。避免这一点正是保留单独测试集的目的！'
- en: '*Deploy your final model in production — as a web API, as part of a JavaScript
    or C++ application, on an embedded device, etc.* Keep monitoring its performance
    on real-world data and use your findings to refine the next iteration of the model!'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在生产环境中部署你的最终模型——作为一个Web API，作为JavaScript或C++应用程序的一部分，在嵌入式设备上等。持续监控其在真实世界数据上的性能，并使用你的发现来改进模型的下一版本！*'
- en: Key network architectures
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键网络架构
- en: 'The families of network architectures that you should be familiar with after
    reading this book are *densely connected networks*, *convolutional networks*,
    *recurrent networks*, *Diffusion Models*, and *Transformers*. Each type of model
    is meant for specific data modalities: a network architecture encodes *assumptions*
    about the structure of the data — a *hypothesis space* within which the search
    for a good model will proceed. Whether a given architecture will work on a given
    problem depends entirely on the match between the structure of the data and the
    assumptions of the network architecture.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读完这本书后，你应该熟悉以下网络架构家族：*密集连接网络*、*卷积网络*、*循环网络*、*扩散模型*和*变换器*。每种模型都针对特定的数据模态：网络架构编码了关于数据结构的*假设*——一个*假设空间*，在其中将进行寻找良好模型的搜索。一个给定的架构是否适用于一个给定的问题完全取决于数据结构与网络架构假设之间的匹配。
- en: These different network types can easily be combined to achieve larger multimodal
    models, much as you combine LEGO bricks. In a way, deep learning layers are LEGO
    bricks for information processing. Table 20.1 shows a quick overview of the mapping
    between input and output modalities and the appropriate network architectures.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些不同的网络类型可以很容易地组合起来以实现更大的多模态模型，就像你组合乐高积木一样。从某种意义上说，深度学习层是信息处理的乐高积木。表20.1展示了输入和输出模态之间的映射以及适当的网络架构的快速概述。
- en: '| Input | Output | Model |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | 输出 | 模型 |'
- en: '| --- | --- | --- |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Vector data | Class probability, Regression value | Densely connected network
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 向量数据 | 类别概率，回归值 | 密集连接网络 |'
- en: '| Timeseries data | Class probability, Regression value | RNN, Transformer
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 时间序列数据 | 类别概率，回归值 | RNN，变换器 |'
- en: '| Images | Class probability, Regression value | ConvNet |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | 类别概率，回归值 | 卷积神经网络 |'
- en: '| Text | Class probability, Regression value | Transformer |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 类别概率，回归值 | 变换器 |'
- en: '| Text, Images | Text | Transformer |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 文本，图像 | 文本 | 变换器 |'
- en: '| Text, Images | Images | VAE, Diffusion Model |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 文本，图像 | 图像 | VAE，扩散模型 |'
- en: '[Table 20.1](#table-20-1): Model architectures for different data types'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[表20.1](#table-20-1)：不同数据类型的模型架构'
- en: Now let’s quickly review the specificities of each network architecture.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们快速回顾一下每种网络架构的具体特点。
- en: Densely connected networks
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 密集连接网络
- en: 'A densely connected network is a stack of `Dense` layers, meant to process
    vector data (where each sample is a vector of numerical or categorical attributes).
    Such networks assume no specific structure in the input features: they’re called
    *densely connected* because the units of a `Dense` layer are connected to every
    other unit. The layer attempts to map relationships between any two input features;
    this is unlike a 2D convolution layer, for instance, which only looks at *local*
    relationships.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 密集连接网络是一系列`Dense`层，旨在处理向量数据（其中每个样本是一个数值或分类属性的向量）。这类网络假设输入特征没有特定的结构：它们被称为*密集连接*，因为`Dense`层的单元与其他所有单元相连。该层试图映射任何两个输入特征之间的关系；这与例如2D卷积层不同，后者只关注*局部*关系。
- en: Densely connected networks are most commonly used for categorical data (for
    example, where the input features are lists of attributes), such as the Boston
    Housing Price dataset used in chapter 4\. They’re also used as the final classification
    or regression stage of most networks. For instance, the ConvNets covered in chapter
    8 typically end with one or two `Dense` layers, and so do the recurrent networks
    in chapter 13.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 密集连接网络最常用于分类数据（例如，输入特征是属性列表的情况），例如第4章中使用的波士顿房价数据集。它们也用作大多数网络的最终分类或回归阶段。例如，第8章中介绍的卷积神经网络通常以一个或两个`Dense`层结束，第13章中的循环神经网络也是如此。
- en: 'Remember, to perform *binary classification*, end your stack of layers with
    a `Dense` layer with a single unit and a `sigmoid` activation, and use `binary_crossentropy`
    as the loss. Your targets should be either 0 or 1:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，要执行**二分类**，请在您的层堆栈中添加一个具有单个单元和`sigmoid`激活的`Dense`层，并使用`binary_crossentropy`作为损失。您的目标应该是0或1：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To perform *single-label categorical classification* (where each sample has
    exactly one class, no more), end your stack of layers with a `Dense` layer with
    a number of units equal to the number of classes and a `softmax` activation. If
    your targets are one-hot encoded, use `categorical_crossentropy` as the loss;
    if they’re integers, use `sparse_categorical_ crossentropy`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行**单标签分类分类**（其中每个样本恰好有一个类别，没有更多），请在您的层堆栈中添加一个具有与类别数量相等的单元数的`Dense`层，并使用`softmax`激活。如果您的目标是one-hot编码，请使用`categorical_crossentropy`作为损失；如果它们是整数，请使用`sparse_categorical_crossentropy`：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To perform *multilabel categorical classification* (where each sample can have
    several classes), end your stack of layers with a `Dense` layer with a number
    of units equal to the number of classes and a `sigmoid` activation, and use `binary_crossentropy`
    as the loss. Your targets should be k-hot encoded:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行**多标签分类分类**（其中每个样本可以有多个类别），请在您的层堆栈中添加一个具有与类别数量相等的单元数和`sigmoid`激活的`Dense`层，并使用`binary_crossentropy`作为损失。您的目标应该是k-hot编码：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To perform *regression* toward a vector of continuous values, end your stack
    of layers with a `Dense` layer with a number of units equal to the number of values
    you’re trying to predict (often a single one, such as the price of a house) and
    no activation. Various losses can be used for regression — most commonly `mean_squared_error`
    (MSE):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行对连续值向量的**回归**，请在您的层堆栈中添加一个具有与您试图预测的值数量相等的单元数的`Dense`层，并且没有激活。可以用于回归的损失函数有很多种——最常见的是`mean_squared_error`（均方误差）：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ConvNets
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'Convolution layers look at spatially local patterns by applying the same geometric
    transformation to different spatial locations (*patches*) in an input tensor.
    This results in representations that are *translation invariant*, making convolution
    layers highly data efficient and modular. This idea is applicable to spaces of
    any dimensionality: 1D (continuous sequences), 2D (images), 3D (volumes), and
    so on. You can use the `Conv1D` layer to process sequences, the `Conv2D` layer
    to process images, and the `Conv3D` layer to process volumes. As a leaner, more
    efficient alternative to convolution layers, you can also use *depthwise separable
    convolution* layers, such as `SeparableConv2D`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层通过将相同的几何变换应用于输入张量中的不同空间位置（*块*）来观察空间局部模式。这导致的结果是*平移不变性*，使得卷积层在数据效率和模块化方面非常高效。这个想法适用于任何维度的空间：1D（连续序列）、2D（图像）、3D（体积）等等。您可以使用`Conv1D`层处理序列，`Conv2D`层处理图像，`Conv3D`层处理体积。作为一种更轻量、更高效的卷积层替代方案，您还可以使用*深度可分离卷积*层，例如`SeparableConv2D`。
- en: '*ConvNets*, or *convolutional networks*, consist of stacks of convolution and
    max-pooling layers. The pooling layers let you spatially downsample the data,
    which is required to keep feature maps to a reasonable size as the number of features
    grows and to allow subsequent convolution layers to “see” a greater spatial extent
    of the inputs. ConvNets are often ended with either a `Flatten` operation or a
    global pooling layer, turning spatial feature maps into vectors, followed by `Dense`
    layers to achieve classification or regression.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积神经网络*，或称*卷积网络*，由一系列卷积和最大池化层组成。池化层允许您在空间上对数据进行下采样，这对于在特征数量增加时保持特征图的大小合理，并允许后续卷积层“看到”更大的输入空间范围是必要的。卷积神经网络通常以`Flatten`操作或全局池化层结束，将空间特征图转换为向量，然后通过`Dense`层实现分类或回归。'
- en: 'Here’s a typical image-classification network (categorical classification,
    in this case) using `SeparableConv2D` layers:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的图像分类网络（在这种情况下是分类分类）使用`SeparableConv2D`层：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When building a very deep ConvNet, it’s common to add *batch normalization*
    layers as well as *residual connections* — two architecture patterns that help
    gradient information flow smoothly through the network.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建一个非常深的卷积神经网络时，通常还会添加*批归一化*层以及*残差连接*——两种有助于梯度信息在网络中平滑流动的架构模式。
- en: Transformers
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Transformers
- en: A Transformer looks at a set of vectors (such as word vectors) and uses *neural
    attention* to transform each vector into a representation that is aware of the
    *context* provided by the other vectors in the set. When the set in question is
    an ordered sequence, you can also use *positional encoding* to create Transformers
    that can take into account both global context and word order, capable of processing
    long text paragraphs much more effectively than RNNs or 1D ConvNets.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer查看一组向量（如词向量）并使用*神经注意力*将每个向量转换为一个表示，该表示了解集合中其他向量提供的*上下文*。当所涉及的集合是一个有序序列时，你也可以使用*位置编码*来创建能够同时考虑全局上下文和词序的Transformer，这些Transformer可以比RNN或1D卷积神经网络更有效地处理长文本段落。
- en: Transformers can be used for any set-processing or sequence-processing task,
    including text classification, but they excel especially at *sequence-to-sequence
    learning*, such as translating paragraphs in a source language into a target language.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer可以用于任何集合处理或序列处理任务，包括文本分类，但它们在*序列到序列学习*方面特别出色，例如将源语言的段落翻译成目标语言。
- en: 'A sequence-to-sequence Transformer is made of two parts:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 序列到序列Transformer由两部分组成：
- en: A `TransformerEncoder` that turns an input vector sequence into a context-aware,
    order-aware output vector sequence
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`TransformerEncoder`，它将输入向量序列转换为具有上下文感知和顺序感知的输出向量序列
- en: A `TransformerDecoder` that takes the output of the `TransformerEncoder`, as
    well as a target sequence, and predicts what should come next in the target sequence
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`TransformerDecoder`，它接受`TransformerEncoder`的输出以及一个目标序列，并预测目标序列中的下一个应该是什么。
- en: If you’re only processing a single sequence (or set) of vectors, you’d only
    use the `TransformerEncoder`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只处理单个向量（或集合）序列，你将只使用`TransformerEncoder`。
- en: 'Following is a sequence-to-sequence Transformer for mapping a source sequence
    to a target sequence (this setup could be used for machine translation or question-answering,
    for instance):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个将源序列映射到目标序列的序列到序列Transformer（这种设置可以用于机器翻译或问答，例如）：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And this is a lone `TransformerEncoder` for binary classification of integer
    sequences:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于整数序列二分类的独立`TransformerEncoder`：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Recurrent neural networks
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: '*Recurrent neural networks* (RNNs) work by processing sequences of inputs one
    timestep at a time and maintaining a state throughout (a state is typically a
    vector or set of vectors). They should be used preferentially over 1D ConvNets
    in the case of sequences where patterns of interest aren’t invariant by temporal
    translation (for instance, timeseries data where the recent past is more important
    than the distant past).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*循环神经网络*（RNNs）通过逐个时间步处理输入序列并在整个过程中保持状态（状态通常是向量或向量集）来工作。在感兴趣的模式不是通过时间平移不变的序列（例如，近期过去比遥远过去更重要的时间序列数据）的情况下，应优先使用1D卷积神经网络。'
- en: 'Three RNN layers are available in Keras: `SimpleRNN`, `GRU`, and `LSTM`. For
    most practical purposes, you should use either `GRU` or `LSTM`. `LSTM` is the
    more powerful of the two but is also more expensive; you can think of `GRU` as
    a simpler, cheaper alternative to it.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Keras中有三个RNN层：`SimpleRNN`、`GRU`和`LSTM`。对于大多数实际用途，你应该使用`GRU`或`LSTM`。`LSTM`是两者中更强大的，但成本也更高；你可以将`GRU`视为它的一个更简单、更便宜的替代品。
- en: To stack multiple RNN layers on top of each other, each layer prior to the last
    layer in the stack should return the full sequence of its outputs (each input
    timestep will correspond to an output timestep); if you aren’t stacking any further
    RNN layers, then it’s common to return only the last output, which contains information
    about the entire sequence.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要堆叠多个RNN层，每个层在堆栈中的最后一层之前都应该返回其输出的完整序列（每个输入时间步将对应一个输出时间步）；如果你没有堆叠任何更多的RNN层，那么通常只返回最后一个输出，它包含有关整个序列的信息。
- en: 'Following is a single RNN layer for binary classification of vector sequences:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个用于向量序列二分类的单个RNN层：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And this is a stacked RNN layer for binary classification of vector sequences:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种用于二进制分类向量序列的堆叠RNN层：
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Limitations of deep learning
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的局限性
- en: 'Building deep learning models is like playing with LEGO bricks: layers can
    be plugged together to map essentially anything to anything, given that you have
    appropriate training data available and that the mapping is achievable via a continuous
    geometric transformation of reasonable complexity.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 构建深度学习模型就像玩乐高积木：只要你有合适的训练数据，并且映射可以通过合理的连续几何变换实现，层就可以组合起来将本质上任何事物映射到任何事物。
- en: 'Here’s the catch, though — this mapping is often not learnable in a way that
    will generalize. Deep learning models operate like vast, interpolative databases
    of patterns. Their pattern-matching strength is also their core weakness:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这里有一个问题——这种映射往往无法以通用的方式学习。深度学习模型像庞大的插值模式数据库一样运行。它们的模式匹配能力也是它们的根本弱点：
- en: '*They fundamentally struggle to adapt to novelty.* Because their parameters
    are fixed after training, they can only retrieve or replicate patterns similar
    to their training data. Faced with inputs significantly outside this familiar
    distribution — no matter how simple the underlying task — their performance degrades
    drastically, as they lack mechanisms for fluid generalization beyond their memorized
    experience. This explains why even large models fail on novel tasks or simple
    variations of familiar problems — like ARC-AGI tasks.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它们在适应新颖事物方面存在根本性的困难。* 由于它们的参数在训练后是固定的，它们只能检索或复制与训练数据相似的图案。面对显著超出这种熟悉分布的输入——无论底层任务多么简单——它们的性能会急剧下降，因为它们缺乏超越记忆经验的流畅泛化机制。这解释了为什么即使是大型模型在新型任务或熟悉问题的简单变化（如ARC-AGI任务）上也失败。'
- en: '*They’re very sensitive to phrasing and other distractors.* Deep learning models
    exhibit high sensitivity to superficial variations in input presentation, such
    as minor phrasing changes (consider prompt sensitivity in LLMs) or imperceptible
    perturbations (consider adversarial examples in vision), indicating a lack of
    robust, human-like understanding.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它们对措辞和其他干扰因素非常敏感。* 深度学习模型对输入呈现的表面变化表现出高度敏感性，例如微小的措辞变化（考虑LLM中的提示敏感性）或难以察觉的扰动（考虑视觉中的对抗样本），这表明缺乏稳健、类似人类的理解。'
- en: '*They often can’t learn generalizable algorithms.* The continuous, geometric
    nature of deep learning models makes them fundamentally ill-suited for learning
    exact, discrete, step-by-step algorithms, such as those that are the bread and
    butter of classical computer science. Models approximate such processes through
    interpolation rather than implementing robust, generalizable procedures.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它们通常无法学习可泛化的算法。* 深度学习模型的连续、几何性质使它们在本质上不适合学习精确、离散、逐步的算法，例如那些是经典计算机科学的核心。模型通过插值而不是实现稳健、可泛化的程序来近似这些过程。'
- en: You should always resist the temptation to anthropomorphize deep learning models.
    Their performance is built on pointwise statistical patterns rather than human-like
    experiential grounding, making it brittle when encountering deviations from training
    data.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该始终抵制将深度学习模型拟人化的诱惑。它们的性能建立在点wise统计模式上，而不是类似人类的经验基础上，这使得它们在遇到训练数据之外的偏差时变得脆弱。
- en: The narrative that simply scaling up model size and training data would lead
    to general intelligence has proven insufficient. While scaling enhances performance
    on benchmarks that amount to memorization tests, it fails to address the fundamental
    limitations of deep learning, which stem from the core paradigm of fitting static,
    interpolative curves to data. Five years of exponential scaling of base LLMs haven’t
    overcome these constraints because the underlying approach remains unchanged.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地扩大模型规模和训练数据就能导致通用智能的叙述已被证明是不充分的。虽然扩大规模增强了在相当于记忆测试的基准测试上的性能，但它未能解决深度学习的根本局限性，这些局限性源于将静态、插值曲线拟合到数据的核心范式。五年来的指数级扩大基础LLM并没有克服这些限制，因为底层方法保持不变。
- en: By 2024, this realization spurred a transition toward test-time adaptation (TTA),
    where models perform search or fine-tuning during the inference phase to adapt
    to novel problems. While TTA methods have yielded major breakthroughs, such as
    OpenAI’s o3 surpassing human baseline on ARC-AGI-1 in late 2024, this performance
    has come at an extreme computational cost. Efficient, human-like adaptation is
    still a completely open problem, and the slightly harder ARC-AGI-2 benchmark remains
    completely unsolved as of today. We still need further conceptual advances beyond
    mere scaling or brute-force search.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到2024年，这一认识推动了向测试时适应（TTA）的转变，其中模型在推理阶段进行搜索或微调以适应新问题。虽然TTA方法已经取得了重大突破，例如OpenAI的o3在2024年底在ARC-AGI-1上超越了人类基线，但这种性能是以极端的计算成本为代价的。高效、类似人类的适应仍然是一个完全未解决的问题，而稍微困难的ARC-AGI-2基准至今仍未解决。我们仍然需要进一步的概念进步，而不仅仅是扩展或蛮力搜索。
- en: What might lie ahead
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前方可能是什么
- en: Solving human-like fluid intelligence (and ARC-AGI-2) requires moving beyond
    the limitations inherent in current approaches. While deep learning excels at
    *value-centric abstraction*, which enables pattern recognition and intuition,
    it fundamentally lacks capabilities for *program-centric abstraction*, which underpins
    discrete reasoning, planning, and causal understanding. Human intelligence seamlessly
    integrates both — future AI must do the same.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 解决类似人类流畅智能（和ARC-AGI-2）需要超越当前方法固有的局限性。虽然深度学习在*价值中心抽象*方面表现出色，这有助于模式识别和直觉，但它本质上缺乏*程序中心抽象*的能力，这是离散推理、规划和因果理解的基础。人类智能无缝地整合了这两者——未来的AI必须做到同样。
- en: Future key developments may include
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 未来可能的关键发展可能包括
- en: '*Hybrid models* — Future models will likely integrate learned algorithmic modules
    (providing reasoning and symbolic manipulation) with deep learning modules (providing
    perception and intuition). These systems might learn to use programming primitives
    like control flow, variables, recursion, and complex data structures dynamically.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*混合模型* — 未来的模型可能会将学习到的算法模块（提供推理和符号操作）与深度学习模块（提供感知和直觉）集成。这些系统可能会学习动态地使用编程原语，如控制流、变量、递归和复杂的数据结构。'
- en: '*Deep-learning guided program search* — Program synthesis — automatically discovering
    executable code that meets specifications — offers a route to program-centric
    abstraction. However, its reliance on inefficient discrete search is a major bottleneck.
    A crucial advance will be using deep learning to guide this search, utilizing
    learned intuition about program structure to navigate vast, combinatorial spaces
    of programs efficiently, much like human developers use experience and intuition
    to narrow down their choices.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习引导的程序搜索* — 程序综合——自动发现满足规格的可执行代码——为程序中心抽象提供了一条途径。然而，它对低效的离散搜索的依赖是一个主要瓶颈。一个关键进步将是使用深度学习来引导这一搜索，利用关于程序结构的直觉来有效地导航程序的大量组合空间，就像人类开发者使用经验和直觉来缩小他们的选择范围一样。'
- en: '*Modular recombination and lifelong learning* — We’ll move away from monolithic,
    end-to-end models trained from scratch. Instead, future AI systems will use massive
    libraries of reusable, modular components that can be repurposed across many problems,
    acquired from experience. These libraries will feature both “geometric” (deep
    learning based) and “algorithmic” modules. When faced with a new problem, such
    AI systems will fetch relevant modules and dynamically recombine them into a new
    model adapted to the situation at hand. Whenever the system ends up developing
    a reusable component as a by-product of this problem-solving loop, the new component
    would get added to the library, becoming available for every future task the system
    might encounter.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模块化重组和终身学习* — 我们将远离从头开始训练的单一、端到端模型。相反，未来的AI系统将使用大量可重用、模块化的组件库，这些组件可以在许多问题之间重新部署，并从经验中获取。这些库将包括“几何”（基于深度学习）和“算法”模块。面对新问题时，这样的AI系统将检索相关模块，并将它们动态地重新组合成适应当前情况的新模型。每当系统在问题解决循环中作为副产品开发出可重用组件时，新组件就会被添加到库中，可供系统未来可能遇到的每个任务使用。'
- en: Ultimately, developing AI that mirrors human-like fluid intelligence will require
    blending continuous pattern recognition together with discrete, symbolic programs
    and fully embracing the paradigm of on-the-fly adaptation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，开发出类似人类流畅智能的AI需要将连续模式识别与离散、符号程序相结合，并完全接受即时适应的范式。
- en: Staying up to date in a fast-moving field
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在快速发展的领域中保持最新
- en: As final parting words, I want to give you some pointers about how to keep learning
    and updating your knowledge and skills after you’ve turned the last page of this
    book. The field of modern deep learning, as we know it today, is only a few years
    old, despite a long, slow prehistory stretching back decades. With an exponential
    increase in financial resources and research headcount since 2013, the field as
    a whole is now moving at a frenetic pace. What you’ve learned in this book won’t
    stay relevant forever, and it isn’t all you’ll need for the rest of your career.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在此书的最后一页翻过之后，我想给您一些建议，关于如何继续学习和更新您的知识和技能。正如我们所知，现代深度学习领域，尽管有着几十年的漫长而缓慢的史前时期，但至今只有几年历史。自2013年以来，随着资金和研究人员的指数级增长，整个领域现在正以极快的速度发展。您在这本书中学到的知识不会永远相关，而且这也不是您整个职业生涯所需的所有知识。
- en: Fortunately, there are plenty of free online resources that you can use to stay
    up to date and expand your horizons. Here are a few.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有很多免费的在线资源供您使用，以保持最新状态并拓宽您的视野。以下是一些资源。
- en: Practice on real-world problems using Kaggle
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Kaggle进行实战练习
- en: An effective way to acquire real-world experience is to try your hand at machine
    learning competitions on Kaggle ([https://kaggle.com](https://kaggle.com)). The
    only real way to learn is through practice and actual coding — that’s the philosophy
    of this book, and Kaggle competitions are the natural continuation of this. On
    Kaggle, you’ll find an array of constantly renewed data science competitions,
    many of which involve deep learning, prepared by companies interested in obtaining
    novel solutions to some of their most challenging machine learning problems. Fairly
    large monetary prizes are offered to top entrants.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 获取实战经验的有效方法之一是尝试在Kaggle（[https://kaggle.com](https://kaggle.com)）上参加机器学习竞赛。唯一真正学习的方法是通过实践和实际编码——这正是本书的哲学，而Kaggle竞赛是这一哲学的自然延续。在Kaggle上，您会发现一系列不断更新的数据科学竞赛，其中许多涉及深度学习，由对获得他们最复杂机器学习问题新解决方案感兴趣的公司准备。为顶尖参赛者提供了相当大的现金奖励。
- en: By participating in a few competitions, maybe as part of a team, you’ll become
    more familiar with the practical side of some of the advanced best practices described
    in this book, especially hyperparameter tuning, avoiding validation-set overfitting,
    and model ensembling.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参加几场比赛，也许作为团队的一部分，您将更加熟悉书中描述的一些高级最佳实践的实际应用，特别是超参数调整、避免验证集过拟合和模型集成。
- en: Read about the latest developments on arXiv
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在arXiv上了解最新的发展
- en: 'Deep learning research, in contrast with some other scientific fields, takes
    place completely in the open. Papers are made publicly and freely accessible as
    soon as they’re finalized, and a lot of related software is open source. arXiv
    ([https://arxiv.org](https://arxiv.org)) — pronounced “archive” (the X stands
    for the Greek *chi*) — is an open access preprint server for physics, mathematics,
    and computer science research papers. It has become the de facto way to stay up
    to date on the cutting edge of machine learning and deep learning. The large majority
    of deep learning researchers upload any paper they write to arXiv shortly after
    completion. This allows them to plant a flag and claim a specific finding without
    waiting for a conference acceptance (which takes months), which is necessary given
    the fast pace of research and the intense competition in the field. It also allows
    the field to move extremely fast: all new findings are immediately available for
    all to see and to build on.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他一些科学领域相比，深度学习研究完全在公开中进行。论文在完成之后立即公开和免费提供，许多相关软件也是开源的。arXiv（[https://arxiv.org](https://arxiv.org)）——发音为“archive”（X代表希腊字母χ）——是一个开放获取的预印本服务器，用于物理、数学和计算机科学研究论文。它已成为了解机器学习和深度学习前沿的既定方式。大多数深度学习研究人员在完成论文后不久就会将其上传到arXiv。这允许他们在等待会议接受（可能需要几个月）之前就树立一个旗帜并宣布一个特定的发现，这在研究速度快和领域竞争激烈的背景下是必要的。这也使得该领域能够以极快的速度发展：所有新的发现都立即对所有人和所有人可见，并在此基础上进行构建。
- en: 'An important downside is that the sheer quantity of new papers posted every
    day on arXiv makes it impossible to even skim them all, and the fact that they
    aren’t peer-reviewed makes it difficult to identify those that are both important
    and high quality. It’s challenging, and becoming increasingly more so, to find
    the signal in the noise. But some tools can help: in particular, you can use Google
    Scholar ([https://scholar.google.com](https://scholar.google.com)) to keep track
    of publications by your favorite authors.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的缺点是，每天在arXiv上发布的论文数量巨大，以至于甚至无法浏览它们，而且它们未经同行评审，这使得很难识别出那些既重要又高质量的论文。在噪声中找到信号具有挑战性，而且这种挑战性正在日益增加。但一些工具可以帮助：特别是，你可以使用Google
    Scholar ([https://scholar.google.com](https://scholar.google.com))来跟踪你最喜欢的作者发表的论文。
- en: Explore the Keras ecosystem
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索Keras生态系统
- en: 'With over 2.5 million users as of early 2025 and still growing, Keras has a
    large ecosystem of tutorials, guides, and related open source projects:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2025年初，Keras已有超过250万用户，并且仍在增长，Keras拥有庞大的教程、指南和相关开源项目生态系统：
- en: Your main reference for working with Keras is the online documentation at [https://keras.io](https://keras.io).
    In particular, you’ll find extensive developer guides at [https://keras.io/guides](https://keras.io/guides),
    and you’ll find dozens of high-quality Keras code examples at [https://keras.io/examples](https://keras.io/examples).
    Make sure to check them out!
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用Keras的主要参考资料是[https://keras.io](https://keras.io)上的在线文档。特别是，你可以在[https://keras.io/guides](https://keras.io/guides)找到广泛的开发者指南，你可以在[https://keras.io/examples](https://keras.io/examples)找到数十个高质量的Keras代码示例。务必查看它们！
- en: The Keras source code can be found at [https://github.com/keras-team/keras](https://github.com/keras-team/keras),
    and Keras Hub can be found at [https://github.com/keras-team/keras-hub](https://github.com/keras-team/keras-hub).
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras的源代码可以在[https://github.com/keras-team/keras](https://github.com/keras-team/keras)找到，Keras
    Hub可以在[https://github.com/keras-team/keras-hub](https://github.com/keras-team/keras-hub)找到。
- en: You can follow François (@fchollet) and Matt (@mattdangerw) on X (formerly Twitter).
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在X（前身为Twitter）上关注弗朗索瓦（@fchollet）和马特（@mattdangerw）。
- en: Final words
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后的话
- en: This is the end of *Deep Learning with Python*! I hope you’ve learned a thing
    or two about machine learning, deep learning, Keras, and maybe even cognition
    in general. Learning is a lifelong journey, especially in the field of AI, where
    we have far more unknowns on our hands than certitudes. So please go on learning,
    questioning, and researching. Never stop. Because even given the progress made
    so far, most of the fundamental questions in AI remain unanswered. Many haven’t
    even been properly asked yet.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是《Python深度学习》的结束！我希望你已经学到了一些关于机器学习、深度学习、Keras，甚至是一般认知的知识。学习是一个终身的旅程，尤其是在人工智能领域，我们手头的未知远多于确定性。所以请继续学习、质疑和研究。永远不要停止。因为即使到目前为止已经取得的进步，人工智能中的许多基本问题仍然没有答案。许多问题甚至还没有得到适当的提出。
- en: Footnotes
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 脚注
- en: Richard Feynman, interview, *The World from Another Point of View*, Yorkshire
    Television, 1972. [[↩]](#footnote-link-1)
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理查德·费曼，访谈，*从另一个角度看世界*，约克郡电视台，1972年 [[↩]](#footnote-link-1)
