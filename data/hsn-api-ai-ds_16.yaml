- en: Chapter 13\. Deploying a Machine Learning API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章\. 部署机器学习API
- en: Always in motion is the future.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 未来永远在运动之中。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yoda, *The Empire Strikes Back*
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约达，《星球大战》系列电影中的《帝国反击战》
- en: Fantasy football managers spend most of their time attempting to predict the
    future and plotting strategies based on those predictions. Before the season begins,
    managers want to know how NFL players will perform in the upcoming season so that
    they can build the best team. During their fantasy drafts, managers want to know
    where a player would be picked by other managers so that they can outmaneuver
    their competition. Each week, managers want to know which of their players are
    going to score the most so that they can set their lineups accordingly.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 梦幻足球经理们大部分时间都在试图预测未来，并基于这些预测制定策略。在赛季开始之前，经理们想要了解NFL球员在即将到来的赛季中的表现，以便他们能组建最佳球队。在他们的梦幻选秀中，经理们想要知道其他经理会挑选哪个球员，以便他们能超越竞争对手。每周，经理们想要知道哪些球员将会得分最多，以便他们能据此调整阵容。
- en: Many fantasy websites and platforms provide predictions to these managers. One
    of the tools available to the platforms is a *machine learning* (ML) model, which
    you learned about in [Chapter 12](ch12.html#chapter_12). The platforms train various
    models and use them to make predictions, or *inferences*, to managers. If a model
    processes an entire group of predictions at once, it is called *batch inference*.
    Some fantasy questions are appropriate for batch inference, such as making a week’s
    worth of player predictions all at once. Batch inference may be done by a scheduled
    script or job. But if the predictions are changing minute by minute—like in the
    case of a live score prediction for a game—then real-time inference is needed.
    *Real-time inference* is calling a model to get a single prediction immediately.
    This is where deploying the model as an API is most valuable.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 许多梦幻足球网站和平台为这些经理提供预测。平台可用的工具之一是机器学习（ML）模型，你已在第12章（ch12.html#chapter_12）中了解过。这些平台训练各种模型，并使用它们为经理做出预测，或进行*推理*。如果一个模型一次处理整个预测组，则称为*批量推理*。一些梦幻足球问题适合批量推理，例如一次性做出一周的球员预测。批量推理可以通过预定脚本或作业来完成。但如果预测每分钟都在变化——比如对一场比赛的实时得分预测——则需要实时推理。*实时推理*是指立即调用模型以获取单个预测。这就是将模型作为API部署最有价值的地方。
- en: 'In this chapter, you will create an ML model and deploy it with an API to make
    real-time inference. As you proceed through the chapter, here are a few terms
    that you will come across:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将创建一个机器学习模型，并通过API部署它以进行实时推理。随着你通过本章，以下是一些你将遇到的术语：
- en: Classification
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 分类
- en: A type of model that predicts what category a value will fall into. For example,
    a classification model might predict if a player will be drafted or undrafted.
    Models that perform classification are called *classifiers*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一种预测值将落入哪个类别的模型类型。例如，分类模型可能会预测一名球员是否会被选中或未被选中。执行分类的模型被称为*分类器*。
- en: Decision trees
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树
- en: A type of ML algorithm that creates a recursive tree structure to perform classification
    or regression.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一种创建递归树结构以执行分类或回归的机器学习算法类型。
- en: Evaluating a model
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型
- en: Comparing the model’s predictions to test data to see how well it would have
    predicted past events.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型的预测与测试数据比较，以查看其预测过去事件的能力如何。
- en: Gradient boosting
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升
- en: An ML technique that combines multiple models to create a model that is more
    effective than the individual models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一种将多个模型结合在一起以创建比单个模型更有效的模型的机器学习技术。
- en: Regression
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 回归
- en: A type of model that predicts a continuous numeric value. For example, a regression
    model might predict how many points a player will score. Models that perform regression
    are called *regressors*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一种预测连续数值的模型类型。例如，回归模型可能会预测一名球员将得多少分。执行回归的模型被称为*回归器*。
- en: Training a model
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型
- en: Using the training portion of historical data to create a model that can make
    inferences based on new data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用历史数据的训练部分来创建一个可以基于新数据进行推理的模型。
- en: Training Machine Learning Models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练机器学习模型
- en: '*Supervised learning* is a method of creating models by processing existing
    data where the expected values are known. For example, a financial fraud detection
    model might be trained by processing a large number of bank transactions that
    have been *labeled* or categorized as either fraud or nonfraud. Through this process,
    the model recognizes future records that are potentially fraudulent. Through this
    type of supervised learning, ML models can be created that create predictions
    on various data formats including tabular data, images, audio files, and others.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*监督学习*是通过处理已知预期值的现有数据来创建模型的方法。例如，一个金融欺诈检测模型可能通过处理大量已被*标记*或分类为欺诈或非欺诈的银行交易来训练。通过这个过程，模型可以识别出未来可能存在欺诈的记录。通过这种监督学习方法，可以创建出可以针对各种数据格式进行预测的机器学习模型，包括表格数据、图像、音频文件等。'
- en: '[Figure 13-1](#machine_learning_diagram_ch12) shows this type of training.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13-1](#machine_learning_diagram_ch12)展示了这种类型的训练。'
- en: '![Machine learning training](assets/haad_1301.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习训练](assets/haad_1301.png)'
- en: Figure 13-1\. ML training model
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-1\. 机器学习训练模型
- en: The diagram shows a set of historical rows of data. The goal of the ML model
    in this case would be to predict future values of the output column. The training
    process would involve using software to read the input columns from historical
    data and look for patterns in how they are related to the output column.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了一组历史数据行。在这种情况下，机器学习模型的目的是预测输出列的未来值。训练过程将涉及使用软件读取历史数据中的输入列，并寻找它们与输出列之间关系的模式。
- en: When the model has been trained, it can be used to read the input columns from
    new rows of data and predict what the values will be for the output columns. This
    is the *inference* process, shown in [Figure 13-2](#machine_learning_diagram_2_ch12).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型训练完成后，它可以用来读取新数据行中的输入列，并预测输出列的值。这是*推理*过程，如[图13-2](#machine_learning_diagram_2_ch12)所示。
- en: '![Machine learning inference model](assets/haad_1302.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习推理模型](assets/haad_1302.png)'
- en: Figure 13-2\. ML inference model
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-2\. 机器学习推理模型
- en: The model you will create in this chapter is a supervised ML model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节中你将创建的是一个监督学习机器学习模型。
- en: New Software Used in This Chapter
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章节中使用的新的软件
- en: '[Table 13-1](#tools_table_chapter_13) lists a few of the new software components
    you will begin using in this chapter.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[表13-1](#tools_table_chapter_13)列出了你将在本章节开始使用的几个新的软件组件。'
- en: Table 13-1\. Software used in this chapter
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 表13-1\. 本章节使用的软件
- en: '| Software name | Purpose |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 软件名称 | 用途 |'
- en: '| --- | --- |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ONNX Runtime | A cross-platform tool for using models from a variety of different
    frameworks. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| ONNX Runtime | 一个跨平台的工具，用于使用来自各种不同框架的模型。 |'
- en: '| scikit-learn | An ML framework for training models. You will use the `GradientBoostingRegressor`
    from this library. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| scikit-learn | 一个用于训练模型的机器学习框架。你将使用这个库中的`GradientBoostingRegressor`。 |'
- en: '| sklearn-onnx | A library that converts scikit-learn models to ONNX format.
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| sklearn-onnx | 一个将scikit-learn模型转换为ONNX格式的库。 |'
- en: ONNX Runtime
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ONNX Runtime
- en: The Open Neural Network Exchange (ONNX) is an open standard for ML models. Because
    such a variety of programming languages and libraries are used to make ML models,
    it can be complicated to deploy and run multiple different models. ONNX is a standard
    format that models from different programming languages and different frameworks
    can be converted to and run in a standard way.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 开放神经网络交换（ONNX）是机器学习模型的一个开放标准。由于制作机器学习模型使用了各种各样的编程语言和库，因此部署和运行多个不同的模型可能会很复杂。ONNX是一个标准格式，不同编程语言和不同框架的模型可以转换为这种格式并以标准方式运行。
- en: This allows greater interoperability, because when models from different programming
    languages and frameworks are converted to ONNX format, they can be more easily
    deployed using the standard ONNX Runtime. The ONNX Runtime also includes acceleration
    that can improve model inference performance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得更大的互操作性成为可能，因为当不同编程语言和框架的模型转换为ONNX格式后，它们可以更容易地使用标准的ONNX Runtime进行部署。ONNX
    Runtime还包括可以提升模型推理性能的加速功能。
- en: After you have developed your model in scikit-learn, you will convert it to
    ONNX format, and then use the [ONNX Runtime](https://oreil.ly/IGEBD) in your API
    to make predictions (inferences).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在你使用scikit-learn开发完模型后，你将将其转换为ONNX格式，然后在你的API中使用[ONNX Runtime](https://oreil.ly/IGEBD)进行预测（推理）。
- en: scikit-learn
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn
- en: The scikit-learn library is a Python framework that allows you to create models
    for classification, regression, clustering, and a variety of other tasks. This
    is one of the more popular ML libraries in Python, along with PyTorch, TensorFlow,
    and XGBoost.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn库是一个Python框架，允许你创建用于分类、回归、聚类和其他各种任务的模型。这是Python中更受欢迎的ML库之一，与PyTorch、TensorFlow和XGBoost并列。
- en: sklearn-onnx
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sklearn-onnx
- en: Since you are using scikit-learn to create your model, you will use the sklearn-onnx
    library to convert your model into ONNX format. This will be the final step of
    the model training process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你使用scikit-learn创建模型，因此你将使用sklearn-onnx库将你的模型转换为ONNX格式。这将是模型训练过程的最后一步。
- en: Installing the New Libraries in Your Codespace
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你的Codespace中安装新库
- en: 'Open the Part III GitHub Codespace that you created in [Chapter 12](ch12.html#chapter_12).
    To install the libraries you need for this chapter, create a file named *chapter13/requirements.txt*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 打开你在[第12章](ch12.html#chapter_12)中创建的第三部分GitHub Codespace。为了安装本章所需的库，创建一个名为 *chapter13/requirements.txt*
    的文件：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Update *chapter13/requirements.txt* with the following contents:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下内容更新到 *chapter13/requirements.txt*：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO1-1)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO1-1)'
- en: The scikit-learn library will be used to create the ML model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用scikit-learn库创建ML模型。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO1-2)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO1-2)'
- en: The numpy library will be used to format numbers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: numpy库将用于格式化数字。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO1-3)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO1-3)'
- en: The pandas library will be used to process the input data file.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: pandas库将用于处理输入数据文件。
- en: '[![4](assets/4.png)](#co_deploying_a_machine_learning_api_CO1-4)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_deploying_a_machine_learning_api_CO1-4)'
- en: The skl2onnx library will be used to save the scikit-learn model into ONNX format.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用skl2onnx库将scikit-learn模型保存为ONNX格式。
- en: '[![5](assets/5.png)](#co_deploying_a_machine_learning_api_CO1-5)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_deploying_a_machine_learning_api_CO1-5)'
- en: Uvicorn is the web server used to host FastAPI.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Uvicorn是用于托管FastAPI的Web服务器。
- en: '[![6](assets/6.png)](#co_deploying_a_machine_learning_api_CO1-6)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_deploying_a_machine_learning_api_CO1-6)'
- en: The onnxruntime library is used to perform inference with a saved ONNX model
    file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: onnxruntime库用于使用保存的ONNX模型文件进行推理。
- en: 'Execute the following command to install the new libraries in your Codespace:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下命令以在你的Codespace中安装新库：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You should see a message that states that these libraries were successfully
    installed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一个消息，表明这些库已成功安装。
- en: Using the CRISP-DM Process
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CRISP-DM流程
- en: ML projects have many steps requiring people with a lot of specialized skills.
    A useful method of organizing an ML modeling project is the Cross-Industry Standard
    Process for Data Mining (Shearer, 2000). This model is widely used in the data
    science community.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ML项目有许多步骤，需要具有大量专业技能的人员。组织ML建模项目的一个有用方法是跨行业数据挖掘标准流程（Shearer，2000）。这个模型在数据科学社区中得到广泛应用。
- en: 'The following are definitions of the stages in CRISP-DM:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对CRISP-DM中各阶段定义的说明：
- en: Business understanding
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 业务理解
- en: During the this stage, the team identifies business objectives and assesses
    tools and techniques available.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，团队将确定业务目标并评估可用的工具和技术。
- en: Data understanding
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 数据理解
- en: Collecting data that is available to solve the problem, explore it, and verify
    the data quality.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 收集可用于解决问题、探索和验证数据质量的数据。
- en: Data preparation
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备
- en: During this stage, data scientists select specific data elements to be used,
    format them, and merge with any additional sources needed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，数据科学家会选择特定的数据元素用于使用，格式化它们，并与任何需要的额外来源合并。
- en: Modeling
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 建模
- en: Selecting a modeling technique and building a model that answers your business
    question.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 选择建模技术并构建一个回答你业务问题的模型。
- en: Evaluation
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 评估
- en: Review the model for its ability to solve the question and its readiness for
    production.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 审查模型解决问题的能力及其投入生产的准备情况。
- en: Deployment
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 部署
- en: Models are deployed in an environment where they can be consumed by the customer.
    Monitor and maintain the model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型被部署在客户可以消费的环境中。监控和维护模型。
- en: You will follow this process as you proceed with the chapter. The primary focus
    is on the deployment stage, so I will only touch lightly on some of the other
    stages.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续本章内容的过程中，你将遵循此流程。主要关注部署阶段，因此我将只简要介绍其他阶段的一些内容。
- en: Business Understanding
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 业务理解
- en: The first stage of the process is to establish a business understanding of the
    problem you are trying to solve. You are creating a model to serve fantasy football
    managers who are running their own team in a league with other owners. The question
    they need to answer each week of the season is “How much will it cost to acquire
    this player on waivers?”
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 过程的第一阶段是建立对您试图解决的问题的商业理解。您正在创建一个模型来服务于在联盟中拥有自己球队的幻想足球经理。他们在每个赛季每周需要回答的问题是“在转会中收购这位球员需要花费多少？”
- en: Fantasy managers can add new players to their rosters through a *waiver request*.
    In many leagues, a blind bidding auction is performed to decide who gets the best
    available players. Managers decide which players they want to bid for and put
    in the dollar amount they want to spend, which is hidden from other managers.
    When the bidding is processed on Tuesday or Wednesday of each week, the highest
    bidder gets the player at full price. Lower bidders miss out (but also don’t lose
    their money).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 幻想经理可以通过 *waiver request* 将新球员添加到他们的阵容中。在许多联盟中，进行一次盲拍竞标来决定谁可以得到最好的可用球员。经理决定他们想要竞标的球员，并放入他们想要花费的金额，这个金额对其他经理是隐藏的。当每周的二或三号处理竞标时，最高出价者以全价获得球员。出价较低的竞标者将错过（但也不会损失他们的钱）。
- en: Each manager has a set amount of money they can use for the season, such as
    $100\. (These aren’t real-world dollars, these are fantasy dollars.) This is sometimes
    called the *free agent acquisition budget* (FAAB). A manager wants to bid high
    enough to win the bid, but not overspend. The best-case scenario would be to win
    the bid at a lower dollar amount—getting a bargain.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每位经理都有一定数量的资金可以在赛季中使用，例如 $100。这些不是现实世界的美元，而是幻想美元。这有时被称为*自由球员收购预算*（FAAB）。经理希望出价足够高以赢得竞标，但不要超支。最佳情况是在较低的金额下赢得竞标——得到一笔划算的交易。
- en: 'To help the manager bid enough to win the player they want without overspending,
    you will give the manager a range of predictions: the low-end cost (10th percentile),
    the median cost (50th percentile), and the high-end cost (90th percentile).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助经理出价足够高以赢得他们想要的球员而不超支，您将给经理一个预测范围：低端成本（第 10 个百分位数）、中端成本（第 50 个百分位数）和高端成本（第
    90 个百分位数）。
- en: Data Understanding
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据理解
- en: 'In this stage, you will collect and explore the data that is available for
    your project. In the project repository, you’ll find the file *player_training_data_full.csv*.
    It contains historical fantasy football transaction data with the following columns:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您将收集和探索您项目可用的数据。在项目存储库中，您将找到文件 *player_training_data_full.csv*。它包含以下列的历史幻想足球交易数据：
- en: Fantasy regular season weeks remaining
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的幻想常规赛周数
- en: How many weeks are left in the regular season. For example, in week 2 of a season
    with 14 weeks, this would be 12.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的常规赛周数有多少。例如，在一个 14 周赛季的第 2 周，这将占 12 周。
- en: League budget percentage remaining
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的联盟预算百分比
- en: The percent of total dollars available in the league. For example, if $900 remain
    in the league’s original $1,200, this would be 75.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 总可用美元在联盟中的百分比。例如，如果联盟原始的 $1,200 中还剩下 $900，这将占 75%。
- en: Player season number
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 球员赛季编号
- en: The number of seasons this player has been in the league. Rookies have a value
    of 1.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 该球员在联盟中的赛季数。新秀的价值为 1。
- en: Position
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 位置
- en: The fantasy football position of the players that was acquired.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 被收购的球员的幻想足球位置。
- en: Waiver value tier
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 转会价值等级
- en: A qualitative measure of how valuable an individual player is. Each week, some
    players are “top tier” pickup targets, and they would get a 1\. Players who are
    nothing special would get a 5\. This is a categorical feature because putting
    players into the tiers is a qualitative judgment. (You may get these from a fantasy
    website or assign them yourself.)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 评估单个球员价值的定性指标。每周，一些球员是“顶级”的选秀目标，他们将得到 1 分。没有什么特别的球员将得到 5 分。这是一个分类特征，因为将球员放入等级是定性判断。（您可以从幻想网站上获取这些信息或自行分配。）
- en: 'To begin reviewing the data and selecting fields you want to use in your model,
    create a Jupyter Notebook by running the following commands in the Terminal window:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始审查数据和选择你想要在模型中使用的数据字段，请在终端窗口中运行以下命令以创建一个 Jupyter Notebook：
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Open the *player_acquisition_model.ipynb* file. As you did in [Chapter 9](ch09.html#chapter_9),
    select the Python kernel and enable the Python and Jupyter extensions, then select
    the recommended Python environment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 *player_acquisition_model.ipynb* 文件。正如您在 [第 9 章](ch09.html#chapter_9) 中所做的那样，选择
    Python 内核并启用 Python 和 Jupyter 扩展，然后选择推荐的 Python 环境。
- en: 'Enter the following title in the Markdown cell and run it:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在Markdown单元格中输入以下标题并运行它：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now you will import the Python libraries you need. Create and run the following
    Markdown cell:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将导入所需的Python库。创建并运行以下Markdown单元格：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Add and run a new Python cell with the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行一个新的Python单元格，以下代码：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO2-1)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_deploying_a_machine_learning_api_CO2-1)'
- en: This function is used to split data files into train and test sets.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数用于将数据文件分割成训练集和测试集。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO2-2)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_deploying_a_machine_learning_api_CO2-2)'
- en: Your model will use the `GradientBoostingRegressor` algorithm.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你的模型将使用`GradientBoostingRegressor`算法。
- en: 'Add another Markdown cell with the following text:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 添加另一个Markdown单元格，内容如下：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Add and run a Python code cell with the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行以下Python代码单元格：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO3-1)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_deploying_a_machine_learning_api_CO3-1)'
- en: This statement removes any existing logging handlers configured by CodeSpaces.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这条语句移除了CodeSpaces配置的任何现有日志处理程序。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO3-2)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_deploying_a_machine_learning_api_CO3-2)'
- en: This sets the logging level to record in the log.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置日志级别以记录到日志中。
- en: 'To begin loading your training data, add another Markdown cell with the following
    text:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始加载你的训练数据，添加另一个Markdown单元格，内容如下：
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add and run a Python code cell with the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行以下Python代码单元格：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Data Preparation
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'Next you will select the data to be included in the model. Rather than simply
    trying out all possible variables, you should consider the reason or theory that
    each would make a contribution to your model. Here are the three columns you’ll
    include, and the theory behind each:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将选择要包含在模型中的数据。而不仅仅是尝试所有可能的变量，你应该考虑每个变量为何或为何理论会为你的模型做出贡献。以下是你将包含的三列，以及每列背后的理论：
- en: League budget percentage remaining
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 联盟预算剩余百分比
- en: Your intuition is that a higher budget remaining leads to higher bids. This
    would make this a *linear* feature, in which the output variable goes up or down
    at a consistent rate as this value changes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你的直觉是剩余预算越高，出价就越高。这会使它成为一个*线性*特征，其中输出变量会以一致的速度随着该值的变化而上升或下降。
- en: Fantasy regular season weeks remaining
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的梦幻赛季周数
- en: The theory here is that players cost more at different points of the season.
    This probably isn’t a strictly linear value. History suggests some of the highest
    bids come in at the beginning of the season when the starting lineups are revealed,
    but other peak bids occur from injured players during the season and when managers
    have “use it or lose it” at the end of the season.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的理论是球员在不同赛季阶段的花费更高。这可能不是一个严格的线性值。历史表明，一些最高的出价出现在赛季初，当时首发阵容被公布，但其他高峰出价发生在赛季中受伤球员和赛季结束时经理们有“用或失”的情况。
- en: Waiver value tier
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 免签价值层级
- en: 'At a high level this is straightforward: higher-value players will cost more.
    But how much more? And how is each tier affected? These are more nuanced questions
    that you hope the model will be able to detect in the training data.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，这是简单的：价值更高的球员花费更多。但多高？每个层级又是如何受影响的？这些问题更为复杂，你希望模型能够在训练数据中检测到。
- en: Modeling
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模
- en: Now you will begin the modeling stage, first by selecting the algorithm and
    ML framework to use for your model. This decision is a combination of technical
    limitations and modeling factors.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将开始建模阶段，首先选择用于模型的算法和机器学习框架。这个决定是技术限制和建模因素的组合。
- en: Your technical limitations are that you want to use a Python framework and you
    want to convert the model to the ONNX format for inference. You also want to make
    predictions for the 10th, 50th, and 90th percentiles, so you need to use an algorithm
    that meets these technical criteria.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你的技术限制是想要使用Python框架，并且想要将模型转换为ONNX格式进行推理。你还想要预测第10、50和90百分位数，因此你需要使用满足这些技术标准的算法。
- en: Two modeling factors to consider are the type of output and the features you’ve
    selected. Your output will be numerical dollar values, so you will use a regression
    model (regressor). If your input features were all linear (as your input goes
    up or down, your prediction goes up or down), you could use a linear regressor.
    But your selected features are budget remaining (a linear feature), value tier
    (a categorical feature), and weeks remaining (a slightly more complicated feature).
    Because of the complexity of these features, some type of decision tree regressor
    is more appropriate.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的两个建模因素是输出类型和选定的特征。你的输出将是数值美元值，因此你将使用回归模型（回归器）。如果你的输入特征都是线性的（随着输入的增加或减少，预测也增加或减少），你可以使用线性回归器。但你的选定特征包括预算剩余（一个线性特征）、价值层级（一个分类特征）和剩余周数（一个稍微复杂一些的特征）。由于这些特征的复杂性，某种类型的决策树回归器更为合适。
- en: Based on these technical and modeling factors, you will use the [`GradientBoostingRegressor`
    algorithm](https://oreil.ly/_gqSO) from scikit-learn. The gradient boosting algorithm
    is way of combining multiple decision trees into an ensemble model that is more
    predictive than using the individual decision trees by themselves. It also supports
    the multiple predictions by percentile that you want to use. This algorithm is
    also supported by the ONNX format you will be saving the model in.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些技术和建模因素，你将使用 scikit-learn 中的 `GradientBoostingRegressor` 算法。梯度提升算法是将多个决策树组合成一个集成模型的方法，该模型比单独使用单个决策树更具预测性。它还支持你想要使用的按百分位数进行的多次预测。此算法还支持你将模型保存为
    ONNX 格式。
- en: To get started with the modeling process, you will first split your data into
    multiple variables for the training (80% of the rows) and testing (20% of the
    rows). There are conventions for naming of variables, and you will follow those
    so that your code is understandable by other data scientists. [Table 13-2](#training_variables_ch13)
    explains the purpose of these variable names.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始建模过程，你首先将数据分成多个变量用于训练（80% 的行）和测试（20% 的行）。存在变量命名的惯例，你将遵循这些惯例，以便其他数据科学家能理解你的代码。[表
    13-2](#training_variables_ch13) 解释了这些变量名的作用。
- en: Table 13-2\. Conventional variable names for training models
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 表 13-2\. 训练模型的常规变量名
- en: '| Variable name | Purpose | Columns included | Data included |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 变量名 | 目的 | 包含的列 | 包含的数据 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| X (uppercase) | Input columns for full data | Input | All |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| X (大写) | 全数据的输入列 | 输入 | 所有 |'
- en: '| y (lowercase) | Output columns for full data | Output | All |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| y (小写) | 全数据的输出列 | 输出 | 所有 |'
- en: '| X_train | Input columns of training data | Input | Training data (80%) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| X_train | 训练数据的输入列 | 输入 | 训练数据（80%）|'
- en: '| y_train | Output columns of training data | Output | Training data (80%)
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| y_train | 训练数据的输出列 | 输出 | 训练数据（80%）|'
- en: '| X_test | Input columns of test data | Input | Test data (20%) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| X_test | 测试数据的输入列 | 输入 | 测试数据（20%）|'
- en: '| y_test | Output columns of test data | Output | Test data (20%) |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| y_test | 测试数据的输出列 | 输出 | 测试数据（20%）|'
- en: 'Add another Markdown cell with the following text:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 添加另一个包含以下文本的 Markdown 单元：
- en: '[PRE11]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Add and run a Python code cell with the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行以下 Python 代码单元：
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO4-1)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO4-1)'
- en: You are selecting three of the input columns for X.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在选择 X 的三个输入列。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO4-2)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO4-2)'
- en: You only include the output column when creating y.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 y 时，你只包括输出列。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO4-3)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO4-3)'
- en: The `train_test_split` function reads the X and y variables and then outputs
    the variables explained in [Table 13-2](#training_variables_ch13).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_test_split` 函数读取 X 和 y 变量，然后输出 [表 13-2](#training_variables_ch13) 中解释的变量。'
- en: '[![4](assets/4.png)](#co_deploying_a_machine_learning_api_CO4-4)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_deploying_a_machine_learning_api_CO4-4)'
- en: This parameter determines that 20% of the data will be in the test set and 80%
    will be in the training set.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 此参数确定测试集中将有 20% 的数据，而训练集中将有 80% 的数据。
- en: '[![5](assets/5.png)](#co_deploying_a_machine_learning_api_CO4-5)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_deploying_a_machine_learning_api_CO4-5)'
- en: If you use the same `random_state` value each time you call this method, you
    will get the same rows in the train and test variables.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你每次调用此方法时都使用相同的 `random_state` 值，你将在训练和测试变量中获得相同的行。
- en: Now that you split the data, you are ready to build a model. Because you want
    to give a range of predictions, you will create three separate models. When you
    create the API, you will combine the results of these models into a single API
    call.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经分割了数据，你准备好构建模型了。因为你想要给出一系列预测，所以你会创建三个独立的模型。当你创建API时，你将把这些模型的预测结果合并成一个单独的API调用。
- en: The process of training your model is called *fitting*, where the library takes
    a general algorithm and *fits* it or applies it to your training data to make
    a specialized model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 训练你的模型的流程被称为*拟合*，其中库会取一个通用算法并将其*拟合*或应用到你的训练数据上，以创建一个专门的模型。
- en: 'Add another Markdown cell with the following text:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 添加另一个Markdown单元格，内容如下：
- en: '[PRE13]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Add and run a Python code cell with the following:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行一个Python代码单元格，内容如下：
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO5-1)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO5-1)'
- en: This command creates a `GradientBoostingRegressor` model that will try to predict
    the 10th percentile values. In this case, this means a dollar amount that will
    be less than 90% of the bids. The next two statements are similar except with
    different percentiles.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令创建一个`GradientBoostingRegressor`模型，试图预测第10百分位数的值。在这种情况下，这意味着一个金额将小于90%的出价。接下来的两个语句与此类似，只是有不同的百分位数。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO5-2)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO5-2)'
- en: This statement uses the `fit()` method to prepare this model to make predictions
    based on the training data you provided. The next two lines do the same for the
    other two models.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句使用`fit()`方法准备这个模型，使其能够根据你提供的训练数据进行预测。接下来的两行对其他两个模型做同样的操作。
- en: 'At this point, your models are in scikit_learn format and are only available
    in this Jupyter Notebook. To prepare these models for deployment and make them
    more cross-platform compatible, you will save your models in the ONNX format.
    Before doing this, you’ll need to combine the features from the X variable into
    the two-dimensional array format required by the converter. Add another Markdown
    cell with the following text:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你的模型处于scikit_learn格式，并且仅在此Jupyter Notebook中可用。为了准备这些模型以进行部署并使它们更跨平台兼容，你将使用ONNX格式保存你的模型。在这样做之前，你需要将X变量中的特征合并到转换器所需的二维数组格式中。添加另一个Markdown单元格，内容如下：
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Add and run a Python code cell with the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 添加并运行一个Python代码单元格，内容如下：
- en: '[PRE16]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO6-1)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO6-1)'
- en: This statement combines the features from the X variable into the two-dimensional
    array format required by the convertor.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句将X变量中的特征合并到转换器所需的二维数组格式中。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO6-2)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO6-2)'
- en: This statement converts the first model to ONNX format. It sets the names of
    the input and output attributes in the model by reading the first row of the `X_array`,
    which contains the element names.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句将第一个模型转换为ONNX格式。它通过读取包含元素名称的`X_array`的第一行来设置模型中输入和输出属性的名字。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO6-3)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO6-3)'
- en: This statement creates a file in the local filesystem and saves the model in
    ONNX format.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句在本地文件系统中创建一个文件，并将模型以ONNX格式保存。
- en: Evaluation
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: Planning and training models is an iterative process, so the model at this point
    likely needs improving. In a full project, you would iteratively evaluate the
    model with formal metrics for accuracy, fairness, and other qualities that make
    a model appropriate for production. At that point, you might decide to try a different
    combination of features and tune your model in different ways.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 规划和训练模型是一个迭代的过程，所以这个阶段的模型可能需要改进。在一个完整的项目中，你会使用正式的度量标准（如准确性、公平性等）来迭代评估模型，以使模型适合生产。在那个阶段，你可能会决定尝试不同的特征组合，并以不同的方式调整你的模型。
- en: Since this chapter is focused on deploying models, you will not be performing
    those steps. For more information about model evaluation, read *Designing Machine
    Learning Sytems* by Chip Huyen (O’Reilly, 2022).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章的重点是部署模型，你将不会执行这些步骤。有关模型评估的更多信息，请阅读Chip Huyen所著的《设计机器学习系统》（O’Reilly，2022年）。
- en: Deployment
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: You are are ready to deploy the model for real-time inference, with one API
    call returning a prediction that combines all three models.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以部署模型进行实时推理，一个API调用就可以返回结合了所有三个模型的预测。
- en: '[Figure 13-3](#model_serving_api_ch13) demonstrates the components used to
    create this API. If you compare this to the components of the API created in Part
    I of this book, you will see many similarities. FastAPI is still used as the controller,
    and Pydantic is still used for data transfer and data validation. However, instead
    of retrieving data from a database like the Part I API did, this API will use
    the ONNX Runtime to perform inference from the models that you trained and saved.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13-3](#model_serving_api_ch13) 展示了创建此API所使用的组件。如果您将其与本书第一部分的API组件进行比较，您将看到许多相似之处。FastAPI仍然用作控制器，Pydantic仍然用于数据传输和数据验证。然而，与第一部分的API从数据库中检索数据不同，此API将使用ONNX
    Runtime从您训练并保存的模型中进行推理。'
- en: '![Model serving API components](assets/haad_1303.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![模型服务API组件](assets/haad_1303.png)'
- en: Figure 13-3\. Model-serving API components
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-3\. 模型服务API组件
- en: 'Begin by creating a Pydantic file named *schemas.py* to define the inputs and
    outputs to the API. FastAPI will use these schemas to generate the OAS file:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个名为 *schemas.py* 的Pydantic文件来定义API的输入和输出。FastAPI将使用这些模式生成OAS文件：
- en: '[PRE17]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Add the following to this file:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下内容添加到此文件中：
- en: '[PRE18]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO7-1)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_deploying_a_machine_learning_api_CO7-1)'
- en: The Pydantic library includes a `BaseModel` object that contains the validation
    logic.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Pydantic库包含一个包含验证逻辑的 `BaseModel` 对象。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO7-2)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_deploying_a_machine_learning_api_CO7-2)'
- en: This class defines the input values that users will send to get a prediction
    from the model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 此类定义了用户将发送以从模型获取预测的输入值。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO7-3)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_deploying_a_machine_learning_api_CO7-3)'
- en: This class defines the output that will be returned from the model. It contains
    three values—one from each model that you trained in the previous section.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 此类定义了模型将返回的输出。它包含三个值——来自您在上一节中训练的每个模型的值。
- en: 'Next, create the *main.py* file, which will contain the rest of the code for
    your API:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建 *main.py* 文件，其中将包含API的其余代码：
- en: '[PRE19]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'At the top of this file, add the imports and an API description. These will
    be used in the OAS file and then displayed on the Swagger UI documentation that
    FastAPI produces. Add this Python code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在此文件的顶部，添加导入和API描述。这些将在OAS文件中使用，然后显示在FastAPI生成的Swagger UI文档中。添加以下Python代码：
- en: '[PRE20]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO8-1)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_deploying_a_machine_learning_api_CO8-1)'
- en: This library is used to load the models from their files and serve inferences
    in the API.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 此库用于从文件中加载模型并在API中提供推理服务。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO8-2)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_deploying_a_machine_learning_api_CO8-2)'
- en: This imports the Pydantic schemas, which will be used to define the inputs and
    outputs of the API.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 此处导入Pydantic模式，这些模式将用于定义API的输入和输出。
- en: Next, you will add the code that uses the ONNX Runtime to load an inference
    session object for each of the three models. Then, these sessions are used to
    get labels for the input and output expected for this model. You defined the three
    inputs expected and the one output when you created the model in scikit-learn
    and then converted it to ONNX format.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将添加使用ONNX Runtime为三个模型中的每一个加载推理会话对象的代码。然后，这些会话用于获取此模型所需的输入和输出标签。您在scikit-learn中创建模型时定义了三个期望的输入和一个输出，然后将它转换为ONNX格式。
- en: 'Add the following code to the bottom of *main.py*:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码添加到 *main.py* 文件的底部：
- en: '[PRE21]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO9-1)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_deploying_a_machine_learning_api_CO9-1)'
- en: This loads the first ONNX model from the file and creates a session object that
    can be used to make inferences. The next two lines do the same for the other model
    files.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此处从文件中加载第一个ONNX模型并创建一个会话对象，该对象可用于进行推理。接下来的两行对其他模型文件执行相同的操作。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO9-2)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_deploying_a_machine_learning_api_CO9-2)'
- en: This statement gets the name of the input features from the session object.
    These will be used when making inferences.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 此语句从会话对象中获取输入特征名称。这些将在进行推理时使用。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO9-3)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_deploying_a_machine_learning_api_CO9-3)'
- en: This statement gets the name of the output features from the session object.
    These will be used when making inferences.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此语句从会话对象中获取输出特征名称。这些将在进行推理时使用。
- en: Because you have placed this code outside any function definitions, it will
    run once at startup of the API.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你将此代码放置在函数定义之外，它将在 API 启动时运行一次。
- en: The next section of FastAPI code will be familiar to you if you created the
    API in Part I. The first statement creates the FastAPI `app` object using the
    API description you added previously. Then, the `@app.get()` method creates the
    health check. This is a useful best practice that allows users to check the status
    of the API before making other API calls.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在第一部分创建了 API，那么接下来的 FastAPI 代码段将对你来说很熟悉。第一条语句使用你之前添加的 API 描述创建 FastAPI `app`
    对象。然后，`@app.get()` 方法创建健康检查。这是一个有用的最佳实践，允许用户在执行其他 API 调用之前检查 API 的状态。
- en: 'Add the following code to the bottom of *main.py*:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码添加到 *main.py* 文件的底部：
- en: '[PRE22]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO10-1)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_deploying_a_machine_learning_api_CO10-1]'
- en: This creates the main FastAPI `app` object using the `api_description` defined
    previously.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用之前定义的 `api_description` 创建主要的 FastAPI `app` 对象。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO10-2)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_deploying_a_machine_learning_api_CO10-2]'
- en: This is the FastAPI decorator that defines a `GET` endpoint at the root address.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这是定义根地址的 `GET` 端点的 FastAPI 装饰器。
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO10-3)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[#co_deploying_a_machine_learning_api_CO10-3]'
- en: This is the function that will be excecuted when this endpoint is called. It
    returns a single Python statement to show that the API is running.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这是当调用此端点时将执行的函数。它返回一个单独的 Python 语句以表明 API 正在运行。
- en: The remaining code defines the API endpoint that provides the prediction capabilities
    for users. It begins with a Python decorator that provides information that will
    end up in the OAS file (and documentation). Then, it has the `predict()` method
    that uses the ONNX Runtime to call each model and put their outputs in the API
    response.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的代码定义了提供用户预测功能的 API 端点。它以一个 Python 装饰器开始，该装饰器提供最终将出现在 OAS 文件（和文档）中的信息。然后，它有
    `predict()` 方法，该方法使用 ONNX Runtime 调用每个模型并将它们的输出放入 API 响应中。
- en: 'Add the following code to the bottom of *main.py*:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码添加到 *main.py* 文件的底部：
- en: '[PRE23]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[![1](assets/1.png)](#co_deploying_a_machine_learning_api_CO11-1)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_deploying_a_machine_learning_api_CO11-1]'
- en: This decorator creates a `POST` endpoint at the */predict* address. It will
    be used to perform inferences.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个装饰器在 */predict* 地址创建一个 `POST` 端点。它将用于执行推理。
- en: '[![2](assets/2.png)](#co_deploying_a_machine_learning_api_CO11-2)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_deploying_a_machine_learning_api_CO11-2]'
- en: The `ResponseModel` statement is used by FastAPI to define the return type of
    this endpoint. This will be used to generate the OAS file.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`ResponseModel` 语句由 FastAPI 用于定义此端点的返回类型。这将用于生成 OAS 文件。'
- en: '[![3](assets/3.png)](#co_deploying_a_machine_learning_api_CO11-3)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[#co_deploying_a_machine_learning_api_CO11-3]'
- en: This is the function that will be called at this endpoint.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这是将在该端点调用的函数。
- en: '[![4](assets/4.png)](#co_deploying_a_machine_learning_api_CO11-4)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)[#co_deploying_a_machine_learning_api_CO11-4]'
- en: This statement reformats the input variables into a NumPy array, which is expected
    by the ONNX Runtime to call the model.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这条语句将输入变量重新格式化为 NumPy 数组，这是 ONNX Runtime 调用模型所期望的。
- en: '[![5](assets/5.png)](#co_deploying_a_machine_learning_api_CO11-5)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)[#co_deploying_a_machine_learning_api_CO11-5]'
- en: This statement calls the ONNX Runtime and gets an inference for the 10th percentile
    model using the input from the API call. The next two statements use the same
    input to call the other two models.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这条语句调用 ONNX Runtime 并使用 API 调用的输入获取第 10 百分位模型的推理。接下来的两个语句使用相同的输入调用其他两个模型。
- en: '[![6](assets/6.png)](#co_deploying_a_machine_learning_api_CO11-6)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '![6](assets/6.png)[#co_deploying_a_machine_learning_api_CO11-6]'
- en: This statement creates a `PredictionOutput` object with the inference values,
    and returns it in the API call. It rounds the values to two decimal places for
    presentation.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这条语句创建一个包含推理值的 `PredictionOutput` 对象，并在 API 调用中返回它。为了展示，它将值四舍五入到两位小数。
- en: 'With all of the API code completed, you are ready to run the API and test out
    the ML model. Enter the following command from the command line:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成所有 API 代码后，你就可以运行 API 并测试 ML 模型了。从命令行输入以下命令：
- en: '[PRE24]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You will see the application startup occur as shown in [Figure 13-4](#fast_api_run_ch13).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到应用程序启动，如图 13-4 所示。
- en: '![ML model running](assets/haad_1304.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![ML 模型运行](assets/haad_1304.png)'
- en: Figure 13-4\. ML Model API running
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-4\. ML 模型 API 运行
- en: In Codespaces, you will also see a pop-up as shown in [Figure 13-5](#codespaces_api_open_browser).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在Codespaces中，你也会看到一个如图13-5所示的弹出窗口。
- en: '![Codespaces browser window popup](assets/haad_1305.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![Codespaces浏览器窗口弹出](assets/haad_1305.png)'
- en: Figure 13-5\. Codespaces browser window pop-up
  id: totrans-247
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-5\. Codespaces浏览器窗口弹出
- en: 'Click “Open in Browser” to open a browser tab outside your Codespaces. This
    browser will show a base URL ending in *app.github.dev* that contains the response
    from your API running on Codespaces. You should see the following health check
    message in your web browser:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“在浏览器中打开”以在您的Codespaces之外打开一个浏览器标签页。此浏览器将显示一个以*app.github.dev*结尾的基本URL，其中包含在Codespaces上运行的API的响应。你应该在你的网页浏览器中看到以下健康检查消息：
- en: '[PRE25]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This confirms your API is running. To view the interactive API documentation
    for your API, copy and paste the following onto the end of the base URL in your
    browser: **`/docs`**. For example, the full URL might be *[*https://happy-pine-tree-1234-8000.app.github.dev/docs*](https://happy-pine-tree-1234-8000.app.github.dev/docs)*
    in the browser. You should see documentation, as shown in [Figure 13-6](#swagger_docs_1_ch13).'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这确认了您的API正在运行。要查看API的交互式API文档，请在浏览器中基本URL的末尾复制并粘贴以下内容：**`/docs`**。例如，完整的URL可能是浏览器中的*[*https://happy-pine-tree-1234-8000.app.github.dev/docs*](https://happy-pine-tree-1234-8000.app.github.dev/docs)。你应该会看到如图13-6所示的文档。
- en: '![Documentation for the ML API](assets/haad_1306.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![ML API文档](assets/haad_1306.png)'
- en: Figure 13-6\. Documentation for the ML API
  id: totrans-252
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-6\. ML API文档
- en: To call the ML API, select the `POST` */predict/* endpoint to open up that section,
    and then select “Try it out,” after which you should see a display as shown in
    [Figure 13-7](#swagger_docs_2_ch13).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 要调用ML API，选择`POST` */predict/* 端点以打开该部分，然后选择“尝试”，之后你应该会看到一个如图13-7所示的显示。
- en: '![Trying it out for /predict](assets/haad_1307.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![尝试/predict](assets/haad_1307.png)'
- en: Figure 13-7\. Trying it out for /predict
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-7\. 尝试/predict
- en: 'Here is one big difference from the API you created in Part I: you are using
    a `POST` endpoint instead of `GET`. To make a call to a `POST` endpoint, you provide
    an HTTP request body in JSON format. This is where users will provide the input
    values to send to the API. These were automatically generated based on the `FantasyAcquisitionFeatures`
    Pydantic class you defined in the previous section. Update the request body with
    the following values:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 与第一部分中创建的API相比，这里有一个很大的不同：你使用的是`POST`端点而不是`GET`。要调用`POST`端点，你需要提供一个JSON格式的HTTP请求体。这是用户提供要发送到API的输入值的地方。这些值是根据你在上一节中定义的`FantasyAcquisitionFeatures`
    Pydantic类自动生成的。使用以下值更新请求体：
- en: '[PRE26]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Click Execute to send these values to the API. Scroll down and you should see
    a server response with a Code value of 200, which indicates success. The predicted
    values will be returned in the HTTP response body, which matches the definition
    of the `PredictionOutput` Pydantic class. You should see an output similar to
    [Figure 13-8](#swagger_docs_3_ch13), although the predicted values may differ.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“执行”以将这些值发送到API。向下滚动，你应该会看到一个服务器响应，其代码值为200，这表示成功。预测值将在HTTP响应体中返回，这与`PredictionOutput`
    Pydantic类的定义相匹配。你应该会看到一个类似于[图13-8](#swagger_docs_3_ch13)的输出，尽管预测值可能不同。
- en: '![API response with prediction](assets/haad_1308.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![API预测响应](assets/haad_1308.png)'
- en: Figure 13-8\. API response with prediction
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-8\. API预测响应
- en: 'To see the final structure of your project, execute the `tree` command as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看项目的最终结构，执行以下`tree`命令：
- en: '[PRE27]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Congratulations! You have created the first draft of an ML model and served
    it with a REST API.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经创建了机器学习模型的第一稿，并通过REST API提供服务。
- en: Additional Resources
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: To learn more about data science projects, read *Practical Data Science with
    Python* by Nathan George (Packt Publishing, 2021).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于数据科学项目的信息，请阅读Nathan George（Packt Publishing，2021年）所著的《Python实用数据科学》。
- en: To get more experience using scikit-learn and other ML libraries, read *Hands-On
    Machine Learning with Scikit-Learn, Keras, and Tensorflow* by Aurélien Géron (O’Reilly,
    2022).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得更多使用scikit-learn和其他机器学习库的经验，请阅读Aurélien Géron（O’Reilly，2022年）所著的《使用Scikit-Learn、Keras和Tensorflow动手机器学习》。
- en: To learn more about deploying models for prediction, read *Designing Machine
    Learning Systems* by Chip Huyen (O’Reilly, 2022).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于部署预测模型的信息，请阅读Chip Huyen（O’Reilly，2022年）所著的《设计机器学习系统》。
- en: Summary
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the ML lifecycle and created an ML model
    using scikit-learn. Then, you converted the model to ONNX format to make it compatible
    with more frameworks. Finally, you deployed your model using FastAPI and used
    it for real-time inference.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了机器学习生命周期，并使用scikit-learn创建了一个机器学习模型。然后，你将模型转换为ONNX格式，使其与更多框架兼容。最后，你使用FastAPI部署了你的模型，并用于实时推理。
- en: In [Chapter 14](ch14.html#chapter_14), you will use generative AI to call an
    API using LangChain.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第14章](ch14.html#chapter_14)中，你将使用生成式AI通过LangChain调用API。
