- en: Chapter 18\. Debugging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第18章。调试
- en: You’re bound to run into some confusing errors as you integrate machine learning
    into your product, embedded or otherwise, and probably sooner rather than later.
    In this chapter, we discuss some approaches to understanding what’s happening
    when things go wrong.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将机器学习集成到您的产品中时，无论是嵌入式还是其他方式，您都很可能会遇到一些令人困惑的错误，而且可能会比您想象的要早。在本章中，我们将讨论一些在事情出错时理解发生了什么的方法。
- en: Accuracy Loss Between Training and Deployment
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和部署之间的准确性损失
- en: There are a lot of ways for problems to creep in when you take a machine learning
    model out of an authoring environment like TensorFlow and deploy it into an application.
    Even after you’re able to get a model building and running without reporting any
    errors, you might still not be getting the results you expect in terms of accuracy.
    This can be very frustrating because the neural network inference step can seem
    like a black box, with no visibility into what’s happening internally or what’s
    causing any problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将一个机器学习模型从TensorFlow等创作环境部署到应用程序中时，问题可能会悄然而至。即使您能够构建和运行模型而不报告任何错误，您可能仍然无法获得您期望的准确性结果。这可能会非常令人沮丧，因为神经网络推断步骤似乎是一个黑匣子，没有内部发生的可见性或导致任何问题的原因。
- en: Preprocessing Differences
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理差异
- en: An area that doesn’t get very much attention in machine learning research is
    how training samples are converted into a form that a neural network can operate
    on. If you’re trying to do object classification on images, those images must
    be converted into tensors, which are multidimensional arrays of numbers. You might
    think that would be straightforward, because images are already stored as 2D arrays,
    usually with three channels for red, green, and blue values. Even in this case,
    though, you do still need to make some changes. Classification models expect their
    inputs to be a particular width and height, for example 224 pixels wide by 224
    high, and a camera or other input source is unlikely to produce them in the correct
    size. This means you’ll need to rescale your captured data to match. Something
    similar has to be done for the training process, because the dataset will probably
    be a set of arbitrarily sized images on disk.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习研究中很少受到关注的一个领域是如何将训练样本转换为神经网络可以操作的形式。如果您尝试对图像进行对象分类，那么这些图像必须转换为张量，即数字的多维数组。您可能会认为这应该很简单，因为图像已经以2D数组的形式存储，通常具有红色、绿色和蓝色值的三个通道。即使在这种情况下，您仍然需要进行一些更改。分类模型期望它们的输入具有特定的宽度和高度，例如宽224像素，高224像素，而相机或其他输入源不太可能以正确的尺寸产生它们。这意味着您需要将捕获的数据重新缩放以匹配。对于训练过程也必须做类似的处理，因为数据集可能是磁盘上一组任意大小的图像。
- en: A subtle problem that often creeps in is that the rescaling method used for
    a deployment doesn’t match the one that was used to train the model. For example,
    early versions of [Inception](https://oreil.ly/rGKnL) used bilinear scaling to
    shrink images, which was confusing to people with a background in image processing
    because downscaling that way degrades the visual quality of an image and is generally
    to be avoided. As a result, many developers using these models for inference in
    their applications instead used the more *correct* approach of area sampling—but
    it turns out that this actually decreases the accuracy of the results! The intuition
    is that the trained models had learned to look for the artifacts that bilinear
    downscaling produces, and their absence caused the top-one error rate to increase
    by a few percent.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经常出现的微妙问题是，用于部署的重新缩放方法与用于训练模型的方法不匹配。例如，早期版本的[Inception](https://oreil.ly/rGKnL)使用双线性缩放来缩小图像，这让具有图像处理背景的人感到困惑，因为这种方式的缩小会降低图像的视觉质量，通常应该避免。因此，许多开发人员在应用程序中使用这些模型进行推断时，改用了更*正确*的区域采样方法，但事实证明，这实际上降低了结果的准确性！直觉是，训练模型已经学会寻找双线性缩放产生的伪影，而它们的缺失导致了前一错误率增加了几个百分点。
- en: 'The image preprocessing doesn’t stop at the rescaling step, either. There’s
    also the question of how to convert image values typically encoded from 0 to 255
    into the floating-point numbers used during training. For several reasons, these
    are usually linearly scaled into a smaller range: either –1.0 to 1.0 or 0.0 to
    1.0\. You’ll need to do the same value scaling in your application if you’re feeding
    in floating-point values. If you’re feeding 8-bit values directly, you won’t need
    to do this at runtime—the original 8-bit values can be used untransformed—but
    you do still need to pass them into the `toco` export tool through the `--mean_values`
    and `--std_values` flags. For a range of –1.0 to 1.0, you’d use `--mean_values=128
    --std_values=128`.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像预处理并不仅止于重新缩放步骤。还有一个问题，即如何将通常编码为0到255的图像值转换为训练期间使用的浮点数。出于几个原因，这些值通常会线性缩放到一个较小的范围内：要么是-1.0到1.0，要么是0.0到1.0。如果您要输入浮点值，您需要在应用程序中进行相同的值缩放。如果您直接输入8位值，您在运行时不需要执行此操作——原始的8位值可以不经转换地使用，但您仍需要通过“toco”导出工具通过“--mean_values”和“--std_values”标志将它们传递进去。对于-1.0到1.0的范围，您可以使用“--mean_values=128
    --std_values=128”。
- en: Confusingly, it’s often not obvious what the correct scale for input image values
    should be from the model code, since this is a detail that’s often buried in the
    implementation of the APIs used. The Slim framework that a lot of published Google
    models use defaults to –1.0 to 1.0, so that’s a good range to try, but you might
    end up having to debug through the training Python implementation to figure it
    out in other cases, if it’s not documented.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 令人困惑的是，从模型代码中往往不明显知道输入图像值的正确比例应该是多少，因为这通常是隐藏在所使用API的实现中的细节。许多发布的Google模型使用的Slim框架默认为-1.0到1.0，因此这是一个不错的尝试范围，但如果没有记录，您可能最终不得不通过训练Python实现进行调试以找出其他情况下的正确比例。
- en: Even worse, you can end up getting *mostly* correct results even if you get
    the resizing or value scaling a bit wrong, but you’ll degrade the accuracy. This
    means that your application can appear to work upon a casual inspection, but end
    up with an overall experience that’s less impressive than it should be. And the
    challenges around image preprocessing are actually a lot simpler than in other
    areas, like audio or accelerometer data, for which there might be a complex pipeline
    of feature generation to convert raw data into an array of numbers for the neural
    network. If you look at [the preprocessing code for the `micro_speech` example](https://oreil.ly/tedw1),
    you’ll see that we had to implement many stages of signal processing to get from
    the audio samples to a spectrogram that could be fed into the model, and any difference
    between this code and the version used in training would degrade the accuracy
    of the results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，即使调整大小或值缩放有点错误，您也可能得到*大部分*正确的结果，但会降低准确性。这意味着您的应用程序在初步检查时可能看起来正常运行，但最终体验可能不如预期那样令人印象深刻。图像预处理周围的挑战实际上比其他领域（如音频或加速度计数据）要简单得多，因为可能存在将原始数据转换为神经网络数字数组的复杂特征生成管道。如果查看`micro_speech`示例的预处理代码，您将看到我们必须实现许多信号处理阶段，以从音频样本获得可馈送到模型中的频谱图，任何此代码与训练中使用的版本之间的差异都会降低结果的准确性。
- en: Debugging Preprocessing
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调试预处理
- en: Given that these input data transformations are so prone to errors, you might
    not easily be able to even spot that you have a problem—and if you do, it might
    be tough to figure out the cause. What are you supposed to do? We’ve found that
    there are a few approaches that can help.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些输入数据转换很容易出错，您可能甚至很难发现问题，即使发现了问题，也可能很难找出原因。您应该怎么办？我们发现有一些方法可以帮助。
- en: It’s always best to have some version of your code that you can run on a desktop
    machine if at all possible, even if the peripherals are stubbed out. You’ll have
    much better debugging tools in a Linux, macOS, or Windows environment, and it’s
    easy to transfer test data between your training tools and the application. For
    the sample code in TensorFlow Lite for Microcontrollers, we’ve broken the different
    parts of our applications into modules and enabled Makefile building for Linux
    and macOS targets, so we can run the inference and preprocessing stages separately.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，最好有一个可以在桌面机器上运行的代码版本，即使外围设备被存根。在Linux、macOS或Windows环境中，您将拥有更好的调试工具，并且可以轻松在训练工具和应用程序之间传输测试数据。对于TensorFlow
    Lite for Microcontrollers中的示例代码，我们将应用程序的不同部分拆分为模块，并为Linux和macOS目标启用了Makefile构建，因此我们可以分别运行推断和预处理阶段。
- en: The most important tool for debugging preprocessing problems is comparing results
    between the training environment and what you’re seeing in your application. The
    most difficult part of doing this is extracting the correct values for the nodes
    you care about during training and controlling what the inputs are. It’s beyond
    the scope of this book to cover how to do this in detail, but you’ll need to identify
    the names of the ops that correspond to the core neural network stages (after
    file decoding, preprocessing, and the first op that takes in the results of the
    preprocessing). The first op that takes in the results of the preprocessing corresponds
    to the `--input_arrays` argument to `toco`. If you can identify these ops, insert
    a [`tf.print`](https://oreil.ly/JYT_m) op with `summarize` set to `-1` after each
    of them in Python. You’ll then be able to see printouts of the contents of the
    tensors at each stage in the debug console if you run a training loop.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 调试预处理问题最重要的工具是比较训练环境和应用程序中所看到的结果。最困难的部分是在训练过程中提取您关心的节点的正确值并控制输入是什么。本书的范围无法详细介绍如何做到这一点，但您需要识别与核心神经网络阶段对应的操作的名称（在文件解码、预处理和接收预处理结果的第一个操作之后）。接收预处理结果的第一个操作对应于`toco`的`--input_arrays`参数。如果您能识别这些操作，请在Python中在每个操作后插入一个`tf.print`操作，其中`summarize`设置为`-1`。然后，如果运行训练循环，您将能够在调试控制台中看到每个阶段张量内容的打印输出。
- en: You should then be able to take these tensor contents and convert them into
    C data arrays that you can compile into your program. There are some examples
    of this in the `micro_speech` code, like [a one-second audio sample of someone
    saying “yes”](https://oreil.ly/qFoMn), and [the expected results of preprocessing
    that input](https://oreil.ly/uKYWo). After you have these reference values, you
    should be able to feed them as inputs into the modules holding each stage of your
    pipeline (preprocessing, neural network inference) and make sure the outputs match
    what you expect. You can do this with throwaway code if you’re short on time,
    but it’s worth the extra investment to turn them into [unit tests](https://oreil.ly/t2E03)
    that ensure your preprocessing and model inference continue to be verified as
    the code changes over time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您应该能够将这些张量内容转换为C数据数组，然后将其编译到您的程序中。在`micro_speech`代码中有一些示例，比如[一个说“yes”的一秒音频样本](https://oreil.ly/qFoMn)，以及[预处理该输入的预期结果](https://oreil.ly/uKYWo)。在获得这些参考值之后，您应该能够将它们作为输入馈送到保存每个阶段的模块（预处理、神经网络推断）中，并确保输出与您的预期相匹配。如果时间不足，您可以使用临时代码来完成此操作，但将其转换为[单元测试](https://oreil.ly/t2E03)是值得额外投资的，以确保随着代码随时间变化，您的预处理和模型推断仍然得到验证。
- en: On-Device Evaluation
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设备上的评估
- en: At the end of training, neural networks are evaluated using a test set of inputs,
    and the predictions are compared to the expected results to characterize the overall
    accuracy of the model. This happens as a normal part of the training process,
    but it’s rare to do the same evaluation on the code that has been deployed on
    a device. Often the biggest barrier is just transferring the thousands of input
    samples that make up a typical test dataset onto an embedded system with limited
    resources. This is a shame, though; making sure that the on-device accuracy matches
    what was seen at the end of training is the only way to be sure that the model
    has been correctly deployed, because there are so many ways to introduce subtle
    errors that are difficult to spot otherwise. We didn’t manage to implement a full
    test set evaluation for the `micro_speech` demo, but there is at least [an end-to-end
    test](https://oreil.ly/4372z) that makes sure we get the correct labels for two
    different inputs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练结束时，神经网络会使用一组测试输入进行评估，将预测结果与期望结果进行比较，以表征模型的整体准确性。这是训练过程的正常部分，但很少对已部署在设备上的代码进行相同的评估。通常最大的障碍只是将构成典型测试数据集的成千上万个输入样本传输到资源有限的嵌入式系统上。然而，这是一种遗憾；确保设备上的准确性与训练结束时看到的准确性相匹配是确保模型已正确部署的唯一方法，因为有很多方式可以引入难以察觉的细微错误。我们没有设法为`micro_speech`演示实现完整的测试集评估，但至少有[端到端测试](https://oreil.ly/4372z)，确保我们对两个不同输入获得正确的标签。
- en: Numerical Differences
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值差异
- en: A neural network is a chain of complex mathematical operations performed on
    large arrays of numbers. The original training is usually done in floating point,
    but we try to convert down to a lower-precision integer representation for embedded
    applications. The operations themselves can be implemented in many different ways,
    depending on the platform and optimization trade-offs. All these factors mean
    that you can’t expect bit-wise identical results from a network on different devices,
    even if it’s given the same input. This means you must determine what differences
    you can tolerate, and, if those differences become too large, how to track down
    where they come from.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是对大量数字数组执行的一系列复杂数学操作。原始训练通常是以浮点数进行的，但我们尝试将其转换为嵌入式应用程序的低精度整数表示。这些操作本身可以以许多不同的方式实现，取决于平台和优化权衡。所有这些因素意味着您不能期望从不同设备上的网络获得位级相同的结果，即使给定相同的输入。这意味着您必须确定您可以容忍的差异，并且如果这些差异变得太大，如何追踪其来源。
- en: Are the Differences a Problem?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 差异是否是问题？
- en: We sometimes joke that the only metric that really matters is the app store
    rating. Our goal should be to produce products that people are happy with, so
    all other metrics are just proxies for user satisfaction. Since there are always
    going to be numerical differences from the training environment, the first challenge
    is to understand whether they hurt the product experience. This can be obvious
    if the values you’re getting out of your network are nonsensical, but if they
    only differ by a few percentage points from what’s expected, it’s worth trying
    out the resulting network as part of a full application with a realistic use case.
    It might be that the accuracy loss isn’t a problem, or that there are other issues
    that are more important and should be prioritized.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有时开玩笑说，唯一真正重要的度量标准是应用商店评分。我们的目标应该是生产让人们满意的产品，因此所有其他度量标准只是用户满意度的代理。由于训练环境总会存在数值差异，第一个挑战是了解它们是否影响产品体验。如果您从网络中获得的值毫无意义，这可能很明显，但如果它们与预期值仅有几个百分点的差异，值得尝试将生成的网络作为具有现实用例的完整应用程序的一部分。也许准确性损失不是问题，或者有其他更重要的问题应该优先考虑。
- en: Establish a Metric
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建立一个度量标准
- en: When you are sure that you have a real problem, it helps to quantify it. It
    can be tempting to pick a numerical measure, like the percentage difference in
    the output score vector from the expected result. This might not reflect the user
    experience very well, though. For example, if you’re doing image classification
    and all of the scores are 5% below what you’d expect, but the relative ordering
    of the results remains the same, the end result might be perfectly fine for many
    applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当您确定确实存在问题时，量化问题会有所帮助。可能会诱人选择一个数值度量，比如输出得分向量与期望结果之间的百分差异。然而，这可能并不很好地反映用户体验。例如，如果您正在进行图像分类，所有得分都比您期望的低5%，但结果的相对排序保持不变，那么最终结果对于许多应用程序可能是完全合适的。
- en: Instead, we recommend designing a metric that does reflect what the product
    needs. In the image classification case, you might pick what’s called a *top-one*
    score across a set of test images, because this will show how often the model
    picks the correct label. The top-one metric is how often the model picks the ground
    truth label as its highest-scoring prediction (*top-five* is similar, but covers
    how often the ground truth label is in the five highest-scoring predictions).
    You can then use the top-one metric to keep track of your progress and, importantly,
    get an idea of when the changes you’ve made are good enough.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们建议设计一个反映产品需求的度量标准。在图像分类案例中，您可能会选择所谓的*top-one*分数，跨一组测试图像，因为这将显示模型选择正确标签的频率。top-one度量标准是模型将地面真实标签选为最高得分预测的频率（*top-five*类似，但涵盖地面真实标签在五个最高得分预测中的频率）。然后，您可以使用top-one度量标准来跟踪您的进展，并且重要的是，了解您所做的更改何时足够好。
- en: You should also be careful to assemble a standard set of inputs that reflect
    what’s actually fed into the neural network processing, because as we discussed
    earlier, there are lots of ways that preprocessing can introduce errors.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应小心组装一组标准输入，以反映实际输入到神经网络处理的内容，因为正如我们之前讨论的，预处理可能会引入错误。
- en: Compare Against a Baseline
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与基准比较
- en: TensorFlow Lite for Microcontrollers was designed to have reference implementations
    for all of its functionality, and one of the reasons we did this was so that it’s
    possible to compare their results against optimized code to debug potential differences.
    Once you have some standard inputs, you should try running them through a desktop
    build of the framework, with no optimizations enabled so that the reference operator
    implementations are called. If you want a starting point for this kind of standalone
    test, take a look at [*micro_speech_test.cc*](https://oreil.ly/x5QYp). If you
    run your results through the metric you’ve established, you should see a score
    that you expect. If not, there might have been some error during the conversion
    process or something else might have gone wrong earlier in your workflow, so you’ll
    need to debug back into training to understand what the problem is.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite for Microcontrollers被设计为具有其所有功能的参考实现，我们这样做的原因之一是为了能够将它们的结果与优化代码进行比较，以调试潜在的差异。一旦您有了一些标准输入，您应该尝试通过桌面版本的框架运行它们，不启用任何优化，以便调用参考操作符实现。如果您想要这种独立测试的起点，请查看[micro_speech_test.cc](https://oreil.ly/x5QYp)。如果您将结果通过您建立的度量标准运行，您应该会看到您期望的分数。如果没有，可能在转换过程中出现了一些错误，或者在您的工作流程中的早期阶段出现了其他问题，因此您需要调试回到训练阶段以了解问题所在。
- en: If you do see good results using the reference code, you should then try building
    and running the same test on your target platform with all optimizations enabled.
    It might not be as simple as this, of course, since often embedded devices don’t
    have the memory to hold all the input data, and outputting the results can be
    tricky if all you have is a debug logging connection. It’s worth persevering,
    though, even if you must break your test up into multiple runs. When you have
    the results, run them through your metric to understand what the deficit actually
    is.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您看到使用参考代码获得了良好的结果，那么您应该尝试在目标平台上启用所有优化构建并运行相同的测试。当然，这可能并不像这么简单，因为通常嵌入式设备没有足够的内存来保存所有输入数据，如果您只有调试日志连接，输出结果可能会很棘手。然而，值得坚持，即使您必须将测试分成多次运行。当您获得结果时，请通过您的度量标准运行它们，以了解实际的差距是什么。
- en: Swap Out Implementations
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换实现
- en: Many platforms will enable optimizations by default, given that the reference
    implementations may take so long to run on an embedded device that they’re practically
    unusable. There are lots of ways to disable these optimizations, but we find the
    simplest is often just to find all the kernel implementations that are currently
    being used, usually in subfolders of [*tensorflow/lite/micro/kernels*](https://oreil.ly/k3lln),
    and overwrite them with the reference versions that are in that parent directory
    (making sure you have backups of the files you’re replacing). As a first step,
    replace all of the optimized implementations and rerun the on-device tests, to
    ensure that you do see the better score that you’d expect.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 许多平台默认启用优化，因为参考实现在嵌入式设备上运行时间太长，实际上无法使用。有很多方法可以禁用这些优化，但我们发现最简单的方法通常是找到当前正在使用的所有内核实现，通常在[tensorflow/lite/micro/kernels](https://oreil.ly/k3lln)的子文件夹中，并用该父目录中的参考版本覆盖它们（确保您备份要替换的文件）。作为第一步，替换所有优化实现并重新运行设备上的测试，以确保您看到您期望的更好分数。
- en: After you’ve done this wholesale replacement, try just overwriting half of the
    optimized kernels and see how that affects the metric. In most cases you’ll be
    able to use a binary search approach to determine which optimized kernel implementation
    is causing the biggest drop in the score. Once you have narrowed it down to a
    particular optimized kernel, you should then be able to create a minimal reproducible
    case by capturing the input values for one of the *bad* runs and the expected
    output values for those inputs from the reference implementation. The easiest
    way to do this is by debug logging from within the kernel implementation during
    one of the test runs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行全面替换之后，尝试仅覆盖一半的优化内核，看看这如何影响度量标准。在大多数情况下，您可以使用二分搜索方法确定哪个优化内核实现导致分数最大下降。一旦您将其缩小到特定的优化内核，然后应该能够通过捕获*坏*运行之一的输入值和来自参考实现的这些输入的预期输出值来创建一个最小可重现案例。在测试运行期间从内核实现中进行调试日志记录是最简单的方法。
- en: Now that you have a reproducible case, you should be able to create a unit test
    out of it. You can look at [one of the standard kernel tests](https://oreil.ly/0rnPW)
    to get started, and either create a new standalone test or add it to the existing
    file for that kernel. That then gives you a tool that you can use to communicate
    the issue to the team responsible for the optimized implementation, because you’ll
    be able to show that there’s a difference in the results from their code and the
    reference version, and that it affects your application. That same test can then
    also be added to the main code base if you contribute it back, and ensure that
    no other optimized implementations cause the same problem. It’s also a great tool
    for debugging an implementation yourself, because you can experiment with the
    code in isolation and iterate quickly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有了一个可重现的案例，您应该能够从中创建一个单元测试。您可以查看[标准内核测试之一](https://oreil.ly/0rnPW)以开始，并创建一个新的独立测试，或将其添加到该内核的现有文件中。这样，您就可以使用这个工具将问题传达给负责优化实现的团队，因为您将能够展示他们的代码和参考版本之间存在差异，并且这影响了您的应用程序。如果您将其贡献回去，同样的测试也可以添加到主代码库中，并确保没有其他优化实现会导致相同的问题。这也是一个很好的用于自行调试实现的工具，因为您可以在隔离的代码中进行实验并快速迭代。
- en: Mysterious Crashes and Hangs
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神秘的崩溃和卡顿
- en: One of the most difficult situations to fix on an embedded system is when your
    program doesn’t run, but there’s no obvious logging output or error to explain
    what went wrong. The easiest way to understand the problem is to attach a debugger
    (like GDB) and either look at a stack trace if it’s hung or step through your
    code to see where execution goes wrong. It’s not always easy to set up a debugger,
    though, or the source of the problem may still not be clear after using one, so
    there are some other techniques you can try.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入式系统中最难修复的情况之一是当你的程序无法运行，但没有明显的日志输出或错误来解释出了什么问题。理解问题的最简单方法是连接调试器（如GDB），然后查看堆栈跟踪（如果挂起）或逐步执行代码，看看执行出了问题的地方。然而，设置调试器并不总是容易的，或者即使使用调试器后问题的根源仍然不明确，所以还有一些其他技术可以尝试。
- en: Desktop Debugging
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 桌面调试
- en: Full operating systems like Linux, macOS, and Windows all have extensive debugging
    tools and error reporting mechanisms, so if at all possible try to keep your program
    portable to one of those platforms, even if you have to stub out some of the hardware-specific
    functionality with dummy implementations. This is how TensorFlow Lite for Microcontrollers
    is designed, and it means that we can first try to reproduce anything that’s going
    wrong on our Linux machines. If the same error occurs in this environment, it’s
    usually much easier and faster to track down using standard tooling, and without
    having to flash devices, speeding up iterations. Even if it would be too difficult
    to maintain your full application as a desktop build, at least see whether you
    can create unit and integration tests for your modules that do compile on a desktop.
    Then you can try giving them similar inputs to those in the situation you’re seeing
    a problem with and discover whether this also causes a similar error.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 像Linux、macOS和Windows这样的完整操作系统都有广泛的调试工具和错误报告机制，所以如果可能的话，尽量保持你的程序可以在这些平台之一上运行，即使你需要用虚拟实现替换一些硬件特定功能。这就是TensorFlow
    Lite for Microcontrollers的设计方式，这意味着我们可以首先尝试在我们的Linux机器上重现任何出现问题的情况。如果在这个环境中发生了相同的错误，通常使用标准工具进行跟踪会更容易更快速，而且无需刷写设备，加快迭代速度。即使维护整个应用程序作为桌面构建太困难，至少看看是否可以为你的模块创建可以在桌面上编译的单元测试和集成测试。然后你可以尝试给它们提供与你遇到问题的情况类似的输入，看看是否也会导致类似的错误。
- en: Log Tracing
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志追踪
- en: The only platform-specific functionality that TensorFlow Lite for Microcontrollers
    requires is an implementation of `DebugLog()`. We have this requirement because
    it’s such an essential tool for understanding what’s going on during development,
    even though it’s not something you need for production deployments. In an ideal
    world, any crashes or program errors should trigger log output—for example, our
    bare-metal support for STM32 devices has a [fault handler](https://oreil.ly/dsHG8)
    that does this)—but that’s not always feasible.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite for Microcontrollers唯一需要的平台特定功能是`DebugLog()`的实现。我们有这个要求是因为在开发过程中理解发生了什么是如此重要，即使在生产部署中并不需要。在理想的情况下，任何崩溃或程序错误都应该触发日志输出，例如，我们为STM32设备提供的裸机支持有一个[故障处理程序](https://oreil.ly/dsHG8)来实现这一点，但这并不总是可行的。
- en: 'You should always be able to inject log statements into the code yourself,
    though. These don’t need to be meaningful, just statements of what location in
    the code has been reached. You can even define an automatic trace macro, like
    this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该始终能够自己向代码中注入日志语句。这些语句不需要有意义，只需要说明代码中的位置。你甚至可以定义一个自动跟踪宏，就像这样：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then use it in your code like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在你的代码中像这样使用它：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You should see output in your debug console showing how far the code managed
    to go. It’s usually best to start with the highest level of your code and then
    see where the logging stops. That will give you an idea of the rough area where
    the crash or hang is happening, and then you can add more `TRACE` statements to
    narrow down exactly where the problem is occurring.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在调试控制台中看到输出，显示代码执行到了哪个位置。通常最好从代码的最高级别开始，然后看看日志停在哪里。这将让你大致了解崩溃或挂起发生的区域，然后你可以添加更多的`TRACE`语句来进一步确定问题发生的具体位置。
- en: Shotgun Debugging
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 散弹式调试
- en: 'Sometimes tracing doesn’t give you enough information about what’s going wrong,
    or the problem might occur only in an environment in which you don’t have access
    to logs, like production. In those cases, we recommend what’s sometimes called
    “shotgun debugging.” This is similar to the “shotgun profiling” we covered in
    [Chapter 15](ch15.xhtml#optimizing_latency), and it’s as simple as commenting
    out parts of your code and seeing whether the error still occurs. If you start
    at the top level of your application and work your way down, you can usually do
    the equivalent of a binary search to isolate which lines of code are causing the
    issue. For example, you might start with something like this in your main loop:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候追踪并不能提供足够的信息来解释出现问题的原因，或者问题可能只会在你无法访问日志的环境中发生，比如生产环境。在这种情况下，我们建议使用所谓的“散弹式调试”。这类似于我们在第15章中介绍的“散弹式性能分析”，只需要注释掉代码的部分部分，看看错误是否仍然发生。如果你从应用程序的顶层开始，逐步向下工作，通常可以做到类似于二分查找的方式来确定哪些代码行导致了问题。例如，你可以从主循环中的某些内容开始：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If this runs successfully with `DoSomething()` commented out, you know that
    the problem is happening within that function. You can then uncomment it and recursively
    do the same within its body to focus in on the misbehaving code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用注释掉`DoSomething()`成功运行，那么你就知道问题发生在该函数内部。然后你可以取消注释，并递归地在其内部执行相同的操作，以便集中关注出现问题的代码。
- en: Memory Corruption
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存损坏
- en: The most painful errors are caused by values in memory being accidentally overwritten.
    Embedded systems don’t have the same hardware to protect against this that desktop
    or mobile CPUs do, so these can be particularly challenging to debug. Even tracing
    or commenting out code can produce confusing results, because the overwriting
    can occur long before the code that uses the corrupted values runs, so crashes
    can be a long way from their cause. They might even depend on sensor input or
    hardware timings, making issues intermittent and maddeningly hard to reproduce.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最痛苦的错误是由于内存中的值被意外覆盖而引起的。嵌入式系统没有与台式机或移动CPU相同的硬件来防止这种情况，因此这些问题可能特别难以调试。即使跟踪或注释掉代码也可能产生令人困惑的结果，因为覆盖可能发生在使用损坏值的代码运行之前很久，因此崩溃可能与其原因相距甚远。它们甚至可能依赖于传感器输入或硬件定时，使问题变得间歇性且难以复现。
- en: 'The number one cause of this in our experience is overrunning the program stack.
    This is where local variables are stored, and TensorFlow Lite for Microcontrollers
    uses these extensively for comparatively large objects; thus, it requires more
    space than is typical for many other embedded applications. The exact size you’ll
    need is not easy to ascertain, unfortunately. Often the biggest contributor is
    the memory arena you need to pass into `SimpleTensorAllocator`, which in [the
    examples](https://oreil.ly/Pb9Pa) is allocated as a local array:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的经验中，导致这种情况的头号原因是超出程序堆栈。这是存储本地变量的地方，而TensorFlow Lite for Microcontrollers广泛使用这些变量来存储相对较大的对象；因此，它需要比许多其他嵌入式应用程序更多的空间。不幸的是，确切的所需大小并不容易确定。通常，最大的贡献者是您需要传递给`SimpleTensorAllocator`的内存区域，该区域在示例中被分配为本地数组：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you are using the same approach, you’ll need to make sure the stack size
    is approximately the size of that arena, plus several kilobytes for miscellaneous
    variables used by the runtime. If your arena is held elsewhere (maybe as a global
    variable), you should need only a few kilobytes of stack. The exact amount of
    memory required depends on your architecture, the compiler, and the model you’re
    running, so unfortunately it’s not easy to give an exact value ahead of time.
    If you are seeing mysterious crashes, it’s worth increasing this value as much
    as you can to see whether that helps, though.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用相同的方法，您需要确保堆栈大小大约等于该区域的大小，再加上运行时使用的几千字节的杂项变量。如果您的区域存放在其他地方（可能作为全局变量），则您只需要几千字节的堆栈。所需的确切内存量取决于您的架构、编译器和正在运行的模型，因此不幸的是，事先很难给出确切的值。如果您遇到神秘的崩溃，值得尽可能增加此值，以查看是否有所帮助。
- en: If you’re still seeing problems, you should start by trying to establish what
    variable or area of memory is being overwritten. Hopefully this should be possible
    using the logging or code elimination approaches described earlier, narrowing
    down the issue to the read of a value that seems to have been corrupted. Once
    you know what variable or array entry is being clobbered, you can then write a
    variation on the `TRACE` macro that outputs the value of that memory location
    along with the file and line it’s been called from. You might need to do special
    tricks like storing the memory address in a global variable so that it’s accessible
    from deeper stack frames if it’s a local. Then, just like you would for tracking
    down a normal crash, you can `TRACE` out the contents of that location as you
    run through the program and attempt to identify which code is responsible for
    overwriting it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您仍然遇到问题，您应该首先尝试确定哪个变量或内存区域被覆盖。希望可以使用之前描述的日志记录或代码消除方法来实现这一点，将问题缩小到似乎已被损坏的值的读取。一旦您知道哪个变量或数组条目被破坏，您可以编写一个类似于`TRACE`宏的变体，该宏输出该内存位置的值以及调用它的文件和行。您可能需要执行特殊技巧，例如将内存地址存储在全局变量中，以便在本地时可以从更深的堆栈帧中访问。然后，就像您追踪普通崩溃一样，您可以在运行程序并尝试确定哪些代码负责覆盖它时，`TRACE`出该位置的内容。
- en: Wrapping Up
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Coming up with a solution when things work in a training environment but fail
    on a real device can be a long and frustrating process. In this chapter, we’ve
    given you a set of tools to try when you do find yourself stuck and spinning your
    wheels. Unfortunately there aren’t many shortcuts in debugging, but by methodically
    working through the problem using these approaches, we do have confidence that
    you can track down any embedded machine learning problems.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练环境中正常工作但在实际设备上失败时提出解决方案可能是一个漫长而令人沮丧的过程。在本章中，我们为您提供了一套工具，当您发现自己陷入困境并一筹莫展时，可以尝试使用这些方法。不幸的是，在调试中没有太多捷径，但通过使用这些方法系统地解决问题，我们确信您可以追踪到任何嵌入式机器学习问题。
- en: Once you’ve gotten one model working in a product, you’ll probably start to
    wonder about how you can adapt it or even create an entirely new model to tackle
    different issues. [Chapter 19](ch19.xhtml#ch19) discusses how you can transfer
    your own model from the TensorFlow training environment into the TensorFlow Lite
    inference engine.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在产品中使一个模型正常工作，您可能会开始思考如何调整它，甚至创建一个全新的模型来解决不同的问题。[第19章](ch19.xhtml#ch19)讨论了如何将您自己的模型从TensorFlow训练环境转移到TensorFlow
    Lite推断引擎中。
