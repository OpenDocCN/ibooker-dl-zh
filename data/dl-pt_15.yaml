- en: 14 End-to-end nodule analysis, and where to go next
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 端到端结节分析，以及接下来的步骤
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容包括
- en: Connecting segmentation and classification models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接分割和分类模型
- en: Fine-tuning a network for a new task
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为新任务微调网络
- en: Adding histograms and other metric types to TensorBoard
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将直方图和其他指标类型添加到TensorBoard
- en: Getting from overfitting to generalizing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从过拟合到泛化
- en: 'Over the past several chapters, we have built a decent number of systems that
    are important components of our project. We started loading our data, built and
    improved classifiers for nodule candidates, trained segmentation models to find
    those candidates, handled the support infrastructure needed to train and evaluate
    those models, and started saving the results of our training to disk. Now it’s
    time to unify the components we have into a cohesive whole, so that we may realize
    the full goal of our project: it’s time to automatically detect cancer.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几章中，我们已经构建了许多对我们的项目至关重要的系统。我们开始加载数据，构建和改进结节候选的分类器，训练分割模型以找到这些候选，处理训练和评估这些模型所需的支持基础设施，并开始将我们的训练结果保存到磁盘。现在是时候将我们拥有的组件统一起来，以便实现我们项目的完整目标：是时候自动检测癌症了。
- en: 14.1 Towards the finish line
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 迈向终点
- en: 'We can get a hint of the work remaining by looking at figure 14.1\. In step
    3 (grouping) we see that we still need to build the bridge between the segmentation
    model from chapter 13 and the classifier from chapter 12 that will tell us whether
    what the segmentation network found is, indeed, a nodule. On the right is step
    5 (nodule analysis and diagnosis), the last step to the overall goal: seeing whether
    a nodule is cancer. This is another classification task; but to learn something
    in the process, we’ll take a fresh angle at how to approach it by building on
    the nodule classifier we already have.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看图14.1我们可以得到剩余工作的一些线索。在第3步（分组）中，我们看到我们仍需要建立第13章的分割模型和第12章的分类器之间的桥梁，以确定分割网络找到的是否确实是结节。右侧是第5步（结节分析和诊断），整体目标的最后一步：查看结节是否为癌症。这是另一个分类任务；但为了在过程中学到一些东西，我们将通过借鉴我们已有的结节分类器来采取新的方法。
- en: '![](../Images/CH14_F01_Stevens2_GS.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F01_Stevens2_GS.png)'
- en: 'Figure 14.1 Our end-to-end lung cancer detection project, with a focus on this
    chapter’s topics: steps 3 and 5, grouping and nodule analysis'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 我们的端到端肺癌检测项目，重点关注本章的主题：第3步和第5步，分组和结节分析
- en: Of course, these brief descriptions and their simplified depiction in figure
    14.1 leave out a lot of detail. Let’s zoom in a little with figure 14.2 and see
    what we’ve got left to accomplish.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些简短的描述及其在图14.1中的简化描述遗漏了很多细节。让我们通过图14.2放大一下，看看我们还有哪些任务要完成。
- en: '![](../Images/CH14_F02_Stevens2_GS.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F02_Stevens2_GS.png)'
- en: Figure 14.2 A detailed look at the work remaining for our end-to-end project
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 一个关于我们端到端项目剩余工作的详细查看
- en: 'As you can see, three important tasks remain. Each item in the following list
    corresponds to a major line item from figure 14.2:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，还有三项重要任务。以下列表中的每一项对应于图14.2的一个主要项目：
- en: 'Generate nodule candidates. This is step 3 in the overall project. Three tasks
    go into this step:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成结节候选。这是整个项目的第3步。这一步骤包括三项任务：
- en: '*Segmentation* --The segmentation model from chapter 13 will predict if a given
    pixel is of interest: if we suspect it is part of a nodule. This will be done
    per 2D slice, and every 2D result will be stacked to form a 3D array of voxels
    containing nodule candidate predictions.'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分割* --第13章的分割模型将预测给定像素是否感兴趣：如果我们怀疑它是结节的一部分。这将在每个2D切片上完成，并且每个2D结果将被堆叠以形成包含结节候选预测的体素的3D数组。'
- en: '*Grouping* --We will group the voxels into nodule candidates by applying a
    threshold to the predictions, and then grouping connected regions of flagged voxels.'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分组* --我们将通过将预测应用于阈值来将体素分组为结节候选，然后将连接区域的标记体素分组。'
- en: '*Constructing sample tuples* --Each identified nodule candidate will be used
    to construct a sample tuple for classification. In particular, we need to produce
    the coordinates (index, row, column) of that nodule’s center.'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*构建样本元组* --每个识别的结节候选将用于构建一个用于分类的样本元组。特别是，我们需要生成该结节中心的坐标（索引、行、列）。'
- en: Once this is achieved, we will have an application that takes a raw CT scan
    from a patient and produces a list of detected nodule candidates. Producing such
    a list is the task in the LUNA challenge. If this project were to be used clinically
    (and we reemphasize that our project should not be!), this nodule list would be
    suitable for closer inspection by a doctor.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦实现了这一点，我们将拥有一个应用程序，该应用程序接收患者的原始CT扫描并生成检测到的结节候选列表。生成这样的列表是LUNA挑战的任务。如果这个项目被临床使用（我们再次强调我们的项目不应该被使用！），这个结节列表将适合由医生进行更仔细的检查。
- en: 'Classify nodules and malignancy. We’ll take the nodule candidates we just produced
    and pass them to the candidate classification step we implemented in chapter 12,
    and then perform malignancy detection on the candidates flagged as nodules:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对结节和恶性进行分类。我们将取出我们刚刚产生的结节候选并将其传递到我们在第12章实现的候选分类步骤，然后对被标记为结节的候选进行恶性检测：
- en: '*Nodule classification* --Each nodule candidate from segmentation and grouping
    will be classified as either nodule or non-nodule. Doing so will allow us to screen
    out the many normal anatomical structures flagged by our segmentation process.'
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*结节分类* --从分割和分组中得到的每个结节候选将被分类为结节或非结节。这样做将允许我们筛选出被我们的分割过程标记为许多正常解剖结构。'
- en: '*ROC/AUC metrics* --Before we can start our last classification step, we’ll
    define some new metrics for examining the performance of classification models,
    as well as establish a baseline metric against which to compare our malignancy
    classifiers.'
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ROC/AUC指标* --在我们开始最后的分类步骤之前，我们将定义一些用于检查分类模型性能的新指标，并建立一个基准指标，以便与我们的恶性分类器进行比较。'
- en: '*Fine-tuning the malignancy model* --Once our new metrics are in place, we
    will define a model specifically for classifying benign and malignant nodules,
    train it, and see how it performs. We will do the training by fine-tuning: a process
    that cuts out some of the weights of an existing model and replaces them with
    fresh values that we then adapt to our new task.'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*微调恶性模型* --一旦我们的新指标就位，我们将定义一个专门用于分类良性和恶性结节的模型，对其进行训练，并查看其表现。我们将通过微调进行训练：这个过程会剔除现有模型的一些权重，并用新值替换它们，然后我们将这些值调整到我们的新任务中。'
- en: 'At that point we will be within arm’s reach of our ultimate goal: to classify
    nodules into benign and malignant classes and then derive a diagnosis from the
    CT. Again, diagnosing lung cancer in the real world involves much more than staring
    at a CT scan, so our performing this diagnosis is more an experiment to see how
    far we can get using deep learning and imaging data alone.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 到那时，我们将离我们的最终目标不远了：将结节分类为良性和恶性类别，然后从CT中得出诊断。再次强调，在现实世界中诊断肺癌远不止盯着CT扫描，因此我们进行这种诊断更多是为了看看我们能够使用深度学习和成像数据单独走多远。
- en: End-to-end detection. Finally, we will put all of this together to get to the
    finish line, combining the components into an end-to-end solution that can look
    at a CT and answer the question “Are there malignant nodules present in the lungs?”
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 端到端检测。最后，我们将把所有这些组合起来，达到终点，将组件组合成一个端到端的解决方案，可以查看CT并回答问题“肺部是否存在恶性结节？”
- en: '*IRC* --We will segment our CT to get nodule candidate samples to classify.'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*IRC* --我们将对我们的CT进行分割，以获取结节候选样本进行分类。'
- en: '*Determine the nodules* --We will perform nodule classification on the candidate
    to determine whether it should be fed into the malignancy classifier.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定结节* --我们将对候选进行结节分类，以确定是否应将其输入恶性分类器。'
- en: '*Determine malignancy --*We will perform malignancy classification on the nodules
    that pass through the nodule classifier to determine whether the patient has cancer.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定恶性程度 --*我们将对通过结节分类器的结节进行恶性分类，以确定患者是否患癌症。'
- en: We’ve got a lot to do. To the finish line!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很多事情要做。冲刺终点！
- en: '*Note* As in the previous chapter, we will discuss the key concepts in detail
    in the text and leave out the code for repetitive, tedious, or obvious parts.
    Full details can be found in the book’s code repository.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 正如前一章中所述，我们将在文本中详细讨论关键概念，并略过重复、繁琐或显而易见的代码部分。完整的细节可以在书籍的代码存储库中找到。'
- en: 14.2 Independence of the validation set
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 验证集的独立性
- en: 'We are in danger of making a subtle but critical mistake, which we need to
    discuss and avoid: we have a potential leak from the training set to the validation
    set! For each of the segmentation and classification models, we took care of splitting
    the data into a training set and an independent validation set by taking every
    tenth example for validation and the remainder for training.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们面临着一个微妙但关键的错误的危险，我们需要讨论并避免：我们有一个潜在的从训练集到验证集的泄漏！对于分割和分类模型的每一个，我们都小心地将数据分割成一个训练集和一个独立的验证集，通过将每十个示例用于验证，其余用于训练。
- en: However, the split for the classification model was done on the list of nodules,
    and the split for the segmentation model was done on the list of CT scans. This
    means we likely have nodules from the segmentation validation set in the training
    set of the classification model and vice versa. We must avoid that! If left unfixed,
    this situation could lead to performance figures that would be artificially higher
    compared to what we would obtain on an independent dataset. This is called a *leak*,
    and it would invalidate our validation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，分类模型的分割是在结节列表上进行的，分割模型的分割是在CT扫描列表上进行的。这意味着我们很可能在分类模型的训练集中有来自分割验证集的结节，反之亦然。我们必须避免这种情况！如果不加以修正，这种情况可能导致性能指标人为地高于我们在独立数据集上获得的性能。这被称为*泄漏*，它将使我们的验证失效。
- en: To rectify this potential data leak, we need to rework the classification dataset
    to also work at the CT scan level, just as we did for the segmentation task in
    chapter 13\. Then we need to retrain the classification model with this new dataset.
    On the bright side, we didn’t save our classification model earlier, so we would
    have to retrain anyway.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纠正这种潜在的数据泄漏，我们需要重新设计分类数据集，以便像我们在第13章中为分割任务所做的那样也在CT扫描级别上工作。然后我们需要用这个新数据集重新训练分类模型。好消息是，我们之前没有保存我们的分类模型，所以我们无论如何都需要重新训练。
- en: Your takeaway from this should be to keep an eye on the end-to-end process when
    defining the validation set. Probably the easiest way to do this (and the way
    it is done for most important datasets) is to make the validation split as explicit
    as possible--for example, by having two separate directories for training and
    validation--and then stick to this split for your entire project. When you need
    to redo the split (for example, when you need to add stratification of the dataset
    split by some criterion), you need to retrain all of your models with the newly
    split dataset.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该从中得到的启示是在定义验证集时要注意整个端到端的过程。可能最简单的方法（也是对大多数重要数据集采用的方法）是尽可能明确地进行验证分割--例如，通过为训练和验证分别设置两个目录--然后在整个项目中坚持这种分割。当您需要重新分割时（例如，当您需要按某些标准对数据集进行分层时），您需要使用新分割的数据集重新训练所有模型。
- en: So what we did for you was to take `LunaDataset` from chapters 10-12 and copy
    over getting the candidate list and splitting it into test and validation datasets
    from `Luna2dSegmentationDataset` in chapter 13\. As this is very mechanical, and
    there is not much to learn from the details (you are a dataset pro by now), we
    won’t show the code in detail.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为您做的是从第10-12章的`LunaDataset`中复制候选列表，并从第13章的`Luna2dSegmentationDataset`中将其分割为测试和验证数据集。由于这是非常机械的，并且没有太多细节可供学习（您现在已经是数据集专家了），我们不会详细展示代码。
- en: We’ll retrain our classification model by rerunning the training for the classifier:[¹](#pgfId-1012275)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过重新运行分类器的训练来重新训练我们的分类模型：[¹](#pgfId-1012275)
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After 100 epochs, we achieve about 95% accuracy for positive samples and 99%
    for negative ones. As the validation loss isn’t seen to be trending upward again,
    we could train the model longer to see if things continued to improve.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 经过 100 个周期，我们对正样本的准确率达到约 95%，对负样本达到 99%。由于验证损失没有再次上升的趋势，我们可以继续训练模型以查看是否会继续改善。
- en: After 90 epochs, we reach the maximal F1 score and have 99.2% validation accuracy,
    albeit only 92.8% on the actual nodules. We’ll take this model, even though we
    might also try to trade a bit of overall accuracy for better accuracy on the malignant
    nodules (in between, the model got 95.4% accuracy on actual nodules for 98.9%
    total accuracy). This will be good enough for us, and we are ready to bridge the
    models.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 经过 90 个周期，我们达到了最大的 F1 分数，并且在验证准确率方面达到了 99.2%，尽管在实际结节上只有 92.8%。我们将采用这个模型，尽管我们可能也会尝试在恶性结节的准确率上稍微牺牲一些总体准确率（在此期间，模型在实际结节上的准确率为
    95.4%，总准确率为 98.9%）。这对我们来说已经足够了，我们准备连接这些模型。
- en: 14.3 Bridging CT segmentation and nodule candidate classification
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 连接 CT 分割和结节候选分类
- en: 'Now that we have a segmentation model saved from chapter 13 and a classification
    model we just trained in the previous section, figure 14.3, steps 1a, 1b, and
    1c show that we’re ready to work on writing the code that will convert our segmentation
    output into sample tuples. We are doing the *grouping*: finding the dashed outline
    around the highlight of step 1b in figure 14.3\. Our input is the *segmentation*:
    the voxels flagged by the segmentation model in 1a. We want to find 1c, the coordinates
    of the center of mass of each “lump” of flagged voxels: the index, row, and column
    of the 1b plus mark is what we need to provide in the list of sample tuples as
    output.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经从第 13 章保存了一个分割模型，并且在上一节刚刚训练了一个分类模型，图 14.3 的步骤 1a、1b 和 1c 显示我们已经准备好开始编写代码，将我们的分割输出转换为样本元组。我们正在进行*分组*：在图
    14.3 的步骤 1b 的高亮周围找到虚线轮廓。我们的输入是*分割*：由第 1a 中的分割模型标记的体素。我们想要找到 1c，即每个“块”中心的质心坐标：我们需要在样本元组列表中提供的是
    1b 加号标记的索引、行和列。
- en: '![](../Images/CH14_F03_Stevens2_GS.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F03_Stevens2_GS.png)'
- en: Figure 14.3 Our plan for this chapter, with a focus on grouping segmented voxels
    into nodule candidates
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3 我们本章的计划，重点是将分割的体素分组为结节候选
- en: Running the models will naturally look very similar to how we handled them during
    training and validation (validation in particular). The difference here is the
    loop over the CTs. For each CT, we segment *every* slice and then take all the
    segmented output as the input to grouping. The output from grouping will be fed
    into a nodule classifier, and the nodules that survive that classification will
    be fed into a malignancy classifier.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 运行模型时，其处理方式与我们在训练和验证（尤其是验证）期间处理它们的方式非常相似。这里的区别在于对 CT 进行循环。对于每个 CT，我们会分割*每个*切片，然后将所有分割输出作为分组的输入。分组的输出将被馈送到结节分类器中，通过该分类器幸存下来的结节将被馈送到恶性分类器中。
- en: This is accomplished by the following outer loop over the CTs, which for each
    CT segments, groups, classifies candidates, and provides the classifications for
    further processing.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对 CT 的外部循环，对每个 CT 进行分割、分组、分类候选，并提供分类以进行进一步处理。
- en: Listing 14.1 nodule_analysis.py:324, `NoduleAnalysisApp.main`
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.1 nodule_analysis.py:324，`NoduleAnalysisApp.main`
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Loops over the series UIDs
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 循环遍历系列 UID
- en: ❷ Gets the CT (step 1 in the big picture)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取 CT（大图中的步骤 1）
- en: ❸ Runs our segmentation model on it (step 2)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在其上运行我们的分割模型（步骤 2）
- en: ❹ Groups the flagged voxels in the output (step 3)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对输出中的标记体素进行分组（步骤 3）
- en: ❺ Runs our nodule classifier on them (step 4)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 在它们上运行我们的结节分类器（步骤 4）
- en: We’ll break down the `segmentCt`, `groupSegmentationOutput`, and `classifyCandidates`
    methods in the following sections.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下部分详细介绍`segmentCt`、`groupSegmentationOutput`和`classifyCandidates`方法。
- en: 14.3.1 Segmentation
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.1 分割
- en: First up, we are going to perform segmentation on every slice of the entire
    CT scan. As we need to feed a given patient’s CT slice by slice, we build a `Dataset`
    that loads a CT with a single `series_uid` and returns each slice, one per `__getitem__`
    call.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将对整个 CT 扫描的每个切片执行分割。由于我们需要逐个患者的 CT 逐个切片进行处理，我们构建一个`Dataset`，加载具有单个`series_uid`的
    CT 并返回每个切片，每次调用`__getitem__`。
- en: '*Note* The segmentation step in particular can take quite a while when executed
    on the CPU. Even though we gloss over it here, the code will use the GPU if available.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 特别是在 CPU 上执行时，分割步骤可能需要相当长的时间。尽管我们在这里只是简单提及，但代码将在可用时使用 GPU。'
- en: Other than the more expansive input, the main difference is what we do with
    the output. Recall that the output is an array of per-pixel probabilities (that
    is, in the range 0...1) that the given pixel is part of a nodule. While iterating
    over the slices, we collect the slice-wise predictions in a mask array that has
    the same shape as our CT input. Afterward, we threshold the predictions to get
    a binary array. We will use a threshold of 0.5, but if we wanted to, we could
    experiment with thresholding to trade getting more true positives for an increase
    in false positives.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了更广泛的输入之外，主要区别在于我们如何处理输出。回想一下，输出是每个像素的概率数组（即在 0...1 范围内），表示给定像素是否属于结节。在遍历切片时，我们在一个与我们的
    CT 输入形状相同的掩模数组中收集切片预测。之后，我们对预测进行阈值处理以获得二进制数组。我们将使用 0.5 的阈值，但如果需要，我们可以尝试不同的阈值来在增加假阳性的情况下获得更多真阳性。
- en: We also include a small cleanup step using the erosion operation from `scipy.ndimage.morphology`.
    It deletes one layer of boundary voxels and only keeps the inner ones--those for
    which all eight neighboring voxels in the axis direction are also flagged. This
    makes the flagged area smaller and causes very small components (smaller than
    3 × 3 × 3 voxels) to vanish. Put together with the loop over the data loader,
    which we instruct to feed us all slices from a single CT, we have the following.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还包括一个使用 `scipy.ndimage.morphology` 中的腐蚀操作进行小的清理步骤。它删除一个边��体素层，仅保留内部体素——那些所有八个相邻体素在轴方向上也被标记的体素。这使得标记区域变小，并导致非常小的组件（小于
    3 × 3 × 3 体素）消失。结合数据加载器的循环，我们指示它向我们提供来自单个 CT 的所有切片，我们有以下内容。
- en: Listing 14.2 nodule_analysis.py:384, `.segmentCt`
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.2 nodule_analysis.py:384, `.segmentCt`
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ We do not need gradients here, so we don’t build the graph.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们这里不需要梯度，所以我们不构建图。
- en: '❷ This array will hold our output: a float array of probability annotations.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 这个数组将保存我们的输出：一个概率注释的浮点数组。
- en: ❸ We get a data loader that lets us loop over our CT in batches.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们获得一个数据加载器，让我们可以按批次循环遍历我们的 CT。
- en: ❹ After moving the input to the GPU ...
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将输入移动到 GPU 后...
- en: ❺ ... we run the segmentation model ...
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ ... 我们运行分割模型 ...
- en: ❻ ... and copy each element to the output array.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ ... 并将每个元素复制到输出数组中。
- en: ❼ Thresholds the probability outputs to get a binary output, and then applies
    binary erosion as cleanup
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 将概率输出阈值化以获得二进制输出，然后应用二进制腐蚀进行清理
- en: This was easy enough, but now we need to invent the grouping.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经足够简单了，但现在我们需要发明分组。
- en: 14.3.2 Grouping voxels into nodule candidates
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.2 将体素分组为结节候选
- en: We are going to use a simple connected-components algorithm for grouping our
    suspected nodule voxels into chunks to feed into classification. This grouping
    approach labels connected components, which we will accomplish using `scipy.ndimage
    .measurements.label`. The `label` function will take all nonzero pixels that share
    an edge with another nonzero pixel and mark them as belonging to the same group.
    Since our output from the segmentation model has mostly blobs of highly adjacent
    pixels, this approach matches our data well.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个简单的连通分量算法将我们怀疑的结节体素分组成块以输入分类。这种分组方法标记连接的组件，我们将使用 `scipy.ndimage.measurements.label`
    完成。`label` 函数将获取所有与另一个非零像素共享边缘的非零像素，并将它们标记为属于同一组。由于我们从分割模型输出的大部分都是高度相邻像素的块，这种方法很好地匹配了我们的数据。
- en: Listing 14.3 nodule_analysis.py:401
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.3 nodule_analysis.py:401
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Assigns each voxel the label of the group it belongs to
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为每个体素分配所属组的标签
- en: ❷ Gets the center of mass for each group as index, row, column coordinates
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取每个组的质心作为索引、行、列坐标
- en: The output array `candidateLabel_a` is the same shape as `clean_a`, which we
    used for input, but it has 0 where the background voxels are, and increasing integer
    labels 1, 2, ..., with one number for each of the connected blobs of voxels making
    up a nodule candidate. Note that the labels here are *not* the same as labels
    in a classification sense! These are just saying “This blob of voxels is blob
    1, this blob over here is blob 2, and so on.”
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出数组 `candidateLabel_a` 与我们用于输入的 `clean_a` 具有相同的形状，但在背景体素处为 0，并且递增的整数标签 1、2、...，每个连接的体素块组成一个结节候选。请注意，这里的标签
    *不* 是分类意义上的标签！这只是在说“这个体素块是体素块 1，这边的体素块是体素块 2，依此类推”。
- en: 'SciPy also sports a function to get the centers of mass of the nodule candidates:
    `scipy.ndimage.measurements.center_of_mass`. It takes an array with per-voxel
    densities, the integer labels from the `label` function we just called, and a
    list of which of those labels need to have a center calculated. To match the function’s
    expectation that the mass is non-negative, we offset the (clipped) `ct.hu_a` by
    1,001\. Note that this leads to all flagged voxels carrying some weight, since
    we clamped the lowest air value to -1,000 HU in the native CT units.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy 还提供了一个函数来获取结节候选的质心：`scipy.ndimage.measurements.center_of_mass`。它接受一个每个体素密度的数组，刚刚调用的
    `label` 函数返回的整数标签，以及需要计算质心的这些标签的列表。为了匹配函数期望的质量为非负数，我们将（截取的）`ct.hu_a` 偏移了 1,001。请注意，这导致所有标记的体素都携带一些权重，因为我们将最低的空气值在本机
    CT 单位中夹紧到 -1,000 HU。
- en: Listing 14.4 nodule_analysis.py:409
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.4 nodule_analysis.py:409
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Converts the voxel coordinates to real patient coordinates
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将体素坐标转换为真实患者坐标
- en: ❷ Builds our candidate info tuple and appends it to the list of detections
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建我们的候选信息元组并将其附加到检测列表中
- en: As output, we get a list of three arrays (one each for the index, row, and column)
    the same length as our `candidate_count`. We can use this data to populate a list
    of `candidateInfo_tup` instances; we have grown attached to this little data structure,
    so we stick our results into the same kind of list we’ve been using since chapter
    10\. As we don’t really have suitable data for the first four values (`isNodule_bool`,
    `hasAnnotation_bool`, `isMal_bool`, and `diameter_mm`), we insert placeholder
    values of a suitable type. We then convert our coordinates from voxels to physical
    coordinates in a loop, creating the list. It might seem a bit silly to move our
    coordinates away from our array-based index, row, and column, but all of the code
    that consumes `candidateInfo_tup` instances expects `center_xyz`, not `center_irc`.
    We’d get wildly wrong results if we tried to swap one for the other!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作为输出，我们得到一个包含三个数组的列表（分别为索引、行和列），与我们的 `candidate_count` 长度相同。我们可以使用这些数据来填充一个
    `candidateInfo_tup` 实例的列表；我们已经对这种小数据结构产生了依恋，所以我们将结果放入自从第 10 章以来一直在使用的相同类型的列表中。由于我们实际上没有适合的数据来填充前四个值（`isNodule_bool`、`hasAnnotation_bool`、`isMal_bool`
    和 `diameter_mm`），我们插入了适当类型的占位符值。然后我们在循环中将我们的坐标从体素转换为物理坐标，创建列表。将我们的坐标从基于数组的索引、行和列移开可能看起来有点愚蠢，但所有消耗
    `candidateInfo_tup` 实例的代码都期望 `center_xyz`，而不是 `center_irc`。如果我们尝试互换一个和另一个，我们将得到极其错误的结果！
- en: Yay--we’ve conquered step 3, getting nodule locations from the voxel-wise detections!
    We can now crop out the suspected nodules and feed them to our classifier to weed
    out some more false positives.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 耶--我们征服了第3步，从体素级别的检测中获取结节位置！现在我们可以裁剪出疑似结节，并将它们馈送给我们的分类器，以进一步消除一些假阳性。
- en: 14.3.3 Did we find a nodule? Classification to reduce false positives
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.3 我们找到了结节吗？分类以减少假阳性
- en: 'As we started part 2 of this book, we described the job of a radiologist looking
    through CT scans for signs of cancer thus:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始本书的第2部分时，我们描述了放射科医生查看CT扫描以寻找癌症迹象的工作如下：
- en: Currently, the work of reviewing the data must be performed by highly trained
    specialists, requires painstaking attention to detail, and it is dominated by
    cases where no cancer exists.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，审查数据的工作必须由经过高度训练的专家执行，需要对细节进行仔细的注意，主要是在不存在癌症的情况下。
- en: Doing that job well is akin to being placed in front of 100 haystacks and being
    told, “Determine which of these, if any, contain a needle.”
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 做好这项工作就像被放在100堆草垛前，并被告知：“确定这些草垛中是否有针。”
- en: We’ve spent time and energy discussing the proverbial needles; let’s discuss
    the hay for a moment by looking at figure 14.4\. Our job, so to speak, is to fork
    away as much hay as we can from in front of our glassy-eyed radiologist, so that
    they can refocus their highly trained attention where it can do the most good.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花费了时间和精力讨论谚语中的针；让我们通过查看图14.4来讨论一下草垛。我们的工作，可以说，就是尽可能多地从我们那位眼睛发直的放射科医生面前的草垛中分离出来，这样他们就可以重新聚焦他们经过高度训练的注意力，以便发挥最大的作用。
- en: '![](../Images/CH14_F04_Stevens2_GS.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F04_Stevens2_GS.png)'
- en: Figure 14.4 The steps of our end-to-end detection project, and the rough order
    of magnitude of data removed at each step
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 我们端到端检测项目的步骤，以及每个步骤删除的数据的数量级。
- en: Let’s look at how much we are discarding at each step while we perform our end-to-end
    diagnosis. The arrows in figure 14.4 show the data as it flows from the raw CT
    voxels through our project to our final malignancy determination. Each arrow that
    ends with an X indicates a swath of data discarded by the previous step; the arrow
    pointing to the next step represents the data that survived the culling. Note
    that the numbers here are *very* approximate.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在执行端到端诊断时每个步骤丢弃了多少数据。图14.4中的箭头显示了数据从原始CT体素流经我们的项目到最终恶性确定的过程。以X结尾的每个箭头表示上一步丢弃的一部分数据；指向下一步的箭头代表经过筛选幸存下来的数据。请注意，这里的数字是*非常*近似的。
- en: 'Let’s go through the steps in figure 14.4 in more detail:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看一下图14.4中的步骤：
- en: '*Segmentation* --Segmentation starts with the entire CT: hundreds of slices,
    or about 33 million (225) voxels (give or take quite a lot). About 220 voxels
    are flagged as being of interest; this is orders of magnitude smaller than the
    total input, which means we’re throwing out 97% of the voxels (that’s the 225
    on the left leading to the X).'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分割* --分割从整个CT开始：数百张切片，或大约3300万（225）体素（加减很多）。大约有220个体素被标记为感兴趣的；这比总输入要小几个数量级，这意味着我们要丢弃97%的体素（这是左边导致X的225）。'
- en: '*Grouping*. While grouping doesn’t remove anything explicitly, it does reduce
    the number of items we’re considering, since we consolidate voxels into nodule
    candidates. The grouping produces about 1,000 candidates (210) from 1 million
    voxels. A nodule of 16 × 16 × 2 voxels would have a total of 210 voxels.[²](#pgfId-1014021)'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分组*。虽然分组并没有明确删除任何内容，但它确实减少了我们考虑的项目数量，因为我们将体素合并为结节候选者。分组从100万体素中产生了大约1000个候选者（210）。一个16×16×2体素的结节将有总共210个体素。[²](#pgfId-1014021)'
- en: '*Nodule classification*. This process throws away the majority of the remaining
    ~210 items. From our thousands of nodule candidates, we’re left with tens of nodules:
    about 25.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*结节分类*。这个过程丢弃了剩下的大多数~210个项目。从我们成千上万的结节候选者中，我们剩下了数十个结节：大约25个。'
- en: '*Malignant classification*. Finally, the malignancy classifier takes tens of
    nodules (25) and finds the one or two (21) that are cancer.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*恶性分类*。最后，恶性分类器会取出数十个结节（25个），找出其中一个或两个（21个）是癌症的。'
- en: Each step along the way allows us to discard a huge amount of data that our
    model is confident is irrelevant to our cancer-detection goal. We went from millions
    of data points to a handful of tumors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 沿途的每一步都允许我们丢弃大量数���，我们的模型确信这些数据与我们的癌症检测目标无关。我们从数百万数据点到少数肿瘤。
- en: Fully automated vs. assistive systems
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 完全自动化与辅助系统
- en: There is a difference between a fully automated system and one that is designed
    to augment a human’s abilities. For our automated system, once a piece of data
    is flagged as irrelevant, it is gone forever. When presenting data for a human
    to consume, however, we should allow them to peel back some of the layers and
    look at the near misses, as well as annotate our findings with a degree of confidence.
    Were we designing a system for clinical use, we’d need to carefully consider our
    exact intended use and make sure our system design supported those use cases well.
    Since our project is fully automated, we can move forward without having to consider
    how best to surface the near misses and the unsure answers.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 完全自动化系统和旨在增强人类能力的系统之间存在差异。对于我们的自动化系统，一旦一条数据被标记为无关紧要，它就永远消失了。然而，当向人类呈现数据供其消化时，我们应该允许他们剥开一些层次，查看近似情况，并用一定的信心程度注释我们的发现。如果我们设计一个用于临床使用的系统，我们需要仔细考虑我们确切的预期用途，并确保我们的系统设计能够很好地支持这些用例。由于我们的项目是完全自动化的，我们可以继续前进，而不必考虑如何最好地展示近似情况和不确定的答案。
- en: Now that we have identified regions in the image that our segmentation model
    considers probable candidates, we need to crop these candidates from the CT and
    feed them into the classification module. Happily, we have `candidateInfo_list`
    from the previous section, so all we need to do is make a `DataSet` from it, put
    it into a `DataLoader`, and iterate over it. Column 1 of the probability predictions
    is the predicted probability that this is a nodule and is what we want to keep.
    Just as before, we collect the output from the entire loop.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了图像中我们的分割模型认为是潜在候选的区域，我们需要从 CT 中裁剪这些候选并将它们馈送到分类模块中。幸运的是，我们有前一节的 `candidateInfo_list`，所以我们只需要从中创建一个
    `DataSet`，将其放入 `DataLoader`，并对其进行迭代。概率预测的第一列是预测的这是一个结节的概率，这是我们想要保留的。就像以前一样，我们收集整个循环的输出。
- en: Listing 14.5 nodule_analysis.py:357, `.classifyCandidates`
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.5 结节分析.py:357，`.classifyCandidates`
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Again, we get a data loader to loop over, this time based on our candidate
    list.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 再次，我们获得一个数据加载器来循环遍历，这次是基于我们的候选列表。
- en: ❷ Sends the inputs to the device
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将输入发送到设备
- en: ❸ Runs the inputs through the nodule vs. non-nodule network
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将输入通过结节与非结节网络运行
- en: ❹ If we have a malignancy model, we run that, too.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 如果我们有一个恶性模型，我们也运行它。
- en: ❺ Does our bookkeeping, constructing a list of our results
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 进行我们的簿记，构���我们结果的列表
- en: 'This is great! We can now threshold the output probabilities to get a list
    of things our model thinks are actual nodules. In a practical setting, we would
    probably want to output them for a radiologist to inspect. Again, we might want
    to adjust the threshold to err a bit on the safe side: that is, if our threshold
    was 0.3 instead of 0.5, we would present a few more candidates that turn out not
    to be nodules, while reducing the risk of missing actual nodules.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这太棒了！我们现在可以将输出概率阈值化，得到我们的模型认为是实际结节的列表。在实际设置中，我们可能希望将它们输出供放射科医生检查。同样，我们可能希望调整阈值以更安全地出错一点：也就是说，如果我们的阈值是
    0.3 而不是 0.5，我们将呈现更多的候选，结果证明不是结节，同时减少错过实际结节的风险。
- en: Listing 14.6 nodule_analysis.py:333, `NoduleAnalysisApp.main`
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.6 结节分析.py:333，`NoduleAnalysisApp.main`
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ If we don’t pass run_validation, we print individual information ...
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果我们不通过运行验证，我们打印单独的信息...
- en: ❷ ... for all candidates found by the segmentation where the classifier assigned
    a nodule probability of 50% or more.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ ... 对于分割找到的所有候选，其中分类器分配的结节概率为 50% 或更高。
- en: ❸ If we have the ground truth data, we compute and print the confusion matrix
    and also add the current results to the total.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果我们有真实数据，我们计算并打印混淆矩阵，并将当前结果添加到总数中。
- en: Let’s run this for a given CT from the validation set:[³](#pgfId-1014840)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们针对验证集中的给定 CT 运行这个：[³](#pgfId-1014840)
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ This candidate is assigned a 53% probability of being malignant, so it barely
    makes the probability threshold of 50%. The malignancy classification assigns
    a very low (3%) probability.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这个候选被分配了 53% 的恶性概率，所以它勉强达到了 50% 的概率阈值。恶性分类分配了一个非常低（3%）的概率。
- en: ❷ Detected as a nodule with very high confidence and assigned a 42% probability
    of malignancy
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 被检测为结节，具有非常高的置信度，并被分配了 42% 的恶性概率
- en: 'The script found 16 nodule candidates in total. Since we’re using our validation
    set, we have a full set of annotations and malignancy information for each CT,
    which we can use to create a confusion matrix with our results. The rows are the
    truth (as defined by the annotations), and the columns show how our project handled
    each case:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本总共找到了 16 个结节候选。由于我们正在使用验证集，我们对每个 CT 都有完整的注释和恶性信息，我们可以使用这些信息创建一个混淆矩阵来展示我们的结果。行是真相（由注释定义），列显示我们的项目如何处理每种情况：
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Scan ID
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 扫描 ID
- en: '❷ Prognosis: Complete Miss means the segmentation didn’t find a nodule, Filtered
    Out is the classifier’s work, and Predicted Nodules are those it marked as nodules.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 预后：完全未检出表示分割未找到结节，被过滤掉是分类器的工作，预测结节是它标记为结节的。
- en: ❸ The rows contain the ground truth.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 行包含了真相。
- en: The Complete Miss column is when our segmenter did not flag a nodule at all.
    Since the segmenter was not trying to flag non-nodules, we leave that cell blank.
    Our segmenter was trained to have high recall, so there are a large number of
    non-nodules, but our nodule classifier is well equipped to screen those out.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 完全未检出列是当我们的分割器根本没有标记结节时。由于分割器并不试图标记非结节，我们将该单元格留空。我们的分割器经过训练具有很高的召回率，因此有大量的非结节，但我们的结节分类器很擅长筛选它们。
- en: So we found the 1 malignant nodule in this scan, but missed a 17th benign one.
    In addition, 15 false positive non-nodules made it through the nodule classifier.
    The filtering by the classifier brought the false positives down from over 1,000!
    As we saw earlier, 1,088 is about O(210), so that lines up with what we expect.
    Similarly, 15 is about O(24), which isn’t far from the O(25) we ballparked.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在这个扫描中找到了 1 个恶性结节，但漏掉了第 17 个良性结节。此外，有 15 个误报的非结节通过了结节分类器。分类器的过滤将误报降至 1,000
    多个！正如我们之前看到的，1,088 大约是 O(210)，所以这符合我们的预期。同样，15 大约是 O(24)，这与我们估计的 O(25) 差不多。
- en: Cool! But what’s the larger picture?
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒！但更大的画面是什么？
- en: 14.4 Quantitative validation
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 定量验证
- en: 'Now that we have anecdotal evidence that the thing we built might be working
    on one case, let’s take a look at the performance of our model on the entire validation
    set. Doing so is simple: we run our validation set through the previous prediction
    and check how many nodules we get, how many we miss, and how many candidates are
    erroneously identified as nodules.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一些个案证据表明我们建立的东西可能在一个案例上起作用，让我们看看我们的模型在整个验证集上的表现。这样做很简单：我们将我们的验证集通过之前的预测运行，检查我们得到了多少结节，漏掉了多少，以及多少候选被错误地识别为结节。
- en: 'We run the following, which should take half an hour to an hour when run on
    the GPU. After coffee (or a full-blown nap), here is what we get:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行以下内容，如果在 GPU 上运行，应该需要半小时到一个小时。喝完咖啡（或者睡个好觉）后，这是我们得到的结果：
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We detected 132 of the 154 nodules, or 85%. Of the 22 we missed, 13 were not
    considered candidates by the segmentation, so this would be the obvious starting
    point for improvements.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检测到了154个结节中的132个，或者85%。我们错过的22个中，有13个未被分割认为是候选结节，因此这将是改进的明显起点。
- en: About 95% of the detected nodules are false positives. This is of course not
    great; on the other hand, it’s a lot less critical--having to look at 20 nodule
    candidates to find one nodule will be much easier than looking at the entire CT.
    We will go into this in more detail in section 14.7.2, but we want to stress that
    rather than treating these mistakes as a black box, it’s a good idea to investigate
    the misclassified cases and see if they have commonalities. Are there characteristics
    that differentiate them from the samples that were correctly classified? Can we
    find anything that could be used to improve our performance?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 大约95%的检测到的结节是假阳性。这当然不是很好；另一方面，这并不是很关键--不得不查看20个结节候选才能找到一个结节要比查看整个CT要容易得多。我们将在第14.7.2节中更详细地讨论这一点，但我们要强调的是，与其将这些错误视为黑匣子，不如调查被错误分类的情况并看看它们是否有共同点。有什么特征可以将它们与被正确分类的样本区分开吗？我们能找到什么可以用来改善我们表现的东西吗？
- en: 'For now, we’re going to accept our numbers as is: not bad, but not perfect.
    The exact numbers may differ when you run your self-trained model. Toward the
    end of this chapter, we will provide some pointers to papers and techniques that
    can help improve these numbers. With inspiration and some experimentation, we
    are confident that you can achieve better scores than we show here.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将接受我们的数字如此：不错，但并非完美。当您运行自己训练的模型时，确切的数字可能会有所不同。在本章末尾，我们将提供一些指向可以帮助改善这些数字的论文和技术。通过灵感和一些实验，我们确信您可以获得比我们在这里展示的更好的分数。
- en: 14.5 Predicting malignancy
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 预测恶性
- en: 'Now that we have implemented the nodule-detection task of the LUNA challenge
    and can produce our own nodule predictions, we ask ourselves the logical next
    question: can we distinguish malignant nodules from benign ones? We should say
    that even with a good system, diagnosing malignancy would probably take a more
    holistic view of the patient, additional non-CT context, and eventually a biopsy,
    rather than just looking at single nodules in isolation on a CT scan. As such,
    this seems to be a task that is likely to be performed by a doctor for some time
    to come.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经实现了LUNA挑战的结节检测任务，并可以生成自己的结节预测，我们问自己一个逻辑上的下一个问题：我们能区分恶性结节和良性结节吗？我们应该说，即使有一个好的系统，诊断恶性可能需要更全面地查看患者，额外的非CT背景信息，最终可能需要活检，而不仅仅是孤立地查看CT扫描中的单个结节。因此，这似乎是一个可能由医生执行的任务，未来可能会有一段时间。
- en: 14.5.1 Getting malignancy information
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.1 获取恶性信息
- en: 'The LUNA challenge focuses on nodule detection and does not come with malignancy
    information. The LIDC-IDRI dataset ([http://mng.bz/4A4R](http://mng.bz/4A4R))
    has a superset of the CT scans used for the LUNA dataset and includes additional
    information about the degree of malignancy of the identified tumors. Conveniently,
    there is a PyLIDC library that can be installed easily, as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: LUNA挑战专注于结节检测，并不包含恶性信息。LIDC-IDRI数据集([http://mng.bz/4A4R](http://mng.bz/4A4R))包含了用于LUNA数据集的CT扫描的超集，并包括有关已识别肿瘤恶性程度的额外信息。方便地，有一个可以轻松安装的PyLIDC库，如下所示：
- en: '[PRE10]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `pylicd` library gives us ready access to the additional malignancy information
    we want. Just like matching the annotations with the candidates by location as
    we did in chapter 10, we need to associate the annotation information from LIDC
    with the coordinates of the LUNA candidates.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`pylicd`库为我们提供了我们想要的额外恶性信息的便捷访问。就像我们在���10章中所做的那样，将LIDC的注释与LUNA候选者的坐标匹配，我们需要将LIDC的注释信息与LUNA候选者的坐标关联起来。'
- en: In the LIDC annotations, the malignancy information is encoded per nodule and
    diagnosing radiologist (up to four looked at the same nodule) using an ordinal
    five-value scale from 1 (highly unlikely) through moderately unlikely, indeterminate,
    and moderately suspicious, and ending with 5 (highly suspicious).[⁴](#pgfId-1015357)
    These annotations are based on the image alone and subject to assumptions about
    the patient. To convert the list of numbers to a single Boolean yes/no, we will
    consider nodules to be malignant when at least two radiologists rated that nodule
    as “moderately suspicious” or greater. Note that this criterion is somewhat arbitrary;
    indeed, the literature has many different ways of dealing with this data, including
    predicting the five steps, using averages, or removing nodules from the dataset
    where the rating radiologists were uncertain or disagreed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在LIDC注释中，恶性信息按照每个结节和诊断放射科医师（最多四位医师查看同一结节）使用从1（高度不可能）到适度不可能、不确定、适度可疑，最后是5（高度可疑）的有序五值量表进行编码。这些注释基于图像本身，并受到关于患者的假设的影响。为了将数字列表转换为单个布尔值是/否，我们将考虑当至少有两位放射科医师将该结节评为“适度可疑”或更高时，结节被认为是恶性的。请注意，这个标准有些是任意的；事实上，文献中有许多不同的处理这些数据的方法，包括预测五个步骤，使用平均值，或者从数据集中删除放射科医师评级不确定或不一致的结节。
- en: The technical aspects of combining the data are the same as in chapter 10, so
    we skip showing the code here (it is in the code repository for this chapter)
    and will use the extended CSV file. We will use the dataset in a way very similar
    to what we did for the nodule classifier, except that we now only need to process
    actual nodules and use whether a given nodule is malignant or not as the label
    to predict. This is structurally very similar to the balancing we used in chapter
    12, but instead of sampling from `pos_list` and `neg_list`, we sample from `mal_list`
    and `ben_list`. Just as we did for the nodule classifier, we want to keep the
    training data balanced. We put this into the `MalignancyLunaDataset` class, which
    subclasses the `LunaDataset` but is otherwise very similar.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 结合数据的技术方面与第10章相同，因此我们跳过在此处显示代码（代码存储库中有此章节的代码），并将使用扩展的CSV文件。我们将以与我们为结节分类器所做的非常相似的方式使用数据集，只是现在我们只需要处理实际结节，并使用给定结节是否为恶性作为要预测的标签。这在结构上与我们在第12章中使用的平衡非常相似，但我们不是从`pos_list`和`neg_list`中抽样，而是从`mal_list`和`ben_list`中抽样。就像我们为结节分类器所做的那样，我们希望保持训练数据平衡。我们将这些放入`MalignancyLunaDataset`类中，该类是`LunaDataset`的子类，但在其他方面非常相似。
- en: For convenience, we create a `dataset` command-line argument in training.py
    and dynamically use the dataset class specified on the command line. We do this
    by using Python’s `getattr` function. For example, if `self.cli_args.dataset`
    is the string `MalignancyLunaDataset`, it will get `p2ch14.dsets.MalignancyLunaDataset`
    and assign this type to `ds_cls`, as we can see here.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们在training.py中创建了一个`dataset`命令行参数，并动态使用命令行指定的数据集类。我们通过使用Python的`getattr`函数来实现这一点。例如，如果`self.cli_args.dataset`是字符串`MalignancyLunaDataset`，它将获取`p2ch14.dsets.MalignancyLunaDataset`并将此类型分配给`ds_cls`，我们可以在这里看到。
- en: Listing 14.7 training.py:154, `.initTrainDl`
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.7 training.py:154，`.initTrainDl`
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Dynamic class-name lookup
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 动态类名查找
- en: ❷ Recall that this is the one-to-one balancing of the training data, here between
    benign and malignant.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 请记住，这是训练数据之间的一对一平衡，这里是良性和恶性之间的平衡。
- en: '14.5.2 An area under the curve baseline: Classifying by diameter'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.2 曲线下面积基线：按直径分类
- en: It is always good to have a baseline to see what performance is better than
    nothing. We could go for better than random, but here we can use the diameter
    as a predictor for malignancy--larger nodules are more likely to be malignant.
    Step 2b of figure 14.5 hints at a new metric we can use to compare classifiers.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个基线总是好的，可以看到什么性能比没有好。我们可以追求比随机更好，但在这里我们可以使用直径作为恶性的预测因子--更大的结节更有可能是恶性的。图14.5的第2b步提示了一个我们可以用来比较分类器的新度量标准。
- en: '![](../Images/CH14_F05_Stevens2_GS.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F05_Stevens2_GS.png)'
- en: Figure 14.5 The end-to-end project we are implementing in this chapter, with
    a focus on the ROC graph
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5 我们在本章中实施的端到端项目，重点是ROC图
- en: We could use the nodule diameter as the sole input to a hypothetical classifier
    predicting whether a nodule is malignant. It wouldn’t be a very good classifier,
    but it turns out that saying “Everything bigger than this threshold X is malignant”
    is a better predictor of malignancy than we might expect. Of course, picking the
    right threshold is key--there’s a sweet spot that gets all the huge tumors and
    none of the tiny specks, and roughly splits the uncertain area that’s a jumble
    of larger benign nodules and smaller malignant ones.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将结节直径作为假设分类器预测结节是否为恶性的唯一输入。这不会是一个很好的分类器，但事实证明，说“一切大于这个阈值X的东西都是恶性的”比我们预期的更好地预测了恶性。当然，选择正确的阈值是关键--有一个甜蜜点，可以获取所有巨大的肿瘤，而没有任何微小的斑点，并且大致分割了那个不确定区域，其中有一堆较大的良性结节和较小的恶性结节。
- en: As we might recall from chapter 12, our true positive, false positive, true
    negative, and false negative counts change based on what threshold value we choose.
    As we decrease the threshold over which we predict that a nodule is malignant,
    we will increase the number of true positives, but also the number of false positives.
    The *false positive rate* (FPR) is FP / (FP + TN), while the *true positive rate*
    (TPR) is TP / (TP + FN), which you might also remember from chapter 12 as the
    recall.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们可能从第12章中记得的那样，我们的真正阳性、假正性、真正性和假负性计数会根据我们选择的阈值值而改变。当我们降低我们预测结节为恶性的阈值时，我们将增加真正阳性的数量，但也会增加假正性的数量。*假正率*（FPR）是FP
    /（FP + TN），而*真正率*（TPR）是TP /（TP + FN），您可能还记得这是从第12章中的召回中得到的。
- en: 'No one true way to measure false positives: Precision vs. false positive rate'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 测量假阳性没有一种真正的方法：精度与假阳性率
- en: The FPR here and the precision from chapter 12 are rates (between 0 and 1) that
    measure things that are not quite opposites. As we discussed, precision is TP
    / (TP + FP) and measures how many of the samples predicted to be positive will
    actually be positive. The FPR is FP / (FP + TN) and measures how many of the actually
    negative samples are predicted to be positive. For heavily imbalanced datasets
    (like the nodule versus non-nodule classification), our model might achieve a
    very good FPR (which is closely related to the cross-entropy criterion as a loss)
    while the precision--and thus the F1 score--is still very poor. A low FPR means
    we’re weeding out a lot of what we’re not interested in, but if we are looking
    for that proverbial needle, we still have mostly hay.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的FPR和第12章中的精度是（介于0和1之间的）率，用于衡量不完全相反的事物。正如我们讨论过的，精度是TP /（TP + FP），用于衡量预测为阳性的样本中有多少实际上是阳性的。FPR是FP
    /（FP + TN），用于衡量实际上为负的样本中有多少被预测为阳性。对于极度不平衡的数据集（如结节与非结节分类），我们的模型可能会实现非常好的FPR（这与交叉熵标准作为损失密切相关），而精��--因此F1分数--仍然非常差。低FPR意味着我们正在淘汰我们不感兴趣的很多内容，但如果我们正在寻找那根传说中的针，我们仍然主要是干草。
- en: Let’s set a range for our threshold. The lower bound will be the value at which
    *all* of our samples are classified as positive, and the upper bound will be the
    opposite, where all samples are classified as negative. At one extreme, our FPR
    and TPR will both be zero, since there won’t be *any* positives; and at the other,
    both will be one, since TNs and FNs won’t exist (everything is positive!).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为我们的阈值设定一个范围。下限将是使得*所有*样本都被分类为阳性的值，上限将是相反的情况，即所有样本都被分类为阴性。在一个极端情况下，我们的 FPR
    和 TPR 都将为零，因为不会有*任何*阳性；在另一个极端情况下，两者都将为一，因为不会有 TN 和 FN（一切都是阳性！）。
- en: For our nodule data, that’s from 3.25 mm (the smallest nodule) to 22.78 mm (the
    largest). If we pick a threshold value somewhere between those two values, we
    can then compute FPR(threshold) and TPR(threshold). If we set the FPR value to
    *X* and TPR to *Y*, we can plot a point that represents that threshold; and if
    we instead plot the FPR versus TPR for every possible threshold, we get a diagram
    called the *receiver operating characteristic* (ROC) shown in figure 14.6\. The
    shaded area is the *area under the (ROC) curve*, or AUC. It is between 0 and 1,
    and higher is better.[⁵](#pgfId-1015921)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的结节数据，直径范围从 3.25 毫米（最小结节）到 22.78 毫米（最大结节）。如果我们选择一个介于这两个值之间的阈值，然后可以计算 FPR（阈值）和
    TPR（阈值）。如果我们将 FPR 值设为*X*，TPR 设为*Y*，我们可以绘制代表该阈值的点；如果我们反而绘制每个可能阈值的 FPR 对 TPR，我们得到一个名为*受试者工作特征*（ROC）的图表，如图
    14.6 所示。阴影区域是*ROC 曲线下的面积*，或者 AUC。它的取值范围在 0 到 1 之间，数值越高越好。[⁵](#pgfId-1015921)
- en: '![](../Images/CH14_F06_Stevens2_GS.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F06_Stevens2_GS.png)'
- en: Figure 14.6 Receiver operating characteristic (ROC) curve for our baseline
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 我们基线的受试者工作特征（ROC）曲线
- en: 'Here, we also call out two specific threshold values: diameters of 5.42 mm
    and 10.55 mm. We chose those two values because they give us somewhat reasonable
    endpoints for the range of thresholds we might consider, were we to need to pick
    a single threshold. Anything smaller than 5.42 mm, and we’d only be dropping our
    TPR. Larger than 10.55 mm, and we’d just be flagging malignant nodules as benign
    for no gain. The best threshold for this classifier will probably be in the middle
    somewhere.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还指出了两个特定的阈值：直径为 5.42 毫米和 10.55 毫米。我们选择这两个值，因为它们为我们可能考虑的阈值范围提供了相对合理的端点，如果我们需要选择一个单一的阈值。小于
    5.42 毫米，我们只会降低我们的 TPR。大于 10.55 毫米，我们只会将恶性结节标记为良性而没有任何收益。这个分类器的最佳阈值可能会在中间某处。
- en: How do we actually compute the values shown here? We first grab the candidate
    info list, filter out the annotated nodules, and get the malignancy label and
    diameter. For convenience, we also get the number of benign and malignant nodules.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上是如何计算这里显示的数值的呢？我们首先获取候选信息列表，过滤出已注释的结节，并获取恶性标签和直径。为了方便起见，我们还获取了良性和恶性结节的数量。
- en: Listing 14.8 p2ch14_malben_baseline.ipynb
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.8 p2ch14_malben_baseline.ipynb
- en: '[PRE12]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Takes the regular dataset and in particular the list of benign and malignant
    nodules
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取常规数据集，特别是良性和恶性结节的列表
- en: ❷ Gets lists of malignancy status and diameter
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取恶性状态和直径的列表
- en: ❸ For normalization of the TPR and FPR, we take the number of malignant and
    benign nodules.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为了对 TPR 和 FPR 进行归一化，我们获取了恶性和良性结节的数量。
- en: 'To compute the ROC curve, we need an array of the possible thresholds. We get
    this from `torch.linspace`, which takes the two boundary elements. We wish to
    start at zero predicted positives, so we go from maximal threshold to minimal.
    This is the 3.25 to 22.78 we already mentioned:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算 ROC 曲线，我们需要一个可能阈值的数组。我们从 `torch.linspace` 获取这个数组，它取两个边界元素。我们希望从零预测的阳性开始，所以我们从最大阈值到最小阈值。这就是我们已经提到的
    3.25 到 22.78：
- en: '[PRE13]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We then build a two-dimensional tensor in which the rows are per threshold,
    the columns are per-sample information, and the value is whether this sample is
    predicted as positive. This Boolean tensor is then filtered by whether the label
    of the sample is malignant or benign. We sum the rows to count the number of `True`
    entries. Dividing by the number of malignant or benign nodules gives us the TPR
    and FPR--the two coordinates for the ROC curve:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们构建一个二维张量，其中行是每个阈值，列是每个样本信息，值是该样本是否被预测为阳性。然后根据样本的标签（恶性或良性）对此布尔张量进行过滤。我们对行求和以计算`True`条目的数量。除以恶性或良性结节的数量给出了
    TPR 和 FPR--ROC 曲线的两个坐标：
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Indexing by None adds a dimension of size 1, just like .unsqueeze(ndx). This
    gets us a 2D tensor of whether a given nodule (in a column) is classified as malignant
    for a given diameter (in the row).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过 None 索引添加了一个大小为 1 的维度，就像 .unsqueeze(ndx) 一样。这使我们得到一个 2D 张量，其中给定结节（在列中）是否被分类为恶性，直径（在行中）。
- en: ❷ With the predictions matrix, we can compute the TPRs and FPRs for each diameter
    by summing over the columns.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用预测矩阵，我们可以通过对列求和来计算每个直径的 TPR 和 FPR。
- en: 'To compute the area under this curve, we use numeric integration by the trapezoidal
    rule ([https://en.wikipedia.org/wiki/Trapezoidal_rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)),
    where we multiply the average TPRs (on the Y-axis) between two points by the difference
    of the two FPRs (on the X-axis)--the area of trapezoids between two points of
    the graph. Then we sum the area of the trapezoids:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算这条曲线下的面积，我们使用梯形法进行数值积分（[https://en.wikipedia.org/wiki/Trapezoidal_rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)），其中我们将两点之间的平均
    TPR（Y 轴上）乘以两个 FPR 之间的差值（X 轴上）--图表中两点之间梯形的面积。然后我们将梯形的面积相加：
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, if we run `pyplot.plot(fp_diam, tp_diam, label=f"diameter baseline, AUC={auc_diam:.3f}")`
    (along with the appropriate figure setup we see in cell 8), we get the plot we
    saw in figure 14.6\.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们运行`pyplot.plot(fp_diam, tp_diam, label=f"diameter baseline, AUC={auc_diam:.3f}")`（以及我们在第
    8 单元中看到的适当图表设置），我们将得到图 14.6 中看到的图表。
- en: '14.5.3 Reusing preexisting weights: Fine-tuning'
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.3 重复使用预先存在的权重：微调
- en: One way to quickly get results (and often also get by with much less data) is
    to start not from random initializations but from a network trained on some task
    with related data. This is called *transfer learning* or, when training only the
    last few layers, *fine-tuning*. Looking at the highlighted part in figure 14.7,
    we see that in step 2c, we’re going to cut out the last bit of the model and replace
    it with something new.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 一种快速获得结果的方法（通常也可以用更少的数据完成）是不从随机初始化开始，而是从在某个具有相关数据的任务上训练过的网络开始。这被称为*迁移学习*或者，当仅训练最后几层时，称为*微调*。从图
    14.7 中突出显示的部分可以看出，在步骤 2c 中，我们将剪掉模型的最后一部分，并用新的东西替换它。
- en: '![](../Images/CH14_F07_Stevens2_GS.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F07_Stevens2_GS.png)'
- en: Figure 14.7 The end-to-end project we’re implementing in this chapter, with
    a focus on fine-tuning
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.7 我们在本章中实施的端到端项目，重点是微调
- en: Recall from chapter 8 that we could interpret the intermediate values as features
    extracted from the image--features could be edges or corners that the model detects
    or indications of any pattern. Before deep learning, it was very common to use
    handcrafted features similar to what we briefly experimented with when starting
    with convolutions. Deep learning has the network derive features useful for the
    task at hand, such as discrimination between classes, from the data. Now, fine-tuning
    has us mix the ancient ways (almost a *decade* ago!) of using preexisting features
    and the new way of using learned features. We treat some (often large) part of
    the network as a fixed *feature extractor* and only train a relatively small part
    on top of it.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下第 8 章，我们可以将中间值解释为从图像中提取的特征--特征可以是模型检测到的边缘或角落，或者任何模式的指示。在深度学习之前，很常见使用手工制作的特征，类似于我们在卷积开始时简要尝试的内容。深度学习使网络从数据中提取对当前任务有用的特征，例如区分类别。现在，微调让我们混合使用古老的方法（将近*十年*前！）使用预先存在的特征和使用学习特征的新方法。我们将网络的一部分（通常是大部分）视为固定的*特征提取器*，只训练其上的相对较小的部分。
- en: This generally works very well. Pretrained networks trained on ImageNet as we
    saw in chapter 2 are very useful as feature extractors for many tasks dealing
    with natural images--sometimes they also work amazingly for completely different
    inputs, from paintings or imitations thereof in style transfer to audio spectrograms.
    There are cases when this strategy works less well. For example, one of the common
    data augmentation strategies in training models on ImageNet is randomly flipping
    the images--a dog looking right is the same class as one looking left. As a result,
    the features between flipped images are very similar. But if we now try to use
    the pretrained model for a task where left or right matters, we will likely encounter
    accuracy problems. If we want to identify traffic signs, *turn left here* is quite
    different than *turn right here*; but a network building on ImageNet-based features
    will probably make lots of wrong assignments between the two classes.[⁶](#pgfId-1019905)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常效果非常好。像我们在第 2 章中看到的在 ImageNet 上训练的预训练网络对处理自然图像的许多任务非常有用--有时它们也对完全不同的输入效果惊人，从绘画或风格转移中的仿制品到音频频谱图。有些情况下，这种策略效果不佳。例如，在训练在
    ImageNet 上的模型时，常见的数据增强策略之一是随机翻转图像--一个向右看的狗与向左看的狗属于同一类。因此，翻转图像之间的特征非常相似。但是如果我们现在尝试使用预训练模型进行一个左右有关的任务，我们可能会遇到准确性问题。如果我们想要识别交通标志，*这里左转*与*这里右转*是完全不同的；但是基于
    ImageNet 特征构建的网络可能会在这两个类之间产生许多错误的分配。
- en: 'In our case, we have a network that has been trained on similar data: the nodule
    classification network. Let’s try using that.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们有一个在类似数据上训练过的网络：结节分类网络。让我们尝试使用它。
- en: 'For the sake of exposition, we will stay very basic in our fine-tuning approach.
    In the model architecture in figure 14.8, the two bits of particular interest
    are highlighted: the last convolutional block and the `head_linear` module. The
    simplest fine-tuning is to cut out the `head_linear` part--in truth, we are just
    keeping the random initialization. After we try that, we will also explore a variant
    where we retrain both `head_linear` and the last convolutional block.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们在微调方法中保持非常基本。在图 14.8 中的模型架构中，两个特别感兴趣的部分被突出显示：最后的卷积块和`head_linear`模块。最简单的微调是剪掉`head_linear`部分--事实上，我们只是保留了随机初始化。在尝试了这个之后，我们还将探索一种重新训练`head_linear`和最后一个卷积块的变体。
- en: '![](../Images/CH14_F08_Stevens2_GS.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_Stevens2_GS.png)'
- en: Figure 14.8 The model architecture from chapter 11, with the depth-1 and depth-2
    weights highlighted
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.8 章节 11 中的模型架构，突出显示了深度-1和深度-2的权重
- en: 'We need to do the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做以下事情：
- en: Load the weights of the model we wish to start with, except for the last linear
    layer, where we want to keep the initialization.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载我们希望从中开始的模型的权重，除了最后的线性层，我们希望保留初始化。
- en: Disable gradients for the parameters we do not want to train (everything except
    parameters with names starting with `head`).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于我们不想训练的参数禁用梯度（除了以`head`开头的参数）。
- en: 'When we do fine-tuning training on more than `head_linear`, we still only reset
    `head _linear` to random, because we believe the previous feature-extraction layers
    might not be ideal for our problem, but we expect them to be a reasonable starting
    point. This is easy: we add some loading code into our model setup.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在超过`head_linear`上进行微调训练时，我们仍然只将`head_linear`重置为随机值，因为我们认为先前的特征提取层可能不太适合我们的问题，但我们期望它们是一个合理的起点。这很简单：我们在模型设置中添加一些加载代码。
- en: Listing 14.9 training.py:124, `.initModel`
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.9 training.py:124，`.initModel`
- en: '[PRE16]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Filters out top-level modules that have parameters (as opposed to the final
    activation)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 过滤掉具有参数的顶层模块（而不是最终激活）
- en: ❷ Takes the last finetune_depth blocks. The default (if fine-tuning) is 1.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取最后的finetune_depth块。默认值（如果进行微调）为1。
- en: ❸ Filters out the last block (the final linear part) and does not load it. Starting
    from a fully initialized model would have us begin with (almost) all nodules labeled
    as malignant, because that output means “nodule” in the classifier we start from.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 过滤掉最后一个块（最后的线性部分）并且不加载它。从一个完全初始化的模型开始将使我们从（几乎）所有结节被标记为恶性的状态开始，因为在我们开始的分类器中，该输出表示“结节”。
- en: ❹ Passing strict=False lets us load only some weights of the module (with the
    filtered ones missing).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 通过strict=False参数，我们可以仅加载模块的一些权重（其中过滤的权重缺失）。
- en: ❺ For all but finetune_blocks, we do not want gradients.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 对于除finetune_blocks之外的所有部分，我们不希望梯度。
- en: 'We’re set! We can train only the head by running this:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备好了！我们可以通过运行以下命令来仅训练头部：
- en: '[PRE17]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Let’s run our model on the validation set and get the ROC curve, shown in figure
    14.9\. It’s a lot better than random, but given that we’re not outperforming the
    baseline, we need to see what is holding us back.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在验证集上运行我们的模型并获得ROC曲线，如图14.9所示。这比随机要好得多，但考虑到我们没有超越基线，我们需要看看是什么阻碍了我们。
- en: '![](../Images/CH14_F09_Stevens2_GS.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F09_Stevens2_GS.png)'
- en: Figure 14.9 ROC curve for our fine-tuned model with a retrained final linear
    layer. Not too bad, but not quite as good as the baseline.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9 我们重新训练最后一个线性层的微调模型的ROC曲线。不算太糟糕，但也不如基线那么好。
- en: 'Figure 14.10 shows the TensorBoard graphs for our training. Looking at the
    validation loss, we see that while the AUC slowly increases and the loss decreases,
    even the training loss seems to plateau at a somewhat high level (say, 0.3) instead
    of trending toward zero. We could run a longer training to check whether it is
    just very slow; but comparing this to the loss progression discussed in chapter
    5--in particular, figure 5.14--we can see our loss value has not flatlined as
    badly as case A in the figure, but our problem with losses stagnating is qualitatively
    similar. Back then, case A indicated that we did not have enough capacity, so
    we should consider the following three possible causes:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10显示了我们训练的TensorBoard图表。观察验证损失，我们可以看到虽然AUC缓慢增加，损失减少，但即使训练损失似乎在一个相对较高的水平（比如0.3）上趋于平稳，而不是朝向零。我们可以进行更长时间的训练来检查是否只是非常缓慢；但将这与第5章讨论的损失进展进行比较--特别是图5.14--我们可以看到我们的损失值并没有像图中的A案那样完全平稳，但我们的损失停滞问题在质量上是相似的。当时，A案表明我们的容量不足，因此我们应考虑以下三种可能的原因：
- en: Features (the output of the last convolution) obtained by training the network
    on nodule versus non-nodule classification are not useful for malignancy detection.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在结节与非结节分类上训练网络获得的特征（最后一个卷积的输出）对恶性检测并不有用。
- en: The capacity of the head--the only part we are training--is not large enough.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 头部的容量--我们唯一训练的部分--并不够大。
- en: The network might have too little capacity overall.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整体网络的容量可能太小了。
- en: '![](../Images/CH14_F10_Stevens2_GS.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F10_Stevens2_GS.png)'
- en: Figure 14.10 AUC (left) and loss (right) for the fine-tuning of the last linear
    layer
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10 最后一个线性层微调的AUC（左）和损失（右）
- en: 'If training only the fully connected part in fine-tuning is not enough, the
    next thing to try is to include the last convolutional block in the fine-tuning
    training. Happily, we introduced a parameter for that, so we can include the `block4`
    part into our training:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仅对全连接部分进行微调训练不够，下一步尝试的是将最后一个卷积块包括在微调训练中。幸运的是，我们引入了一个参数，所以我们可以将`block4`部分包含在我们的训练中：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ This CLI parameter is new.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这个CLI参数是新的。
- en: Once done, we can check our new best model against the baseline. Figure 14.11
    looks more reasonable! We flag about 75% of the malignant nodules with almost
    no false positives. This is clearly better than the 65% the diameter baseline
    can give us. Trying to push beyond 75%, our model’s performance falls back to
    the baseline. When we go back to the classification problem, we will want to pick
    a point on the ROC curve to balance true positives versus false positives.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以将我们的新最佳模型与基线进行比较。图14.11看起来更合理！我们几乎没有误报，就能标记出约75%的恶性结节。这显然比直径基线的65%要好。当我们试图超过75%时，我们的模型性能会回到基线。当我们回到分类问题时，我们将希望在ROC曲线上选择一个平衡真阳性与假阳性的点。
- en: '![](../Images/CH14_F11_Stevens2_GS.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F11_Stevens2_GS.png)'
- en: Figure 14.11 ROC curve for our modified model. Now we’re getting really close
    to the baseline.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.11 我们修改后模型的ROC曲线。现在我们离基线非常接近。
- en: We are roughly on par with the baseline, and we will be content with that. In
    section 14.7, we hint at the many things that you can explore to improve these
    results, but that didn’t fit in this book.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大致与基线持平，我们会对此感到满意。在第14.7节中，我们暗示了许多可以探索以改善这些结果的方法，但这些内容没有包含在本书中。
- en: Looking at the loss curves in figure 14.12, we see that our model is now overfitting
    very early; thus the next step would be to check into further regularization methods.
    We will leave that for you.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 从图14.12中观察损失曲线，我们可以看到我们的模型现在很早就开始过拟合；因此下一步将是进一步检查正则化方法。我们将留给您处理。
- en: '![](../Images/CH14_F12_Stevens2_GS.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F12_Stevens2_GS.png)'
- en: Figure 14.12 AUC (left) and loss (right) for the fine-tuning of the last convolutional
    block and the fully connected layer
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.12 最后一个卷积块和全连接层微调的AUC（左）和损失（右）
- en: 'There are more refined methods of fine-tuning. Some advocate gradually unfreeze
    the layers, starting from the top. Others propose to train the later layers with
    the usual learning rate and use a smaller rate for the lower layers. PyTorch does
    natively support using different optimization parameters like learning rates,
    weight decay, and momentum for different parameters by separating them in several
    *parameter groups* that are just that: lists of parameters with separate hyperparameters
    ([https://pytorc .org/docs/stable/optim.html#per-parameter-options](https://pytorch.org/docs/stable/optim.html#per-parameter-options)).'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 有更精细的微调方法。有些人主张逐渐解冻层，从顶部开始。其他人建议用通常的学习率训练后面的层，并为较低的层使用较小的学习率。PyTorch 本身支持使用不同的优化参数，如学习率、权重衰减和动量，通过将它们分开在几个*参数组*中，这些参数组只是那样：具有单独超参数的参数列表（[https://pytorch.org/docs/stable/optim.html#per-parameter-options](https://pytorch.org/docs/stable/optim.html#per-parameter-options)）。
- en: 14.5.4 More output in TensorBoard
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.5.4 TensorBoard 中的更多输出
- en: While we are retraining the model, it might be worth looking at a few more outputs
    we could add to TensorBoard to see how we are doing. For histograms, TensorBoard
    has a premade recording function. For ROC curves, it does not, so we have an opportunity
    to meet the Matplotlib interface.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们重新训练模型时，值得看一看我们可以添加到 TensorBoard 中的一些额外输出，以查看我们的表现如何。对于直方图，TensorBoard 有一个预制的记录功能。对于
    ROC 曲线，它没有，因此我们有机会满足 Matplotlib 接口。
- en: Histograms
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 直方图
- en: 'We can take the predicted probabilities for malignancy and make a histogram
    of them. Actually, we make two: one for (according to the ground truth) benign
    and one for malignant nodules. These histograms give us a fine-grained view into
    the outputs of the model and let us see if there are large clusters of output
    probabilities that are completely wrong.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以获取恶性的预测概率并制作一个直方图。实际上，我们制作了两个：一个是（根据地面实况）良性的，一个是恶性结节的。这些直方图让我们深入了解模型的输出，并让我们看到是否有完全错误的大集群输出概率。
- en: '*Note* In general, shaping the data you display is an important part of getting
    quality information from the data. If you have many extremely confident correct
    classifications, you might want to exclude the leftmost bin. Getting the right
    things onscreen will typically require some iteration of careful thought and experimentation.
    Don’t hesitate to tweak what you’re showing, but also take care to remember if
    you change the definition of a particular metric without changing the name. It
    can be easy to compare apples to oranges unless you’re disciplined about naming
    schemes or removing now-invalid runs of data.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 一般来说，塑造您显示的数据是从数据中获取高质量信息的重要部分。如果您有许多非常自信的正确分类，您可能希望排除最左边的箱子。将正确的内容显示在屏幕上通常需要一些仔细思考和实验的迭代。不要犹豫调整您显示的内容，但也要注意记住，如果您更改了特定指标的定义而没有更改名称，将很容易将苹果与橙子进行比较。除非您在命名方案或删除现在无效的数据运行时有纪律地更改。'
- en: We first create some space in the tensor `metrics_t` holding our data. Recall
    that we defined the indices somewhere near the top.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在保存我们的数据的张量`metrics_t`中创建一些空间。回想一下，我们在某处定义了索引。
- en: Listing 14.10 training.py:31
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.10 training.py:31
- en: '[PRE19]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Our new index, carrying the prediction probabilities (rather than prethresholded
    predictions)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们的新指数，携带着预测概率（而不是经过阈值处理的预测）
- en: Once that’s done, we can call `writer.add_histogram` with a label, the data,
    and the `global_step` counter set to our number of training samples presented;
    this is similar to the scalar call earlier. We also pass in `bins` set to a fixed
    scale.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成这一步，我们可以调用`writer.add_histogram`，传入一个标签、数据以及设置为我们呈现的训练样本数的`global_step`计数器；这类似于之前的标量调用。我们还传入`bins`设置为一个固定的尺度。
- en: Listing 14.11 training.py:496, `.logMetrics`
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.11 training.py:496，`.logMetrics`
- en: '[PRE20]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now we can take a look at our prediction distribution for benign samples and
    how it evolves over each epoch. We want to examine two main features of the histograms
    in figure 14.13\. As we would expect if our network is learning anything, in the
    top row of benign samples and non-nodules, there is a mountain on the left where
    the network is very confident that what it sees is not malignant. Similarly, there
    is a mountain on the right for the malignant samples.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看一看我们对良性样本的预测分布以及它在每个时期如何演变。我们想要检查图 14.13 中直方图的两个主要特征。正如我们所期望的，如果我们的网络正在学习任何东西，在良性样本和非结节的顶行中，左侧有一个山峰，表示网络非常确信它所看到的不是恶性的。同样，在恶性样本中右侧也有一个山峰。
- en: But looking closer, we see the capacity problem of fine-tuning only one layer.
    Focusing on the top-left series of histograms, we see the mass to the left is
    somewhat spread out and does not seem to reduce much. There is even a small peak
    round 1.0, and quite a bit of probability mass is spread out across the entire
    range. This reflects the loss that didn’t want to decrease below 0.3.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 但仔细观察，我们看到了仅微调一个层的容量问题。专注于左上角的直方图系列，我们看到左侧的质量有些分散，并且似乎没有减少太多。甚至在 1.0 附近有一个小峰值，而且相当多的概率质量分布在整个范围内。这反映了损失不愿意降到
    0.3 以下。
- en: '![](../Images/CH14_F13_Stevens2_GS.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F13_Stevens2_GS.png)'
- en: Figure 14.13 TensorBoard histogram display for fine-tuning the head only
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.13 TensorBoard 直方图显示仅微调头部
- en: Given this observation on the training loss, we would not have to look further,
    but let’s pretend for a moment that we do. In the validation results on the right
    side, it appears that the probability mass away from the “correct” side is larger
    for the non-malignant samples in the top-right diagram than for the malignant
    ones in the bottom-right diagram. So the network gets non-malignant samples wrong
    more often than malignant ones. This might have us look into rebalancing the data
    to show more non-malignant samples. But again, this is when we pretend there was
    nothing wrong with the training on the left side. We typically want to fix training
    first!
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于对训练损失的观察，我们不必再深入研究，但让我们假装一下。在右侧的验证结果中，似乎在顶部右侧图表中，远离“正确”一侧的概率质量对于非恶性样本比底部右侧图表中的恶性样本更大。因此，网络更经常将非恶性样本错误分类为恶性样本。这可能会让我们考虑重新平衡数据以展示更多的非恶性样本。但再次强调，这是当我们假装左侧的训练没有任何问题时。我们通常希望先修复训练！
- en: For comparison, let’s take a look at the same graph for our depth 2 fine-tuning
    (figure 14.14). On the training side (the left two diagrams), we have very sharp
    peaks at the correct answer and not much else. This reflects that training works
    well.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较，让我们看看我们深度为2的微调相同图表（图14.14）。在训练方面（左侧两个图表），我们在正确答案处有非常尖锐的峰值，其他内容不多。这反映了训练效果很好。
- en: '![](../Images/CH14_F14_Stevens2_GS.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F14_Stevens2_GS.png)'
- en: Figure 14.14 TensorBoard histogram display for fine-tuning with depth 2
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.14 TensorBoard直方图显示，深度为2的微调
- en: On the validation side, we now see that the most pronounced artifact is the
    little peak at 0 predicted probability for malignancy in the bottom-right histogram.
    So our systematic problem is that we’re misclassifying malignant samples as non-malignant.
    (This is the reverse of what we had earlier!) This is the overfitting we saw with
    two-layer fine-tuning. It probably would be good to pull up a few images of that
    type to see what’s happening.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证方面，我们现在看到最明显的问题是底部右侧直方图中预测概率为0的小峰值。因此，我们的系统性问题是将恶性样本误分类为非恶性。这与我们之前看到的两层微调过拟合相反！可能最好查看一些这种类型的图像，看看发生了什么。
- en: ROC and other curves in TensorBoard
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: TensorBoard中的ROC和其他曲线
- en: 'As mentioned earlier, TensorBoard does not natively support drawing ROC curves.
    We can, however, use the ability to export any graph from Matplotlib. The data
    preparation looks just like in section 14.5.2: we use the data that we also plotted
    in the histogram to compute the TPR and FPR--`tpr` and `fpr`, respectively. We
    again plot our data, but this time we keep track of `pyplot.figure` and pass it
    to the `SummaryWriter` method `add_figure`.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，TensorBoard本身不支持绘制ROC曲线。但是，我们可以利用Matplotlib导出任何图形的功能。数据准备看起来就像第14.5.2节中的一样：我们使用了在直方图中绘制的数据来计算TPR和FPR--分别是`tpr`和`fpr`。我们再次绘制我们的数据，但这次我们跟踪`pyplot.figure`并将其传递给`SummaryWriter`方法`add_figure`。
- en: Listing 14.12 training.py:482, `.logMetrics`
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.12 training.py:482，`.logMetrics`
- en: '[PRE21]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Sets up a new Matplotlib figure. We usually don’t need it because it is implicitly
    done in Matplotlib, but here we do.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置一个新的Matplotlib图。通常我们不需要它，因为Matplotlib会隐式完成，但在这里我们需要。
- en: ❷ Uses arbitrary pyplot functions
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用任意pyplot函数
- en: ❸ Adds our figure to TensorBoard
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将我们的图表添加到TensorBoard
- en: Because this is given to TensorBoard as an image, it appears under that heading.
    We didn’t draw the comparison curve or anything else, so as not to distract you
    from the actual function call, but we could use any Matplotlib facilities here.
    In figure 14.15, we see again that the depth-2 fine-tuning (left) overfits, while
    the head-only fine-tuning (right) does not.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是作为图像提供给TensorBoard的，所以它出现在该标题下。我们没有绘制比较曲线或其他任何内容，以免让您分心，但我们可以在这里使用任何Matplotlib工具。在图14.15中，我们再次看到深度为2的微调（左侧）过拟合，而仅对头部进行微调（右侧）则没有。
- en: '![](../Images/CH14_F15_Stevens2_GS.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F15_Stevens2_GS.png)'
- en: Figure 14.15 Training ROC curves in TensorBoard. A slider lets us go through
    the iterations.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.15 在TensorBoard中训练ROC曲线。滑块让我们浏览迭代。
- en: 14.6 What we see when we diagnose
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.6 当我们进行诊断时看到的情况
- en: 'Following along with steps 3a, 3b, and 3c in figure 14.16, we now need to run
    the full pipeline from the step 3a segmentation on the left to the step 3c malignancy
    model on the right. The good news is that almost all of our code is in place already!
    We just need to stitch it together: the moment has come to actually write and
    run our end-to-end diagnosis script.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 沿着图14.16中的步骤3a、3b和3c，我们现在需要运行从左侧的步骤3a分割到右侧的步骤3c恶性模型的完整流程。好消息是，我们几乎所有的代码都已经就位！我们只需要将它们组合起来：现在是时候实际编写并运行我们的端到端诊断脚本了。
- en: We saw our first hints at handling the malignancy model back in the code in
    section 14.3.3\. If we pass an argument `--malignancy-path` to the `nodule_analysis`
    call, it runs the malignancy model found at this path and outputs the information.
    This works for both a single scan and the `--run-validation` variant.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第14.3.3节的代码中首次看到了处理恶性模型的线索。如果我们向`nodule_analysis`调用传递一个参数`--malignancy-path`，它将运行在此路径找到的恶性模型并输出信息。这适用于单个扫描和`--run-validation`变体。
- en: '![](../Images/CH14_F16_Stevens2_GS.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F16_Stevens2_GS.png)'
- en: Figure 14.16 The end-to-end project we are implementing in this chapter, with
    a focus on end-to-end detection
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.16 我们在本章实施的端到端项目，重点是端到端检测
- en: Be warned that the script will probably take a while to finish; even just the
    89 CTs in the validation set took about 25 minutes.[⁷](#pgfId-1024353)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，脚本可能需要一段时间才能完成；即使只有验证集中的89个CT花费了大约25分钟。[⁷](#pgfId-1024353)
- en: 'Let’s see what we get:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们得到了什么：
- en: '[PRE22]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Not too bad! We detect about 85% of the nodules and correctly flag about 70%
    of the malignant ones, end to end.[⁸](#pgfId-1024413) While we have a lot of false
    positives, it would seem that having 16 of them per true nodule reduces what needs
    to be looked at (well, if it were not for the 30% false negatives). As we already
    warned in chapter 9, this isn’t at the level where you could collect millions
    of funding for your medical AI startup,[⁹](#pgfId-1024432) but it’s a pretty reasonable
    starting point. In general, we should be pretty happy that we’re getting results
    that are clearly meaningful; and of course our *real* goal has been to study deep
    learning along the way.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 不算太糟糕！我们检测到大约85%的结节，并正确标记了约70%的恶性结节，从头到尾。[⁸](#pgfId-1024413) 虽然我们有很多假阳性，但似乎每个真结节有16个假阳性减少了需要查看的内容（好吧，如果没有30%的假阴性的话）。正如我们在第9章中已经警告过的那样，这还不到你可以为你的医疗人工智能初创公司筹集数百万资金的水平，[⁹](#pgfId-1024432)
    但这是一个相当合理的起点。总的来说，我们应该对我们得到的明显有意义的结果感到满意；当然，我们*真正*的目标一直是在学习深度学习的过程中。
- en: We might next choose to look at the nodules that are actually misclassified.
    Keep in mind that for our task at hand, even the radiologists who annotated the
    dataset differed in opinion. We might stratify our validation set by how clearly
    they identified a nodule as malignant.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可能会选择查看实际被错误分类的结节。请记住，对于我们手头的任务，即使标注数据集的放射科医生们在看法上也存在差异。我们可能会根据他们清晰地将结节识别为恶性的程度来分层我们的验证集。
- en: 14.6.1 Training, validation, and test sets
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.6.1 训练、验证和测试集
- en: There is one caveat that we must mention. While we didn’t explicitly train our
    model on the validation set, although we ran this risk at the beginning of the
    chapter, we did *choose* the epoch of training to use based on the model’s performance
    on the validation set. That’s a bit of a data leak, too. In fact, we should expect
    our real-world performance to be slightly worse than this, as it’s unlikely that
    whatever model performs best on our validation set will perform equally well on
    every other unseen set of data (on average, at least).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须提到一个警告。虽然我们没有明确地在验证集上训练我们的模型，尽管我们在本章的开头冒了这个风险，但我们确实*选择*了基于模型在验证集上的表现来使用的训练时期。这也是一种数据泄漏。事实上，我们应该预期我们的实际性能会略逊色于这个，因为最好的模型在我们的验证集上表现得很好，不太可能在每个其他未见过的数据集上表现得同样出色（至少平均而言）。
- en: 'For this reason, practitioners often split data into *three* sets:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，实践者经常将数据分为*三*组：
- en: A *training set*, exactly as we’ve done here
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*训练集*，就像我们在这里所做的一样
- en: A *validation set*, used to determine which epoch of evolution of the model
    to consider “best”
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*验证集*，用于确定模型演化的哪个时期被认为是“最佳”
- en: A *test set*, used to actually predict performance for the model (as chosen
    by the validation set) on unseen, real-world data
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*测试集*，用于实际预测模型的性能（由验证集选择）在未见过的真实世界数据上
- en: Adding a third set would have led us to pull another nontrivial chunk of our
    training data, which would have been somewhat painful, given how badly we had
    to fight overfitting already. It would also have complicated the presentation,
    so we purposely left it out. Were this a project with the resources to get more
    data and an imperative to build the best possible system to use in the wild, we’d
    have to make a different decision here and actively seek more data to use as an
    independent test set.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 添加第三组将导致我们再次拉取我们的训练数据的另一个非常重要的部分，考虑到我们已经不得不为了对抗过拟合而努力。这也会使呈现变得更加复杂，所以我们故意将其排除在外。如果这是一个有资源获取更多数据并迫切需要构建在野外使用的最佳系统的项目，我们将不得不在这里做出不同的决定，并积极寻找更多数据用作独立的测试集。
- en: 'The general message is that there are subtle ways for bias to creep into our
    models. We should use extra care to control information leakage at every step
    of the way and verify its absence using independent data as much as possible.
    The price to pay for taking shortcuts is failing egregiously at a later stage,
    at the worst possible time: when we’re closer to production.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，偏见潜入我们的模型的方式是微妙的。我们应该特别小心地控制信息泄漏的每一步，并尽可能使用独立数据验证其不存在。采取捷径的代价是在后期惨败，而这种情况发生的时间是最糟糕的：当我们接近生产时。
- en: 14.7 What next? Additional sources of inspiration (and data)
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.7 接下来呢？灵感（和数据）的额外来源
- en: Further improvements will be difficult to measure at this point. Our classification
    validation set contains 154 nodules, and our nodule classification model is typically
    getting at least 150 of them right, with most of the variance coming from epoch-by-epoch
    training changes. Even if we were to make a significant improvement to our model,
    we don’t have enough fidelity in our validation set to tell whether that change
    is an improvement for certain! This is also very pronounced in the benign versus
    malignant classification, where the validation loss zigzags a lot. If we reduced
    our validation stride from 10 to 5, the size of our validation set would double,
    at the cost of one-ninth of our training data. That might be worth it if we wanted
    to try other improvements. Of course, we would also need to address the question
    of a test set, which would take away from our already limited training data.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，进一步的改进将很难衡量。我们的分类验证集包含154个结节，我们的结节分类模型通常至少有150个正确，大部分的变化来自每个时期的训练变化。即使我们对模型进行了显著改进，我们的验证集中也没有足够的准确性来确定这种改变是否肯定是改进！这在良性与恶性分类中也非常明显，验证损失经常曲折。如果我们将验证步幅从10减少到5，我们的验证集的大小将翻倍，代价是我们训练数据的九分之一。如果我们想尝试其他改进，这可能是值得的。当然，我们还需要解决测试集的问题，这将减少我们已经有限的训练数据。
- en: We would also want to take a good look at the cases where the network does not
    perform as well as we’d like, to see if we can identify any pattern. But beyond
    that, let’s talk briefly about some general ways we could improve our project.
    In a way, this section is like section 8.5 in chapter 8\. We will endeavor to
    fill you with ideas to try; don’t worry if you don’t understand each in detail.[^(10)](#pgfId-1024600)
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望仔细研究网络表现不如我们期望的情况，看看是否能够识别出任何模式。但除此之外，让我们简要谈谈一些通用的方法，我们可以改进我们的项目。在某种程度上，这一部分就像第8章中的第8.5节。我们将努力为您提供尝试的想法；如果您不详细了解每个想法也不要担心。
- en: '14.7.1 Preventing overfitting: Better regularization'
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.7.1 防止过拟合：更好的正则化
- en: Reflecting on what we did throughout part 2, in each of the three problems--the
    classifiers in chapter 11 and section 14.5, as well as the segmentation in chapter
    13--we had overfitting models. Overfitting in the first case was catastrophic;
    we dealt with it by balancing the data and augmentation in chapter 12\. This balancing
    of the data to prevent overfitting has also been the main motivation to train
    the U-Net on crops around nodules and candidates rather than full slices. For
    the remaining overfitting, we bailed out, stopping training early when the overfitting
    started to affect our validation results. This means preventing or reducing overfitting
    would be a great way to improve our results.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾第2部分我们所做的事情，在三个问题中--第11章和第14.5节中的分类器，以及第13章中的分割--我们都有过拟合模型。在第一种情况下，过拟合是灾难性的；我们通过在第12章中平衡数据和增强来处理它。这种数据平衡以防止过拟合也是训练U-Net在结节和候选者周围的裁剪而不是完整切片的主要动机。对于剩余的过拟合，我们选择了退出，当过拟合开始影响我们的验证结果时提前停止训练。这意味着预防或减少过拟合将是改善我们结果的好方法。
- en: This pattern--get a model that overfits, and then work to reduce that overfitting--can
    really can be seen as a recipe.[^(11)](#pgfId-1024635) So this two-step process
    should be used when we want to improve on the state we have achieved now.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式--获得一个过拟合的模型，然后努力减少过拟合--实际上可以看作是一个配方。因此，当我们想要改进我们现在所取得的状态时，应该使用这种两步方法。
- en: Classic regularization and augmentation
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 经典正则化和增强
- en: You might have noticed that we did not even use all the regularization techniques
    from chapter 8\. For example, dropout would be an easy thing to try.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，我们甚至没有使用第8章中的所有正则化技术。例如，辍学将是一个容易尝试的事情。
- en: While we have some augmentation in place, we could go further. One relatively
    powerful augmentation method we did not attempt to employ is elastic deformations,
    where we put “digital crumples” into the inputs.[^(12)](#pgfId-1024679) This makes
    for much more variability than rotation and flipping alone and would seem to be
    applicable to our tasks as well.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经进行了一些增强，但我们可以走得更远。我们没有尝试使用的一个相对强大的增强方法是弹性变形，其中我们将“数字皱褶”放入输入中。这比仅仅旋转和翻转产生了更多的变化，似乎也适用于我们的任务。
- en: More abstract augmentation
  id: totrans-275
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更抽象的增强
- en: So far, our augmentation has been geometrically inspired--we transformed our
    input to more or less look like something plausible we might see. It turns out
    that we need not limit ourselves to that type of augmentation.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的增强受到几何启发--我们将输入转换为更或多或少看起来像我们可能看到的合理东西。事实证明，我们不必局限于这种类型的增强。
- en: Recall from chapter 8 that mathematically, the cross-entropy loss we have been
    using is a measure of the discrepancy between two probability distributions--that
    of the predictions and the distribution that puts all probability mass on the
    label and can be represented by the one-hot vector for the label. If overconfidence
    is a problem for our network, one simple thing we could try is not using the one-hot
    distribution but rather putting a small probability mass on the “wrong” classes.[^(13)](#pgfId-1024748)
    This is called *label smoothing*.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾第8章，从数学上讲，我们一直在使用的交叉熵损失是预测和将所有概率质量放在标签上的分布之间的差异度量，可以用标签的独热向量表示。如果我们的网络存在过度自信的问题，我们可以尝试的一个简单方法是不使用独热分布，而是在“错误”类别上放置一小部分概率质量。这被称为*标签平滑*。
- en: We can also mess with inputs and labels at the same time. A very general and
    also easy-to-apply augmentation technique for doing this has been proposed under
    the name of *mixup* :[^(14)](#pgfId-1024791) the authors propose to randomly interpolate
    both inputs and labels. Interestingly, with a linearity assumption for the loss
    (which is satisfied by binary cross entropy), this is equivalent to just manipulating
    the inputs with a weight drawn from an appropriately adapted distribution.[^(15)](#pgfId-1024805)
    Clearly, we don’t expect blended inputs to occur when working on real data, but
    it seems that this mixing encourages stability of the predictions and is very
    effective.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以同时处理输入和标签。一个非常通用且易于应用的增强技术被提出，名为*mixup*：作者建议随机插值输入和标签。有趣的是，在对损失进行线性假设（这由二元交叉熵满足）的情况下，这等效于仅使用从适当调整的分布中绘制的权重来操作输入。显然，在处理真实数据时，我们不希望出现混合输入，但似乎这种混合鼓励预测的稳定性并且非常有效。
- en: 'Beyond a single best model: Ensembling'
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 超越单一最佳模型：集成
- en: One perspective we could have on the problem of overfitting is that our model
    is capable of working the way we want if we knew the right parameters, but we
    don’t actually know them.[^(16)](#pgfId-1024846) If we followed this intuition,
    we might try to come up with several sets of parameters (that is, several models),
    hoping that the weaknesses of each might compensate for the other. This technique
    of evaluating several models and combining the output is called *ensembling*.
    Simply put, we train several models and then, in order to predict, run all of
    them and average the predictions. When each individual model overfits (or we have
    taken a snapshot of the model just before we started to see the overfitting),
    it seems plausible that the models might start to make bad predictions on different
    inputs, rather than always overfit the same sample first.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对过拟合问题的一个观点是，如果我们知道正确的参数，我们的模型可以按照我们想要的方式工作，但我们实际上并不知道这些参数。如果我们遵循这种直觉，我们可能��尝试提出几组参数（也就是几个模型），希望每个模型的弱点可以互相补偿。这种评估几个模型并组合输出的技术称为*集成*。简而言之，我们训练几个模型，然后为了预测，运行它们所有并平均预测。当每个单独模型过拟合时（或者我们在开始看到过拟合之前拍摄了模型的快照），似乎这些模型可能开始对不同的输入做出错误预测，而不总是首先过拟合相同的样本。
- en: 'In ensembling, we typically use completely separate training runs or even varying
    model structures. But if we were to make it particularly simple, we could take
    several snapshots of the model from a single training run--preferably shortly
    before the end or before we start to observe overfitting. We might try to build
    an ensemble of these snapshots, but as they will still be somewhat close to each
    other, we could instead average them. This is the core idea of *stochastic weight
    averaging*.[^(17)](#pgfId-1024897) We need to exercise some care when doing so:
    for example, when our models use batch normalization, we might want to adjust
    the statistics, but we can likely get a small accuracy boost even without that.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成中，我们通常使用完全独立的训练运行或者不同的模型结构。但如果我们想要简化，我们可以从单次训练运行中获取几个模型的快照--最好是在结束前不久或者在开始观察到过拟合之前。我们可以尝试构建这些快照的集成，但由于它们仍然相互接近，我们可以选择对它们进行平均。这就是*随机权重平均*的核心思想。我们在这样做时需要一些小心：例如，当我们的模型使用批量归一化时，我们可能需要调整统计数据，但即使没有这样做，我们也可能获得一些小的准确度提升。
- en: Generalizing what we ask the network to learn
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概括我们要求网络学习的内容
- en: We could also look at *multitask learning*, where we require a model to learn
    additional outputs beyond the ones we will then evaluate,[^(18)](#pgfId-1024951)
    which has a proven track record of improving results. We could try to train on
    nodule versus non-nodule and benign versus malignant at the same time. Actually,
    the data source for the malignancy data provides additional labeling we could
    use as additional tasks; see the next section. This idea is closely related to
    the transfer-learning concept we looked at earlier, but here we would typically
    train both tasks in parallel rather than first doing one and then trying to move
    to the next.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看看*多任务学习*，在这里我们要求模型学习除了我们将要评估的输出之外的额外输出，这已经被证明可以改善结果。我们可以尝试同时训练结节与非结节以及良性与恶性。实际上，恶性数据的数据源提供了我们可以用作额外任务的额外标签；请参见下一节。这个想法与我们之前看到的迁移学习概念密切相关，但在这里我们通常会同时训练两个任务，而不是先完成一个再尝试转移到下一个。
- en: If we do not have additional tasks but rather have a stash of additional unlabeled
    data, we can look into *semi-supervised learning*. An approach that was recently
    proposed and looks very effective is unsupervised data augmentation.[^(19)](#pgfId-1024987)
    Here we train our model as usual on the data. On the unlabeled data, we make a
    prediction on an unaugmented sample. We then take that prediction as the target
    for this sample and train the model to predict that target on the augmented sample
    as well. In other words, we don’t know if the prediction is correct, but we ask
    the network to produce consistent outputs whether we augment or not.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有额外的任务，而是有一堆额外的未标记数据，我们可以研究*半监督学习*。最近提出的一个看起来非常有效的方法是无监督数据增强。在这里，我们像往常一样在数据上训练我们的模型。在未标记数据上，我们对未增强的样本进行预测。然后我们将该预测作为该样本的目标，并训练模型在增强样本上也预测该目标。换句话说，我们不知道预测是否正确，但我们要求网络无论增强与否都产生一致的输出。
- en: When we run out of tasks of genuine interest but do not have additional data,
    we may look at making things up. Making up data is somewhat difficult (although
    people sometimes use GANs similar to the ones we briefly saw in chapter 2, with
    some success), so we instead make up tasks. This is when we enter the realm of
    *self-supervised learning*; the tasks are often called *pretext tasks*. A very
    popular crop of pretext tasks apply some sort of corruption to some of the inputs.
    Then we can train a network to reconstruct the original (for example, using a
    U-Net-like architecture) or train a classifier to detect real from corrupted data
    while sharing large parts of the model (such as the convolutional layers).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们没有更多感兴趣的任务但又没有额外数据时，我们可能会考虑捏造数据。捏造数据有些困难（尽管有时人们会使用类似第二章中简要介绍的 GANs，取得一定成功），因此我们选择捏造任务。这时我们进入了*自监督学习*的领域；这些任务通常被称为*借口任务*。一个非常流行的借口任务系列是对一些输入进行某种形式的破坏。然后我们可以训练一个网络来重建原始数据（例如，使用类似
    U-Net 结构）或者训练一个分类器来检测真实数据和破坏数据，同时共享模型的大部分部分（例如卷积层）。
- en: This is still dependent on us coming up with a way to corrupt our inputs. If
    we don’t have such a method in mind and aren’t getting the results we want, there
    are other ways to do self-supervised learning. A very generic task would be if
    the features the model learns are good enough to let the model discriminate between
    different samples of our dataset. This is called *contrastive learning*.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然取决于我们想出一种损坏输入的方法。如果我们没有这样的方法并且没有得到想要的结果，还有其他方法可以进行自监督学习。一个非常通用的任务是，如果模型学习的特征足够好，可以让模型区分数据集的不同样本。这被称为*对比学习*。
- en: 'To make things more concrete, consider the following: we take the extracted
    features from the current image and a largish number *K* of other images. This
    is our *key* set of features. Now we set up a classification pretext task as follows:
    given the features of the current image, the *query*, to which of the *K* + 1
    *key* features does it belong? This might seem trivial at first, but even if there
    is perfect agreement between the query features and the key features for the correct
    class, training on this task encourages the feature of the query to be maximally
    dissimilar from those of the *K* other images (in terms of being assigned low
    probability in the classifier output). Of course, there are many details to fill
    in; we recommend (somewhat arbitrarily) looking at momentum contrast.[^(20)](#pgfId-1025126)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更具体，考虑以下情况：我们从当前图像中提取的特征以及另外 *K* 张图像的特征。这是我们的*关键*特征集。现在我们设置一个分类前提任务如下：给定当前图像的特征，即*查询*，它属于
    *K* + 1 个*关键*特征中的哪一个？这乍一看可能很琐碎，但即使对于正确类别的查询特征和关键特征之间存在完美一致，训练这个任务也鼓励查询特征在分类器输出中被分配低概率时与
    *K* 其他图像的特征最大程度地不同。当然，还有许多细节需要填充；我们建议（有些是任意的）查看动量对比。[^(20)](#pgfId-1025126)
- en: 14.7.2 Refined training data
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.7.2 优化的训练数据
- en: 'We could improve our training data in a few ways. We mentioned earlier that
    the malignancy classification is actually based on a more nuanced categorization
    by several radiologists. An easy way to use the data we discarded by making it
    into the dichotomy “malignant or not?” would be to use the five classes. The radiologists’
    assessments could then be used as a smoothed label: we could one-hot-encode each
    one and then average over the assessments of a given nodule. So if four radiologists
    look at a nodule and two call it “indeterminate,” one calls that same nodule “moderately
    suspicious,” and the fourth labels it “highly suspicious,” we would train on the
    cross entropy between the model output and the target probability distribution
    given by the vector `0 0 0.5 0.25 0.25`. This would be similar to the label smoothing
    we mentioned earlier, but in a smarter, problem-specific way. We would, however,
    have to find a new way of evaluating these models, as we lose the simple accuracy,
    ROC, and AUC notions we have in binary classification.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过几种方式改进我们的训练数据。我们之前提到恶性分类实际上是基于几位放射科医生更细致的分类。通过将我们丢弃的数据转化为“恶性或非恶性？”的二分法，一个简单的方法是使用这五类。然后，放射科医生的评估可以用作平滑标签：我们可以对每个评估进行独热编码，然后对给定结节的评估进行平均。因此，如果四位放射科医生观察一个结节，其中两位称其为“不确定”，一位将同一结节称为“中度可疑”，第四位将其标记为“高度可疑”，我们将根据模型输出和目标概率分布之间的交叉熵进行训练，给定向量`0
    0 0.5 0.25 0.25`。这类似于我们之前提到的标签平滑，但以更智能、问题特定的方式。然而，我们必须找到一种新的评估这些模型的方法，因为我们失去了在二元分类中简单的准确性、ROC
    和 AUC 的概念。
- en: Another way to use multiple assessments would be to train a number of models
    instead of one, each trained on the annotations given by an individual radiologist.
    At inference we would then ensemble the models by, for example, averaging their
    output probabilities.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 利用多个评估的另一种方法是训练多个模型而不是一个，每个模型都是根据单个放射科医生给出的注释进行训练的。在推断时，我们可以通过例如平均它们的输出概率来集成模型。
- en: In the direction of multiple tasks mentioned earlier, we could again go back
    to the PyLIDC-provided annotation data, where other classifications are provided
    for each annotation (subtlety, internal structure, calcification, sphericity,
    margin definedness, lobulation, spiculation, and texture ([https://pylidc.github.io/annotation.html](https://pylidc.github.io/annotation.html)).
    We might have to learn a lot more about nodules, first, though.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前提到的多任务方向上，我们可以再次回到 PyLIDC 提供的注释数据，其中为每个注释提供了其他分类（微妙性、内部结构、钙化、球形度、边缘定义性、分叶、刺状和纹理
    ([https://pylidc.github.io/annotation.html](https://pylidc.github.io/annotation.html))）。不过，首先我们可能需要更多地了解结节。
- en: 'In the segmentation, we could try to see whether the masks provided by PyLIDC
    work better than those we generated ourselves. Since the LIDC data has annotations
    from multiple radiologists, it would be possible to group nodules into “high agreement”
    and “low agreement” groups. It might be interesting to see if that corresponds
    to “easy” and “hard” to classify nodules in terms of seeing whether our classifier
    gets almost all easy ones right and only has trouble on the ones that were more
    ambiguous to the human experts. Or we could approach the problem from the other
    side, by defining how difficult nodules are to detect in terms of our model performance:
    “easy” (correctly classified after an epoch or two of training), “medium” (eventually
    gotten right), and “hard” (persistently misclassified) buckets.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在分割中，我们可以尝试看看 PyLIDC 提供的掩模是否比我们自己生成的掩模效果更好。由于 LIDC 数据具有多位放射科医生的注释，可以将结节分组为“高一致性”和“低一致性”组。看看这是否对应于“易”和“难”分类的结节，即看看我们的分类器是否几乎完全正确地处理所有易处理的结节，只在那些对人类专家更模糊的结节上遇到困难。或者我们可以从另一方面解决问题，通过定义结节在我们的模型性能方面的检测难度：将其分为“易”（经过一两个训练周期后正确分类）、“中”（最终正确分类）和“难”（持续错误分类）三个桶。
- en: Beyond readily available data, one thing that would probably make sense is to
    further partition the nodules by malignancy type. Getting a professional to examine
    our training data in more detail and flag each nodule with a cancer type, and
    then forcing the model to report that type, could result in more efficient training.
    The cost to contract out that work is prohibitive for hobby projects, but paying
    might make sense in commercial contexts.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 除了现成的数据，一个可能有意义的事情是进一步按恶性类型对结节进行分区。让专业人士更详细地检查我们的训练数据，并为每个结节标记一个癌症类型，然后强制模型报告该类型，可能会导致更有效的训练。外包这项工作的成本对于业余项目来说是高昂的，但在商业环境中支付可能是合理的。
- en: Especially difficult cases could also be subject to a limited repeat review
    by human experts to check for errors. Again, that would require a budget but is
    certainly within reason for serious endeavors.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其困难的情况也可能会受到人类专家的有限重复审查，以检查错误。同样，这将需要预算，但对于认真的努力来说绝对是合理的。
- en: 14.7.3 Competition results and research papers
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.7.3比赛结果和研究论文
- en: Our goal in part 2 was to present a self-contained path from problem to solution,
    and we did that. But the particular problem of finding and classifying lung nodules
    has been worked on before; so if you want to dig deeper, you can also see what
    other people have done.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第2部分的目标是呈现从问题到解决方案的自包含路径，我们做到了。但是寻找和分类肺结节的特定问题以前已经���人研究过；因此，如果您想深入了解，您也可以看看其他人做了什么。
- en: Data Science Bowl 2017
  id: totrans-297
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Data Science Bowl 2017
- en: While we have limited the scope of part 2 to the CT scans in the LUNA dataset,
    there is also a wealth of information available from Data Science Bowl 2017 ([www.kaggle
    .com/c/data-science-bowl-2017](https://www.kaggle.com/c/data-science-bowl-2017)),
    hosted by Kaggle ([www.kaggle.com](https://www.kaggle.com/)). The data itself
    is no longer available, but there are many accounts of people describing what
    worked for them and what did not. For example, some of the Data Science Bowl (DSB)
    finalists reported that the detailed malignancy level (1...5) information from
    LIDC was useful during training.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将第2部分的范围限定在LUNA数据集中的CT扫描上，但在Data Science Bowl 2017（[www.kaggle .com/c/data-science-bowl-2017](https://www.kaggle.com/c/data-science-bowl-2017)）中也有大量信息可供参考，该比赛由Kaggle（[www.kaggle.com](https://www.kaggle.com/)）主办。数据本身已不再可用，但有许多人描述了对他们有效和无效的方法。例如，一些Data
    Science Bowl（DSB）的决赛选手报告说，来自LIDC的详细恶性程度（1...5）信息在训练过程中很有用。
- en: Two highlights you could look at are these:[^(21)](#pgfId-1026936)
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看的两个亮点是这些：[^(21)](#pgfId-1026936)
- en: 'Second-place solution write-up by Daniel Hammack and Julian de Wit: [http://
    mng.bz/Md48](http://mng.bz/Md48)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二名解决方案的撰写：Daniel Hammack和Julian de Wit [http:// mng.bz/Md48](http://mng.bz/Md48)
- en: 'Ninth-place solution write-up by Team Deep Breath: [http://mng.bz/aRAX](http://mng.bz/aRAX)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第九名解决方案的撰写：Team Deep Breath [http://mng.bz/aRAX](http://mng.bz/aRAX)
- en: '*Note* Many of the newer techniques we hinted at previously were not yet available
    to the DSB participants. The three years between the 2017 DSB and this book going
    to print are an eternity in deep learning!'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 我们之前暗示的许多新技术对DSB参与者尚不可用。2017年DSB和本书印刷之间的三年在深度学习领域是一个漫长的时间！'
- en: One idea for a more legitimate test set would be to use the DSB dataset instead
    of reusing our validation set. Unfortunately, the DSB stopped sharing the raw
    data, so unless you happen to have access to an old copy, you would need another
    data source.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更合理的测试集的一个想法是使用DSB数据集而不是重复使用我们的验证集。不幸的是，DSB停止分享原始数据，所以除非您碰巧有旧版本的副本，否则您需要另一个数据来源。
- en: LUNA papers
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LUNA论文
- en: The LUNA Grand Challenge has collected several results ([https://luna16.grand-challenge.org/Results](https://luna16.grand-challenge.org/Results))
    that show quite a bit of promise. While not all of the papers provided include
    enough detail to reproduce the results, many do contain enough information to
    improve our project. You could review some of the papers and attempt to replicate
    approaches that seem interesting.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: LUNA Grand Challenge已经收集了一些结果（[https://luna16.grand-challenge.org/Results](https://luna16.grand-challenge.org/Results)），显示出相当大的潜力。虽然并非所有提供的论文都包含足够的细节来重现结果，但许多论文确实包含了足够的信息来改进我们的项目。您可以查阅一些论文，并尝试复制看起来有趣的方法。
- en: 14.8 Conclusion
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.8 结论
- en: 'This chapter concludes part 2 and delivers on the promise we made back in chapter
    9: we now have a working, end-to-end system that attempts to diagnose lung cancer
    from CT scans. Looking back at where we started, we’ve come a long way and, hopefully,
    learned a lot. We trained a model to do something interesting and difficult using
    publicly available data. The key question is, “Will this be good for anything
    in the real world?” with the follow-up question, “Is this ready for production?”
    The definition of *production* critically depends on the *intended use*, so if
    we’re wondering whether our algorithm can replace an expert radiologist, this
    is definitely not the case. We’d argue that this can represent version 0.1 of
    a tool that could in the future support a radiologist during clinical routine:
    for instance, by providing a second opinion about something that could have gone
    unnoticed.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束了第2部分，并实现了我们在第9章中承诺的承诺：我们现在有一个可以尝试从CT扫描中诊断肺癌的工作端到端系统。回顾我们的起点，我们已经走了很长的路，希望也学到了很多。我们使用公开可用的数据训练了一个能够做出有趣且困难的事情的模型。关键问题是，“这对现实世界有好处吗？”随之而来的问题是，“这准备好投入生产了吗？”*生产*的定义关键取决于*预期用途*，因此，如果我们想知道我们的算法是否可以取代专业放射科医师，那肯定不是这种情况。我们认为这可以代表未来支持放射科医师在临床例行工作中的工具的0.1版本：例如，通过提供对可能被忽视的事项的第二意见。
- en: Such a tool would require clearance by regulatory bodies of competence (like
    the Food and Drug Administration in the United States) in order for it to be employed
    outside of research contexts. Something we would certainly be missing is an extensive,
    curated dataset to further train and, even more importantly, validate our work.
    Individual cases would need to be evaluated by multiple experts in the context
    of a research protocol; and a proper representation of a wide spectrum of situations,
    from common presentations to corner cases, would be mandatory.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的工具需要通过监管机构（如美国食品药品监督管理局）的批准，以便在研究环境之外使用。我们肯定会缺少一个广泛的、经过精心策划的数据集来进一步训练，甚至更重要的是验证我们的工作。个别案例需要在研究协议的背景下由多位专家评估；而对于各种情况的适当表达，从常见病例到边缘情况，都是必不可少的。
- en: All these cases, from pure research use to clinical validation to clinical use,
    would require us to execute our model in an environment amenable to be scaled
    up. Needless to say, this comes with its own set of challenges, both technical
    and in terms of process. We’ll discuss some of the technical challenges in chapter
    15.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些情况，从纯研究用途到临床验证再到临床使用，都需要我们在一个适合扩展的环境中执行我们的模型。不用说，这带来了一系列挑战，无论是技术上还是流程上。我们将在第15章讨论一些技术挑战。
- en: 14.8.1 Behind the curtain
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.8.1 幕后花絮
- en: 'As we close out the modeling in part 2, we want to pull back the curtain a
    bit and give you a glimpse at the unvarnished truth of working on deep learning
    projects. Fundamentally, this book has presented a skewed take on things: a curated
    set of obstacles and opportunities; a well-tended garden path through the larger
    wilds of deep learning. We think this semi-organic series of challenges (especially
    in part 2) makes for a better book, and we hope a better learning experience.
    It does not, however, make for a more *realistic* experience.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们结束第二部分的建模时，我们想拉开幕布，让你一窥在深度学习项目中工作的真相。从根本上说，这本书呈现了一种偏颇的看法：一系列经过策划的障碍和机会；一个经过精心呵护的花园小径，穿过深度学习的更广阔领域。我们认为这种半有机的挑战系列（尤其是第二部分）会使这本书更好，也希望会有更好的学习体验。然而，这并不意味着会有一个更*真实*的体验。
- en: In all likelihood, the vast majority of your experiments will not work out.
    Not every idea will be a discovery, and not every change will be a breakthrough.
    Deep learning is fiddly. Deep learning is fickle. And remember that deep learning
    is literally pushing at the forefront of human knowledge; it’s a frontier that
    we are exploring and mapping further every day, *right now*. It’s an exciting
    time to be in the field, but as with most fieldwork, you’re going to get some
    mud on your boots.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，你的大部分实验都不会成功。并非每个想法都会成为一个发现，也不是每个改变都会是一个突破。深度学习是棘手的。深度学习是善变的。请记住，深度学习实际上是在推动人类知识的前沿；这是我们每天都在探索和拓展的领域，*就在此刻*。现在是从事这个领域的激动人心的时刻，但就像大多数野外工作一样，你的靴子上总会沾上一些泥巴。
- en: 'In the spirit of transparency, here are some things that we tried, that we
    tripped over, that didn’t work, or that at least didn’t work well enough to bother
    keeping:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 符合透明度精神，这里有一些我们尝试过的、我们遇到困难的、不起作用的，或者至少不够好以至于不值得保留的事情：
- en: Using `HardTanh` instead of `Softmax` for the classification network (it was
    simpler to explain, but it didn’t actually work well).
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分类网络中使用`HardTanh`而不是`Softmax`（这样更容易解释，但实际上效果并不好）。
- en: Trying to fix the issues caused by `HardTanh` by making the classification network
    more complicated (skip connections, and so on).
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 试图通过使分类网络更复杂（跳跃连接等）来解决`HardTanh`引起的问题。
- en: Poor weight initialization causing training to be unstable, particularly for
    segmentation.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不良的权重初始化导致训练不稳定，特别是对于分割。
- en: Training on full CT slices for segmentation.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对完整的CT切片进行分割训练。
- en: Loss weighting for segmentation with SGD. It didn’t work, and Adam was needed
    for it to be useful.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SGD进行分割的损失加权。这并没有起作用，需要使用Adam才能使其有用。
- en: True 3D segmentation of CT scans. It didn’t work for us, but then DeepMind went
    and did it anyway.[^(22)](#pgfId-1027215) This was before we moved to cropping
    to nodules, and we ran out of memory, so you might try again based on the current
    setup.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CT扫描的真正三维分割。对我们来说不起作用，但DeepMind后来还是做到了。这是在我们转向裁剪到结节之前，我们的内存用完了，所以你可以根据当前的设置再试一次。
- en: Misunderstanding the meaning of the `class` column from the LUNA data, which
    caused some rewrites partway through authoring the book.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 误解LUNA数据中`class`列的含义，导致在撰写本书的过程中进行了一些重写。
- en: Accidentally leaving in an “I want results quickly” hack that threw away 80%
    of the candidate nodules found by the segmentation module, causing the results
    to look atrocious until we figured out what was going on (that cost an entire
    weekend!).
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无意中留下一个“我想快速获得结果”的技巧，导致分割模块找到的候选结节中有80%被丢弃，直到我们弄清楚问题所在（这花了整个周末！）。
- en: A host of different optimizers, loss functions, and model architectures.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列不同的优化器、损失函数和模型架构。
- en: Balancing the training data in various ways.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以各种方式平衡训练数据。
- en: There are certainly more that we’ve forgotten. A lot of things went wrong before
    they went right! Please learn from our mistakes.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们肯定还忘记了更多。很多事情在变得正确之前都出了错！请从我们的错误中学习。
- en: 'We might also add that for many things in this text, we just picked an approach;
    we emphatically *do not* imply that other approaches are inferior (many of them
    are probably better!). Additionally, coding style and project design typically
    differ a lot between people. In machine learning, it is very common for people
    to do a lot of programming in Jupyter Notebooks. Notebooks are a great tool to
    try things quickly, but they come with their own caveats: for example, around
    how to keep track of what you did. Finally, instead of using the caching mechanism
    we used with `prepcache`, we could have had a separate preprocessing step that
    wrote out the data as serialized tensors. Each of these approaches seems to be
    a matter of taste; even among the three authors, any one of us would do things
    slightly differently.[^(23)](#pgfId-1027314) It is always good to try things and
    find which one works best for you while remaining flexible when cooperating with
    your peers.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能还要补充一点，对于这篇文章中的许多内容，我们只是选择了一种方法；我们强调*并不*意味着其他方法不如（其中许多可能更好！）。此外，编码风格和项目设计在人们之间通常有很大的不同。在机器学习中，人们经常在Jupyter笔记本中进行大量编程。笔记本是一个快速尝试事物的好工具，但它们也有自己的注意事项：例如，如何跟踪你所做的事情。最后，与我们之前使用的`prepcache`缓存机制不同，我们可以有一个单独的预处理步骤，将数据写出为序列化张量。这些方法中的每一种似乎都是一种品味；即使在三位作者中，我们中的任何一位都会略有不同地做事情。尝试事物并找出哪种方法最适合你，同时在与同事合作时保持灵活性是很好的。
- en: 14.9 Exercises
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.9 练习
- en: Implement a test set for classification, or reuse the test set from chapter
    13’s exercises. Use the validation set to pick the best epochs while training,
    but use the test set to evaluate the end-to-end project. How well does performance
    on the validation set line up with performance on the test set?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为分类实现一个测试集，或者重用第13章练习中的测试集。在训练时使用验证集选择最佳时期，但在最终项目评估时使用测试集。验证集上的性能与测试集上的性能如何相匹配？
- en: Can you train a single model that is able to do three-way classification, distinguishing
    among non-nodules, benign modules, and malignant nodules in one pass?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能训练一个能够在一次传递中进行三路分类，区分非结节、良性结节和恶性结节的单一模型吗？
- en: What class-balancing split works best for training?
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么类平衡分割对训练效果最好？
- en: How does this single-pass model perform, compared to the two-pass approach we
    are using in the book?
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与我们在书中使用的两遍方法相比，这种单遍模型的表现如何？
- en: We trained our classifier on annotations, but expect it to perform on the output
    of our segmentation. Use the segmentation model to build a list of non-nodules
    to use during training instead of the non-nodules provided.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在注释上训练了我们的分类器，但期望它在我们分割的输出上表现。使用分割模型构建一个非结节的列表，用于训练，而不是提供的非结节。
- en: Does the classification model performance improve when trained on this new set?
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当在这个新集合上训练时，分类模型的性能是否有所提高？
- en: Can you characterize what kinds of nodule candidates see the biggest changes
    with the newly trained model?
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能描述哪种结节候选者在新训练的模型中看到了最大的变化吗？
- en: The padded convolutions we use result in less than full context near the edges
    of the image. Compute the loss for segmented pixels near the edges of the CT scan
    slice, versus those in the interior. Is there a measurable difference between
    the two?
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用的填充卷积导致图像边缘附近的上下文不足。计算CT扫描切片边缘附近分割像素的损失，与内部的损失相比。这两者之间是否有可测量的差异？
- en: Try running the classifier on the entire CT by using overlapping 32 × 48 × 48
    patches. How does this compare to the segmentation approach?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用重叠的32×48×48块在整个CT上运行分类器。这与分割方法相比如何？
- en: 14.10 Summary
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.10 总结
- en: An unambiguous split between training and validation (and test) sets is crucial.
    Here, splitting by patient is much less prone to getting things wrong. This is
    even more true when you have several models in your pipeline.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集和验证（以及测试）集之间的明确分割至关重要。在这里，按病人分割要比其他方式更不容易出错。当您的管道中有几个模型时，这一点更为真实。
- en: Getting from pixel-wise marks to nodules can be achieved using very traditional
    image processing. We don’t want to look down on the classics, but value these
    tools and use them where appropriate.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从像素标记到结节的转换可以通过非常传统的图像处理实现。我们不想看不起经典，但重视这些工具，并在适当的地方使用它们。
- en: Our diagnosis script performs both segmentation and classification. This allows
    us to diagnose a CT that we have not seen before, though our current `Dataset`
    implementation is not configured to accept `series_uid`s from sources other than
    LUNA.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的诊断脚本同时执行分割和分类。这使我们能够诊断我们以前没有见过的CT，尽管我们当前的`Dataset`实现未配置为接受来自LUNA以外来源的`series_uid`。
- en: Fine-tuning is a great way to fit a model while using a minimum of training
    data. Make sure the pretrained model has features relevant to your task, and make
    sure that you retrain a portion of the network with enough capacity.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调是在使用最少的训练数据的情况下拟合模型的好方法。确保预训练模型具有与您的任务相关的特征，并确保重新训练具有足够容量的网络的一部分。
- en: TensorBoard allows us to write out many different types of diagrams that help
    us determine what’s going on. But this is not a replacement for looking at data
    on which our model works particularly badly.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard允许我们编写许多不同类型的图表，帮助我们确定发生了什么。但这并不是查看我们的模型在哪些数据上表现特别糟糕的替代品。
- en: Successful training seems to involve an overfitting network at some stage, and
    which we then regularize. We might as well take that as a recipe; and we should
    probably learn more about regularization.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功的训练似乎在某个阶段涉及过拟合网络，然后我们对其进行正则化。我们可能也可以将其视为一种配方；我们可能应该更多地了解正则化。
- en: Training neural networks is about trying things, seeing what goes wrong, and
    improving on it. There usually isn’t a magic bullet.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练神经网络是尝试事物，看看出了什么问题，然后改进它。通常没有什么灵丹妙药。
- en: Kaggle is an excellent source of project ideas for deep learning. Many new datasets
    have cash prizes for the top performers, and older contests have examples that
    can be used as starting points for further experimentation.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle是深度学习项目创意的绝佳来源。许多新数据集为表现最佳者提供现金奖励，而旧的比赛则有可用作进一步实验起点的示例。
- en: '* * *'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)You can also use the p2_run_everything notebook.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1.)你也可以使用p2_run_everything笔记本。
- en: ^(2.)The size of any given nodule is highly variable, obviously.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ^(2.)任何给定结节的大小显然是高度可变的。
- en: ^(3.)We chose this series specifically because it has a nice mix of results.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: ^(3.)我们特意选择了这个系列，因为它有一个很好的结果混合。
- en: '^(4.)See the PyLIDC documentation for full details: [http://mng.bz/Qyv6](http://mng.bz/Qyv6).'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: ^(4.)查看PyLIDC文档以获取完整详情：[http://mng.bz/Qyv6](http://mng.bz/Qyv6)。
- en: ^(5.)Note that random predictions on a balanced dataset would result in an AUC
    of 0.5, so that gives us a floor for how good our classifier must be.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ^(5.)请注意，在平衡数据集上的随机预测将导致AUC为0.5，因此这为我们的分类器必须有多好提供了一个下限。
- en: ^(6.)You can try it yourself with the venerable German Traffic Sign Recognition
    Benchmark dataset at [http:// mng.bz/XPZ9](http://mng.bz/XPZ9).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ^(6.)你可以尝试使用受人尊敬的德国交通标志识别基准数据集，网址为[http:// mng.bz/XPZ9](http://mng.bz/XPZ9)。
- en: ^(7.)Most of the delay is from SciPy’s processing of the connected components.
    At the time of writing, we are not aware of an accelerated implementation.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ^(7.)大部分延迟来自于SciPy对连接组件的处理。在撰写本文时，我们还不知道有加速实现。
- en: ^(8.)Recall that our earlier “75% with almost no false positives” ROC number
    was looking at malignancy classification in isolation. Here we are filtering out
    seven malignant nodules before we even get to the malignancy classifier.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: ^(8.)请记住，我们之前的“几乎没有假阳性的75%” ROC 数字是针对恶性分类的孤立情况。在我们甚至进入恶性分类器之前，我们已经过滤掉了七个恶性结节。
- en: ^(9.)If it were, we’d have done that instead of writing this book!
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ^(9.)如果是这样的话，我们会选择这样做而不是写这本书！
- en: ^(10.)At least one of the authors would love to write an entire book on the
    topics touched on in this section.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ^(10.)至少有一位作者很愿意在本节涉及的主题上写一本完整的书。
- en: ^(11.)See also Andrej Karparthy’s blog post “A Recipe for Training Neural Networks”
    at [https://karpathy.github .io/2019/04/25/recipe](https://karpathy.github.io/2019/04/25/recipe)
    for a more elaborate recipe.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ^(11.)另请参阅Andrej Karparthy的博客文章“A Recipe for Training Neural Networks”，网址为[https://karpathy.github
    .io/2019/04/25/recipe](https://karpathy.github.io/2019/04/25/recipe)以获取更详细的配方。
- en: ^(12.)You can find a recipe (albeit aimed at TensorFlow) at [http://mng.bz/Md5Q](http://mng.bz/Md5Q).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: ^(12.)你可以在[http://mng.bz/Md5Q](http://mng.bz/Md5Q)找到一个配方（尽管是针对TensorFlow的）。
- en: ^(13.)You can use `nn.KLDivLoss` loss for this.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: ^(13.)你可以使用`nn.KLDivLoss`损失函数。
- en: '^(14.)Hongyi Zhang et al., “mixup: Beyond Empirical Risk Minimization,” [https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412).'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ^(14.)Hongyi Zhang等人，“mixup:超越经验风险最小化”，[https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412)。
- en: ^(15.)See Ferenc Huszár’s post at [http://mng.bz/aRJj/](http://mng.bz/aRJj/);
    he also provides PyTorch code.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ^(15.)请参阅Ferenc Huszár在[http://mng.bz/aRJj/](http://mng.bz/aRJj/)发布的文章；他还提供了PyTorch代码。
- en: ^(16.)We might expand that to be outright Bayesian, but we’ll just go with this
    bit of intuition.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ^(16.)我们可能会将其扩展为纯贝叶斯，但我们只会使用这一点直觉。
- en: ^(17.)Pavel Izmailov and Andrew Gordon Wilson present an introduction with PyTorch
    code at [http://mng.bz/gywe](http://mng.bz/gywe).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: ^(17.)Pavel Izmailov和Andrew Gordon Wilson在[http://mng.bz/gywe](http://mng.bz/gywe)提供了一个PyTorch代码的介绍。
- en: ^(18.)See Sebastian Ruder, “An Overview of Multi-Task Learning in Deep Neural
    Networks,” [https://arxiv.org/ abs/1706.05098](https://arxiv.org/abs/1706.05098);
    but this is also a key idea in many areas.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: ^(18.)请参阅Sebastian Ruder，“深度神经网络中多任务学习概述”，[https://arxiv.org/ abs/1706.05098](https://arxiv.org/abs/1706.05098)；但这也是许多领域的关键思想。
- en: ^(19.)Q. Xie et al., “Unsupervised Data Augmentation for Consistency Training,”
    [https://arxiv.org/abs/ 1904.12848](https://arxiv.org/abs/1904.12848).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ^(19.)Q. Xie等人，“无监督数据增强用于一致性训练”，[https://arxiv.org/abs/ 1904.12848](https://arxiv.org/abs/1904.12848)。
- en: ^(20.)K. He et al., “Momentum Contrast for Unsupervised Visual Representation
    Learning,” [https://arxiv.org/ abs/1911.05722](https://arxiv.org/abs/1911.05722).
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ^(20.)K. He等人，“动量对比用于无监督视觉表示学习”，[https://arxiv.org/ abs/1911.05722](https://arxiv.org/abs/1911.05722)。
- en: ^(21.)Thanks to the Internet Archive for saving them from redesigns.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ^(21.)感谢互联网档案馆将它们从重新设计中保存下来。
- en: ^(22.)Stanislav Nikolov et al., “Deep Learning to Achieve Clinically Applicable
    Segmentation of Head and Neck Anatomy for Radiotherapy,” [https://arxiv.org/pdf/1809.04430.pdf](https://arxiv.org/pdf/1809.04430.pdf)
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: ^(22.)Stanislav Nikolov等人，“用于放射治疗头颈解剖学临床适用分割的深度学习”，[https://arxiv.org/pdf/1809.04430.pdf](https://arxiv.org/pdf/1809.04430.pdf)
- en: ^(23.)Oh, the discussions we’ve had!
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: ^(23.)哦，我们进行过的讨论！
