- en: 16 Pretrained large
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 16 预训练大型
- en: language models and the LangChain library
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型和LangChain库
- en: This chapter covers
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using pretrained large language models for text, image, speech, and code generation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练大型语言模型进行文本、图像、语音和代码生成
- en: Few-shot, one-shot, and zero-shot prompting techniques
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少样本、单样本和零样本提示技术
- en: Creating a zero-shot personal assistant with LangChain
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LangChain创建零样本个人助理
- en: Limitations and ethical concerns of generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI的限制和伦理问题
- en: The rise of pretrained large language models (LLMs) has transformed the field
    of natural language processing (NLP) and generative tasks. OpenAI’s GPT series,
    a notable example, showcases the extensive capabilities of these models in producing
    life-like text, images, speech, and even code. The effective utilization of these
    pretrained LLMs is essential for several reasons. It enables us to deploy advanced
    AI functionalities without the need for vast resources to develop and train these
    models. Moreover, understanding these LLMs paves the way for innovative applications
    that leverage NLP and generative AI, fostering progress across various industries.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练大型语言模型（LLMs）的兴起已经改变了自然语言处理（NLP）和生成任务的领域。OpenAI的GPT系列是一个显著的例子，展示了这些模型在生成逼真文本、图像、语音甚至代码方面的广泛能力。有效利用这些预训练LLMs对于几个原因至关重要。它使我们能够在不开发这些模型的大量资源的情况下部署高级AI功能。此外，理解这些LLMs为利用NLP和生成AI的创新应用铺平了道路，促进了各个行业的进步。
- en: In a world increasingly influenced by AI, mastering the integration and customization
    of pretrained LLMs offers a crucial competitive advantage. As AI evolves, leveraging
    these sophisticated models becomes vital for innovation and success in the digital
    landscape.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个日益受到AI影响的世界上，掌握预训练大型语言模型（LLMs）的集成和定制提供了关键竞争优势。随着AI的发展，利用这些复杂的模型对于在数字领域的创新和成功变得至关重要。
- en: Typically, these models are operated through browser-based interfaces, which
    vary across different LLMs that function independently of each other. Each model
    has unique strengths and specialties. Interfacing through a browser limits our
    ability to fully take advantage of the potential of each specific LLM. Utilizing
    programming languages like Python, particularly through tools such as the LangChain
    library, provides substantial benefits for the following reasons.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些模型通过基于浏览器的界面操作，这些界面在不同的LLMs之间有所不同，这些LLMs独立于彼此运行。每个模型都有其独特的优势和专长。通过浏览器进行接口限制了我们对每个特定LLM潜力的充分利用。利用Python等编程语言，尤其是通过LangChain库等工具，提供了以下原因的实质性好处。
- en: Python’s role in interacting with LLMs enhances the automation of workflows
    and processes. Python scripts, capable of running autonomously, facilitate uninterrupted
    operations without the need for manual input. This is especially beneficial for
    businesses that regularly handle large amounts of data. For instance, a Python
    script could autonomously generate monthly reports by querying an LLM, synthesizing
    the data insights, and disseminating these findings via email or into a database.
    Python offers a greater level of customization and control in managing interactions
    with LLMs than browser-based interfaces do, enabling us to craft custom code to
    meet specific operational needs such as implementing conditional logic, processing
    multiple requests in loops, or managing exceptions. This adaptability is essential
    for customizing outputs to meet particular business objectives or research inquiries.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Python在交互LLMs中的作用增强了工作流程和过程的自动化。能够自主运行的Python脚本，无需手动输入即可实现不间断的运行。这对那些经常处理大量数据的业务特别有益。例如，一个Python脚本可以通过查询LLM、综合数据洞察并将这些发现通过电子邮件或数据库传播来自主生成月度报告。Python在管理LLMs交互方面提供了比基于浏览器的界面更高的定制和控制水平，使我们能够编写定制代码以满足特定的操作需求，如实现条件逻辑、在循环中处理多个请求或管理异常。这种适应性对于定制输出以满足特定的商业目标或研究查询至关重要。
- en: Python’s extensive collection of libraries makes it ideally suited for integrating
    LLMs with existing software and systems. A prime example of this is the LangChain
    library, which extends Python’s functionality with LLMs. LangChain enables the
    combination of multiple LLMs or the integration of LLM capabilities with other
    services, such as the Wikipedia API or the Wolfram Alpha API, which will be covered
    later in this chapter. This capability of “chaining” different services allows
    for the construction of sophisticated, multistep AI systems where tasks are segmented
    and handled by the best-suited models or services, enhancing both performance
    and accuracy.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python丰富的库集合使其非常适合将LLMs与现有软件和系统集成。LangChain库就是这样一个典型的例子，它通过LLMs扩展了Python的功能。LangChain允许组合多个LLMs或将LLM功能与其他服务（如Wikipedia
    API或Wolfram Alpha API）集成，这些内容将在本章后面进行介绍。这种“链式”不同服务的能力允许构建复杂的、多步骤的AI系统，其中任务被分割并由最适合的模型或服务处理，从而提高性能和准确性。
- en: 'To that end, in this chapter, you’ll first learn how to use the OpenAI API
    to create various content using Python programming: text, images, speech, and
    Python code. You’ll also learn the difference between few-shot, one-shot, and
    zero-shot content generation. Few-shot prompting means you give the model multiple
    examples to help it understand the task, while one-shot or zero-shot prompting
    means one example or no example is provided.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，你将首先学习如何使用OpenAI API通过Python编程创建各种内容：文本、图像、语音和Python代码。你还将了解少量示例、单次示例和零示例内容生成的区别。少量示例提示意味着你给出多个示例以帮助模型理解任务，而单次或零示例提示则意味着提供一个示例或没有示例。
- en: Modern LLMs such as ChatGPT are trained on preexisting knowledge a few months
    ago so they cannot provide recent or real-time information such as weather conditions,
    flight status, or stock prices. You’ll learn to combine LLMs with Wolfram Alpha
    and Wikipedia APIs using the LangChain library to create a zero-shot know-it-all
    personal assistant.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现代LLMs，如ChatGPT，是在几个月前基于现有知识进行训练的，因此它们无法提供如天气状况、航班状态或股价等最新或实时信息。你将学习如何使用LangChain库将LLMs与Wolfram
    Alpha和Wikipedia API结合使用，创建一个零示例的全知个人助理。
- en: Despite LLMs’ impressive capabilities, they do not possess an intrinsic understanding
    of the content. This can lead to errors in logic, factual inaccuracies, and a
    failure to grasp complex concepts or nuances. The rapid advancement and widespread
    application of these models also lead to various ethical concerns such as bias,
    misinformation, privacy, and copyright. These issues demand careful consideration
    and proactive measures to ensure that the development and deployment of LLMs align
    with ethical standards and societal values.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs具有令人印象深刻的性能，但它们并不具备对内容内容的内在理解。这可能导致逻辑错误、事实不准确，以及无法掌握复杂概念或细微差别。这些模型的快速发展和广泛应用也引发了各种伦理问题，如偏见、错误信息、隐私和版权。这些问题需要仔细考虑和采取主动措施，以确保LLMs的开发和部署符合伦理标准和社会主义核心价值观。
- en: 16.1 Content generation with the OpenAI API
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.1 使用OpenAI API进行内容生成
- en: While there are other LLMs such as Meta’s LLAMA and Google’s Gemini, OpenAI’s
    GPT series is the most prominent one. We therefore use OpenAI GPTs as our examples
    in this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然还有其他LLMs，如Meta的LLAMA和Google的Gemini，但OpenAI的GPT系列是最突出的。因此，在本章中，我们将使用OpenAI
    GPTs作为示例。
- en: OpenAI allows you to use LLMs to generate various content such as text, images,
    audio, and code. You can access their service either through a web browser or
    an API. We’ll focus on content generation with Python programs via an API in this
    chapter due to the advantages of interacting with LLMs using Python mentioned
    earlier.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI允许你使用LLMs生成各种内容，如文本、图像、音频和代码。你可以通过网页浏览器或API访问他们的服务。由于之前提到使用Python与LLMs交互的优势，本章将重点介绍通过API使用Python程序进行内容生成。
- en: You do need your OpenAI API key for the programs in this chapter to work. I
    assume you have already obtained your API key in chapter 15\. If not, go back
    to chapter 15 for detailed instructions on how to get one.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你确实需要本章程序中的OpenAI API密钥才能运行。我假设你已经在第15章中获得了你的API密钥。如果没有，请回到第15章，获取获取API密钥的详细说明。
- en: I’ll focus mainly on text generation in this section but will provide an example
    for each of the cases of code, image, and speech generation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将主要关注文本生成，但将为代码、图像和语音生成的每个案例提供一个示例。
- en: 'This chapter involves the use of several new Python libraries. To install them,
    run the following lines of code in a new cell in your Jupypter Notebook app on
    your computer:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涉及使用几个新的Python库。要在您的计算机上的Jupyter Notebook应用的新单元格中安装它们，请运行以下代码行：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Follow the on-screen instructions to finish the installation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 按照屏幕上的说明完成安装。
- en: 16.1.1 Text generation tasks with OpenAI API
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.1 使用OpenAI API进行文本生成任务
- en: You can generate text for many different purposes, such as question-answering,
    text summarization, and creative writing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以生成用于多种目的的文本，例如问答、文本摘要和创意写作。
- en: When you ask OpenAI GPT a question, keep in mind that all LLMs, including OpenAI
    GPTs, are trained on historical data gathered through automated web crawling.
    As of this writing, GPT-4 was trained using data up to December 2023, with a three-month
    lag. GPT-3.5 was trained on data up to September 2021.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当您向OpenAI GPT提问时，请记住，所有LLM，包括OpenAI GPT，都是通过自动化网络爬取收集的历史数据训练的。截至本文撰写时，GPT-4使用截至2023年12月的数据进行训练，存在三个月的滞后。GPT-3.5使用截至2021年9月的数据进行训练。
- en: Let’s first ask GPT a question about historical facts. Enter the lines of code
    in the following listing in a new cell.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先向GPT提问有关历史事实的问题。在新的单元格中输入以下代码行。
- en: Listing 16.1 Checking historical facts with OpenAI API
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表16.1 使用OpenAI API检查历史事实
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Provides your OpenAI API key
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ① 提供您的OpenAI API密钥
- en: ② Creates an OpenAI() class instance and names it client
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ② 创建一个名为client的OpenAI()类实例
- en: ③ Defines the role of the system
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 定义系统的角色
- en: ④ Asks the question
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 提出问题
- en: Make sure you provide your OpenAI API key in the listing 16.1\. We first instantiate
    the `OpenAI()` class and call it `client`. In the `chat.completions.create()`
    method, we specify the model as `gpt-3.5-turbo`. The site [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
    provides various models available. You can use either gpt-4 or gpt-3.5-turbo for
    text generation. The former provides better results but also incurs higher expenses.
    We’ll use the latter for most cases since our examples are simple enough, so it
    provides equally good results.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在列表16.1中提供您的OpenAI API密钥。我们首先实例化`OpenAI()`类，并将其命名为`client`。在`chat.completions.create()`方法中，我们指定模型为`gpt-3.5-turbo`。网站[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)提供了各种可用的模型。您可以使用gpt-4或gpt-3.5-turbo进行文本生成。前者提供更好的结果，但费用也更高。由于我们的示例足够简单，我们将使用后者，因为它提供同样好的结果。
- en: The `messages` parameter in the preceding code block consists of several message
    objects, with each object containing a role (which can be “system,” “user,” or
    “assistant”) and content. A system message determines the assistant’s behavior;
    absent a system message, the default setting characterizes the assistant as “a
    helpful assistant.” User messages include inquiries or remarks for the assistant
    to address. For instance, in the previous example, the user message is “Who won
    the Nobel Prize in Economics in 2000?” The output is
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个代码块中的`messages`参数由几个消息对象组成，每个对象包含一个角色（可以是“system”、“user”或“assistant”）和内容。系统消息决定了助手的行为了；如果没有系统消息，默认设置将助手描述为“一个有用的助手”。用户消息包括助手需要处理的询问或评论。例如，在先前的例子中，用户消息是“2000年谁获得了诺贝尔经济学奖？”输出如下
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: OpenAI has provided the correct answer.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI提供了正确答案。
- en: 'You can also ask the LLM to write an essay on a certain topic. Next, we ask
    it to write a short essay on the importance of self-motivation:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以要求LLM就某个特定主题撰写文章。接下来，我们要求它撰写一篇关于自我激励重要性的短文：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `n=1` argument here tells the assistant to generate one response. If you
    want multiple responses, you can set n to a different number. The default value
    for n is 1\. The output is
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`n=1`参数告诉助手生成一个响应。如果您想要多个响应，可以将n设置为不同的数字。n的默认值是1。输出如下
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The output is six paragraphs long, and I have included only the first few sentences.
    You can go to the book’s GitHub repository ([https://github.com/markhliu/DGAI](https://github.com/markhliu/DGAI))
    to see the whole essay. As you can see, the writing is coherent, to the point,
    and without grammatical errors.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 输出共有六段，我只包括了前几句话。您可以访问书籍的GitHub仓库([https://github.com/markhliu/DGAI](https://github.com/markhliu/DGAI))查看全文。如您所见，文章结构清晰，观点明确，且没有语法错误。
- en: 'You can even ask OpenAI’s GPT to write a joke for you:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您甚至可以要求OpenAI的GPT为您写一个笑话：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We asked it to tell a math joke, and the result is
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求它讲一个数学笑话，结果是
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can carry out back-and-forth conversations with the assistant. The messages
    parameter automatically includes conversation history. For example, after running
    the previous code block, if you run the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以与助手进行双向对话。messages参数自动包括对话历史。例如，在运行前面的代码块之后，如果您运行以下代码：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: you’ll get a response similar to
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您将得到一个类似的响应
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The user’s query “Haha, that’s funny! Tell me another one.” only makes sense
    in the context of the prior messages where you ask the assistant to tell a math
    joke. Other text generation capabilities include text summarization and classification,
    and you’ll see such examples later in the chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 用户的查询“哈哈，这很有趣！再给我讲一个。”只有在您要求助手讲一个数学笑话的前言消息的上下文中才有意义。其他文本生成能力包括文本摘要和分类，您将在本章后面看到这样的例子。
- en: 16.1.2 Code generation with OpenAI API
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.2 使用OpenAI API生成代码
- en: Codex is specifically designed to understand and generate code. It can work
    with multiple programming languages and can translate natural language descriptions
    into code. Codex is now an integrated part of OpenAI GPTs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Codex专门设计用于理解和生成代码。它可以与多种编程语言一起工作，并将自然语言描述转换为代码。Codex现在是OpenAI GPTs的集成部分。
- en: 'Next, we ask OpenAI GPT to produce a Python program to plot a sine curve:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要求OpenAI GPT生成一个Python程序来绘制正弦曲线：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that ChatGPT uses GPT-3.5-Turbo to manage both the conversational aspect
    and the code generation tasks effectively. It does not provide a separate Codex
    model for code generation only. The output is
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，ChatGPT使用GPT-3.5-Turbo有效地管理对话方面和代码生成任务。它不只为代码生成提供单独的Codex模型。输出如下
- en: '[PRE10]python'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10]python'
- en: import matplotlib.pyplot as plt
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: import numpy as np
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: Generate x values from 0 to 2*pi
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从0到2*pi生成x值
- en: x = np.linspace(0, 2*np.pi, 100)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: x = np.linspace(0, 2*np.pi, 100)
- en: Calculate y values using the sine function
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正弦函数计算y值
- en: y = np.sin(x)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: y = np.sin(x)
- en: Plot the sine graph
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制正弦图
- en: plt.figure()
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: plt.figure()
- en: plt.plot(x, y)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: plt.plot(x, y)
- en: plt.title('Sine Graph')
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: plt.title('正弦图')
- en: plt.xlabel('x')
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: plt.xlabel('x')
- en: plt.ylabel('sin(x)')
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: plt.ylabel('sin(x)')
- en: plt.grid(True)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: plt.grid(True)
- en: plt.show()
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If you copy and paste the generated Python program into a cell in Jupyter Notebook
    and run it, you’ll see an image similar to figure 16.1.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将生成的Python程序复制并粘贴到Jupyter Notebook中的一个单元中并运行它，您将看到一个类似于图16.1的图像。
- en: '![](../../OEBPS/Images/CH16_F01_Liu.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F01_Liu.png)'
- en: Figure 16.1 Use OpenAI GPT-3.5 to generate Python code to plot a sine curve.
    We use the text description “Write a Python program to plot a sine graph” to ask
    it to generate a Python program. We then run the program to create the graph.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.1 使用OpenAI GPT-3.5生成Python代码绘制正弦曲线。我们使用文本描述“编写一个Python程序绘制正弦图”来请求它生成一个Python程序。然后我们运行程序来创建图表。
- en: The LLM not only provides the Python code, but it also lets you know that you
    need to run the code in a Python environment with the matplotlib library installed.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: LLM不仅提供了Python代码，还让您知道您需要在安装了matplotlib库的Python环境中运行代码。
- en: 16.1.3 Image generation with OpenAI DALL-E 2
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.3 使用OpenAI DALL-E 2生成图像
- en: DALL-E 2 is an AI model developed by OpenAI, designed to generate images from
    textual descriptions. It is a successor to the original DALL-E model and represents
    advancements in the field of generative AI for visual content.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 2是由OpenAI开发的一个AI模型，旨在根据文本描述生成图像。它是原始DALL-E模型的继承者，代表了在视觉内容生成AI领域的进步。
- en: DALL-E 2 uses a diffusion model similar to what we discussed in chapter 15,
    which starts with a random pattern of pixels and gradually refines it into a coherent
    image that matches the input text. It has improved upon the original DALL-E by
    producing higher-quality images with more accurate and detailed representations
    of the textual descriptions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 2使用了一种类似于我们在第15章讨论的扩散模型，它从随机的像素模式开始，并逐渐将其细化成一个与输入文本相匹配的连贯图像。它通过产生更高质量、更准确和更详细的文本描述图像来改进了原始的DALL-E。
- en: 'Incorporating DALL-E 2 into OpenAI’s GPT series allows us to not only generate
    text but also create images based on text prompts. Next, we ask DALL-E 2 to create
    an image of someone fishing at the riverbank:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将DALL-E 2集成到OpenAI的GPT系列中，使我们不仅能够生成文本，还能根据文本提示创建图像。接下来，我们要求DALL-E 2创建一个河岸上钓鱼的人的图像：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The code block generates a URL. If you click on the URL, you’ll see an image
    similar to figure 16.2.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块生成一个URL。如果您点击该URL，您将看到一个类似于图16.2的图像。
- en: '![](../../OEBPS/Images/CH16_F02_Liu.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F02_Liu.png)'
- en: Figure 16.2 An image generated by DALL-E 2 with the text prompt “someone fishing
    at the riverbank”
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.2 使用文本提示“有人在河岸钓鱼”生成的 DALL-E 2 图像
- en: The URL expires in an hour, so make sure you access it promptly. Furthermore,
    the image generated by DALL-E 2 is slightly different even if you use the same
    text prompt because the output is randomly generated.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: URL 在一小时后过期，所以请确保你及时访问它。此外，即使使用相同的文本提示，DALL-E 2 生成的图像也可能略有不同，因为输出是随机生成的。
- en: 16.1.4 Speech generation with OpenAI API
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.1.4 使用 OpenAI API 进行语音生成
- en: 'Text-to-speech (TTS) is a technology that converts written text into spoken
    words. TTS is trained through multimodal Transformers in which the input is text
    and the output is in audio format. In the context of ChatGPT, integrating TTS
    capabilities means that the LLM can not only generate textual responses but can
    also speak them out loud. Next, we ask OpenAI API to convert a short text into
    speech:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到语音（TTS）是一种将书面文本转换为语音的技术。TTS 通过多模态 Transformer 进行训练，其中输入是文本，输出是音频格式。在 ChatGPT
    的背景下，集成 TTS 功能意味着 LLM 不仅能够生成文本响应，还可以大声说出这些响应。接下来，我们请求 OpenAI API 将一段简短文本转换为语音：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: After running the previous code cell, a file, speech.mp3, is saved on your computer,
    and you can listen to it. The documentation site ([https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech))
    provides voice options. Here we have chosen the `shimmer` option. Other options
    include `alloy`, `echo`, and so on.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的代码单元后，会在你的电脑上保存一个名为 speech.mp3 的文件，你可以听一下。文档网站（[https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech)）提供了语音选项。这里我们选择了
    `shimmer` 选项。其他选项包括 `alloy`、`echo` 等等。
- en: 16.2 Introduction to LangChain
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.2 LangChain 简介
- en: LangChain is a Python library designed to facilitate the use of LLMs in various
    applications. It provides a suite of tools and abstractions that make it easier
    to build, deploy, and manage applications powered by LLMs like GPT-3, GPT-4, and
    other similar models.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个 Python 库，旨在简化 LLM 在各种应用中的使用。它提供了一套工具和抽象，使得构建、部署和管理由 LLM（如 GPT-3、GPT-4
    以及其他类似模型）驱动的应用程序变得更加容易。
- en: LangChain abstracts away the complexities of interacting with different LLMs
    and applications, allowing developers to focus on building their application logic
    without worrying about the underlying model specifics. It is particularly well
    suited for building a “know-it-all” agent by chaining together an LLM with applications
    like Wolfram Alpha and Wikipedia that can provide real-time information or recent
    facts. LangChain’s modular architecture allows for easy integration of different
    components, enabling the agent to leverage the strengths of various LLMs and applications.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 抽象掉了与不同 LLM 和应用交互的复杂性，使得开发者可以专注于构建他们的应用程序逻辑，而无需担心底层模型的具体细节。它特别适合通过将
    LLM 与如 Wolfram Alpha 和 Wikipedia 这样的应用链接起来，构建一个“全知全能”的代理，这些应用可以提供实时信息或最近的事实。LangChain
    的模块化架构允许轻松集成不同的组件，使代理能够利用各种 LLM 和应用的优势。
- en: 16.2.1 The need for the LangChain library
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.1 LangChain 库的需求
- en: Imagine that your goal is to build a zero-shot know-it-all agent so that it
    can produce various content, retrieve real-time information, and answer factual
    questions for us. You want the agent to automatically go to the right source to
    retrieve the relevant information based on the task at hand without explicitly
    telling it what to do. The LangChain library is the right tool for this.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你的目标是构建一个零样本的全知全能代理，使其能够生成各种内容，检索实时信息，并为我们回答事实性问题。你希望代理能够根据当前任务自动前往正确的来源检索相关信息，而无需明确告诉它要做什么。LangChain
    库正是这个任务的正确工具。
- en: In this project, you’ll learn to use the LangChain library to combine LLMs with
    the Wolfram Alpha and Wikipedia APIs to create a zero-shot know-it-all agent.
    We use Wolfram Alpha API to retrieve real-time information and the Wikipedia API
    to answer questions about recent facts. LangChain allows us to create an agent
    to utilize multiple tools to answer a question. The agent first understands the
    query and then decides which tool in the toolbox to use to answer the question.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，你将学习如何使用 LangChain 库将 LLM 与 Wolfram Alpha 和 Wikipedia API 结合起来，创建一个零样本的全知全能代理。我们使用
    Wolfram Alpha API 检索实时信息，使用 Wikipedia API 回答关于最近事实的问题。LangChain 允许我们创建一个代理，利用多个工具来回答问题。代理首先理解查询，然后决定在工具箱中使用哪个工具来回答问题。
- en: 'To show you that even the most advanced LLMs lack these abilities, let’s ask
    who won the Best Actor Award in the 2024 Academy Awards:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示即使是功能最先进的LLMs也缺乏这些能力，让我们来问一下2024年奥斯卡最佳男主角奖的获得者是谁：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The output is
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: I made this query on March 17, 2024, and GPT-4 was not able to answer the question.
    It’s possible that when you make the same query, you’ll get the correct answer
    because the model has been updated using more recent data. If that’s the case,
    change the question to an event a few days ago, and you should get a similar response.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我在2024年3月17日提出了这个查询，GPT-4无法回答这个问题。有可能当你提出相同的查询时，你会得到正确的答案，因为模型已经使用更近期的数据进行更新。如果那样的话，将问题改为几天前的事件，你应该会得到类似的回答。
- en: Therefore, we’ll use LangChain to chain together an LLM with the Wolfram Alpha
    and Wikipedia APIs. Wolfram Alpha is good at scientific computations and retrieving
    real-time information, while Wikipedia is famous for providing information on
    both historical and recent events and facts.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用LangChain将LLM与Wolfram Alpha和Wikipedia API链在一起。Wolfram Alpha擅长科学计算和检索实时信息，而Wikipedia则以提供历史和近期事件及事实的信息而闻名。
- en: 16.2.2 Using the OpenAI API in LangChain
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.2 在LangChain中使用OpenAI API
- en: The langchain-openai library you installed earlier in this chapter allows you
    to use OpenAI GPTs with minimal prompt engineering. You only need to explain what
    you want the LLM to do in plain English.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本章早期安装的langchain-openai库允许你以最少的提示工程使用OpenAI GPTs。你只需要用普通的英语解释你希望LLM做什么。
- en: 'Here is an example of how we ask it to correct grammar errors in text:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个例子，展示我们如何要求它纠正文本中的语法错误：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The output is
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that we didn’t use any prompt engineering. We didn’t specify which model
    to use either. LangChain found the best model for the job based on the task requirements
    and other factors such as cost, latency, and performance. It also automatically
    formats and structures the queries to be suitable for the model it uses. The preceding
    prompt simply asks the agent, in plain English, to correct the grammar errors
    in the text. It returns text with the correct grammar, as shown in the previous
    output.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们没有使用任何提示工程。我们也没有指定使用哪个模型。LangChain根据任务要求和其他因素（如成本、延迟和性能）找到了最适合的模型。它还自动格式化和结构化查询，使其适合使用的模型。前面的提示只是简单地要求代理用普通的英语纠正文本中的语法错误。它返回了语法正确的文本，如前一个输出所示。
- en: 'Here is another example. We asked the agent to name the capital city of Kentucky:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是另一个例子。我们要求代理说出肯塔基州的首府：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The output is
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It tells us the correct answer, which is Frankfort, Kentucky.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 它告诉我们正确的答案，即肯塔基州的法兰克福。
- en: 16.2.3 Zero-shot, one-shot, and few-shot prompting
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.3 零样本、单样本和少样本提示
- en: Few-shot, one-shot, and zero-shot prompting refer to different ways of providing
    examples or instructions to LLMs to guide their responses. These techniques are
    used to help the model understand the task at hand and generate more accurate
    or relevant outputs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本、单样本和零样本提示指的是向LLMs提供示例或指令的不同方式，以指导它们的响应。这些技术用于帮助模型理解当前的任务，并生成更准确或相关的输出。
- en: In zero-shot prompting, the model is given a task or a question without any
    examples. The prompt typically includes a clear description of what is expected,
    but the model must generate a response based solely on its preexisting knowledge
    and understanding. In one-shot prompting, the model is provided with a single
    example to illustrate the task. In few-shot prompting, the model is given multiple
    examples to help it understand the task. Few-shot prompting is based on the idea
    that providing more examples can help the model better grasp the pattern or the
    rules of the task, leading to more accurate responses.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在零样本提示中，模型被赋予一个任务或问题，但没有提供任何示例。提示通常包括对预期的明确描述，但模型必须仅基于其先验知识和理解来生成响应。在单样本提示中，模型提供了一个示例来展示任务。在少样本提示中，模型被提供了多个示例以帮助它理解任务。少样本提示基于这样的理念：提供更多示例可以帮助模型更好地掌握任务的模式或规则，从而产生更准确的响应。
- en: All your interactions so far with OpenAI GPTs are zero-shot prompting since
    you haven’t provided them with any examples.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你与OpenAI GPTs的所有交互都是零样本提示，因为你没有向它们提供任何示例。
- en: 'Let’s try an example of few-shot prompting. Suppose you want the LLM to conduct
    sentiment analysis: you want it to classify a sentence as positive or negative.
    You can provide several examples in the prompt:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个少样本提示的例子。假设你想让 LLM 进行情感分析：你希望它将句子归类为正面或负面。你可以在提示中提供几个示例：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The output is
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the prompt, we provided three examples. Two reviews are classified as positive,
    while one is classified as negative. We then provided the sentence, “How horrible
    the movie is!” The LLM classified it correctly as negative.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示中，我们提供了三个示例。其中两个评论被归类为正面，而另一个被归类为负面。然后我们提供了句子，“这部电影多么糟糕！”LLM 正确将其归类为负面。
- en: We used `//` to separate the sentence and the corresponding sentiment in the
    previous example. You can use other separators such as `->`, so long as you are
    consistent.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中，我们使用 `//` 来分隔句子和相应的情感。你可以使用其他分隔符，如 `->`，只要保持一致即可。
- en: 'Here is an example of one-shot prompting:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个单样本提示的例子：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The output is
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By providing one single example, we are effectively asking the LLM, “What is
    to a plane as a driver is to a car?” The LLM correctly answered `Pilot`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供一个单一示例，我们实际上是在询问 LLM，“飞机对驾驶员来说就像汽车对驾驶员一样？”LLM 正确回答了“飞行员”。
- en: Exercise 16.1
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 16.1
- en: Suppose you want to ask the LLM, “What is to a garden as a chef is to a kitchen?”
    Use one-shot prompting to get the answer.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想问 LLM，“花园对厨师来说就像厨房对厨师一样？”使用单样本提示来获取答案。
- en: 'Finally, here is an example of zero-shot prompting:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这里是一个零样本提示的例子：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The output is
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We didn’t provide any examples in the prompt. However, we provided instruction
    in plain English to ask the LLM to classify the tone in the sentence as positive,
    negative, or neutral.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在提示中没有提供任何示例。然而，我们用简单的英语指令要求 LLM 将句子的语气归类为正面、负面或中性。
- en: 16.3 A zero-shot know-it-all agent in LangChain
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.3 LangChain 中的零样本全知全能代理
- en: You’ll learn to create a zero-shot know-it-all agent in LangChain in this section.
    You’ll use OpenAI GPTs to generate various content such as text, images, and code.
    To compensate for LLM’s inability to provide real-time information, you’ll learn
    to add Wolfram Alpha and Wikipedia APIs to the toolbox.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何在 LangChain 中创建一个零样本的全知全能代理。你将使用 OpenAI GPTs 生成各种内容，如文本、图像和代码。为了弥补
    LLM 无法提供实时信息的能力，你将学习如何将 Wolfram Alpha 和 Wikipedia API 添加到工具箱中。
- en: Wolfram Alpha is a computational knowledge engine designed to handle factual
    queries online, specializing in numerical and computational tasks, particularly
    in the science and technology fields. By integrating the Wolfram Alpha API, the
    agent gains the ability to answer virtually any question across various subjects.
    Should Wolfram Alpha be unable to provide a response, we will use Wikipedia as
    a secondary source for fact-based questions on specific topics.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Wolfram Alpha 是一个计算知识引擎，旨在在线处理事实查询，特别擅长处理数值和计算任务，尤其是在科学和技术领域。通过集成 Wolfram Alpha
    API，代理获得了回答各种主题的几乎所有问题的能力。如果 Wolfram Alpha 无法提供响应，我们将使用 Wikipedia 作为特定主题基于事实问题的次要来源。
- en: Figure 16.3 is a diagram of the steps we’ll take to create the zero-shot know-it-all
    agent in this section.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.3 是我们将在本节中创建零样本全知全能代理所采取步骤的示意图。
- en: '![](../../OEBPS/Images/CH16_F03_Liu.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F03_Liu.png)'
- en: Figure 16.3 Steps to create a zero-shot know-it-all agent with the LangChain
    library
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.3 使用 LangChain 库创建零样本全知全能代理的步骤
- en: Specifically, we’ll first create an agent in LangChain with just one tool—the
    Wolfram Alpha API—to answer questions related to real-time information and recent
    facts. We’ll then add the Wikipedia API to the toolbox as a backup on questions
    related to recent facts. We’ll add various tools utilizing the OpenAI API such
    as text summarizer, joke teller, and sentiment classifier. Finally, we’ll add
    image and code generation functionalities.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们首先将在 LangChain 中创建一个仅使用一个工具——Wolfram Alpha API 的代理来回答与实时信息和最新事实相关的问题。然后，我们将
    Wikipedia API 添加到工具箱中，作为关于最新事实问题的备用。我们将添加各种工具，利用 OpenAI API，如文本摘要器、笑话讲述者和情感分类器。最后，我们将添加图像和代码生成功能。
- en: 16.3.1 Applying for a Wolfram Alpha API Key
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.3.1 申请 Wolfram Alpha API 密钥
- en: Wolfram Alpha gives you up to 2,000 noncommercial API calls per month for free.
    To obtain an API key, first go to [https://account.wolfram.com/login/create/](https://account.wolfram.com/login/create/)
    and complete the steps to create an account.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Wolfram Alpha 每月免费提供高达 2,000 次非商业 API 调用。要获取 API 密钥，请首先访问 [https://account.wolfram.com/login/create/](https://account.wolfram.com/login/create/)
    并完成创建账户的步骤。
- en: The Wolfram account itself gives you only browser access; you need to apply
    for an API key at [https://products.wolframalpha.com/api/](https://products.wolframalpha.com/api/).
    Once there, click Get API Access in the bottom left corner. A small dialog should
    pop up, fill in the fields Name and Description, select *Simple API* from the
    dropdown menu, and then click Submit, as shown in figure 16.4.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Wolfram 账户本身只提供浏览器访问；您需要在 [https://products.wolframalpha.com/api/](https://products.wolframalpha.com/api/)
    申请 API 密钥。一旦到达那里，点击左下角的“获取 API 访问”。应该会弹出一个小的对话框，填写名称和描述字段，从下拉菜单中选择“简单 API”，然后点击提交，如图
    16.4 所示。
- en: '![](../../OEBPS/Images/CH16_F04_Liu.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F04_Liu.png)'
- en: Figure 16.4 Applying for a Wolfram Alpha AppID
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.4 申请 Wolfram Alpha AppID
- en: After that, your AppID should appear in a new window. Copy the API key and save
    it in a file for later use.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，你的 AppID 应该会出现在一个新窗口中。复制 API 密钥并将其保存到文件中以便以后使用。
- en: 'Here is how you can use the Wolfram Alpha API to conduct math operations:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您如何使用 Wolfram Alpha API 进行数学运算的方法：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The output is
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The Wolfram Alpha API provides the correct answer.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Wolfram Alpha API 提供正确答案。
- en: 'We’ll also include the Wikipedia API to provide answers to various topics.
    You don’t need to apply for an API key if you have installed the Wikipedia library
    on your computer. Here is an example of using the Wikipedia API in the LangChain
    library:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将包括维基百科 API，以提供对各种主题的答案。如果你已经在你的计算机上安装了维基百科库，你不需要申请 API 密钥。以下是 LangChain
    库中使用维基百科 API 的示例：
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The output is
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE29]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We have omitted most of the output for brevity.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁，我们省略了大部分输出内容。
- en: 16.3.2 Creating an agent in LangChain
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.3.2 在 LangChain 中创建代理
- en: Next, we’ll create an agent in LangChain, with only the Wolfram Alpha API in
    the toolbox. An agent in this context refers to an individual entity designed
    to handle specific tasks or processes through natural language interactions. We’ll
    then gradually add more tools to the chain so that the agent becomes capable of
    handling more tasks.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在 LangChain 中创建一个代理，工具箱中只有 Wolfram Alpha API。在这个上下文中，代理是指通过自然语言交互处理特定任务或过程的单个实体。然后我们将逐步添加更多工具，使代理能够处理更多任务。
- en: Listing 16.2 Creating an agent in LangChain
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 16.2 在 LangChain 中创建代理
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ① Defines which LLM to use
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ① 定义要使用的 LLM
- en: ② Adds Wolfram Alpha to the toolbox
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将 Wolfram Alpha 添加到工具箱
- en: ③ Defines an agent
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 定义代理
- en: ④ Asks the agent a question
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 向代理提问
- en: The `hwchase17/react` in LangChain refers to a specific type of ReAct agent
    configuration. ReAct stands for Reactive Action, which is a framework within LangChain
    designed to optimize the use of language model capabilities in combination with
    other tools to solve complex tasks effectively. See [https://python.langchain.com/docs/how_to/migrate_agent/](https://python.langchain.com/docs/how_to/migrate_agent/)
    for more details. When you create an agent in LangChain, you need to specify the
    tools to be used by the agent. In the previous example, we use only one tool,
    the Wolfram Alpha API.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 中的 `hwchase17/react` 指的是一种特定的 ReAct 代理配置。ReAct 代表反应性动作，它是 LangChain
    内的一个框架，旨在优化语言模型能力与其他工具结合以有效解决复杂任务。有关更多详细信息，请参阅 [https://python.langchain.com/docs/how_to/migrate_agent/](https://python.langchain.com/docs/how_to/migrate_agent/)。在
    LangChain 中创建代理时，您需要指定代理要使用的工具。在先前的示例中，我们只使用了一个工具，即 Wolfram Alpha API。
- en: 'As an example, we ask the current temperature in Lexington, Kentucky, and here
    is the output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们询问肯塔基州列克星敦的当前温度，以下是输出结果：
- en: '[PRE31]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The output not only shows the final answer, which says the current temperature
    in Lexington, Kentucky, is 44 degrees Fahrenheit, but it also shows the chain
    of thoughts. It uses Wolfram Alpha as the source to obtain the answer.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 输出不仅显示了最终答案，即肯塔基州列克星敦的当前温度为 44 华氏度，而且还显示了思维链。它使用 Wolfram Alpha 作为获取答案的来源。
- en: 'We can also add Wikipedia to the toolbox:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将维基百科添加到工具箱中：
- en: '[PRE32]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'I ask who won the Best Actor Award in the 2024 Academy Awards, and the agent
    uses Wikipedia to get the correct answer:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我询问谁赢得了 2024 年奥斯卡最佳男主角奖，代理使用维基百科获取正确答案：
- en: '[PRE33]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In the preceding output, the agent first decides to use Wikipedia as the tool
    to solve the problem. After searching through various Wikipedia sources, the agent
    provides the correct answer.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，代理首先决定使用维基百科作为解决问题的工具。在搜索了各种维基百科来源后，代理提供了正确答案。
- en: Next, you’ll learn to add various OpenAI GPT tools to the agent’s toolbox.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习如何将各种 OpenAI GPT 工具添加到代理的工具箱中。
- en: 16.3.3 Adding tools by using OpenAI GPTs
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.3.3 使用 OpenAI GPTs 添加工具
- en: We first add a text summarizer so that the agent can summarize text.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先添加一个文本摘要器，以便代理可以总结文本。
- en: Listing 16.3 Adding a text summarizer to the agent’s tool box
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表16.3 向代理的工具箱添加文本摘要器
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ① Defines a template
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ① 定义一个模板
- en: ② Defines a summarizer function
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义一个摘要器函数
- en: ③ Adds summarizer as a tool
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将摘要器作为工具添加
- en: ④ Redefines the agent with the updated toolbox
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 使用更新后的工具箱重新定义代理
- en: We first provide a template to summarize text. We then define a summarizer function
    and add it to the toolbox. Finally, we redefine the agent by using the updated
    toolbox and ask it to summarize the example text with one sentence. Make sure
    your prompt has the same format as those described in the template so that the
    agent knows which tool to use.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先提供一个模板来总结文本。然后定义一个摘要器函数并将其添加到工具箱中。最后，我们通过使用更新后的工具箱重新定义代理，并要求它用一句话总结示例文本。确保你的提示与模板中描述的格式相同，这样代理就知道使用哪个工具。
- en: The output from listing 16.3 is
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表16.3的输出是
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The agent chooses the summarizer as the tool for the task since the input matches
    the template described in the summarizer function. We use two long sentences as
    the text input and the preceding output is a one-sentence summary.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输入与摘要器函数中描述的模板相匹配，代理选择摘要器作为任务的工具。我们使用两个长句作为文本输入，前面的输出是一个句子摘要。
- en: 'You can add as many tools as you like. For example, you can add a tool to tell
    a joke on a certain subject:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以添加你喜欢的任何工具。例如，你可以添加一个工具来讲述某个主题的笑话：
- en: '[PRE36]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The output is
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE37]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We ask the agent to tell a joke on the subject of coding. The agent identifies
    Joke Teller as the tool. The joke is indeed related to coding.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求代理就编程主题讲一个笑话。代理识别出笑话讲述者是工具。这个笑话确实与编程相关。
- en: Exercise 16.2
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 练习16.2
- en: Add a tool to the agent’s toolbox to conduct sentiment analysis. Name the tool
    Sentiment Classifier. Then ask the agent to classify the text “this movie is so-so”
    as positive, negative, or neutral.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 向代理的工具箱添加一个进行情感分析的工具。命名为情感分类器。然后要求代理将文本“这部电影一般般”分类为正面、负面或中性。
- en: 16.3.4 Adding tools to generate code and images
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.3.4 添加生成代码和图像的工具
- en: You can add various tools to the toolbox in LangChain. Interested readers can
    find more details at [https://python.langchain.com/docs/how_to/#tools](https://python.langchain.com/docs/how_to/#tools).
    Next, we add tools to generate other content forms such as code and images.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将各种工具添加到LangChain的工具箱中。感兴趣的读者可以在[https://python.langchain.com/docs/how_to/#tools](https://python.langchain.com/docs/how_to/#tools)找到更多详细信息。接下来，我们添加生成其他内容形式（如代码和图像）的工具。
- en: 'To add a tool to generate code, you can do the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个生成代码的工具，你可以这样做：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The output is
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: If you run the generated code in a cell, you’ll see an image as in figure 16.5.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个单元格中运行生成的代码，你将看到如图16.5所示的图像。
- en: '![](../../OEBPS/Images/CH16_F05_Liu.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F05_Liu.png)'
- en: Figure 16.5 Adding a tool in LangChain to generate Python code. The tool then
    generates code to plot sine and cosine curves in the same graph, with a legend
    and line styles.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.5 在LangChain中添加一个生成Python代码的工具。该工具随后生成代码，在同一图表中绘制正弦和余弦曲线，并带有图例和线条样式。
- en: 'To add an image generator, you can do the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加一个图像生成器，你可以这样做：
- en: '[PRE40]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The output is a URL for you to visualize and download an image. We asked the
    agent to create an image of a horse grazing on the grassland. The image is shown
    in figure 16.6.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个URL，你可以通过它来可视化并下载图像。我们要求代理创建一幅马在草原上吃草的图像。该图像如图16.6所示。
- en: '![](../../OEBPS/Images/CH16_F06_Liu.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F06_Liu.png)'
- en: Figure 16.6 An image generated by a know-it-all agent in LangChain
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.6 LangChain中一个全知全能代理生成的图像
- en: With that, you have learned how to create a zero-shot know-it-all agent in LangChain.
    You can add more tools to the toolbox depending on what you want the agent to
    accomplish.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，你已经学会了如何在LangChain中创建一个零样本的全知全能代理。你可以根据你想让代理完成的事情添加更多工具。
- en: 16.4 Limitations and ethical concerns of LLMs
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.4 LLMs的限制和伦理问题
- en: LLMs such as OpenAI’s GPT series have made significant strides in the field
    of NLP and generative AI. Despite their impressive capabilities, these models
    are not without limitations. Understanding these constraints is crucial for both
    leveraging their strengths and mitigating their weaknesses.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）如OpenAI的GPT系列在自然语言处理和生成式AI领域取得了显著的进步。尽管这些模型拥有令人印象深刻的性能，但它们并非没有局限性。理解这些限制对于发挥它们的优点和减轻它们的弱点至关重要。
- en: At the same time, the rapid advancement and widespread application of these
    models have also given rise to a host of ethical concerns such as bias, inaccuracies,
    breach of privacy, and copyright infringements. These issues demand careful consideration
    and proactive measures to ensure that the development and deployment of LLMs align
    with ethical standards and societal values.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，这些模型的快速进步和广泛应用也引发了一系列伦理问题，如偏见、不准确、侵犯隐私和版权侵权。这些问题需要仔细考虑并采取主动措施，以确保LLMs的开发和部署符合伦理标准和社会主义核心价值观。
- en: In this section, we’ll explore the limitations of LLMs, provide insights into
    why these issues persist, and present examples of notable failures to underscore
    the importance of addressing these challenges. We’ll also examine the key ethical
    concerns associated with LLMs and propose pathways for mitigating these concerns.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨LLMs的限制，分析为什么这些问题持续存在，并举例说明一些显著的失败案例，以强调解决这些挑战的重要性。我们还将检查与LLMs相关的关键伦理问题，并提出缓解这些问题的途径。
- en: 16.4.1 Limitations of LLMs
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.4.1 LLMs的限制
- en: One of the fundamental limitations of LLMs is their lack of true understanding
    and reasoning. While they can generate coherent and contextually relevant responses,
    they do not possess an intrinsic understanding of the content. This can lead to
    errors in logic, factual inaccuracies, and a failure to grasp complex concepts
    or nuances.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的一个基本局限性是它们缺乏真正的理解和推理能力。虽然它们可以生成连贯且与上下文相关的回答，但它们并不具备对内容的内在理解。这可能导致逻辑错误、事实不准确，以及无法掌握复杂概念或细微差别。
- en: 'This manifests in many epic mistakes made by LLMs. The book Smart Until It’s
    Dumb provides many entertaining instances of such mistakes made by GPT-3 and ChatGPT.^([1](#footnote-001))
    For example, consider this question: Mrs. March gave the mother tea and gruel,
    while she dressed the little baby as tenderly as if it had been her own. Who’s
    the baby’s mother? The answer provided by GPT-3 is Mrs. March.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这在LLMs犯下的许多史诗级错误中有所体现。《Smart Until It’s Dumb》这本书提供了许多GPT-3和ChatGPT犯下的此类错误的有趣实例。[1](#footnote-001)
    例如，考虑以下问题：March夫人给了母亲茶和粥，同时她温柔地给小宝宝穿衣，就像它是她自己的孩子一样。谁是这个婴儿的母亲？GPT-3给出的答案是March夫人。
- en: To be fair, with the rapid advancement of LLMs, many of these mistakes are corrected
    over time. However, LLMs still make low-level mistakes. A LinkedIn article in
    June 2023 by David Johnston ([https://www.linkedin.com/pulse/intelligence-tests-llms-fail-why
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 公平地说，随着LLMs的快速进步，许多这些错误随着时间的推移得到了纠正。然而，LLMs仍然会犯低级错误。2023年6月David Johnston在LinkedIn上的一篇文章([https://www.linkedin.com/pulse/intelligence-tests-llms-fail-why-david-johnston/](https://www.linkedin.com/pulse/intelligence-tests-llms-fail-why-david-johnston/))测试了LLMs在人类容易解决的十二个问题上的智力。包括GPT-4在内的LLMs在这些问题上都遇到了困难。其中一个问题是：说出一个动物的名字，其单词长度等于它们腿的数量减去它们尾巴的数量。
- en: '-david-johnston/](https://www.linkedin.com/pulse/intelligence-tests-llms-fail-why-david-johnston/))
    tests the intelligence of LLMs on a dozen problems that humans can easily solve.
    LLMs, including GPT-4, struggle with these problems. One of the problems is as
    follows: name an animal such that the length of the word is equal to the number
    of legs they have minus the number of tails they have.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: -david-johnston/](https://www.linkedin.com/pulse/intelligence-tests-llms-fail-why-david-johnston/))测试了LLMs在人类容易解决的十二个问题上的智力。包括GPT-4在内的LLMs在这些问题上都遇到了困难。其中一个问题是：说出一个动物的名字，其单词长度等于它们腿的数量减去它们尾巴的数量。
- en: This mistake has not been corrected as of this writing. Figure 16.7 is a screenshot
    of the answer by GPT-4 when I used a browser interface.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这个错误还没有被纠正。图16.7是我使用浏览器界面时GPT-4给出的答案的截图。
- en: '![](../../OEBPS/Images/CH16_F07_Liu.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH16_F07_Liu.png)'
- en: Figure 16.7 How GPT-4 still makes low-level mistakes
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7 GPT-4仍然犯的低级错误
- en: The output in figure 16.7 shows that, according to GPT-4, five is equal to the
    number of letters in the word “bee.”
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7的输出显示，根据GPT-4，数字五等于单词“bee”中的字母数量。
- en: 16.4.2 Ethical concerns for LLMs
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.4.2 LLMs的伦理问题
- en: One of the most pressing ethical concerns is the potential for LLMs to perpetuate
    and amplify biases in their training data. Since these models learn from vast
    datasets often derived from human-generated content, they can inherit biases related
    to gender, race, ethnicity, and other social factors. This can result in biased
    outputs that reinforce stereotypes and discrimination.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 最紧迫的伦理问题之一是LLMs可能持续和放大其训练数据中的偏见。由于这些模型从通常来源于人类生成内容的大量数据集中学习，它们可以继承与性别、种族、民族和其他社会因素相关的偏见。这可能导致带有偏见的输出，从而强化刻板印象和歧视。
- en: To mitigate bias, it is essential to adopt diverse and inclusive training datasets,
    implement bias detection and correction algorithms, and ensure transparency in
    model development and evaluation. It’s particularly important to establish industry-wide
    collaboration to set standards for bias mitigation practices and promote responsible
    AI development.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻偏见，采用多元包容的训练数据集、实施偏见检测和纠正算法，以及在模型开发和评估中确保透明度是至关重要的。尤其重要的是建立行业范围内的合作，以制定偏见减轻实践的标准，并促进负责任的AI发展。
- en: However, we must keep in mind not to overcorrect. A counterexample is that Google’s
    Gemini overcorrected the stereotypes in image generation by including people of
    color in groups like Nazi-era German soldiers.^([2](#footnote-000))
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须记住不要过度纠正。一个反例是，谷歌的Gemini通过在纳粹时代德国士兵等群体中包含有色人种，过度纠正了图像生成中的刻板印象.^([2](#footnote-000))
- en: Another concern for LLMs is their potential for misinformation and manipulation.
    LLMs have the ability to generate realistic and persuasive text, which can be
    exploited for creating and spreading misinformation, propaganda, or manipulative
    content. This poses significant risks to public discourse, democracy, and trust
    in information.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LLM的另一个担忧是它们潜在的虚假信息和操纵能力。LLM能够生成逼真且具有说服力的文本，这可能被用于制造和传播虚假信息、宣传或操纵性内容，这对公共讨论、民主和信息信任构成重大风险。
- en: The solution to this concern lies in developing robust content moderation systems.
    Establishing guidelines for responsible use and fostering collaborations between
    AI developers, policymakers, and media organizations are crucial steps in combating
    misinformation.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一担忧的方案在于开发强大的内容审查系统。制定负责任使用的指南，以及促进AI开发者、政策制定者和媒体组织之间的合作，是打击虚假信息的关键步骤。
- en: The third concern is related to privacy. The vast amount of data used to train
    LLMs raises privacy concerns, as sensitive information can be inadvertently revealed
    in the model’s outputs. Additionally, the potential for LLMs to be used in cyberattacks
    or to bypass security measures poses significant security risks.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个担忧与隐私相关。用于训练LLM的大量数据引发了隐私担忧，因为敏感信息可能会在模型输出中无意中被泄露。此外，LLM被用于网络攻击或绕过安全措施的可能性也带来了重大的安全风险。
- en: 'Furthermore, the data used to train LLMs is mostly gathered without authorization.
    Supporters argue that the way data is used to train LLMs is transformative: the
    model doesn’t merely regurgitate the data but uses it to generate new, original
    content. This transformation could qualify under the “fair use” doctrine, which
    allows limited use of copyrighted material without permission if the use adds
    new expression or meaning. Critics argue that LLMs are trained on vast amounts
    of copyrighted texts without permission, which goes beyond what might be considered
    fair use. The scale of data used and the direct ingestion of copyrighted material
    without transformation during training could be seen as infringing. The debate
    is ongoing. The current copyright laws were not designed with generative AI in
    mind, leading to ambiguities about how they apply to technologies like LLMs. It’s
    a debate that likely needs to be resolved by legislative and judicial bodies to
    provide clear guidelines and ensure that the interests of all parties are fairly
    represented.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用于训练大型语言模型（LLM）的数据大多是在未经授权的情况下收集的。支持者认为，用于训练LLM的数据使用方式具有变革性：模型不仅仅重复数据，而是用它来生成新的、原创的内容。这种变革可能符合“合理使用”原则，该原则允许在不获得许可的情况下有限地使用受版权保护的材料，如果使用增加了新的表达或意义。批评者认为，LLM是在未经许可的情况下使用大量受版权保护的文本进行训练的，这超出了可能被认为是合理使用的范围。所使用的数据规模和训练过程中未经转换直接摄取受版权保护的材料可能被视为侵权。这场辩论仍在继续。现行的版权法并非针对生成式AI设计的，导致了对LLM等技术如何适用这些法律的模糊性。这可能是需要由立法和司法机构来解决，以提供明确的指导并确保所有方的利益得到公平代表。
- en: The ethical concerns surrounding LLMs are multifaceted and require a holistic
    approach. Collaborative efforts among AI researchers, developers, and policymakers
    are crucial in developing ethical guidelines and frameworks that guide the responsible
    development and deployment of these powerful models. As we continue to harness
    the potential of LLMs, ethical considerations must remain at the forefront of
    our endeavors to ensure that AI advances in harmony with societal values and human
    well-being.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕 LLMs 的伦理问题多方面且需要全面的方法。AI 研究人员、开发者和政策制定者之间的协作对于制定伦理准则和框架至关重要，这些准则和框架指导着这些强大模型的负责任开发和部署。随着我们继续利用
    LLMs 的潜力，伦理考量必须始终是我们努力的重点，以确保人工智能的进步与社会的价值观和人类的福祉和谐一致。
- en: Summary
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Few-shot prompting means you give LLMs multiple examples to help them understand
    the task, while one-shot or zero-shot prompting means one example or no example
    is provided.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少样本提示意味着你给出多个示例以帮助 LLMs 理解任务，而单样本或零样本提示则意味着提供一个或没有示例。
- en: LangChain is a Python library designed to facilitate the use of LLMs in various
    applications. It abstracts away the complexities of interacting with different
    LLMs and applications. It allows the agent to automatically go to the right tool
    in the toolbox based on the task at hand without explicitly telling it what to
    do.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain 是一个旨在简化在各种应用中使用大型语言模型（LLMs）的 Python 库。它抽象化了与不同 LLMs 和应用交互的复杂性。它允许代理根据当前任务自动选择工具箱中的正确工具，而无需明确告知它要做什么。
- en: Modern pretrained LLMs such as OpenAI’s GPT series can create various formats
    of content such as text, images, audio, and code.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代预训练的 LLMs，如 OpenAI 的 GPT 系列，可以创建各种格式的内蓉，如文本、图像、音频和代码。
- en: Despite their impressive achievements, LLMs lack a true understanding of the
    content or the ability to reason. These limitations can lead to errors in logic,
    factual inaccuracies, and a failure to grasp complex concepts or nuances. Furthermore,
    the rapid advancement and widespread application of these models have given rise
    to a host of ethical concerns such as bias, misinformation, breach of privacy,
    and copyright infringements. These issues demand careful consideration and proactive
    measures to ensure that the development and deployment of LLMs align with ethical
    standards and societal values.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管它们取得了令人印象深刻的成就，但 LLMs 缺乏对内容内容的真正理解或推理能力。这些局限性可能导致逻辑错误、事实不准确，以及无法掌握复杂概念或细微差别。此外，这些模型的快速进步和广泛应用引发了一系列伦理问题，如偏见、错误信息、隐私侵犯和版权侵权。这些问题需要仔细考虑和主动措施，以确保
    LLMs 的开发和部署与伦理标准和社会价值观相一致。
- en: '* * *'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '^([1](#footnote-001-backlink))  Maggiori, Emmanuel, 2023, *Smart Until It’s
    Dumb: Why Artificial Intelligence Keeps Making Epic Mistakes (and Why the AI Bubble
    Will Burst)*, Applied Maths Ltd. Kindle Edition.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](#footnote-001-backlink))  Maggiori, Emmanuel，2023 年，*Smart Until It’s
    Dumb: Why Artificial Intelligence Keeps Making Epic Mistakes (and Why the AI Bubble
    Will Burst)*，Applied Maths Ltd. 电子书版。'
- en: ^([2](#footnote-000-backlink))  Adi Robertson, February 21, 2024, “Google Apologizes
    for 'Missing the Mark’ after Gemini Generated Racially Diverse Nazis.” The Verge,
    [https://mng.bz/2ga9](https://mng.bz/2ga9).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](#footnote-000-backlink))  Adi Robertson，2024 年 2 月 21 日，“Google 因 Gemini
    生成的种族多样性纳粹而道歉。”The Verge，[https://mng.bz/2ga9](https://mng.bz/2ga9)。
