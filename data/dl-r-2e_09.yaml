- en: 6 The universal workflow of machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 机器学习的通用工作流程
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Steps for framing a machine learning problem
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建机器学习问题的步骤
- en: Steps for developing a working model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发可行模型的步骤
- en: Steps for deploying your model in production and maintaining it
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署模型到生产环境并进行维护的步骤
- en: Our previous examples have assumed that we already had a labeled dataset to
    start from, and that we could immediately start training a model. In the real
    world, this is often not the case. You don’t start from a dataset; you start from
    a problem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们先前的示例假设我们已经有了一个标记的数据集，并且我们可以立即开始训练模型。但在现实世界中，情况通常并非如此。你并不是从一个数据集开始；你是从一个问题开始的。
- en: 'Imagine that you’re starting your own machine learning consulting shop. You
    incorporate, you put up a fancy website, you notify your network. The following
    projects start rolling in:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在开设自己的机器学习咨询公司。你注册了公司，建立了一个华丽的网站，通知了你的人脉。随后，以下项目开始涌现：
- en: A personalized photo search engine for a picture-sharing social network— type
    in “wedding” and retrieve all the pictures you took at weddings, without any manual
    tagging needed
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个为图片分享社交网络设计的个性化照片搜索引擎——输入“婚礼”并检索出你在婚礼上拍摄的所有照片，无需任何手动标记
- en: Flagging spam and offensive text content among the posts of a budding chat app
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在新兴的聊天应用程序的帖子中标记垃圾邮件和冒犯性文本内容
- en: Building a music recommendation system for users of an online radio station.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为在线广播电台用户构建音乐推荐系统。
- en: Detecting credit card fraud for an e-commerce website.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测电子商务网站的信用卡欺诈。
- en: Predicting display ad click-through rates to decide which ad to serve to a given
    user at a given time.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测展示广告的点击率，以决定在特定时间为特定用户提供哪个广告。
- en: Flagging anomalous cookies on the conveyor belt of a cookie-manufacturing line.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在饼干生产线上标记异常饼干。
- en: Using satellite images to predict the location of as-yet-unknown archeological
    sites
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用卫星图像来预测尚未知晓的考古遗址的位置
- en: '**Note on ethics**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**伦理说明**'
- en: 'You may sometimes be offered ethically dubious projects, such as “building
    an AI that rates the trustworthiness of someone from a picture of their face.”
    First of all, the validity of the project is in doubt: it isn’t clear why trustworthiness
    would be reflected on someone’s face. Second, such a task opens the door to all
    kinds of ethical problems. Collecting a dataset for this task would amount to
    recording the biases and prejudices of the people who label the pictures. The
    models you would train on such data would merely encode these same biases into
    a black-box algorithm that would give them a thin veneer of legitimacy. In a largely
    tech-illiterate society like ours, “the AI algorithm said this person cannot be
    trusted” strangely appears to carry more weight and objectivity than “John Smith
    said this person cannot be trusted,” despite the former being a learned approximation
    of the latter. Your model would be laundering and operationalizing at scale the
    worst aspects of human judgment, with negative effects on the lives of real people.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你可能会被提供伦理上可疑的项目，比如“构建一个从某人面部照片评估其可信度的人工智能。”首先，该项目的有效性存在疑问：不清楚为什么可信度会反映在某人的面部上。其次，这样的任务开启了各种伦理问题的大门。为这个任务收集数据集将意味着记录标记图片的人的偏见和成见。你用这些数据训练的模型只会将这些偏见编码到一个黑匣子算法中，这个算法会赋予它们一层薄薄的合法性。在我们这样一个主要技术文盲的社会中，“AI算法说这个人不可信”似乎比“约翰·史密斯说这个人不可信”更具权威性和客观性，尽管前者只是对后者的一个学习近似。你的模型将以规模化的方式清洗和操作化人类判断的最糟糕的方面，对真实人生产生负面影响。
- en: 'Technology is never neutral. If your work has any impact on the world, this
    impact has a moral direction: technical choices are also ethical choices. Always
    be deliberate about the values you want your work to support.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 技术从来都不是中立的。如果你的工作对世界有任何影响，这种影响都具有道德方向：技术选择也是伦理选择。始终要谨慎选择你的工作要支持的价值观。
- en: It would be very convenient if you could access the correct dataset with keras::data-set_mydataset()
    and start fitting some deep learning models. Unfortunately, in the real world,
    you’ll have to start from scratch.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以通过 keras::data-set_mydataset() 访问正确的数据集并开始拟合一些深度学习模型，那将会非常方便。不幸的是，在现实世界中，你将不得不从零开始。
- en: In this chapter, you’ll learn about a universal step-by-step blueprint that
    you can use to approach and solve any machine learning problem, like those in
    the previous list. This template will bring together and consolidate everything
    you’ve learned in chapters 4 and 5 and will give you the wider context that should
    anchor what you’ll learn in the next chapters.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习一个通用的、逐步的蓝图，您可以使用它来处理和解决任何机器学习问题，就像前面列表中的问题一样。这个模板将汇集和 consaolidate
    你在第 4 章和第 5 章中学到的一切，并给你更广泛的上下文，应该锚定你将在下一章学到的东西。
- en: 'The universal workflow of machine learning is broadly structured in three parts:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的通用工作流程大致分为三个部分：
- en: '**1** *Define the task*—Understand the problem domain and the business logic
    underlying what the customer asked for. Collect a dataset, understand what the
    data represents, and choose how you will measure success on the task.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**1** *定义任务*—了解问题域和客户要求背后的业务逻辑。收集数据集，了解数据代表什么，并选择如何在任务上衡量成功。'
- en: '**2** *Develop a model*—Prepare your data so that it can be processed by a
    machine learning model, select a model-evaluation protocol and a simple baseline
    to beat, train a first model that has generalization power and that can overfit,
    and then regularize and tune your model until you achieve the best possible generalization
    performance.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**2** *开发模型*—准备好数据，使其可以被机器学习模型处理，选择一个模型评估协议和一个简单的基准来超越，训练一个具有泛化能力的第一个模型，并且可以过拟合，然后正则化和调整你的模型，直到达到最佳的泛化性能。'
- en: '**3** *Deploy the model*—Present your work to stakeholders; ship the model
    to a web server, a mobile app, a web page, or an embedded device; monitor the
    model’s performance in the wild; and start collecting the data you’ll need to
    build the next-generation model.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**3** *部署模型*—向利益相关者展示你的工作；将模型部署到 Web 服务器、移动应用程序、网页或嵌入式设备中；在实际应用中监视模型的性能；开始收集构建下一代模型所需的数据。'
- en: Let’s dive in.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解。
- en: 6.1 Define the task
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 定义任务
- en: You can’t do good work without a deep understanding of the context of what you’re
    doing. Why is your customer trying to solve this particular problem? What value
    will they derive from the solution—how will your model be used, and how will it
    fit into your customer’s business processes? What kind of data is available or
    could be collected? What kind of machine learning task can be mapped to the business
    problem?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你如果没有对你正在做的事情的背景有深刻的理解，就无法做出好的工作。你的客户为什么要解决这个特定的问题？他们将从解决方案中获得什么价值——你的模型将如何使用，它将如何融入客户的业务流程？有哪些数据可用或可以收集？什么样的机器学习任务可以映射到业务问题上？
- en: 6.1.1 Frame the problem
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.1 框架问题
- en: 'Framing a machine learning problem usually involves many detailed discussions
    with stakeholders. Here are the questions that should be on the top of your mind:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 框定一个机器学习问题通常涉及与利益相关者的许多详细讨论。以下是你脑海中应该考虑的问题：
- en: 'What will your input data be? What are you trying to predict? You can learn
    to predict something only if you have training data available: for example, you
    can learn to classify the sentiment of movie reviews only if you have both movie
    reviews and sentiment annotations available. As such, data availability is usually
    the limiting factor at this stage. In many cases, you will have to resort to collecting
    and annotating new data-sets yourself (which we’ll cover in the next section).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输入数据将是什么？你想要预测什么？只有在有训练数据可用的情况下，你才能学会预测某些东西：例如，只有在有电影评论和情感注释可用时，你才能学会分类电影评论的情感。因此，在这个阶段，数据可用性通常是限制因素。在许多情况下，你将不得不自己收集和注释新的数据集（我们将在下一节中介绍）。
- en: 'What type of machine learning task are you facing? Is it binary classification?
    Multiclass classification? Scalar regression? Vector regression? Multiclass, multilabel
    classification? Image segmentation? Ranking? Something else, like clustering,
    generation, or reinforcement learning? In some cases, it may be that machine learning
    isn’t even the best way to make sense of the data, and you should use something
    else, such as plain old-school statistical analysis:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你面对的是什么类型的机器学习任务？它是二元分类吗？多类分类？标量回归？向量回归？多类别、多标签分类？图像分割？排名？其他一些，如聚类、生成或强化学习？在某些情况下，机器学习甚至可能不是理解数据的最佳方法，你应该使用其他方法，如纯粹的老式统计分析：
- en: The photo search engine project is a multiclass, multilabel classification task.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片搜索引擎项目是一个多类别、多标签分类任务。
- en: The spam detection project is a binary classification task. If you set “offensive
    content” as a separate class, it’s a three-way classification task.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾邮件检测项目是一个二元分类任务。如果将“攻击性内容”作为一个单独的类，那么它就是一个三元分类任务。
- en: The music recommendation engine turns out to be better handled not via deep
    learning but via matrix factorization (collaborative filtering).
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐推荐引擎的处理方式最好不是通过深度学习，而是通过矩阵分解（协同过滤）来处理。
- en: The credit card fraud-detection project is a binary classification task.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测项目是一个二元分类任务。
- en: The click-through rate prediction project is a scalar regression task.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击率预测项目是一个标量回归任务。
- en: Anomalous cookie detection is a binary classification task, but it will also
    require an object detection model as a first stage to correctly crop out the cookies
    in raw images. Note that the set of machine learning techniques known as “anomaly
    detection” would not be a good fit in this setting!
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常饼干检测是一个二元分类任务，但它还需要一个对象检测模型作为第一阶段，以正确裁剪原始图像中的饼干。请注意，被称为“异常检测”的一组机器学习技术在这种情况下并不适用！
- en: 'The project for finding new archeological sites from satellite images is an
    image-similarity ranking task: you need to retrieve new images that look the most
    like known archeological sites.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从卫星图像中找到新考古遗址的项目是一个图像相似性排名任务：你需要检索出看起来最像已知考古遗址的新图像。
- en: What do existing solutions look like? Perhaps your customer already has a hand-crafted
    algorithm that handles spam filtering or credit card fraud detection, with lots
    of nested if statements. Perhaps a human is currently in charge of manually handling
    the process under consideration—monitoring the conveyor belt at the cookie plant
    and manually removing the bad cookies, or crafting playlists of song recommendations
    to be sent out to users who liked a specific artist. You should make sure you
    understand what systems are already in place and how they work.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现有解决方案是什么样的？也许你的客户已经有一个手工制作的算法来处理垃圾邮件过滤或信用卡欺诈检测，其中包含大量的嵌套if语句。也许目前是一个人手动处理正在考虑的过程
    - 监控饼干厂的传送带并手动移除坏饼干，或者制作歌曲推荐播放列表以发送给喜欢特定艺术家的用户。你应该确保你了解已经存在的系统以及它们是如何工作的。
- en: Are there particular constraints you will need to deal with? For example, you
    could find out that the app for which you’re building a spam-detection system
    is strictly endto-end encrypted, so that the spam-detection model will have to
    live on the end user’s phone and must be trained on an external dataset. Perhaps
    the cookie-filtering model has such latency constraints that it will need to run
    on an embedded device at the factory rather than on a remote server. You should
    understand the full context in which your work will fit.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有特定的约束你将需要处理？例如，你可能发现你正在为其构建垃圾邮件检测系统的应用程序是严格端到端加密的，因此垃圾邮件检测模型必须存在于最终用户的手机上，并且必须在外部数据集上进行训练。也许饼干过滤模型有这样的延迟约束，它将需要在工厂的嵌入式设备上运行，而不是在远程服务器上运行。你应该了解你的工作将适合的完整环境。
- en: 'Once you’ve done your research, you should know what your inputs will be, what
    your targets will be, and what broad type of machine learning task the problem
    maps to. Be aware of the hypotheses you’re making at this stage:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了研究，你应该知道你的输入是什么，你的目标是什么，以及问题映射到的机器学习任务的广泛类型是什么。在这个阶段要注意你正在做出的假设：
- en: You hypothesize that your targets can be predicted given your inputs.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设你的目标可以根据你的输入来预测。
- en: You hypothesize that the data that’s available (or that you will soon collect)
    is sufficiently informative to learn the relationship between inputs and targets
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设可用的数据（或者你即将收集的数据）足够信息丰富，可以学习输入和目标之间的关系。
- en: Until you have a working model, these are merely hypotheses, waiting to be validated
    or invalidated. Not all problems can be solved with machine learning; just because
    you’ve assembled examples of inputs X and targets Y doesn’t mean X contains enough
    information to predict Y. For instance, if you’re trying to predict the movements
    of a stock on the stock market given its recent price history, you’re unlikely
    to succeed, because price history doesn’t contain much predictive information.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在你有一个工作模型之前，这些只是等待验证或无效的假设。并不是所有的问题都可以用机器学习来解决；仅仅因为你已经组装了输入X和目标Y的示例，并不意味着X包含足够的信息来预测Y。例如，如果你试图根据其最近的价格历史来预测股票在股票市场上的走势，你很可能不会成功，因为价格历史并没有太多的预测信息。
- en: 6.1.2 Collect a dataset
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.2 收集数据集
- en: 'Once you understand the nature of the task and you know what your inputs and
    targets are going to be, it’s time for data collection—the most arduous, time-consuming,
    and costly part of most machine learning projects:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您了解任务的性质，并且知道您的输入和目标将是什么，就到了数据收集的时候——这是大多数机器学习项目中最费力、耗时和昂贵的部分：
- en: The photo search engine project requires you to first select the set of labels
    you want to classify—you settle on 10,000 common image categories. Then you need
    to manually tag hundreds of thousands of your past user-uploaded images with labels
    from this set.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片搜索引擎项目需要您首先选择要分类的标签集——您选择了 10,000 个常见图像类别。然后，您需要手动为您过去上传的数十万张用户图片中的每一张打上这个集合中的标签。
- en: For the chat app’s spam-detection project, because user chats are end-to-end
    encrypted, you cannot use their contents for training a model. You need to gain
    access to a separate dataset of tens of thousands of unfiltered social media posts
    and manually tag them as spam, offensive, or acceptable.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于聊天应用的垃圾邮件检测项目，由于用户聊天是端到端加密的，您无法使用其内容来训练模型。您需要获取一个包含数万条未经筛选的社交媒体帖子的单独数据集，并手动标记它们为垃圾邮件、冒犯性内容或可接受内容。
- en: 'For the music recommendation engine, you can just use the “likes” of your users.
    No new data needs to be collected. Likewise for the click-through rate prediction
    project: you have an extensive record of click-through rates for your past ads,
    going back years.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于音乐推荐引擎，您可以只使用用户的“喜欢”。不需要收集新数据。同样，对于点击率预测项目：您有过去多年来广告点击率的广泛记录。
- en: For the cookie-flagging model, you will need to install cameras above the conveyor
    belts to collect tens of thousands of images, and then someone will need to manually
    label these images. The people who know how to do this currently work at the cookie
    factory, but it doesn’t seem too difficult. You should be able to train people
    to do it.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 cookie 标记模型，您将需要在传送带上方安装摄像头来收集数万张图像，然后需要有人手动标记这些图像。目前知道如何做这件事的人在饼干工厂工作，但似乎并不太困难。您应该能够培训人员来做这件事。
- en: The satellite imagery project will require a team of archeologists to collect
    a database of existing sites of interest, and for each site you will need to find
    existing satellite images taken in different weather conditions. To get a good
    model, you’re going to need thousands of different sites
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卫星图像项目将需要一支考古学家团队收集现有感兴趣地点的数据库，并且对于每个地点，您需要找到不同天气条件下拍摄的现有卫星图像。要获得一个好的模型，您将需要成千上万个不同的地点。
- en: 'You learned in chapter 5 that a model’s ability to generalize comes almost
    entirely from the properties of the data it is trained on: the number of data
    points you have, the reliability of your labels, the quality of your features.
    A good dataset is an asset worthy of care and investment. If you get an extra
    50 hours to spend on a project, chances are that the most effective way to allocate
    them is to collect more data rather than search for incremental modeling improvements.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您在第 5 章学到，模型的泛化能力几乎完全来自于其所训练的数据的属性：您拥有的数据点数量，标签的可靠性，特征的质量。一个好的数据集是值得关注和投资的资产。如果您额外有
    50 小时可用于项目，最有效的分配方式很可能是收集更多数据，而不是寻找增量建模改进。
- en: The point that data matters more than algorithms was most famously made in a
    2009 paper by Google researchers titled, “The Unreasonable Effectiveness of Data”
    (the title is a riff on the well-known 1960 article “The Unreasonable Effectiveness
    of Mathematics in the Natural Sciences” by Eugene Wigner). This was before deep
    learning was popular, but, remarkably, the rise of deep learning has only made
    the importance of data greater.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据比算法更重要的观点最著名的是由谷歌研究人员在 2009 年发表的一篇名为“数据的不合理有效性”的论文中提出的（标题是对尤金·维格纳于 1960
    年发表的著名文章“数学在自然科学中的不合理有效性”的变种）。这是在深度学习流行之前，但值得注意的是，深度学习的兴起只是使数据的重要性更加突出。
- en: If you’re doing supervised learning, then once you’ve collected inputs (such
    as images) you’re going to need *annotations* for them (such as tags for those
    images)— the targets you will train your model to predict. Sometimes, annotations
    can be retrieved automatically, such as those for the music recommendation task
    or the click-through rate prediction task. But often you have to annotate your
    data by hand. This is a labor-heavy process.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在进行监督学习，那么一旦你收集到了输入（例如图像），你将需要对它们进行*注释*（例如图像的标签）——你将训练模型去预测的目标。有时，注释可以自动获取，例如音乐推荐任务或点击率预测任务的注释。但通常你需要手动注释你的数据。这是一个劳动密集型的过程。
- en: INVESTING IN DATA ANNOTATION INFRASTRUCTURE
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 投资于数据标注基础设施
- en: 'Your data annotation process will determine the quality of your targets, which
    in turn determine the quality of your model. Carefully consider the options you
    have available:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据标注过程将决定你的目标的质量，进而决定你模型的质量。仔细考虑你可用的选项：
- en: Should you annotate the data yourself?
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该自己注释数据？
- en: Should you use a crowdsourcing platform like Mechanical Turk to collect labels?
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该使用像 Mechanical Turk 这样的众包平台来收集标签？
- en: Should you use the services of a specialized data-labeling company
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该使用专门的数据标注公司的服务
- en: Outsourcing can potentially save you time and money, but it takes away control.
    Using something like Mechanical Turk is likely to be inexpensive and scale well,
    but your annotations may end up being quite noisy.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 外包可能会节省时间和金钱，但会带走控制权。使用类似 Mechanical Turk 的东西可能价格便宜且规模化效果好，但你的标注可能会非常嘈杂。
- en: 'To pick the best option, consider the constraints you’re working with:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择最佳选项，考虑你正在处理的约束条件：
- en: Do the data labelers need to be subject matter experts, or could anyone annotate
    the data? The labels for a cat-versus-dog image-classification problem can be
    selected by anyone, but those for a dog breed classification task require specialized
    knowledge. Meanwhile, annotating CT scans of bone fractures pretty much requires
    a medical degree.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据标注员是否需要是专业领域的专家，还是任何人都可以对数据进行注释？猫狗图像分类问题的标签可以由任何人选择，但狗品种分类任务的标签需要专业知识。与此同时，标注骨折的
    CT 扫描几乎需要医学学位。
- en: If annotating the data requires specialized knowledge, can you train people
    to do it? If not, how can you get access to relevant experts?
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果注释数据需要专业知识，你是否能够培训人员来做？如果不能，你如何才能获得相关的专家？
- en: Do you, yourself, understand the way experts come up with the annotations? If
    you don’t, you will have to treat your dataset as a black box, and you won’t be
    able to perform manual feature engineering—this isn’t critical, but it can be
    limiting
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你自己是否了解专家是如何提出注释的？如果不了解，你将不得不将你的数据集视为黑盒子，你将无法进行手动特征工程——这并不是关键，但可能会限制你。
- en: If you decide to label your data in-house, ask yourself what software you will
    use to record annotations. You may well need to develop that software yourself.
    Productive data annotation software will save you a lot of time, so it’s worth
    investing in it early in a project.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果决定在内部标注数据，问问自己你会使用什么软件记录注释。你可能需要自己开发这个软件。高效的数据标注软件会节省你大量的时间，因此在项目初期投资于它是值得的。
- en: BEWARE OF NONREPRESENTATIVE DATA
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 警惕非代表性数据
- en: Machine learning models can only make sense of inputs that are similar to what
    they’ve seen before. As such, it’s critical that the data used for training should
    be *representative* of the production data. This concern should be the foundation
    of all your data-collection work.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型只能理解与它们以前看到的相似的输入。因此，关键是训练所使用的数据应该*代表*生产数据。这个问题应该是所有数据收集工作的基础。
- en: 'Suppose you’re developing an app where users can take pictures of a plate of
    food to find out the name of the dish. You train a model using pictures from an
    image-sharing social network that’s popular with foodies. Come deployment time,
    feedback from angry users starts rolling in: your app gets the answer wrong 8
    times out of 10 times. What’s going on? Your accuracy on the test set was well
    over 90%! A quick look at user-uploaded data reveals that mobile picture uploads
    of random dishes from random restaurants taken with random smartphones look nothing
    like the professional-quality, well-lit, appetizing pictures you trained the model
    on: *your training data wasn’t representative of the production data*. That’s
    a cardinal sin—welcome to machine learning hell.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在开发一个应用，用户可以拍摄一盘食物的照片以查找菜名。你使用了一个受到美食爱好者欢迎的图像分享社交网络上的图片来训练模型。但在部署后，愤怒用户的反馈开始涌现：你的应用在10次中有8次都答错了。发生了什么？你在测试集上的准确率远远超过了90％！快速查看用户上传的数据发现，随机从随机餐厅拍摄的随机菜品的移动照片与你训练模型的专业质量、光线充足、诱人的照片完全不同：*你的训练数据不代表生产数据*。这是一个重大错误——欢迎来到机器学习地狱。
- en: If possible, collect data directly from the environment where your model will
    be used. A movie-review sentiment-classification model should be used on new IMDB
    reviews, not on Yelp restaurant reviews or on Twitter status updates. If you want
    to rate the sentiment of a tweet, start by collecting and annotating actual tweets
    from a similar set of users as those you’re expecting in production. If it’s not
    possible to train on production data, then make sure you fully understand how
    your training and production data differ and that you are actively correcting
    for these differences.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，直接从模型将被使用的环境中收集数据。电影评论情感分类模型应该用于新的IMDB评论，而不是Yelp餐厅评论或Twitter状态更新。如果你想评价一条推文的情感，首先收集和注释来自与你预期在生产中的相似用户集的实际推文。如果无法在生产数据上训练，那么确保你完全了解你的训练和生产数据的差异，并且你正在积极地纠正这些差异。
- en: A related phenomenon you should be aware of is *concept drift*. You’ll encounter
    concept drift in almost all real-world problems, especially those that deal with
    user-generated data. Concept drift occurs when the properties of the production
    data change over time, causing model accuracy to gradually decay. A music-recommendation
    engine trained in the year 2013 may not be very effective today. Likewise, the
    IMDB dataset you worked with was collected in 2011, and a model trained on it
    would likely not perform as well on reviews from 2020 compared to reviews from
    2012, because vocabulary, expressions, and movie genres evolve over time. Concept
    drift is particularly acute in adversarial contexts like credit card fraud detection,
    where fraud patterns change practically every day. Dealing with fast concept drift
    requires constant data collection, annotation, and model retraining.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该注意的一个相关现象是*概念漂移*。你几乎在所有真实世界的问题中都会遇到概念漂移，尤其是那些涉及用户生成数据的问题。当生产数据的属性随时间改变时，会导致模型准确性逐渐下降，这就是概念漂移。2013年训练的音乐推荐引擎可能今天已经不太有效。同样，你处理过的IMDB数据集是在2011年收集的，而基于它训练的模型可能在处理2020年的评论时与2012年的评论相比表现不佳，因为词汇、表达和电影类型随时间而演变。概念漂移在诸如信用卡欺诈检测之类的对抗性环境中特别严重，因为欺诈模式几乎每天都在变化。处理快速概念漂移需要不断进行数据收集、注释和模型重新训练。
- en: Keep in mind that machine learning can only be used to memorize patterns that
    are present in your training data. You can only recognize what you’ve seen before.
    Using machine learning trained on past data to predict the future is making the
    assumption that the future will behave like the past. That often isn’t the case.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，机器学习只能用于记忆训练数据中存在的模式。你只能识别你以前见过的东西。使用过去数据训练的机器学习来预测未来是假设未来会像过去一样的假设。这通常并不是情况。
- en: '**The problem of sampling bias**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**采样偏差问题**'
- en: A particularly insidious and common case of nonrepresentative data is *sampling
    bias*. Sampling bias occurs when your data-collection process interacts with what
    you are trying to predict, resulting in biased measurements. A famous historical
    example occurred in the 1948 US presidential election. On election night, the
    *Chicago Tribune* printed the headline “DEWEY DEFEATS TRUMAN.” The next morning,
    Truman emerged as the winner. The editor of the *Tribune* had trusted the results
    of a phone survey—but phone users in 1948 were not a random, representative sample
    of the voting population. They were more likely to be richer and conservative
    and to have voted for Dewey, the Republican candidate.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别阴险而常见的非代表性数据情况是*抽样偏差*。当你的数据收集过程与你试图预测的内容互动时，就会产生偏倚的测量结果。一个著名的历史例子发生在1948年的美国总统选举中。在选举之夜，《芝加哥论坛报》刊登了标题“杜威击败杜鲁门”。第二天早晨，杜鲁门被宣布为胜利者。《论坛报》的编辑信任了一项电话调查的结果——但是1948年的电话用户并不是选民群体的随机、代表性样本。他们更有可能是富裕和保守的，更有可能投票给共和党候选人杜威。
- en: '![Image](../images/f0172-01.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0172-01.jpg)'
- en: '**“DEWEY DEFEATS TRUMAN”: A famous example of sampling bias**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**“杜威击败杜鲁门”：抽样偏差的著名例子**'
- en: Nowadays, every phone survey takes sampling bias into account. That doesn’t
    mean that sampling bias is a thing of the past in political polling—far from it.
    But unlike in 1948, pollsters are aware of it and take steps to correct it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，每一次电话调查都会考虑到抽样偏差。这并不意味着在政治民意调查中抽样偏差已经成为历史——相反，与1948年不同的是，民意调查员们意识到了这一点，并采取措施予以纠正。
- en: 6.1.3 Understand your data
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.3 了解你的数据
- en: 'It’s pretty bad practice to treat a dataset as a black box. Before you start
    training models, you should explore and visualize your data to gain insights about
    what makes it predictive, which will inform feature engineering and screen for
    potential issues:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 把数据集当作黑匣子是相当糟糕的做法。在开始训练模型之前，您应该探索和可视化您的数据，以获取关于什么使其具有预测性的见解，这将为特征工程提供信息，并筛选出潜在问题：
- en: If your data includes images or natural language text, take a look at a few
    samples (and their labels) directly.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含图像或自然语言文本，请直接查看几个样本（以及它们的标签）。
- en: If your data contains numerical features, it’s a good idea to plot the histogram
    of feature values to get a feel for the range of values taken and the frequency
    of different values.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含数值特征，绘制特征值的直方图是个好主意，以了解取值范围和不同取值的频率。
- en: If your data includes location information, plot it on a map. Do any clear patterns
    emerge?
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含位置信息，请在地图上标出它。是否有明显的模式出现？
- en: Are some samples missing values for some features? If so, you’ll need to deal
    with this when you prepare the data (we’ll cover how to do this in the next section).
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些样本是否缺少一些特征值？如果是，您将需要在准备数据时处理这些值（我们将在下一节介绍如何做到这一点）。
- en: If your task is a classification problem, print the number of instances of each
    class in your data. Are the classes roughly equally represented? If not, you will
    need to account for this imbalance.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的任务是一个分类问题，请打印出数据中每个类的实例数。各类别是否大致平衡？如果不是，你将需要考虑这种不平衡。
- en: 'Check for *target leaking*: the presence of features in your data that provide
    information about the targets and which may not be available in production. If
    you’re training a model on medical records to predict whether someone will be
    treated for cancer in the future, and the records include the feature “this person
    has been diagnosed with cancer,” then your targets are being artificially leaked
    into your data. Always ask yourself, is every feature in your data something that
    will be available in the same form in production'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查是否存在*目标泄露*：数据中是否存在提供有关目标信息的特征，这些信息在生产环境中可能不可用。如果你正在对医疗记录进行建模，以预测未来某人是否会接受癌症治疗，并且记录中包含“这个人被诊断为患有癌症”这个特征，那么你的目标就被人为地泄漏到了你的数据中。请时刻问自己，您的数据中的每个特征是否都是在生产中以同样的形式可用的。
- en: 6.1.4 Choose a measure of success
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.4 选择成功的度量标准
- en: To control something, you need to be able to observe it. To achieve success
    on a project, you must first define what you mean by success. Accuracy? Precision
    and recall? Customer retention rate? Your metric for success will guide all of
    the technical choices you make throughout the project. It should directly align
    with your higher-level goals, such as the business success of your customer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 控制某物，你需要能够观察它。要在项目上取得成功，你必须首先定义成功的含义。准确性？精确度和召回率？客户保留率？你对成功的度量将指导你在整个项目中做出的所有技术选择。它应直接与你的更高级别目标保持一致，例如你的客户的业务成功。
- en: For balanced classification problems, where every class is equally likely, accuracy
    and the area under a *receiver operating characteristic* (ROC) curve, abbreviated
    as ROC AUC, are common metrics. For class-imbalanced problems, ranking problems,
    or multilabel classification, you can use precision and recall, as well as a weighted
    form of accuracy or ROC AUC. It isn’t uncommon to have to define your own custom
    metric by which to measure success. To get a sense of the diversity of machine
    learning success metrics and how they relate to different problem domains, it’s
    helpful to browse the data science competitions on Kaggle ([https://kaggle.com](https://kaggle.com));
    they showcase a wide range of problems and evaluation metrics.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平衡分类问题，其中每个类别的概率相等，准确率和*接收器操作特征*（ROC）曲线下的面积，简称ROC AUC，是常见的度量标准。对于类别不平衡问题、排名问题或多标签分类问题，你可以使用精确率和召回率，以及准确率或ROC
    AUC的加权形式。定义自己的自定义度量标准来衡量成功并不少见。要了解机器学习成功度量的多样性以及它们与不同问题领域的关系，浏览Kaggle（[https://kaggle.com](https://kaggle.com)）上的数据科学竞赛是有帮助的；它们展示了各种问题和评估度量标准的广泛范围。
- en: 6.2 Develop a model
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 开发模型
- en: Once you know how you will measure your progress, you can get started with model
    development. Most tutorials and research projects assume that this is the only
    step— skipping problem definition and dataset collection, which are assumed already
    done, and skipping model deployment and maintenance, which are assumed to be handled
    by someone else. In fact, model development is only one step in the machine learning
    workflow, and if you ask me, it’s not the most difficult one. The hardest things
    in machine learning are framing problems and collecting, annotating, and cleaning
    data. So cheer up—what comes next will be easy in comparison!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你知道如何衡量你的进展，你就可以开始模型开发。大多数教程和研究项目假定这是唯一的步骤——跳过了问题定义和数据集收集，这些都假定已经完成，并跳过了模型部署和维护，这些都假定由其他人处理。事实上，模型开发只是机器学习工作流程中的一个步骤，如果你问我，这不是最困难的步骤。机器学习中最困难的事情是框定问题、收集、注释和清理数据。所以振作起来——接下来的事情将会比较容易！
- en: 6.2.1 Prepare the data
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 准备数据
- en: As you’ve learned earlier, deep learning models typically don’t ingest raw data.
    Data preprocessing aims at making the raw data at hand more amenable to neural
    networks. This includes vectorization, normalization, or handling missing values.
    Many preprocessing techniques are domain-specific (e.g., specific to text data
    or image data); we’ll cover those in the following chapters as we encounter them
    in practical examples. For now, we’ll review the basics that are common to all
    data domains.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你之前学到的，深度学习模型通常不会直接处理原始数据。数据预处理旨在使手头的原始数据更适合神经网络处理。这包括向量化、标准化或处理缺失值。许多预处理技术是特定于领域的（例如，特定于文本数据或图像数据）；我们将在接下来的章节中涵盖这些技术，当我们在实际示例中遇到它们时。现在，我们将回顾所有数据领域通用的基础知识。
- en: VECTORIZATION
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量化
- en: All inputs and targets in a neural network must typically be tensors of floating-point
    data (or, in specific cases, tensors of integers or strings). Whatever data you
    need to process—sound, images, or text—you must first turn it into tensors, a
    step called *data vectorization*. For instance, in the two text-classification
    examples in chapter 4, we started with text represented as lists of integers (standing
    for sequences of words), and we used one-hot encoding to turn them into a tensor
    of float32 data. In the examples of classifying digits and predicting house prices,
    the data came in vectorized form, so we were able to skip this step.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的所有输入和目标通常都必须是浮点数据张量（或者在特定情况下，整数或字符串张量）。无论你需要处理的数据是声音、图像还是文本，你都必须首先将其转换为张量，这一步称为*数据向量化*。例如，在第4章中的两个文本分类示例中，我们从文本表示为整数列表（代表单词序列）开始，然后使用一种称为独热编码的方法将它们转换为float32数据张量。在分类数字和预测房价的示例中，数据以向量化形式提供，因此我们可以跳过此步骤。
- en: VALUE NORMALIZATION
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 值归一化
- en: In the MNIST digit-classification example from chapter 2, we started with image
    data encoded as integers in the 0–255 range, encoding grayscale values. Before
    we fed this data into our network, we divide by 255 so we’d end up with floating-point
    values in the 0–1 range. Similarly, when predicting house prices, we started with
    features that took a variety of ranges—some features had small floating-point
    values, and others had fairly large integer values. Before we fed this data into
    our network, we had to normalize each feature independently so that it had a standard
    deviation of 1 and a mean of 0.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2章的MNIST数字分类示例中，我们从图像数据开始，这些数据编码为0-255范围内的整数，编码灰度值。 在将这些数据馈送到我们的网络之前，我们将其除以255，以便最终得到0-1范围内的浮点值。
    类似地，当预测房屋价格时，我们从具有各种范围的特征开始 - 一些特征具有较小的浮点值，而另一些特征具有相当大的整数值。 在将这些数据馈送到我们的网络之前，我们必须独立地对每个特征进行归一化，使其具有标准差为1和平均值为0。
- en: 'In general, it isn’t safe to feed into a neural network data that takes relatively
    large values (e.g., multidigit integers that are much larger than the initial
    values taken by the weights of a network) or data that is heterogeneous (e.g.,
    data where one feature is in the range 0–1 and another is in the range 100–200).
    Doing so can trigger large gradient updates that will prevent the network from
    converging. To make learning easier for your network, your data should have the
    following characteristics:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将相对较大的值（例如，比网络权重的初始值大得多的多位整数）或异构数据（例如，其中一个特征在0-1范围内，另一个特征在100-200范围内的数据）馈入神经网络是不安全的。
    这样做可能会触发大的梯度更新，从而阻止网络收敛。 为了使网络更容易学习，您的数据应具有以下特征：
- en: '*Take small values*—Typically, most values should be in the 0–1 range.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*取小值* - 通常，大多数值应在0-1范围内。'
- en: '*Be homogenous*—All features should take values in roughly the same range.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*要同质化* - 所有特征的值应该在大致相同的范围内。'
- en: 'Additionally, the following stricter normalization practice is common and can
    help, although it isn’t always necessary (e.g., we didn’t do this in the digit-classification
    example):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下更严格的归一化做法是常见的，并且可能有所帮助，尽管并不总是必要的（例如，在数字分类示例中我们没有这样做）：
- en: Normalize each feature independently to have a mean of 0.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立地对每个特征进行归一化，使其具有平均值为0。
- en: Normalize each feature independently to have a standard deviation of 1
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立地对每个特征进行归一化，使其具有标准差为1
- en: 'This is easy to do using the scale() function:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这很容易使用scale()函数实现：
- en: x <- scale(x)➊
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: x <- scale(x)➊
- en: ➊ **Assuming x is a 2D data matrix of shape (samples, features)**
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ➊ **假设x是形状为（样本，特征）的2D数据矩阵**
- en: HANDLING MISSING VALUES
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: 'You may sometimes have missing values in your data. For instance, in the house-price
    example, the first feature was the per capita crime rate. What if this feature
    wasn’t available for all samples? You’d then have missing values in the training
    or test data. You could just discard the feature entirely, but you don’t necessarily
    have to do so:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据中有时可能会有缺失值。 例如，在房价示例中，第一个特征是人均犯罪率。 如果这个特征在所有样本中都不可用怎么办？ 然后，您在训练或测试数据中会有缺失值。
    您可以简单地丢弃整个特征，但您不一定必须这样做：
- en: If the feature is categorical, it’s safe to create a new category that means
    “the value is missing.” The model will automatically learn what this implies with
    respect to the targets.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果该特征是分类的，则安全地创建一个新类别，表示“值丢失”。 模型将自动学习这对于目标意味着什么。
- en: If the feature is numerical, avoid inputting an arbitrary value like 0, because
    it may create a discontinuity in the latent space formed by your features, making
    it harder for a model trained on it to generalize. Instead, consider replacing
    the missing value with the average or median value for the feature in the dataset.
    You could also train a model to predict the feature value given the values of
    other features
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果该特征是数值的，请避免输入像0这样的任意值，因为它可能会在由特征形成的潜在空间中创建不连续性，使得在其上训练的模型更难泛化。 相反，考虑使用数据集中该特征的平均值或中位数值替换缺失值。
    您还可以训练一个模型，根据其他特征的值来预测特征值。
- en: 'Note that if you’re expecting missing categorical features in the test data,
    but the network was trained on data without any missing values, the network won’t
    have learned to ignore missing values! In this situation, you should artificially
    generate training samples with missing entries: copy some training samples several
    times, and drop some of the categorical features that you expect are likely to
    be missing in the test data.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果您预计测试数据中缺少分类特征，而网络是在没有任何缺失值的数据上训练的，那么该网络将无法学会忽略缺失值！在这种情况下，您应该人为生成含有缺失项的训练样本：多次复制一些训练样本，并删除您预计在测试数据中可能缺失的一些分类特征。
- en: 6.2.2 Choose an evaluation protocol
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 选择评估协议
- en: 'As you learned in the previous chapter, the purpose of a model is to achieve
    generalization, and every modeling decision you will make throughout the model-development
    process will be guided by *validation metrics* that seek to measure generalization
    performance. The goal of your validation protocol is to accurately estimate what
    your success metric of choice (such as accuracy) will be on actual production
    data. The reliability of that process is critical to building a useful model.
    In chapter 5, we reviewed three common evaluation protocols:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在上一章中所学，模型的目的是实现泛化，而在整个模型开发过程中您做出的每个决策都将由*验证指标*指导，以衡量泛化性能。您的评估协议的目标是准确估算您选择的成功指标（例如准确率）在实际生产数据上的表现。这个过程的可靠性对于构建有用的模型至关重要。在第5章中，我们回顾了三种常见的评估协议：
- en: '*Maintaining a holdout validation set*—This is the way to go when you have
    plenty of data.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*维护保留验证集*——当您有大量数据时，这是一种可行的方法。'
- en: '*Doing K-fold cross-validation*—This is the right choice when you have too
    few samples for holdout validation to be reliable.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*进行 K 折交叉验证*——当您缺乏足够样本用于保留验证时，这是一种可靠的选择。'
- en: '*Doing iterated K-fold validation*—This is for performing highly accurate model
    evaluation when little data is available.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*迭代 K 折验证*——这是在数据有限时进行高精度模型评估的方法。'
- en: Pick one of these. In most cases, the first will work well enough. As you learned,
    though, always be mindful of the *representativity* of your validation set, and
    be careful not to have redundant samples between your training set and your validation
    set.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 选择其中之一。在大多数情况下，首选方法会足够有效。然而，如您所知，始终要注意验证集的*代表性*，并且要小心训练集和验证集之间没有重复的样本。
- en: 6.2.3 Beat a baseline
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 击败基准
- en: 'As you start working on the model itself, your initial goal is to achieve *statistical
    power*, as you saw in chapter 5: that is, to develop a small model that is capable
    of beating a simple baseline. At this stage, these are the three most important
    things you should focus on:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始真正着手于模型时，您的初始目标是获得*统计效力*，正如您在第5章中看到的：也就是说，开发一个能够击败简单基准的小模型。在这个阶段，您应该关注以下三点：
- en: '*Feature engineering*—Filter out uninformative features (feature selection),
    and use your knowledge of the problem to develop new features that are likely
    to be useful.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程*——过滤掉无用的特征（特征选择），并利用您对问题的了解开发可能有用的新特征。'
- en: '*Selecting the correct architecture priors*—What type of model architecture
    will you use? A densely connected network, a convnet, a recurrent neural network,
    a transformer? Is deep learning even a good approach for the task, or should you
    use something else?'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择正确的架构先验*——您将使用哪种类型的模型架构？密集连接的网络、卷积神经网络、循环神经网络、transformers？深度学习是否适合这个任务，还是应该使用其他方法？'
- en: '*Selecting a good-enough training configuration*—What loss function should
    you use? What batch size and learning rate?'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择足够好的训练配置*——您应该使用什么损失函数？使用多大批量和学习率？'
- en: For most problems, you can start from existing templates. You’re not the first
    person to try to build a spam detector, a music recommendation engine, or an image
    classifier. Make sure you research prior art to identify the feature-engineering
    techniques and model architectures that are most likely to perform well on your
    task.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数问题，您可以从现有的模板开始。您并不是第一个尝试构建垃圾邮件检测器、音乐推荐引擎或图像分类器的人。确保您研究了先前的技术，以确定最有可能在您的任务上表现良好的特征工程技术和模型架构。
- en: 'Note that it’s not always possible to achieve statistical power. If you can’t
    beat a simple baseline after trying multiple reasonable architectures, it may
    be that the answer to the question you’re asking isn’t present in the input data.
    Remember that you’re making two hypotheses:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，不一定总能获得统计功效。如果在尝试了多种合理的架构后仍无法击败一个简单的基线，那么可能是你所问的问题在输入数据中没有答案。请记住，你有两个假设：
- en: You hypothesize that your outputs can be predicted given your inputs
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设可以根据输入来预测你的输出。
- en: You hypothesize that the available data is sufficiently informative to learn
    the relationship between inputs and outputs
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设可用数据足够信息丰富，可以学习输入和输出之间的关系。
- en: It may well be that these hypotheses are false, in which case you must go back
    to the drawing board.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能这些假设是错误的，如果是这样，你必须回到起点。
- en: '**Picking the right loss function**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择合适的损失函数**'
- en: It’s often not possible to directly optimize for the metric that measures success
    on a problem. Sometimes there is no easy way to turn a metric into a loss function;
    loss functions, after all, need to be computable given only a mini-batch of data
    (ideally, a loss function should be computable for as little as a single data
    point) and must be differentiable (otherwise, you can’t use backpropagation to
    train your network). For instance, the widely used classification metric ROC AUC
    can’t be directly optimized. Hence, in classification tasks, it’s common to optimize
    for a proxy metric of ROC AUC, such as cross-entropy. In general, you can hope
    that the lower the cross-entropy gets, the higher the ROC AUC will be.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 往往不可能直接优化衡量问题成功的度量标准。有时，将度量标准转化为损失函数并不容易；毕竟，损失函数需要仅通过一个小批量数据就可以计算出来（理想情况下，损失函数应该可以计算出一个数据点）并且必须可微分（否则，你不能使用反向传播来训练你的网络）。例如，广泛使用的分类度量
    ROC AUC 不能直接优化。因此，在分类任务中，通常会优化 ROC AUC 的代理度量标准，例如交叉熵。一般来说，你可以期望交叉熵越低，ROC AUC 就越高。
- en: The following table can help you choose a last-layer activation and a loss function
    for a few common problem types.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格可以帮助你为几种常见的问题类型选择最后一层激活函数和损失函数。
- en: Choosing the right last-layer activation and loss function
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的最后一层激活函数和损失函数
- en: '| Problem type | Last-layer activation | Loss function |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 问题类型 | 最后一层激活函数 | 损失函数 |'
- en: '| Binary classification | sigmoid | binary_crossentropy |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 二元分类 | sigmoid | binary_crossentropy |'
- en: '| Multiclass, single-label classification | softmax | categorical_crossentropy
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 多类别、单标签分类 | softmax | categorical_crossentropy |'
- en: '| Multiclass, multilabel classification | sigmoid | binary_crossentropy |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 多类别、多标签分类 | sigmoid | binary_crossentropy |'
- en: '6.2.4 Scale up: Develop a model that overfits'
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 扩展规模：开发一个过拟合的模型
- en: Once you’ve obtained a model that has statistical power, the question becomes,
    is your model sufficiently powerful? Does it have enough layers and parameters
    to properly model the problem at hand? For instance, a logistic regression model
    has statistical power on MNIST but wouldn’t be sufficient to solve the problem
    well. Remember that the universal tension in machine learning is between optimization
    and generalization. The ideal model is one that stands right at the border between
    underfitting and over-fitting, between undercapacity and overcapacity. To figure
    out where this border lies, first you must cross it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你得到了一个具有统计功效的模型，问题就变成了，你的模型是否足够强大？它是否有足够的层和参数来正确地建模手头的问题？例如，逻辑回归模型在 MNIST
    上具有统计功效，但不能很好地解决问题。请记住，机器学习中的普遍紧张关系在于优化和泛化之间。理想的模型是站在欠拟合和过拟合之间的边界上，站在容量不足和容量过大之间。要确定这个边界在哪里，首先你必须越过它。
- en: 'To figure out how big a model you’ll need, you must develop a model that overfits.
    This is fairly easy, as you learned in chapter 5:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定你需要多大的模型，你必须开发一个过拟合的模型。这相当容易，就像你在第五章学到的那样：
- en: '**1** Add layers.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**1** 增加层。'
- en: '**2** Make the layers bigger.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**2** 使层变大。'
- en: '**3** Train for more epochs.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**3** 训练更多的时期。'
- en: Always monitor the training loss and validation loss, as well as the training
    and validation values for any metrics you care about. When you see that the model’s
    performance on the validation data begins to degrade, you’ve achieved overfitting.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 总是监视训练损失和验证损失，以及你关心的任何指标的训练和验证值。当你发现模型在验证数据上的性能开始下降时，你就已经出现了过拟合。
- en: 6.2.5 Regularize and tune your model
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.5 正则化和调优你的模型
- en: Once you’ve achieved statistical power and you’re able to overfit, you know
    you’re on the right path. At this point, your goal becomes to maximize generalization
    performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您达到了统计功率并且能够过度拟合，您就知道您正在正确的道路上。在这一点上，您的目标是最大化泛化性能。
- en: 'This phase will take the most time: you’ll repeatedly modify your model, train
    it, evaluate on your validation data (not the test data at this point), modify
    it again, and repeat, until the model is as good as it can get. Here are some
    things you should try:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段将花费最多的时间：您将反复修改您的模型，训练它，在验证数据上评估（此时不是测试数据），再次修改它，然后重复，直到模型达到最佳状态。以下是一些您应该尝试的事项：
- en: Try different architectures; add or remove layers
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的架构；添加或删除层次
- en: Add dropout.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加丢失。
- en: If your model is small, add L1 or L2 regularization.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的模型很小，可以添加L1或L2正则化。
- en: Try different hyperparameters (such as the number of units per layer or the
    learning rate of the optimizer) to find the optimal configuration.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的超参数（例如每层的单元数或优化器的学习率）以找到最佳配置。
- en: 'Optionally, iterate on data curation or feature engineering: collect and annotate
    more data, develop better features, or remove features that don’t seem to be informative'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地，对数据筛选或特征工程进行迭代：收集并注释更多数据，开发更好的特征，或者删除看起来不具信息量的特征。
- en: It’s possible to automate a large chunk of this work by using *automated hyperparameter
    tuning software*, such as KerasTuner. We’ll cover this in chapter 13.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用*自动化超参数调整软件*（例如KerasTuner）自动化大部分这项工作。我们将在第13章中介绍这个。
- en: 'Be mindful of the following: Every time you use feedback from your validation
    process to tune your model, you leak information about the validation process
    into the model. Repeated just a few times, this is innocuous; done systematically
    over many iterations, it will eventually cause your model to overfit to the validation
    process (even though no model is directly trained on any of the validation data).
    This makes the evaluation process less reliable.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 慎重考虑以下事项：每次您利用验证过程的反馈来调整模型时，都会将关于验证过程的信息泄漏到模型中。这样做几次是无害的；但如果系统地进行多次迭代，最终会导致您的模型过度拟合验证过程（即使没有任何模型直接在任何验证数据上进行训练）。这会使评估过程变得不太可靠。
- en: Once you’ve developed a satisfactory model configuration, you can train your
    final production model on all the available data (training and validation) and
    evaluate it one last time on the test set. If it turns out that performance on
    the test set is significantly worse than the performance measured on the validation
    data, this may mean either that your validation procedure wasn’t reliable after
    all, or that you began over-fitting to the validation data while tuning the parameters
    of the model. In this case, you may want to switch to a more reliable evaluation
    protocol (such as iterated *K*-fold validation).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您开发出令人满意的模型配置，您可以在所有可用数据（训练和验证）上训练最终的生产模型，并最后在测试集上进行最后一次评估。如果结果显示测试集上的性能明显比在验证数据上测量的性能差，这可能意味着您的验证程序毕竟不够可靠，或者您在调整模型参数时开始对验证数据过拟合。在这种情况下，您可能希望切换到更可靠的评估协议（例如迭代的*K*-折验证）。
- en: 6.3 Deploy the model
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 部署模型
- en: Your model has successfully cleared its final evaluation on the test set—it’s
    ready to be deployed and to begin its productive life.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您的模型已经成功地通过了对测试集的最终评估——它已经准备好部署并开始其生产生活。
- en: 6.3.1 Explain your work to stakeholders and set expectations
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 向利益相关者解释您的工作并设定期望
- en: Success and customer trust are about consistently meeting or exceeding people’s
    expectations. The actual system you deliver is only half of that picture; the
    other half is setting appropriate expectations before launch.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 成功和客户信任意味着始终满足或超越人们的期望。您提供的实际系统只是其中一部分；另一部分是在发布之前设定适当的期望。
- en: The expectations of nonspecialists toward AI systems are often unrealistic.
    For example, they might expect that the system “understands” its task and is capable
    of exercising human-like common sense in the context of the task. To address this,
    you should consider showing some examples of the *failure modes* of your model
    (e.g., show what incorrectly classified samples look like, especially those for
    which the misclassification seems surprising).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 非专业人士对人工智能系统的期望往往是不现实的。例如，他们可能期望系统“理解”其任务，并能够在任务的上下文中行使类似人类常识的能力。为了解决这个问题，您应该考虑展示一些模型的*失败模式*的示例（例如，展示一些被错误分类的样本是什么样子，特别是对于那些误分类看起来令人惊讶的样本）。
- en: They might also expect human-level performance, especially for processes that
    were previously handled by people. Most machine learning models, because they
    are (imperfectly) trained to approximate human-generated labels, do not nearly
    get there. You should clearly convey model performance expectations. Avoid using
    abstract statements like “The model has 98% accuracy” (which most people mentally
    round up to 100%), and prefer talking, for instance, about false negative rates
    and false positive rates. You could say, “With these settings, the fraud detection
    model would have a 5% false negative rate and a 2.5% false positive rate. Every
    day, an average of 200 valid transactions would be flagged as fraudulent and sent
    for manual review, and an average of 14 fraudulent transactions would be missed.
    An average of 266 fraudulent transactions would be correctly caught.” Clearly
    relate the model’s performance metrics to business goals.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 他们可能还期望人类级别的性能，特别是对于以前由人处理的过程。大多数机器学习模型，因为它们（不完美地）被训练来近似人生成的标签，所以并不完全达到那个水平。您应该清楚地传达模型的性能期望。避免使用抽象的陈述，比如“该模型的准确率为98%”（大多数人心理上会四舍五入为100%），而更倾向于讨论例如假阴性率和假阳性率。您可以说，“使用这些设置，欺诈检测模型的假阴性率为5%，假阳性率为2.5%。每天，平均会有200笔有效交易被标记为欺诈并发送进行手动审查，而平均会漏掉14笔欺诈交易。平均会正确捕捉到266笔欺诈交易。”将模型的性能指标清晰地与业务目标相关联。
- en: You should also make sure to discuss with stakeholders the choice of key launch
    parameters—for instance, the probability threshold at which a transaction should
    be flagged (different thresholds will produce different false negative and false
    positive rates). Such decisions involve tradeoffs that can be handled only with
    a deep understanding of the business context.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该确保与利益相关者讨论关键的启动参数选择，例如交易应该在何种概率阈值下被标记为可疑（不同的阈值会产生不同的假阴性和假阳性率）。此类决策涉及可以通过对业务背景有深入了解来处理的权衡。
- en: 6.3.2 Ship an inference model
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.2 运送一个推理模型
- en: 'A machine learning project doesn’t end when you arrive at a script that can
    save a trained model. You rarely put in production the exact same model object
    that you manipulated during training. First, you may want to export your model
    to something other than R:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目并不会在您获得可以保存已训练模型的脚本时结束。您很少会将在训练过程中操作的确切模型对象投入生产。首先，您可能希望将模型导出到R之外的其他内容：
- en: Your production environment may not support R at all—for instance, if it’s a
    mobile app or an embedded system.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的生产环境可能根本不支持R——例如，如果它是一个移动应用程序或嵌入式系统。
- en: If the rest of the app isn’t in R (it could be in JavaScript, C++, etc.), the
    use of R to serve a model may induce significant overhead
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用的其余部分不是用R编写的（可能是JavaScript、C++等），则使用R来提供模型可能会导致显着的开销。
- en: Second, because your production model will be used only to output predictions
    (a phase called *inference*), rather than for training, you have room to perform
    various optimizations that can make the model faster and reduce its memory footprint.
    Let’s take a quick look at the different model deployment options you have available.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，因为您的生产模型仅用于输出预测（称为*推理*阶段），而不是用于训练，所以您可以进行各种优化，以使模型更快速、减少其内存占用。让我们快速看一下您可以使用的不同模型部署选项。
- en: DEPLOYING A MODEL AS A REST API
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将模型部署为REST API
- en: 'This is perhaps the common way to turn a model into a product: install TensorFlow
    on a server or cloud instance, and query the model’s predictions via a REST API.
    You could build your own serving app using something like Shiny (or any other
    R webevelopment library), or the tfdeploy R package, which uses TensorFlow’s own
    library for shipping models as APIs, called *TensorFlow Serving* ([http://www.tensorflow.org/tfx/guide/serving](http://www.tensorflow.org/tfx/guide/serving)).
    With tfdeploy and TensorFlow Serving, you can deploy a Keras model in minutes.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是将模型转化为产品的常见方式：在服务器或云实例上安装TensorFlow，并通过REST API查询模型的预测结果。您可以使用类似Shiny（或任何其他R
    web开发库）或tfdeploy R包构建自己的服务应用，后者使用TensorFlow自己的用于将模型作为API部署的库，称为*TensorFlow Serving*（[http://www.tensorflow.org/tfx/guide/serving](http://www.tensorflow.org/tfx/guide/serving)）。使用tfdeploy和TensorFlow
    Serving，您可以在几分钟内部署一个Keras模型。
- en: 'You should use this deployment setup when:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当您：
- en: The application that will consume the model’s prediction will have reliable
    access to the internet (obviously). For instance, if your application is a mobile
    app, serving predictions from a remote API means that the application won’t be
    usable in airplane mode or in a low-connectivity environment.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费模型的应用程序将始终可靠地访问互联网（显然）。例如，如果您的应用程序是手机应用程序，从远程API提供预测意味着不成飞行模式或低网络连通性环境下应用程序将无法使用。
- en: 'The application does not have strict latency requirements: the request, inference,
    and answer round trip will typically take around 500 ms.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序没有严格的延迟要求：请求、推理和答案的往返通常需要约500毫秒。
- en: 'The input data sent for inference is not highly sensitive: the data will need
    to be available on the server in a decrypted form, because it will need to be
    seen by the model (but note that you should use SSL encryption for the HTTP request
    and answer)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送用于推理的输入数据不高度敏感：数据需要以解密的形式在服务器上可用，因为模型需要看它（但请注意，应该使用 SSL 加密 HTTP 请求和答案）。
- en: For instance, the image search engine project, the music recommendation system,
    the credit card fraud detection project, and the satellite imagery project are
    all good fits for serving via a REST API.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，图像搜索引擎项目、音乐推荐系统、信用卡欺诈检测项目和卫星图像项目都适合通过 REST API 提供服务。
- en: An important question when deploying a model as a REST API is whether you want
    to host the code on your own, or whether you want to use a fully managed third-party
    cloud service. For instance, Cloud AI Platform, a Google product, lets you simply
    upload your TensorFlow model to Google Cloud Storage (GCS), and it gives you an
    API endpoint to query it. It takes care of many practical details such as batching
    predictions, load balancing, and scaling.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当将模型部署为 REST API 时，一个重要的问题是你是想托管自己的代码，还是想使用一个完全托管的第三方云服务，比如谷歌的 Cloud AI Platform
    可以让你简单地将 TensorFlow 模型上传到 Google Cloud Storage （GCS），并提供一个 API 终端点来查询它。它会自动处理许多实际的细节，例如批量处理预测，负载均衡和扩展。
- en: DEPLOYING A MODEL ON A DEVICE
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在设备上部署模型
- en: 'Sometimes, you may need your model to live on the same device that runs the
    application that uses it—maybe a smartphone, an embedded ARM CPU on a robot, or
    a microcontroller on a tiny device. You may have seen a camera capable of automatically
    detecting people and faces in the scenes you pointed it at: that was probably
    a small deep learning model running directly on the camera.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你需要让模型运行在使用它的应用程序运行的同一个设备上，比如智能手机、机器人上的嵌入式 ARM CPU 或微型设备上的微控制器。你可能已经见过一款相机能够在你拍摄的场景中自动识别出人和面孔：这可能是一个小型深度学习模型直接在相机上运行。
- en: 'You should use this setup when:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要这样一个设置的时候，你应该：
- en: Your model has strict latency constraints or needs to run in a low-connectivity
    environment. If you’re building an immersive augmented reality application, querying
    a remote server is not a viable option.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的模型有严格的延迟限制或需要在低网络连通性环境下运行，那么从远程服务器查询可能不是一个可行的选择，比如你在开发一个沉浸式增强现实应用程序。
- en: Your model can be made sufficiently small that it can run under the memory and
    power constraints of the target device. You can use the TensorFlow Model Optimization
    Toolkit to help with this ([http://www.tensorflow.org/model_optimization](http://www.tensorflow.org/model_optimization)).
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的模型可以足够小，以便在目标设备的内存和功率约束下运行。你可以使用 TensorFlow Model Optimization Toolkit 来帮助实现这一点（[http://www.tensorflow.org/model_optimization](http://www.tensorflow.org/model_optimization)）。
- en: Getting the highest possible accuracy isn’t mission critical for your task.
    There is always a tradeoff between runtime efficiency and accuracy, so memory
    and power constraints often require you to ship a model that isn’t quite as good
    as the best model you could run on a large GPU.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于你的任务，获得最高可能的准确度并不是至关重要的。运行效率和准确性之间总是存在一个权衡，因此内存和电源限制通常要求您使用一个不如在大型GPU上运行的最佳模型好的模型。
- en: The input data is strictly sensitive and thus shouldn’t be decryptable on a
    remote server
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据是严格保密的，因此不应该在远程服务器上解密
- en: Our spam detection model will need to run on the end user’s smartphone as part
    of the chat app, because messages are end-to-end encrypted and thus cannot be
    read by a remotely hosted model. Likewise, the bad-cookie detection model has
    strict latency constraints and will need to run at the factory. Thankfully, in
    this case, we don’t have any power or space constraints, so we can actually run
    the model on a GPU.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的垃圾邮件检测模型将需要作为聊天应用的一部分在最终用户的智能手机上运行，因为消息是端到端加密的，因此无法被远程托管模型读取。同样，恶意 cookie
    检测模型具有严格的延迟约束，需要在工厂运行。幸运的是，在这种情况下，我们没有任何功耗或空间约束，因此实际上可以在 GPU 上运行模型。
- en: To deploy a Keras model on a smartphone or embedded device, your go-to solution
    is TensorFlow Lite ([http://www.tensorflow.org/lite](http://www.tensorflow.org/lite)).
    It’s a framework for efficient on-device deep learning inference that runs on
    Android and iOS smartphones, as well as ARM64-based computers, Raspberry Pi, or
    certain microcontrollers. It includes a converter that can straightforwardly turn
    your Keras model into the TensorFlow Lite format.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要在智能手机或嵌入式设备上部署 Keras 模型，您的首选解决方案是 TensorFlow Lite ([http://www.tensorflow.org/lite](http://www.tensorflow.org/lite))。这是一个用于在设备上高效进行深度学习推断的框架，可在
    Android 和 iOS 智能手机上运行，以及基于 ARM64 的计算机、树莓派或某些微控制器。它包括一个转换器，可以直接将您的 Keras 模型转换为
    TensorFlow Lite 格式。
- en: DEPLOYING A MODEL IN THE BROWSER
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在浏览器中部署模型
- en: Deep learning is often used in browser-based or desktop-based JavaScript applications.
    Although it is usually possible to have the application query a remote model via
    a REST API, there can be key advantages in having the model run directly in the
    browser, on the user’s computer (utilizing GPU resources if they’re available).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习经常用于基于浏览器或桌面的 JavaScript 应用程序。尽管通常可以让应用程序通过 REST API 查询远程模型，但直接在浏览器中运行模型，即在用户的计算机上运行（如果可用，则利用
    GPU 资源）可能具有关键优势。
- en: 'Use this setup when:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此设置时：
- en: You want to offload compute to the end user, which can dramatically reduce server
    costs.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您希望将计算卸载到最终用户，这可以大大降低服务器成本。
- en: The input data needs to stay on the end user’s computer or phone. For instance,
    in our spam detection project, the web version and the desktop version of the
    chat app (implemented as a cross-platform app written in JavaScript) should use
    a locally run model.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据需要保留在最终用户的计算机或手机上。例如，在我们的垃圾邮件检测项目中，聊天应用的 Web 版本和桌面版本（以 JavaScript 编写的跨平台应用程序）应使用在本地运行的模型。
- en: Your application has strict latency constraints. Although a model running on
    the end user’s laptop or smartphone is likely to be slower than one running on
    a large GPU on your own server, you don’t have the extra 100 ms of network round
    trip.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的应用程序具有严格的延迟约束。虽然在最终用户的笔记本电脑或智能手机上运行的模型很可能比在您自己服务器上的大型 GPU 上运行的模型慢，但您没有额外的
    100 毫秒网络往返时间。
- en: You need your app to keep working without connectivity, after the model has
    been downloaded and cached
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型已被下载并缓存后，您需要您的应用程序在没有连接的情况下继续工作
- en: 'You should go with this option only if your model is small enough that it won’t
    hog the CPU, GPU, or RAM of your user’s laptop or smartphone. In addition, because
    the entire model will be downloaded to the user’s device, you should make sure
    that nothing about the model needs to stay confidential. Be mindful of the fact
    that, given a trained deep learning model, it is usually possible to recover some
    information about the training data: better not to make your trained model public
    if it was trained on sensitive data.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在您的模型足够小以至于不会占用用户笔记本电脑或智能手机的 CPU、GPU 或 RAM 时，才应选择此选项。此外，由于整个模型将下载到用户的设备上，您应确保模型的任何内容都不需要保密。请注意，鉴于一个经过训练的深度学习模型，通常可以恢复一些关于训练数据的信息：如果模型是在敏感数据上进行训练的，则最好不要将您的经过训练的模型公开。
- en: To deploy a model in JavaScript, the TensorFlow ecosystem includes TensorFlow.js
    ([http://www.tensorflow.org/js](http://www.tensorflow.org/js)), a JavaScript library
    for deep learning that implements almost all of the Keras API (originally developed
    under the working name WebKeras) as well as many lower-level TensorFlow APIs.
    You can easily import a saved Keras model into TensorFlow.js to query it as part
    of your browser-based JavaScript app or your desktop Electron app.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 JavaScript 中部署模型，TensorFlow 生态系统包括 TensorFlow.js ([http://www.tensorflow.org/js](http://www.tensorflow.org/js))，这是一个用于深度学习的
    JavaScript 库，几乎实现了所有的 Keras API（最初以 WebKeras 为工作名称开发）以及许多较低级别的 TensorFlow API。您可以轻松地将保存的
    Keras 模型导入到 TensorFlow.js 中，以便作为浏览器中的 JavaScript 应用程序或桌面 Electron 应用程序的一部分进行查询。
- en: INFERENCE MODEL OPTIMIZATION
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推断模型优化
- en: Optimizing your model for inference is especially important when deploying in
    an environment with strict constraints on available power and memory (smartphones
    and embedded devices) or for applications with low latency requirements. You should
    always seek to optimize your model before importing into TensorFlow.js or exporting
    it to TensorFlow Lite.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署在可用功率和内存有严格限制的环境（智能手机和嵌入式设备）或具有低延迟要求的应用程序中，优化推理模型尤为重要。你应该在将模型导入到 TensorFlow.js
    或将其导出到 TensorFlow Lite 之前始终寻求优化你的模型。
- en: 'You can apply two popular optimization techniques:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用两种流行的优化技术：
- en: '*Weight pruning*—Not every coefficient in a weight tensor contributes equally
    to the predictions. It’s possible to considerably lower the number of parameters
    in the layers of your model by keeping only the most significant ones. This reduces
    the memory and compute footprint of your model, at a small cost in performance
    metrics. By deciding how much pruning you want to apply, you are in control of
    the tradeoff between size and accuracy.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*权重剪枝*——权重张量中的每个系数对预测的贡献并不相等。通过仅保留最显著的系数，可以大大降低模型层中的参数数量。这减少了模型的内存和计算占用，但性能指标略有损失。通过决定要应用多少剪枝，你可以控制尺寸和准确度之间的权衡。'
- en: '*Weight quantization*—Deep learning models are trained with single-precision
    floating-point (float32) weights. However, it’s possible to *quantize* weights
    to 8-bit signed integers (int8) to get an inference-only model that’s a quarter
    the size but remains near the accuracy of the original model.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*权重量化*——深度学习模型是用单精度浮点（float32）权重训练的。然而，可以将权重量化为 8 位有符号整数（int8），以获得一个仅用于推理的模型，其大小是原模型的四分之一，但保持接近原模型的准确度。'
- en: The TensorFlow ecosystem includes a weight pruning and quantization toolkit
    ([http://www.tensorflow.org/model_optimization](http://www.tensorflow.org/model_optimization))
    that is deeply integrated with the Keras API.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 生态系统包括一个权重剪枝和量化工具包（[http://www.tensorflow.org/model_optimization](http://www.tensorflow.org/model_optimization)），与
    Keras API 深度集成。
- en: 6.3.3 Monitor your model in the wild
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.3 在野外监控你的模型
- en: You’ve exported an inference model, you’ve integrated it into your application,
    and you’ve done a dry run on production data—the model behaved exactly as you
    expected. You’ve written unit tests as well as logging and status-monitoring code—
    perfect. Now it’s time to press the big red button and deploy to production.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经导出了推理模型，将其集成到你的应用程序中，并在生产数据上进行了一次干跑——模型的行为与你预期的完全一致。你已经编写了单元测试以及日志记录和状态监控代码——完美。现在是时候按下大红按钮，部署到生产环境了。
- en: 'Even this is not the end. Once you’ve deployed a model, you need to keep monitoring
    its behavior, its performance on new data, its interaction with the rest of the
    application, and its eventual impact on business metrics:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 但这还不是结束。一旦部署了模型，你需要继续监控其行为，对新数据的性能、与应用程序其余部分的交互以及对业务指标的最终影响进行监控：
- en: 'Is user engagement in your online radio station up or down after deploying
    the new music recommendation system? Has the average ad click-through rate increased
    after switching to the new click-through-rate-prediction model? Consider using
    *randomized A/B testing* to isolate the impact of the model itself from other
    changes: a subset of cases should go through the new model, whereas another control
    subset should stick to the old process. Once sufficiently many cases have been
    processed, the difference in outcomes between the two is likely attributable to
    the model.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在部署新的音乐推荐系统后，你的在线电台用户参与度是上升还是下降？切换到新的点击率预测模型后，平均广告点击率是否增加了？考虑使用*随机化 A/B 测试*来将模型本身的影响与其他变化隔离开来：一部分案例应通过新模型处理，而另一部分对照组应坚持使用旧流程。一旦处理了足够多的案例，两者之间结果的差异很可能归因于模型。
- en: 'If possible, do a regular manual audit of the model’s predictions on production
    data. It’s generally possible to reuse the same infrastructure as for data annotation:
    send some fraction of the production data to be manually annotated, and compare
    the model’s predictions to the new annotations. For instance, you should definitely
    do this for the image search engine and the bad-cookie flagging system.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能的话，请定期手动审计模型对生产数据的预测。通常可以重用与数据注释相同的基础设施：将一部分生产数据发送到手动注释，然后将模型的预测与新注释进行比较。例如，你绝对应该对图像搜索引擎和坏
    cookie 标记系统进行这样的操作。
- en: When manual audits are impossible, consider alternative evaluation avenues such
    as user surveys (e.g., in the case of the spam and offensive-content flagging
    system)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当无法进行手动审计时，考虑替代性的评估途径，例如用户调查（例如在垃圾邮件和不良内容标记系统的情况下）
- en: 6.3.4 Maintain your model
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.4 维护你的模型
- en: 'Finally, no model lasts forever. You’ve already learned about *concept drift*:
    over time, the characteristics of your production data will change, gradually
    degrading the performance and relevance of your model. The life span of your music
    recommendation system will be counted in weeks. For the credit card fraud detection
    system, it will be days; a couple of years is the best case for the image search
    engine.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，没有一个模型能永远持续。你已经学习了关于*概念漂移*的内容：随着时间的推移，你的生产数据的特征会发生变化，逐渐降低你的模型的性能和相关性。你的音乐推荐系统的寿命将被计算为几周。对于信用卡欺诈检测系统，将是几天；图像搜索引擎的最佳情况是几年。
- en: 'As soon as your model has launched, you should be getting ready to train the
    next generation that will replace it. As such:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的模型已经启动，你应该准备好训练下一个将取代它的代代相传。因此：
- en: Watch out for changes in the production data. Are new features becoming available?
    Should you expand or otherwise edit the label set?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意生产数据的变化。有新功能可用吗？需要扩展或编辑标签集吗？
- en: Keep collecting and annotating data, and keep improving your annotation pipeline
    over time. In particular, you should pay special attention to collecting samples
    that seem to be difficult for your current model to classify—such samples are
    the most likely to help improve performance
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续收集和注释数据，并随时间不断改进你的注释管道。特别是，你应该特别关注收集对你当前的模型分类难度较大的样本——这些样本最有可能帮助改善性能
- en: 'This concludes the universal workflow of machine learning—that’s a lot of things
    to keep in mind. It takes time and experience to become an expert, but don’t worry:
    you’re already a lot wiser than you were a few chapters ago. You are now familiar
    with the big picture—the entire spectrum of what machine learning projects entail.
    Although most of this book will focus on model development, you’re now aware that
    it’s only one part of the entire workflow. Always keep in mind the big picture!'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是机器学习的通用工作流程——需要牢记很多东西。要成为专家，需要时间和经验，但不用担心：相对于前几章，你已经更加聪明了。现在你已经熟悉大局——机器学习项目所涉及的整个光谱。虽然本书的大部分内容都将集中在模型开发上，但你现在知道这只是整个工作流程的一部分。始终记住大局！
- en: Summary
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'When you take on a new machine learning project, first define the problem at
    hand:'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你接手一个新的机器学习项目时，首先定义你手头的问题：
- en: Understand the broader context of what you’re setting out to do—what’s the end
    goal and what are the constraints?
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解你所要做的更广泛的背景——终极目标和限制是什么？
- en: Collect and annotate a dataset; make sure you understand your data in depth.
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集并注释数据集；确保你深入了解你的数据。
- en: Choose how you’ll measure success for your problem—what metrics will you monitor
    on your validation data?
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择如何衡量问题的成功：在验证数据上监测哪些度量标准？
- en: 'Once you understand the problem and you have an appropriate dataset, develop
    a model:'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦你理解了问题并拥有一个适当的数据集，就可以开发一个模型：
- en: Prepare your data.
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备你的数据。
- en: 'Pick your evaluation protocol: holdout validation? *K*-fold validation? Which
    portion of the data should you use for validation?'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择评估协议：留出验证？*K*-折验证？应该使用哪一部分数据来进行验证？
- en: 'Achieve statistical power: beat a simple baseline.'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得统计力量：打败一个简单的基准。
- en: 'Scale up: develop a model that can overfit.'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩大规模：开发一个可以过度拟合的模型。
- en: Regularize your model and tune its hyperparameters, based on performance on
    the validation data. A lot of machine learning research tends to focus only on
    this step, but keep the big picture in mind.
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据验证数据上的性能进行正则化和超参数调整。许多机器学习研究往往只关注这一步，但请铭记大局。
- en: 'When your model is ready and yields good performance on the test data, it’s
    time for deployment:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型已准备好并在测试数据上有良好的表现时，就该开始部署了：
- en: First, make sure you set appropriate expectations with stakeholders.
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，确保你与利益相关者设定适当的期望。
- en: Optimize a final model for inference, and ship a model to the deployment environment
    of choice—web server, mobile, browser, embedded device, and so on.
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为推理优化一个最终模型，并在选择的部署环境中发布模型——Web服务器、移动设备、浏览器、嵌入式设备等等。
- en: Monitor your model’s performance in production, and keep collecting data so
    you can develop the next generation of the model.
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控你的模型在生产中的表现，并不断收集数据，以便开发下一代模型。
