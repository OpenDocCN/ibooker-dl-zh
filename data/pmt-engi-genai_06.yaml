- en: Chapter 6\. Autonomous Agents with Memory and Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：具有记忆和工具的自主代理
- en: This chapter dives deeper into the importance of chain-of-thought reasoning
    and the ability of large language models (LLMs) to reason through complex problems
    as agents. By breaking down complex problems into smaller, more manageable components,
    LLMs can provide more thorough and effective solutions. You will also learn about
    the components that make up autonomous agents, such as inputs, goal or reward
    functions, and available actions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了思维链推理的重要性以及大型语言模型（LLM）作为代理通过复杂问题的推理能力。通过将复杂问题分解成更小、更易于管理的组件，LLM可以提供更全面和有效的解决方案。你还将了解构成自主代理的组件，如输入、目标或奖励函数以及可用的操作。
- en: Chain-of-Thought
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维链
- en: The ability of AI to reason through complex problems is essential for creating
    effective, reliable, and user-friendly applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: AI通过复杂问题的推理能力对于创建有效、可靠和用户友好的应用至关重要。
- en: '*Chain-of-thought reasoning* (CoT) is a method of guiding LLMs through a series
    of steps or logical connections to reach a conclusion or solve a problem. This
    approach is particularly useful for tasks that require a deeper understanding
    of context or multiple factors to consider.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*思维链推理*（CoT）是一种引导LLM通过一系列步骤或逻辑连接来得出结论或解决问题的方法。这种方法对于需要更深入理解上下文或考虑多个因素的作业特别有用。'
- en: '[CoT](https://oreil.ly/fAeLo) is asking an LLM to *think* through complex problems,
    breaking them down into smaller, more manageable components. This allows the LLM
    to focus on each part individually, ensuring a more thorough understanding of
    the issue at hand.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[CoT](https://oreil.ly/fAeLo)要求LLM通过复杂问题进行 *思考*，将它们分解成更小、更易于管理的组件。这允许LLM单独关注每个部分，确保对当前问题的更深入理解。'
- en: 'In practice, chain-of-thought reasoning might involve:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，思维链推理可能涉及：
- en: Asking an LLM to provide explanations for its decisions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求LLM对其决策提供解释
- en: Planning multiple steps before deciding on a final answer
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在做出最终决定之前规划多个步骤
- en: In the following sections, you’ll explore examples of both ineffective and effective
    chain-of-thought reasoning. We will also discuss various techniques for building
    effective chain-of-thought reasoning and how they can be integrated into AI applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将探索无效和有效的思维链推理的例子。我们还将讨论构建有效思维链推理的各种技术以及它们如何集成到AI应用中。
- en: Let’s imagine that a user wants the AI to generate a comprehensive marketing
    plan for promoting a new software product.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一个用户希望AI生成一个全面的营销计划来推广一款新的软件产品。
- en: 'Input:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this example, GPT-4 doesn’t use chain-of-thought reasoning, and it does not
    address the specific aspects of the marketing plan. The LLM generates a generic
    list of marketing strategies that could apply to any product, rather than focusing
    on the unique characteristics of the new software product.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，GPT-4没有使用思维链推理，也没有针对营销计划的特定方面进行说明。LLM生成了一般性的营销策略列表，这些策略可以适用于任何产品，而不是专注于新软件产品的独特特性。
- en: 'Input:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now GPT-4 specifically addresses the unique characteristics of the new software
    product, demonstrating effective chain-of-thought reasoning.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，GPT-4专门针对新软件产品的独特特性，展示了有效的思维链推理。
- en: Give Direction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给予指导
- en: Take note of the phrase *step-by-step*, a critical element in CoT. By incorporating
    this phrase into your prompt, you’re asking the LLM to reason through the steps
    that are required to generate a highly effective software product.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意短语 *step-by-step*，这是CoT中的一个关键要素。通过将这个短语纳入你的提示中，你是在要求LLM通过生成高度有效的软件产品所需的步骤进行推理。
- en: Also, by providing a $20,000 budget and the type of software, GPT-4 is able
    to provide a much more relevant and contextualized response.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过提供20,000美元的预算和软件类型，GPT-4能够提供更加相关和具体化的响应。
- en: Agents
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理
- en: Generative AI models have given rise to an *agent-based architecture*. Conceptually,
    an agent acts, perceives, and makes decisions within a specified environment to
    achieve predefined objectives.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型催生了 *基于代理的架构*。从概念上讲，代理在指定环境中行动、感知并做出决策，以实现预定义的目标。
- en: Agents can take various actions such as executing a Python function; afterward,
    the agent will observe what happens and will decide on whether it is finished
    or what action to take next.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可以执行各种操作，例如执行Python函数；之后，代理将观察发生了什么，并决定是否完成或采取下一步行动。
- en: 'The agent will continously loop through a series of actions and observations
    until there are no further actions, as you can see in the following pseudocode:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 代理将持续循环一系列动作和观察，直到没有更多的动作，如下面的伪代码所示：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The behavior of the agent is governed by three principal components:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的行为由三个主要组成部分控制：
- en: Inputs
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 输入
- en: These are the sensory stimuli or data points the agent receives from its environment.
    Inputs can be diverse, ranging from visual (like images) and auditory (like audio
    files) to thermal signals and beyond.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是代理从其环境中接收到的感官刺激或数据点。输入可以多种多样，从视觉（如图像）和听觉（如音频文件）到热信号等。
- en: Goal or reward function
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 目标或奖励函数
- en: This represents the guiding principle for an agent’s actions. In goal-based
    frameworks, the agent is tasked with reaching a specific end state. In a reward-based
    setting, the agent is driven to maximize cumulative rewards over time, often in
    dynamic environments.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这代表了代理动作的指导原则。在基于目标的框架中，代理被要求达到一个特定的最终状态。在基于奖励的设置中，代理被驱动去最大化随时间累积的奖励，通常是在动态环境中。
- en: Available actions
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 可用动作
- en: The *action space* is the range of permissible actions an agent [can undertake
    at any given moment](https://oreil.ly/5AVfM). The breadth and nature of this space
    are contingent upon the task at hand.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*动作空间*是代理在任何给定时刻可以采取的允许动作的范围。[可以执行的动作](https://oreil.ly/5AVfM)。这个空间的范围和性质取决于手头的任务。'
- en: 'To explain these concepts further, consider a self-driving car:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步解释这些概念，可以考虑自动驾驶汽车：
- en: Inputs
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输入
- en: The car’s sensors, such as cameras, LIDAR, and ultrasonic sensors, provide a
    continuous stream of data about the environment. This can include information
    about nearby vehicles, pedestrians, road conditions, and traffic signals.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 汽车的传感器，如摄像头、激光雷达和超声波传感器，提供有关环境的连续数据流。这可能包括关于附近车辆、行人、道路状况和交通信号的信息。
- en: Goal or reward function
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 目标或奖励函数
- en: The primary goal for a self-driving car is safe and efficient navigation from
    point A to point B. If we were to use a reward-based system, the car might receive
    positive rewards for maintaining a safe distance from other objects, adhering
    to speed limits, and following traffic rules. Conversely, it could receive negative
    rewards for risky behaviors, like hard braking or veering off the lane. Tesla
    specifically uses miles driven without an intervention as their reward function.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自动驾驶汽车来说，主要目标是安全且高效地从A点到B点的导航。如果我们使用基于奖励的系统，汽车可能会因为保持与其他物体的安全距离、遵守速度限制和遵守交通规则而获得正奖励。相反，它可能会因为危险行为，如紧急制动或偏离车道，而收到负奖励。特斯拉特别使用无需干预行驶的英里数作为它们的奖励函数。
- en: Available actions
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 可用动作
- en: The car’s action space includes accelerating, decelerating, turning, changing
    lanes, and more. Each action is chosen based on the current input data and the
    objective defined by the goal or reward function.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 汽车的动作空间包括加速、减速、转向、换道等。每个动作都是基于当前输入数据和由目标或奖励函数定义的目标来选择的。
- en: You’ll find that agents in systems like self-driving cars rely on foundational
    principles like inputs, goal/reward functions, and available actions. However,
    when delving into the realm of LLMs like GPT, there’s a bespoke set of dynamics
    that cater specifically to their unique nature.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，在自动驾驶汽车等系统中，代理依赖于诸如输入、目标/奖励函数和可用动作等基础原则。然而，当深入研究GPT等LLM领域时，存在一套专门针对其独特性质的动态。
- en: 'Here’s how they align with your needs:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它们如何满足你的需求的：
- en: Inputs
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 输入
- en: 'For LLMs, the gateway is primarily through text. But that doesn’t restrain
    the wealth of information you can use. Whether you’re dealing with thermal readings,
    musical notations, or intricate data structures, your challenge lies in molding
    these into textual representations suitable for an LLM. Think about videos: while
    raw footage might seem incompatible, video text transcriptions allow an LLM to
    extract insights for you.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型语言模型（LLMs），入口主要是通过文本。但这并不限制你可以使用的信息量。无论你处理的是温度读数、音乐符号，还是复杂的数据结构，你的挑战在于将这些内容塑造成适合LLM的文本表示。想想视频：虽然原始素材可能看起来不兼容，但视频文本转录允许LLM为你提取见解。
- en: Harnessing goal-driven directives
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 利用目标驱动的指令
- en: 'LLMs primarily use goals defined within your text prompts. By creating effective
    prompts with objectives, you’re not just accessing the LLM’s vast knowledge; you’re
    effectively charting its reasoning path. Think of it as laying down a blueprint:
    your specific prompt instructs the model, guiding it to dissect your overarching
    objective into a systematic sequence of steps.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs主要使用您在文本提示中定义的目标。通过创建具有明确目标的提示，您不仅能够访问LLM的丰富知识，而且实际上在规划其推理路径。将其视为绘制蓝图：您的具体提示指导模型，引导它将总体目标分解成一系列系统的步骤。
- en: Crafting action through functional tools
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过功能性工具制定行动
- en: LLMs are not limited to mere text generation; there’s so much more you can achieve.
    By integrating *ready-made tools* or *custom-developed tools*, you can equip LLMs
    to undertake diverse tasks, from API calls to database engagements or even orchestrating
    external systems. Tools can be written in any programming language, and by adding
    more tools you are effectively *expanding the action space* of what an LLM can
    achieve.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs不仅限于简单的文本生成；您还可以实现更多。通过集成*现成的工具*或*自定义开发的工具*，您可以装备LLMs执行各种任务，从API调用到数据库交互，甚至编排外部系统。工具可以用任何编程语言编写，通过添加更多工具，您实际上在*扩展LLM能够实现的行为空间*。
- en: 'There are also different components that are directly applicable to LLMs:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些不同的组件可以直接应用于LLMs：
- en: Memory
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆
- en: It’s ideal to store state between agent steps; this is particularly useful for
    chatbots, where remembering the previous chat history provides a better user experience.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理步骤之间存储状态是理想的；这在聊天机器人中尤其有用，记住之前的聊天历史可以提供更好的用户体验。
- en: Agent planning/execution strategies
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 代理规划/执行策略
- en: There are multiple ways to achieve a high-level goal, of which a mixture of
    planning and executing is essential.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 实现高级目标有多种方式，其中规划和执行的结合是至关重要的。
- en: Retrieval
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 检索
- en: LLMs can use different types of retrieval methods. Semantic similarity within
    vector databases is the most common, but there are others such as including custom
    information from a SQL database into prompts.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs可以使用不同类型的检索方法。在向量数据库中的语义相似性是最常见的，但还有其他方法，例如将来自SQL数据库的定制信息包含到提示中。
- en: Let’s dive deeper into the shared and different components and explore the implementation
    details.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨共享和不同的组件，并探索实现细节。
- en: Reason and Act (ReAct)
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和行动（ReAct）
- en: There are many agent frameworks that ultimately aim to improve LLM responses
    toward a goal. The original framework was *ReAct*, which is an improved version
    of CoT, allowing an LLM to create observations after taking actions via tools.
    These observations are then turned into *thoughts* about what would be the *right
    tool* to use within the next step ([Figure 6-1](#fig-6-1)). The LLM continues
    to reason until either a `'Final Answer'` string value is present or a maximum
    number of iterations has taken place.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多代理框架旨在最终提高LLM向目标响应的能力。原始框架是*ReAct*，它是CoT的改进版本，允许LLM在通过工具采取行动后创建观察。然后，这些观察被转化为关于在下一步中应该使用什么*正确工具*的*思维*（[图6-1](#fig-6-1)）。LLM继续推理，直到出现`'Final
    Answer'`字符串值或达到最大迭代次数。
- en: '![The ReAct Framework](assets/pega_0601.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![ReAct框架](assets/pega_0601.png)'
- en: Figure 6-1\. The ReAct framework
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1. ReAct框架
- en: 'The [ReAct](https://oreil.ly/ssdnL) framework uses a mixture of task decomposition,
    a thought loop, and multiple tools to solve questions. Let’s explore the thought
    loop within ReAct:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[ReAct](https://oreil.ly/ssdnL)框架结合了任务分解、思维循环和多种工具来解决疑问。让我们探索ReAct中的思维循环：'
- en: Observe the environment.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察环境。
- en: Interpret the environment with a thought.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用思维解释环境。
- en: Decide on an action.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定一个行动。
- en: Act on the environment.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在环境中采取行动。
- en: Repeat steps 1–4 until you find a solution or you’ve done too many iterations
    (the solution is “I’ve found the answer”).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1-4，直到找到解决方案或迭代次数过多（解决方案是“我已经找到答案”）。
- en: 'You can easily create a ReAct-style prompt by using the preceding thought loop
    while also providing the LLM with several inputs such as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用前面的思维循环，同时向LLM提供多个输入，如以下内容，轻松创建一个ReAct风格的提示：
- en: '`{question}`: The query that you want answered.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{问题}`：您希望得到回答的查询。'
- en: '`{tools}`: These refer to functions that can be used to accomplish a step within
    the overall task. It is common practice to include a list of tools where each
    tool is a Python function, a name, and a description of the function and its purpose.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{tools}`：这些指的是可以用于完成整体任务中某个步骤的函数。通常的做法是包括一个工具列表，其中每个工具都是一个Python函数、一个名称以及该函数及其目的的描述。'
- en: 'The following is a prompt that implements the ReAct pattern with prompt variables
    wrapped in `{}` characters such as `{question}`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个实现ReAct模式并使用大括号`{}`字符包裹的提示变量`{question}`的提示：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is a breakdown of the prompt:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是提示的分解：
- en: 'The introduction of the prompt clearly establishes the LLM’s purpose: `You
    will attempt to solve the problem of finding the answer to a question.`'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示的引入清楚地确立了LLM的目的：`你将尝试解决找到问题答案的问题。`
- en: 'The problem-solving approach is then outlined: `Use chain-of-thought reasoning
    to solve through the problem, using the following pattern:`'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后概述问题解决方法：`使用链式思维推理通过以下模式解决问题：`
- en: 'The steps in the chain-of-thought reasoning are then laid out:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 链式思维推理的步骤随后被列出：
- en: 'The LLM starts by observing the original question and subsequently formulates
    an observation about it: `original_question: original_problem_text`, `observation:
    observation_text`.'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LLM首先观察原始问题，然后对其形成观察：`original_question: original_problem_text`，`observation:
    observation_text`。'
- en: 'Based on this observation, the AI should formulate a thought that signifies
    a step in the reasoning process: `thought: thought_text`.'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于这个观察，AI应该制定一个表示推理过程中一步的思想：`thought: thought_text`。'
- en: 'Having established a thought, it then decides on an action using one of the
    available tools: `action: tool_name`, `action_input: tool_input`.'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在确立了一个思想之后，它然后决定使用可用的工具之一采取行动：`action: tool_name`，`action_input: tool_input`。'
- en: The LLM is then reminded not to make assumptions about what a tool might return,
    and it should explicitly outline its intended action and the corresponding input.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后提醒LLM不要对工具可能返回的内容做出假设，它应该明确说明其预期的行动和相应的输入。
- en: '`You have access to the following tools: {tools}` communicates to the LLM what
    tools it has available for solving the problem.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`你有以下工具可用：{tools}` 通知LLM它可用于解决问题的工具。'
- en: 'The actual problem that the LLM must solve is then introduced: `original_​problem:
    {question}`.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'LLM必须解决的实际上是以下问题：`original_problem: {question}`。'
- en: Finally, instructions are provided on how the LLM should respond based on the
    results of its actions. It can either continue with new observations, actions,
    and inputs or, if a solution is found, provide the final answer.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，根据其行动的结果，提供了LLM应该如何响应的说明。它可以选择继续进行新的观察、行动和输入，或者如果找到了解决方案，提供最终答案。
- en: The prompt outlines a systematic problem-solving process in which the LLM observes
    a problem, thinks about it, decides on an action, and repeats this process until
    a solution is discovered.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 提示概述了一个系统化的问题解决过程，其中LLM观察一个问题，思考它，决定采取行动，并重复此过程，直到找到解决方案。
- en: Reason and Act Implementation
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理由和行动实施
- en: Now that you’re aware of ReAct, it’s important to create a simple Python implementation
    that replicates what LangChain does automatically, allowing you to build the intuition
    about what’s truly happening between the LLM responses.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经了解了ReAct，那么创建一个简单的Python实现来复制LangChain自动执行的操作就很重要了，这样你可以建立起对LLM响应之间真正发生的事情的直觉。
- en: To keep it simple, this example will not implement looping and will assume that
    the output can be obtained from a single tool call.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持简单，这个例子将不会实现循环，并假设输出可以从单个工具调用中获得。
- en: 'To create a basic ReAct implementation, you’ll implement the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建基本的ReAct实现，你需要实现以下内容：
- en: At every thought, you need to extract the tool that the LLM wants to use. Therefore,
    you’ll extract the last `action` and `action_input`. The `action` represents the
    tool name, while the `action_input` consists of the values of the function arguments.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每一个思维过程中，你需要提取LLM想要使用的工具。因此，你会提取最后的`action`和`action_input`。`action`代表工具名称，而`action_input`由函数参数的值组成。
- en: Check whether the LLM thinks that it has found the final answer, in which case
    the thought loop has ended.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查LLM是否认为它已经找到了最终答案，如果是这样，那么思维循环就结束了。
- en: 'You can use regular expressions to extract the `action` and `action_input`
    values from the LLM response:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用正则表达式从LLM响应中提取`action`和`action_input`值：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s break down the regular expression to extract the `action`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解这个正则表达式以提取 `action`：
- en: '`action_pattern = re.compile(r"(?i)action\s*:\s*([^\n]+)", re.MULTILINE)`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`action_pattern = re.compile(r"(?i)action\s*:\s*([^\n]+)", re.MULTILINE)`'
- en: '`(?i)`: This is called an *inline flag* and makes the regex pattern case-insensitive.
    It means that the pattern will match “action,” “Action,” “ACTION,” or any other
    combination of uppercase and lowercase letters.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(?i)`: 这被称为 *内联标志*，使正则表达式模式不区分大小写。这意味着模式将匹配“action”，“Action”，“ACTION”或任何其他大小写字母的组合。'
- en: '`action`: This part of the pattern matches the word *action* literally. Due
    to the case-insensitive flag, it will match any capitalization of the word.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`action`: 模式的一部分匹配单词 *action* 字面意义。由于不区分大小写的标志，它将匹配任何大小写形式的单词。'
- en: '`\s*`: This part of the pattern matches zero or more whitespace characters
    (spaces, tabs, etc.). The `\*` means *zero or more*, and `\s` is the regex shorthand
    for a whitespace character.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\s*`: 模式的一部分匹配零个或多个空白字符（空格、制表符等）。`\*` 表示“零个或多个”，`\s` 是正则表达式中空白字符的缩写。'
- en: '`:` This part of the pattern matches the colon character literally.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:` 模式的一部分匹配冒号字符字面意义。'
- en: '`\s*`: This is the same as the previous `\s\*` part, matching zero or more
    whitespace characters after the colon.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\s*`: 这与之前的 `\s\*` 部分相同，匹配冒号后面的零个或多个空白字符。'
- en: '`+([^\n]++)`: This pattern is a capturing group, denoted by the parentheses.
    It matches one or more characters that are *not a newline character*. The `^`
    inside the square brackets `[]` negates the character class, and `\n` represents
    the newline character. The `+` means *one or more*. The text matched by this group
    will be extracted when using the `findall()` function.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`+([^\n]++)`: 这个模式是一个捕获组，由括号表示。它匹配一个或多个不是换行符的字符。方括号 `[]` 内部的 `^` 取反了字符类，`\n`
    代表换行符。`+` 表示“一个或多个”。这个组匹配的文本将在使用 `findall()` 函数时被提取。'
- en: '`re.MULTILINE`: This is a flag passed to `re.compile()` function. It tells
    the regex engine that the input text may have multiple lines, so the pattern should
    be applied line by line.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`re.MULTILINE`: 这个标志是传递给 `re.compile()` 函数的。它告诉正则表达式引擎输入文本可能有多个行，因此模式应该逐行应用。'
- en: In regular expressions, square brackets `[]` are used to define a character
    class, which is a set of characters that you want to match. For example, `[abc]`
    would match any single character that is either `'a'`, `'b'`, or `'c'`.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在正则表达式中，方括号 `[]` 用于定义字符类，这是一组你想要匹配的字符。例如，`[abc]` 将匹配任何单个字符，该字符是 `'a'`、`'b'`
    或 `'c'` 之一。
- en: When you add a caret `^` at the beginning of the character class, it negates
    the character class, meaning it will match any character that is *not in the character
    class*. In other words, it inverts the set of characters you want to match.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你在字符类开头添加一个上标 `^` 时，它将字符类取反，意味着它将匹配任何不在字符类中的字符。换句话说，它反转了你想要匹配的字符集。
- en: So, when we use `[^abc]`, it will match any single character that is *not* `'a'`,
    `'b'`, or `'c'`. In the regex pattern `+([^\n]++)`, the character class is `[^n]`,
    which means it will match any character that is *not* a newline character (`\n`).
    The `+` after the negated character class means that the pattern should match
    one or more characters that are not newlines.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，当我们使用 `[^abc]` 时，它将匹配任何不是 `'a'`、`'b'` 或 `'c'` 的单个字符。在正则表达式模式 `+([^\n]++)`
    中，字符类是 `[^n]`，这意味着它将匹配任何不是换行符的字符。取反字符类后面的 `+` 表示模式应该匹配一个或多个不是换行的字符。
- en: By using the negated character class `[^n]` in the capturing group, we ensure
    that the regex engine captures text up to the end of the line without including
    the newline character itself. This is useful when we want to extract the text
    after the word *action* or *action input* up to the end of the line.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在捕获组中使用取反的字符类 `[^n]`，我们确保正则表达式引擎捕获的文本直到行尾，不包括换行符本身。这在我们要提取单词 *action* 或 *action
    input* 后面直到行尾的文本时很有用。
- en: Overall, this regular expression pattern matches the word *action* (case-insensitive)
    followed by optional whitespace, a colon, and optional whitespace again, and then
    captures any text up to the end of the line.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这个正则表达式模式匹配单词 *action*（不区分大小写）后面跟着可选的空白字符，一个冒号，再跟着可选的空白字符，然后捕获任何直到行尾的文本。
- en: 'The only difference between these two regex patterns is the literal text they
    are looking for at the beginning:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个正则表达式模式之间的唯一区别是它们在开头寻找的文本：
- en: '`action_pattern` looks for the word `"action".`'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`action_pattern` 寻找单词 `"action"`。'
- en: '`action_input_pattern` looks for the word `"action_input".`'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`action_input_pattern` 寻找单词 `"action_input"`。'
- en: 'You can now abstract the regex into a Python function that will always find
    the last `action` and `action_input`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以将正则表达式抽象成一个 Python 函数，该函数将始终找到最后一个 `action` 和 `action_input`：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To determine and extract whether the LLM has discovered the final answer, you
    can also use regular expressions:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定和提取 LLM 是否发现了最终答案，您也可以使用正则表达式：
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Warning
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: LLMs do not always respond in the intended way, so your application needs to
    be able to handle regex parsing errors. Several approaches include using an LLM
    to fix the previous LLM response or making another new LLM request with the previous
    state.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 不总是以预期的方式响应，因此您的应用程序需要能够处理正则表达式解析错误。几种方法包括使用 LLM 修复上一个 LLM 的响应或使用上一个状态发出另一个新的
    LLM 请求。
- en: 'You can now combine all of the components; here is a step-by-step explanation:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以组合所有组件；以下是一个逐步说明：
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Initialize the `ChatOpenAI` instance:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化 `ChatOpenAI` 实例：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Adding a `stop` sequence forces an LLM to stop generating new tokens after encounting
    the phrase `"tool_result:"`. This helps by stopping hallucinations for tool usage.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 添加 `stop` 序列会强制 LLM 在遇到短语 `"tool_result:"` 后停止生成新标记。这有助于通过停止工具使用时的幻觉。
- en: 'Define the available tools:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 定义可用的工具：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Set the base prompt template:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 设置基本提示模板：
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Generate the model output:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型输出：
- en: '[PRE13]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Extract the last `action`, `action_input`, and call the relevant function:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 提取最后一个 `action`、`action_input` 并调用相关函数：
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Print the tool details:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 打印工具详细信息：
- en: '[PRE15]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Set the current prompt with the tool result:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 设置包含工具结果的当前提示：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Generate the model output for the current prompt:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为当前提示生成模型输出：
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Print the model output for the current prompt:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 打印当前提示的模型输出：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Output:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE19]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding steps provide a very simple ReAct implementation. In this case,
    the LLM decided to use the `search_on_google` tool with `"Jason Derulo current
    relationship status"` as the `action_input`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤提供了一个非常简单的 ReAct 实现。在这种情况下，LLM 决定使用 `search_on_google` 工具，其 `action_input`
    为 `"Jason Derulo current relationship status"`。
- en: Note
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: LangChain agents will automatically do all of the preceding steps in a concise
    manner, as well as provide multiple tool usage (through looping) and handling
    for tool failures when an agent can’t parse the `action` or `action_input`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 代理将自动以简洁的方式执行所有前面的步骤，包括提供多次工具使用（通过循环）以及处理工具失败的情况，当代理无法解析 `action`
    或 `action_input` 时。
- en: Before exploring LangChain agents and what they have to offer, it’s vital that
    you learn *tools* and how to create and use them.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索 LangChain 代理及其提供的功能之前，学习 *工具* 以及如何创建和使用它们至关重要。
- en: Using Tools
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具：
- en: As large language models such as GPT-4 can only generate text, providing tools
    that can perform other actions such as interacting with a database or reading/writing
    files provides an effective method to increase an LLM’s capabilities. A *tool*
    is simply a predefined function that permits the agent to take a specific action.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型如 GPT-4 只能生成文本，提供可以执行其他操作的工具（如与数据库交互或读取/写入文件）可以有效地提高 LLM 的能力。*工具* 简单来说是一个预定义的函数，允许代理执行特定的操作。
- en: 'A common part of an agent’s prompt will likely include the following:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 代理提示的一个常见部分可能包括以下内容：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Most tools are written as functions within a programming language. As you explore
    LangChain, you’ll find that it offers three different approaches to tool creation/usage:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数工具都是用编程语言编写的函数。在探索 LangChain 的过程中，您会发现它提供了三种不同的工具创建/使用方法：
- en: Create your own custom tools.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建您自己的自定义工具。
- en: Use preexisting tools.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用现有工具。
- en: Leverage `AgentToolkits`, which are multiple tools bundled together to accomplish
    a specific task.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用 `AgentToolkits`，这些工具捆绑在一起以完成特定任务。
- en: 'Let’s start by creating a custom tool that checks the length of a given string
    using LangChain:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个使用 LangChain 检查给定字符串长度的自定义工具开始：
- en: '[PRE21]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Following the import of necessary modules, you initialize a `ChatOpenAI` chat
    model. Then create a function called `count_characters_in_string` that computes
    the length of any given string. This function is encapsulated within a `Tool`
    object, providing a descriptive name and explanation for its role.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入必要的模块后，您初始化一个 `ChatOpenAI` 聊天模型。然后创建一个名为 `count_characters_in_string` 的函数，该函数计算任何给定字符串的长度。此函数封装在一个
    `Tool` 对象中，提供描述性名称和说明其作用。
- en: Subsequently, you utilize `create_react_agent` to initialize your agent, combining
    the defined `Tool`, the `ChatOpenAI` model, and a react prompt pulled from the
    LangChain hub. This sets up a comprehensive interactive agent.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，你使用 `create_react_agent` 初始化你的代理，结合定义的 `Tool`、`ChatOpenAI` 模型和从 LangChain
    中心拉取的 react 提示。这设置了一个全面的交互式代理。
- en: With `AgentExecutor`, the agent is equipped with the tools and verbose output
    is enabled, allowing for detailed logging.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `AgentExecutor`，代理配备了工具，并启用了详细输出，允许进行详细记录。
- en: Finally, `agent_executor.invoke(...)` is executed with a query about the character
    count in “supercalifragilisticexpialidocious.” The agent utilizes the defined
    tool to calculate and return the precise character count in the word.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`agent_executor.invoke(...)` 执行了一个关于“supercalifragilisticexpialidocious”中字符数的查询。代理利用定义的工具来计算并返回该单词中精确的字符数。
- en: 'In [Example 6-1](#ex_agent_custom_tool_character), you can see that the agent
    decided to use the `Action` called `Characters` `in a text string` with an `Action
    Input`: `''supercalifragilisticexpialidocious''`. This pattern is extremely familiar
    to the simplistic ReAct implementation that you previously made.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 6-1](#ex_agent_custom_tool_character) 中，你可以看到代理决定使用名为 `Action` 的 `Characters`
    `in a text string`，并带有 `Action Input`：`'supercalifragilisticexpialidocious'`。这种模式与您之前制作的简单
    ReAct 实现极为相似。
- en: Example 6-1\. A single tool, agent output
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-1\. 单个工具，代理输出
- en: '[PRE22]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Give Direction
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给出指示
- en: Writing expressive names for your Python functions and tool descriptions will
    increase an LLM’s ability to effectively choose the right tools.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为你的 Python 函数和工具描述编写表达性的名称将提高 LLM 有效选择正确工具的能力。
- en: Using LLMs as an API (OpenAI Functions)
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LLM 作为 API（OpenAI 函数）
- en: As mentioned in [Chapter 4](ch04.html#advanced_text_04), OpenAI [released more
    fine-tuned LLMs](https://oreil.ly/hYTus) tailored toward function calling. This
    is important because it offers an alternative against the standard ReAct pattern
    for tool use. It’s similar to ReAct in that you’re still utilizing an LLM as a
    *reasoning engine.*
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 4 章](ch04.html#advanced_text_04) 中所述，OpenAI [发布了更多针对功能调用的微调 LLM](https://oreil.ly/hYTus)。这很重要，因为它为工具使用提供了标准
    ReAct 模式的替代方案。它与 ReAct 类似，因为你仍然在利用 LLM 作为 *推理引擎*。
- en: As shown in [Figure 6-2](#fig-6-2), function calling allows an LLM to easily
    transform a user’s input into a weather API call.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 6-2](#fig-6-2) 所示，函数调用允许 LLM 容易地将用户的输入转换为天气 API 调用。
- en: '![Function calling flow using OpenAI functions](assets/pega_0602.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![使用 OpenAI 函数的功能调用流程](assets/pega_0602.png)'
- en: Figure 6-2\. Function calling flow using OpenAI functions
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-2\. 使用 OpenAI 函数的功能调用流程
- en: LangChain allows users to effortlessly switch between different agent types
    including ReAct, OpenAI functions, and many more.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 允许用户轻松地在不同的代理类型之间切换，包括 ReAct、OpenAI 函数等。
- en: Refer to [Table 6-1](#table-6-1) for a comprehensive comparison of the different
    agent types.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 [表 6-1](#table-6-1) 以全面比较不同的代理类型。
- en: Table 6-1\. Comparison of agent types
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-1\. 代理类型比较
- en: '| Agent type | Description |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 代理类型 | 描述 |'
- en: '| --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| OpenAI Functions | Works with fine-tuned models like gpt-3.5-turbo-0613 and
    gpt-4-0613 for function calling. It intelligently outputs JSON objects for the
    function calls. Best for open source models and providers adopting this format.
    Note: deprecated in favor of OpenAI Tools. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI 函数 | 与 gpt-3.5-turbo-0613 和 gpt-4-0613 等微调模型一起工作，用于函数调用。它智能地输出 JSON
    对象以进行函数调用。最适合采用此格式的开源模型和提供商。注意：已被 OpenAI 工具取代。 |'
- en: '| OpenAI Tools | Enhanced version for newer models, capable of invoking one
    or more functions. It intelligently outputs JSON objects for these function calls,
    optimizing the response efficiency and reducing response times in some architectures.
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI 工具 | 新模型的增强版本，能够调用一个或多个函数。它智能地输出 JSON 对象以进行这些函数调用，优化响应效率并减少某些架构中的响应时间。
    |'
- en: '| XML Agent | Ideal for language models like Anthropic’s Claude, which excel
    in XML reasoning/writing. Best used with regular LLMs (not chat models) and unstructured
    tools accepting single string inputs. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| XML 代理 | 适用于像 Anthropic 的 Claude 这样的语言模型，这些模型在 XML 推理/写作方面表现出色。最佳搭配常规 LLM（非聊天模型）和接受单个字符串输入的非结构化工具。
    |'
- en: '| JSON Chat Agent | Tailored for language models skilled in JSON formatting.
    This agent uses JSON to format its outputs, supporting chat models for scenarios
    requiring JSON outputs. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| JSON 聊天代理 | 定制用于擅长 JSON 格式的语言模型。此代理使用 JSON 格式其输出，支持需要 JSON 输出的聊天模型。 |'
- en: '| Structured Chat | Capable of using multi-input tools, this agent is designed
    for complex tasks requiring structured inputs and responses. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 结构化聊天 | 能够使用多输入工具，此代理旨在处理需要结构化输入和响应的复杂任务。|'
- en: '| ReAct | Implements ReAct logic, using tools like Tavily’s Search for interactions
    with a document store or search tools. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| ReAct | 实现ReAct逻辑，使用Tavily的搜索与文档存储或搜索工具进行交互。|'
- en: '| Self-Ask with Search | Utilizes the Intermediate Answer tool for factual
    question resolution, following the self-ask with search methodology. Best for
    scenarios requiring quick and accurate factual answers. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 自问自答与搜索 | 利用中间答案工具进行事实性问题解决，遵循自问自答与搜索方法。适用于需要快速准确事实答案的场景。|'
- en: 'Let’s use prepackaged tools such as a `Calculator` to answer math questions
    using OpenAI function calling from the LangChain documentation:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用预包装的工具，例如`计算器`，通过从LangChain文档中调用OpenAI功能来回答数学问题：
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After initiating the necessary libraries, you’ll use `ChatOpenAI`, setting the
    `temperature` parameter to 0 for deterministic outputs. By using `hub.pull("...")`,
    you can easily download prompts that have been saved on LangChainHub.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化必要的库之后，你将使用`ChatOpenAI`，将`temperature`参数设置为0以获得确定性输出。通过使用`hub.pull("...")`，你可以轻松下载保存在LangChainHub上的提示。
- en: 'This model is then coupled with a tool named `Calculator` that leverages the
    capabilities of `LLMMathChain` to compute math queries. The OpenAI functions agent
    then decides to use the `Calculator` tool to compute `5 + 5` and returns `Answer:
    10`.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型随后与名为`计算器`的工具相结合，利用`LLMMathChain`的能力来计算数学查询。OpenAI函数代理随后决定使用`计算器`工具来计算`5
    + 5`并返回`答案：10`。
- en: 'Following on, you can equip an agent with multiple tools, enhancing its versatility.
    To test this, let’s add an extra `Tool` object to our agent that allows it to
    perform a fake Google search:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你可以给一个代理配备多个工具，增强其多功能性。为了测试这一点，让我们给我们的代理添加一个额外的`工具`对象，使其能够执行模拟的Google搜索：
- en: '[PRE24]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: When executed, the agent will first invoke the `google_search` function and
    then proceed to the `llm_math_chain.run` function. By mixing both custom and prepackaged
    tools, you significantly increase the flexibility of your agents.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行时，代理将首先调用`google_search`函数，然后继续执行`llm_math_chain.run`函数。通过混合自定义和预包装的工具，你可以显著提高代理的灵活性。
- en: Note
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Depending upon how many tools you provide, an LLM will either restrict or increase
    its ability to solve different user queries. Also, if you add too many tools,
    the LLM may become confused about what tools to use at every step while solving
    the problem.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你提供的工具数量，LLM将限制或增加解决不同用户查询的能力。此外，如果你添加了太多工具，LLM在解决问题的每一步可能会对使用哪些工具感到困惑。
- en: 'Here are several recommended tools that you might want to explore:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些推荐你想要探索的工具：
- en: '[Google search](https://oreil.ly/TjrnF)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google搜索](https://oreil.ly/TjrnF)'
- en: Enables an LLM to perform web searches, which provides timely and relevant context.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使LLM能够执行网络搜索，这提供了及时和相关的上下文。
- en: '[File system tools](https://oreil.ly/5tAB0)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[文件系统工具](https://oreil.ly/5tAB0)'
- en: Essential for managing files, whether it involves reading, writing, or reorganizing
    them. Your LLM can interact with the file system more efficiently with them.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管理文件至关重要，无论是涉及读取、写入还是重新组织文件。有了这些工具，你的LLM可以更有效地与文件系统交互。
- en: '[Requests](https://oreil.ly/vZjm1)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[Requests](https://oreil.ly/vZjm1)'
- en: A pragmatic tool that makes an LLM capable of executing HTTP requests for create,
    read, update, and delete (CRUD) functionality.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实用的工具，使LLM能够执行创建、读取、更新和删除（CRUD）功能的HTTP请求。
- en: '[Twilio](https://oreil.ly/ECS4r)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twilio](https://oreil.ly/ECS4r)'
- en: Enhance the functionality of your LLM by allowing it to send SMS messages or
    WhatsApp messages through Twilio.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通过允许LLM通过Twilio发送短信或WhatsApp消息，增强LLM的功能。
- en: Divide Labor and Evaluate Quality
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分工合作并评估质量
- en: When using tools, make sure you divide the tasks appropriately. For example,
    entrust Twilio with communication services, while assigning requests for HTTP-related
    tasks. Additionally, it is crucial to consistently evaluate the performance and
    quality of the tasks performed by each tool.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用工具时，确保适当分配任务。例如，将通信服务委托给Twilio，同时分配与HTTP相关的请求。此外，持续评估每个工具执行任务的表现和质量至关重要。
- en: Different tools may be called more or less frequently, which will influence
    your LLM agent’s performance. Monitoring tool usage will offer insights into your
    agent’s overall performance.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的工具可能被调用得更频繁或更少，这将影响你的LLM代理的性能。监控工具使用情况将为你提供关于代理整体性能的见解。
- en: Comparing OpenAI Functions and ReAct
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较OpenAI 函数和 ReAct
- en: Both OpenAI functions and the ReAct framework bring unique capabilities to the
    table for executing tasks with generative AI models. Understanding the differences
    between them can help you determine which is better suited for your specific use
    case.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 函数和 ReAct 框架为使用生成式 AI 模型执行任务提供了独特的功能。了解它们之间的差异可以帮助你确定哪个更适合你的特定用例。
- en: 'OpenAI functions operate in a straightforward manner. In this setup, the LLM
    decides at runtime whether to execute a function. This is beneficial when integrated
    into a conversational agent, as it provides several features including:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 函数以简单直接的方式运行。在这个设置中，LLM 在运行时决定是否执行函数。当集成到对话代理中时，这很有益，因为它提供了包括以下在内的几个特性：
- en: Runtime decision making
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时决策
- en: The LLM autonomously makes the decision on whether a function(s) should be executed
    or not in real time.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 在实时自主决定是否执行某个（些）函数。
- en: Single tool execution
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 单个工具执行
- en: OpenAI functions are ideal for tasks requiring a single tool execution.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 函数非常适合需要单个工具执行的任务。
- en: Ease of implementation
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 实现简便
- en: OpenAI functions can be easily merged with conversational agents.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 函数可以轻松地与对话代理合并。
- en: Parallel function calling
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 并行函数调用
- en: For single task executions requiring multiple parses, OpenAI functions offer
    parallel function calling to invoke several functions within the same API request.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要多个解析的单个任务执行，OpenAI 函数提供并行函数调用，在同一个 API 请求中调用多个函数。
- en: Use Cases for OpenAI Functions
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI 函数的用例
- en: If your task entails a definitive action such as a simple search or data extraction,
    OpenAI functions are an ideal choice.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的任务涉及明确的行动，如简单的搜索或数据提取，OpenAI 函数是一个理想的选择。
- en: ReAct
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct
- en: If you require executions involving multiple sequential tool usage and deeper
    introspection of previous actions, ReAct comes into play. Compared to function
    calling, ReAct is designed to go through many *thought loops* to accomplish a
    higher-level goal, making it suitable for queries with multiple intents.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要涉及多个顺序工具使用和更深入反思先前行动的执行，ReAct 就派上用场。与函数调用相比，ReAct 被设计成通过许多*思维循环*来实现更高层次的目标，这使得它适合具有多个意图的查询。
- en: 'Despite ReAct’s compatibility with `conversational-react` as an agent, it doesn’t
    yet offer the same level of stability as function calling and often favors toward
    using tools over simply responding with text. Nevertheless, if your task requires
    successive executions, ReAct’s ability to generate many thought loops and decide
    on a single tool at a time demonstrates several distinct features including:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ReAct作为代理与`conversational-react`兼容，但它尚未提供与函数调用相同级别的稳定性，并且通常更倾向于使用工具而不是简单地以文本形式响应。尽管如此，如果你的任务需要连续执行，ReAct生成多个思维循环并在每次决定使用单个工具的能力展示了几个显著特性，包括：
- en: Iterative thought process
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代思维过程
- en: ReAct allows agents to generate numerous thought loops for complex tasks.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 允许代理为复杂任务生成多个思维循环。
- en: Multi-intent handling
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 多意图处理
- en: ReAct handles queries with multiple intents effectively, thus making it suitable
    for complex tasks.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 有效地处理具有多个意图的查询，因此它适合复杂任务。
- en: Multiple tool execution
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 多个工具执行
- en: Ideal for tasks requiring multiple tool executions sequentially.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于需要顺序执行多个工具的任务。
- en: Use Cases for ReAct
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct 的用例
- en: If you’re working on a project that requires introspection of previous actions
    or uses multiple functions in succession such as saving an interview and then
    sending it in an email, ReAct is the best choice.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理一个需要反思先前行动或连续使用多个函数的项目，例如保存一次采访然后通过电子邮件发送，ReAct 是最佳选择。
- en: To aid decision making, see a comprehensive comparison in [Table 6-2](#table-6-2).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助决策，请参阅[表 6-2](#table-6-2)中的全面比较。
- en: Table 6-2\. A feature comparison between OpenAI functions and ReAct
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-2\. OpenAI 函数与 ReAct 的特性比较
- en: '| Feature | OpenAI functions | ReAct |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | OpenAI 函数 | ReAct |'
- en: '| --- | --- | --- |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Runtime decision making | ✓ | ✓ |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 运行时决策 | ✓ | ✓ |'
- en: '| Single tool execution | ✓ | ✓ |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 单个工具执行 | ✓ | ✓ |'
- en: '| Ease of implementation | ✓ | x |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 实现简便 | ✓ | x |'
- en: '| Parallel function calling | ✓ | x |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 并行函数调用 | ✓ | x |'
- en: '| Iterative thought process | x | ✓ |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 迭代思维过程 | x | ✓ |'
- en: '| Multi-intent handling | ✓ | ✓ |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 多意图处理 | ✓ | ✓ |'
- en: '| Sequential tool execution | x | ✓ |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 顺序工具执行 | x | ✓ |'
- en: '| Customizable prompt | ✓ | ✓ |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 可定制的提示 | ✓ | ✓ |'
- en: Give Direction
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给予指导
- en: When interacting with different AI frameworks, it’s crucial to understand that
    each framework has its strengths and trade-offs. Each framework will provide a
    unique form of direction to your LLM.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当与不同的AI框架交互时，理解每个框架都有其优势和权衡是至关重要的。每个框架将为您的LLM提供独特的形式指引。
- en: Agent Toolkits
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理工具包
- en: '*[Agent toolkits](https://oreil.ly/_v6dm)* are a LangChain integration that
    provides multiple tools and chains together, allowing you to quickly automate
    tasks.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '*[代理工具包](https://oreil.ly/_v6dm)*是LangChain的集成，提供了多个工具，并将它们串联起来，使您能够快速自动化任务。'
- en: 'First, install some more packages by typing `**pip install langchain_experimental
    pandas tabulate langchain-community pymongo --upgrade**` on your terminal. Popular
    agent toolkits include:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过在您的终端中输入`**pip install langchain_experimental pandas tabulate langchain-community
    pymongo --upgrade**`来安装更多包。流行的代理工具包包括：
- en: CSV Agent
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CSV Agent
- en: Gmail Toolkit
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gmail Toolkit
- en: OpenAI Agent
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI Agent
- en: Python Agent
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python Agent
- en: JSON Agent
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON Agent
- en: Pandas DataFrame Agent
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas DataFrame Agent
- en: The CSV Agent uses a Pandas DataFrame Agent and `python_repl_ast` tool to investigate
    a *.csv* file. You can ask it to quantify the data, identify column names, or
    create a correlation matrix.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: CSV代理使用Pandas DataFrame代理和`python_repl_ast`工具来调查*.csv*文件。您可以要求量化数据、识别列名或创建相关矩阵。
- en: 'Create a new Jupyter Notebook or Python file in *content/chapter_6* of the
    [shared repository](https://oreil.ly/x6FHn), then you will need to import `create_csv_agent`,
    `ChatOpenAI`, and `AgentType`. The `create_csv_agent` function requires an LLM,
    dataset `file path`, and `agent_type`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在[共享仓库](https://oreil.ly/x6FHn)的*content/chapter_6*中创建一个新的Jupyter Notebook或Python文件，然后您需要导入`create_csv_agent`、`ChatOpenAI`和`AgentType`。`create_csv_agent`函数需要一个LLM、数据集`文件路径`和`agent_type`：
- en: '[PRE25]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'It’s even possible for you to interact with a SQL database via a SQLDatabase
    agent:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 您甚至可以通过SQLDatabase代理与SQL数据库进行交互：
- en: '[PRE26]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]sql\nINSERT INTO Users (FirstName, LastName, Email,'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE27]sql\nINSERT INTO Users (FirstName, LastName, Email,'
- en: DateJoined)\nVALUES (\'John\', \'Doe\', \'john.doe@email.com\',
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: DateJoined)\nVALUES (\'John\', \'Doe\', \'john.doe@email.com\',
- en: \'2023-05-01\'), \n(\'Mary\', \'Johnson\', \'mary.johnson@email.com\',
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: \'2023-05-01\'), \n(\'Mary\', \'Johnson\', \'mary.johnson@email.com\',
- en: \'2023-05-02\'),\n (\'Peter\', \'Smith\', \'peter.smith@email.com\',
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: \'2023-05-02\'),\n (\'Peter\', \'Smith\', \'peter.smith@email.com\',
- en: \'2023-05-03\'),\n (\'Paul\', \'Brown\', \'paul.brown@email.com\',
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: \'2023-05-03\'),\n (\'Paul\', \'Brown\', \'paul.brown@email.com\',
- en: \'2023-05-04\'),\n (\'Jane\', \'Davis\', \'jane.davis@email.com\',
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: \'2023-05-04\'),\n (\'Jane\', \'Davis\', \'jane.davis@email.com\',
- en: \'2023-05-05\');\n[PRE28]
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: \'2023-05-05\');\n[PRE28]
- en: First, the `agent_executor` inspects the SQL database to understand the database
    schema, and then the agent writes and executes a SQL statement that successfully
    adds five users into the SQL table.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`agent_executor`检查SQL数据库以了解数据库模式，然后代理编写并执行一个SQL语句，成功将五个用户添加到SQL表中。
- en: Customizing Standard Agents
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义标准代理
- en: 'It’s worth considering how to customize LangChain agents. Key function arguments
    can include the following:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑如何自定义LangChain代理是值得的。关键函数参数可以包括以下内容：
- en: '`prefix` and `suffix` are the prompt templates that are inserted directly into
    the agent.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prefix`和`suffix`是直接插入到代理中的提示模板。'
- en: '`max_iterations` and `max_execution_time` provide you with a way to limit API
    and compute costs in case an agent becomes stuck in an endless loop:'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_iterations`和`max_execution_time`为您提供了限制API和计算成本的方法，以防代理陷入无限循环：'
- en: '[PRE29]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s update the previously created `agent_executor` so that the agent can
    perform more SQL statements. The `SQL_PREFIX` is directly inserted into the `create_sql_agent`
    function as the `prefix`. Additionally, you’ll insert the recommended `user_sql`
    from the previous agent that wouldn’t directly run `INSERT`, `UPDATE`, or `EDIT`
    commands; however, the new agent will happily execute CRUD (create, read, update,
    delete) operations against the SQLite database:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更新之前创建的`agent_executor`，以便代理可以执行更多的SQL语句。`SQL_PREFIX`直接插入到`create_sql_agent`函数中作为`prefix`。此外，您还将插入之前代理中推荐的`user_sql`，该代理不会直接运行`INSERT`、`UPDATE`或`EDIT`命令；然而，新代理将愉快地执行对SQLite数据库的CRUD（创建、读取、更新、删除）操作：
- en: '[PRE30]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Custom Agents in LCEL
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LCEL中的自定义代理
- en: 'It’s very easy to create a custom agent using LCEL; let’s create a chat model
    with one tool:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LCEL创建自定义代理非常简单；让我们使用一个工具创建一个聊天模型：
- en: '[PRE31]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, you’ll set up the prompt with a system message, user message, and a `MessagesPlaceholder`,
    which allows the agent to store its intermediate steps:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将使用系统消息、用户消息和`MessagesPlaceholder`来设置提示，这允许代理存储其中间步骤：
- en: '[PRE32]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Before creating an agent, you’ll need to bind the tools directly to the LLM
    for function calling:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建代理之前，你需要直接将工具绑定到LLM以进行函数调用：
- en: '[PRE33]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Here’s a step-by-step walk-through of the code:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码的逐步解析：
- en: 1\. Importing tool conversion function
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 导入工具转换函数
- en: You begin by importing `convert_to_openai_tool`. This allows you to convert
    Python function tools into a JSON schema, making them compatible with OpenAI’s
    LLMs.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先导入`convert_to_openai_tool`。这允许你将Python函数工具转换为JSON模式，使其与OpenAI的LLM兼容。
- en: 2\. Binding tools to your language model (LLM)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 将工具绑定到你的语言模型（LLM）
- en: Next, you bind the tools to your LLM. By iterating over each tool in your `tools`
    list and converting them with `convert_to_openai_tool`, you effectively create
    `llm_with_tools`. This equips your LLM with the functionalities of the defined
    tools.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将工具绑定到你的LLM。通过遍历你的`tools`列表中的每个工具并使用`convert_to_openai_tool`进行转换，你实际上创建了`llm_with_tools`。这使你的LLM具备了定义工具的功能。
- en: 3\. Importing agent formatting and parsing functions
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 导入代理格式化和解析函数
- en: Here, you import `format_to_openai_tool_messages` and `OpenAIToolsAgentOutputParser`.
    These format the agent’s scratchpad and parse the output from your LLM bound with
    tools.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你导入`format_to_openai_tool_messages`和`OpenAIToolsAgentOutputParser`。这些格式化代理的草稿本并解析与工具绑定的LLM的输出。
- en: 4\. Setting up your agent chain
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 设置你的代理链
- en: In this final and crucial step, you set up the agent chain.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最终且至关重要的步骤中，你设置了代理链。
- en: You take the lead by processing the user’s input directly.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以直接处理用户的输入来引领整个过程。
- en: You then strategically format intermediate steps into OpenAI function messages.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后你策略性地将中间步骤格式化为OpenAI函数消息。
- en: The `llm_with_tools` will then be called.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后将调用`llm_with_tools`。
- en: '`OpenAIToolsAgentOutputParser` is used to parse the output.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OpenAIToolsAgentOutputParser`用于解析输出。'
- en: 'Finally, let’s create and use the `AgentExecutor`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们创建并使用`AgentExecutor`：
- en: '[PRE34]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The LCEL agent uses the `.invoke(...)` function and correctly identifies that
    there are eight letters within the word *software*.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: LCEL代理使用`.invoke(...)`函数并正确地识别出单词*software*中有八个字母。
- en: Understanding and Using Memory
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解和使用记忆
- en: When interacting with LLMs, understanding the role and importance of memory
    is paramount. It’s not just about how these models recall information but also
    about the strategic interplay between long-term (LTM) and short-term memory (STM).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 与LLM交互时，理解记忆的角色和重要性至关重要。这不仅关乎这些模型如何回忆信息，还关乎长期记忆（LTM）和短期记忆（STM）之间的战略互动。
- en: Long-Term Memory
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 长期记忆
- en: Think of long-term memory as the library of an LLM. It’s the vast, curated collection
    of data, storing everything from text to conceptual frameworks. This knowledge
    pool aids the model in comprehending and generating responses.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 将长期记忆视为LLM的图书馆。它是一个庞大的、经过精心挑选的数据集合，存储从文本到概念框架的一切。这个知识库帮助模型理解和生成响应。
- en: 'Applications include:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 应用包括：
- en: Vector databases
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 矢量数据库
- en: These databases can store unstructured text data, providing the model with a
    reference point when generating content. By indexing and categorizing this data,
    LLMs can swiftly retrieve relevant information via *similarity distance metrics*.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据库可以存储非结构化文本数据，为模型在生成内容时提供参考点。通过索引和分类这些数据，LLM可以通过*相似度距离度量*快速检索相关信息。
- en: Self-reflection
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 自我反思
- en: Advanced applications include an LLM that introspects, records, and stores thoughts.
    Imagine an LLM that meticulously observes user patterns on a book review platform
    and catalogs these as deep insights. Over time, it pinpoints preferences, such
    as favored genres and writing styles. These insights are stored and accessed using
    retrieval. When users seek book recommendations, the LLM, *powered by the retrieved
    context*, provides bespoke suggestions aligned with their tastes.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 高级应用包括一个自我反思、记录和存储思想的LLM。想象一个LLM，它细致地观察书评平台上的用户模式，并将这些模式作为深入见解进行分类。随着时间的推移，它能够精确地指出偏好，例如喜欢的文学类型和写作风格。这些见解通过检索进行存储和访问。当用户寻求书籍推荐时，由检索到的上下文驱动的LLM，提供符合他们口味的定制建议。
- en: Custom retrievers
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义检索器
- en: Creating specific retrieval functions can significantly boost an LLM’s efficiency.
    Drawing parallels with human memory systems, these functions can prioritize data
    based on its relevance, the elapsed time since the last memory, and its utility
    in achieving a particular objective.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 创建特定的检索函数可以显著提高LLM的效率。与人类记忆系统进行类比，这些函数可以根据数据的相关性、自上次记忆以来经过的时间以及其在实现特定目标中的效用来优先排序数据。
- en: Short-Term Memory
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 短期记忆
- en: Short-term memory in LLMs is akin to a temporary workspace. Here, recent interactions,
    active tasks, or ongoing conversations are kept at the forefront to ensure continuity
    and context.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs中的短期记忆类似于一个临时工作空间。在这里，最近的交互、活跃的任务或进行的对话被保持在最前沿，以确保连续性和上下文。
- en: 'Applications include:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 应用包括：
- en: Conversational histories
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 对话历史
- en: For chatbots, tracking conversational history is essential. It allows the bot
    to maintain context over multiple exchanges, preventing redundant queries and
    ensuring the conversation flows naturally.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聊天机器人来说，跟踪对话历史至关重要。它允许机器人维护多个交流的上下文，防止冗余查询并确保对话自然流畅。
- en: Repetition avoidance
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 避免重复
- en: STM proves invaluable when similar or identical queries are posed by users.
    By referencing its short-term recall, the model can provide consistent answers
    or diversify its responses, based on the application’s requirement.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户提出相似或相同的查询时，STM变得非常有价值。通过参考其短期回忆，模型可以提供一致的答案或根据应用程序的需求多样化其响应。
- en: Having touched upon the foundational concepts of LTM and STM, let’s transition
    to practical applications, particularly in the realm of question-answer (QA) systems.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要介绍了LTM和STM的基础概念之后，让我们转向实际应用，特别是在问答（QA）系统的领域。
- en: Short-Term Memory in QA Conversation Agents
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: QA对话代理中的短期记忆
- en: 'Imagine Eva, a virtual customer support agent for an e-commerce platform. A
    user might have several interlinked queries:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下Eva，一个电子商务平台的虚拟客户支持代理。用户可能会有几个相互关联的查询：
- en: 'User: “How long is the return policy for electronics?”'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户：“电子产品退货政策有多长时间？”
- en: 'Eva: “The return policy for electronics is 30 days.”'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eva：“电子产品的退货政策是30天。”
- en: 'User: “What about for clothing items?”'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户：“关于服装商品呢？”
- en: 'Eva, leveraging STM: “For clothing items, it’s 45 days. Would you like to know
    about any other categories?”'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eva，利用STM：“对于服装商品，是45天。您想了解其他任何类别吗？”
- en: Notice that by utilizing short term memory (STM), Eva seamlessly continues the
    conversation, anticipating potential follow-up questions. This fluidity is only
    possible due to the effective deployment of short-term memory, allowing the agent
    to perceive conversations not as isolated QAs but as a cohesive interaction.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，通过利用短期记忆（STM），Eva无缝地继续对话，预测可能的后续问题。这种流畅性仅因有效部署短期记忆，使代理能够将对话视为连贯的交互，而不是孤立的问答。
- en: For developers and prompt engineers, understanding and harnessing this can significantly
    elevate the user experience, fostering engagements that are meaningful, efficient,
    and humanlike.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开发者和提示工程师来说，理解和利用这一点可以显著提升用户体验，培养出有意义、高效且类似人类的互动。
- en: Memory in LangChain
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain中的记忆
- en: 'LangChain provides easy techniques for adding memory to LLMs. As shown in [Figure 6-3](#fig-6-3),
    every memory system in a chain is tasked with two fundamental operations: reading
    and storing.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了向LLMs添加记忆的简单技术。如图6-3所示，链中的每个记忆系统都负责两个基本操作：读取和存储。
- en: It’s pivotal to understand that each chain has innate steps that demand particular
    inputs. While a user provides some of this data, the chain can also source other
    pieces of information from its memory.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这一点至关重要，即每个链都有内在的步骤，需要特定的输入。虽然用户提供了一些这些数据，但链也可以从其记忆中获取其他信息。
- en: '![Memory within LangChain](assets/pega_0603.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain中的记忆](assets/pega_0603.png)'
- en: Figure 6-3\. Memory within LangChain
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3\. LangChain中的记忆
- en: 'In every operation of the chain, there are two crucial interactions with its
    memory:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在链的每个操作中，都有两个与其记忆的关键交互：
- en: '*After collecting the initial user data but before executing*, the chain retrieves
    information from its memory, adding to the user’s input.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在收集初始用户数据之后但在执行之前*，链从其记忆中检索信息，添加到用户的输入中。'
- en: '*After the chain has completed but before returning the answer*, a chain will
    write the inputs and outputs of the current run to memory so that they can be
    referred to in future runs.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在链完成之后但在返回答案之前*，链会将当前运行的输入和输出写入记忆，以便在未来的运行中参考。'
- en: 'There are two pivotal choices you’ll need to make when creating a memory system:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建记忆系统时，您需要做出两个关键的选择：
- en: The method of storing state
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储状态的方法
- en: The approach to querying the memory state
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询记忆状态的方法
- en: Preserving the State
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存状态
- en: Beneath the surface, the foundational memory of generative AI models is structured
    as a sequence of chat messages. These messages can be stored in temporary in-memory
    lists or anchored in a more durable database. For those leaning toward long-term
    storage, there’s a wide range of [database integrations available](https://oreil.ly/ECD_n),
    streamlining the process and saving you from the hassle of manual integration.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在表面之下，生成式AI模型的基础记忆是以一系列聊天消息的形式组织的。这些消息可以存储在临时的内存列表中，或者锚定在更持久的数据库中。对于那些倾向于长期存储的人来说，有各种各样的[数据库集成可用](https://oreil.ly/ECD_n)，简化了流程，并让你免于手动集成的麻烦。
- en: 'With five to six lines of code, you can easily integrate a `MongoDBChatMessageHistory`
    that’s unique based on a `session_id` parameter:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 通过五到六行代码，你可以轻松地集成一个基于`session_id`参数的独特`MongoDBChatMessageHistory`：
- en: '[PRE35]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Querying the State
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询状态
- en: A basic memory framework might merely relay the latest messages with every interaction.
    A slightly more nuanced setup might distill a crisp synopsis of the last set of
    messages. An even more advanced setup would discern specific entities from dialogue
    and relay only data about those entities highlighted in the ongoing session.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本的记忆框架可能只是每次交互时传递最新的消息。一个稍微复杂一点的设置可能会提炼出最后一组消息的清晰摘要。一个更高级的设置会从对话中识别特定实体，并仅传递当前会话中突出显示的这些实体的数据。
- en: Different applications require varying demands on memory querying. LangChain’s
    memory toolkit will help you to create simplistic memory infrastructures while
    empowering you to architect bespoke systems when necessary.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的应用对记忆查询有不同的需求。LangChain的记忆工具包将帮助你创建简单的记忆基础设施，并在必要时赋予你构建定制系统的能力。
- en: ConversationBufferMemory
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConversationBufferMemory
- en: There are various types of memory within LangChain, and one of the most popular
    is ConversationBufferMemory. This allows you to store multiple chat messages with
    no restriction on chat history size.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain中有各种类型的记忆，其中最受欢迎的是ConversationBufferMemory。这允许你存储多个聊天消息，没有对聊天历史大小的限制。
- en: 'Start by importing `ConversationBufferMemory`, and you can then add context
    with the `save_context` function. The `load_memory_variables` function returns
    a Python dictionary containing the `Human` and `AI` messages:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入`ConversationBufferMemory`，然后你可以使用`save_context`函数添加上下文。`load_memory_variables`函数返回一个包含`Human`和`AI`消息的Python字典：
- en: '[PRE36]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You can also return the LangChain schema messages, i.e., `SystemMessage`, `AIMessage`
    or `HumanMessage`, by adding `return_messages=True` to `ConversationBufferMemory`:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过将`return_messages=True`添加到`ConversationBufferMemory`来返回LangChain的架构消息，即`SystemMessage`、`AIMessage`或`HumanMessage`：
- en: '[PRE37]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s add memory directly to a chain in LCEL:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在LCEL中直接将记忆添加到一个链中：
- en: '[PRE38]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Notice the `MessagesPlaceholder` has a `variable_name` of `"history"`. This
    is aligned with the `memory` key within `ConversationBufferMemory`, allowing the
    previous chat history to be directly formatted into the `ChatPromptTemplate`.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`MessagesPlaceholder`有一个`variable_name`为`"history"`。这与`ConversationBufferMemory`中的`memory`键对齐，允许之前的聊天历史直接格式化到`ChatPromptTemplate`中。
- en: 'After setting up the LCEL chain, let’s invoke it and save the messages to the
    `memory` variable:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好LCEL链之后，让我们调用它并将消息保存到`memory`变量中：
- en: '[PRE39]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The memory has two messages, a `HumanMessage` and an `AIMessage`; both are
    saved to memory by using the `save_context` function. Let’s test whether the LCEL
    chain is able to use previous context to answer new questions:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆包含两条消息，一条`HumanMessage`和一条`AIMessage`；两者都通过使用`save_context`函数保存到记忆中。让我们测试LCEL链是否能够使用之前的内容来回答新的问题：
- en: '[PRE40]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The LCEL chain is now able to use previous messages to answer new queries!
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: LCEL链现在能够使用之前的消息来回答新的查询了！
- en: 'Furthermore, you can easily add memory to an agent by adding a `MessagesPlaceHolder`
    to the `ChatPromptTemplate` and adding memory to the `AgentExecutor`:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以通过在`ChatPromptTemplate`中添加`MessagesPlaceHolder`并将记忆添加到`AgentExecutor`中来轻松地为代理添加记忆：
- en: '[PRE41]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: You can view the full implementation within this [Jupyter Notebook](https://oreil.ly/LXQNy).
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本地的[Jupyter Notebook](https://oreil.ly/LXQNy)中查看完整的实现。
- en: By leveraging this memory, your agent delivers a more context-aware and fluid
    conversational experience, negating the need for additional tools to recall past
    interactions.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用这种记忆，你的代理可以提供更加情境感知和流畅的对话体验，从而无需额外的工具来回忆过去的交互。
- en: 'ConversationBufferMemory doesn’t have a buffer limit, but different memory
    types such as ConversationSummaryBufferMemory allow you specify a maximum token
    limit, after which the conversation is summarized:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ConversationBufferMemory没有缓冲区限制，但不同的内存类型，如ConversationSummaryBufferMemory，允许你指定最大标记限制，超过该限制后，对话将被总结：
- en: '[PRE42]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note
  id: totrans-356
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: By default, memory is stored locally within the Python process. This approach
    is inherently transient and limited by the session or process lifespan. For applications
    requiring continuity over time and the ability to learn from historical data,
    a shift to database-backed memory becomes essential.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，内存存储在Python进程的本地。这种方法本质上是短暂的，并受会话或进程生命周期的限制。对于需要时间连续性和能够从历史数据中学习应用程序，转向数据库支持的内存变得至关重要。
- en: There are several integrations available for [database-backed memory](https://oreil.ly/nTBox),
    which transition the memory usage from a short-term, session-specific context
    to a more robust, long-term storage solution.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于数据库的内存（[database-backed memory](https://oreil.ly/nTBox)），有几种集成方式，这些方式将内存使用从短期、会话特定的上下文转变为更健壮的长期存储解决方案。
- en: Other Popular Memory Types in LangChain
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain中其他流行的内存类型
- en: While ConversationBufferMemory is a well-known memory type, it has limitations
    such as context length limits, potential lack of relevance, and lack of summarization.
    To address these issues, LangChain offers several other memory types.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ConversationBufferMemory是一种众所周知的内存类型，但它有一些限制，例如上下文长度限制、可能缺乏相关性以及缺乏摘要。为了解决这些问题，LangChain提供了几种其他内存类型。
- en: ConversationBufferWindowMemory
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConversationBufferWindowMemory
- en: 'This type maintains a sliding window of the most recent interactions, ensuring
    the buffer doesn’t grow excessively large. Features include the following:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 此类型维护最近交互的滑动窗口，确保缓冲区不会过大。功能包括以下内容：
- en: Keeps only the last `K` interactions
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅保留最后`K`次交互
- en: Can return history as either a string or a list of messages
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以返回历史记录作为字符串或消息列表
- en: '[PRE43]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: ConversationSummaryMemory
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConversationSummaryMemory
- en: 'This one condenses and summarizes the conversation over time and is ideal for
    longer conversations where verbatim message history would be token-expensive.
    Features include the following:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这一种方法会随着时间的推移对对话进行压缩和总结，非常适合较长的对话，因为逐字记录消息历史可能会消耗大量的标记。功能包括以下内容：
- en: Summarizes conversation on the fly
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线总结对话
- en: Can return history as a summary string or a list of system messages
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以返回历史记录作为摘要字符串或系统消息列表
- en: Allows direct prediction of new summaries
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许直接预测新的摘要
- en: Can be initialized with existing messages or summaries
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用现有的消息或摘要进行初始化
- en: '[PRE44]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ConversationSummaryBufferMemory
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConversationSummaryBufferMemory
- en: This is a hybrid memory that maintains a buffer of recent interactions but also
    compiles older interactions into a summary.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个混合内存，它不仅维护最近交互的缓冲区，还将较老的交互编译成摘要。
- en: 'Features include the following:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 功能包括以下内容：
- en: Uses token length to determine when to flush interactions
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标记长度来确定何时刷新交互
- en: Can return history as a summary with recent interactions or a list of messages
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以返回带有最近交互的历史记录摘要或消息列表
- en: Allows direct prediction of new summaries
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许直接预测新的摘要
- en: '[PRE45]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: ConversationTokenBufferMemory
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ConversationTokenBufferMemory
- en: This one keeps a buffer of recent interactions using token length to determine
    when to flush interactions.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这一种方法使用标记长度来保持最近的交互，并确定何时刷新交互。
- en: 'Features include the following:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 功能包括以下内容：
- en: Uses token length for flushing
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标记长度进行刷新
- en: Can return history as a string or a list of messages
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以返回历史记录作为字符串或消息列表
- en: '[PRE46]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: You’ve learned about the importance of memory in LangChain. Also, you now understand
    how to build and customize a memory system using LangChain’s memory toolkit, including
    methods of storing state and querying memory; you’ve seen examples on integrating
    MongoDBChatMessageHistory and utilizing the versatile ConversationBufferMemory.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解了在LangChain中内存的重要性。现在，你也明白了如何使用LangChain的内存工具包构建和自定义内存系统，包括存储状态和查询内存的方法；你看到了将MongoDBChatMessageHistory集成和利用多才多艺的ConversationBufferMemory的示例。
- en: 'Let’s summarize the different memory types available in LangChain and when
    they might be particularly useful:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下LangChain中可用的不同内存类型及其可能特别有用的场景：
- en: ConversationBufferWindowMemory
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ConversationBufferWindowMemory
- en: This memory type maintains the most recent interactions, thus proving useful
    in cases where the context of the conversation is essential without letting the
    buffer grow extensively large.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 此内存类型维护最近的交互，因此在对话的上下文至关重要且不使缓冲区过大时非常有用。
- en: ConversationSummaryMemory
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 交互总结内存
- en: Ideal for extended conversations, this memory type provides summarized versions
    of the conversation, saving valuable token space.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 对于长对话来说，这种内存类型提供了对话的摘要版本，节省了宝贵的令牌空间。
- en: ConversationSummaryBufferMemory
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 交互总结缓冲内存
- en: Convenient for situations where you not only want to maintain a record of recent
    interactions but also want to compile older interactions into a summary, thereby
    offering a hybrid approach.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于你不仅想记录最近交互，还想将旧交互汇总成总结的情况，从而提供一种混合方法。
- en: ConversationTokenBufferMemory
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇缓冲内存
- en: This memory type is useful when defining a specific token length is vital and
    a buffer of recent interactions needs to be maintained. It determines when to
    flush interactions based on token length.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 当定义特定令牌长度至关重要且需要维护最近交互的缓冲区时，这种内存类型很有用。它根据令牌长度确定何时刷新交互。
- en: Understanding the different memory options available can help you choose the
    most suitable one for your exact needs, depending on the situation.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 了解可用的不同内存选项可以帮助你根据具体情况选择最适合你的需求的一个。
- en: Give Direction
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指导方向
- en: Even as you’re determining which memory type to use, remember to direct the
    AI model appropriately. For instance, with ConversationBufferWindowMemory, you
    would need to specify the number of recent interactions (`K`) you want to keep.
    Be clear about your requirements for optimal results.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你在确定要使用哪种内存类型时，也要记住适当地指导 AI 模型。例如，使用 ConversationBufferWindowMemory，你需要指定你想要保留的最近交互的数量（`K`）。为了获得最佳结果，请明确你的要求。
- en: OpenAI Functions Agent with Memory
  id: totrans-399
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有内存的 OpenAI 函数代理
- en: 'Dive deeper into agents with a comprehensive example available on [GitHub](https://oreil.ly/jyLab).
    In this example, you’ll uncover how OpenAI integrates several essential components:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 GitHub 上的一个综合示例深入了解代理，[GitHub](https://oreil.ly/jyLab)。在这个示例中，你将发现 OpenAI
    如何整合几个关键组件：
- en: Memory management using chat messages
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用聊天消息进行内存管理
- en: Use tools such as API requests and file saving that can handle multiple function
    parameters
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用能够处理多个函数参数的工具，如 API 请求和文件保存
- en: Integrate a custom `SystemMessage` to guide and define the agent’s behavior
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成自定义 `SystemMessage` 以指导和定义代理的行为
- en: 'To illustrate, consider how a Python function’s docstring is utilized to provide
    a tool’s description:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，考虑一下 Python 函数的文档字符串是如何用来提供工具描述的：
- en: '[PRE47]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`StructuredTool.from_function()` will create a LangChain tool that’s capable
    of accepting multiple function arguments.'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: '`StructuredTool.from_function()` 将创建一个 LangChain 工具，该工具能够接受多个函数参数。'
- en: Give Direction and Specify Format
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指导并指定格式
- en: The docstring within the Python function showcases a designated format guiding
    the LLM on the content to use for the `raw_interview_text` parameter.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: Python 函数中的文档字符串展示了指导 LLM 使用 `raw_interview_text` 参数内容的指定格式。
- en: Additionally, the `return` statement emphasizes instructing the LLM to inform
    the user that the interview has been stored. This ensures the agent returns a
    more conversational response post-tool execution.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`return` 语句强调指导 LLM 通知用户访谈已被存储。这确保代理在工具执行后返回更具对话性的响应。
- en: 'To further demonstrate prompt engineering techniques, let’s examine another
    Python code snippet from the notebook:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步展示提示工程技巧，让我们检查笔记本中的另一个 Python 代码片段：
- en: '[PRE48]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In this example, `args_schema` is used within the `SummarizeFileFromURL` class.
    This attribute leverages the `ArgumentType` class, ensuring that the tool’s arguments
    are validated before execution. Specifically, it enforces that a valid URL string
    be provided and that the `file_type` argument should be either `"pdf"` or `"txt"`.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，`args_schema` 在 `SummarizeFileFromURL` 类中使用。该属性利用 `ArgumentType` 类，确保在执行之前验证工具的参数。具体来说，它强制提供有效的
    URL 字符串，并且 `file_type` 参数应该是 `"pdf"` 或 `"txt"`。
- en: By adding validation checks, you can guarantee that the agent processes functional
    arguments correctly, which, in turn, enhances the overall reliability and efficiency
    of tool execution.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加验证检查，你可以确保代理正确处理功能参数，这反过来又提高了工具执行的整体可靠性和效率。
- en: Advanced Agent Frameworks
  id: totrans-414
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级代理框架
- en: You now know about ReAct and OpenAI functions, but there are several other agent
    frameworks. Two other popular frameworks include *plan and execute agents* and
    *tree of thoughts*.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经了解了 ReAct 和 OpenAI 函数，但还有其他几个代理框架。其他两个流行的框架包括 *计划和执行代理* 和 *思维树*。
- en: Plan-and-Execute Agents
  id: totrans-416
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计划和执行代理
- en: Rather than have the LLM do the task planning and tool execution, you can separate
    this into two separate modules. Each module can be handled separately by an individual
    LLM that has access to the objective, current tasks, and completed tasks.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是让大型语言模型（LLM）进行任务规划和工具执行，你可以将这一过程分为两个独立的模块。每个模块都可以由一个可以访问目标、当前任务和已完成任务的独立LLM分别处理。
- en: Two popular versions of the plan-and-execute framework include [BabyAGI](https://oreil.ly/xeijG)
    and [AutoGPT](https://oreil.ly/M4z8K).
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 计划与执行框架的两个流行版本包括[BabyAGI](https://oreil.ly/xeijG)和[AutoGPT](https://oreil.ly/M4z8K)。
- en: '[Figure 6-4](#fig-6-4) showcases BabyAGI’s agent setup, which is designed to
    merge OpenAI LLMs with vector databases such as Chroma/Weaviate to create a robust,
    adaptive task management system.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-4](#fig-6-4)展示了BabyAGI的智能体设置，该设置旨在将OpenAI LLM与Chroma/Weaviate等向量数据库合并，以创建一个强大、自适应的任务管理系统。'
- en: In a continuous loop, the agent starts by fetching a task and passes it to the
    `execution_agent`, which taps into OpenAI to perform the task based on contextual
    data. After this, the outcomes are enriched and archived in Chroma/Weaviate.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个连续的循环中，智能体首先获取一个任务，并将其传递给`execution_agent`，该智能体利用OpenAI根据上下文数据执行任务。之后，结果被丰富并存档在Chroma/Weaviate中。
- en: The `task_creation_agent` then steps in, utilizing OpenAI to discern new tasks
    from the objective and results of the prior task. These tasks are presented as
    a list of dictionaries, giving structure to the resultant tasks.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '`task_creation_agent`随后介入，利用OpenAI从先前任务的目标和结果中识别新任务。这些任务以字典列表的形式呈现，为结果任务提供结构。'
- en: The `prioritization_agent` then interacts with OpenAI to rearrange the task
    list, ensuring alignment with the main objective. The synergy of these agents
    ensures that the system is always evolving, continuously generating and prioritizing
    tasks in an informed manner. Integrating [Chroma](https://oreil.ly/9R3pU) or [Weaviate](https://oreil.ly/2wu-y)
    plays a crucial role by offering a reservoir of contextual data, ensuring that
    tasks are always aligned with their predefined goals.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 然后`prioritization_agent`与OpenAI交互，重新排列任务列表，确保与主要目标保持一致。这些智能体的协同作用确保系统始终在进化，以信息化的方式持续生成和优先处理任务。整合[Chroma](https://oreil.ly/9R3pU)或[Weaviate](https://oreil.ly/2wu-y)起着至关重要的作用，因为它提供了一个上下文数据的宝库，确保任务始终与其预定义的目标保持一致。
- en: '![BabyAGI](assets/pega_0604.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![BabyAGI](assets/pega_0604.png)'
- en: Figure 6-4\. BabyAGI’s agent architecture
  id: totrans-424
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4\. BabyAGI的智能体架构
- en: The [plan-and-execute agent type](https://oreil.ly/8vYF5) does exist within
    LangChain, though it’s still experimental.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '[计划与执行智能体类型](https://oreil.ly/8vYF5)确实存在于LangChain中，尽管它仍然是实验性的。'
- en: Tree of Thoughts
  id: totrans-426
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维树
- en: As the application of language models in problem-solving expands across diverse
    tasks, their inference method remains bound to token-level, linear processing.
    This approach, while effective in many contexts, is limited when faced with tasks
    that need advanced strategic foresight or where the initial decisions are crucial.
    The [Tree of Thoughts (ToT) framework](https://oreil.ly/1rYDI) is a novel way
    to harness language models that goes beyond the conventional chain-of-thought
    prompting technique ([Figure 6-5](#fig-6-5)).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 随着语言模型在解决各种任务中的应用不断扩大，它们的推理方法仍然局限于基于标记的、线性的处理。这种方法在许多情况下都有效，但在需要高级战略预见或初始决策至关重要的任务面前就有限了。[思维树（ToT）框架](https://oreil.ly/1rYDI)是一种利用语言模型的新方法，它超越了传统的思维链提示技术([图6-5](#fig-6-5))。
- en: The central premise of ToT is to enable exploration across coherent text chunks,
    termed *thoughts*. These thoughts represent stages in problem-solving, facilitating
    the language model to undertake a more deliberate decision-making process. Instead
    of sticking to one reasoning path, the model can explore various reasoning trajectories,
    self-assessing its decisions at each step. The framework is designed to allow
    for forward planning, revisiting past decisions, and making overarching choices.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 思维树（ToT）的核心前提是允许在连贯的文本块之间进行探索，这些文本块被称为*思维*。这些思维代表了问题解决的各个阶段，有助于语言模型进行更谨慎的决策过程。模型不再局限于一条推理路径，可以探索各种推理轨迹，并在每一步自我评估其决策。该框架旨在允许进行前瞻性规划、回顾过去的决策，并做出总体选择。
- en: '![Tree of Thoughts](assets/pega_0605.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![思维树](assets/pega_0605.png)'
- en: Figure 6-5\. Tree of Thoughts (ToT)
  id: totrans-430
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-5\. 思维树（ToT）
- en: Evidence of its success comes from experimental results on tasks requiring intricate
    planning or searching capabilities. In a game like *game of 24*, the traditional
    GPT-4, when prompted using chain-of-thought, managed a 4% success rate. In contrast,
    the ToT approach skyrocketed this figure to an impressive 74%. This paradigm shift
    isn’t limited to games. The ToT method also showed promise in areas like creative
    writing and mini crosswords, underscoring its versatility.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 其成功的证据来自于对需要复杂规划或搜索能力的任务的实验结果。在一个像*24点游戏*这样的游戏中，传统的GPT-4在提示使用思维链时，成功率为4%。相比之下，ToT方法将这一数字飙升至令人印象深刻的74%。这种范式转变不仅限于游戏。ToT方法在创意写作和迷你填字游戏等领域的应用也显示出其多功能性。
- en: Complementing the theory is a [LangChain implementation](https://oreil.ly/fub1z),
    which gives a glimpse into how ToT can be actualized. A sudoku puzzle serves as
    the illustrative example, with the main aim to replace wildcard characters (*)
    with numbers, while adhering to sudoku rules.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 与理论相辅相成的是[LangChain实现](https://oreil.ly/fub1z)，它展示了ToT如何实现。一个数独谜题作为说明性示例，主要目的是用数字替换通配符字符(*)，同时遵守数独规则。
- en: ToT is not just a new method; it’s a paradigm shift in how we envision language
    model inference. By providing models the capacity to think, backtrack, and strategize,
    ToT is redefining the boundaries of AI problem-solving.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: ToT不仅仅是一种新的方法；它是在我们设想语言模型推理方面的范式转变。通过为模型提供思考、回溯和策略规划的能力，ToT正在重新定义AI问题解决的边界。
- en: If you consider ToT as a strategy for commanding LLMs, LangChain callbacks can
    be viewed as tools to diagnose and ensure the smooth operation of these strategies.
    Let’s dive into how you can harness this feature effectively.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将ToT视为指挥LLMs的策略，LangChain回调可以被视为诊断和确保这些策略顺利运行的工具。让我们深入了解如何有效地利用这一功能。
- en: Callbacks
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回调
- en: 'LangChain’s [*callbacks*](https://oreil.ly/8EhXl) empower you to seamlessly
    monitor and pinpoint issues within your application. Until now, you’ve encountered
    the parameter `verbose=True` in `AgentExecutor` chains:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的[*回调*](https://oreil.ly/8EhXl)使您能够无缝监控和定位应用程序中的问题。到目前为止，您在`AgentExecutor`链中遇到了`verbose=True`参数：
- en: '[PRE49]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This parameter logs useful outputs for debugging purposes, but what if you’re
    keen on tracking specific events? Enter callbacks, your go-to solution.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 此参数记录了用于调试的有用输出，但如果你热衷于跟踪特定事件呢？请进入回调，这是你的首选解决方案。
- en: 'The `BaseCallbackHandler` class acts as a foundation for monitoring and responding
    to various events during the execution of your generative AI models. Each method
    in this class corresponds to specific stages like the start, end, or even errors
    during the model’s runtime. For instance, the `on_llm_start` gets triggered when
    an LLM begins its operation. Similarly, methods like `on_chain_error` and `on_tool_end`
    react to errors in chains or after using a tool:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '`BaseCallbackHandler`类在您的生成式AI模型执行期间充当监控和响应各种事件的基础。该类中的每个方法都对应于特定的阶段，如模型的开始、结束，甚至在模型运行时发生的错误。例如，当LLM开始其操作时，会触发`on_llm_start`。同样，`on_chain_error`和`on_tool_end`等方法会对链中的错误或使用工具后的错误做出反应：'
- en: '[PRE50]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Each callback can be scoped to either the class or individual requests.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 每个回调都可以作用域为类或单个请求。
- en: Global (Constructor) Callbacks
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全局（构造函数）回调
- en: 'When defining callbacks within a constructor, like `AgentExecutor(callbacks=[handler],
    tags=[''a-tag''])`, they are activated for every call made on that instance. These
    callbacks are limited to that specific instance. To illustrate, when a handler
    is passed to an `LLMChain` during its creation, it won’t interact with any children
    chains:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数中定义回调，例如`AgentExecutor(callbacks=[handler], tags=['a-tag'])`，它们会在对该实例的每次调用时被激活。这些回调仅限于该特定实例。为了说明，当一个处理程序在创建`LLMChain`时被传递，它不会与任何子链交互：
- en: '[PRE51]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The tags you include, such as `'a-tag'`, can be tremendously useful in tracing
    and sorting the outputs of your generative AI setup. Especially in large projects
    with numerous chains, utilizing tags can significantly streamline your workflow.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 你包含的标签，如`'a-tag'`，在追踪和整理您的生成式AI设置输出方面非常有用。特别是在具有许多链的大型项目中，利用标签可以显著简化您的流程。
- en: Request-Specific Callbacks
  id: totrans-446
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 请求特定回调
- en: 'On the other hand, callbacks can be defined within the `invoke()` method. For
    instance, a request to an `LLMChain` might subsequently trigger another `LLMChain`
    request, and the same handler would be applied:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，回调可以在`invoke()`方法中定义。例如，对`LLMChain`的请求可能会随后触发另一个`LLMChain`请求，并应用相同的处理程序：
- en: '[PRE52]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The Verbose Argument
  id: totrans-449
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 详细说明论点
- en: A common utility, the `verbose` argument, is accessible for most API objects.
    When you use `AgentExecutor(verbose=True)`, it’s the same as integrating a `ConsoleCallbackHandler`
    into the callbacks argument of the object and its descendants. It acts as a useful
    debugging tool by logging every event directly to your console.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 常用实用工具 `verbose` 参数对大多数 API 对象都是可用的。当您使用 `AgentExecutor(verbose=True)` 时，它与将
    `ConsoleCallbackHandler` 集成到对象的回调参数及其后代中相同。它通过直接将每个事件记录到您的控制台而充当有用的调试工具。
- en: When to Use Which?
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用哪个？
- en: Constructor callbacks
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数回调
- en: Ideal for overarching tasks like logging or monitoring across an entire chain.
    If tracking all interactions within agents is your goal, attach the handler during
    its initiation.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于跨整个链的日志记录或监控等全局任务。如果您目标是跟踪代理的所有交互，请在初始化期间附加处理程序。
- en: Request callbacks
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 请求回调
- en: Tailored for specific use cases like streaming, where outputs from a single
    request are relayed to dedicated endpoints, say a websocket. So, for a scenario
    where the output from a singular request needs to be streamed to a websocket,
    the handler should be linked to the `invoke()` method.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 定制用于特定用例，如流式传输，其中单个请求的输出被转发到专用端点，例如 WebSocket。因此，对于需要将单个请求的输出流式传输到 WebSocket
    的场景，处理程序应链接到 `invoke()` 方法。
- en: Verbose arguments
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 冗长参数
- en: Useful for debugging and local LLM development, but it can generate a large
    number of logs.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 对于调试和本地 LLM 开发很有用，但它可以生成大量的日志。
- en: Token Counting with LangChain
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 LangChain 进行令牌计数
- en: LangChain provides an effective method for token counting during your interactions
    with generative AI models.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 在您与生成式 AI 模型交互期间提供了有效的令牌计数方法。
- en: 'You need to set up the necessary modules; import the `asyncio` module and the
    relevant functions from the LangChain package:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要设置必要的模块；导入 `asyncio` 模块和 LangChain 包中的相关函数：
- en: '[PRE53]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now, employ the `get_openai_callback` context manager to make a request and
    count the tokens used:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用 `get_openai_callback` 上下文管理器发出请求并计算使用的令牌：
- en: '[PRE54]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: After executing this code, `total_tokens` will store the number of tokens used
    for your request.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码后，`total_tokens` 将存储您请求使用的令牌数。
- en: 'When making multiple requests within the context manager, you can verify that
    the total tokens counted are accurate:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文管理器中发出多个请求时，您可以验证总令牌计数是否准确：
- en: '[PRE55]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: As you can observe, making the same request twice often results in `cb.total_tokens`
    being twice the value of `total_tokens`.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所观察到的，两次发出相同的请求通常会导致 `cb.total_tokens` 是 `total_tokens` 的两倍。
- en: 'LangChain supports concurrent runs, letting you execute multiple requests at
    the same time:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 支持并发运行，让您可以同时执行多个请求：
- en: '[PRE56]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '`cb` provides a detailed breakdown of your interaction with the AI model, offering
    key metrics that are pivotal for prompt engineering:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '`cb` 提供了您与 AI 模型的交互的详细分解，提供了对提示工程至关重要的关键指标：'
- en: '`cb.successful_requests` tracks the number of requests that have been executed
    successfully. It’s a direct indicator of how many API requests were effectively
    processed without encountering errors.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb.successful_requests` 跟踪已成功执行的请求数量。它是有效处理 API 请求且未遇到错误的直接指标。'
- en: With `cb.total_cost`, you get a transparent view of the cost associated with
    your requests. This can be a crucial metric for budgeting and managing expenses
    when working extensively with the AI.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `cb.total_cost`，您可以得到与您的请求相关的成本的透明视图。这在大量使用 AI 时，对于预算和费用管理是一个关键指标。
- en: '`cb.total_tokens` denotes the cumulative number of tokens used in both the
    prompt and the completion. This provides a holistic view of token consumption.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb.total_tokens` 表示在提示和完成过程中使用的累积令牌数。这提供了一个对令牌消耗的整体视图。'
- en: '`cb.prompt_tokens` gives insight into how many tokens were used in the prompts
    you provided. This can guide you in optimizing your prompts to be concise yet
    effective.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb.prompt_tokens` 提供了您提供的提示中使用的令牌数量的见解。这可以帮助您优化提示，使其简洁而有效。'
- en: '`cb.completion_tokens` highlights the number of tokens taken up by the AI’s
    response. This can be beneficial when analyzing the verbosity or depth of the
    AI’s answers.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb.completion_tokens` 强调了 AI 响应占用的令牌数量。这在分析 AI 响应的冗长或深度时可能很有用。'
- en: Summary
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the concept of chain-of-thought reasoning
    and its importance in autonomous agents. You discovered how LLMs can break down
    complex problems into smaller components to provide effective solutions.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了思维链推理的概念及其在自主代理中的重要性。你发现了LLM如何将复杂问题分解成更小的组件以提供有效解决方案。
- en: Additionally, you explored the agent-based architecture in generative AI models
    and gained valuable insights into memory integration and advanced agent frameworks.
    You investigated several agent frameworks such as ReAct and OpenAI function calling
    and learned that these frameworks enhance LLM model responses by utilizing external
    tools.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你探索了生成式AI模型中的基于代理的架构，并获得了关于记忆集成和高级代理框架的宝贵见解。你研究了几个代理框架，例如ReAct和OpenAI函数调用，并了解到这些框架通过利用外部工具来增强LLM模型的响应。
- en: In [Chapter 7](ch07.html#intro_image_07), you’ll be introduced to image generation
    using generative AI. You will learn the history of generative AI image models,
    including the strengths and weaknesses of each vendor.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.html#intro_image_07)中，你将了解到使用生成式AI进行图像生成。你将学习生成式AI图像模型的历史，包括每个供应商的优缺点。
