- en: Chapter 3\. Some Economics of Agents, Model Usage, and Selection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章：代理的经济学、模型使用和选择
- en: LLMs serve as the cognitive engines that power AI agents—just like how different
    car engines are built for different purposes, from ATVs to school buses. Extending
    this framework, outlined in [*What Are AI Agents? When and How to Use LLM Agents*](https://learning.oreilly.com/library/view/what-are-ai/9781098159726/)
    (O’Reilly), selecting the right LLM for your agent isn’t just about performance—it’s
    also about a trade-off between capabilities and economics. The foundation model
    you choose will directly affect not only what your agent can do but also how much
    it costs to run, how efficiently it operates, and ultimately, whether your project
    makes financial sense. Understanding these economic trade-offs is crucial for
    anyone building AI agents, whether you’re a startup watching every dollar or an
    enterprise looking to scale.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）作为驱动人工智能代理的认知引擎——就像不同的汽车引擎为不同的目的而设计，从全地形车到校车。在[*什么是人工智能代理？何时以及如何使用LLM代理*](https://learning.oreilly.com/library/view/what-are-ai/9781098159726/)（O'Reilly）中概述的框架基础上，为您的代理选择合适的LLM不仅关乎性能——它还关乎能力和经济之间的权衡。您选择的基座模型将直接影响您的代理能做什么，以及运行它的成本、其操作的效率，以及最终，您的项目是否具有财务意义。理解这些经济权衡对于任何构建人工智能代理的人来说至关重要，无论您是关注每一美元的初创公司，还是希望扩展的企业。
- en: The Economics of Agent Adoption
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理采用的经济学
- en: The first thing to note about AI agents is that as they expand in their capacity
    to access and work with more tools—through protocols like Model Context Protocol
    (MCP) or through functional calls within LLMs themselves—the end user benefits
    more from the agent. But as with everything in economics, there is a trade-off.
    As the complexity of the task an agent is provided increases, so too does the
    marginal cost of a given action—whether we measure that cost by the hours it takes
    to complete a task, the cost of API calls, or the ability of the underlying agent
    to solve the niche tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 关于人工智能代理的第一点要注意的是，随着它们在通过协议（如模型上下文协议MCP）或通过LLM内部的函数调用等方式获取和操作更多工具的能力扩大，最终用户从代理中获得的利益也更大。但就像经济学中的所有事物一样，存在权衡。随着代理提供的任务复杂性的增加，特定行动的边际成本也增加——无论我们通过完成任务所需的小时数、API调用的成本，还是底层代理解决特定任务的能力来衡量这种成本。
- en: 'The chart shown in [Figure 3-1](#ch03_figure_1_1758256567876034) plots task
    complexity (*x*-axis) against marginal benefit and marginal cost (*y*-axis). As
    complexity rises, the extra value an AI model adds (marginal benefit) falls while
    the extra cost or risk (marginal cost) climbs. Their intersection (*) marks the
    economically optimal point: any task with complexity to the left of * still delivers
    a positive net benefit (MB > MC), making AI deployment worthwhile; tasks to the
    right cost more than they’re worth.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-1](#ch03_figure_1_1758256567876034)中显示的图表将任务复杂度（*x*轴）与边际收益和边际成本（*y*轴）进行对比。随着复杂度的增加，人工智能模型增加的额外价值（边际收益）下降，而额外的成本或风险（边际成本）上升。它们的交点（*）标志着经济最优点：任何复杂度在*左侧的任务仍然提供正的净收益（MB
    > MC），使得人工智能部署是有价值的；右侧的任务成本超过其价值。'
- en: '![Diagram illustrating how current AI capabilities relate task complexity with
    marginal benefit and cost, showing the economically optimal point for AI deployment
    where benefits outweigh costs.](assets/mmai_0301.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![说明当前人工智能能力如何将任务复杂性与边际收益和成本相关联的图表，显示了人工智能部署的经济最优点，其中收益超过成本。](assets/mmai_0301.png)'
- en: Figure 3-1\. Current AI capabilities
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1：当前人工智能能力
- en: But there’s more. When breakthrough models or new integration capabilities arrive—think
    GPT-5 or a cutting-edge open source foundation model—the marginal cost curve shifts
    downward and to the right. In practical terms, each additional unit of task complexity
    now carries a lower cost, so the intersection with the marginal benefit curve
    moves farther right. That expands the zone where MB > MC, meaning more complex
    tasks become economically viable for AI automation. In other words, as model efficiency
    improves, your “deployment frontier” widens—AI can add positive net benefit to
    a broader range of projects ([Figure 3-2](#ch03_figure_2_1758256567876062)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有更多。当突破性模型或新的集成能力出现时——想想GPT-5或前沿的开源基座模型——边际成本曲线会向下并向右移动。从实际意义上讲，现在每个额外的任务复杂度单位成本更低，因此与边际收益曲线的交点向右移动。这扩大了MB
    > MC的区域，意味着更复杂的任务对人工智能自动化来说在经济上变得可行。换句话说，随着模型效率的提高，您的“部署前沿”变宽——人工智能可以为更广泛的项目增加正的净收益（[图3-2](#ch03_figure_2_1758256567876062)）。
- en: '![Diagram illustrating how the introduction of new AI models shifts the intersection
    of marginal cost (MC) and marginal value (MV), expanding the frontier for economically
    viable AI automation.](assets/mmai_0302.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![说明引入新AI模型如何改变边际成本（MC）和边际价值（MV）的交叉点，扩大经济可行的AI自动化的前沿的图表](assets/mmai_0302.png)'
- en: Figure 3-2\. When new AI models emerge, the frontier shifts
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2。当新的AI模型出现时，前沿发生移动
- en: 'The Model Selection Matrix: A Multifactor Analysis'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型选择矩阵：多因素分析
- en: Building an AI agent requires a corresponding LLM to run it. The choice of an
    LLM is not as simple as it may seem. Defaulting to the latest model, such as Claude
    Sonnet 4 or GPT-5, may be a solid heuristic for quick, general projects, but when
    it comes to specialized applications or applications that may become the core
    of your business or product, much more thought, planning, and explanation are
    required. Do you only need text-based agents, or do you need multimodal agents
    that can ingest voice or vision inputs? How many users will use your agents? What
    are your latency needs? These questions are just table stakes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个AI代理需要一个相应的LLM来运行它。选择一个LLM并不像看起来那么简单。默认选择最新的模型，如Claude Sonnet 4或GPT-5，可能是一个快速、通用项目的有效启发式方法，但当涉及到专门的应用或可能成为你业务或产品核心的应用时，就需要更多的思考、计划和解释。你是否只需要基于文本的代理，或者你需要能够处理声音或视觉输入的多模态代理？将有多少用户使用你的代理？你的延迟需求是什么？这些问题只是基本条件。
- en: Making these decisions effectively requires understanding how different models
    perform across several key dimensions. Some factors—like quality and accuracy—seem
    obvious, but others, like the relationship between context window size and cost,
    can catch teams off guard when they reach production scale.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有效做出这些决策需要了解不同模型在几个关键维度上的表现。一些因素——如质量和准确性——似乎很明显，但其他因素——如上下文窗口大小与成本之间的关系——当团队达到生产规模时可能会让他们措手不及。
- en: Core Performance Metrics
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心性能指标
- en: 'When it comes to AI agents, there’s a general trade-off between speed and reasoning
    agents’ output and reasoning. Many in the industry have started distinguishing
    between what they call “System 1” versus “System 2” thinking—borrowing theory
    of the human mind developed in the parallel domain of behavioral economics by
    Daniel Kahneman and Amos Tversky.^([1](ch03.html#id72)) System 1 processes are
    fast, automatic, and instinctual: the mental heuristics and quick judgments we
    use to navigate daily life without expending too much cognitive energy. System
    2 processes are deliberate and require conscious effort, the kind of rational
    deliberation and critical thinking we associate with complex problem solving.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到AI代理时，速度和推理代理的输出与推理之间存在一种普遍的权衡。许多行业人士已经开始区分他们所说的“系统1”与“系统2”思考——借鉴了丹尼尔·卡尼曼和阿莫斯·特沃斯基在行为经济学平行领域发展的人类心智理论。[1](ch03.html#id72)
    系统1的处理速度快、自动且本能：我们用来在日常生活中导航而不消耗太多认知能量的心理启发式和快速判断。系统2的处理是有意为之的，需要意识努力，这种理性思考和批判性思维与我们关联的复杂问题解决相联系。
- en: Quality and accuracy
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 质量和准确性
- en: 'In LLMs, techniques like chain-of-thought prompting essentially force the model
    into System 2 mode, where it reexamines its logic iteratively. This reasoning
    process can significantly improve accuracy and reliability, but it can come at
    a cost: more processing time and higher compute expenses. The trade-off is real—System
    2 thinking can deliver better results but costs more to run.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型语言模型（LLMs）中，像思维链提示这样的技术本质上迫使模型进入系统2模式，在该模式下，模型会迭代地重新审视其逻辑。这个推理过程可以显著提高准确性和可靠性，但可能会付出代价：更多的处理时间和更高的计算费用。这种权衡是真实的——系统2的思考可以带来更好的结果，但运行成本更高。
- en: The good news? Clever engineering strategies can sometimes recover most of the
    quality gains of chain-of-thought processing, with two to three times less latency
    or token usage.^([2](ch03.html#id73)) Techniques like early exit inference and
    speculative decoding are making it possible to get closer to System 2 quality
    without the full System 2 cost.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是？聪明的工程策略有时可以恢复思维链处理的大部分质量增益，同时将延迟或令牌使用量减少到原来的二到三倍。[2](ch03.html#id73) 技术如早期退出推理和推测解码使得在不完全付出系统2成本的情况下，更接近系统2的质量成为可能。
- en: Cost
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成本
- en: The most well-known LLMs (OpenAI’s GPTs, Claude’s Sonnet, Google’s Gemini) provide
    proprietary APIs for pay-as-you-go usage. Prices vary by model and are constantly
    being revised based on the market and the latest model, but do *not* let the cheap
    per-token cost of most models fool you. The average project usually requires the
    user to pass in the context of their code, writing, or documents to prime the
    model—accruing context windows in the hundreds of thousands—if not millions—of
    tokens *per day*. These costs can quickly add up. [Figure 3-3](#ch03_figure_3_1758256567876080)
    shows the cost per million tokens of 21 LLMs from some of the most popular providers.
    As the size and quality of the model increase, so too do the prices.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最知名的 LLM（OpenAI 的 GPTs、Claude 的 Sonnet、Google 的 Gemini）提供按需付费的专属 API。价格因模型而异，并且根据市场和最新模型不断修订，但**不要**让大多数模型按字符计价的低廉成本欺骗了你。平均项目通常需要用户传递他们的代码、写作或文档的上下文以启动模型——每天积累数百万甚至数千万的字符上下文。这些成本会迅速增加。[图
    3-3](#ch03_figure_3_1758256567876080) 展示了来自一些最受欢迎的提供商的 21 个 LLM 的每百万字符成本。随着模型规模和质量的增加，价格也随之上升。
- en: '![Bar chart comparing input and output token pricing for 21 AI models across
    Google, OpenAI, and Anthropic, illustrating higher costs with increased model
    quality.](assets/mmai_0303.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![条形图比较 Google、OpenAI 和 Anthropic 的 21 个 AI 模型的输入和输出字符定价，展示了随着模型质量提高成本增加的情况。](assets/mmai_0303.png)'
- en: Figure 3-3\. AI model pricing comparison
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. AI 模型定价比较
- en: In fact, there is a significant discrepancy between the cost of content you
    provide a model and the cost of content it provides you. Ingress costs among LLMs
    are relatively cheap, but the egress costs from the LLM back to you can be substantial.
    The more you ask the model to return, the more your costs will rise. So for those
    companies looking to position themselves as central to their product, it bears
    careful consideration of how much these models will be used and how much you can
    afford to spend.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你提供给模型的内容的成本和模型提供给你的内容的成本之间存在显著差异。LLM 之间的入口成本相对较低，但从 LLM 返回给你的出口成本可能相当高。你要求模型返回的内容越多，你的成本就会越高。因此，对于那些希望将自己定位为产品核心的公司，仔细考虑这些模型的使用程度以及你愿意花费多少是值得的。
- en: The Rise of the Multimodel Strategy
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模型策略的兴起
- en: 'As agentic systems become more complex, organizations and industry experts
    are increasingly abandoning a one-size-fits-all approach to model selection. Instead,
    a more sophisticated multimodel strategy is emerging as a best practice. This
    involves using a combination of different LLMs rather than sticking to a single
    LLM vendor. In this multimodel strategy, model selection is context dependent
    and optimized to the specific requirements of a particular task within a larger
    workflow:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随着代理系统变得更加复杂，组织和行业专家越来越放弃“一刀切”的模型选择方法。相反，一种更复杂的多模型策略正在成为最佳实践。这涉及到使用不同 LLM 的组合，而不是坚持使用单一
    LLM 供应商。在这个多模型策略中，模型选择取决于上下文，并针对更大工作流中特定任务的特定要求进行优化：
- en: Specialized roles for different models
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型的专用角色
- en: A common and effective pattern is to create a hierarchy of models. A highly
    capable but more expensive and potentially slower model, such as o3 Pro or Claude
    Opus 4, is used for the most complex cognitive tasks, such as high-level planning,
    complex reasoning, or decomposing a difficult problem into subtasks. Once the
    plan is formulated, the execution of the individual, more straightforward subtasks
    is delegated to a fleet of smaller, faster, and more cost-effective models, such
    as Claude Sonnet 4, Gemini Flash 2.5, or GPT-5 mini. This approach allows the
    system to achieve a balance between reasoning and cost-efficient execution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 常见且有效的一种模式是创建一个模型层级。一个功能强大但价格更高且可能运行速度更慢的模型，例如 o3 Pro 或 Claude Opus 4，用于最复杂的认知任务，如高级规划、复杂推理或把一个难题分解成子任务。一旦计划制定完成，更直接、更简单的子任务的执行就委托给一支由更小、更快、成本效益更高的模型组成的队伍，例如
    Claude Sonnet 4、Gemini Flash 2.5 或 GPT-5 mini。这种方法使得系统在推理和成本效益执行之间达到平衡。
- en: Scalable orchestration
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的编排
- en: For large enterprises deploying hundreds or even thousands of agents, relying
    on a single, powerful, monolithic model for every operation can be prohibitively
    expensive and difficult to scale. A more scalable architecture may involve using
    sparse models, such as mixture-of-experts (MoE) models like Mixtral, or orchestrating
    a large number of specialized lightweight agents. This allows the system to scale
    cost-effectively while maintaining high performance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部署数百甚至数千个代理的大型企业来说，依赖每个操作的单个强大、单一模型可能会非常昂贵且难以扩展。更可扩展的架构可能涉及使用稀疏模型，如Mixtral这样的专家混合（MoE）模型，或者编排大量专门轻量级代理。这允许系统以成本效益的方式扩展，同时保持高性能。
- en: A Framework for Empirical Evaluation
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实证评估框架
- en: In such a fast-changing industry, many look to industry benchmarks as useful
    signals for which models they should use. While public benchmarks such as these
    are a useful starting point for comparing models, they cannot guarantee how a
    model will perform on your specific project or proprietary use case. It is therefore
    essential for all agent and LLM developers and architects to develop their own
    domain-specific evaluation frameworks to test models against their unique data
    and requirements. Here’s how.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样一个快速变化的行业中，许多人将行业基准视为有用的信号，以确定他们应该使用哪些模型。虽然此类公共基准对于比较模型是一个有用的起点，但它们不能保证模型在你的特定项目或专有用例上的表现。因此，对于所有代理和LLM的开发者和架构师来说，开发他们自己的特定领域评估框架来测试模型与他们的独特数据和需求是至关重要的。以下是方法。
- en: Creating Use-Case-Specific Test Criteria
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建特定用例的测试标准
- en: 'The first step to developing an internal evaluation framework is to define
    clear, objective, and measurable criteria for what constitutes success for the
    agent’s task—after all, you cannot manage what you cannot measure. These evaluation
    criteria should go beyond simply checking for a single “right answer” and should
    instead assess the quality of the entire agentic process. Key areas for evaluation
    include:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 开发内部评估框架的第一步是为代理任务的成功定义清晰、客观和可衡量的标准——毕竟，你不能管理你不能衡量的东西。这些评估标准应超越仅仅检查单个“正确答案”，而应评估整个代理过程的整体质量。评估的关键领域包括：
- en: Task completion
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 任务完成
- en: 'The most fundamental metric: did the agent successfully achieve its high-level
    goal? Specifically, did a piece of substantive work get completed in a timely
    and relatively correct manner?'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的指标：代理是否成功实现了其高级目标？具体来说，是否有实质性工作按时并以相对正确的方式完成？
- en: Tool correctness and efficiency
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 工具的正确性和效率
- en: Did the agent select the correct tools for the job? Did it invoke them with
    the correct parameters? Was the tool usage efficient, or were there redundant
    or unnecessary calls?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是否选择了正确的工具来完成工作？它是否以正确的参数调用了它们？工具的使用是否高效，或者是否存在冗余或不必要的调用？
- en: Reasoning coherence and relevance
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 推理的连贯性和相关性
- en: Was the agent’s internal chain of thought logical? Did its reasoning steps directly
    contribute to solving the problem, or were they irrelevant?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的内部思维链是否逻辑清晰？其推理步骤是否直接有助于解决问题，或者它们是否无关紧要？
- en: The “LLM-as-a-Judge” Methodology
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “LLM作为裁判”的方法论
- en: 'Take it from a practitioner: evaluating thousands of agent outputs is impractical
    and does not scale. A powerful technique that has emerged to address this challenge
    is the “LLM-as-a-judge” approach. This method involves using a powerful, state-of-the-art
    LLM to act as an impartial evaluator. The judge LLM is given the agent’s output,
    the original prompt, a set of ground-truth data, and a detailed evaluation rubric
    or scoring template. It is then prompted to assess the agent’s performance against
    the defined criteria and provide a score and a qualitative explanation for its
    judgment. To improve the reliability of this method, it is common to use advanced
    prompting techniques like chain-of-thought prompting, which instructs the judge
    LLM to think step-by-step through its evaluation, making its reasoning more transparent
    and less prone to random variability. This methodology enables the scalable, repeatable,
    and nuanced evaluation of agent performance, although it requires careful prompt
    engineering and awareness of potential biases in the judge model itself.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从实践者的角度来说：评估数千个代理的输出是不切实际的，并且无法扩展。为了应对这一挑战，出现了一种强大的技术，即“LLM作为裁判”的方法。这种方法涉及使用一个强大、最先进的LLM来充当一个公正的评估者。裁判LLM被提供代理的输出、原始提示、一组事实数据以及一个详细的评估标准或评分模板。然后，它被提示根据定义的标准评估代理的表现，并为它的判断提供分数和定性解释。为了提高这种方法的可信度，通常使用高级提示技术，如思维链提示，它指导裁判LLM逐步思考其评估，使其推理更加透明，并减少随机变异性。这种方法使得对代理性能的评估具有可扩展性、可重复性和细微差别，尽管它需要仔细的提示工程和对裁判模型自身潜在偏差的认识。
- en: ^([1](ch03.html#id72-marker)) Daniel Kahneman, *Thinking, Fast and Slow* (Farrar,
    Straus, and Giroux, 2011).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#id72-marker)) Daniel Kahneman, *Thinking, Fast and Slow* (Farrar,
    Straus, and Giroux, 2011).
- en: '^([2](ch03.html#id73-marker)) Yaniv Leviathan, Matan Kalman, and Yossi Matias,
    “Fast Inference from Transformers via Speculative Decoding,” in *Proceedings of
    the 40th International Conference on Machine Learning*, PMLR 202, 2023; Mostafa
    Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen
    Lai, et al., “LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding,”
    in *Proceedings of the 62nd Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), 12622–12642*, 2024.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '^([2](ch03.html#id73-marker)) Yaniv Leviathan, Matan Kalman, and Yossi Matias,
    “Fast Inference from Transformers via Speculative Decoding,” in *Proceedings of
    the 40th International Conference on Machine Learning*, PMLR 202, 2023; Mostafa
    Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen
    Lai, et al., “LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding,”
    in *Proceedings of the 62nd Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), 12622–12642*, 2024.'
