- en: Chapter 1\. AI in the Tableau Platform
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. Tableau平台中的AI
- en: 'Artificial intelligence isn’t new. It’s been around since the famous mathematician
    Alan Turing first asked, “Can machines think?” in his well known 1950 paper “Computing
    Machinery and Intelligence.” AI was formalized into an academic area for research,
    study, and innovation (according to many academics and historians in the field)
    in 1956\. In the beginning, we can imagine that the goals of AI were to replicate
    or emulate human intelligence and decision making. This may have been best stated
    by computer scientist John McCarthy, who coined the term *artificial intelligence*:
    “Every aspect of learning or any other feature of intelligence can in principle
    be so precisely described that a machine can be made to simulate it.” Many would
    add that computers could (in theory and now in practice) handle complex operations—sometimes
    much more complex (particularly mathematical ones) than humans could.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能并不新鲜。它自著名的数学家艾伦·图灵在他的著名论文“计算机机械与智能”中首次提出“机器能思考吗？”的问题以来就已经存在。根据许多该领域学者和历史学家的说法，人工智能在1956年被正式确立为一个研究领域，用于研究、学习和创新。最初，我们可以想象，人工智能的目标是复制或模拟人类的智能和决策。这一点可能最好由计算机科学家约翰·麦卡锡提出，他创造了“人工智能”这个术语：“学习的每一个方面或任何其他智能特征都可以在原则上被精确描述，以至于可以制造出模拟它的机器。”许多人还会补充说，计算机可以（理论上现在实际上）处理复杂的操作——有时比人类能处理的更复杂（尤其是数学上的）。
- en: Since that time, AI has slowly woven itself into every area of our lives. The
    idea of being bested by a computer at chess is nothing new. In fact, AI’s place
    in any sort of strategic game now feels common and expected. More recent and prolific
    applications of AI would include recommendation engines, such as those determining
    what to watch next on Netflix or what to buy on Amazon. Voice assistants like
    Apple’s Siri that can translate your speech into some type of action also qualify
    as AI. And then there are self-driving vehicles like Google’s Waymo that take
    the idea of *autopilot*, a concept that’s been around for roughly 100 years, to
    a brand-new paradigm.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从那时起，人工智能逐渐融入了我们生活的各个领域。在棋类游戏中被计算机击败的想法并不新鲜。事实上，现在人工智能在任何战略游戏中的位置都显得司空见惯和预期。最近和更广泛的应用包括推荐引擎，比如那些决定你在Netflix上接下来要看什么或是在Amazon上要买什么。像苹果的Siri这样的语音助手，可以将你的语音翻译成某种行动，也属于人工智能的范畴。还有像谷歌的Waymo这样的自动驾驶汽车，将*自动驾驶*这一概念，一个大约存在了100年的概念，推向了一个全新的范式。
- en: So much of AI has depended on the capabilities of computers. Early computers
    were limited in the information and knowledge that they could hold. And similarly,
    even if they had access to the knowledge, the computational and processing power
    necessary to access, retrieve, and serve up that information was massive. But
    in the early 2000s, the pace of innovation with computer hardware caught up with
    the needs of AI. Multiple processors and multithreading proliferated, smartphones
    became prominent fixtures in our everyday lives, and cloud computing became the
    new normal.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的许多方面都依赖于计算机的能力。早期的计算机在所能承载的信息和知识方面有限。同样，即使它们能够接触到这些知识，访问、检索和提供这些信息的必要计算和处理能力也是巨大的。但在2000年代初，计算机硬件的创新步伐赶上了人工智能的需求。多处理器和多线程技术得到了广泛的应用，智能手机成为了我们日常生活中突出的设备，云计算也成为了新的常态。
- en: AI in Analytics
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析学中的AI
- en: As advancements in computer hardware became more prominent, the domain of analytics
    started to see its own advancements. In particular, this meant the inclusion of
    more advanced methods of mathematical analysis. *Multivariate analysis* became
    more pervasive in business applications as more knowledge workers could lean on
    computers to help with the complex mathematical computations. *Predictive analytics*
    and the ways in which something could be predicted expanded from the simple linear
    regression model of old to much more robust and sophisticated methods. Classification
    methods, like *k-means clustering* (available in Tableau) were possible. Machine
    learning (ML), both *supervised*, where the input and output are provided to the
    model, and *unsupervised*, where models are given the freedom to derive their
    own patterns, came into prominence. A computer could now be given a massive amount
    of data and draw conclusions with varying levels of aid and decision input from
    humans.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 随着计算机硬件的进步变得更加显著，分析领域也开始看到自己的进步。特别是，这意味着数学分析方法的引入。**多元分析**在商业应用中变得更加普遍，因为更多的知识工作者可以依赖计算机来帮助进行复杂的数学计算。**预测分析**以及预测事物的方式从旧式的简单线性回归模型扩展到更加稳健和复杂的方法。分类方法，如（在Tableau中可用的）**k-means聚类**成为可能。机器学习（ML），无论是**监督学习**，其中模型提供了输入和输出，还是**无监督学习**，其中模型被赋予自由以推导出自己的模式，都变得突出。现在，计算机可以给出大量数据，并在不同程度上从人类获得帮助和决策输入的情况下得出结论。
- en: Then came *natural language processing* (NLP). As mentioned in the Preface,
    Ask Data was released by Tableau in 2018, allowing users to ask a question and
    get an answer, but speech recognition and transcription tools have been living
    in the business world for much longer. *Sentiment analysis*—or the process of
    scoring language to determine whether it is positive, negative, or neutral—started
    becoming mainstream. Computer languages like Python and R became prominent, and
    the practice of data science and the emergence of the data scientist reached a
    fever pitch in the 2010s, along with the term *big data*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 然后出现了**自然语言处理**（NLP）。如前言所述，Tableau于2018年发布了Ask Data，使用户能够提出问题并获得答案，但语音识别和转录工具在商业世界中已经存在了很长时间。**情感分析**——或对语言进行评分以确定其是正面、负面还是中性的过程——开始变得主流。Python和R等计算机语言变得突出，数据科学实践和数据科学家的出现也在2010年代达到了高潮，同时“大数据”这一术语也应运而生。
- en: 2018 also heralded the first *generative pre-trained transformer* (GPT) technologies,
    a type of *large language model* (LLM), by OpenAI, the company that soon became
    known for its famous ChatGPT chatbot, capable of having coherent and improvised
    conversations with humans, and its generative digital art tool DALL-E. I was introduced
    to both technologies in 2022\. I signed up for the early invitation-only beta
    of DALL-E and loved creating digital art that would have been previously out of
    my own reach (like melting bar charts in the style of Salvador Dali, and Darth
    Vader walking Princess Leia down the aisle as a heartfelt watercolor vignette
    (see [Figure 1-1](#ch01_figure_1_1732595607196098)). AI-generated sonnets, poems,
    parodies, and rote business communications started popping up as novelties at
    my workplace. My then-boss jokingly posted his ChatGPT-created professional biography
    which included glowing praise of who he was but was also littered with inaccuracies
    and accolades that he had never received. Generative and creative AI had officially
    arrived.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年也标志着OpenAI首次推出了**生成预训练转换器**（GPT）技术，这是一种**大型语言模型**（LLM），该公司很快因其著名的ChatGPT聊天机器人而闻名，该机器人能够与人类进行连贯和即兴对话，以及其生成式数字艺术工具DALL-E。我在2022年接触到了这两种技术。我注册了DALL-E的早期邀请制测试版，并喜欢创作那些以前无法触及的数字艺术（如以萨尔瓦多·达利的风格融化的条形图，以及达斯·维达带着心水的水彩画风格将公主莉娅引向红毯的场景（见图1-1））。AI生成的十四行诗、诗歌、讽刺作品和刻板的商业通讯开始在我的工作场所作为新奇事物出现。我的当时老板开玩笑地发布了由ChatGPT创建的专业传记，其中包含了对他的高度赞扬，但也充斥着他从未获得的不准确赞誉和荣誉。生成式和创意AI正式到来。
- en: '![](assets/lait_0101.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/lait_0101.png)'
- en: Figure 1-1\. AI-generated art created using DALL-E (left) and MidJourney (right)
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 使用DALL-E（左）和MidJourney（右）生成的AI艺术
- en: The technology and structure underpinning LLMs and GPTs are in full use in both
    Tableau Pulse and Tableau Agent, the focal points of this book. Both rely heavily
    on LLMs. In Pulse, an LLM is used to summarize the insights and serve them up
    in a meaningful way. With Tableau Agent, you get direct interaction and results
    based on your input into a chat box. This is a very privileged position for technology
    to have in our domain, and as such, it’s important for analytics professionals
    to understand how AI technology works as much as possible. Referring to generative
    AI as opaque or enigmatic technology isn’t acceptable when you’re serving up information
    to end users to make business-critical and sometimes life-or-death decisions based
    on data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 支撑 LLMs 和 GPTs 的技术和结构在 Tableau Pulse 和 Tableau Agent 中得到了充分的应用，这两者是本书的重点。两者都高度依赖于
    LLMs。在 Pulse 中，LLM 用于总结洞察并以有意义的方式提供。使用 Tableau Agent，你可以根据在聊天框中的输入直接交互并获得结果。在我们这个领域，技术拥有这样的特权地位，因此，对于分析专业人士来说，尽可能多地了解
    AI 技术的工作原理是非常重要的。当你在向最终用户提供信息，基于数据做出业务关键甚至生死攸关的决定时，将生成式 AI 称为不透明或神秘的技术是不可接受的。
- en: Generative AI Explained
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式 AI 解释
- en: A good way to think about how LLMs and GPTs function is to start by thinking
    about words as a set of coordinates, called *word vectors*. Similar to latitude
    and longitude, imagine that each word has an elaborate set of coordinates determining
    where it is located in the universe of words. Unlike the confines of the three
    dimensions that we experience in the physical world, each word in the universe
    of words has a very large number of dimensions (300+). Moreover, each word can
    be represented multiple times in the universe based on what it represents. Good
    examples of this are *homonyms*, words that are spelled the same but have different
    meanings, like the word *hide*, which can mean an animal skin pelt and can also
    mean to position something out of sight. It’s easy to imagine that there are two
    separate coordinates for these two concepts, just as there are (at least) two
    definitions of *hide* in a dictionary.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要思考 LLMs 和 GPTs 如何工作，一个好的方法是首先将单词视为一组坐标，称为 *词向量*。类似于经纬度，想象每个单词都有一个复杂的坐标系统，决定了它在单词宇宙中的位置。与我们在物理世界中体验到的三维限制不同，单词宇宙中的每个单词都有非常多的维度（300+）。此外，每个单词可以根据其表示的内容在宇宙中多次表示。这种情况的良好例子是
    *同音异义词*，即拼写相同但含义不同的单词，比如单词 *hide*，它可以指动物皮毛，也可以指将某物放置在看不见的地方。很容易想象这两个概念有两个独立的坐标，就像字典中至少有两个关于
    *hide* 的定义一样。
- en: 'LLMs are trained on copious amounts of text, called *training data**,* which
    they go through to systematically assign coordinates to each word in the universe.
    Those coordinates have a natural proximity to other words that are closely related,
    and you can further imagine that those coordinates can shift slightly with each
    additional new passage of text received. Eventually, from a mathematical angle,
    there are diminishing returns on this—similar to limits in calculus: as you approach
    infinity, the coordinate of a word eventually settles at a final location within
    the word universe.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 在大量的文本上训练，称为 *训练数据*，它们通过系统地为单词宇宙中的每个单词分配坐标。这些坐标与密切相关单词的自然邻近性，你可以进一步想象这些坐标可以随着接收到的每个新增文本段落而略微移动。最终，从数学的角度来看，这种回报是递减的——类似于微积分中的极限：当你接近无穷大时，单词的坐标最终会在单词宇宙中的某个最终位置稳定下来。
- en: Alongside the coordinates of words is the GPT, or transformer, process of the
    model. I like to explain this process in terms of *layers*. These layers (for
    example, GPT-3 from OpenAI has 96 layers) go through the text input called a *prompt*
    it receives, categorizes the words within the prompt, and eventually aims at comprehending
    it. All of this is somewhat opaque, because humans haven’t dictated to the models
    at which layer different actions should be taken. From what has been observed,
    it appears that most models start by understanding the sentence syntax and role
    (noun/verb/adjective/pronoun) each word takes on. After those initial layers are
    done, more contextual layers process the prompt. I try to think of this as what
    humans innately and effortlessly do. When you start reading a book, you get a
    grounding in the words, and eventually, once you’ve read enough, your brain starts
    imagining the whole scene. [Figure 1-2](#ch01_figure_2_1732595607196141) demonstrates
    how an LLM may process a simple sentence through the transformer layers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在单词的坐标旁边是 GPT 或转换器模型的处理过程。我倾向于用 *层* 来解释这个过程。这些层（例如，OpenAI 的 GPT-3 有 96 层）会处理接收到的文本输入，称为
    *提示*，对提示中的单词进行分类，并最终试图理解它。所有这些都有点不透明，因为人类并没有指示模型在哪个层应该采取不同的行动。从观察到的结果来看，大多数模型首先通过理解句子的语法和每个单词的角色（名词/动词/形容词/代词）来开始。在最初的这些层完成之后，更多的上下文层会处理提示。我试图将这个过程想象成人类天生且毫不费力就能做到的事情。当你开始阅读一本书时，你会对单词有一个基础的了解，最终，一旦你读得足够多，你的大脑开始想象整个场景。[图
    1-2](#ch01_figure_2_1732595607196141) 展示了 LLM 可能如何通过转换器层处理一个简单的句子。
- en: '![](assets/lait_0102.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/lait_0102.png)'
- en: Figure 1-2\. An example of how an LLM processes a sentence
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 一个示例，展示了如何处理一个句子
- en: 'After the prompt is processed comes the heart of the model’s generation: a
    prediction of what should come next. Again, this is not unlike what humans might
    also innately do on their own. If someone asks you what your favorite ice-cream
    flavor is, at the very least you are limited by the list of flavors you are aware
    of (possible predictions). In addition to that list, you rely on your own experiences
    with each of these flavors, and that eventually leads you to a single answer.
    Maybe it’s hard to land on one flavor, or you might be mentally scoring each flavor
    to get to a result. Maybe vanilla is your favorite “safe” flavor because it’s
    hard to get vanilla wrong, but you experience more pleasure and delight when eating
    mint chocolate chip. Maybe Ben and Jerry’s Cherry Garcia is your guilty pleasure,
    but not every ice-cream parlor has that on the menu. It is possible to answer
    the question differently depending entirely on the question’s *context*: who is
    asking, your recent ice-cream experiences, where you are, what you are craving.
    The models resolve this by relying on interpreting the context of the prompt and
    what they have learned from the training data. And it’s important to say, the
    model’s training data is far beyond the scope of what any one human knows, so
    it quite often has a very broad understanding of the possible answers.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理提示之后，模型生成的核心是预测接下来应该发生什么。这也不像人类可能天生就会做的事情。如果有人问你最喜欢的冰淇淋口味是什么，至少你受限于你所知道的口味列表（可能的预测）。除了这个列表，你还依赖于自己对每种口味的个人体验，这最终会引导你得出一个答案。可能很难确定一个口味，或者你可能会在心理上对每种口味进行评分以得出结果。可能香草是你的“安全”口味，因为很难出错，但当你吃薄荷巧克力碎片时，你可能会体验到更多的愉悦和快乐。可能
    Ben and Jerry 的 Cherry Garcia 是你的“罪恶的乐趣”，但不是每个冰淇淋店都有这个口味。根据问题的 *上下文* 不同，回答问题的方式也可能不同：是谁在问，你最近的冰淇淋体验，你在哪里，你渴望什么。模型通过依赖解释提示的上下文以及从训练数据中学到的知识来解决这个问题。重要的是要说明，模型的训练数据远远超出了任何一个人所知道的范畴，因此它通常对可能的答案有非常广泛的理解。
- en: Remember, the whole act of processing the syntax and sentence structure of the
    prompt through comprehension and context is completely dependent on the information
    the model has on hand. The predictions it is able to generate are from the information
    it’s been given, which has been presented in sentences written by humans. So in
    particular, when we apply LLMs to a narrow field like coding or analytics, the
    model is relying entirely on what humans have already done. This isn’t to say
    that there aren’t original outputs (dare I say thoughts) or creativity in the
    process. In fact, one of the reasons I like generative AI for creating art is
    that it is not bounded by practicality. DALL-E may generate beautiful images that
    include an extra hand or misspelled word, because the prediction model has resolved
    to output the “best result.” A human artist would never paint an extra limb unless
    it was highly intentional, even if it better conveyed the idea behind the overall
    piece of art.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，整个通过理解和上下文处理提示语中的语法和句子结构的行为完全依赖于模型手头的信息。它能生成的预测来自它所接受的信息，这些信息是以人类书写的句子形式呈现的。所以，当我们把LLMs应用于像编码或分析这样的狭窄领域时，模型完全依赖于人类已经完成的工作。这并不是说在这个过程中没有原创的输出（我敢说思想）或创造力。事实上，我喜欢生成式AI用于创作艺术的原因之一是它不受实用性的限制。DALL-E可能会生成包含额外一只手或拼写错误的美丽图像，因为预测模型已经决定输出“最佳结果”。一个人类艺术家永远不会画上额外的肢体，除非这是高度故意的，即使这样能更好地传达整体艺术作品背后的想法。
- en: Given how LLMs function, we must treat their prediction method as a double-edged
    sword. It can be contaminated by human bias innate in the text, limited by the
    information it has been given, and may predict an output that is nonsensical or
    factually inaccurate. It may also provide answers or results that are uniquely
    different from what a human (or meticulously crafted algorithm) completing the
    same task may produce.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLMs的工作方式，我们必须将它们的预测方法视为一把双刃剑。它可能受到文本中固有的人类偏差的污染，受到它所提供信息的限制，并可能预测出无意义或事实不准确的结果。它还可能提供与人类（或精心设计的算法）完成相同任务可能产生的答案或结果截然不同的答案。
- en: Risks and Considerations with AI
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与AI相关的风险和考虑因素
- en: 'There are three big areas of risk and consideration I want to discuss:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要讨论的三个主要风险和考虑因素是：
- en: Model bias
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型偏差
- en: Model hallucination
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型幻觉
- en: Worker displacement
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工人失业
- en: It’s important to discuss these because they will inevitably come up on your
    organization’s journey to include generative AI tools in your analytics practice.
    Knowing what these issues are up front arms you with the knowledge your organization
    needs to make responsible and informed decisions about these tools.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论这些问题很重要，因为它们不可避免地会在你组织将生成式AI工具纳入分析实践的过程中出现。提前了解这些问题，可以让你组织拥有做出负责任和明智决策所需的知识。
- en: Model Bias
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型偏差
- en: 'You’ve already learned that a model can be biased based on the information
    it has been trained on or has access to. But a model can also be biased based
    on how the algorithm was designed. A relatively easy example to understand is
    an algorithm that has been tuned to over-rely on information that shows up frequently
    or more recently. When that is applied to the question *Who is the most popular
    singer?*, the result might be *Taylor Swift* based on the success of her recent
    *Eras* tour and how often her music is requested and served up. But looking at
    the question over a longer span of time could surface a different answer: *Frank
    Sinatra*, who released an astounding 59 studio albums over his 50+ year career.
    You can imagine how that question gets murkier when you’re applying it directly
    to data or statistical information. The question *What has caused the decline
    in sales?* (after looking at a chart of trending sales values) could yield different
    answers based on whether the model considers only the data points observed in
    the chart or has access to the entire history of sales.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解到，模型可以根据其训练或访问的信息存在偏差。但模型也可以根据算法的设计存在偏差。一个相对容易理解的例子是，一个被调整过度依赖频繁出现或最近出现的信息的算法。当应用于“谁是最受欢迎的歌手？”这个问题时，结果可能是“泰勒·斯威夫特”，基于她最近的“时代”巡回演出和她的音乐被请求和播放的频率。但从一个更长的时间跨度来看，可能会出现不同的答案：“弗兰克·辛纳特拉”，他在50多年的职业生涯中发行了惊人的59张录音室专辑。你可以想象，当你直接将这个问题应用于数据或统计信息时，这个问题会变得多么复杂。查看趋势销售价值图表后，关于“什么导致了销售额的下降？”的问题（查看趋势销售价值图表后）可能会根据模型是否只考虑图表中观察到的数据点，还是可以访问整个销售历史而得出不同的答案。
- en: User interaction is another tricky part which will naturally influence what
    the model produces. If the model knows that you are the manager of the electronics
    department or if you’ve asked many questions that tilt toward electronics, it
    will likely produce an output more directly related to electronics. This could
    produce an answer that is accurate, but perhaps not the largest or most direct
    root cause of the example question *What has caused the decline in sales?* I often
    see this unfold in my own interactions with ChatGPT, where I’ll ask for something
    in a list format, and from then on it has trouble breaking out of a pattern of
    listing items, even if my follow-up requests aren’t best resolved with lists.
    ChatGPT also tends to use similar language or structure to what I am providing,
    which, again, seems logical (we humans often tend to adopt the same words and
    style of those around us) but works against getting an unbiased response.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 用户交互是另一个棘手的部分，它自然会影响到模型产生的结果。如果模型知道你是电子部门的经理，或者你提出了很多倾向于电子的问题，它很可能会产生与电子更直接相关的输出。这可能会产生一个准确的答案，但可能不是例子问题“是什么导致了销售额的下降？”的最主要或最直接的根本原因。我经常在我的ChatGPT交互中看到这种情况，我会以列表的形式提出要求，然后它就难以跳出列表项的模式，即使我的后续请求并不适合用列表来最好地解决。ChatGPT也倾向于使用与我提供的内容相似的语言或结构，这再次看起来合乎逻辑（我们人类往往倾向于采用周围人的相同词汇和风格），但这对获得无偏见的回答是起反作用的。
- en: Finally, there are social prejudices, stereotypes, and representation biases
    to contend with. These can appear by a model parroting back the most popular prejudices
    that have woven their way into the body of human knowledge. A fairly benign example
    is the word *nurse*. When you read that word, your mental image of a nurse is
    likely a woman. But you could extrapolate that act out to something more analytically
    oriented. For example, you seek help in creating a formula to predict how sales
    will perform, and the model defaults to recommending a linear regression because
    of its popularity in analytics. In a nonharmful way, the model may simply be providing
    the most common way to address your data. However, the model’s response could
    also be negating a more sound and reasoned method that would be more appropriate
    for addressing your data, leaving you with a method that may not be the right
    fit for your situation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有社会偏见、刻板印象和代表性偏见需要应对。这些偏见可能通过模型重复最流行的偏见来出现，这些偏见已经渗透到人类知识的体系中。一个相对无害的例子是单词“护士”。当你读到这个词时，你脑海中护士的形象可能是一个女性。但你可以将这个行为扩展到更具有分析性的方向。例如，你寻求帮助创建一个预测销售表现的公式，模型默认推荐线性回归，因为它在分析中的流行。以无害的方式，模型可能只是提供了处理你的数据最常见的方法。然而，模型的回答也可能否定一个更合理和有理的方法，这个方法可能更适合处理你的数据，让你得到的可能不是最适合你情况的方法。
- en: Model Hallucination
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型幻觉
- en: '*Model hallucination* is a model’s return of a result that is not factually
    accurate or not grounded in reality. The example of the extra limb added to a
    generated image of a human figure mentioned earlier comes to mind, or fake legal
    cases used as supporting evidence in a new defense, or the production of seemingly
    valid numerical facts that are totally made up. All these possibilities can be
    generated by models, and they are especially dangerous when the task at hand is
    to use underlying supporting data as evidence to draw a conclusion. This is true
    particularly in data analytics, where there isn’t one defining fact or figure
    that can accurately capture the nuance and complexity of reality.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型幻觉*是指模型返回一个不准确或不基于现实的结果。前面提到的给生成的人类形象图像添加额外肢体的情况，或者在新辩护中用作支持证据的虚假法律案例，或者生产看似有效的、完全虚构的数值事实，都是这样的例子。所有这些可能性都可以由模型生成，当任务是用基础支持数据作为证据来得出结论时，这些可能性尤其危险。这在数据分析中尤其如此，因为没有一个定义性的事实或数字可以准确地捕捉现实的微妙和复杂性。'
- en: You can see model hallucination play out when you ask AI to explain how it arrived
    at an answer. Since the whole model is opaque technology that provides predictions,
    the sound reasoning that you may be familiar with receiving from a human is typically
    not available. You can also see model hallucinations and limitations when it outputs
    what you know to be a wrong answer and you try to coax the AI into arriving at
    the right answer. [Figure 1-3](#ch01_figure_3_1732595607196167) shows a conversation
    I recently had with ChatGPT about the popular TV show *Survivor* and the phrase
    its host uses at challenges. In this exchange, the model initially provides a
    factually incorrect answer, including the word “guys” at the end of the phrase.
    Only after redirecting the model to consider more information, like that it was
    updated in a recent season, does it return the factually accurate answer. This
    isn’t hard to imagine, since there were 40 seasons of Survivor where “guys” was
    part of the phrasing, likely influencing the model more heavily to include the
    word “guys” and ignoring more recent history.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当你要求AI解释它是如何得出答案的时候，你可以看到模型幻觉是如何发生的。由于整个模型是一个提供预测的透明技术，你可能会从人类那里收到的合理推理通常是不存在的。你还可以看到当它输出一个你知道是错误的答案，而你试图引导AI得出正确答案时，模型幻觉和局限性。![图1-3](#ch01_figure_3_1732595607196167)展示了我与ChatGPT最近关于热门电视节目*Survivor*及其主持人用于挑战的短语的一次对话。在这个交流中，模型最初提供了一个事实错误答案，包括短语末尾的“guys”一词。只有当将模型重新引导以考虑更多信息，例如它在最近一季中进行了更新，它才会返回事实准确答案。这并不难想象，因为Survivor有40季，其中“guys”是短语的一部分，可能对模型产生更强烈的影响，而忽略了更近的历史。
- en: '![](assets/lait_0103.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![assets/lait_0103.png]'
- en: Figure 1-3\. A discussion with ChatGPT about Jeff Probst
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 与ChatGPT关于杰夫·普罗布斯特的讨论
- en: Since the hallucination phenomenon tends to be more prominent in ambiguous situations—when
    the question itself may be unclear, the training data is insufficient, or extrapolation
    is required—it’s crucial to remain skeptical. These scenarios are common in the
    world of analytics, where understanding the reasoning behind insights is essential.
    Historically, human experience and intuition have been key to overcoming these
    challenges—an ability AI lacks, making it harder to fully trust its conclusions
    without deeper scrutiny.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于幻觉现象往往在模糊的情况下更为突出——当问题本身可能不清楚、训练数据不足或需要外推时——保持怀疑态度至关重要。这些场景在数据分析领域很常见，其中理解洞察背后的推理是至关重要的。从历史上看，人类经验和直觉是克服这些挑战的关键——这是AI所缺乏的，这使得在没有更深入审查的情况下完全信任其结论变得更加困难。
- en: Worker Displacement
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作岗位流失
- en: AI holds the promise, danger, and fear of displacing humans who are doing the
    work. In data analytics, there is a very real sense that if an end user can interact
    directly with AI to get the analytics and insights they need, the utility of the
    analytics professional is displaced. It can be frightening to consider what your
    actual job is if the AI can—with a few simple text commands—do tasks like building
    charts, curating data sets, or constructing complex queries that have been your
    full-time job. One of AI’s major marketing pitches is that AI will improve efficiency,
    but *improved efficiency* almost always means that someone will be made redundant
    in the process.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: AI承载着取代从事工作的人类的承诺、危险和恐惧。在数据分析领域，有一种非常真实的感受，即如果最终用户可以直接与AI互动以获取他们需要的分析和洞察，那么数据分析专业人士的效用就会被取代。如果AI可以通过几个简单的文本命令来完成像构建图表、整理数据集或构建复杂查询这样的任务，那么考虑你的实际工作可能会令人恐惧。AI的主要营销卖点之一是它将提高效率，但*提高效率*几乎总是意味着在这个过程中有人会被淘汰。
- en: Although the prospect of AI taking away jobs may seem scary and inevitable,
    this is an area where data professionals must be loud advocates and have confidence
    in the body of work they have produced. The charge of data analytics hasn’t changed.
    The analyst’s responsibility and purpose have always been to ensure that the analytics
    being produced can be trusted and is useful. If anything, that purpose becomes
    much more necessary when computers start doing the work unsupervised.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然AI夺取工作的前景可能看起来令人恐惧且不可避免，但这是数据专业人士必须大声呼吁并对其所做的工作充满信心的领域。数据分析的任务并没有改变。分析师的责任和目的始终是确保产生的分析是可以信赖的并且是有用的。如果有什么不同的话，当计算机开始无监督地工作时，这种目的变得更加必要。
- en: The tasks of data analytics can and will change with this shift. But remember
    that new tasks will usher in new jobs and responsibilities, much like the story
    I shared with you in the Preface of how improvements to Tableau Desktop’s connectivity
    to multiple databases changed my requests from standalone data sets to requests
    for direct access to databases. It is still the responsibility of the data professional
    to manage the analytics, manage the access, manage the information produced, and
    manage the data products that are available to audiences. And in an applied situation,
    such as when Tableau Agent starts producing charts automatically, the analyst
    must still ensure that the chart constructed is accurate. The learned human skills
    and knowledge to make that discernment don’t disappear over time; they become
    even more mission critical.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这种转变，数据分析的任务可以并且将会发生变化。但请记住，新任务将带来新的工作和责任，就像我在前言中分享的故事一样，Tableau Desktop连接到多个数据库的改进改变了我对独立数据集的需求，转而要求直接访问数据库。数据专业人士仍然负责管理分析、管理访问、管理产生的信息以及管理提供给受众的数据产品。在应用场景中，例如当Tableau
    Agent开始自动生成图表时，分析师仍然必须确保构建的图表是准确的。用于做出这种区分的学习人类技能和知识不会随着时间的推移而消失；它们变得更加关键。
- en: Finally, a reverse force is working in humans’ favor. One of the most often-heard
    soundbites in data analytics is how many people are *underserved* with data and
    analytics. A disparity exists between the massive amounts of data being collected
    and the availability and comprehension of said data to workers. So if anything,
    it would be sound to reason that the audiences for data analytics are bound to
    grow as tools for easier access become available to them. And if you’re a true
    zealot like me, obsessed with democratizing availability of data for decision
    making, it is an exciting time to be the sherpa of this practice to a broader
    group of people.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一种反向力量正在为人类谋福利。在数据分析中最常听到的观点之一是，有多少人*没有得到充分服务*。在收集的大量数据和工人的数据可用性和理解之间存在差距。因此，如果有什么的话，可以合理地认为，随着更容易访问的工具变得可用，数据分析的受众必然会增加。如果你像我一样是一个真正的狂热者，痴迷于民主化决策数据可用性，那么对更广泛的人群来说，成为这一实践的保护者是一个激动人心的时刻。
- en: Trusting AI
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信任AI
- en: This discussion of the risks associated with LLMs and generative AI leads naturally
    to a discussion of how Tableau and Salesforce handle trust and risk mitigation.
    The primary arbiter of trust with these technologies is called the *Einstein Trust
    Layer*. You can consider this layer as an intermediary between your enterprise
    data and the LLM models (at the time of writing, Tableau uses OpenAI’s GPT-3.5
    Turbo) that generate summaries and respond to your prompts/queries. [Figure 1-4](#ch01_figure_4_1732595607196190)
    shows the relationships among Tableau Cloud, the Einstein Trust Layer, and LLM
    models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 关于与LLMs和生成式AI相关的风险的讨论自然引出了Tableau和Salesforce如何处理信任和风险缓解的讨论。这些技术的信任主要仲裁者被称为*爱因斯坦信任层*。你可以将这一层视为介于你的企业数据和生成摘要并响应你的提示/查询的LLM模型（截至写作时，Tableau使用OpenAI的GPT-3.5
    Turbo）之间的中介。![图1-4](#ch01_figure_4_1732595607196190)展示了Tableau Cloud、爱因斯坦信任层和LLM模型之间的关系。
- en: '![](assets/lait_0104.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![assets/lait_0104.png]'
- en: Figure 1-4\. The relationships among Tableau Cloud, Einstein Trust Layer, and
    LLMs
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4. Tableau Cloud、爱因斯坦信任层和LLMs之间的关系
- en: 'The key components of the Einstein Trust Layer include the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 爱因斯坦信任层的关键组件包括以下内容：
- en: Secure data retrieval
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 安全数据检索
- en: Access controls and permissions are built into the Tableau platform. These controls
    are managed by administrators and creators and dictate who has access to data
    sources, dashboards, and Pulse metrics. During the process of interacting with
    AI, these controls are checked and verified prior to generating a response or
    serving up an insight.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制和权限内置在Tableau平台中。这些控制由管理员和创建者管理，并规定谁可以访问数据源、仪表板和Pulse指标。在与AI交互的过程中，这些控制在生成响应或提供见解之前会进行检查和验证。
- en: Dynamic grounding
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 动态基础
- en: The LLMs are enriched with context related to your business. Additionally, when
    Pulse metrics are served up, templates are used as guidelines for the prompt response.
    This process includes very clear instructions to the LLM model on not guessing,
    using neutral language, and handling the numerical values it receives. It also
    gives clear instructions on the format of the response, like the inclusion of
    time period comparisons.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）被赋予了与您的业务相关的上下文。此外，当提供Pulse指标时，模板被用作提示响应的指南。这个过程包括对LLM模型非常明确的指示，不要猜测，使用中性语言，并处理它接收到的数值。它还提供了关于响应格式的明确指示，例如包含时间段比较。
- en: Data masking
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据遮蔽
- en: To eliminate passing of protected information, like *personally identifiable
    information* (PII), sensitive values or words (such as a customer’s name) are
    *tokenized*. In the case of a customer’s name, the name isn’t sent to the model,
    but instead a substitute token or string of text is used. Upon serving up the
    result, the token is then translated back to the PII it represented.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了消除传递受保护信息，如*个人身份信息*（PII）、敏感值或单词（例如客户的姓名），会进行*标记化*。在客户姓名的情况下，姓名不会发送到模型，而是使用替代标记或文本字符串。在提供结果时，该标记随后被转换回它所代表的PII。
- en: Toxicity detection
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 毒性检测
- en: This is the process of scoring prompt results or generated summaries for harmful
    information, which includes language that exhibits hate, violence, identity, or
    sexual content. Each response is scored, and if it is overly toxic, it will not
    be served back to the end user.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是指对提示结果或生成的摘要进行评分，以识别有害信息的过程，包括表现出仇恨、暴力、身份或性内容的语言。每个响应都会被评分，如果它过于有毒，则不会返回给最终用户。
- en: Auditing
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 审计
- en: An audit trail is created and stored in Salesforce’s Data Cloud associated with
    the prompt or information processed by the LLM. This includes the user who initiated
    the prompt, the body of the prompt (both masked and unmasked), a categorization
    of whether PII was found in the prompt, the toxicity score, and any user feedback
    associated with the output they receive.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 创建并存储在Salesforce数据云中的审计跟踪与LLM处理的提示或信息相关。这包括启动提示的用户、提示正文（既遮蔽又未遮蔽）、是否在提示中找到PII的分类、毒性评分以及与用户收到的输出相关的任何用户反馈。
- en: Zero retention
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 零保留
- en: After the prompt is resolved, the prompt itself is purged from the system. This
    ensures that the LLM doesn’t retain the prompt as future information it has “learned”
    to influence the next response or the overall model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示解决后，提示本身将从系统中清除。这确保了LLM不会保留提示作为未来信息，它“学习”了影响下一个响应或整体模型。
- en: Tip
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Beyond the Einstein Trust Layer, all data is encrypted both at rest and in transit.
    Salesforce uses OpenAI’s GPT models and has agreements in place that dictate OpenAI
    will not store or retain any information or prompts that are fed into the models.
    And if you’re deeply curious, all these services are hosted on Amazon Web Services
    (AWS), which exists globally across many availability regions. For a deeper dive
    or explanation, watch [this Salesforce presentation](https://oreil.ly/zExox) on
    the topic.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在Einstein Trust Layer之外，所有数据在静止和传输过程中都进行了加密。Salesforce使用OpenAI的GPT模型，并已签订协议，规定OpenAI将不会存储或保留任何输入到模型中的信息或提示。如果您对此非常好奇，所有这些服务都托管在亚马逊网络服务（AWS）上，AWS在全球许多可用区域存在。对于更深入的了解或解释，请观看[这个Salesforce演示](https://oreil.ly/zExox)。
- en: Competitors and AI
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争对手和AI
- en: As this chapter comes to a close, I want to touch on how competitors to Tableau
    are imagining and implementing AI into their business intelligence (BI) platforms.
    While many options certainly are available for comparison, I’ve chosen to focus
    on Microsoft Power BI (PBI) and Google Looker.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 随着本章的结束，我想谈谈Tableau的竞争对手是如何想象和将AI整合到他们的商业智能（BI）平台中的。虽然确实有许多选项可供比较，但我选择专注于微软Power
    BI（PBI）和谷歌Looker。
- en: AI in Power BI
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Power BI中的AI
- en: 'Microsoft Power BI has three distinct types of AI features:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Power BI具有三种不同的AI功能：
- en: Advanced analytics assisted by AI
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由AI辅助的高级分析
- en: This feature includes baked-in advanced analysis types available to those working
    in PBI without the need to code. Of note is anomaly detection, which scans data
    presented in a visualization or data set and provides statistical results aimed
    at finding anything out of the ordinary. Two advanced data exploration options,
    take the form of interactive charts. One is called *key influencers*, an AI-driven
    visual aimed at finding primary drivers, and the other is a decomposition tree.
    The *decomposition tree* breaks a metric into the (likely) hierarchical dimensions
    and categories that exist within a data set. Sentiment analysis and forecasting
    are also available as no-code solutions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能包括为在 PBI 中工作且无需编码的人员提供的内置高级分析类型。值得注意的是异常检测，它扫描可视化或数据集中呈现的数据，并提供旨在发现任何异常的统计结果。两种高级数据探索选项以交互式图表的形式出现。一个是“关键影响因素”，这是一个由
    AI 驱动的可视化，旨在找到主要驱动因素，另一个是分解树。*分解树*将指标分解为数据集中存在的（可能的）层次维度和类别。情感分析和预测也作为无代码解决方案提供。
- en: AI assistance for analytics creation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 分析创建的 AI 助手
- en: Very similar to Tableau Agent, this is an interactive AI chatbot that can help
    developers create Data Analysis Expressions (DAX) code, a formula expression language.
    There are also areas throughout Microsoft Office products, like Teams and SharePoint,
    which can take suggested starting visualizations or analytical questions and automatically
    build them in PBI.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Tableau Agent 非常相似，这是一个交互式 AI 聊天机器人，可以帮助开发者创建数据分析表达式（DAX）代码，这是一种公式表达式语言。在
    Microsoft Office 产品中，如 Teams 和 SharePoint，也有这样的区域，可以自动在 PBI 中构建建议的起始可视化或分析问题。
- en: Natural language query (NLQ)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言查询（NLQ）
- en: This is nearly identical to the concept of Ask Data or interacting with Tableau
    Pulse. Here users can formulate questions that are turned into queries and return
    visualizations and results. The distinction to remember is that the input is coming
    from a nontechnical business user.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎与“询问数据”或与 Tableau Pulse 交互的概念相同。在这里，用户可以提出问题，这些问题被转换成查询，并返回可视化和结果。需要注意的是，输入来自非技术业务用户。
- en: AI in Looker
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Looker 中的 AI
- en: 'Google’s listed and upcoming AI capabilities nearly mirror what I’ve already
    described for Tableau and Power BI. Of note, they are focusing on the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Google 列出的和即将推出的 AI 功能几乎与我之前描述的 Tableau 和 Power BI 的功能相同。值得注意的是，他们专注于以下方面：
- en: Duet AI assistant
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Duet AI 助手
- en: An AI assistant designed to help analytics creators make visualizations and
    access data. Notably, this includes methods to translate natural language requests
    into its own proprietary query language, LookML.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一种旨在帮助分析创建者制作可视化和访问数据的 AI 助手。值得注意的是，这包括将自然语言请求翻译成其专有查询语言 LookML 的方法。
- en: AI-powered visualizations
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: AI 驱动的可视化
- en: Again, this is technology designed for a business user to automatically create
    visualizations based on information and data they have access to.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这是为业务用户设计的科技，可以自动根据他们可访问的信息和数据创建可视化。
- en: Summarized insights
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要见解
- en: While there aren’t many specifics on how or where this will be implemented,
    this is fundamentally similar to the insight summaries served up in Tableau Pulse.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关于如何或在哪里实施的具体细节不多，但这本质上与 Tableau Pulse 提供的洞察力摘要相似。
- en: Of note in discussing these competitors are the AI models that are the engines.
    Microsoft has a large stake in OpenAI and utilizes that company’s models or variations
    of its models. Google, on the other hand, leans on its own proprietary LLMs—namely,
    Gemini (formerly Bard).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论这些竞争对手时，值得注意的是作为引擎的 AI 模型。微软在 OpenAI 中拥有大量股份，并利用该公司的模型或其变体。另一方面，谷歌则依赖其自己的专有
    LLM——即 Gemini（以前称为 Bard）。
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you’ve learned about AI in the analytics space. Key applications
    of AI in analytics include the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了分析空间中的 AI。AI 在分析中的关键应用包括以下内容：
- en: More sophisticated analysis methods, like predictive multivariate models and
    sentiment analysis (scoring of text as positive/negative/neutral)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更复杂的分析方法，如预测性多元统计分析、情感分析（将文本评分为积极/消极/中性）
- en: Natural language processing and querying (NLP and NLQ), which allow users to
    ask questions in normal (human) language and receive analytical results
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理和查询（NLP 和 NLQ），允许用户用正常（人类）语言提问，并接收分析结果
- en: Generative AI that summarizes information and surfaces interesting insights
    to end users
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式 AI，可总结信息并向最终用户展示有趣见解
- en: AI assistance that makes building analytics easier
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使构建分析更简单的 AI 助手
- en: 'To help you understand the latest AI tools in this book, the chapter unpacked
    how LLMs function:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您理解本书中最新的人工智能工具，本章详细介绍了LLMs的工作原理：
- en: They consume large amounts of text and categorize words across a copious number
    of dimensions.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们消耗大量的文本，并在众多维度上对单词进行分类。
- en: Prompts and text inputs are processed in layers called *transformers*. These
    models tend to first resolve sentence structure and ultimately reach comprehension
    and context of the input.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示和文本输入在称为*transformers*的层中处理。这些模型倾向于首先解决句子结构，最终达到对输入的理解和上下文。
- en: Humans control what training data is fed into the models as well as guidelines
    for processing that information. However, much of what occurs within the LLM is
    unknown and left to the model.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类控制输入到模型中的训练数据以及处理该信息的指南。然而，LLM内部发生的大部分事情都是未知的，并留给模型处理。
- en: 'It is important to remember that LLMs and generative AI are essentially very
    sophisticated prediction engines. They rely heavily on the training data they
    receive. The output is influenced in how the LLM was constructed and whatever
    instructions it was given. Additionally, there are some inherent risks to be aware
    of when working with generative AI:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这一点很重要，即LLMs和生成式AI本质上是非常复杂的预测引擎。它们高度依赖于接收到的训练数据。输出受到LLM构建方式和所给指令的影响。此外，在处理生成式AI时，还有一些固有的风险需要注意：
- en: Model bias
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 模型偏差
- en: An LLM can have bias built in from the training data it receives. The model
    relies on information that has already been recorded by humans. In particular,
    there can be biases around societal issues (like diversity), and responses can
    be heavily influenced by user input.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可以从接收到的训练数据中内置偏差。该模型依赖于人类已经记录的信息。特别是，在社会问题（如多样性）方面可能存在偏差，并且用户的输入可能会对响应产生重大影响。
- en: Model hallucination
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 模型幻觉
- en: An LLM could respond with a factually made up or erroneous result. This typically
    occurs in ambiguous situations or where extrapolation is involved—both of which
    occur frequently in analytics.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一个LLM可能会以事实错误或虚构的结果回应。这种情况通常发生在模糊的情况或涉及外推的情况下——这两种情况在分析中都很常见。
- en: Worker displacement
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 工人替代
- en: Although it can cause worry to consider how analytics roles may change, the
    bedrock of analytical skills you hold are necessary to ensure that the AI-derived
    results are grounded in sound analytical reasoning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然考虑分析角色可能发生变化可能会引起担忧，但您所持有的分析技能的基石是确保AI得出的结果基于合理的分析推理所必需的。
- en: 'Tableau and Salesforce aim at creating trust while using AI-powered tools via
    the Einstein Trust Layer. This layer acts as a go-between for enterprise data
    and the LLM engines processing prompts. The six facets of this trust layer are
    as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Tableau和Salesforce旨在通过Einstein Trust Layer创建信任，使用AI工具。这一层作为企业数据和LLM处理提示之间的中介。这个信任层的六个方面如下：
- en: Secure data retrieval
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全数据检索
- en: Dynamic grounding
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态扎根
- en: Data masking
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据掩码
- en: Toxicity detection
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毒性检测
- en: Auditing
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计
- en: Zero retention
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零保留
- en: 'And finally, two major competitors of Tableau, Microsoft Power BI and Google
    Looker, show common themes in the utility of AI in the analytics space, namely:
    AI assistance in analytics creation, advanced mathematical analyses, summarized
    insights, and natural language query.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Tableau的两个主要竞争对手，Microsoft Power BI和Google Looker，在分析空间中AI的效用方面显示了共同的主题，即：在分析创建中的AI辅助、高级数学分析、总结洞察力和自然语言查询。
- en: In [Chapter 2](ch02.html#ch02_getting_started_with_tableau_pulse_1732595607647464),
    I’ll show you how to get started with Tableau Pulse. I’ll break down how to activate
    it in your Tableau environment, how to build your first metric, and more. By the
    end of the chapter, you’ll have the confidence and knowledge to start deploying
    your own metrics for business users to start following. And with the history of
    Tableau and knowledge of LLMs you received here, you will be able to accurately
    convey AI’s role and the risks when using it in Tableau.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](ch02.html#ch02_getting_started_with_tableau_pulse_1732595607647464)中，我将向您展示如何开始使用Tableau
    Pulse。我会分解如何在您的Tableau环境中激活它，如何构建您的第一个指标，以及更多内容。到本章结束时，您将拥有信心和知识，开始部署自己的指标，以便业务用户开始跟踪。并且，凭借您在这里获得的Tableau和LLMs的知识，您将能够准确传达在Tableau中使用AI的角色和风险。
