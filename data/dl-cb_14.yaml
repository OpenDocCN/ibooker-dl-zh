- en: Chapter 14\. Generating Icons Using Deep Nets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章。使用深度网络生成图标
- en: 'In the previous chapter we looked at generating hand-drawn sketches from the
    Quick Draw project and digits from the MNIST dataset. In this chapter we’ll try
    three types of networks on a slightly more challenging task: generating icons.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看了一下从Quick Draw项目生成手绘草图和从MNIST数据集生成数字。在本章中，我们将尝试三种类型的网络来完成一个稍微具有挑战性的任务：生成图标。
- en: Before we can do any generating we need to get our hands on a set of icons.
    Searching online for “free icons” results in a lot of hits. None of these are
    “free as in speech” and most of them struggle where it comes to “free as in beer.”
    Also, you can’t freely reuse the icons, and usually the sites strongly suggest
    you pay for them after all. So, we’ll start with how to download, extract, and
    process icons into a standard format that we can use in the rest of the chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行任何生成之前，我们需要获取一组图标。在线搜索“免费图标”会得到很多结果。这些都不是“言论自由”的，大多数在“免费啤酒”方面都有困难。此外，您不能自由重复使用这些图标，通常网站强烈建议您最终付费。因此，我们将从如何下载、提取和处理图标开始，将它们转换为我们可以在本章的其余部分中使用的标准格式。
- en: The first thing we’ll try is to train a conditional variational autoencoder
    on our set of icons. We’ll use the network we ended up with in the previous chapter
    as a basis, but we’ll add some convolutional layers to it to make it perform better
    since the icon space is so much more complex than that of hand-drawn digits.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试的第一件事是在我们的图标集上训练一个条件变分自动编码器。我们将使用上一章中得到的网络作为基础，但我们将添加一些卷积层以使其表现更好，因为图标空间比手绘数字的空间复杂得多。
- en: The second type of network we’ll try is a generative adversarial network. Here
    we’ll train two networks, one to generate icons and another to distinguish between
    generated icons and real icons. The competition between the two leads to better
    results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试的第二种类型的网络是生成对抗网络。在这里，我们将训练两个网络，一个用于生成图标，另一个用于区分生成的图标和真实的图标。两者之间的竞争会带来更好的结果。
- en: The third and final type of network we’ll try is an RNN. In [Chapter 5](ch05.html#text_generation)
    we used this to generate texts in a certain style. By reinterpreting icons as
    a set of drawing instructions, we can use the same technique to generate images.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试的第三种也是最后一种类型的网络是RNN。在[第5章](ch05.html#text_generation)中，我们使用它来生成特定风格的文本。通过将图标重新解释为一组绘图指令，我们可以使用相同的技术来生成图像。
- en: 'Code related to this chapter can be found in the following notebooks:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章相关的代码可以在以下笔记本中找到：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 14.1 Acquiring Icons for Training
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.1 获取训练图标
- en: Problem
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you get a large set of icons in a standard format?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如何获取标准格式的大量图标？
- en: Solution
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Extract them from the Mac application *Icons8*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从Mac应用程序*Icons8*中提取它们。
- en: 'Icons8 distributes a large set of icons—over 63,000\. This is partly because
    icons of different formats are counted double, but still, it is a nice set. Unfortunately
    the icons are distributed inside applications for Mac and Windows. The good news
    is that a Mac *.dmg* archive is really just a p7zip archive containing an application,
    which itself is also a p7zip archive. Let’s start by downloading the app. Navigate
    to [*https://icons8.com/app*](https://icons8.com/app) and make sure to download
    the Mac version (even if you are on Linux or Windows). Now install the command-line
    version of p7zip for your favorite operating system and extract the contents of
    the *.dmg* file to its own folder:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Icons8分发了一个庞大的图标集——超过63,000个。这部分是因为不同格式的图标被计为两倍，但仍然是一个不错的集合。不幸的是，这些图标分布在Mac和Windows的应用程序中。好消息是Mac的*.dmg*存档实际上只是一个包含应用程序的p7zip存档，而应用程序本身也是一个p7zip存档。让我们从下载应用程序开始。转到[*https://icons8.com/app*](https://icons8.com/app)并确保下载Mac版本（即使您在Linux或Windows上也是如此）。现在为您喜欢的操作系统安装p7zip的命令行版本，并将*.dmg*文件的内容提取到自己的文件夹中：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The *.dmg* contains some metainformation and the Mac application. Let’s unpack
    the app too:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*.dmg*包含一些元信息和Mac应用程序。让我们也解压缩应用程序：'
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Like an onion, this thing has many layers. You should now see a *.tar* file
    that also needs unpacking:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就像洋葱一样，这个东西有很多层。现在您应该看到一个也需要解压缩的*.tar*文件：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This gives us a directory called *icons* that contains an *.ldb* file, which
    suggests that the directory represents a LevelDB database. Switching to Python,
    we can take a look inside:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们一个名为*icons*的目录，其中包含一个*.ldb*文件，这表明该目录代表一个LevelDB数据库。切换到Python，我们可以查看其中的内容：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Bingo. We have found our icons, and they seem to be encoded using the *.svg*
    vector format. It looks like they are contained in yet another format, with the
    header `TSAF`. Reading online, it seems to be some IBM-related format, but a Python
    library to extract data from this is not easy to find. Then again, this simple
    dump suggests that we are dealing with key/value pairs separated by a `\x00` with
    the key and value separated by a `\x08`. It doesn’t quite pan out, but it is good
    enough to build a hacky parser:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了。我们已经找到了我们的图标，它们似乎是使用*.svg*矢量格式编码的。看起来它们包含在另一种格式中，带有`TSAF`头。在线阅读，似乎是一些与IBM相关的格式，但是很难找到一个Python库来从中提取数据。再说一遍，这个简单的转储表明我们正在处理由`\x00`分隔的键/值对，键和值由`\x08`分隔。它并不完全奏效，但足以构建一个hacky解析器：
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This extracts the SVGs and some basic properties that might come in handy later.
    The various platforms contain more or less the same icons, so we need to pick
    one platform. iOS seems to have the most icons, so let’s go with that:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这会提取SVG文件和一些可能在以后有用的基本属性。各个平台包含更多或更少相同的图标，因此我们需要选择一个平台。iOS似乎拥有最多的图标，所以让我们选择它：
- en: '[PRE7]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now let’s write this all to disk for later processing. We’ll keep the SVGs
    but also write out bitmaps as PNGs:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将所有内容写入磁盘以供以后处理。我们将保留SVG文件，同时也将位图写出为PNG文件：
- en: '[PRE8]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Discussion
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Even though there are many sites online advertising free icons, in practice
    getting a good training set is rather involved. In this case we found the icons
    as SVGs inside a mysterious `TSAF` store inside a LevelDB database inside a Mac
    app inside of the *.dmg* file that we downloaded. On the one hand, this seems
    more involved than it should be. On the other hand, it goes to show that with
    a little detective work we can uncover some very interesting datasets.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多在线广告免费图标的网站，但实际上获得一个好的训练集是相当复杂的。在这种情况下，我们在一个神秘的`TSAF`商店内找到了SVG格式的图标，这些图标存储在一个LevelDB数据库内的Mac应用程序内，而这个Mac应用程序存储在我们下载的*.dmg*文件中。一方面，这似乎比应该的要复杂。另一方面，这表明通过一点侦探工作，我们可以发现一些非常有趣的数据集。
- en: 14.2 Converting the Icons to a Tensor Representation
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.2 将图标转换为张量表示
- en: Problem
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you convert the saved icons into a format suitable for training a network?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如何将保存的图标转换为适合训练网络的格式？
- en: Solution
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Concatenate them and normalize them.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 连接它们并对它们进行归一化。
- en: 'This is similar to how we handled images for the pretrained network, except
    that now we will train our own network. We know all images will be 32×32 pixels,
    and we’ll keep track of the mean and standard deviation so we can normalize and
    denormalize the images correctly. We’ll also split the data up into a training
    set and a test set:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们为预训练网络处理图像的方式类似，只是现在我们将训练自己的网络。我们知道所有图像都将是32×32像素，我们将跟踪均值和标准差，以便正确地对图像进行归一化和反归一化。我们还将数据分成训练集和测试集：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Discussion
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The processing is fairly standard. We read in the images, append them all to
    one array, normalize the array, and then split the resulting set into a training
    set and test set. We normalize by just dividing the grayscale pixels by 255\.
    The activation we’ll use later on is a sigmoid, which will only produce positive
    numbers, so no need to subtract the mean.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 处理过程相当标准。我们读取图像，将它们全部附加到一个数组中，对数组进行归一化，然后将结果集拆分为训练集和测试集。我们通过将灰度像素除以255来进行归一化。我们稍后将使用的激活函数是sigmoid，它只会产生正数，因此不需要减去均值。
- en: 14.3 Using a Variational Autoencoder to Generate Icons
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.3 使用变分自动编码器生成图标
- en: Problem
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to generate icons in a certain style.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您想以某种风格生成图标。
- en: Solution
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Add convolutional layers to the MNIST solution of [Chapter 13](ch13.html#autoencoders).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第13章](ch13.html#autoencoders)的MNIST解决方案中添加卷积层。
- en: 'The variational autoencoder we used to generate digits had a latent space of
    only two dimensions. We can get away with such a small space because ultimately
    there isn’t that much variation between handwritten digits. By their nature, there
    are only 10 different ones that all look fairly similar. Moreover, we used a fully
    connected layer to go to and from the latent space. Our icons are much more diverse,
    so we’ll use a few convolutional layers to reduce the size of the image before
    we apply a fully connected layer and end up with our latent state:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用于生成数字的变分自动编码器只有两个维度的潜在空间。我们可以使用这样一个小空间，因为手写数字之间的变化并不那么大。从本质上讲，只有10种看起来相似的不同数字。此外，我们使用全连接层来进入和离开潜在空间。我们的图标更加多样化，因此我们将使用一些卷积层来减小图像的大小，然后应用一个全连接层，最终得到我们的潜在状态：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We handle the loss function and distribution as before. The weight for the
    `KL_loss` is important. Set it too low and the resulting space won’t be dense.
    Set it too high and the network will quickly learn that predicting empty bitmaps
    gets it a decent `reconstruction_loss` and a great `KL_loss`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像以前一样处理损失函数和分布。`KL_loss`的权重很重要。如果设置得太低，结果空间将不会很密集。如果设置得太高，网络将很快学会预测空位图会得到一个体面的`reconstruction_loss`和一个很好的`KL_loss`：
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we’ll upscale the latent state back into an icon. As before, we do this
    in parallel for the encoder and the autoencoder:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将潜在状态放大回图标。与以前一样，我们为编码器和自动编码器并行执行此操作：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To train the network, we need to make sure the training and test sets have
    a size that is divisible by the `batch_size`, as otherwise the `KL_loss` function
    will fail:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练网络，我们需要确保训练集和测试集的大小可以被`batch_size`整除，否则`KL_loss`函数将失败：
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can sample some random icons from the space as before:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像以前一样从空间中抽样一些随机图标：
- en: '![Autoencoder generated icon images](assets/dlcb_14in01.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![自动编码器生成的图标图像](assets/dlcb_14in01.png)'
- en: As you can see, the network definitely learned something about icons. They tend
    to have some sort of box that is filled in somewhat and usually don’t touch the
    outsides of the 32×32 container. But it is still rather vague!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，网络确实学到了一些关于图标的东西。它们往往有一种填充在某种程度上的盒子，通常不会触及32×32容器的外部。但仍然相当模糊！
- en: Discussion
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: To apply the variational autoencoder we developed in the previous chapter on
    the more heterogeneous space of icons we need to use convolutional layers that
    step by step reduce the dimensions of the bitmap and increase the abstraction
    level until we are in the latent space. This is very similar to how image recognition
    networks function. Once we have our icons projected in a 128-dimensional space,
    we use the upsampling layers for both the generator and the autoencoder.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们在上一章中开发的变分自动编码器应用于图标更异构的空间，我们需要使用卷积层逐步减少位图的维度并增加抽象级别，直到我们进入潜在空间。这与图像识别网络的功能非常相似。一旦我们的图标投影到一个128维空间中，我们就可以为生成器和自动编码器使用上采样层。
- en: The result is more interesting than a slam dunk. Part of the issue is that icons,
    like the cats in the previous chapter, contain a lot of line drawings, which makes
    it hard for the network to get them exactly right. When in doubt, the network
    will opt for vague lines instead. Worse, icons often contain regions that are
    dithered like a checkerboard. These patterns are certainly learnable, but an off-by-one
    pixel error would mean that the entire answer is now completely wrong!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 结果比一次扣篮更有趣。问题的一部分是，图标，就像上一章中的猫一样，包含许多线条绘图，这使得网络很难完全正确地识别它们。当存在疑问时，网络会选择模糊的线条。更糟糕的是，图标通常包含像棋盘一样抖动的区域。这些模式肯定是可以学习的，但一个像素错误就会导致整个答案完全错误！
- en: Another reason why the performance of our network is relatively poor is that
    we have relatively few icons. The next recipe shows a trick to get around that.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网络性能相对较差的另一个原因是我们的图标相对较少。下一个配方展示了一个绕过这个问题的技巧。
- en: 14.4 Using Data Augmentation to Improve the Autoencoder’s Performance
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.4 使用数据增强来提高自动编码器的性能
- en: Problem
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How can you improve on the performance of your network without getting more
    data?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在不增加更多数据的情况下提高网络的性能？
- en: Solution
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use data augmentation.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据增强。
- en: Our autoencoder in the previous recipe learned the vague outlines of our icon
    set, but nothing more than that. The results suggested that it was picking up
    on something, but not enough to do a stellar job. Throwing more data at the problem
    could help, but it would require us to find more icons, and those icons would
    have to be sufficiently similar to our original set to help. Instead we’re going
    to generate more data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个配方中，我们的自动编码器学习了图标集的模糊轮廓，但仅限于此。结果表明它正在捕捉某些东西，但不足以做出出色的工作。增加更多数据可能有所帮助，但这将要求我们找到更多图标，并且这些图标必须与我们的原始集合足够相似才能帮助。相反，我们将生成更多数据。
- en: 'The idea behind data augmentation, as discussed in [Chapter 1](ch01.html#tools_techniques),
    is to generate variations of the input data that shouldn’t matter to the network.
    In this case we want our network to learn the notion of *iconness* by feeding
    it icons. But if we flip or rotate our icons, does that make them less *icony*?
    Not really. Doing this will increase our input by a factor of 16\. Our network
    will learn from these new training examples that rotations and flipping don’t
    matter and hopefully perform better. Augmentation would look like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强的背后思想，如[第1章](ch01.html#tools_techniques)中讨论的，是生成输入数据的变化，这些变化对网络不重要。在这种情况下，我们希望通过输入图标让我们的网络学习*图标特性*的概念。但如果我们翻转或旋转我们的图标，这会使它们不那么*图标化*吗？实际上并不是。这样做将使我们的输入增加16倍。我们的网络将从这些新的训练示例中学习，旋转和翻转并不重要，希望能够表现更好。增强会是这样的：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s apply that to our training and test data:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这应用到我们的训练和测试数据中：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Training the network will now obviously take a bit longer. But the results
    are better, too:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练网络显然需要更长一点时间。但结果也更好：
- en: '![Autoencoder icon after data augmentation](assets/dlcb_14in02.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![数据增强后的自动编码器图标](assets/dlcb_14in02.png)'
- en: Discussion
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Data augmentation is a technique widely used when it comes to computer images.
    Rotations and flips are sort of obvious ways of doing this, but given the fact
    that we actually started out with the *.svg* representation of the icons there
    are a number of other things we could do. SVG is a vector format, so we could
    easily create icons that have a slight rotation or magnification without getting
    the sort of artifacts that we’d get if our baseline data comprised just bitmaps.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是在计算机图像方面广泛使用的技术。旋转和翻转是这样做的一种明显方式，但考虑到我们实际上是从图标的*.svg*表示开始的，我们还可以做很多其他事情。SVG是一种矢量格式，因此我们可以轻松地创建具有轻微旋转或放大的图标，而不会出现我们如果基线数据仅包含位图时会出现的那种伪影。
- en: The icon space that we ended up with is better than the one from the previous
    recipe and it seems to capture some form of iconness.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的图标空间比上一个配方的要好，似乎捕捉到了某种图标特性。
- en: 14.5 Building a Generative Adversarial Network
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.5 构建生成对抗网络
- en: Problem
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to construct a network that can generate images and another that
    can learn to distinguish generated images from the originals.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您想构建一个可以生成图像的网络，另一个可以学习区分生成图像和原始图像的网络。
- en: Solution
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Create an image generator and an image discriminator that can work together.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个可以一起工作的图像生成器和图像鉴别器。
- en: 'The key insight behind generative adversarial networks is that if you have
    two networks, one generating images and one judging the generated images, and
    train them in tandem, they keep each other on their toes as they learn. Let’s
    start with a generator network. This is similar to what we did with the decoder
    bit of an autoencoder:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络背后的关键见解是，如果你有两个网络，一个生成图像，一个评判生成的图像，并且同时训练它们，它们在学习过程中会互相刺激。让我们从一个生成器网络开始。这与自动编码器的解码器部分类似：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The other network, the discriminator, will take in an image and output whether
    it thinks it is generated or one of the originals. In that sense it looks like
    a classic convolutional network that has just a binary output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个网络，鉴别器，将接收一幅图像并输出它认为是生成的还是原始图像之一。在这个意义上，它看起来像一个具有二进制输出的经典卷积网络：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the next recipe we’ll look at how to train these two networks together.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个配方中，我们将看看如何训练这两个网络。
- en: Discussion
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Generative adversarial networks or GANs are a fairly recent innovation for generating
    images. One way to look at them is to see the two component networks, the generator
    and the discriminator, as learning together, becoming better in competition.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络或GAN是一种相对较新的用于生成图像的创新。看待它们的一种方式是将两个组件网络，生成器和鉴别器，视为一起学习，通过竞争变得更好。
- en: The other way to look at them is to see the discriminator as a dynamic loss
    function for the generator. A straightforward loss function works well when a
    network is learning to distinguish between cats and dogs; something is a cat,
    or it isn’t and we can use as a loss function the difference between the answer
    and the truth.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看待它们的方式是将鉴别器视为生成器的动态损失函数。当网络学习区分猫和狗时，直接的损失函数效果很好；某物是猫，或者不是，我们可以使用答案与真相之间的差异作为损失函数。
- en: When generating images, this is trickier. How do you compare two images? Earlier
    in this chapter, when we were generating images using autoencoders, we ran into
    this problem. There, we just compared images pixel by pixel; that works when seeing
    if two images are the same, but it doesn’t work so well for similarity. Two icons
    that are exactly the same but offset by one pixel won’t necessarily have many
    pixels in the same position. As a result, the autoencoder often opted to generate
    fuzzy images.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成图像时，这更加棘手。如何比较两幅图像？在本章早些时候，当我们使用自动编码器生成图像时，我们遇到了这个问题。在那里，我们只是逐像素比较图像；当查看两幅图像是否相同时，这种方法有效，但对于相似性来说效果不佳。两个完全相同但偏移一个像素的图标不一定会有许多像素处于相同位置。因此，自动编码器通常选择生成模糊的图像。
- en: Having a second network do the judging allows the overall system to develop
    a sense of image similarity that is more fluid. Moreover, it can become stricter
    as the images become better, while with the autoencoder if we start with too much
    emphasis on the dense space the network will never learn.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让第二个网络进行评判允许整个系统发展出更流畅的图像相似性感知。此外，随着图像变得更好，它可以变得更加严格，而使用自动编码器，如果我们一开始过于强调密集空间，网络将永远无法学习。
- en: 14.6 Training Generative Adversarial Networks
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.6 训练生成对抗网络
- en: Problem
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you train the two components of a GAN together?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如何训练 GAN 的两个组件？
- en: Solution
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Fall back on the underlying TensorFlow framework to run both networks together.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 回退到底层 TensorFlow 框架来同时运行两个网络。
- en: Normally we just let Keras do the heavy lifting when it comes to talking to
    the underlying TensorFlow framework. But the best we can do using Keras directly
    is alternate between training the generator and the discriminator network, which
    is suboptimal. Qin Yongliang has written a [blog post](http://bit.ly/2ILx7Te)
    that describes how to get around this.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当涉及与底层 TensorFlow 框架通信时，我们只让 Keras 承担繁重的工作。但是，我们直接使用 Keras 所能做的最好的事情是在训练生成器和鉴别器网络之间交替，这是次优的。秦永亮写了一篇[博客文章](http://bit.ly/2ILx7Te)描述了如何解决这个问题。
- en: 'We’ll start by generating some noise and feeding that into the generator to
    get a generated image, and then feed a real image and a generated image into the
    discriminator:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从生成一些噪音开始，并将其输入生成器以获得生成的图像，然后将真实图像和生成的图像输入鉴别器：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now we can construct two loss functions. The generator is scored against how
    likely to be real the discriminator thought the image was. The discriminator is
    scored on a combination of how well it did with fake and real images:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以构建两个损失函数。生成器的得分取决于鉴别器认为图像是真实的可能性。鉴别器的得分取决于它在假和真实图像上的表现：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we’ll calculate the gradients to optimize these two loss functions for
    the trainable weights of the two networks:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将计算梯度，以优化这两个损失函数对两个网络的可训练权重：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We collect the various steps and tensors:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集各种步骤和张量：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And we’re ready to set up the trainer. Keras needs the `learning_phase` set:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备设置训练器。Keras 需要设置 `learning_phase`：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The variables of which we can provide by generating our own batches:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过生成自己的批次提供的变量：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Discussion
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Updating the weights for both networks in one go took us down to the level of
    TensorFlow itself. While this is a bit hairy, it is also good to get to know the
    underlying systems from time to time and not always rely on the “magic” that Keras
    provides.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 同时更新两个网络的权重使我们降到了 TensorFlow 本身的级别。虽然这有点复杂，但也很好地了解底层系统，而不总是依赖 Keras 提供的“魔法”。
- en: Note
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are a number of implementations on the web that use the easy way out and
    just run both networks step by step, but not at the same time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 网络上有许多实现采用简单的方式，只是逐步运行两个网络，但不是同时。
- en: 14.7 Showing the Icons the GAN Produces
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.7 展示 GAN 生成的图标
- en: Problem
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you show the progress that the GAN is making while it learns?
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习过程中如何展示 GAN 的进展？
- en: Solution
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Add an icon renderer after each epoch.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时代后添加一个图标渲染器。
- en: 'Since we’re running our own batch processing, we might as well take advantage
    of this and update the notebook with the intermediate result at the end of each
    epoch. Let’s start with rendering a set of icons using the generator:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在运行自己的批处理，我们可以利用这一点，并在每个时代结束时使用中间结果更新笔记本。让我们从使用生成器渲染一组图标开始：
- en: '[PRE24]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, let’s put them on a poster overview:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将它们放在海报概览上：
- en: '[PRE25]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can now add the following code to our epoch loop:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将以下代码添加到我们的时代循环中：
- en: '[PRE26]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'After one epoch some vague icons start to appear already:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一个时代后，一些模糊的图标已经开始出现：
- en: '![First GAN generated images](assets/dlcb_14in03.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![第一个 GAN 生成的图像](assets/dlcb_14in03.png)'
- en: 'Another 25 epochs and we are really starting to see some iconness:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 再经过 25 个时代，我们真的开始看到一些图标的出现：
- en: '![After 25 epochs](assets/dlcb_14in04.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![经过 25 个时代后](assets/dlcb_14in04.png)'
- en: Discussion
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The final results for generating icons using GANs are better than what we got
    out of the autoencoders. Mostly, the drawings are a lot sharper, which can be
    attributed to having the discriminator network decide whether an icon is any good,
    rather than comparing icons on a pixel-by-pixel basis.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GAN 生成图标的最终结果比我们从自动编码器中得到的要好。大多数绘图更加清晰，这可以归因于鉴别器网络决定一个图标是否好，而不是逐像素比较图标。
- en: Note
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There has been an explosion of applications for GANs and their derivatives,
    ranging from reconstructing 3D models from pictures to coloring of old pictures
    and super-resolution, where the network increases the resolution of a small image
    without making it look blurred or blocky.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: GAN及其衍生应用已经爆炸性增长，范围从从图片重建3D模型到为旧图片上色和超分辨率，网络可以增加小图像的分辨率而不使其看起来模糊或块状。
- en: 14.8 Encoding Icons as Drawing Instructions
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.8 将图标编码为绘图指令
- en: Problem
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to convert icons into a format that is suitable to train an RNN.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您想将图标转换为适合训练RNN的格式。
- en: Solution
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Encode the icons as drawing instructions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 将图标编码为绘图指令。
- en: RNNs can learn sequences, as we saw in [Chapter 5](ch05.html#text_generation).
    But what if we wanted to generate icons using an RNN? We could simply encode each
    icon as a sequence of pixels. One way to do this would be to view an icon as a
    sequence of pixels that have been “turned on.” There are 32 * 32 = 1,024 different
    pixels, so that would be our vocabulary. This does work, but we can do a little
    better by using actual drawing instructions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: RNN可以学习序列，就像我们在第5章中看到的那样。但是如果我们想使用RNN生成图标怎么办？我们可以简单地将每个图标编码为像素序列。一种方法是将图标视为一系列已“打开”的像素。有32
    * 32 = 1,024个不同的像素，因此这将是我们的词汇表。这样做是有效的，但是通过使用实际的绘图指令，我们可以做得更好。
- en: 'If we treat an icon as a series of scanlines, we need only 32 different tokens
    for the pixels in a scanline. Add one token to move to the next scanline and a
    final token to mark the end of an icon and we have a nice sequential representation.
    Or, in code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将图标视为一系列扫描线，我们只需要32个不同的令牌来表示扫描线中的像素。添加一个令牌以移动到下一个扫描线，再添加一个最终令牌来标记图标的结束，我们就有了一个很好的顺序表示。或者，在代码中：
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can then decode an image by going through the pixels:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过遍历像素来解码图像：
- en: '[PRE28]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Discussion
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Encoding icons as a set of drawing instructions is just another way of preprocessing
    the data such that a network will have an easier job learning what we want it
    to learn, similar to other approaches we saw in [Chapter 1](ch01.html#tools_techniques).
    By having explicit drawing instructions we make sure, for example, that the network
    doesn’t learn to draw vague lines, as our autoencoder was prone to do—it won’t
    be able to.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将图标编码为一组绘图指令只是预处理数据的另一种方式，使网络更容易学习我们想要学习的内容，类似于我们在第1章中看到的其他方法。通过具体的绘图指令，我们确保网络不会学习绘制模糊线条，就像我们的自动编码器容易做的那样——它将无法做到。
- en: 14.9 Training an RNN to Draw Icons
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.9 训练RNN绘制图标
- en: Problem
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to train an RNN to generate icons.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 您想训练一个RNN来生成图标。
- en: Solution
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Train a network based on the drawing instructions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 基于绘图指令训练网络。
- en: 'Now that we can encode single icons as drawing instructions, the next step
    is to encode a whole set. Since we’re going to feed chunks into the RNN, asking
    it to predict the next instruction, we actually construct one big “document”:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将单个图标编码为绘图指令，下一步是编码整个集合。由于我们将向RNN馈送块，并要求它预测下一个指令，因此我们实际上构建了一个大“文档”：
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We’ll run with the same model that helped us generate our Shakespearean text:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用帮助我们生成莎士比亚文本的相同模型运行：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Discussion
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: To see in more detail how the network we use here is trained and the data is
    generated, it might be a good idea to look back at [Chapter 5](ch05.html#text_generation).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要更详细地了解我们在这里使用的网络是如何训练的以及数据是如何生成的，最好回顾一下第5章。
- en: You can experiment with different numbers of layers and nodes or try different
    values for dropout. Different RNN layers also have an effect. The model is somewhat
    fragile; it is easy to get into a state where it doesn’t learn anything or, when
    it does, gets stuck on a local maximum.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试不同层数和节点数，或尝试不同的dropout值。不同的RNN层也会产生影响。该模型有点脆弱；很容易陷入不学习任何内容的状态，或者在学习时陷入局部最大值。
- en: 14.10 Generating Icons Using an RNN
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14.10 使用RNN生成图标
- en: Problem
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’ve trained the network; now how do you get it to produce icons?
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经训练了网络；现在如何让它生成图标？
- en: Solution
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Feed the network some random bits of your test set and interpret the predictions
    as drawing instructions.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 将一些测试集的随机位馈送到网络中，并将预测解释为绘图指令。
- en: 'The basic approach here is again the same as when we were generating Shakespearean
    text or Python code; the only difference is that we need to feed the predictions
    into the icon decoder to get icons out. Let’s first run some predictions:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的基本方法与我们生成莎士比亚文本或Python代码时相同；唯一的区别是我们需要将预测输入到图标解码器中以获取图标。让我们首先运行一些预测：
- en: '[PRE31]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `diversity` parameter controls how far the predictions are from deterministic
    (which the model will turn into if `diversity` is `0`). We need this to generate
    diverse icons, but also to avoid getting stuck in a loop.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`diversity`参数控制预测与确定性之间的距离（如果`diversity`为`0`，模型将将其转换为确定性）。我们需要这个来生成多样化的图标，但也要避免陷入循环。'
- en: 'We’ll collect each prediction in a variable, `so_far`, which we flush every
    time we encounter the value `33` (end of icon). We also check whether the `y`
    value is in range—the model learns more or less the size of the icons, but will
    sometimes try to color outside of the lines:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将每个预测收集到一个变量`so_far`中，每次遇到值`33`（图标结束）时我们都会清空它。我们还检查`y`值是否在范围内——模型更多或更少地学习了图标的大小，但有时会尝试在线条外部着色：
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'With this, we can now draw a “poster” of icons:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们现在可以绘制一个图标“海报”：
- en: '[PRE33]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![RNN generated icons](assets/dlcb_14in05.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![RNN生成的图标](assets/dlcb_14in05.png)'
- en: Discussion
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The icons generated using the RNN are the boldest of the three attempts we undertook
    in this chapter and arguably capture the nature of iconness best. The model learns
    symmetry and the basic shapes found in icons and even occasionally dithers to
    get a notion of halftones across.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RNN生成的图标是我们在本章中进行的三次尝试中最大胆的，可以说最好地捕捉了图标的本质。该模型学习了图标中的对称性和基本形状，甚至偶尔进行抖动以获得半色调的概念。
- en: We could try to combine the different approaches in this chapter. For example,
    instead of trying to predict the next drawing instruction, we could have an RNN
    that takes in the drawing instructions, capture the latent state at that point,
    and then have a second RNN based on that state reconstruct the drawing instructions.
    This way we would have an RNN-based autoencoder. In the text world there have
    been some successes in this area.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试结合本章中的不同方法。例如，我们可以有一个RNN，它不再尝试预测下一个绘图指令，而是接受绘图指令，捕捉该点的潜在状态，然后有一个基于该状态的第二个RNN重构绘图指令。这样我们就会有一个基于RNN的自动编码器。在文本世界中，在这个领域已经取得了一些成功。
- en: RNNs can also be combined with GANs. Instead of having a generator network that
    takes a latent variable and upscales it into an icon, we’d use an RNN to generate
    drawing instructions and then have the discriminator network decide whether these
    are real or fake.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs也可以与GANs结合。我们不再使用一个生成器网络，它接受一个潜变量并将其放大成一个图标，而是使用RNN生成绘图指令，然后让鉴别器网络决定这些是真实的还是假的。
