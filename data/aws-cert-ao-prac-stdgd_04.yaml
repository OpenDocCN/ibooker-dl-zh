- en: Chapter 3\. AI and Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 章\. 人工智能与机器学习
- en: AI is not a new field; its origins date back decades. In the 1940s, researchers
    like Warren McCulloch and Walter Pitts developed foundational concepts for neural
    networks. This was followed by the pioneering work of mathematician Alan Turing,
    who in 1950 authored the paper “Computing Machinery and Intelligence.” In it,
    he introduced the Turing test, a method for evaluating a machine’s ability to
    exhibit intelligent behavior equivalent to, or indistinguishable from, that of
    a human.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能不是一个新领域；其起源可以追溯到几十年前。在 1940 年代，像沃伦·麦克洛奇和沃尔特·皮茨这样的研究人员为神经网络开发了基础概念。这随后是数学家艾伦·图灵的先驱工作，他在
    1950 年发表了论文“计算机与智能”。在论文中，他介绍了图灵测试，这是一种评估机器展现与人类智能相当或无法区分的行为的方法。
- en: The term *artificial intelligence* was coined in 1956 by computer scientist
    John McCarthy for a conference at Dartmouth College. The event gathered luminaries
    such as Marvin Minsky and Claude Shannon. Two attendees, Allen Newell and Herbert
    A. Simon, demonstrated the Logic Theorist, an AI program that could solve mathematical
    theorems. While today’s AI developments are far more advanced, the fundamental
    concepts established by these early pioneers remain critical building blocks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 术语“人工智能”是在 1956 年由计算机科学家约翰·麦卡锡为达特茅斯学院的会议提出的。这次会议聚集了像马文·明斯基和克劳德·香农这样的杰出人物。两位与会者，艾伦·纽厄尔和赫伯特·A·西蒙，展示了逻辑理论家，这是一个能够解决数学定理的人工智能程序。尽管今天的
    AI 发展更为先进，但这些早期先驱确立的基本概念仍然是关键的建筑块。
- en: No doubt, today’s AI developments are light-years ahead of these early applications.
    Yet some of their underlying fundamentals have been worked on for many years.
    They were the critical building blocks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，今天的 AI 发展远远领先于这些早期应用。然而，一些其基本原理已经研究了多年。它们是关键的建筑块。
- en: In this chapter, we’ll focus on the fundamentals, which are a major part of
    the AIF-C01 exam. This will include focusing on a core topic of AI—that is, machine
    learning.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注基础知识，这是 AIF-C01 考试的重要组成部分。这包括关注人工智能的核心主题——即机器学习。
- en: Understanding AI
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解人工智能
- en: AI can seem overwhelming. Part of this is due to the complexity of the technology.
    After all, it often involves advanced mathematics, complex algorithms, and large
    amounts of data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可能看起来令人难以置信。这部分原因是技术的复杂性。毕竟，它通常涉及高级数学、复杂的算法和大量数据。
- en: Meanwhile, AI is undergoing significant change and innovation. It’s extremely
    difficult—if not impossible—to keep up with everything. This is the case even
    for the world’s top data scientists.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，人工智能正在经历重大的变革和创新。即使对于世界顶级数据科学家来说，跟上所有这些也非常困难。
- en: Then there is the hype, as it seems like every tech company is about AI. Even
    many traditional companies boast about their own AI.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是炒作，因为似乎每家科技公司都在谈论人工智能。甚至许多传统公司也吹嘘他们自己的人工智能。
- en: Given all this, it should be no surprise that it’s common for people to have
    misunderstandings about AI. This even includes its definition!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，人们普遍对人工智能存在误解并不奇怪。这甚至包括其定义！
- en: 'But of course, when it comes to the AIF-C01 exam, you need to have a good one.
    What to do? The best is to see how [AWS defines AI](https://oreil.ly/vniGg):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但当然，当涉及到 AIF-C01 考试时，你需要有一个很好的理解。怎么办？最好的办法是看看 [AWS 如何定义人工智能](https://oreil.ly/vniGg)：
- en: AI, also known as artificial intelligence, is a technology with humanlike problem-solving
    capabilities. AI in action appears to simulate human intelligence—it can recognize
    images, write poems, and make data-based predictions.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能，也称为人工智能，是一种具有类似人类问题解决能力的技术。人工智能的应用似乎模拟了人类智能——它可以识别图像、写诗，并基于数据进行预测。
- en: This is certainly a good, high-level definition. Yet we need to dig deeper.
    And a good way to do this is to get a visual of AI, as shown in [Figure 3-1](#figure_three_onedot_the_various_compone).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然是一个很好的、高层次的定义。然而，我们需要更深入地挖掘。而一个很好的方法是获取人工智能的视觉图像，如图 3-1 所示[图](#figure_three_onedot_the_various_compone)。
- en: '![](assets/awsc_0301.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0301.png)'
- en: Figure 3-1\. The various components of AI
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-1\. 人工智能的各个组成部分
- en: For the most part, AI is a collection of different approaches and fields. In
    some cases, they can work on their own. In other situations, there is a combination.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在很大程度上，人工智能是一系列不同的方法和领域。在某些情况下，它们可以独立工作。在其他情况下，则存在组合。
- en: A subset of AI is ML, which is where a computer learns from data. The ML algorithms
    find the patterns in the data and use these as the basis for predictions. Generally,
    the more data, the better—especially if it is high quality. Some of the common
    use cases for ML include fraud detection, predictive analytics, and recommendation
    engines.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的一个子集是机器学习，这是计算机从数据中学习的地方。机器学习算法在数据中找到模式，并以此作为预测的基础。一般来说，数据越多越好——尤其是如果它是高质量的话。机器学习的常见用例包括欺诈检测、预测分析和推荐引擎。
- en: Next, a subset of ML is *deep learning*. This is a flavor of ML that uses neural
    networks. These are essentially modeled on the human brain. The processing of
    data is based on analyzing data across layers and connections. This can often
    detect complex patterns and relationships. In some cases, they do what humans
    are not able to do. Thanks to deep learning, we have seen advances in categories
    like speech processing, NLP, and image recognition.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，机器学习的一个子集是*深度学习*。这是一种使用神经网络的机器学习类型。这些网络本质上是以人类大脑为模型构建的。数据处理基于分析跨层和连接的数据。这通常可以检测到复杂的模式和关系。在某些情况下，它们可以做到人类无法做到的事情。得益于深度学习，我们在语音处理、自然语言处理和图像识别等领域取得了进步。
- en: A subset of deep learning is generative AI. This is at the cutting-edge of AI.
    It’s what powers breakout applications like OpenAI’s ChatGPT and Anthropic’s Claude.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个子集是生成式AI。这是人工智能的前沿。它是OpenAI的ChatGPT和Anthropic的Claude等突破性应用背后的动力。
- en: A generative AI model also processes data, but the scale is usually massive.
    With this, it can create new content like text, software code, images, audio,
    and video. It can often seem humanlike.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型也会处理数据，但规模通常很大。有了这个，它可以创建新的内容，如文本、软件代码、图像、音频和视频。它常常看起来像人类。
- en: Even though generative AI is powerful, it is not a silver bullet. Sometimes
    it’s better to use ML or deep learning, depending on the use case and requirements.
    Knowing some of these is important for the book.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式AI很强大，但它并不是万能的。有时根据用例和需求，使用机器学习或深度学习会更好。了解这些内容对于本书很重要。
- en: Machine Learning
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: During the 1950s and 1960s, Arthur Samuel was a noted computer scientist and
    researcher at IBM. He created one of the first pioneering AI applications, which
    learned how to play checkers. He also coined *machine learning*, which he [defined](https://oreil.ly/l32nO)
    as “the field of study that gives computers the ability to learn without explicitly
    being programmed.”
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪50年代和60年代，亚瑟·萨缪尔是IBM的一名著名计算机科学家和研究员。他创造了第一个开创性的AI应用，这个应用学会了如何下国际象棋。他还提出了*机器学习*这一概念，他将它[定义为](https://oreil.ly/l32nO)“一个研究领域，它赋予计算机在没有明确编程的情况下学习的能力。”
- en: 'To understand this, let’s walk through an example. Suppose you’re working at
    a real estate agency, and you want to predict how much house 5 in [Table 3-1](#table_three_onedot_house_values_example)
    will sell for. You know that many factors go into pricing: location, the size
    of the house, the number of bedrooms, and how close it is to good schools. Instead
    of trying to create a long list of rules for calculating prices, you can use ML
    to handle the heavy lifting.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们通过一个例子来了解一下。假设你在一个房地产代理机构工作，你想预测[表3-1](#table_three_onedot_house_values_example)中房屋5的销售价格。你知道有很多因素会影响定价：位置、房屋大小、卧室数量以及它离好学校的远近。与其试图创建一个长长的规则列表来计算价格，你不如使用机器学习来处理这项繁重的工作。
- en: Table 3-1\. House values example
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1. 房屋价值示例
- en: '| House | Location | Size (in sq. ft.) | Number of bedrooms | Price |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 房屋 | 位置 | 面积（平方英尺） | 卧室数量 | 价格 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1 | Tier 1 | 500 | 1 | $500,000 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 一级 | 500 | 1 | $500,000 |'
- en: '| 2 | Tier 2 | 500 | 1 | $350,000 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 二级 | 500 | 1 | $350,000 |'
- en: '| 3 | Tier 2 | 1,000 | 2 | $700,000 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 二级 | 1,000 | 2 | $700,000 |'
- en: '| 4 | Tier 2 | 1,500 | 3 | $1,500,000 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 二级 | 1,500 | 3 | $1,500,000 |'
- en: '| 5 | Tier 1 | 1,000 | 2 | To be predicted |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 一级 | 1,000 | 2 | 待预测 |'
- en: 'Here’s how it works: you gather a bunch of data on homes—maybe thousands of
    records—including details about their features and their actual sale prices. Then,
    you feed all of this into an ML algorithm. It analyzes the data and learns the
    patterns. For example, it might understand that homes in a certain neighborhood
    are worth more or that every extra bedroom adds a specific amount to the price.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何工作的：你收集一大堆关于房屋的数据——可能包括数千条记录，包括它们的特征和实际销售价格。然后，你将所有这些数据输入到机器学习算法中。它分析数据并学习模式。例如，它可能理解某个地区的房屋价值更高，或者每个额外的卧室都会增加特定的价格。
- en: Once the algorithm is trained, it’s ready to make predictions. Even though it’s
    never seen house 5 before, the model can estimate its price based on what it learned
    from the previous data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦算法被训练，它就准备好进行预测。即使它以前从未见过房子5，该模型也可以根据从先前数据中学到的知识来估计其价格。
- en: That’s the beauty of machine learning. It lets computers learn from data and
    improve over time, instead of relying on hard-coded rules.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是机器学习的美丽之处。它让计算机从数据中学习并随着时间的推移而改进，而不是依赖于硬编码的规则。
- en: Amazon SageMaker
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon SageMaker
- en: In this chapter, we’ll explore Amazon SageMaker, which is a platform for anyone
    working with ML on AWS. SageMaker is powerful, but with so many tools and features,
    it can feel overwhelming at first. This is why we’ll start with a high-level overview
    to make the components easier to understand.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨Amazon SageMaker，这是一个适用于在AWS上使用机器学习的任何人的平台。SageMaker功能强大，但由于工具和功能众多，一开始可能会感到不知所措。这就是为什么我们将从高级概述开始，以便更容易理解组件。
- en: Amazon SageMaker is a fully managed service that helps you build, train, and
    deploy ML models at scale. Instead of worrying about setting up infrastructure,
    you can focus on what matters most—developing and improving your models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker是一项全面管理的服务，可帮助您大规模地构建、训练和部署机器学习模型。您无需担心设置基础设施，可以专注于最重要的事情——开发和改进您的模型。
- en: SageMaker supports the entire ML lifecycle, from preparing data to monitoring
    deployed models. It also integrates smoothly with other AWS services like Amazon
    S3, Amazon Redshift, and Kinesis.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker支持整个机器学习生命周期，从准备数据到监控已部署的模型。它还与其他AWS服务（如Amazon S3、Amazon Redshift和Kinesis）无缝集成。
- en: '[Figure 3-2](#figure_three_twodot_key_components_of_s) shows the key components
    that make up the SageMaker ecosystem.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-2](#figure_three_twodot_key_components_of_s)显示了构成SageMaker生态系统的关键组件。'
- en: '![](assets/awsc_0302.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0302.png)'
- en: Figure 3-2\. Key components of SageMaker
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2\. SageMaker的关键组件
- en: 'Let’s look at each component (we’ll also cover these in more detail in this
    chapter):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个组件（我们将在本章中更详细地介绍这些内容）：
- en: SageMaker Studio Classic
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio Classic
- en: A web-based development environment where you can manage every step of your
    ML workflow in one place. It supports team collaboration and automation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基于Web的开发环境，您可以在一个地方管理机器学习工作流程的每个步骤。它支持团队协作和自动化。
- en: Notebook instances
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本实例
- en: Managed Jupyter notebooks for writing code, running experiments, and visualizing
    results—no setup required.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 管理Jupyter笔记本，用于编写代码、运行实验和可视化结果——无需设置。
- en: JumpStart
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 快速启动
- en: A library of pretrained models and built-in algorithms to help you get started
    quickly or fine-tune models for your specific use case.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个预训练模型和内置算法库，帮助您快速入门或针对特定用例微调模型。
- en: Data Wrangler
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理器
- en: A tool for cleaning, transforming, and exploring data. It connects to over 50
    data sources, making preprocessing faster and easier.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于清理、转换和探索数据的工具。它连接超过50个数据源，使预处理更快、更简单。
- en: Model Monitor
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 模型监控器
- en: Keeps an eye on deployed models, automatically detecting issues like data drift
    or declining performance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 关注已部署的模型，自动检测数据漂移或性能下降等问题。
- en: MLOps tools
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps工具
- en: Includes services to manage ML workflows with automation, governance, and version
    control.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 包括管理机器学习工作流程的服务，具有自动化、治理和版本控制功能。
- en: SageMaker is built for flexibility and scale. There are also strong systems
    for security, compliance, and access controls.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker旨在提供灵活性和可扩展性。同时，它还拥有强大的安全、合规性和访问控制系统。
- en: The ML Lifecycle
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习生命周期
- en: 'The ML lifecycle is a fancy way of describing the process for building AI systems.
    There is no right way to do this, as there are various approaches and flavors.
    But AWS does offer its own flow, which includes the following steps:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期是一种描述构建人工智能系统过程的术语。没有一种正确的方法来做这件事，因为存在各种方法和风味。但AWS确实提供自己的流程，包括以下步骤：
- en: Business goal identification
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业目标识别
- en: ML problem framing
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习问题界定
- en: Data processing
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理
- en: Model development
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型开发
- en: Model deployment
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型部署
- en: Monitoring
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控
- en: Let’s go through each of these steps.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析这些步骤。
- en: Business Goal Identification
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业目标识别
- en: 'The first step in the ML lifecycle is about answering a straightforward question:
    What’s the goal of the project? Usually, it’s senior leaders and managers who
    hammer out the key details and make the final decision. They have the authority
    and budget to make things happen. When it comes to AI, these projects can be expensive.
    They are also often considered strategic for a company.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期中的第一步是回答一个简单的问题：项目的目标是什么？通常，这是高级领导和经理们敲定关键细节并做出最终决定的时候。他们有权力和预算来实现这些事情。当涉及到人工智能时，这些项目可能非常昂贵。它们通常也被认为对公司具有战略意义。
- en: A plan may not necessarily be detailed. For example, it could be a PowerPoint
    with 5 to 10 slides or so. However, it should be clear what the goal is. A way
    to express this is with key performance indicators (KPIs), which are the metrics
    to measure whether the ML project is hitting its mark or not.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 计划可能不一定很详细。例如，它可能是一个包含5到10张幻灯片的PowerPoint演示文稿。然而，目标应该是清晰的。一种表达方式是使用关键绩效指标（KPI），这些是衡量机器学习项目是否达到目标的标准。
- en: For example, suppose you work at a traditional retail company. During the past
    year, there have been problems with customer churn. However, you believe that
    AI can help solve the problem. You work with senior executives but also include
    domain experts in the organization, such as from the customer success department.
    From all this, you and the team come up with the KPI to reduce churn by 15% in
    the next year and set aside a budget of $200,000 for building and deploying the
    ML model.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你在一家传统零售公司工作。在过去的一年里，客户流失问题一直存在。然而，你相信人工智能可以帮助解决这个问题。你与高级管理人员合作，同时也包括组织内的领域专家，例如来自客户成功部门的专家。通过所有这些，你和团队提出了在明年将客户流失率降低15%的KPI，并预留了20万美元的预算用于构建和部署机器学习模型。
- en: This is not to imply that this KPI is set in stone. It may need to be adjusted
    because of the complexities of AI. This is especially the case for organizations
    that do not have much or any experience with AI projects. Regardless, it’s important
    to set specific KPIs to help guide the project and provide for accountability.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说这个KPI是固定不变的。由于人工智能的复杂性，它可能需要调整。这对于没有太多或没有人工智能项目经验的组织尤其如此。无论如何，设定具体的KPI对于指导项目并提供问责制非常重要。
- en: ML Problem Framing
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习问题界定
- en: After you’ve settled on a business objective, the next step is to translate
    this into something that ML can handle. This is known as ML *problem framing*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定业务目标后，下一步是将这些目标转化为机器学习可以处理的内容。这被称为机器学习*问题界定*。
- en: This stage of the process involves a team of technical experts, such as data
    scientists, data engineers, and ML architects. There are also subject matter experts
    (SMEs), who have a strong understanding of a particular process in an organization
    or industry-specific expertise.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程阶段涉及一个技术专家团队，例如数据科学家、数据工程师和机器学习架构师。还有主题领域专家（SMEs），他们对组织或特定行业的某个流程有深入的理解或专业知识。
- en: It’s important that this team take an open-minded approach. The fact is that
    ML may not be the right solution—or any other AI technique. Rather, a problem
    could be solved by using traditional data analytics or process automation.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个团队采取开放心态非常重要。事实上，机器学习可能不是正确的解决方案——或者任何其他人工智能技术。相反，一个问题可能可以通过使用传统数据分析或流程自动化来解决。
- en: 'However, if ML is the right choice, then there needs to be an evaluation of
    important factors like:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果机器学习是正确的选择，那么需要对以下重要因素进行评估：
- en: Is there quality data for the ML model?
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于机器学习模型，是否有质量数据？
- en: Does the organization have the skills needed for success for the project?
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织是否拥有实现项目成功的所需技能？
- en: Are there enough resources?
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有足够的资源？
- en: 'For example, suppose a healthcare company wants to predict patient readmission
    rates to improve care and reduce costs. The business problem is clear: fewer readmissions
    lead to better outcomes and lower expenses. During ML problem framing, the team
    decides that this can be formulated as a classification problem. The goal is to
    predict whether a patient is likely to be readmitted within 30 days after discharge.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设一家医疗保健公司希望预测患者再入院率以改善护理和降低成本。业务问题是明确的：减少再入院次数可以带来更好的结果和更低的费用。在机器学习问题界定过程中，团队决定可以将这个问题表述为一个分类问题。目标是预测患者是否可能在出院后30天内再次入院。
- en: 'However, it’s equally important to recognize situations where ML may not be
    the right solution. For instance, if the task can be solved using a straightforward
    rule-based system—like calculating a patient’s BMI from weight and height—then
    ML introduces unnecessary complexity. In such cases, traditional programming is
    faster, cheaper, and easier to maintain. Similarly, ML may not be suitable when
    full transparency and explainability are nonnegotiable. In regulatory-heavy environments
    such as healthcare or finance, decisions affecting patient eligibility or loan
    approval may demand a clear, auditable logic path—something that many ML models,
    especially deep learning ones, struggle to provide. Before jumping into model
    development, teams should ask: Can a rules engine handle this? And will we be
    able to confidently explain the output to users or auditors? If the answer is
    no, machine learning may not be the right tool for the job.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，识别出机器学习可能不是正确解决方案的情况同样重要。例如，如果任务可以通过简单的基于规则的系统解决——比如从体重和身高计算患者的BMI——那么机器学习引入了不必要的复杂性。在这种情况下，传统的编程更快、更便宜，且更容易维护。同样，当需要完全透明和可解释性时，机器学习可能不适用。在监管严格的领域，如医疗保健或金融，影响患者资格或贷款批准的决定可能需要清晰的、可审计的逻辑路径——这是许多机器学习模型，尤其是深度学习模型，难以提供的。在开始模型开发之前，团队应该问自己：规则引擎可以处理这个问题吗？我们能否自信地向用户或审计员解释输出结果？如果答案是“不”，那么机器学习可能不是完成这项工作的正确工具。
- en: After this, the team will evaluate the data requirements. In this case, there
    will likely need to be historical patient records, discharge summaries, and demographic
    details. Are these available? And if they are, does the team have the right to
    use the data?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，团队将评估数据需求。在这种情况下，可能需要历史患者记录、出院总结和人口统计细节。这些数据是否可用？如果可用，团队是否有权使用这些数据？
- en: In the meantime, there needs to be a focus on putting together the team to carry
    out the project. However, there may not be enough employees. In this case, there
    needs to be a realistic analysis of what it would take to hire people or bring
    on contractors. How long would this take? What are the costs?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，需要关注组建团队以执行项目。然而，可能没有足够的员工。在这种情况下，需要对招聘人员或聘请承包商所需的时间和成本进行现实分析。这需要多长时间？成本是多少？
- en: This process can take some time, but it is well worth the effort. It can greatly
    mitigate the potential for failure of an ML project.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可能需要一些时间，但这是值得的。它可以大大降低机器学习项目失败的可能性。
- en: Data Processing
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据处理
- en: 'Data processing is about converting data into a usable format. This includes
    these main steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理是将数据转换为可用格式的过程。这包括以下主要步骤：
- en: Data collection and integration
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集和整合
- en: Data preprocessing
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Feature engineering, which is the process of selecting, creating, or modifying
    input variables (features) to improve model performance by making the data more
    meaningful and predictive
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程，这是一个选择、创建或修改输入变量（特征）的过程，通过使数据更具意义和预测性来提高模型性能。
- en: Data visualization
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可视化
- en: We’ll cover each of these steps in the next few sections.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的几节中介绍这些步骤。
- en: Data collection and integration
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集和整合
- en: When collecting and integrating data for an ML project, you want to have it
    in a central place. This helps to streamline the process, providing for more consistency,
    accuracy, and speed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集和整合机器学习项目所需的数据时，您希望将其集中在一个地方。这有助于简化流程，提供更多的一致性、准确性和速度。
- en: With AWS, there is the advantage of using different types of data stores like
    Amazon S3 and Amazon EBS, which we covered in [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).
    For more sophisticated workloads, you can use data warehouses. These can store
    large amounts of structured data from many sources. Amazon Redshift has this capability.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AWS，您可以使用不同类型的数据存储，如Amazon S3和Amazon EBS，这些我们在[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)中已经介绍过。对于更复杂的工作负载，您可以使用数据仓库。这些可以存储来自许多来源的大量结构化数据。Amazon
    Redshift具有这种能力。
- en: Or you can use a lakehouse. This is a modern architecture for storage, which
    stores any type of data. Amazon SageMaker Lakehouse exemplifies this by integrating
    Amazon S3 data lakes and Amazon Redshift data warehouses. This allows for access
    and management of diverse data types.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您可以使用湖仓。这是一种现代存储架构，可以存储任何类型的数据。Amazon SageMaker Lakehouse通过整合Amazon S3数据湖和Amazon
    Redshift数据仓库来体现这一点。这允许访问和管理多种数据类型。
- en: Then there is Kinesis. This is designed to handle large amounts of real-time
    data processing. While Kinesis is not a lakehouse, it integrates seamlessly into
    a lakehouse architecture.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是Kinesis。它被设计来处理大量实时数据处理。虽然Kinesis不是一个湖屋，但它可以无缝集成到湖屋架构中。
- en: 'Regardless of these storage options, the fact remains that all data is not
    created equal. Simply put, if your data is low quality, the results of the ML
    model will likely fall short. This goes to the famous rule of thumb: garbage in,
    garbage out. This is why it is critical to choose your data sources thoughtfully.
    Some questions to ask:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 无论这些存储选项如何，事实仍然是并非所有数据都是平等的。简单来说，如果你的数据质量低，机器学习模型的结果可能会不尽如人意。这遵循着著名的经验法则：垃圾进，垃圾出。这就是为什么选择数据源时必须深思熟虑。以下是一些需要提出的问题：
- en: Does the data relate to the problem to be solved?
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否与要解决的问题相关？
- en: Is the data accurate?
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否准确？
- en: Is it diverse? Is it representative of the real world?
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是否多样化？它是否代表了现实世界？
- en: Is there enough data for the model?
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是否有足够的数据？
- en: Is the data up-to-date?
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否是最新的？
- en: 'It’s important to know that data comes in two main categories:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要知道数据主要分为两大类：
- en: Labeled data
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 标记数据
- en: This is where the data has a description. For instance, in a spam filter, emails
    are labeled as “spam” or “not spam.” These labels usually come from human input.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据有描述的地方。例如，在垃圾邮件过滤器中，电子邮件被标记为“垃圾邮件”或“非垃圾邮件”。这些标签通常来自人工输入。
- en: Unlabeled data
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 未标记数据
- en: This is raw data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是原始数据。
- en: 'There are also two formats of data:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也有两种格式：
- en: Structured data
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据
- en: This is organized data. The most common format is for rows and columns in a
    spreadsheet or database (which is also called *tabular data*). This type of data
    is certainly useful for ML projects. But structured data can also be expressed
    as time-series data. This is where it is collected over time, such as stock prices
    or weather information.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是组织良好的数据。最常见的形式是电子表格或数据库中的行和列（也称为*表格数据*）。这种类型的数据对于机器学习项目肯定很有用。但结构化数据也可以表示为时间序列数据。这是随着时间的推移收集的数据，例如股价或天气信息。
- en: Unstructured data
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: This data doesn’t have a predefined format. Examples of this include text, images,
    audio, and video. To make sense of it, you’ll need more advanced AI techniques
    to uncover patterns and insights.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这类数据没有预定义的格式。例如，包括文本、图像、音频和视频。为了理解它，你需要更高级的AI技术来揭示模式和见解。
- en: Data preprocessing, feature engineering, and data visualization
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据预处理、特征工程和数据可视化
- en: Data is messy. Missing values, outliers, errors, and inconsistencies are common.
    To deal with these problems, there is data preprocessing or data preparation.
    But there’s a hitch—this process can be time-consuming and costly. According to
    a survey by Anaconda,^([1](ch03.html#ch01fn1)) data scientists spend about 45%
    of their time wrestling with these tasks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是杂乱的。缺失值、异常值、错误和不一致性很常见。为了处理这些问题，有数据预处理或数据准备。但有一个问题——这个过程可能既耗时又昂贵。根据Anaconda的调查，数据科学家大约花费45%的时间在这些任务上。
- en: Even when the data is cleaned up, there is more to do. The next step is feature
    engineering. This is where data scientists will determine the meaningful aspects
    of the data. The focus is on finding those values that have the biggest impact
    on accurate predictions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据已经被清理，还有更多的工作要做。下一步是特征工程。这是数据科学家确定数据有意义方面的地方。重点是找到那些对准确预测影响最大的值。
- en: To help with this, there is data visualization. Data scientists will try to
    get a better understanding of the dataset by using scatterplots, histograms, and
    box plots. This is known as exploratory data analysis (EDA).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助解决这个问题，有数据可视化。数据科学家将尝试通过使用散点图、直方图和箱线图来更好地理解数据集。这被称为探索性数据分析（EDA）。
- en: Data preprocessing, feature engineering, and data visualization can be labor-intensive.
    But with SageMaker you can use Data Wrangler to streamline the process. It provides
    access to all AWS data sources, but there are also integrations with 50+ third-party
    data providers, such as Snowflake and Databricks. Next, Data Wrangler verifies
    data quality and detects anomalies. This is done with 300+ built-in transformations.
    This means there is no need to learn tools like PySpark or Apache Spark. Data
    Wrangler also provides visualization templates and reports. What may take weeks—using
    traditional approaches—can take only minutes using Data Wrangler.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理、特征工程和数据可视化可能很费时。但使用SageMaker，您可以使用Data Wrangler来简化流程。它提供了对所有AWS数据源的访问，但也与50多个第三方数据提供商（如Snowflake和Databricks）进行了集成。接下来，Data
    Wrangler验证数据质量并检测异常。这是通过300多个内置转换来完成的。这意味着不需要学习像PySpark或Apache Spark这样的工具。Data
    Wrangler还提供可视化模板和报告。使用传统方法可能需要几周的时间，而使用Data Wrangler可能只需几分钟。
- en: Model Development
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: 'Model development has three main steps, which we’ll cover in the following
    sections:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发有三个主要步骤，我们将在以下章节中介绍：
- en: Training
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练
- en: Evaluation
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估
- en: Tuning
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调优
- en: Training
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: 'Training involves teaching a model to learn patterns and making predictions.
    This is based on using ML algorithms on datasets. The process is iterative, as
    it will require adjustments to the model parameters to improve the predictions
    of the model. There are three types of algorithms:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 训练涉及教会模型学习模式和做出预测。这是基于在数据集上使用机器学习算法。这个过程是迭代的，因为它将需要调整模型参数以改进模型的预测。有三种类型的算法：
- en: Supervised learning
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Unsupervised learning
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Reinforcement learning
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: 'Evaluating these types of models requires expertise in data science. There
    are rules of thumb as to which to use for certain use cases. We’ll look at these
    in the next few sections of this book. But before doing this, it’s important that
    the dataset is split up into three sections:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 评估这些类型的模型需要数据科学方面的专业知识。对于某些用例，有一些经验法则。我们将在本书的下一几个章节中探讨这些内容。但在做这件事之前，重要的是将数据集分成三个部分：
- en: Training data (70% to 80% of the dataset)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据（数据集的70%至80%）
- en: This is where you use the data with the ML algorithms to teach it to understand
    patterns and make predictions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在这里您使用数据与机器学习算法来教会它理解模式和做出预测的地方。
- en: Validating data (10% to 15%)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 验证数据（10%至15%）
- en: This is for tuning the data to get better performance.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了调整数据以获得更好的性能。
- en: Testing data (10% to 15%)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据（10%至15%）
- en: Here, the model is evaluated based on unseen data. This helps to provide a sense
    of how it may work with real-world applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，模型基于未见过的数据进行评估。这有助于提供一种感觉，了解它可能如何与实际应用相结合。
- en: Supervised learning
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监督学习
- en: In supervised learning, the model learns using labeled data. Basically, the
    labels act as a guide, helping the model understand the relationship between inputs
    and their matching outputs. Think of it as a teacher supervising a student—hence
    the name “supervised learning.” For example, let’s say there’s a dataset full
    of images of fruits, each labeled as an apple, banana, or orange. After training
    on this data, the model can take a new, unlabeled image of a banana and identify
    it correctly.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，模型使用标记数据来学习。基本上，标签充当指南，帮助模型理解输入与其匹配输出的关系。将其想象成一个老师监督学生——这就是“监督学习”这个名字的由来。例如，假设有一个包含大量水果图像的数据集，每个图像都被标记为苹果、香蕉或橙子。在训练这些数据后，模型可以正确识别一张新的、未标记的香蕉图像。
- en: 'Supervised learning can be divided into two main tasks: classification and
    regression.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习可以分为两个主要任务：分类和回归。
- en: '***Classification.*** Classification is about sorting data into predefined
    categories. The model learns patterns from labeled data so it can categorize new
    examples. An example is credit risk assessment. A classification model can analyze
    a loan applicant’s credit history, income, and debts to determine whether they
    fall into the “low risk” or “high risk” category. This helps financial institutions
    make smarter lending decisions.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '***分类。*** 分类是将数据分类到预定义类别的过程。模型从标记数据中学习模式，以便对新的例子进行分类。一个例子是信用风险评估。分类模型可以分析贷款申请人的信用记录、收入和债务，以确定他们是否属于“低风险”或“高风险”类别。这有助于金融机构做出更明智的贷款决策。'
- en: 'Other examples of classification include the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 其他分类的例子包括以下内容：
- en: Fraud detection
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欺诈检测
- en: Customer churn prediction
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户流失预测
- en: Image recognition
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像识别
- en: Medical diagnostics
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医学诊断
- en: Sentiment analysis
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析
- en: Spam filtering
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邮件过滤
- en: '***Regression.*** Regression refers to predicting continuous values rather
    than categories. It looks at the relationship between variables to make forecasts.
    Here are some examples of use cases:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**。回归是指预测连续值而不是类别。它通过观察变量之间的关系来进行预测。以下是一些用例示例：'
- en: Forecasting sales numbers
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测销售数量
- en: Estimating stock market trends
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估计股市趋势
- en: Predicting population growth
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测人口增长
- en: Calculating life expectancy
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算预期寿命
- en: 'Let’s take a more detailed look with an example. Suppose you are building an
    ML model to predict hourly energy consumption of a building. In the feature engineering
    stage, you determine the independent variables. These are values that are not
    changed by other values in the algorithm. For our example, we come up with the
    following:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子更详细地看看。假设你正在构建一个机器学习模型来预测建筑的每小时能耗。在特征工程阶段，你确定自变量。这些是算法中不受其他值影响的值。在我们的例子中，我们提出了以下内容：
- en: Outdoor temperature
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 室外温度
- en: Humidity levels
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 湿度水平
- en: Time of day
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 白天时间
- en: Day of the week
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期几
- en: Occupancy levels
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 占用率
- en: Historical energy consumption data
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 历史能耗数据
- en: Then we have the dependent variable. This is the value we are predicting in
    our ML model, which is the energy consumption or kWh (kilowatt-hour).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们有因变量。这是我们机器学习模型中预测的值，即能耗或千瓦时（kWh）。
- en: There are different types of regression algorithms like linear regression, random
    forest regression, or support vector regression (SVR). Then which one to use?
    Evaluation can be a complex process. You need to know the intricacies of the algorithms.
    But generally, when it comes to a regression model, it’s about understanding the
    relationship between the independent and dependent variables. In our example,
    the linear regression model would probably not be a good option. The reason is
    that it assumes a straight-line relationship between input features and the target
    variable, which may not capture the complex, nonlinear patterns often present
    in building energy consumption data. Rather, a random forest regression and SVR
    are better suited for modeling such complexities.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 存在着不同类型的回归算法，如线性回归、随机森林回归或支持向量回归（SVR）。那么应该使用哪一种呢？评估可能是一个复杂的过程。你需要了解算法的复杂性。但一般来说，当涉及到回归模型时，它关乎理解自变量和因变量之间的关系。在我们的例子中，线性回归模型可能不是一个好的选择。原因是它假设输入特征和目标变量之间存在线性关系，这可能无法捕捉到建筑能耗数据中常见的复杂、非线性模式。相反，随机森林回归和支持向量回归更适合模拟这种复杂性。
- en: Unsupervised learning
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning is where a model is trained on unlabeled datasets. The
    algorithms will analyze the structure of the data, such as to find the underlying
    patterns, groupings, and relationships. This is done without any prior guidance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是在未标记的数据集上训练模型。算法将分析数据的结构，例如寻找潜在的模式、分组和关系。这是在没有先验指导的情况下完成的。
- en: 'There are two main approaches to unsupervised learning:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习有两种主要方法：
- en: Clustering
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: Dimensionality reduction
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维度约简
- en: '***Clustering.*** Clustering groups data based on similarities. This is usually
    done by using a measurement technique. The closer two points are, the more similar
    they are. Here are common approaches to this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**。聚类根据相似性对数据进行分组。这通常是通过使用测量技术来完成的。两个点越接近，它们就越相似。以下是常见的这种方法：'
- en: Euclidean distance
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: This measures the straight-line distance between two points. It’s done in multidimensional
    space. This refers to areas that extend beyond the typical three dimensions of
    length, width, and height.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了两个点之间的直线距离。这是在多维空间中完成的。这指的是超出典型长度、宽度和高度三个维度的区域。
- en: Cosine similarity
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度
- en: This measures the angle between two points (the cosine). If the two are in the
    same direction, then they are similar.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了两个点之间的角度（余弦值）。如果两者方向相同，则它们是相似的。
- en: Manhattan distance
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿距离
- en: This is the sum of the absolute differences of two points. Yes, it’s based on
    how a taxicab navigates through a city grid.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这是两个点之间绝对差值的总和。是的，它基于出租车在城市网格中导航的方式。
- en: As for the algorithms for clustering, one of the most popular is *k*-means clustering.
    It often uses Euclidean distance to cluster the data points that are the closest.
    For example, a retail company can use *k*-means clustering to group customers
    based on the spending amount, product preferences, or purchase frequency. This
    can be used for more personalized marketing, say with relevant product selections
    and discounts.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 至于聚类算法，最流行的一种是*k*均值聚类。它通常使用欧几里得距离来聚类最近的数据点。例如，一家零售公司可以使用*k*均值聚类根据消费金额、产品偏好或购买频率来分组客户。这可以用于更个性化的营销，比如通过相关产品选择和折扣。
- en: Another algorithm for clustering is density-based spatial clustering of applications
    with noise (DBSCAN), which often uses Euclidean or Manhattan measurements. A common
    example of this is fraud detection. By using DBSCAN, outliers can be detected,
    which may indicate fraudulent behavior. It could find that generally the transactions
    are in the range of $100 to $200, with a few that are for more than $10,000.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种用于聚类的算法是基于密度的空间聚类应用噪声（DBSCAN），它通常使用欧几里得或曼哈顿测量。一个常见的例子是欺诈检测。通过使用DBSCAN，可以检测到异常值，这可能会表明欺诈行为。它可能会发现，通常交易额在100到200美元之间，只有少数超过10000美元。
- en: Amazon’s Random Cut Forest (RCF) algorithm is particularly effective for identifying
    outliers in financial transaction data. Unlike clustering algorithms that group
    similar data points, RCF focuses on detecting anomalies by assigning an anomaly
    score to each data point based on how easily it can be isolated. For instance,
    in a dataset where most transactions range between $100 and $200, an unexpected
    transaction of $10,000 would likely receive a high anomaly score, flagging it
    for further investigation.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊的随机切割森林（RCF）算法特别有效于识别金融交易数据中的异常值。与将相似数据点分组的聚类算法不同，RCF通过为每个数据点分配一个基于其如何容易隔离的异常分数来检测异常。例如，在一个大多数交易额在100到200美元之间的数据集中，一次意外的10000美元交易可能会得到一个很高的异常分数，从而将其标记为需要进一步调查。
- en: '***Dimensionality reduction.*** High-dimensional data is when a dataset has
    a large number of features. However, this can cause problems for ML models. This
    phenomenon is referred to as the “curse of dimensionality.”'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '***降维。***高维数据是指数据集具有大量特征。然而，这可能会给机器学习模型带来问题。这种现象被称为“维度诅咒”。'
- en: A typical issue with high-dimensional data is high computational costs. This
    requires more processing power, memory, and time to analyze the data.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 高维数据的一个典型问题是计算成本高。这需要更多的处理能力、内存和时间来分析数据。
- en: Next, there is the issue with overfitting, which is when an ML model learns
    too much from the training data and does not generalize well on unseen data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，是过拟合的问题，即机器学习模型从训练数据中学习太多，并且对未见过的数据泛化不好。
- en: To understand this, let’s take an example. Suppose we have a spam filter that
    has training data with a high frequency of the word *free*. Overfitting would
    mean that the model will detect spam, even though the word has many legitimate
    uses.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们举一个例子。假设我们有一个垃圾邮件过滤器，其训练数据中“免费”一词出现频率很高。过拟合意味着模型会检测到垃圾邮件，即使这个词有多个合法用途。
- en: To deal with these problems, you can use dimensionality reduction. Simply put,
    this is the process of reducing the number of features in a dataset, but the changes
    must not materially impact the dataset.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些问题，你可以使用降维。简单来说，这就是减少数据集中特征数量的过程，但变化不能对数据集产生实质性影响。
- en: Principal component analysis (PCA), t-SNE, and autoencoders are some of the
    other algorithms that can be used.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）、t-SNE和自动编码器是其他可以使用的算法。
- en: Reinforcement learning
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强化学习
- en: You did not use a guidebook or take lessons to ride a bike, right? Of course
    not. Instead, you watched others and then tried it yourself. There was lots of
    falling and some scraped knees and hands. But ultimately, you were able to figure
    it out. Riding a bike would soon become natural.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你没有使用指南书或上课程来骑自行车，对吧？当然没有。相反，你观察了别人，然后自己尝试。有很多摔倒，一些擦伤膝盖和手。但最终，你能够弄明白。骑自行车很快就会变得自然。
- en: This process is similar to reinforcement learning. This is how an ML model learns
    by trial and error—that is, there is positive and negative reinforcement based
    on interacting with an environment.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程与强化学习类似。这就是机器学习模型通过试错来学习的方式——也就是说，根据与环境的交互，存在正负强化。
- en: 'Reinforcement learning has been shown to be particularly effective with:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习已被证明在以下方面特别有效：
- en: Games
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏
- en: They have the benefit of clear rules, scores, and constraints (like a game board).
    With this environment, an ML model can run millions of simulations, which will
    allow for learning. This has been key for systems like AlphaGo, which beat the
    world champion of the game Go.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 它们具有清晰的规则、分数和约束（如游戏板）。在这个环境中，机器学习模型可以运行数百万次模拟，这将允许学习。这对于像AlphaGo这样的系统至关重要，它击败了围棋的世界冠军。
- en: Robotics
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人
- en: Since robotics navigate in the real world, reinforcement learning can allow
    these systems to understand their environment.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器人需要在现实世界中导航，强化学习可以使这些系统理解其环境。
- en: The three types of ML learning—supervised learning, unsupervised learning, and
    reinforcement learning—are shown in [Figure 3-3](#figure_three_threedot_the_three_main_ty).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的三种学习类型——监督学习、无监督学习和强化学习——在[图3-3](#figure_three_threedot_the_three_main_ty)中展示。
- en: '![](assets/awsc_0303.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0303.png)'
- en: Figure 3-3\. The three main types of ways for machines to learn using ML
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. 机器学习用于学习的三种主要方式
- en: Using AWS for model development
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用AWS进行模型开发
- en: Model development in ML involves the process of designing, training, and refining
    algorithms to analyze data and make predictions or decisions. This includes selecting
    appropriate models, preparing data, training the models, and evaluating their
    performance to ensure they meet the desired objectives.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的模型开发涉及设计、训练和改进算法的过程，以分析数据并做出预测或决策。这包括选择合适的模型、准备数据、训练模型以及评估其性能，以确保它们满足预期的目标。
- en: 'With Amazon SageMaker, there are three main options for model development:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker，模型开发有三个主要选项：
- en: Pretrained models
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型
- en: There are hundreds of pretrained models available, which require little fine-tuning
    or configuration. You can access them using SageMaker JumpStart (see [Figure 3-4](#figure_three_fourdot_foundation_models)).
    FMs, computer vision models, and NLP models are available.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 有数百个预训练模型可供使用，这些模型需要很少的微调或配置。你可以使用SageMaker JumpStart（见[图3-4](#figure_three_fourdot_foundation_models)）访问它们。FMs、计算机视觉模型和NLP模型都可用。
- en: '![](assets/awsc_0304.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0304.png)'
- en: Figure 3-4\. Foundation models section of the SageMaker JumpStart dashboard
    for pretrained models
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-4\. SageMaker JumpStart仪表板中预训练模型的基础模型部分
- en: Built-in algorithms
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 内置算法
- en: These are tailored for large datasets and where there is a need for scalability
    and performance optimization.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是为大型数据集和需要可扩展性和性能优化而量身定制的。
- en: Docker images
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Docker镜像
- en: Docker images are for popular ML frameworks like TensorFlow, PyTorch, and scikit-learn.
    There are also images for your own models. This is when you want customization.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Docker镜像适用于流行的机器学习框架，如TensorFlow、PyTorch和scikit-learn。也有为你自己的模型准备的镜像。这就是你想要定制的时候。
- en: Evaluation
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估
- en: 'Before a model goes into production, there needs to be extensive evaluation
    of the performance. There are various metrics for this, and many of these depend
    on the type of model you use. The metrics are not foolproof but provide general
    guidance. We’ll take a look at the following metrics:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型投入生产之前，需要对性能进行广泛的评估。这里有各种指标，其中许多取决于你使用的模型类型。这些指标并非万无一失，但提供了一般性的指导。我们将查看以下指标：
- en: Model fit
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型拟合
- en: Classification
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Regression
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Model fit
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型拟合
- en: Model fit refers to how well a model captures patterns in the data. The goal
    is to strike a balance between overfitting and underfitting to achieve optimal
    accuracy.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 模型拟合指的是模型捕捉数据中模式的好坏。目标是平衡过拟合和欠拟合，以实现最佳精度。
- en: 'To mitigate overfitting, you can:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻过拟合，你可以：
- en: Reduce the number of features.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少特征数量。
- en: Increase the size of the training dataset.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加训练数据集的大小。
- en: Apply regularization techniques like L1 (lasso regression) and L2 (ridge regression)
    to simplify the model.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用正则化技术，如L1（lasso回归）和L2（ridge回归）以简化模型。
- en: Underfitting happens when a model is too simple to capture the underlying patterns
    in the data. For example, if you’re building a model to recognize handwritten
    digits and use logistic regression, it may struggle because handwritten digits
    have complex, nonlinear patterns. In such cases, a more complex algorithm, like
    a neural network or decision tree, may be more appropriate.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型过于简单，无法捕捉数据中的潜在模式时，就会发生欠拟合。例如，如果你正在构建一个用于识别手写数字的模型并使用逻辑回归，它可能会因为手写数字具有复杂、非线性的模式而难以处理。在这种情况下，更复杂的算法，如神经网络或决策树，可能更合适。
- en: There are other causes of underfitting. One is that the data does not have enough
    features. There may also be too few iterations—or epochs—for the training.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他导致欠拟合的原因。其中一个原因是数据特征不足。也可能是因为训练迭代（或epoch）太少。
- en: To measure overfitting and underfitting, you can use bias and variance, which
    are statistical calculations. Bias is the difference between the average predicted
    values and actual values. It’s a way to gauge a model’s tendency to make errors
    based on simplistic assumptions, which means there is underfitting.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量过拟合和欠拟合，你可以使用偏差和方差，这些都是统计计算。偏差是平均预测值与实际值之间的差异。它是衡量模型基于简单假设犯错误倾向的一种方法，这意味着存在欠拟合。
- en: Variance, on the other hand, measures the fluctuations in the predicted values.
    A high variance means that the model is sensitive to small changes in the training,
    which can indicate overfitting.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，方差衡量的是预测值的波动。高方差意味着模型对训练中的微小变化很敏感，这可能表明过拟合。
- en: Again, the goal is to strike a balance—that is, to have a model with low bias
    and low variance.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，目标是找到一个平衡点——也就是说，要有一个低偏差和低方差的模型。
- en: Classification
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类
- en: Classification metrics are used to measure the performance of ML models that
    assign labels to data points. These metrics help evaluate how accurately a model
    makes predictions and where it might be going wrong. For example, if you’re developing
    a model to predict whether a patient has a certain disease based on medical test
    results, classification metrics can show how often the model makes correct diagnoses,
    misses true cases, or raises false alarms.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 分类指标用于衡量将标签分配给数据点的机器学习模型的性能。这些指标有助于评估模型预测的准确性以及它可能出错的地方。例如，如果你正在开发一个基于医学测试结果预测患者是否患有某种疾病的模型，分类指标可以显示模型做出正确诊断的频率、错过真实案例或发出虚假警报的频率。
- en: 'For a classification problem, you can evaluate the model by using techniques
    like the following:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，你可以使用以下技术来评估模型：
- en: Confusion matrix
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Accuracy
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率
- en: Precision
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率
- en: Recall
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率
- en: Area under the curve-receiver operating curve (AUC-ROC)
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曲线下面积-接收者操作特征曲线 (AUC-ROC)
- en: To understand these metrics, we’ll use an example. Suppose you are building
    an ML model to detect credit card fraud. It will use the binary classification
    approach, which will indicate whether a transaction is either fraudulent or legitimate.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些指标，我们将使用一个例子。假设你正在构建一个机器学习模型来检测信用卡欺诈。它将使用二元分类方法，这将指示交易是欺诈还是合法。
- en: Let’s next apply the metrics.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们应用这些指标。
- en: '***Confusion matrix.*** A confusion matrix is a way to understand the reasons
    why an outcome of an ML model is wrong. After the training is complete, you will
    get the number of occurrences of true positives, false positives, false negatives,
    and true negatives (see [Table 3-2](#table_three_twodot_confusion_matrix_for)).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '***混淆矩阵。*** 混淆矩阵是一种理解机器学习模型结果错误原因的方法。训练完成后，你会得到真正例、假正例、假反例和真反例的数量（见[表3-2](#table_three_twodot_confusion_matrix_for)）。'
- en: Table 3-2\. Confusion matrix for a fraud deduction ML model
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-2. 欺诈扣除机器学习模型的混淆矩阵
- en: '| Actual/predicted values | Fraudulent (positive) | Legitimate (negative) |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 实际/预测值 | 欺诈（正类） | 合法（负类） |'
- en: '| --- | --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Fraudulent | 70 | 30 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 欺诈 | 70 | 30 |'
- en: '| Legitimate | 20 | 880 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 合法 | 20 | 880 |'
- en: 'Let’s analyze this confusion matrix:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析这个混淆矩阵：
- en: True positives
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 真正例
- en: 70 transactions classified as fraudulent.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 70笔交易被分类为欺诈。
- en: False negatives
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 假反例
- en: 30 fraudulent transactions incorrectly identified as legitimate.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 30笔欺诈交易被错误地识别为合法。
- en: False positives
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 假正例
- en: 20 legitimate transactions incorrectly identified as fraudulent.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 20笔合法交易被错误地识别为欺诈。
- en: True negatives (TN)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 真阴性 (TN)
- en: 880 transactions correctly classified as legitimate.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 880笔交易被正确分类为合法。
- en: The takeaway? While the model is effective in detecting fraud, there can be
    improvement in minimizing the false negative and false positives.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 吸取的教训？虽然该模型在检测欺诈方面很有效，但可以进一步减少假反例和假正例。
- en: Keep in mind that the confusion matrix is also the basis for calculating accuracy,
    precision, and recall.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，混淆矩阵也是计算准确率、精确率和召回率的基础。
- en: '***Accuracy.*** The accuracy of the model is also called the *score*. It is
    the sum of the correct predictions, which are divided by the number of predictions.
    In our credit card fraud example, the accuracy is 95%:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '***准确率。*** 模型的准确率也称为**得分**。它是正确预测的总和，除以预测的总数。在我们的信用卡欺诈示例中，准确率是95%：'
- en: True positives (TP) = 70
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性 (TP) = 70
- en: False negatives (FN) = 30
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性 (FN) = 30
- en: False positives (FP) = 20
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性 (FP) = 20
- en: True negatives (TN) = 880
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阴性 (TN) = 880
- en: Accuracy = (TP + TN) / (TP + FN + FP + TN)
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率 = (TP + TN) / (TP + FN + FP + TN)
- en: = (70 + 880) / (70 + 30 + 20 + 880) = 950 / 1000 = 95%
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: = (70 + 880) / (70 + 30 + 20 + 880) = 950 / 1000 = 95%
- en: But this metric can be deceiving. It can be less useful when there are many
    true negatives in the dataset. This is why it’s important to use several metrics
    when evaluating a model.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个指标可能会误导。当数据集中有许多真实负例时，它可能不那么有用。这就是为什么在评估模型时使用多个指标很重要。
- en: '***Precision.*** Precision focuses on the true and false positives. That is,
    it is calculated as the number of true positives divided by the true positives
    and false positives. For our credit card fraud example, the precision is 77.8%:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '***精确率。*** 精确率关注真阳性和假阳性。也就是说，它是真阳性数除以真阳性和假阳性的总和。在我们的信用卡欺诈示例中，精确率是77.8%：'
- en: 70 / (70 + 20)
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 70 / (70 + 20)
- en: Generally, precision is useful when the cost of false positives is high. This
    is certainly the case with fraud detection. If a false positive happens when a
    transaction is legitimate—tagging it as fraudulent—this can lead to lower customer
    satisfaction. Or if a false negative occurs—where the machine learning model classifies
    a fraudulent transaction as legitimate—it can lead to financial losses.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当假阳性的成本较高时，精确度是有用的。这在欺诈检测中肯定是这样。如果一个假阳性发生在合法交易时——将其标记为欺诈——这可能导致客户满意度降低。或者如果发生假阴性——机器学习模型将欺诈交易分类为合法——这可能导致经济损失。
- en: '***Recall.*** With recall, the focus is the positives for the confusion matrix.
    It’s calculated as the true positives divided by the sum of the true positives
    and false negatives. For our credit card fraud example, it’s 70%:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '***召回率。*** 召回率关注混淆矩阵中的正例。它是真阳性除以真阳性和假阴性的总和。在我们的信用卡欺诈示例中，召回率是70%：'
- en: 70 / (70 + 30)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 70 / (70 + 30)
- en: This essentially measures a model’s ability to classify actual fraudulent transactions.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上衡量了一个模型分类实际欺诈交易的能力。
- en: '***Area under the curve-receiver operating curve (AUC-ROC).*** AUC-ROC plots
    the recall against the false positive rate, as shown in [Figure 3-5](#figure_three_fivedot_the_curve_receiver).
    This is done at different threshold settings. For example, with our credit card
    fraud example, we could have a lower threshold. This means that more transactions
    will be classified as fraudulent, which will increase the detection rate of actual
    frauds or true positives. Or we could do the opposite. It depends on the goals
    and requirements.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '***曲线下面积-接收机操作曲线 (AUC-ROC)。*** AUC-ROC图显示了召回率与假阳性率的关系，如图[图3-5](#figure_three_fivedot_the_curve_receiver)所示。这是在不同的阈值设置下完成的。例如，在我们的信用卡欺诈示例中，我们可以设置一个较低的阈值。这意味着更多的交易将被分类为欺诈，这将提高实际欺诈或真阳性的检测率。或者我们可以做相反的事情。这取决于目标和要求。'
- en: Generally, the higher the AUC, the better the model is at distinguishing between
    fraudulent and legitimate transactions. An AUC close to 1.0 indicates strong performance,
    while an AUC near 0.5 means the model isn’t much better than random guessing.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，AUC越高，模型在区分欺诈和合法交易方面的能力越好。接近1.0的AUC表示性能良好，而接近0.5的AUC意味着模型并不比随机猜测好多少。
- en: '![The curve-receiver operating curve (AUC-ROC)](assets/awsc_0305.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![曲线接收机操作曲线 (AUC-ROC)](assets/awsc_0305.png)'
- en: Figure 3-5\. The curve-receiver operating curve (AUC-ROC)
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-5. 曲线接收机操作曲线 (AUC-ROC)
- en: Regression
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回归
- en: 'There are numerous metrics for regression. But for purposes of the exam, you
    should focus on these two: mean squared error (MSE) and R squared (R²).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归，有许多指标。但为了考试的目的，您应该关注这两个：均方误差（MSE）和R平方（R²）。
- en: Of these two, MSE is generally the most common.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个指标中，均方误差（MSE）通常是最常见的。
- en: '***Mean squared error.*** With MSE, you compare the differences between the
    predictions and actual outcomes. To calculate it, you square each difference,
    sum them, and take the average.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '***均方误差。*** 使用均方误差（MSE）时，您比较预测值和实际结果之间的差异。为了计算它，您将每个差异平方，求和，然后取平均值。'
- en: Suppose you are creating a regression model to predict annual salaries based
    on an employee’s experience with the company. [Table 3-3](#table_three_threedot_regression_model_f)
    shows the data.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在创建一个回归模型，根据员工在公司的工作经验预测年薪。[表3-3](#table_three_threedot_regression_model_f)显示了数据。
- en: Table 3-3\. Regression model for salaries
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-3. 薪资回归模型
- en: '| Employee ID | Years of experience | Actual salary ($1,000s) | Predicted salary
    ($1,000s) | Error (actual/predicted) | Squared error |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 员工ID | 工作经验年数 | 实际薪资（千美元） | 预测薪资（千美元） | 误差（实际/预测） | 平方误差 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 2 | 50 | 55 | –5 | 25 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 50 | 55 | –5 | 25 |'
- en: '| 2 | 5 | 80 | 75 | 5 | 25 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 5 | 80 | 75 | 5 | 25 |'
- en: '| 3 | 7 | 100 | 95 | 5 | 25 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 7 | 100 | 95 | 5 | 25 |'
- en: '| 4 | 10 | 150 | 140 | 10 | 100 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 10 | 150 | 140 | 10 | 100 |'
- en: '| 5 | 12 | 150 | 140 | 10 | 100 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 12 | 150 | 140 | 10 | 100 |'
- en: Based on this, the MSE is 40\. What does this mean? It’s the average of the
    square difference between the predicted and actual values. Generally, the lower
    this is, the more accurate the prediction.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个，均方误差是40。这意味着什么？这是预测值和实际值之间平方差的平均值。一般来说，这个值越低，预测越准确。
- en: '***R squared.*** R² is a value from 0 to 1\. It shows how much of a regression
    model is explained by the variability of the prediction. The closer the value
    is to 1, the more accurate the model.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '***R平方。*** R²是一个介于0到1之间的值。它显示了回归模型中有多少是由预测的可变性解释的。该值越接近1，模型越准确。'
- en: But this also depends on the category. For example, a relatively lower R squared—such
    a 0.40 or 0.50—may be fine for social studies. But for physics and engineering,
    you would probably want something like 0.9 or higher.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 但这也取决于类别。例如，相对较低的R平方——比如0.40或0.50——对于社会科学来说可能就足够了。但对于物理和工程学，你可能希望得到0.9或更高的值。
- en: Tuning
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调优
- en: Tuning is the process of adjusting a model’s parameters and settings to improve
    its performance. When you first train an ML model, the initial results are often
    underwhelming because the default settings may not capture the underlying patterns
    in the data or may not be well-suited to the specific problem. That’s why tuning
    is typically necessary—to refine the model so it can make more accurate predictions.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 调优是调整模型参数和设置以改进其性能的过程。当你第一次训练一个机器学习模型时，初始结果通常不尽人意，因为默认设置可能无法捕捉数据中的潜在模式，或者可能不适合特定问题。这就是为什么调优通常是必要的——为了细化模型，使其能够做出更准确的预测。
- en: 'One approach is hyperparameter optimization. A hyperparameter is a setting
    in an ML model, which is to control how it learns. This can be done by adjusting:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是超参数优化。超参数是机器学习模型中的一个设置，用于控制其学习方式。这可以通过调整以下内容来完成：
- en: Batch size
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理大小
- en: The number of training examples that are processed at a time
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一次处理的训练样本数量
- en: Learning rate
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率
- en: How quickly the model adapts to the new data
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 模型适应新数据的速度
- en: Neural network
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: The number and size of layers
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 层数的数量和大小
- en: How does a hyperparameter differ from a parameter? A parameter is learned during
    training, whereas a hyperparameter must be defined before the training and will
    remain fixed.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如何区分超参数和参数？参数是在训练过程中学习的，而超参数必须在训练之前定义，并且将保持固定。
- en: 'As for hyperparameter optimization, this is where you adjust the hyperparameter
    to improve the performance of the model. Keep in mind that even a small change
    can make a big difference. There are various methods to help with this:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 至于超参数优化，这是调整超参数以改进模型性能的地方。请注意，即使是微小的变化也可能产生重大影响。有各种方法可以帮助完成这项工作：
- en: Grid search
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索
- en: This is where you process multiple combinations of hyperparameters.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是处理多个超参数组合的地方。
- en: Random search
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索
- en: Process random combinations within defined ranges.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义的范围内处理随机组合。
- en: Bayesian optimization
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化
- en: Use probability models for the search.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 使用概率模型进行搜索。
- en: Optuna
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna
- en: This is a modern, open source optimization framework that uses a smarter sampling
    strategy to efficiently search the hyperparameter space. It’s known for being
    fast, flexible, and easy to integrate into Python-based ML workflows.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个现代的开源优化框架，它使用更智能的采样策略来高效地搜索超参数空间。它以其快速、灵活和易于集成到基于Python的机器学习工作流程而闻名。
- en: Model Deployment
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: 'When the ML model finally meets your requirements after the development phase,
    the next step is to put it into production. There are two main ways for this:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习模型在开发阶段满足你的要求后，下一步是将它投入生产。主要有两种方式可以实现这一点：
- en: Self-hosted API
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 自托管API
- en: This is when you deploy the ML model on your own IT infrastructure. This can
    be in a private cloud, on-premises, or a cloud platform, such as AWS. You will
    need to set up VMs, web servers, networking, storage, and databases.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这是指你在自己的IT基础设施上部署机器学习模型。这可以是私有云、本地或云平台，如AWS。你需要设置虚拟机、Web服务器、网络、存储和数据库。
- en: Managed API
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 管理API
- en: This is where a platform—like SageMaker—handles the infrastructure, deployment,
    and automatic scaling.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是平台（如SageMaker）处理基础设施、部署和自动扩展的地方。
- en: There are pros and cons for each option. With the self-hosted API, you have
    much more control. This can allow for customization, unique requirements, and
    implementing security. Then again, this option can be expensive and time-consuming.
    You will also need IT personnel who are experienced with infrastructure.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 每个选项都有利弊。使用自托管API，你拥有更多的控制权。这可以允许定制、满足独特需求并实施安全措施。然而，这个选项可能成本高昂且耗时。你还需要有经验的IT人员来处理基础设施。
- en: The managed API, on the other hand, is much more simplified. You can focus more
    time on building ML models, not managing the underlying infrastructure. The costs
    are usually lower as well. Then again, there is not as much flexibility.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，管理API要简单得多。你可以更多地专注于构建机器学习模型，而不是管理底层基础设施。成本通常也较低。然而，灵活性较低。
- en: Once deployed—whether through a self-hosted API or a managed platform like SageMaker—your
    model is ready for inferencing, making predictions based on new input data.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署——无论是通过自托管API还是像SageMaker这样的托管平台——你的模型就准备好进行推理，根据新的输入数据进行预测。
- en: 'There are different ways to do this. For example, with SageMaker you can do
    the following:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的方法来做这件事。例如，使用SageMaker，你可以做以下事情：
- en: Real-time inference
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 实时推理
- en: Use this when an ML application needs to act near instantaneously. This is for
    high-stakes use cases, such as self-driving cars, healthcare monitoring, and fraud
    detection.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当机器学习应用程序需要几乎即时行动时使用此功能。这适用于高风险用例，如自动驾驶汽车、医疗监控和欺诈检测。
- en: Batch transform
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 批量转换
- en: Batch transform is generally for large datasets that don’t require immediate
    responses. For instance, a marketing team might use batch transform to segment
    thousands of customers overnight, enabling targeted email campaigns the next morning.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 批量转换通常用于不需要立即响应的大数据集。例如，一个营销团队可能会使用批量转换在夜间将数千名客户进行细分，以便第二天早上进行定向电子邮件活动。
- en: Asynchronous inference
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 异步推理
- en: This is for large payloads or long-running jobs; for example, an image recognition
    app that analyzes high-resolution photos uploaded by users. While the image is
    being processed, the user can continue browsing the app without delay.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于大型负载或长时间运行的任务；例如，一个图像识别应用程序分析用户上传的高分辨率照片。在图像处理过程中，用户可以继续浏览应用程序而不会延迟。
- en: On-demand serverless inference
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 按需无服务器推理
- en: Applications with intermittent traffic, as with a small business chatbot, for
    example, can use serverless inference to respond to customer inquiries, automatically
    scaling resources based on the volume of users at any given time—without needing
    a permanently running server.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 对于间歇性流量的应用程序，例如小型企业聊天机器人，可以使用无服务器推理来响应用户查询，根据任何给定时间的用户数量自动扩展资源——无需永久运行的服务器。
- en: Monitoring
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控
- en: Monitoring is about tracking an ML model to ensure it is working as intended.
    Part of this is to look at KPIs, as we mentioned earlier in this chapter.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 监控是跟踪机器学习模型以确保其按预期工作。这包括查看KPI，正如我们在本章前面提到的。
- en: 'But it’s important to understand that even high-quality models will degrade
    in accuracy. This is due to factors like the following:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 但重要的是要理解，即使是高质量的模型也会在准确性上退化。这归因于以下因素：
- en: Data drift
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移
- en: Features of the model change over time, yet the relationships remain the same.
    For example, suppose you have built an ML model for predictive maintenance, where
    the system will try to anticipate needs for repairs for machines. However, after
    a few years, the model may show lower performance levels since the machines will
    be older, which can lead to changes in the characteristics of the features like
    vibration levels and temperature readings.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的特征会随时间变化，但关系保持不变。例如，假设你为预测性维护构建了一个机器学习模型，系统将尝试预测机器的维修需求。然而，几年后，由于机器变旧，模型可能表现出较低的性能水平，这可能导致特征特性（如振动水平和温度读数）的变化。
- en: Concept drift
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移
- en: The relationship between the features has changed. For example, this can be
    the case when a spam filter becomes less effective because spammers find ways
    to game the system.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 特征之间的关系发生了变化。例如，当垃圾邮件过滤器变得不那么有效时，因为垃圾邮件发送者找到了操纵系统的方法，这种情况就会发生。
- en: Label shift
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 标签偏移
- en: There is a shift in the labels of a dataset over time, but the relationships
    of the labels remain the same. To understand this, let’s look again at the spam
    filter scenario. Suppose the ML model was built with a dataset that has 30% of
    emails labeled as spam. But in the next year, there’s a notable increase in spam
    activities. This can have an adverse impact on performance of the ML model since
    it may not be able to pick up on the higher proportion of spam.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，数据集的标签发生了变化，但标签之间的关系保持不变。为了理解这一点，让我们再次看看垃圾邮件过滤器场景。假设ML模型是用一个有30%的电子邮件被标记为垃圾邮件的数据集构建的。但在下一年，垃圾邮件活动显著增加。这可能会对ML模型的性能产生不利影响，因为它可能无法捕捉到更高比例的垃圾邮件。
- en: Feature drift
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 特征漂移
- en: This is similar to data drift. With feature drift, the distribution of features
    in a dataset change over time, but the relationships remain constant. An example
    is with credit scores. Let’s say a model is basing its predictions on income of
    $30,000 to $50,000\. But in a couple years, the population has seen improved gains,
    with income ranging from $50,000 to $70,000\. This means that the distribution
    of the feature has changed. This could easily mean inaccurate predictions.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这与数据漂移类似。在特征漂移中，数据集中特征的分布随时间变化，但关系保持不变。一个例子是信用评分。假设一个模型是基于$30,000到$50,000的收入进行预测的。但在几年后，人口收入有所提高，收入范围在$50,000到$70,000之间。这意味着特征的分布已经改变。这很容易导致预测不准确。
- en: There are many monitoring systems available to detect these problems. As for
    AWS, there is SageMaker Model Monitor. It provides continuous monitoring of real-time
    endpoints, batch transform jobs that run regularly, and asynchronous batch transform
    jobs that are on schedule.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多监控系统可用于检测这些问题。对于AWS来说，有SageMaker Model Monitor。它提供了对实时端点、定期运行的批量转换作业以及按计划进行的异步批量转换作业的持续监控。
- en: The system is highly configurable, allowing for setting alerts for when there
    are issues with an ML model. You can then be proactive in taking actions. These
    may be to retrain the model or fix quality issues.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 系统高度可配置，允许在ML模型出现问题时设置警报。然后你可以主动采取行动。这些可能包括重新训练模型或修复质量问题。
- en: MLOps
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps
- en: 'Machine learning operations (MLOps) is about a set of practices, processes,
    and automations to better manage the ML lifecycle. It is for the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习操作（MLOps）是一套实践、流程和自动化，旨在更好地管理ML生命周期。它包括以下内容：
- en: Data preparation
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Testing and validating models
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试和验证模型
- en: Model training
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Deployment
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Monitoring
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控
- en: MLOps is based on underlying concepts of DevOps, which is focused on the integration
    of software development and IT teams.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps基于DevOps的底层概念，DevOps专注于软件开发和IT团队的集成。
- en: However, with MLOps, it must deal with the unique aspects of ML models. These
    include the experimental nature of these systems, the reliance of large datasets,
    and the continuous monitoring. Then there are the challenges of finding skilled
    employees.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，MLOps必须处理ML模型独特的方面。这包括这些系统的实验性质、对大数据集的依赖以及持续的监控。然后还有寻找有技能的员工的挑战。
- en: A key advantage of MLOps is that an application can get to market faster. It
    provides a framework to organize a project and leverage repeatable processes.
    The planning can go a long way in avoiding wasted efforts and expenses. This also
    includes using automation systems, like SageMaker.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的一个关键优势是应用程序可以更快地进入市场。它提供了一个框架来组织项目并利用可重复的过程。规划可以大大减少浪费的努力和费用。这还包括使用自动化系统，如SageMaker。
- en: MLOps can be integrated with CI/CD. This is for the automations of building,
    testing, and deploying the ML models. This will also include versioning of the
    inputs and outputs of the model, which allows for better understanding of the
    performance of the models. Versioning also provides for rollbacks, which means
    that the system will be returned to the prior setup.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps可以与CI/CD集成。这是为了自动化构建、测试和部署ML模型。这还将包括模型输入和输出的版本控制，这有助于更好地理解模型的性能。版本控制还提供了回滚功能，这意味着系统将返回到先前的设置。
- en: Another advantage of MLOps is that it can help promote a culture of collaboration
    among data scientists, data engineers, software engineers, and IT personnel. This
    is no easy feat given that each role has specialized backgrounds. But there needs
    to be a focus on strong governance. This means having clear documentation and
    ways to provide constructive feedback. Of course, there must be systems in place
    to provide for data, privacy, and security compliance.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的另一个优势是它可以帮助促进数据科学家、数据工程师、软件工程师和IT人员之间的协作文化。鉴于每个角色都有专门的背景，这并非易事。但必须关注强有力的治理。这意味着要有清晰的文档和提供建设性反馈的方式。当然，必须建立系统来确保数据、隐私和安全合规。
- en: 'Amazon SageMaker has numerous tools for MLOps. Some of them we have already
    covered, such as Data Wrangler and Model Monitor. Here are some others:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker为MLOps提供了许多工具。其中一些我们已经介绍过，例如Data Wrangler和Model Monitor。以下是一些其他工具：
- en: SageMaker Feature Store
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker特征存储
- en: This assists in creating, sharing, and managing ML features.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于创建、共享和管理机器学习特征。
- en: SageMaker Experiments
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker实验
- en: You can experiment with mixes of datasets, models, and parameters. The system
    will then evaluate the accuracy.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以对数据集、模型和参数的混合进行实验。然后系统将评估准确性。
- en: SageMaker Processing
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker处理
- en: This automates data preprocessing, feature engineering, and model evaluation.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这自动处理数据预处理、特征工程和模型评估。
- en: SageMaker Model Registry
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker模型注册
- en: With this, you can catalog models, manage model versions, process the approvals,
    or deploy models to production.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此工具，您可以编目模型、管理模型版本、处理审批或部署模型到生产环境。
- en: AWS Development Tools
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS开发工具
- en: 'To support development, SageMaker provides two key environments: SageMaker
    Notebook Instances and SageMaker Studio Classic.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持开发，SageMaker提供了两个关键环境：SageMaker笔记本实例和SageMaker Studio Classic。
- en: SageMaker Notebook Instances
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker笔记本实例
- en: A Jupyter notebook is an open source system, which is accessible from the internet.
    You can create documents that have live code, documentation, equations, and visualizations.
    Jupyter Notebooks are popular for building ML models.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter笔记本是一个开源系统，可以从互联网上访问。您可以创建包含实时代码、文档、方程式和可视化的文档。Jupyter笔记本因其构建机器学习模型而受到欢迎。
- en: You can use these in AWS with SageMaker Notebook Instances. These are fully
    managed Jupyter notebooks that you can launch from the SageMaker console.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这些工具与SageMaker笔记本实例一起在AWS中使用。这些是完全管理的Jupyter笔记本，您可以从SageMaker控制台启动。
- en: Let’s walk through an example to see how it works. First, you will log in to
    your AWS account, which we learned about in [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai),
    and then click the menu icon (sometimes called the “burger” icon) on the top left.
    From the menu, you will click “Create notebook instance.”
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看它是如何工作的。首先，您将登录到您的AWS账户，我们在[第2章](ch02.html#chapter_two_aws_fundamentals_for_the_ai)中了解过，然后点击左上角的菜单图标（有时称为“汉堡”图标）。从菜单中，您将点击“创建笔记本实例”。
- en: You’ll see a configuration screen. Here, you can fill out details like access
    permissions, GitHub integration, and network settings. But at a minimum, you will
    enter a name for the notebook and use the default role.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到一个配置屏幕。在这里，您可以填写诸如访问权限、GitHub集成和网络设置等详细信息。但至少，您将输入笔记本的名称并使用默认角色。
- en: AWS will spin up a VM instance to host your notebook. It might take a couple
    of minutes to set up. When it’s ready, click the name of your instance, and then
    select Open Jupyter. On the left side of the screen, choose New, and from the
    drop-down menu, select conda_python_3\. The notebook will show up (see [Figure 3-6](#figure_three_sixdot_jupyter_notebook_in)).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: AWS将启动一个虚拟机实例来托管您的笔记本。设置可能需要几分钟。当它准备好时，点击您的实例名称，然后选择打开Jupyter。在屏幕的左侧，选择新建，从下拉菜单中选择conda_python_3。笔记本将显示出来（见[图3-6](#figure_three_sixdot_jupyter_notebook_in)）。
- en: As you can see, I put in some sample code. This program loads and displays the
    Iris dataset, a well-known dataset used for ML.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我放入了一些示例代码。这个程序加载并显示Iris数据集，这是一个用于机器学习的知名数据集。
- en: Each line in the notebook is called a *cell*. It can be for either documentation
    or description, which is in a Markdown format. This is similar to how you would
    format a web page. Then there is a cell for the code. For ML projects, this is
    usually Python, Scala, or R.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的每一行都称为一个*单元*。它可以用于文档或描述，格式为Markdown。这与您格式化网页的方式类似。然后有一个用于代码的单元。对于机器学习项目，这通常是Python、Scala或R。
- en: In [Figure 3-6](#figure_three_sixdot_jupyter_notebook_in), the title for the
    project—at the top—is in Markdown; the code is Python.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图3-6](#figure_three_sixdot_jupyter_notebook_in)中，项目的标题——位于顶部——使用Markdown编写；代码是Python编写。
- en: To run the code in a cell, you will click it and then press Shift+Enter. The
    output—if there is any—will appear below it.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 要在单元格中运行代码，您需要点击它，然后按Shift+Enter。如果有输出，它将显示在下方。
- en: Note
  id: totrans-361
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: When you are using SageMaker Notebook Instances—or any other AWS service—you
    need to be careful. In some cases, the billing will continue. For a notebook,
    this may be less than a dollar per month. But this can still add up, as you add
    more. Because of this, if you do not expect to use any in the future, then you
    should delete them.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用SageMaker笔记本实例或任何其他AWS服务时，您需要小心。在某些情况下，计费将持续进行。对于一个笔记本，这可能每月不到一美元。但随着数量的增加，这仍然可能累积起来。因此，如果您预计未来不会使用任何服务，那么您应该删除它们。
- en: '![](assets/awsc_0306.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0306.png)'
- en: Figure 3-6\. Jupyter Notebook in SageMaker
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-6\. SageMaker中的Jupyter Notebook
- en: SageMaker Studio Classic
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker Studio Classic
- en: SageMaker Studio Classic is an IDE for creating and deploying ML models. It’s
    user-friendly, supports team collaboration, and doesn’t use VMs, which helps to
    lower the costs. It is also compatible with tools like Jupyter Notebook, VS Code,
    and RStudio.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio Classic是一个用于创建和部署机器学习模型的IDE。它用户友好，支持团队协作，不使用虚拟机，这有助于降低成本。它还与Jupyter
    Notebook、VS Code和RStudio等工具兼容。
- en: To use SageMaker Studio Classic, log in to your AWS account and select the icon
    on the top left. Choose “Create a SageMaker domain” and then select the “Quick
    setup” option, which is for a single user. It will then take a few minutes for
    SageMaker to be initialized.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用SageMaker Studio Classic，请登录您的AWS账户，并选择左上角的图标。选择“创建SageMaker域”，然后选择“快速设置”选项，这是为单个用户设计的。然后，SageMaker将初始化需要几分钟。
- en: After this, go to User Profiles and choose Launch. You’ll see the dashboard
    for SageMaker Studio Classic, as shown in [Figure 3-7](#figure_three_sevendot_dashboard_for_the).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，转到用户配置文件并选择启动。您将看到SageMaker Studio Classic仪表板，如图[图3-7](#figure_three_sevendot_dashboard_for_the)所示。
- en: '![](assets/awsc_0307.png)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/awsc_0307.png)'
- en: Figure 3-7\. Dashboard for the SageMaker Studio Classic
  id: totrans-370
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-7\. SageMaker Studio Classic仪表板
- en: On the left side of the screen, you’ll find a navigation panel with applications
    like JupyterLab and the Code Editor. Below that, you can access key ML services,
    including Data, Auto ML, and Experiments.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕左侧，您将找到一个包含JupyterLab和代码编辑器等应用程序的导航面板。在其下方，您可以访问包括数据、Auto ML和实验在内的关键机器学习服务。
- en: For the rest of this book, we’ll focus on SageMaker Studio Classic.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，我们将重点关注SageMaker Studio Classic。
- en: Let’s move on and explore other AWS services.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续探索其他AWS服务。
- en: AWS ML Services
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS ML Services
- en: In this section, we’ll focus on ready-to-use AWS ML services that don’t require
    extensive model building or training. These solutions can be quickly integrated
    into applications to add powerful AI capabilities—such as language understanding,
    translation, speech recognition, and personalization—without deep ML expertise.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点关注即用型AWS机器学习服务，这些服务不需要进行大量的模型构建或训练。这些解决方案可以快速集成到应用程序中，以添加强大的AI功能——如语言理解、翻译、语音识别和个人化——而无需深厚的机器学习专业知识。
- en: Amazon Comprehend
  id: totrans-376
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Comprehend
- en: Amazon Comprehend is an NLP tool. It can extract insights from data, such as
    documents, product reviews, social media feeds, and customer support tickets.
    The tool will try to understand the content by focusing on key phrases, entities,
    places, people, sentiment, and topics. Amazon Comprehend also has security features
    to identify and redact personally identifiable information (PII).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend是一个自然语言处理工具。它可以从数据中提取见解，例如文档、产品评论、社交媒体内容和客户支持票证。该工具将通过关注关键词、实体、地点、人物、情感和主题来尝试理解内容。Amazon
    Comprehend还具有安全功能，用于识别和删除个人身份信息（PII）。
- en: Amazon Translate
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Translate
- en: Amazon Translate is for language translation. It can understand 75 languages.
    The system uses neural translation, which is based on sophisticated deep learning
    models. This allows for more accurate and natural-sounding translations.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Translate用于语言翻译。它可以理解75种语言。该系统使用基于复杂深度学习模型的神经翻译，这允许翻译更加准确和自然。
- en: The tool leverages Active Custom Translation (ACT). This means you can use your
    own data to customize the translations. But there is no need to create a new model.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具利用主动自定义翻译（ACT）。这意味着您可以使用自己的数据来自定义翻译，但无需创建新模型。
- en: Amazon Textract
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Textract
- en: Amazon Textract extracts text and handwriting from scanned documents, PDFs,
    and images. But this is more than a typical optical character recognition (OCR)
    system. Amazon Textract can also identify and understand the information that
    is extracted.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Textract 从扫描的文档、PDF 和图像中提取文本和手写内容。但这不仅仅是一个典型的光学字符识别（OCR）系统。亚马逊 Textract
    还能识别和理解提取的信息。
- en: Amazon Lex
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Lex
- en: Amazon Lex is a fully managed AI service that allows for the creation, testing,
    and deployment of conversational interfaces, such as chatbots. The core engine
    is the Alexa platform. Amazon Lex also uses Lambda, which allows for customization
    based on an organization’s internal data.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Lex 是一个完全托管的 AI 服务，允许创建、测试和部署会话式界面，例如聊天机器人。其核心引擎是 Alexa 平台。亚马逊 Lex 还使用 Lambda，允许根据组织的内部数据进行定制。
- en: This system can be easily deployed on mobile, IoT devices, and call centers.
    There are also integrations with Facebook Messenger, Slack, and Twilio SMS.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统可以轻松部署在移动、物联网设备和呼叫中心。还有与 Facebook Messenger、Slack 和 Twilio SMS 的集成。
- en: On the backend, there is a dashboard, which provides extensive analytics.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在后端，有一个仪表板，提供了广泛的分析。
- en: Amazon Polly
  id: totrans-387
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Polly
- en: Amazon Polly provides tools to allow applications to have lifelike speech. It
    comes with more than 100 male and female voices. They span more than 40 languages
    and language variants.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Polly 提供工具，允许应用程序拥有逼真的语音。它包含超过 100 种男性和女性声音。它们涵盖了 40 多种语言和语言变体。
- en: Amazon Polly has many use cases. For example, you can use it to allow text-to-speech
    with blog posts, PDFs, and web pages.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Polly 有许多使用案例。例如，你可以用它来实现博客文章、PDF 和网页的文本到语音转换。
- en: Amazon Transcribe
  id: totrans-390
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Transcribe
- en: Amazon Transcribe is known as an automatic speech recognition (ASR) service.
    This means it can convert speech into text, such as from WAV and MP3 files. The
    service provides timestamps for every word, which allows for search capabilities.
    Amazon Transcribe can also be used in real time.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Transcribe 是一个自动语音识别（ASR）服务。这意味着它可以转换语音为文本，例如从 WAV 和 MP3 文件中。该服务为每个单词提供时间戳，这允许搜索功能。亚马逊
    Transcribe 也可以实时使用。
- en: 'Some of the use cases include:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些使用案例包括：
- en: Transcriptions of customer support calls
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户支持通话的转录
- en: Creation of subtitles for audio and video files
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为音频和视频文件创建字幕
- en: Content analysis
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容分析
- en: Amazon Rekognition
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Rekognition
- en: Amazon Rekognition is a sophisticated computer vision tool. It makes it possible
    to identify objects, people, scenes, and activities in images and videos. This
    system also allows for facial search and analysis, helping with user verification
    and people counting.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Rekognition 是一个复杂的计算机视觉工具。它使得在图像和视频中识别对象、人物、场景和活动成为可能。此系统还允许进行面部搜索和分析，有助于用户验证和人数统计。
- en: 'These are other use cases:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是其他的使用案例：
- en: Detect unsafe or inappropriate content
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测不安全或不适当的内容
- en: Identify video segments that help to lower costs
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别有助于降低成本的视频片段
- en: Provide alerts when an unknown person is detected near your home
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当检测到未知人物靠近你的家时提供警报
- en: Amazon Kendra
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Kendra
- en: Amazon Kendra is an enterprise search system that works across various structured
    and unstructured repositories. This can be easily implemented into corporate websites
    and applications.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Kendra 是一个企业级搜索系统，它可以在各种结构化和非结构化存储库中工作。这可以轻松集成到企业网站和应用中。
- en: A powerful feature is the Kendra GenAI index. This uses RAG, which leverages
    generative AI for searching proprietary documents. With this, you can create personalized
    digital assistants.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 一个强大的功能是 Kendra GenAI 索引。它使用 RAG，利用生成式 AI 来搜索专有文档。有了这个功能，你可以创建个性化的数字助手。
- en: Amazon Personalize
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊 Personalize
- en: Amazon Personalize helps create AI applications that are customized based on
    the interests and behaviors of users. Setup of the system can take a few hours.
    But this is fairly low compared to many others.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Personalize 帮助创建基于用户兴趣和行为定制的 AI 应用程序。系统的设置可能需要几个小时。但与许多其他系统相比，这相当低。
- en: 'Amazon Personalize is built to be highly adaptable. In real time, it will incorporate
    user data to improve recommendations. Some of the use cases for this tool are:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Personalize 设计成高度可适应。实时地，它会结合用户数据来改进推荐。此工具的一些使用案例包括：
- en: Customer sentiment analysis
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户情绪分析
- en: Targeted marketing campaigns
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定向营销活动
- en: Identification of market trends
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别市场趋势
- en: AWS DeepRacer
  id: totrans-411
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS DeepRacer
- en: AWS DeepRacer is a 3D simulation application of a fully autonomous race car.
    This provides a fun way to learn about reinforcement learning.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: AWS DeepRacer是一个完全自主的赛车3D模拟应用程序。这为学习强化学习提供了一种有趣的方式。
- en: In [Table 3-4](#table_three_fourdot_aws_ai_services), you’ll find a summary
    of the AWS AI services.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表3-4](#table_three_fourdot_aws_ai_services)中，您将找到AWS人工智能服务的摘要。
- en: Table 3-4\. AWS AI services
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-4\. AWS人工智能服务
- en: '| Service | Description |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| 服务 | 描述 |'
- en: '| --- | --- |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Amazon Comprehend | Extracts insights from text using NLP, including sentiment
    and PII detection |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Comprehend | 使用NLP从文本中提取见解，包括情感和PII检测 |'
- en: '| Amazon Kendra | Provides intelligent enterprise search across document repositories
    |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Kendra | 在文档存储库中提供智能企业搜索 |'
- en: '| Amazon Lex | Creates conversational chatbots using speech and text input
    |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Lex | 使用语音和文本输入创建对话聊天机器人 |'
- en: '| Amazon Personalize | Generates real-time, personalized recommendations using
    user data |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Personalize | 使用用户数据生成实时、个性化的推荐 |'
- en: '| Amazon Polly | Converts text into lifelike speech in multiple voices and
    languages |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Polly | 在多种声音和语言中将文本转换为逼真的语音 |'
- en: '| Amazon Rekognition | Detects objects, scenes, and faces in images and videos
    |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Rekognition | 在图像和视频中检测对象、场景和面部 |'
- en: '| Amazon Textract | Extracts and understands text and handwriting from documents
    and images |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Textract | 从文档和图像中提取和了解文本和手写 |'
- en: '| Amazon Transcribe | Converts speech to text with support for real-time transcription
    |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Transcribe | 支持实时转录，将语音转换为文本 |'
- en: '| Amazon Translate | Provides real-time language translation for over 75 languages
    |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Translate | 为超过75种语言提供实时语言翻译 |'
- en: '| AWS DeepRacer | Simulates autonomous driving to teach reinforcement learning
    |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| AWS DeepRacer | 模拟自动驾驶以教授强化学习 |'
- en: AWS services, including Amazon SageMaker, are continuously updated with new
    features and capabilities. For the latest information, always refer to the official
    [AWS documentation](https://oreil.ly/_49DF).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: AWS服务，包括Amazon SageMaker，会持续更新以添加新功能和功能。有关最新信息，请始终参考官方[AWS文档](https://oreil.ly/_49DF)。
- en: Conclusion
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we had an overview of ML. It’s certainly a big topic with many
    moving parts. To help make this more understandable, we focused on the ML lifecycle,
    which has phases like data processing, model deployment, and monitoring. In each
    step, we learned about the key concepts and use cases along with the relevant
    AWS tools.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们对机器学习（ML）进行了概述。这当然是一个大话题，有很多组成部分。为了使这一点更容易理解，我们专注于机器学习生命周期，它包括数据处理、模型部署和监控等阶段。在每一步中，我们学习了关键概念和用例，以及相关的AWS工具。
- en: After this, we covered MLOps, which is a comprehensive approach to managing
    ML projects. We also looked at the numerous other AWS ML services for specific
    use cases.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们介绍了MLOps，这是一种管理机器学习项目的综合方法。我们还探讨了针对特定用例的众多其他AWS机器学习服务。
- en: In the next chapter, we’ll take a look at generative AI.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨生成式人工智能。
- en: Quiz
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问答
- en: To check your answers, please refer to the [“Chapter 3 Answer Key”](app02.html#answers_ch_3).
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查您的答案，请参阅[“第3章答案键”](app02.html#answers_ch_3)。
- en: Which of the following best describes the role of feature engineering in machine
    learning (ML)?
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个选项最能描述特征工程在机器学习（ML）中的作用？
- en: It creates new variables or transforms data to improve model performance.
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它创建新的变量或转换数据以提高模型性能。
- en: It trains the model using labeled data.
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它使用标记数据来训练模型。
- en: It evaluates the accuracy of a trained model.
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它评估训练模型的准确性。
- en: It ensures that the model is not biased.
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它确保模型没有偏见。
- en: What is the primary purpose of reinforcement learning in AI?
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习在人工智能中的主要目的是什么？
- en: To learn patterns from labeled data
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从标记数据中学习模式
- en: To optimize decisions based on rewards and penalties
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了根据奖励和惩罚优化决策
- en: To detect anomalies in datasets
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检测数据集中的异常
- en: To reduce dimensionality in high-dimensional datasets
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在高维数据集中降低维度
- en: A company is using Amazon SageMaker to build a machine learning (ML) model.
    What is the primary advantage of using SageMaker over traditional on-premises
    ML infrastructure?
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一家公司正在使用Amazon SageMaker构建机器学习（ML）模型。与传统的本地机器学习基础设施相比，使用SageMaker的主要优势是什么？
- en: It eliminates the need for data preprocessing.
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它消除了数据预处理的必要性。
- en: It requires more manual intervention than on-premises solutions.
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它比本地解决方案需要更多的手动干预。
- en: It provides pretrained models that cannot be customized.
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它提供预训练的模型，无法进行自定义。
- en: It automates the entire ML lifecycle, from training to deployment.
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它自动化了整个机器学习生命周期，从训练到部署。
- en: What is the primary difference between supervised and unsupervised learning?
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习的主要区别是什么？
- en: Supervised learning does not require labeled data, while unsupervised learning
    does.
  id: totrans-450
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习不需要标记数据，而无监督学习则需要。
- en: Supervised learning focuses on reinforcement learning, while unsupervised learning
    does not.
  id: totrans-451
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '监督学习专注于强化学习，而无监督学习则不关注。 '
- en: Supervised learning uses labeled data, while unsupervised learning finds patterns
    in unlabeled data.
  id: totrans-452
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习使用标记数据，而无监督学习则在未标记数据中寻找模式。
- en: Supervised learning is only used for classification tasks, while unsupervised
    learning is used for all other ML applications.
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习仅用于分类任务，而无监督学习则用于所有其他ML应用。
- en: A retailer wants to group its customers based on purchasing behavior without
    using predefined labels. Which machine learning (ML) approach should they use?
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一家零售商想要根据购买行为将客户分组，而不使用预定义的标签。他们应该使用哪种机器学习（ML）方法？
- en: Reinforcement learning
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Supervised learning
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Unsupervised learning
  id: totrans-457
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Semisupervised learning
  id: totrans-458
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Why is model monitoring important in machine learning (ML)?
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么模型监控在机器学习（ML）中很重要？
- en: It prevents overfitting by reducing the number of features in a dataset.
  id: totrans-460
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过减少数据集中特征的数量来防止过拟合。
- en: It ensures that a deployed model maintains accuracy and adapts to data changes.
  id: totrans-461
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它确保部署的模型保持准确性并适应数据变化。
- en: It eliminates the need for retraining models over time.
  id: totrans-462
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它消除了随着时间的推移重新训练模型的需求。
- en: It guarantees that predictions will always be correct.
  id: totrans-463
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它保证了预测总是正确的。
- en: ^([1](ch03.html#ch01fn1-marker)) Alex Woodie, [“Data Prep Still Dominates Data
    Scientists’ Time, Survey Finds”](https://oreil.ly/K1mvn), BigDATAwire, July 6,
    2020.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#ch01fn1-marker)) Alex Woodie, [“数据准备仍然占据数据科学家时间，调查发现”](https://oreil.ly/K1mvn),
    BigDATAwire, 2020年7月6日。
