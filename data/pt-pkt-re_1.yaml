- en: Chapter 1\. An Introduction to PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。PyTorch简介
- en: PyTorch is one of the most popular deep learning Python libraries, and it is
    widely used by the AI research community. Many developers and researchers use
    PyTorch to accelerate deep learning research experimentation and prototyping.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是最受欢迎的深度学习Python库之一，广泛被人工智能研究社区使用。许多开发人员和研究人员使用PyTorch来加速深度学习研究实验和原型设计。
- en: In this chapter, I will give you a brief introduction to what PyTorch is and
    some of the features that make it popular. I’ll also show you how to install and
    set up your PyTorch development environment on your local machine and in the cloud.
    By the end of this chapter, you will be able to verify that PyTorch is properly
    installed and run a simple PyTorch program.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将简要介绍PyTorch是什么以及使其受欢迎的一些特点。我还将向您展示如何在本地机器和云端安装和设置PyTorch开发环境。通过本章的学习，您将能够验证PyTorch已正确安装并运行一个简单的PyTorch程序。
- en: What Is PyTorch?
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是PyTorch？
- en: The PyTorch library is primarily developed by Facebook’s AI Research Lab (FAIR)
    and is free and open source software with over 1,700 contributors. It allows you
    to easily run array-based calculations, build dynamic neural networks, and perform
    autodifferentiation in Python with strong graphics processing unit (GPU) acceleration—all
    important features required for deep learning research. Although some use it for
    accelerated tensor computing, most use it for deep learning development.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch库主要由Facebook的人工智能研究实验室（FAIR）开发，是一款免费的开源软件，拥有超过1700名贡献者。它允许您轻松运行基于数组的计算，在Python中构建动态神经网络，并进行自动微分，具有强大的图形处理单元（GPU）加速——这些都是深度学习研究所需的重要功能。尽管有些人用它来加速张量计算，但大多数人用它来进行深度学习开发。
- en: PyTorch’s simple and flexible interface enables fast experimentation. You can
    load data, apply transforms, and build models with a few lines of code. Then,
    you have the flexibility to write customized training, validation, and test loops
    and deploy trained models with ease.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的简单和灵活接口使快速实验成为可能。您可以加载数据，应用转换，并用几行代码构建模型。然后，您可以灵活地编写定制的训练、验证和测试循环，并轻松部署训练好的模型。
- en: 'It has a strong ecosystem and a large user community, including universities
    like Stanford and companies such as Uber, NVIDIA, and Salesforce. In 2019, PyTorch
    dominated machine learning and deep learning conference proceedings: 69% of the
    Conference on Computer Vision and Pattern Recognition (CVPR) proceedings used
    PyTorch, over 75% of both the Association for Computational Linguistics (ACL)
    and the North American Chapter of the ACL (NAACL) used it, and over 50% of the
    International Conference on Learning Representations (ICLR) and the International
    Conference on Machine Learning (ICML) used it as well. There are also over 60,000
    repositories on GitHub related to PyTorch.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 它拥有强大的生态系统和庞大的用户社区，包括斯坦福大学等大学和优步、英伟达和Salesforce等公司。2019年，PyTorch在机器学习和深度学习会议论文中占据主导地位：69%的计算机视觉与模式识别（CVPR）会议论文使用PyTorch，超过75%的计算语言学协会（ACL）和北美ACL分会（NAACL）使用它，超过50%的学习表示国际会议（ICLR）和国际机器学习会议（ICML）也使用它。GitHub上有超过60000个与PyTorch相关的存储库。
- en: Many developers and researchers use PyTorch to accelerate deep learning research
    experimentation and prototyping. Its simple Python API, GPU support, and flexibility
    make it a popular choice among academic and commercial research organizations.
    Since being open sourced in 2018, PyTorch has reached a stable release and can
    be easily installed on Windows, Mac, and Linux operating systems. The framework
    continues to expand rapidly and now facilitates deployment to production environments
    in the cloud and mobile platforms.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发人员和研究人员使用PyTorch来加速深度学习研究实验和原型设计。其简单的Python API、GPU支持和灵活性使其成为学术和商业研究机构中的热门选择。自2018年开源以来，PyTorch已经发布了稳定版本，并可以轻松安装在Windows、Mac和Linux操作系统上。该框架继续迅速扩展，现在可以方便地部署到云端和移动平台的生产环境中。
- en: Why Use PyTorch?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用PyTorch？
- en: 'If you’re studying machine learning, conducting deep learning research, or
    building AI systems, you’ll probably need to use a deep learning framework. A
    deep learning framework makes it easy to perform common tasks such data loading,
    preprocessing, model design, training, and deployment. PyTorch has become very
    popular with the academic and research communities due to its simplicity, flexibility,
    and Python interface. Here are some reasons to learn and use PyTorch:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在学习机器学习、进行深度学习研究或构建人工智能系统，您可能需要使用一个深度学习框架。深度学习框架使得执行常见任务如数据加载、预处理、模型设计、训练和部署变得容易。由于其简单性、灵活性和Python接口，PyTorch已经在学术和研究社区中变得非常流行。以下是学习和使用PyTorch的一些原因：
- en: PyTorch is popular
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch很受欢迎
- en: Many companies and research organizations use PyTorch as their main deep learning
    framework. In fact, some companies have built their custom machine learning tools
    on top of PyTorch. As a result, PyTorch skills are in demand.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司和研究机构将PyTorch作为他们的主要深度学习框架。事实上，一些公司已经在PyTorch的基础上构建了他们的自定义机器学习工具。因此，PyTorch技能需求量大。
- en: PyTorch is supported by all major cloud platforms, such as Amazon Web Services
    (AWS), Google Cloud Platform (GCP), Microsoft Azure, and Alibaba Cloud
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch得到所有主要云平台的支持，如亚马逊网络服务（AWS）、谷歌云平台（GCP）、微软Azure和阿里云
- en: You can spin up a virtual machine with PyTorch preloaded for frictionless development.
    You can use prebuilt Docker images, perform large-scale training on cloud GPU
    platforms, and run models at production scale.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以快速启动一个预装有PyTorch的虚拟机，进行无摩擦的开发。您可以使用预构建的Docker镜像，在云GPU平台上进行大规模训练，并在生产规模上运行模型。
- en: PyTorch is supported by Google Colaboratory and Kaggle Kernels
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch得到Google Colaboratory和Kaggle Kernels的支持
- en: You can run PyTorch code in a browser with no installation or configuration
    needed. You can compete in Kaggle competitions by running PyTorch directly in
    your kernel.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在浏览器中运行PyTorch代码，无需安装或配置。您可以通过在内核中直接运行PyTorch来参加Kaggle竞赛。
- en: PyTorch is mature and stable
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是成熟和稳定的
- en: PyTorch is regularly maintained and is now beyond release 1.8.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch定期维护，现在已经超过1.8版本。
- en: PyTorch supports CPU, GPU, TPU, and parallel processing
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch支持CPU、GPU、TPU和并行处理
- en: You can accelerate your training and inference using GPUs and TPUs. Tensor processing
    units (TPUs) are AI-accelerated application-specific integrated circuits (ASIC)
    chips that were developed by Google to provide an alternative to GPUs for NN hardware
    acceleration. With parallel processing, you can apply preprocessing on your CPU
    while training a model on the GPU or TPU.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用GPU和TPU加速训练和推断。张量处理单元（TPUs）是由Google开发的人工智能加速的应用特定集成电路（ASIC）芯片，旨在为NN硬件加速提供替代GPU的选择。通过并行处理，您可以在CPU上应用预处理，同时在GPU或TPU上训练模型。
- en: PyTorch supports distributed training
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch支持分布式训练
- en: You can train neural networks over multiple GPUs on multiple machines.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在多台机器上的多个GPU上训练神经网络。
- en: PyTorch supports deployment to production
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch支持部署到生产环境
- en: With the newer TorchScript and TorchServe features, you can easily deploy models
    to production environments including cloud servers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 借助新的TorchScript和TorchServe功能，您可以轻松将模型部署到包括云服务器在内的生产环境中。
- en: PyTorch is beginning to support mobile deployment
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch开始支持移动部署
- en: Although it’s currently experimental, you can now deploy models to iOS and Android
    devices.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管目前仍处于实验阶段，但您现在可以将模型部署到iOS和Android设备上。
- en: PyTorch has a vast ecosystem and set of open source libraries
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch拥有庞大的生态系统和一套开源库
- en: Libraries such as Torchvision, fastai, and PyTorch Lightning extend capabilities
    and support specific fields like natural olanguage processing (NLP) and computer
    vision.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如Torchvision、fastai和PyTorch Lightning等库扩展了功能并支持特定领域，如自然语言处理（NLP）和计算机视觉。
- en: PyTorch also has a C++ frontend
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch还具有C++前端
- en: Although I will focus on the Python interface in this book, PyTorch also supports
    a frontend C++ interface. If you need to build high-performance, low-latency,
    or bare-metal applications, you can write them in C++ using the same design and
    architecture as the Python API.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书将重点放在Python接口上，但PyTorch也支持前端C++接口。如果您需要构建高性能、低延迟或裸机应用程序，可以使用相同的设计和架构在C++中编写，就像使用Python
    API一样。
- en: PyTorch supports the Open Neural Network Exchange (ONNX) format natively
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch原生支持开放神经网络交换（ONNX）格式
- en: You can easily export your models to ONNX format and use them with ONNX-compatible
    platforms, runtimes, or visualizers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以轻松将模型导出为ONNX格式，并在ONNX兼容的平台、运行时或可视化器中使用它们。
- en: PyTorch has a large community of developers and user forums
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch拥有庞大的开发者社区和用户论坛
- en: There are more than 38,000 users on the PyTorch forum, and it’s easy to get
    support or post questions to the community by visiting [the PyTorch Discussion
    Forum](https://pytorch.tips/discuss).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch论坛上有超过38,000名用户，通过访问[PyTorch讨论论坛](https://pytorch.tips/discuss)很容易获得支持或发布问题。
- en: Getting Started
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: If you are familiar with PyTorch, you may already have installed it and set
    up your development environment. If not, I will show you some options to do so
    in this section. The fastest way to get started is to use Google Colaboratory
    (or *Colab*). Google Colab is a free cloud-based development environment similar
    to Jupyter Notebook and comes with PyTorch already installed. Colab comes with
    free limited GPU support and interfaces nicely with Google Drive for saving and
    sharing notebooks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉PyTorch，可能已经安装并设置了开发环境。如果没有，我将在本节中向您展示一些选项。开始的最快方式是使用Google Colaboratory（或*Colab*）。Google
    Colab是一个免费的基于云的开发环境，类似于Jupyter Notebook，并已安装了PyTorch。Colab提供免费的有限GPU支持，并与Google
    Drive接口良好，可用于保存和共享笔记本。
- en: If you don’t have internet access, or you want to run the PyTorch code on your
    own hardware, then I will show you how to install PyTorch on a local machine.
    You can install PyTorch on Windows, Linux, and macOS operating systems. I recommend
    that you have an NVIDIA GPU for acceleration, but it is not required.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有互联网访问，或者想在自己的硬件上运行PyTorch代码，那么我将向您展示如何在本地机器上安装PyTorch。您可以在Windows、Linux和macOS操作系统上安装PyTorch。我建议您拥有NVIDIA
    GPU进行加速，但不是必需的。
- en: Lastly, you may want to develop PyTorch code using a cloud platform like AWS,
    Azure, or GCP. If you would like to use a cloud platform, I will show you the
    options to quickly get started on each platform.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可能希望使用AWS、Azure或GCP等云平台开发PyTorch代码。如果您想使用云平台，我将向您展示在每个平台上快速入门的选项。
- en: Running in Google Colaboratory
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Google Colaboratory中运行
- en: With Google Colab, you can write and execute Python and PyTorch code in your
    browser. You can save files directly to your Google Drive account and easily share
    your work with others. To get started, visit [the Google Colab website](https://pytorch.tips/colab),
    as shown in [Figure 1-1](#fig_colab_welcome).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Google Colab，您可以在浏览器中编写和执行Python和PyTorch代码。您可以直接将文件保存到Google Drive帐户，并轻松与他人共享您的工作。要开始，请访问[Google
    Colab网站](https://pytorch.tips/colab)，如[图1-1](#fig_colab_welcome)所示。
- en: '![“Google Colaboratory welcome page”](Images/ptpr_0101.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![“Google Colaboratory欢迎页面”](Images/ptpr_0101.png)'
- en: Figure 1-1\. Google Colaboratory welcome page
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. Google Colaboratory欢迎页面
- en: If you are already signed into your Google account, you will get a pop-up window.
    Click New Notebook in the bottom-right corner. If the pop-up window does not appear,
    click File and select New Notebook from the menu. You will be prompted to sign
    in or create a Google account, as shown in [Figure 1-2](#fig_google_sign_in).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经登录到您的Google帐户，将会弹出一个窗口。单击右下角的“新笔记本”。如果弹出窗口未出现，请单击“文件”，然后从菜单中选择“新笔记本”。您将被提示登录或创建Google帐户，如[图1-2](#fig_google_sign_in)所示。
- en: '![“Google sign in”](Images/ptpr_0102.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![“Google登录”](Images/ptpr_0102.png)'
- en: Figure 1-2\. Google sign in
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. Google登录
- en: To verify your configuration, import the PyTorch library, print the installed
    version, and check if you are using a GPU, as shown in [Figure 1-3](#fig_colab_base_code).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 验证您的配置，导入PyTorch库，打印已安装的版本，并检查是否正在使用GPU，如[图1-3](#fig_colab_base_code)所示。
- en: '![“Verify PyTorch installation in Google Colaboratory”](Images/ptpr_0103.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![“在Google Colaboratory中验证PyTorch安装”](Images/ptpr_0103.png)'
- en: Figure 1-3\. Verify PyTorch installation in Google Colaboratory
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 在Google Colaboratory中验证PyTorch安装
- en: By default, our Colab notebook does not use a GPU. You will need to select Change
    Runtime Type from the Runtime menu, then select GPU from the “Hardware accelerator”
    drop-down menu and click Save, as shown in [Figure 1-4](#fig_colab_selct_gpu).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们的Colab笔记本不使用GPU。您需要从运行时菜单中选择更改运行时类型，然后从“硬件加速器”下拉菜单中选择GPU并单击保存，如[图1-4](#fig_colab_selct_gpu)所示。
- en: '![“Use a GPU in Google Colaboratory”](Images/ptpr_0104.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![“在Google Colaboratory中使用GPU”](Images/ptpr_0104.png)'
- en: Figure 1-4\. Use a GPU in Google Colaboratory
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 在Google Colaboratory中使用GPU
- en: Now run the cell again by selecting the cell and pressing Shift-Enter. You should
    see `True` as the output of `is_available()`, as shown in [Figure 1-5](#fig_colab_gpu_true).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在再次运行单元格，选择单元格并按Shift-Enter。您应该看到`is_available()`的输出为`True`，如[图1-5](#fig_colab_gpu_true)所示。
- en: '![“Verify GPU is active in Google Colab”](Images/ptpr_0105.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![“在Google Colab中验证GPU是否激活”](Images/ptpr_0105.png)'
- en: Figure 1-5\. Verify GPU is active in Google Colaboratory
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 在Google Colaboratory中验证GPU是否激活
- en: Note
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Google offers a paid version called Colab Pro that provides faster GPUs, longer
    runtimes, and more memory. For the examples in this book, the free version of
    Colab should be sufficient.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Google提供了一个付费版本称为Colab Pro，提供更快的GPU、更长的运行时间和更多内存。对于本书中的示例，免费版本的Colab应该足够了。
- en: Now you have verified that PyTorch is installed, and you also know the version.
    You have also verified that you have a GPU available and that the proper drivers
    are installed and operating correctly. Next, I will show you how to verify your
    PyTorch on a local machine.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经验证了PyTorch已安装，并且您也知道版本。您还验证了您有一个可用的GPU，并且正确安装和运行了适当的驱动程序。接下来，我将向您展示如何在本地机器上验证您的PyTorch。
- en: Running on a Local Computer
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在本地计算机上运行
- en: You may want to install PyTorch on a local machine or your own server under
    certain conditions. For example, you may want to work with local storage, or use
    your own GPU or faster GPU hardware, or you may not have internet access. Running
    PyTorch does not require a GPU, but one would be needed to run GPU acceleration.
    I recommend using an NVIDIA GPU as PyTorch is closely tied to the Compute Unified
    Device Architecture (CUDA) drivers for GPU support.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，您可能希望在本地机器或自己的服务器上安装PyTorch。例如，您可能希望使用本地存储，或者使用自己的GPU或更快的GPU硬件，或者您可能没有互联网访问。运行PyTorch不需要GPU，但需要GPU加速才能运行。我建议使用NVIDIA
    GPU，因为PyTorch与用于GPU支持的Compute Unified Device Architecture（CUDA）驱动程序紧密相关。
- en: Warning
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Check your GPU and CUDA version first! PyTorch only supports specific GPU and
    CUDA versions, and many Mac computers use non-NVIDIA GPUs. If you are using a
    Mac, verify that you have an NVIDIA GPU by clicking the Apple icon on the menu
    bar, selecting “About This Mac,” and clicking the Displays tab. If you see an
    NVIDIA GPU on your Mac and want to use it, you’ll have to build PyTorch from scratch.
    If you do not see an NVIDIA GPU, you should use the CPU-only version of PyTorch
    or choose another computer with a different OS.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先检查您的GPU和CUDA版本！PyTorch仅支持特定的GPU和CUDA版本，许多Mac电脑使用非NVIDIA GPU。如果您使用的是Mac，请通过单击菜单栏上的苹果图标，选择“关于本机”，然后单击“显示”选项卡来验证您是否有NVIDIA
    GPU。如果您在Mac上看到NVIDIA GPU并希望使用它，您将需要从头开始构建PyTorch。如果您没有看到NVIDIA GPU，则应使用PyTorch的仅CPU版本或选择另一台具有不同操作系统的计算机。
- en: The PyTorch website offers a [convenient browser tool for installation](https://pytorch.tips/install-local),
    as shown in [Figure 1-6](#fig_pytorch_start_locally). Select the latest stable
    build, your OS, your preferred Python package manager (Conda is recommended),
    the Python language, and your CUDA version. Execute the command line and follow
    the instructions for your configuration. Note the prerequisites, installation
    instructions, and verification methods.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch网站提供了一个[方便的浏览器工具用于安装](https://pytorch.tips/install-local)，如[图1-6](#fig_pytorch_start_locally)所示。选择最新的稳定版本，您的操作系统，您喜欢的Python包管理器（推荐使用Conda），Python语言和您的CUDA版本。执行命令行并按照您的配置的说明进行操作。请注意先决条件、安装说明和验证方法。
- en: '![“”](Images/ptpr_0106.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![“”](Images/ptpr_0106.png)'
- en: Figure 1-6\. PyTorch online installation configuration tool
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. PyTorch在线安装配置工具
- en: You should be able to run the verification code snippet in your favorite IDE
    (Jupyter Notebook, Microsoft Visual Studio Code, PyCharm, Spyder, etc.) or from
    the terminal. [Figure 1-7](#fig_verify_terminal) shows how to verify that the
    correct version of PyTorch is installed from a terminal on a Mac. The same commands
    can be used to verify this in a Windows or Linux terminal as well.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够在您喜欢的IDE（Jupyter Notebook、Microsoft Visual Studio Code、PyCharm、Spyder等）或终端中运行验证代码片段。[图1-7](#fig_verify_terminal)显示了如何在Mac终端上验证PyTorch的正确版本是否已安装。相同的命令也可以用于在Windows或Linux终端中验证。
- en: '![“”](Images/ptpr_0107.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![“”](Images/ptpr_0107.png)'
- en: Figure 1-7\. PyTorch verification using a Mac terminal
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7\. 使用Mac终端验证PyTorch
- en: Running on Cloud Platforms
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在云平台上运行
- en: If you’re familiar with cloud platforms like AWS, GCP, or Azure, you can run
    PyTorch in the cloud. Cloud platforms provide powerful hardware and infrastructure
    for training and deploying deep learning models. Remember that using cloud services,
    especially GPU instances, incurs additional costs. To get started, follow the
    instructions in [the online PyTorch cloud setup guide](https://pytorch.tips/start-cloud)
    for your platform of interest.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉AWS、GCP或Azure等云平台，您可以在云中运行PyTorch。云平台为训练和部署深度学习模型提供强大的硬件和基础设施。请记住，使用云服务，特别是GPU实例，会产生额外的费用。要开始，请按照感兴趣的平台的[在线PyTorch云设置指南](https://pytorch.tips/start-cloud)中的说明进行操作。
- en: Setting up your cloud environment is beyond the scope of this book, but I’ll
    summarize the available options. Each platform offers a virtual machine instance
    as well as managed services to support PyTorch development.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 设置云环境超出了本书的范围，但我将总结可用的选项。每个平台都提供虚拟机实例以及托管服务来支持PyTorch开发。
- en: Running on AWS
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在AWS上运行
- en: 'AWS offers multiple options to run PyTorch in the cloud. If you prefer a fully
    managed service, you can use AWS SageMaker, or if you’d rather manage your own
    infrastructure, you can use AWS Deep Learning Amazon Machine Images (AMIs) or
    Containers:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供多种在云中运行PyTorch的选项。如果您更喜欢全面托管服务，可以使用AWS SageMaker，或者如果您更喜欢管理自己的基础架构，可以使用AWS深度学习Amazon机器映像（AMI）或容器：
- en: Amazon SageMaker
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker
- en: This is a fully managed service to train and deploy models. You can run Jupyter
    Notebooks from the dashboard and use the SageMaker Python SDK to train and deploy
    models in the cloud. You can run your notebooks on a dedicated GPU instance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个全面托管的服务，用于训练和部署模型。您可以从仪表板运行Jupyter笔记本，并使用SageMaker Python SDK在云中训练和部署模型。您可以在专用GPU实例上运行您的笔记本。
- en: AWS Deep Learning AMIs
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: AWS深度学习AMI
- en: These are preconfigured virtual machine environments. You can choose the Conda
    AMI, which has many libraries (including PyTorch) preinstalled, or you can use
    the base AMI if you’d prefer a clean environment to set up private repositories
    or custom builds.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是预配置的虚拟机环境。您可以选择Conda AMI，其中预先安装了许多库（包括PyTorch），或者如果您更喜欢一个干净的环境来设置私有存储库或自定义构建，可以使用基本AMI。
- en: AWS Deep Learning Containers
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: AWS深度学习容器
- en: These are Docker images that come preinstalled with PyTorch. They enable you
    to skip the process of building and optimizing your environment from scratch and
    are mainly used for deployment.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是预先安装了PyTorch的Docker镜像。它们使您可以跳过从头开始构建和优化环境的过程，主要用于部署。
- en: For more detailed information on how to get started, review the [“Getting Started
    with PyTorch on AWS” instructions](https://pytorch.tips/start-aws).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何入门的更详细信息，请查看[“在AWS上开始使用PyTorch”说明](https://pytorch.tips/start-aws)。
- en: Running on Microsoft Azure
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Microsoft Azure上运行
- en: 'Azure also offers multiple options to run PyTorch in the cloud. You can develop
    PyTorch models using a fully managed service called Azure Machine Learning, or
    you can run Data Science Virtual Machines (DSVMs) if you prefer to manage your
    own infrastructure:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Azure还提供多种在云中运行PyTorch的选项。您可以使用名为Azure Machine Learning的全面托管服务开发PyTorch模型，或者如果您更喜欢管理自己的基础架构，可以运行数据科学虚拟机（DSVMs）：
- en: Azure Machine Learning
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning
- en: This is an enterprise-grade machine learning service for building and deploying
    models. It includes a drag-and-drop designer and MLOps capabilities to integrate
    with existing DevOps processes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于构建和部署模型的企业级机器学习服务。它包括拖放设计器和MLOps功能，可与现有的DevOps流程集成。
- en: DSVMs
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DSVMs
- en: These are preconfigured virtual machine environments. They come preinstalled
    with PyTorch and other deep learning frameworks as well as development tools like
    Jupyter Notebook and VS Code.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是预配置的虚拟机环境。它们预先安装了PyTorch和其他深度学习框架以及开发工具，如Jupyter Notebook和VS Code。
- en: For more detailed information on how to get started, review the [Azure Machine
    Learning documentation](https://pytorch.tips/azure).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何入门的更详细信息，请查看[Azure Machine Learning文档](https://pytorch.tips/azure)。
- en: Running on Google Cloud Platform
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Google云平台上运行
- en: 'GCP also offers multiple options to run PyTorch in the cloud. You can develop
    PyTorch models using the managed service, called AI Platform Notebooks, or run
    Deep Learning VM images if you prefer to manage your own infrastructure:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: GCP还提供多种在云中运行PyTorch的选项。您可以使用名为AI平台笔记本的托管服务开发PyTorch模型，或者如果您更喜欢管理自己的基础架构，可以运行深度学习VM镜像：
- en: AI Platform Notebooks
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: AI平台笔记本
- en: This is a managed service whose integrated JupyterLab environment allows you
    to create preconfigured GPU instances.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个托管服务，其集成的JupyterLab环境允许您创建预配置的GPU实例。
- en: Deep Learning VM images
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习VM镜像
- en: These are preconfigured virtual machine environments. They come preinstalled
    with PyTorch and other deep learning frameworks as well as development tools.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是预配置的虚拟机环境。它们预先安装了PyTorch和其他深度学习框架以及开发工具。
- en: For more detailed information on how to get started, review the instructions
    at Google Cloud [“AI and Machine Learning Products”](https://pytorch.tips/google-cloud).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何入门的更详细信息，请查看Google Cloud的[“AI和机器学习产品”说明](https://pytorch.tips/google-cloud)。
- en: Verifying Your PyTorch Environment
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证您的PyTorch环境
- en: 'Whether you use Colab, your local machine, or your favorite cloud platform,
    you should verify that PyTorch is properly installed and check to see if you have
    a GPU available. You’ve already seen how to do this in Colab. To verify that PyTorch
    is properly installed, use the following code snippet. The code imports the PyTorch
    library, prints the version, and checks to see if a GPU is available:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用Colab、本地计算机还是您喜爱的云平台，您都应该验证PyTorch是否已正确安装，并检查是否有GPU可用。您已经在Colab中看到了如何执行此操作。要验证PyTorch是否已正确安装，请使用以下代码片段。该代码导入PyTorch库，打印版本，并检查是否有GPU可用：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Warning
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: You import the library using `import torch`, not `import pytorch`. PyTorch is
    originally based on the `torch` library, an open source machine learning framework
    based on the C and Lua programming languages. Keeping the library named `torch`
    allows Torch code to be reused with a more efficient PyTorch implementation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您使用`import torch`导入库，而不是`import pytorch`。PyTorch最初基于`torch`库，这是一个基于C和Lua编程语言的开源机器学习框架。保持库命名为`torch`允许Torch代码与更高效的PyTorch实现重用。
- en: A Fun Example
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个有趣的例子
- en: Now that you have verified that your environment is configured properly, let’s
    code up a fun example to show some of the features of PyTorch and demonstrate
    best practices in machine learning. In this example, we’ll build a classic image
    classifier that will attempt to identify an image’s content based on 1,000 possible
    classes or choices.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经验证了您的环境是否正确配置，让我们编写一个有趣的例子，展示PyTorch的一些特性，并演示机器学习中的最佳实践。在这个例子中，我们将构建一个经典的图像分类器，尝试根据1,000个可能的类别或选择来识别图像的内容。
- en: You can access this example from [the book’s GitHub repository](https://github.com/joe-papa/pytorch-book)
    and follow along. Try running the code in Google Colab, on your local machine,
    or on a cloud platform like AWS, Azure, or GCP. Don’t worry about understanding
    all of the concepts of machine learning. We’ll cover them in more detail throughout
    the book.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[本书的GitHub存储库](https://github.com/joe-papa/pytorch-book)访问此示例并跟随。尝试在Google
    Colab、本地计算机或AWS、Azure或GCP等云平台上运行代码。不用担心理解机器学习的所有概念。我们将在本书中更详细地介绍它们。
- en: Note
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, you will import all the necessary libraries at the beginning of
    your code. However, in this example, we will import the libraries as they are
    used so you can see which libraries are needed for each task.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，您将在代码开头导入所有必要的库。然而，在这个例子中，我们将在使用时导入库，这样您就可以看到每个任务需要哪些库。
- en: 'First, let’s select an image we’d like to classify. In this example, we’ll
    choose a nice fresh, hot cup of coffee. Use the following code to download the
    coffee image to your local environment:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们选择一个我们想要分类的图像。在这个例子中，我们将选择一杯美味的新鲜热咖啡。使用以下代码将咖啡图像下载到您的本地环境：
- en: '[PRE1]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Notice that the code uses the `urllib` library’s `urlretrieve()` function to
    get an image from the web. We rename the file to *coffee.jpg* by specifying `fpath`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，代码使用`urllib`库的`urlretrieve()`函数从网络获取图像。我们通过指定`fpath`将文件重命名为*coffee.jpg*。
- en: 'Next, we read our local image using the Pillow library (PIL):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用Pillow库（PIL）读取我们的本地图像：
- en: '[PRE2]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[Figure 1-8](#fig_coffee) shows what our image looks like. We can use `matplotlib`’s
    `imshow()` function to display the image on our system, as shown in the preceding
    code.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-8](#fig_coffee)展示了我们的图像是什么样子的。我们可以使用`matplotlib`的`imshow()`函数在我们的系统上显示图像，就像前面的代码所示的那样。'
- en: '![Input Image for Classifier - A fresh, hot cup of coffee](Images/ptpr_0108.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![分类器的输入图像 - 一杯新鲜热咖啡](Images/ptpr_0108.png)'
- en: Figure 1-8\. Input image for classifier
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。分类器的输入图像
- en: Notice we haven’t used PyTorch yet. Here’s where things get exciting. Next,
    we are going to pass our image into a pretrained image classification neural network
    (NN)—but before we do so, we’ll need to *preprocess* our image. Preprocessing
    data is very common in machine learning since the NN expects the input to meet
    certain requirements.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们还没有使用PyTorch。这里就是事情变得令人兴奋的地方。接下来，我们将把我们的图像传递给一个预训练的图像分类神经网络（NN）—但在这之前，我们需要*预处理*我们的图像。在机器学习中，预处理数据是非常常见的，因为NN期望输入满足某些要求。
- en: 'In our example, the image data is an RGB 1600 × 1200-pixel JPEG-formatted image.
    We need to apply a series of preprocessing steps, called *transforms*, to convert
    the image into the proper format for the NN. We do this using Torchvision in the
    following code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，图像数据是一个RGB 1600 × 1200像素的JPEG格式图像。我们需要应用一系列预处理步骤，称为*转换*，将图像转换为NN的正确格式。我们使用Torchvision在下面的代码中实现这一点：
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We use the `Compose()` transform to define a series of transforms used to preprocess
    our image. First, we need to resize and crop the image to fit within the NN. The
    image is currently in PIL format, since that’s how we read it earlier. But our
    NN requires a tensor input, so we convert the PIL image to a tensor.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`Compose()`转换来定义一系列用于预处理我们的图像的转换。首先，我们需要调整大小并裁剪图像以适应NN。图像目前是PIL格式，因为我们之前是这样读取的。但是我们的NN需要一个张量输入，所以我们将PIL图像转换为张量。
- en: Tensors are the fundamental data objects in PyTorch, and we’ll spend the entire
    next chapter exploring them. You can think of tensors like NumPy arrays or numerical
    arrays with a bunch of extra features. For now, we’ll just convert our image to
    a tensor array of numbers to get it ready.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 张量是PyTorch中的基本数据对象，我们将在整个下一章中探索它们。您可以将张量视为NumPy数组或带有许多额外功能的数值数组。现在，我们只需将我们的图像转换为一个数字的张量数组，使其准备好。
- en: We apply one more transform, called `Normalize()`, to rescale the range of pixel
    values between 0 and 1\. The values for the mean and standard deviation (std)
    were precomputed based on the data used to train the model. Normalizing the image
    improves the accuracy of the classifier.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了另一个叫做`Normalize()`的转换，来重新缩放像素值的范围在0和1之间。均值和标准差（std）的值是基于用于训练模型的数据预先计算的。对图像进行归一化可以提高分类器的准确性。
- en: Finally, we call `transform(img)` to apply all the transforms to the image.
    As you can see, `img_tensor` is a 3 × 224 × 224 `torch.Tensor` representing a
    3-channel image of 224 × 224 pixels.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用`transform(img)`来将所有的转换应用到图像上。正如你所看到的，`img_tensor`是一个3 × 224 × 224的`torch.Tensor`，代表着一个3通道、224
    × 224像素的图像。
- en: 'Efficient machine learning processes data in batches, and our model will expect
    a batch of data. However, we only have one image, so we’ll need to create a batch
    of size 1, as shown in the following code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 高效的机器学习过程会批处理数据，我们的模型会期望一批数据。然而，我们只有一张图像，所以我们需要创建一个大小为1的批次，如下面的代码所示：
- en: '[PRE4]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We use PyTorch’s `unsqueeze()` function to add a dimension to our tensor and
    create a batch of size 1\. Now we have a tensor of size 1 × 3 × 224 × 224, which
    represents a batch size of 1 and 3 channels (RGB) of 224 × 224 pixels. PyTorch
    provides a lot of useful functions like `unsqueeze()` to manipulate tensors, and
    we’ll explore many of them in the next chapter.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用PyTorch的`unsqueeze()`函数向我们的张量添加一个维度，并创建一个大小为1的批次。现在我们有一个大小为1 × 3 × 224 ×
    224的张量，代表一个批次大小为1和3通道（RGB）的224 × 224像素。PyTorch提供了许多有用的函数，比如`unsqueeze()`来操作张量，我们将在下一章中探索其中许多函数。
- en: 'Now our image is ready for our classifier NN! We’ll use a famous image classifier
    called AlexNet. AlexNet won the ImageNet Large Scale Visual Recognition Challenge
    in 2012\. It’s easy to load this model using Torchvision, as shown in the following
    code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的图像已经准备好用于我们的分类器NN了！我们将使用一个名为AlexNet的著名图像分类器。AlexNet在2012年的ImageNet大规模视觉识别挑战赛中获胜。使用Torchvision很容易加载这个模型，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We’re going to use a pretrained model here, so we don’t need to train it. The
    AlexNet model has been pretrained with millions of images and does a pretty good
    job at classifying images. Let’s pass in our image and see how it does:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里使用一个预训练的模型，所以不需要训练它。AlexNet模型已经使用数百万张图像进行了预训练，并且在分类图像方面表现得相当不错。让我们传入我们的图像，看看它的表现：
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: GPU acceleration is a key benefit of PyTorch. In the first line, we use PyTorch’s
    `cuda.is_available()` function to see if our machine has a GPU. This is a very
    common line of PyTorch code, and we’ll explore GPUs further in Chapters [2](ch02.xhtml#Chapter_2)
    and [6](ch06.xhtml#pytorth_acceleration_and_optimization). We’re only classifying
    one image, so we don’t need a GPU here, but if we had a huge batch having a GPU
    might help speed things up.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: GPU加速是PyTorch的一个关键优势。在第一行中，我们使用PyTorch的`cuda.is_available()`函数来查看我们的机器是否有GPU。这是PyTorch代码中非常常见的一行，我们将在第[2](ch02.xhtml#Chapter_2)章和第[6](ch06.xhtml#pytorth_acceleration_and_optimization)章进一步探讨GPU。我们只对一个图像进行分类，所以这里不需要GPU，但如果我们有一个巨大的批次，使用GPU可能会加快速度。
- en: The `model.eval()` function configures our AlexNet model for inference or prediction
    (as opposed to training). Certain components of the model are only used during
    training, and we don’t want to use them here. The use of `model.to(device)` and
    `batch.to(device)` sends our model and input data to the GPU if available, and
    executing `model(batch.to(device))` runs our classifier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.eval()`函数配置我们的AlexNet模型进行推断或预测（与训练相对）。模型的某些组件仅在训练期间使用，我们不希望在这里使用它们。使用`model.to(device)`和`batch.to(device)`将我们的模型和输入数据发送到GPU（如果可用），执行`model(batch.to(device))`运行我们的分类器。'
- en: 'The output, `y`, consists of a batch of 1,000 outputs. Since our batch contains
    only one image, the first dimension is `1` while the number of classes is `1000`,
    one value for each class. The higher the value, the more likely it is that the
    image contains that class. The following code finds the winning class:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 输出`y`包含一个批次的1,000个输出。由于我们的批次只包含一个图像，第一维是`1`，而类的数量是`1000`，每个类有一个值。值越高，图像包含该类的可能性就越大。以下代码找到获胜的类：
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Using PyTorch’s `max()` function, we see that the class with index 967 has
    the highest value, 22.3059, and thus is the winner. However, we don’t know what
    class 967 represents. Let’s load the file with class names and find out:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch的`max()`函数，我们看到索引为967的类具有最高值22.3059，因此是获胜者。但是，我们不知道类967代表什么。让我们加载包含类名的文件并找出：
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Like we did earlier, we use `urlretrieve()` and download the text file containing
    descriptions of each class. Then, we read the file using `readlines()` and create
    a list containing class names. When we `print(classes[967])`, it shows us that
    class 967 is *espresso*!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前做的那样，我们使用`urlretrieve()`下载包含每个类描述的文本文件。然后，我们使用`readlines()`读取文件，并创建一个包含类名的列表。当我们`print(classes[967])`时，它显示类967是*espresso*！
- en: 'Using PyTorch’s `softmax()` function, we can convert the output values to probabilities:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch的`softmax()`函数，我们可以将输出值转换为概率：
- en: '[PRE9]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To print the probability at an index, we use PyTorch’s `tensor.item()` method.
    The `item()` method is frequently used and returns the numeric value contained
    in a tensor. The results show that the model is 87.85% sure that this image is
    an image of an espresso.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要打印索引处的概率，我们使用PyTorch的`tensor.item()`方法。`item()`方法经常被使用，并返回张量中包含的数值。结果显示，模型有87.85%的把握这是一张浓缩咖啡的图像。
- en: 'We can use PyTorch’s `sort()` function to sort the output probabilities and
    look at the top five:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用PyTorch的`sort()`函数对输出概率进行排序，并查看前五个：
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We see that the model predicts that the image is *espresso* with 87.85% probability.
    It also predicts *cup* with 7.28% and *coffee mug* with 4.3% probability, but
    it seems pretty confident that the image is an espresso.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到模型预测图像是*espresso*的概率为87.85%。它还以7.28%的概率预测*cup*，以4.3%的概率预测*coffee mug*，但它似乎非常确信图像是一杯浓缩咖啡。
- en: 'You may feel like you need an espresso right now. We covered a lot in that
    example! The core code to accomplish everything is actually much shorter. Assuming
    you have downloaded the files already, you only need to run the following code
    to classify an image using AlexNet:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能现在感觉需要一杯浓缩咖啡。在那个示例中，我们涵盖了很多内容！实际上，实现所有这些的核心代码要短得多。假设您已经下载了文件，您只需要运行以下代码来使用AlexNet对图像进行分类：
- en: '[PRE11]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: And that’s how you build an image classifier with PyTorch. Try running your
    own images through the model and see how it classifies them. Also, try completing
    the example on another platform. For example, if you used Colab to run the code,
    try running it locally or in the cloud.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是如何使用PyTorch构建图像分类器。尝试通过模型运行自己的图像，并查看它们的分类情况。还可以尝试在另一个平台上完成示例。例如，如果您使用Colab运行代码，请尝试在本地或云中运行它。
- en: Congratulations, you’ve verified that your environment is configured properly
    and that you can execute PyTorch code! We’ll explore each topic more deeply throughout
    the remainder of the book. In the next chapter, we’ll explore the fundamentals
    of PyTorch and provide a quick reference to tensors and their operations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您已经验证了您的环境已正确配置，并且可以执行PyTorch代码！我们将在本书的其余部分更深入地探讨每个主题。在下一章中，我们将探讨PyTorch的基础知识，并提供张量及其操作的快速参考。
