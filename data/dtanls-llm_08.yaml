- en: 7 Analyzing audio data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 分析音频数据
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Transcribing audio data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转录音频数据
- en: Translating audio data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 翻译音频数据
- en: Generating speech
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成语音
- en: 'Watch any credible science fiction TV show or movie, and you won’t see people
    typing to interact with their computers! Whether it’s *Star Trek* or *2001: A
    Space Odyssey* (both released in the 1960s), people speak to (not type into) their
    machines. And there are good reasons for that! For most users, voice is the most
    natural form of communication (because that’s the one they start with). No wonder
    people imagined speaking with computers long before that was technically feasible.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 观看任何可信的科幻电视剧或电影，您不会看到人们通过键盘与他们的计算机交互！无论是1960年代发布的《星际迷航》还是《2001太空漫游》（两者都是1960年代发布的），人们都是对着（而不是输入）他们的机器说话。而且有很好的理由！对于大多数用户来说，语音是最自然的交流形式（因为他们就是从那里开始的）。难怪人们早在技术上可行之前就想象与计算机说话了。
- en: Reality has now caught up with science fiction, and voice assistants, including
    the likes of Amazon’s Alexa, Google’s Assistant, and Microsoft’s Cortana (among
    many others), are ubiquitous. The newest generation of speech recognition (and
    speech generation) models have reached near-human levels of proficiency. And voice-based
    interaction with computers is, of course, only one use case for this amazing technology.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现实已经赶上了科幻小说，包括亚马逊的Alexa、谷歌助手、微软的Cortana（以及其他许多）在内的语音助手无处不在。最新一代的语音识别（和语音生成）模型已经达到了接近人类熟练程度的水平。当然，与计算机的基于语音的交互只是这项令人惊叹的技术的一个用例。
- en: In this chapter, we will use OpenAI’s latest models for speech transcription,
    translation, and speech generation for several mini-projects. First, we will see
    that transcribing voice recordings to text takes just a few lines of Python code.
    After that, we’ll look at more complex applications, starting with a voice-based
    version of our natural language database query interface from chapter 5\. Whereas
    we previously had to type in questions, we can now simply speak them, and the
    system will produce an answer. Finally, we will see how to build a simultaneous
    translator that turns our voice input into voice output in a different language.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用OpenAI的最新模型进行语音转录、翻译和语音生成，以进行几个小型项目。首先，我们将看到将语音录音转录成文本只需几行Python代码。之后，我们将探讨更复杂的应用，从第5章中基于语音的自然语言数据库查询界面开始。以前我们不得不输入问题，而现在我们可以简单地说话，系统将给出答案。最后，我们将看到如何构建一个同声传译器，将我们的语音输入转换成不同语言的语音输出。
- en: 7.1 Preliminaries
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 前期准备
- en: 'Before we can start with all of those cool projects, we need to perform a few
    setup steps. First, you will need to record voice input via your computer. For
    that to work, you first need some kind of microphone. Most laptops nowadays have
    a built-in microphone. It doesn’t have to be a professional microphone; any way
    of recording sound on your computer will do. But beyond the microphone, you also
    need software that can be activated from Python to turn audio recordings into
    files. For that, we will use Python’s `sounddevice` library. Run the following
    command in the terminal to install this library in the correct version:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始所有这些酷炫的项目之前，我们需要执行一些设置步骤。首先，您需要通过计算机记录语音输入。为此，您首先需要某种麦克风。如今，大多数笔记本电脑都内置了麦克风。它不一定要是专业麦克风；任何可以在计算机上记录声音的方式都行。但除了麦克风之外，您还需要可以从Python激活的软件，将音频录音转换为文件。为此，我们将使用Python的`sounddevice`库。在终端中运行以下命令以安装此库的正确版本：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This library interacts with Python’s `scipy` library, which you should also
    install. Run the following command in the terminal:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此库与Python的`scipy`库交互，您也应该安装它。在终端中运行以下命令：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Together, those libraries will enable you to record voice input (which you can
    then transcribe, translate, or summarize using OpenAI’s models).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库共同使用，将使您能够记录语音输入（然后您可以使用OpenAI的模型将其转录、翻译或总结）。
- en: 'We have covered the input side, but what about the output? For some of the
    following projects, we not only want to listen to audio but also generate it!
    To generate speech, we will use OpenAI’s generative AI models again. But after
    generating speech stored in an audio file, we still need suitable libraries to
    play speech on our computer from Python. We will use the `playsound` library for
    that. Run this command in the terminal to install this library in the correct
    version:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了输入方面，那么输出呢？对于以下的一些项目，我们不仅想听音频，还想生成它！为了生成语音，我们再次将使用 OpenAI 的生成式 AI 模型。但在将语音存储在音频文件中之后，我们仍然需要合适的库来从
    Python 在我们的计算机上播放语音。我们将使用 `playsound` 库来做这件事。在终端中运行以下命令来安装这个库的正确版本：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'On certain operating systems (in particular, macOS), you additionally have
    to install the `PyObjC` library using the following command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些操作系统（特别是 macOS）上，你还需要使用以下命令安装 `PyObjC` 库：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you haven’t done so already when working through the last chapter, install
    the `requests` library (enabling you to send requests directly to OpenAI’s API):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在处理上一章时还没有这样做，请安装 `requests` 库（这将使你能够直接向 OpenAI 的 API 发送请求）：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Well done! If you didn’t encounter any error messages running these commands,
    your system is now configured to process audio data with OpenAI’s Transformer
    models. Let’s start with our first project in the next section.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！如果你在运行这些命令时没有遇到任何错误信息，那么你的系统现在已经配置好了，可以使用 OpenAI 的 Transformer 模型处理音频数据。让我们从下一节开始我们的第一个项目。
- en: 7.2 Transcribing audio files
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 转录音频文件
- en: Having recently started your job at Banana, you are overwhelmed by the number
    of meetings. There are just too many meetings to attend, but you don’t want to
    miss anything important! Fortunately, Banana has the good sense to create audio
    recordings of all employee meetings as a general rule (with the consent of all
    participants). But listening to all the recordings of those meetings is still
    too time-consuming.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在香蕉公司刚刚开始你的工作后，你被会议的数量压倒了。要参加的会议实在太多了，但你又不希望错过任何重要的内容！幸运的是，香蕉公司有很好的意识，通常情况下会创建所有员工会议的音频记录（在所有与会者的同意下）。但听所有这些会议的录音仍然太耗时了。
- en: It would be great to have transcripts of meetings, enabling you to quickly search
    for anything relevant to your unit via a simple text search. Unfortunately, Banana
    doesn’t offer such transcripts out of the box, and none of your colleagues are
    willing to take notes during those meetings. Would it be possible to create such
    transcripts automatically? In this section, we will see that it’s not only possible
    but actually easy to create such an automated transcription service.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能有一份会议记录，将使你能够通过简单的文本搜索快速找到与你单位相关的任何内容。不幸的是，香蕉公司并没有提供这样的记录，而且你的同事们都不愿意在那些会议中做笔记。自动创建这样的记录是否可能？在本节中，我们将看到这不仅可能，而且实际上很容易创建这样的自动化转录服务。
- en: 7.2.1 Transcribing speech
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 转录语音
- en: For transcribing speech to text, we will use OpenAI’s Whisper model. Unlike
    the models we have used so far (in particular, GPT models), Whisper is specifically
    targeted at audio transcriptions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于语音转文字，我们将使用 OpenAI 的 Whisper 模型。与迄今为止我们使用的模型（特别是 GPT 模型）不同，Whisper 专门针对音频转录。
- en: What is the Whisper model?
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Whisper 模型是什么？
- en: Whisper is a Transformer model trained on large numbers of audio recordings
    (more than 680,000 hours of recordings, to be precise!). Whisper was trained on
    a multilingual audio corpus and therefore supports a broad range of input languages
    that it transcribes to English (i.e., you get speech transcription and translation
    in a single step).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper 是一个在大量音频记录上训练的 Transformer 模型（确切地说，超过 68 万小时的记录！）！Whisper 在一个多语言音频语料库上进行了训练，因此支持广泛的输入语言，并将其转录成英语（即，你可以在一个步骤中完成语音转录和翻译）。
- en: Similar to the GPT variants, we will access Whisper via OpenAI’s Python library.
    This means no additional setup is required on your local machine (assuming that
    you have installed OpenAI’s Python library, as described in chapter 3).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与 GPT 变体类似，我们将通过 OpenAI 的 Python 库访问 Whisper。这意味着你不需要在本地机器上进行任何额外的设置（假设你已经按照第
    3 章所述安装了 OpenAI 的 Python 库）。
- en: 'In this section, we will use the Whisper model to transcribe an audio file
    to disk. Let’s assume that our audio file is initially stored on disk. Whisper
    supports a wide range of file formats: MP3, MP4, MPEG, MPGA, M4A, WAV, and WEBM.
    At the time of writing, the file size is limited to 25 MB. Given such a file,
    let’s assume that its file path is stored in the variable `audio_path`. Now all
    it takes to transcribe its content to text are the following few lines of Python
    code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Whisper 模型将音频文件转录到磁盘。假设我们的音频文件最初存储在磁盘上。Whisper 支持广泛的文件格式：MP3、MP4、MPEG、MPGA、M4A、WAV
    和 WEBM。在撰写本文时，文件大小限制为 25 MB。给定这样一个文件，假设其文件路径存储在变量 `audio_path` 中。现在，将内容转录为文本只需要以下几行
    Python 代码：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Opens the audio file'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 打开音频文件'
- en: '#2 Transcribes the content'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 转录内容'
- en: As a first step (**1**), we need to open our audio file. For that, we can use
    Python’s `open` command. Note the use of the `rb` flag as a parameter of the `open`
    command. This flag indicates to Python that we want to read the file (`r`) and
    that we are opening a binary file (`b`). A binary file is a file that does not
    contain readable characters. Sound files, such as the one we are trying to open
    here, generally qualify as binary files. After processing the first line, the
    file content is accessible via the variable `audio_file`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步（**1**），我们需要打开我们的音频文件。为此，我们可以使用 Python 的 `open` 命令。注意 `open` 命令参数中使用了 `rb`
    标志。这个标志表示我们想要读取文件（`r`）并且我们正在打开一个二进制文件（`b`）。二进制文件是不包含可读字符的文件。例如，我们试图打开的这种声音文件通常被认为是二进制文件。在处理第一行之后，文件内容可以通过变量
    `audio_file` 访问。
- en: 'As a second step (**2**), we perform the actual transcription. We now use a
    different endpoint, specialized for audio data processing. From that endpoint,
    we invoke the transcription service (`transcriptions.create`) using two parameters:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二步（**2**），我们执行实际的转录。我们现在使用一个专门针对音频数据处理的不同端点。从这个端点，我们使用两个参数调用转录服务（`transcriptions.create`）：
- en: '`file`—A reference to the file to transcribe'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file`—要转录的文件的引用'
- en: '`model`—The name of the model for transcription'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`—用于转录的模型名称'
- en: 'We refer to the previously opened file (`audio_file`) and select `whisper-1`
    as our transcription model. The result of transcription is an object containing
    the transcribed text and metadata about the transcription process. We can access
    the transcribed text via the `text` field (i.e., via `transcription.text`).ents.
    After decompression, you should see three subdirectories in the resulting folder:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引用之前打开的文件（`audio_file`）并选择 `whisper-1` 作为我们的转录模型。转录的结果是一个包含转录文本和转录过程元数据的对象。我们可以通过
    `text` 字段（即通过 `transcription.text`）访问转录的文本。在解压缩后，您应该在结果文件夹中看到三个子目录：
- en: As you see, transcribing text takes just a few lines of Python code! In the
    next subsection, we will use this code to build a simple transcription service.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，转录文本只需几行 Python 代码！在下一小节中，我们将使用此代码构建一个简单的转录服务。
- en: 7.2.2 End-to-end code
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 端到端代码
- en: Listing [7.1](#code__transcription) shows the code for a simple transcription
    program. The actual transcription happens in the `transcribe` function (**1**).
    This is essentially the code we discussed in the previous section. Given the path
    to an audio file as input, it returns the transcribed text.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 [7.1](#code__transcription) 展示了一个简单转录程序的代码。实际的转录发生在 `transcribe` 函数（**1**）中。这基本上是我们在上一节中讨论的代码。给定音频文件的路径作为输入，它返回转录的文本。
- en: Listing 7.1 Transcribing audio files to text
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.1 将音频文件转录为文本
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Transcribes audio to text'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将音频转录为文本'
- en: '#2 Main function'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 主要功能'
- en: The main function (**2**) reads the path to an audio file (which should contain
    speech) as input. After invoking the `transcriptions.create` function, it prints
    the transcribed text on the screen.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 主要功能（**2**）读取音频文件的路径（应包含语音）作为输入。在调用 `transcriptions.create` 函数后，它将在屏幕上打印转录的文本。
- en: 7.2.3 Trying it out
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 尝试一下
- en: To try it, we first need an audio file with recorded speech. You can use any
    such file (including a recording of your company meetings, if available) as long
    as it complies with the format and size restrictions outlined in section [7.2.1](#sub__transcriptionBasics).
    However, keep in mind that you pay per minute of audio data processed! At the
    time of writing, using Whisper via the OpenAI library costs $0.006 per minute
    (you can find more up-to-date information about pricing at [https://openai.com/pricing](https://openai.com/pricing)).
    Processing long recordings can therefore be expensive.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试这个功能，我们首先需要一个包含录音的音频文件。只要它符合第[7.2.1](#sub__transcriptionBasics)节中概述的格式和大小限制，您可以使用任何此类文件（包括您公司会议的录音，如果有的话）。然而，请注意，您需要为每分钟处理的音频数据付费！在撰写本文时，通过OpenAI库使用Whisper的费用为每分钟0.006美元（您可以在[https://openai.com/pricing](https://openai.com/pricing)找到更多关于定价的最新信息）。因此，处理长录音可能会很昂贵。
- en: If you don’t want to use your own recording, have a look at the book’s companion
    website. You can find a short recording in the Audio item in this chapter’s section.
    Download this recording to use it for transcription (by default, the filename
    should be QuoteFromTheAlchemist.mp3).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想使用自己的录音，请查看本书的配套网站。您可以在本章的音频项目中找到一个简短的录音。下载此录音以用于转录（默认情况下，文件名应为QuoteFromTheAlchemist.mp3）。
- en: 'Listing [7.1](#code__transcription) is also available on the book’s companion
    website (item listing1.py in the chapter 7 section). After downloading it, switch
    to the corresponding repository in the terminal. Assuming that you downloaded
    the audio file into the current directory, run the following command in the terminal
    to transcribe the sample file:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 列表[7.1](#code__transcription)也可在本书的配套网站上找到（第7章的item listing1.py）。下载后，在终端中切换到相应的仓库。假设您已将音频文件下载到当前目录，请在终端中运行以下命令以转录样本文件：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If everything goes well, you should see the following output in the terminal
    (for the sample file from the website, that is):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您应该在终端中看到以下输出（针对网站上的样本文件）：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Click the sample file to listen to it yourself; you will find the transcript
    to be accurate! Next, we will integrate speech transcription into more complex
    applications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 点击样本文件自行收听；您会发现转录内容非常准确！接下来，我们将将语音转录集成到更复杂的应用中。
- en: 7.3 Querying relational data via voice
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 通过语音查询关系数据
- en: Analyzing tabular data is fun! A significant part of your job at Banana consists
    of poring over data tables, extracting insights, and preparing corresponding reports
    and visualizations. You’re using the text-to-SQL interface from chapter 5 to automatically
    translate text questions to formal queries (written in SQL), execute them, and
    present the query results. This makes analyzing data easier and is faster than
    writing complex SQL queries from scratch.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 分析表格数据很有趣！在Banana的工作中，您的大部分工作都包括仔细查看数据表，提取见解，并准备相应的报告和可视化。您正在使用第5章中介绍的文本到SQL接口，来自动将文本问题翻译成正式查询（用SQL编写），执行它们，并展示查询结果。这使得数据分析变得更容易，并且比从头开始编写复杂的SQL查询要快。
- en: 'However, there is a problem: you think better when pacing back and forth in
    your office while analyzing data. But typing queries forces you back to your desk
    every time. Can’t we modify our query interface to accept spoken, as opposed to
    typed, input? It turns out that indeed, we can! In this section, we will see how
    to use OpenAI’s models to enable a simple voice query interface for tabular data.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在一个问题：您在分析数据时，在办公室来回走动时思考得更好。但是，每次键入查询都会让您回到办公桌前。我们能否修改我们的查询界面，使其接受语音输入，而不是键盘输入？事实证明，我们确实可以！在本节中，我们将了解如何使用OpenAI的模型为表格数据启用简单的语音查询界面。
- en: 7.3.1 Preliminaries
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 前期准备
- en: We will build a voice query interface that processes spoken questions on tabular
    data. It is an extension of the query interface discussed in chapter 5\. We assume
    that spoken questions refer to data stored in SQLite, a popular system for processing
    queries on relational data. See chapter 5 for a short introduction to SQLite and
    installation instructions. To try the following code, you will first need to install
    the SQLite database system.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个处理表格数据语音问题的语音查询界面。它是第5章中讨论的查询界面的扩展。我们假设语音问题指的是存储在SQLite中的数据，SQLite是一个流行的关系数据查询处理系统。请参阅第5章以获取SQLite的简要介绍和安装说明。要尝试以下代码，您首先需要安装SQLite数据库系统。
- en: The SQLite system processes queries formulated in SQL, the structured query
    language. Fortunately, you won’t need to write SQL queries yourself (we will use
    a language model to write those SQL queries for us). However, language models
    are not perfect and may occasionally produce incorrect queries. To recognize those
    cases, it is useful to have a certain degree of SQL background. You will find
    a short introduction to SQL in chapter 5\. For more details, have a look at [www.databaselecture.com](http://www.databaselecture.com).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: SQLite系统处理以SQL（结构化查询语言）表述的查询。幸运的是，你不需要自己编写SQL查询（我们将使用语言模型来为我们编写这些SQL查询）。然而，语言模型并不完美，有时可能会产生错误的查询。为了识别这些情况，具备一定程度的SQL背景是有用的。你将在第5章中找到SQL的简要介绍。更多详情，请参阅[www.databaselecture.com](http://www.databaselecture.com)。
- en: Our voice query interface processes spoken questions, so you need to ensure
    that your microphone is working. Also, to execute the following code, make sure
    your voice query interface has all the required permissions to access the microphone.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的语音查询界面处理口语问题，因此你需要确保你的麦克风正在工作。此外，为了执行以下代码，请确保你的语音查询界面拥有访问麦克风的全部所需权限。
- en: 7.3.2 Overview
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.2 概述
- en: 'Our voice query interface processes spoken questions on tabular data stored
    in an SQLite database. For instance, having loaded a database with data about
    computer game sales, we can ask questions such as the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的语音查询界面处理存储在SQLite数据库中的表格数据上的口语问题。例如，加载了一个包含关于电脑游戏销售数据的数据库后，我们可以提出如下问题：
- en: “How many games did Activision sell in 2023?”
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Activision在2023年卖出了多少款游戏？”
- en: “How many action games were released between 2019 and 2021?”
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “2019年至2021年之间发布了多少款动作游戏？”
- en: 'On receiving a spoken question, the voice query interface performs the following
    steps:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到一个口语问题后，语音查询界面执行以下步骤：
- en: Transcribes the spoken question into text
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将口语问题转录成文本
- en: Translates the text question into an SQL query
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本问题翻译成SQL查询
- en: Processes the SQL query on the data using SQLite
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SQLite处理数据上的SQL查询
- en: Displays the query result to the user
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向用户显示查询结果
- en: Figure [7.1](#fig__VQIoverview) illustrates the different processing steps in
    more detail. The process is executed for each spoken question.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图[7.1](#fig__VQIoverview)更详细地说明了不同的处理步骤。这个过程为每个口语问题执行。
- en: '![figure](../Images/CH07_F01_Trummer.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F01_Trummer.png)'
- en: Figure 7.1 Our voice query interface transcribes spoken questions into text,
    translates text questions into SQL queries, and finally processes those queries
    and displays the query result.
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.1 我们的语音查询界面将口语问题转录成文本，将文本问题翻译成SQL查询，并最终处理这些查询并显示查询结果。
- en: 7.3.3 Recording audio
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.3 录制音频
- en: 'For our transcription application, we assumed that an audio recording was already
    available. For our new project, we want to issue voice queries repeatedly. That
    means we have to record them ourselves. How can we do that in Python? First, we
    need to import two libraries for precisely that purpose:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的转录应用程序，我们假设已经有一个音频录音可用。对于我们的新项目，我们希望反复发出语音查询。这意味着我们必须自己录制它们。我们如何在Python中做到这一点？首先，我们需要导入两个库，专门用于这个目的：
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Records audio'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 录制音频'
- en: '#2 Stores .wav files'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 存储.wav文件'
- en: 'The `sounddevice` library (**1**) contains many useful functions to record
    audio input from a microphone. What will we do with our recordings? We will store
    them as .wav files on disk. In the previous section, we saw how to transcribe
    audio data stored in that format. This is where the second library (**2**), `scipy`,
    comes into play: it enables us to store the recordings in .wav format on disk.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`sounddevice`库（**1**）包含许多用于从麦克风录制音频输入的有用函数。我们将如何处理我们的录音？我们将把它们作为.wav文件存储在磁盘上。在前一节中，我们看到了如何转录存储在该格式的音频数据。这就是第二个库（**2**），`scipy`发挥作用的地方：它使我们能够将录音以.wav格式存储在磁盘上。'
- en: 'When recording, we need to make two important choices:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在录制时，我们需要做出两个重要的选择：
- en: At what sample rate should we read input from the microphone?
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该以什么采样率从麦克风读取输入？
- en: How many seconds of speech should we record?
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该录制多少秒的语音？
- en: We will record for a duration of 5 seconds. Five seconds should suffice for
    most voice queries. You can try different settings if the recording tends to terminate
    too soon or if you find yourself waiting often after finishing your voice queries.
    A more sophisticated implementation would record continuously or stop recording
    after a speaking pause is detected. To keep things simple in terms of the recording
    mechanism, we will just record for a predetermined amount of time for each voice
    query.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将记录5秒钟。5秒钟对于大多数语音查询应该足够了。如果你发现录音太早结束，或者你在完成语音查询后经常等待，你可以尝试不同的设置。更复杂的实现会持续录音或检测到说话暂停后停止录音。为了简化录音机制，我们将为每个语音查询预先设定记录时间。
- en: 'For the sampling rate—that is, the number of audio data points stored per second—we
    will choose 44,100 Hertz. This is the standard for CD-quality recordings. The
    total number of *frames*—the number of audio data points received in total—is
    then 44,100 times the number of seconds we want to record (in our case, that’s
    5 seconds). We store the number of frames and the sampling rate in auxiliary variables:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于采样率——即每秒存储的音频数据点数量——我们将选择44,100赫兹。这是CD质量录音的标准。总帧数——接收到的总音频数据点数量——是我们要记录的秒数（在我们的例子中是5秒）的44,100倍。我们将帧数和采样率存储在辅助变量中：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we’re ready to record using the `rec` function of the `sounddevice` library:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`sounddevice`库的`rec`函数开始录制：
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Sets up recording'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 设置录制'
- en: '#2 Waits for recording to finish'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 等待录制完成'
- en: The first command (**1**) starts a recording from the input microphone, providing
    as input the total number of frames to record as well as the sampling rate. The
    number of channels (the third parameter in our invocation) depends on the microphone
    used for the recording. If your microphone has more than one channel, try a higher
    value here. After starting the recording, we just need to wait until the predetermined
    recording time has passed. We accomplish that via the `wait` command (**2**).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令（**1**）从输入麦克风开始录制，提供要录制的总帧数以及采样率。通道数（我们调用中的第三个参数）取决于用于录制的麦克风。如果你的麦克风有多个通道，请在这里尝试更高的值。开始录制后，我们只需等待预定录制时间过去。我们通过`wait`命令（**2**）实现这一点。
- en: 'After executing the previous code, the variable `recording` contains the recorded
    audio data. As discussed earlier, we want to store the recording as a .wav file
    on disk. All it takes is a single command from the `scipy` library:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的代码后，变量`recording`包含录制的音频数据。如前所述，我们希望将录音存储为磁盘上的.wav文件。只需`scipy`库的单个命令即可完成：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: That’s it! We have recorded a few seconds of audio input and stored it in a
    file on disk.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经录制了几秒钟的音频输入，并将其存储在磁盘上的文件中。
- en: 7.3.4 End-to-end code
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.4 端到端代码
- en: Listing [7.2](#code__voicequeries) shows the code for our voice query interface.
    Beyond our default libraries, `openai` and `argparse`, we import (**1**) the libraries
    for audio processing (`sounddevice` and `scipy`), as well as the `sqlite3` library
    (which we will need for processing SQL queries) and the `time` library. The latter
    library is required to wait for a specified amount of time (for voice input).
    Next, we will discuss the functions introduced in listing [7.2](#code__voicequeries).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表[7.2](#code__voicequeries)显示了我们的语音查询界面的代码。除了我们的默认库`openai`和`argparse`之外，我们导入（**1**）音频处理库（`sounddevice`和`scipy`），以及`sqlite3`库（我们将需要它来处理SQL查询）和`time`库。后一个库是等待指定时间（语音输入）所必需的。接下来，我们将讨论列表[7.2](#code__voicequeries)中引入的函数。
- en: Listing 7.2 Querying an SQLite database using voice commands
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.2 使用语音命令查询SQLite数据库
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Imports libraries'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 导入库'
- en: '#2 Extracts the database schema'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 提取数据库模式'
- en: '#3 Records audio'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 录制音频'
- en: '#4 Transcribes audio'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 转写音频'
- en: '#5 Creates a text-to-SQL prompt'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 创建文本到SQL提示'
- en: '#6 Translates to SQL'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 翻译为SQL'
- en: '#7 Processes the SQL query'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 处理SQL查询'
- en: '#8 Processes the voice queries'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 处理语音查询'
- en: '#9 Main loop'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#9 主循环'
- en: '#10 Transcribes voice input'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#10 转写语音输入'
- en: '#11 SQL translation'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#11 SQL翻译'
- en: '#12 Executes the SQL query'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#12 执行SQL查询'
- en: We process voice queries that refer to data in a relational database. To translate
    voice commands into formal queries formulated in SQL, we need to know a little
    about the database structure. In particular, we need to know the names of the
    data tables and their columns (i.e., we need to know the database schema). The
    function `get_structure` (**2**) retrieves the commands used to create the database
    schema. These commands contain the names of tables and columns, as well as the
    data types associated with the table columns. We will use those commands as part
    of a prompt, instructing the language model to translate questions into SQL queries.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们处理指向关系数据库中数据的语音查询。要将语音命令翻译成以SQL形式表述的正式查询，我们需要了解一些数据库结构的知识。特别是，我们需要知道数据表和它们的列的名称（即，我们需要知道数据库模式）。函数`get_structure`（**2**）检索创建数据库模式的命令。这些命令包含表和列的名称，以及与表列关联的数据类型。我们将使用这些命令作为提示的一部分，指导语言模型将问题翻译成SQL查询。
- en: Before we can translate questions, we first need to record them from the microphone.
    This is where the function `record` (**3**) comes into play. It uses the `sounddevice`
    library to record 5 consecutive seconds of audio input from the microphone. The
    resulting audio recording is stored as a .wav file on disk at a path specified
    as function input (parameter `output_path`). Strictly speaking, storing the audio
    input as a file is not necessary (we can process it directly in memory). However,
    storing audio input on disk can be useful for debugging purposes. If our system
    fails to translate voice input to appropriate queries, we can listen to the audio
    file ourselves to assess the level of background noise and overall audio quality.
    If the microphone is not set up properly (a common problem), our audio files will
    contain nothing but silence.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以将问题翻译之前，我们首先需要从麦克风录制它们。这就是函数`record`（**3**）发挥作用的地方。它使用`sounddevice`库从麦克风录制5连续秒的音频输入。生成的音频录音以.wav文件的形式存储在磁盘上，路径由函数输入（参数`output_path`）指定。严格来说，将音频输入存储为文件不是必要的（我们可以直接在内存中处理它）。然而，将音频输入存储在磁盘上对于调试目的可能很有用。如果我们系统无法将语音输入翻译成适当的查询，我们可以自己听音频文件来评估背景噪声水平和整体音频质量。如果麦克风设置不当（一个常见问题），我们的音频文件将只包含静音。
- en: After recording input from the microphone, we first want to transcribe voice
    input to text. We use the `transcribe` function (**4**) for that. Given a path
    to an audio file (in this case, recorded audio input from the microphone), it
    returns a transcript generated using OpenAI’s Whisper model (the same one we used
    previously).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在从麦克风录制输入之后，我们首先希望将语音输入转录成文本。我们使用`transcribe`函数（**4**）来完成这项工作。给定音频文件的路径（在这种情况下，来自麦克风的录音音频输入），它返回使用OpenAI的Whisper模型（我们之前使用过的同一个模型）生成的转录文本。
- en: Next, we want to translate questions into formal SQL queries. Of course, we
    will use language models for that task. The `create_prompt` function (**5**) generates
    a suitable prompt. The prompt contains the previously extracted description of
    the database, the transcribed question, and the task description. The `call_llm`
    function (**6**) calls GPT-4o to translate questions, given the previously mentioned
    prompt as input. Finally, the `process_query` function (**7**) processes the resulting
    queries on the database and returns the query result.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们希望将问题翻译成正式的SQL查询。当然，我们将使用语言模型来完成这项任务。`create_prompt`函数（**5**）生成一个合适的提示。提示包含之前提取的数据库描述、转录的问题和任务描述。`call_llm`函数（**6**）调用GPT-4o，根据之前提到的提示将问题翻译成查询。最后，`process_query`函数（**7**）在数据库上处理生成的查询并返回查询结果。
- en: Time to put it all together! Our voice query interface takes the path to an
    SQLite database file as input (**8**). After extracting the database schema, we
    enter the main loop (**9**). Each iteration processes one voice query (unless
    the user enters `quit`, in which case the program terminates). To keep things
    simple, we wait for the user to press the Enter key before recording voice input
    (a more sophisticated version would record continuously). After that, we record
    voice input from the microphone. We print out the transcribed question and store
    the recording itself as question.wav on disk (**10**). Next, we translate the
    transcribed text into a query (**11**), execute it (**12**) (we need exception
    handling here in case of incorrect queries!), and show the result to users.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候将所有这些整合在一起了！我们的语音查询界面以 SQLite 数据库文件的路径作为输入（**8**）。在提取数据库模式后，我们进入主循环（**9**）。每次迭代处理一个语音查询（除非用户输入
    `quit`，在这种情况下程序将终止）。为了简化问题，我们在记录语音输入之前等待用户按下 Enter 键（一个更复杂的版本会持续记录）。之后，我们从麦克风记录语音输入。我们打印出转录的问题，并将录音本身作为
    question.wav 存储在磁盘上（**10**）。接下来，我们将转录的文本翻译成查询（**11**），执行它（**12**）（如果查询不正确，我们需要异常处理！），并将结果展示给用户。
- en: 7.3.5 Trying it out
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.5 尝试一下
- en: Listing [7.2](#code__voicequeries) is listing 2 in the chapter 7 section on
    the book’s website. Download the code, and switch to the containing folder in
    your terminal.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 [7.2](#code__voicequeries) 是第 7 章节在本书网站上的第 2 个列表。下载代码，并在终端中切换到包含文件夹。
- en: 'Beyond the code, we also need an SQLite database to try our voice query interface.
    We discuss in chapter 5 how to set up an example database containing information
    about computer game sales. We assume this database is stored in the same folder
    as your code and named games.db (of course, you are free to use any SQLite database
    you like to try the voice query interface). Now enter the following command in
    the terminal:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 除了代码之外，我们还需要一个 SQLite 数据库来尝试我们的语音查询界面。在第 5 章中，我们讨论了如何设置一个包含有关电脑游戏销售信息的示例数据库。我们假设这个数据库存储在与你的代码相同的文件夹中，命名为
    games.db（当然，你可以自由使用任何你喜欢的 SQLite 数据库来尝试语音查询界面）。现在在终端中输入以下命令：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Update the path to the database file to the one you want to access. Depending
    on your operating system and security settings, you may be asked to enable microphone
    access for your application. After enabling microphone access, press Enter, and
    ask a question! For instance, using the games database, you may ask “How many
    games were sold in 2007?” or “How many games were released for each genre?” You
    should see output like the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据库文件的路径更新为你想要访问的路径。根据你的操作系统和安全设置，你可能需要为你的应用程序启用麦克风访问。在启用麦克风访问后，按 Enter 键，提出一个问题！例如，使用游戏数据库，你可以问“2007
    年卖出了多少款游戏？”或者“每个游戏类型都发布了多少款游戏？”你应该看到如下输出：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This output includes the transcribed question, the translated SQL query, and
    the query result (or an error message if the query cannot be executed). Clearly,
    it’s a long way from a voice question to a query result! A mistake in recording,
    transcription, or translation will lead to incorrect results. Before trusting
    the query result, be sure to check the additional output to verify that the system
    did not make any mistakes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出包括转录的问题、翻译的 SQL 查询以及查询结果（如果查询无法执行，则为错误消息）。显然，从语音问题到查询结果还有很长的路要走！在录音、转录或翻译中出现的错误会导致结果不正确。在信任查询结果之前，请务必检查附加输出以验证系统没有犯任何错误。
- en: Tip If your voice interface only produces nonsense, check the recordings in
    question.wav. If you don’t hear anything, make sure your application has access
    to your microphone. By default, applications typically have no access to the microphone
    (making it harder to spy on you with malicious software). You need to update your
    security settings to enable access.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：如果你的语音界面只产生无意义的内容，请检查 question.wav 中的录音。如果你什么也听不到，请确保你的应用程序有权访问你的麦克风。默认情况下，应用程序通常没有访问麦克风的权限（这使得恶意软件更难监视你）。你需要更新你的安全设置以启用访问。
- en: 7.4 Speech-to-speech translation
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 语音到语音翻译
- en: 'The Banana branch in Paris has started looking into language models and potential
    applications for data science tasks. You have grown your reputation as the local
    expert on the topic, and your manager asks you to advise the French team on how
    to get started. There is just one tiny problem: you don’t speak any French. On
    hearing that Banana Paris conducts most staff meetings in French, you are about
    to decline the assignment. But after thinking about it, you realize that this
    may not be a dealbreaker after all. Although you don’t speak any French, GPT-4o
    certainly does! Would it be possible to use language models to translate for you?'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 巴黎的香蕉分支已经开始研究语言模型以及其在数据科学任务中的潜在应用。你在该领域的本地专家声誉日益增长，你的经理要求你向法国团队提供如何开始的建议。但有一个小问题：你不会说法语。当听说香蕉巴黎的员工会议大多用法语进行时，你正准备拒绝这项任务。但经过思考，你意识到这可能并不是一个不可逾越的障碍。尽管你不会说法语，但GPT-4o肯定可以！能否使用语言模型为你进行翻译？
- en: You can indeed use language models to translate between various languages. In
    this section, we will create a translator tool that takes spoken input in a first
    language and produces spoken output in a second language. Because the tool produces
    spoken output, you don’t even need to learn the French pronunciation. Simply speak
    English and wait for the tool to produce a spoken translation. That way, you can
    collaborate with your French colleagues while simultaneously demonstrating the
    capabilities of state-of-the-art language models!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你确实可以使用语言模型在多种语言之间进行翻译。在本节中，我们将创建一个翻译工具，它接受第一语言的口语输入并产生第二语言的口语输出。因为该工具产生口语输出，你甚至不需要学习法语发音。只需说英语，等待工具生成口语翻译。这样，你可以在与法国同事合作的同时，同时展示最先进语言模型的能力！
- en: 7.4.1 Overview
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 概述
- en: Our translator tool processes spoken input. As before, we will use OpenAI’s
    Whisper model to transcribe input speech to text. Then, we will use the GPT-4o
    model to translate the text to a different language. For our example scenarios,
    we use French as the target language. However, due to the amazing flexibility
    of models like GPT-4o, our tool won’t be restricted to that! Our tool will enable
    users to specify the target language as input, to be used as a text snippet in
    the prompt instructing the language model for the translation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的翻译工具处理口语输入。和之前一样，我们将使用OpenAI的Whisper模型将输入语音转录成文本。然后，我们将使用GPT-4o模型将文本翻译成另一种语言。在我们的示例场景中，我们使用法语作为目标语言。然而，由于GPT-4o等模型惊人的灵活性，我们的工具不会仅限于这一点！我们的工具将使用户能够指定目标语言作为输入，用作提示语言模型进行翻译的文本片段。
- en: After generating a text translation, we still want to generate a spoken version.
    It turns out that we can use yet another OpenAI model to transform text into spoken
    output in various languages. Figure [7.2](#fig__TranslatorOverview) shows the
    complete processing pipeline, starting with spoken input in a first language and
    ending with spoken output in a second.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成文本翻译之后，我们还想生成一个口语版本。结果证明，我们可以使用另一个OpenAI模型将文本转换为各种语言的口语输出。图[7.2](#fig__TranslatorOverview)展示了完整的处理流程，从第一语言的口语输入开始，到第二语言的口语输出结束。
- en: '![figure](../Images/CH07_F02_Trummer.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F02_Trummer.png)'
- en: Figure 7.2 Our translator tool records spoken input in a first language, transcribes
    input to text, trans- lates that text into a second language, and finally generates
    spoken output.
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.2 我们的翻译工具记录第一语言的口语输入，将输入转录成文本，将文本翻译成第二语言，并最终生成口语输出。
- en: 7.4.2 Generating speech
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 生成语音
- en: The pipeline in figure [7.2](#fig__TranslatorOverview) requires several transformations.
    We already saw how to transcribe spoken input to text in the previous sections.
    Translating text via language models is relatively straightforward (ask GPT-4o
    to translate from one language to another, and it will do so). We are still missing
    a way to transform written text (e.g., in French) into spoken output. We discuss
    how to do that next.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图[7.2](#fig__TranslatorOverview)中的流程需要几个转换。我们已经在之前的章节中看到了如何将口语输入转录成文本。通过语言模型进行文本翻译相对简单（让GPT-4o将一种语言翻译成另一种语言，它就会这样做）。我们仍然缺少将书面文本（例如，法语）转换为口语输出的方法。我们将在下一节讨论如何做到这一点。
- en: 'OpenAI (as well as other providers) offers several text-to-speech (TTS) models.
    Such models take written text as input and produce a spoken version as output.
    The following piece of code generates speech for a text string (stored in the
    variable `speech_text`):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI（以及其他提供商）提供多种文本到语音（TTS）模型。此类模型以书面文本为输入，生成语音输出。以下代码片段为文本字符串（存储在变量 `speech_text`
    中）生成语音：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We’re using a new endpoint in this instance (`audio.speech`) and configuring
    the `create` method using three parameters:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了一个新的端点（`audio.speech`）并使用三个参数配置了 `create` 方法：
- en: '`model`—The name of the model used to generate spoken output. We use OpenAI’s
    `tts-1` text-to-speech model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`—用于生成语音输出的模型名称。我们使用 OpenAI 的 `tts-1` 文本到语音模型。'
- en: '`input`—We generate spoken output for this text. Submit text in any of the
    various languages supported by the model ([https://github.com/openai/whisper](https://github.com/openai/whisper)).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`—为这段文本生成语音输出。提交任何模型支持的语言中的文本（[https://github.com/openai/whisper](https://github.com/openai/whisper)）。'
- en: '`voice`—We can choose between different voices for speech. Here, we use `alloy`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`voice`—我们可以选择不同的语音进行语音输出。在这里，我们使用 `alloy`。'
- en: That’s all we need to generate speech output via OpenAI! We already know how
    to transcribe speech and how to translate text between different languages, so
    we now have all we need to code our translator tool.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是通过 OpenAI 生成语音输出的所有所需内容！我们已经知道如何转录语音以及如何在不同语言之间翻译文本，因此我们现在拥有了编写翻译工具所需的一切。
- en: What about pricing?
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关于定价呢？
- en: At the time of writing, OpenAI charges 1.5 cents per 1,000 tokens for text generation
    using the TTS model and twice that for the high-quality version (TTS HD). These
    prices are likely to change over time, so be sure to look at OpenAI’s pricing
    website ([https://openai.com/pricing](https://openai.com/pricing)) for updated
    information.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，OpenAI 使用 TTS 模型进行文本生成时，每 1,000 个标记收费 1.5 美分，而高质量版本（TTS HD）则是这个价格的两倍。这些价格可能会随时间变化，因此请务必查看
    OpenAI 的定价网站 ([https://openai.com/pricing](https://openai.com/pricing)) 以获取最新信息。
- en: 7.4.3 End-to-end code
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.3 端到端代码
- en: Listing [7.3](#code__translator) shows the complete code for our translator
    tool. Let’s start by discussing the libraries it imports (**1**). Besides the
    `openai` and `argparse` libraries included in each project so far, we import `sounddevice`
    and `scipy` to record and store audio files, along with the `time` library to
    limit recording time.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 [7.3](#code__translator) 展示了我们翻译工具的完整代码。让我们首先讨论它导入的库（**1**）。除了每个项目至今包含的 `openai`
    和 `argparse` 库之外，我们还导入了 `sounddevice` 和 `scipy` 以记录和存储音频文件，以及 `time` 库以限制录音时间。
- en: Listing 7.3 Translating spoken input into a different language
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.3 将语音输入翻译为不同语言
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Imports libraries'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 导入库'
- en: '#2 Records audio'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 录制音频'
- en: '#3 Transcribes audio'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 转录音频'
- en: '#4 Generates a prompt for translation'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 生成翻译提示'
- en: '#5 Uses the language model'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 使用语言模型'
- en: '#6 Generates speech'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 生成语音'
- en: '#7 Translates speech to speech'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 将语音翻译为语音'
- en: '#8 Main loop'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 主循环'
- en: '#9 Transcribes the input'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '#9 转录输入'
- en: '#10 Translates to the target language'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '#10 翻译为目标语言'
- en: '#11 Generates speech output'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#11 生成语音输出'
- en: '#12 Plays the generated speech'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '#12 播放生成的语音'
- en: The `playsound` library is used to play audio files generated by OpenAI’s models.
    Because we generate speech via OpenAI’s HTTP interface, we import the `requests`
    library to create HTTP requests. Next, we will discuss the functions used in listing
    [7.3](#code__translator).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `playsound` 库播放 OpenAI 模型生成的音频文件。因为我们通过 OpenAI 的 HTTP 接口生成语音，所以我们导入 `requests`
    库来创建 HTTP 请求。接下来，我们将讨论列表 [7.3](#code__translator) 中使用的函数。
- en: As in the previous project, we record audio data from the microphone. The `record`
    function (**2**) records 5 seconds of audio input and stores it into a .wav file
    on disk. The `transcribe` function (**3**) transcribes that audio input to text.
    Both functions have been discussed in more detail in the prior projects in this
    chapter.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的项目一样，我们从麦克风录制音频数据。`record` 函数（**2**）记录 5 秒的音频输入并将其存储到磁盘上的 .wav 文件中。`transcribe`
    函数（**3**）将音频输入转录为文本。这两个函数在本章之前的项目中已有详细讨论。
- en: The `create_prompt` function (**4**) generates a prompt for translation. As
    in prior projects, the prompt contains a task description, together with all relevant
    input data. In this case, we want to translate from the initial language (English)
    to the target language (French). Note that the target language is specified as
    an input parameter (`to_language`). This input parameter corresponds to a text
    snippet describing the desired output language. In the simplest case, this can
    be the name of a language (e.g., “French”). On the other hand, users can request
    a specific dialect (e.g., “German with Swabian dialect”) or style (e.g., “English
    in the style of Shakespeare”). The target language is integrated into the task
    description that appears in the prompt along with the text to translate.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_prompt`函数（**4**）生成用于翻译的提示。与先前的项目一样，提示包含任务描述以及所有相关输入数据。在这种情况下，我们希望将初始语言（英语）翻译为目标语言（法语）。请注意，目标语言作为输入参数（`to_language`）指定。此输入参数对应于描述所需输出语言的文本片段。在最简单的情况下，这可以是语言名称（例如，“法语”）。另一方面，用户可以请求特定的方言（例如，“带有施瓦本方言的德语”）或风格（例如，“莎士比亚风格的英语”）。目标语言被整合到提示中出现的任务描述中，以及要翻译的文本。'
- en: Note that we do not need to specify the input language. We assume that the language
    model is able to recognize the language of the input text (otherwise, we cannot
    expect the model to translate either).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们不需要指定输入语言。我们假设语言模型能够识别输入文本的语言（否则，我们无法期望模型进行翻译）。
- en: After invoking the `call_llm` function (**5**) with the prompt, we should obtain
    translated text. The `generate_speech` function (**6**) generates the corresponding
    speech using the approach we discussed in the previous section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用提示调用`call_llm`函数（**5**）后，我们应该获得翻译后的文本。`generate_speech`函数（**6**）使用我们在上一节中讨论的方法生成相应的语音。
- en: The translator application (**7**) expects as input a text describing the target
    language. This parameter is a string that can contain arbitrary text. It simply
    replaces a placeholder in the prompt used for translation. In the main loop (**8**),
    users press Enter to speak or enter `quit` to terminate the application.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译应用（**7**）期望输入一个描述目标语言的文本。此参数是一个字符串，可以包含任意文本。它只是简单地替换了用于翻译的提示中的占位符。在主循环（**8**）中，用户按下Enter键进行语音输入或输入`quit`以终止应用。
- en: When recording user input, we first store 5 seconds of audio recording in a
    file named to_translate.wav before transcribing the input via the `transcribe`
    function (**9**). After that, we use GPT-4o to translate the input to the target
    language (**10**) and then generate speech from the translation (**11**). We store
    the generated speech as an .mp3 file on disk (this means we can easily hear the
    last output again) and, finally, use the `playsound` library to—you guessed it—play
    the generated sound file.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在记录用户输入时，我们首先使用`transcribe`函数（**9**）转录输入之前，将5秒的音频录音存储在名为to_translate.wav的文件中。之后，我们使用GPT-4o将输入翻译为目标语言（**10**），然后从翻译中生成语音（**11**）。我们将生成的语音作为磁盘上的.mp3文件存储（这意味着我们可以轻松地再次听到最后一个输出）并最终使用`playsound`库——正如你所猜到的——播放生成的声音文件。
- en: 7.4.4 Trying it out
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.4 尝试运行
- en: 'Time to try our translator! You can find the code on the companion website
    as listing 3 in the chapter 7 section. Download the code, and switch to the containing
    folder in the terminal. We can choose our target language for translation. Of
    course, the quality of the translation and sound output may vary, depending on
    that choice. In particular, the model we use for transcription, as well as the
    model we use for speech generation, support a set of about 60 common languages.
    Transcribing audio input or generating audio output in less common languages may
    fail. Look online to see the current list of supported languages for transcription
    ([https://help.openai.com/en/articles/7031512-whisper-api-faq](https://help.openai.com/en/articles/7031512-whisper-api-faq))
    as well as speech generation ([https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech)).
    For now, consistent with our scenario at the beginning of this section, we will
    go with French as the target language. In the terminal, enter the following command
    to start our translator:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候尝试我们的翻译器了！您可以在配套网站上找到代码，在第7章的列表3中。下载代码，并在终端中切换到包含文件夹。我们可以选择我们的目标语言进行翻译。当然，翻译的质量和声音输出可能因选择而异。特别是，我们用于转录的模型以及我们用于语音生成的模型支持大约60种常见语言。在不太常见的语言中转录音频输入或生成音频输出可能会失败。请在网上查看当前支持的转录语言列表（[https://help.openai.com/en/articles/7031512-whisper-api-faq](https://help.openai.com/en/articles/7031512-whisper-api-faq)）以及语音生成（[https://platform.openai.com/docs/guides/text-to-speech](https://platform.openai.com/docs/guides/text-to-speech)）。目前，与这一节开头的场景保持一致，我们将选择法语作为目标语言。在终端中，输入以下命令以启动我们的翻译器：
- en: '[PRE18]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Strictly speaking, the quotes around the word “French” are unnecessary. However,
    as we can enter multiword descriptions of the desired target language, we will
    need quotes in the following examples to avoid errors if the console misinterprets
    our input as values for multiple parameters.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，单词“French”周围的引号是不必要的。然而，由于我们可以输入多词描述所需的目标语言，我们将在以下示例中使用引号，以避免控制台错误地将我们的输入解释为多个参数的值。
- en: 'As in our previous project, we need to give our application access to the microphone.
    Click Yes if you are asked for microphone access; if not, be sure the security
    settings allow it. The following is an extract from a conversation with our translator
    tool:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前的项目一样，我们需要给我们的应用程序访问麦克风的权限。如果您被要求访问麦克风，请点击“是”；如果没有，请确保安全设置允许这样做。以下是从我们与翻译工具的对话中摘录的内容：
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You see transcribed input and the generated translation. You should also hear
    the spoken version of the translation (if not, check your settings for audio output).
    Not bad for a few lines of Python code!
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到转录的输入和生成的翻译。您还应该听到翻译的口语版本（如果没有，请检查您的音频输出设置）。对于几行Python代码来说，这已经很不错了！
- en: 'Translating to French seems like a reasonable use case for our translator tool.
    However, it may not be the one with the highest “fun factor.” Let’s try something
    different to show the flexibility of language models: let’s see if we can “translate”
    our audio input to a highly polished version. In the terminal, enter the following
    instructions:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 将内容翻译成法语似乎是我们翻译工具的一个合理用例。然而，它可能不是“乐趣因素”最高的一个。让我们尝试一些不同的事情，以展示语言模型的灵活性：让我们看看我们是否可以将音频输入“翻译”成高度精炼的版本。在终端中，输入以下指令：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is what we get when translating our simple greeting into a much more refined
    version (perhaps a nice intro to a course on language models for our U.S. colleagues
    at Banana):'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将简单的问候语翻译成更精致版本（可能是一堂语言模型课程的良好介绍，针对我们的美国同事在Banana公司）的结果：
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Try a few more target languages! The possibilities are (almost) unlimited.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试更多目标语言！可能性几乎是无限的。
- en: Summary
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: OpenAI’s Whisper model transcribes speech input to text.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI的Whisper模型可以将语音输入转录成文本。
- en: Access transcription via the audio transcriptions endpoint.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过音频转录端点访问转录功能。
- en: Pricing for transcription is based on the number of minutes.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转录的价格基于分钟数。
- en: OpenAI offers several models for generating speech from text.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI提供多种模型，用于将文本生成语音。
- en: You can choose the voice and quality for generated speech.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以选择生成语音的语音和音质。
- en: Speech generation pricing depends on the number of tokens.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音生成定价取决于令牌数量。
