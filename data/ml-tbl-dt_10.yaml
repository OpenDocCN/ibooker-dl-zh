- en: 8 Getting started with deep learning with tabular data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 使用表格数据开始深度学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: An introduction to deep learning with tabular data stacks—low-level frameworks
    and high-level APIs for deep learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用表格数据堆栈的深度学习简介—深度学习的低级框架和高级API
- en: The PyTorch with fastai stack
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch与fastai堆栈
- en: The PyTorch with TabNet stack
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch与TabNet堆栈
- en: The PyTorch with Lightning Flash stack
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch与Lightning Flash堆栈
- en: The stacks we didn’t exercise and why we didn’t exercise them
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有练习的堆栈以及为什么没有练习它们
- en: A comparison of the pros and cons of deep learning with tabular data stacks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习表格数据堆栈的优缺点比较
- en: Up to this point, we have focused on classical machine learning tools and algorithms
    to analyze tabular data. Ranging from traditional regression algorithms to more
    sophisticated gradient boosting techniques, these approaches offer advantages
    in simplicity, transparency, and efficacy. That said, deep learning tools have
    become much easier to access and use, and they also provide a powerful alternative
    for handling tabular data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直专注于经典机器学习工具和算法来分析表格数据。从传统的回归算法到更复杂的梯度提升技术，这些方法在简单性、透明性和有效性方面具有优势。尽管如此，深度学习工具的获取和使用变得更加容易，它们也为处理表格数据提供了一个强大的替代方案。
- en: In this chapter, we will review a set of deep learning stacks (low-level framework,
    high-level API, and deep learning for tabular data library) and use three of these
    stacks—fastai, PyTorch with TabNet, and Lightning Flash—to solve the Airbnb NYC
    problem. We’ll work the same problem three times, once with each stack. The goal
    is to illustrate both the general form of the deep learning approach and to highlight
    the unique characteristics of the three tools we’ve selected.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾一系列深度学习堆栈（低级框架、高级API和表格数据深度学习库），并使用这三个堆栈——fastai、PyTorch与TabNet和Lightning
    Flash来解决Airbnb NYC问题。我们将用每个堆栈解决同样的问题三次。目标是展示深度学习方法的通用形式，并突出我们选择的三种工具的独特特性。
- en: 8.1 The deep learning with tabular data stack
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 使用表格数据的深度学习堆栈
- en: 'Before we examine the stacks that are available for deep learning with tabular
    data in general, let’s look at a specific example: the Keras-based deep learning
    solution for the Airbnb NYC price prediction problem from chapter 3.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们检查用于深度学习表格数据的通用堆栈之前，让我们看看一个具体的例子：第3章中描述的基于Keras的深度学习解决方案，用于解决Airbnb NYC价格预测问题。
- en: The Keras solution vs. the XGBoost solution
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Keras解决方案与XGBoost解决方案的比较
- en: The code that is distinct for the Keras solution is contained in the training
    notebook. In particular, the key differences between the Keras solution and the
    XGBoost solution described in chapter 3 include
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 专属于Keras解决方案的代码包含在训练笔记本中。特别是，第3章中描述的Keras解决方案与XGBoost解决方案之间的关键区别包括
- en: '*Model definition*—The Keras model has a large function to define the layers
    that make up the model, with each class of column (continuous, categorical, and
    text) getting a specific set of layers.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型定义*—Keras模型有一个大函数来定义构成模型的层，每个列类（连续、分类和文本）都得到一组特定的层。'
- en: '*Model training*—The Keras model includes additional code to define the callbacks
    required to make the training process efficient, including a callback to stop
    the training process early if the training is no longer making the model better
    and a callback to ensure that the optimal model is saved during the training process.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型训练*—Keras模型包含额外的代码来定义使训练过程高效的回调函数，包括一个回调函数，如果训练不再使模型变得更好，则提前停止训练过程，以及一个回调函数以确保在训练过程中保存最佳模型。'
- en: The Keras solution that we examined in chapter 3 gives us a concrete baseline
    with which to compare the other stacks we will examine in this chapter. In this
    chapter, we will exercise a set of other stacks so you can see the pros and cons
    of each choice.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第3章中我们检查的Keras解决方案为我们提供了一个具体的基线，我们可以用它来比较本章我们将检查的其他堆栈。在本章中，我们将练习一系列其他堆栈，以便您可以看到每个选择的优缺点。
- en: We will also discuss an additional set of stacks that we weren’t able to exercise
    and explain what this experience tells us about these choices. It is important
    to understand the stack choices and the pros and cons of the choices so that you
    can select a deep learning with tabular data stack that works best for your requirements.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论一组我们没有能够练习的堆栈，并解释这一经历告诉我们关于这些选择的信息。了解堆栈选择及其优缺点非常重要，这样您就可以选择最适合您需求的深度学习表格数据堆栈。
- en: Let’s briefly review the Keras solution from chapter 3\. Figure 8.1 shows the
    files that make up the Keras solution, with the training notebook highlighted.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要回顾第3章中的Keras解决方案。图8.1显示了构成Keras解决方案的文件，其中训练笔记本被突出显示。
- en: '![](../Images/CH08_F01_Ryan2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F01_Ryan2.png)'
- en: Figure 8.1 Files that make up the Keras solution to the Airbnb problem
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 解决Airbnb问题的Keras解决方案文件
- en: The training notebook contains the code that varies between the Keras solution
    and the other solutions that we will explore in this chapter. The other files
    stay consistent across all the deep learning solutions, with the exception of
    some settings in the training config file.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 训练笔记本包含在Keras解决方案和其他本章将要探讨的解决方案之间有所不同的代码。其他文件在所有深度学习解决方案中保持一致，除了训练配置文件中的某些设置。
- en: Figure 8.2 shows the components that make up the stack for this solution. These
    components are used in the training notebook.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2显示了构成此解决方案堆栈的组件。这些组件在训练笔记本中使用。
- en: '![](../Images/CH08_F02_Ryan2.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F02_Ryan2.png)'
- en: Figure 8.2 The stack for the Airbnb NYC solution in chapter 3
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 第3章中Airbnb NYC解决方案的堆栈
- en: In this stack the underlying, low-level deep learning framework is TensorFlow.
    Since Keras is delivered as part of the TensorFlow distribution and is the recommended
    high-level API for TensorFlow, it may sound a bit redundant to talk about TensorFlow
    and Keras separately, but keeping them distinct will make the description of the
    general stack choices clearer. In the deep learning solution from chapter 3, we
    used custom-written code to define the model itself. For example, listing 8.1
    shows the custom code that defines layers for categorical columns in the deep
    learning solution from chapter 3\. The listing also shows the statements in the
    `get_model()` function that define the layers for categorical columns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个堆栈中，底层低级深度学习框架是TensorFlow。由于Keras作为TensorFlow的一部分提供，并且是TensorFlow推荐的高级API，因此单独谈论TensorFlow和Keras可能听起来有点多余，但保持它们独立将使一般堆栈选择的描述更清晰。在第3章的深度学习解决方案中，我们使用了自定义编写的代码来定义模型本身。例如，列表8.1显示了第3章深度学习解决方案中定义分类列层的自定义代码。列表还显示了`get_model()`函数中定义分类列层的语句。
- en: Listing 8.1 Statement in the `get_model()`function for categorical column layers
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.1 `get_model()`函数中定义分类列层语句
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ① Defines an input layer to the model for the current column
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ① 为当前列定义一个模型输入层
- en: ② Adds the input layer that was just defined to the list of input layers
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将刚刚定义的输入层添加到输入层列表中
- en: ③ Defines an embedding layer for the current column
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 为当前列定义一个嵌入层
- en: ④ Defines a batch normalization layer for the current column
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 为当前列定义一个批量归一化层
- en: ⑤ Adds the set of layers defined to this column to the overall list of layers
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将定义的层集添加到整体层列表中
- en: 'The `get_model()` function specifies the Keras layers in the model for three
    types of input columns: categorical, continuous, and text. The `get_model()` function
    shown in listing 8.1 also contains statements that define the model layers for
    continuous layers and text layers. Note that this model has multiple inputs (each
    column selected to train the model is an input) and a single output: a prediction
    of whether or not the price of a given Airbnb listing will be above or below the
    median. The details of how the layers for each of the input columns are defined
    is beyond the scope of this chapter, so we won’t go through those now.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_model()`函数指定了模型中三种类型输入列的Keras层：分类、连续和文本。列表8.1中显示的`get_model()`函数还包含定义连续层和文本层模型层的语句。请注意，此模型有多个输入（每个选定的用于训练模型的列都是一个输入）和一个输出：预测给定Airbnb列表的价格是否高于或低于中位数。每个输入列层定义的细节超出了本章的范围，所以我们现在不会详细说明。'
- en: Now that we have reviewed what the stack looks like for the deep learning Airbnb
    NYC solution in chapter 3, let’s generalize to other deep learning approaches
    to tabular data. Figure 8.3 shows a selection of choices for the deep learning
    stack for tabular data problems.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们在第3章中已经回顾了深度学习Airbnb NYC解决方案的堆栈结构，那么让我们将其推广到其他表格数据的深度学习方法。图8.3显示了表格数据问题深度学习堆栈的选择。
- en: '![](../Images/CH08_F03_Ryan2.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F03_Ryan2.png)'
- en: Figure 8.3 Deep learning stacks for tabular data
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 表格数据的深度学习堆栈
- en: 'Let’s examine each layer of the stacks in more detail:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地检查堆栈的每一层：
- en: '*Low-level framework*—There are two predominant low-level deep learning frameworks.
    TensorFlow is used most frequently in industry. PyTorch is the most popular choice
    for researchers.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*低级框架*—有两个主要的低级深度学习框架。在工业界，TensorFlow被使用得最为频繁。PyTorch是研究人员最流行的选择。'
- en: '*High-level API*—To make it easier for beginners to create deep learning applications
    and to abstract some of the complexity for experienced developers, in the mid-2010s
    the need was identified for a high-level API for deep learning. Initially, you
    could use Keras as a front end for several low-level frameworks. In 2019, Keras
    was integrated into the TensorFlow ecosystem and identified as the recommended
    high-level framework for TensorFlow. There isn’t an exact analogy for Keras in
    the PyTorch world. The overall design of PyTorch is supposed to make it more accessible
    than TensorFlow and reduce the need for a high-level API. Nevertheless, there
    are two high-level APIs that abstract different aspects of PyTorch. fastai is
    intended specifically for people coming from other disciplines who want to use
    deep learning to solve problems in their discipline and has as its central ethic
    being able to define, train, and exercise a deep learning model with just a handful
    of lines of code. Lightning, by contrast, abstracts a single aspect of PyTorch,
    the training loop. Lightning Flash, which is built on top of Lightning, is, according
    to its documentation, “a high-level deep learning framework for fast prototyping,
    baselining, fine-tuning and solving deep learning problems.” While both fastai
    and Lightning have devoted communities of users, neither has attracted the popularity
    in the PyTorch world that Keras has in the TensorFlow world.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高级API*—为了使初学者更容易创建深度学习应用，并抽象化一些经验丰富的开发者的复杂性，在2010年代中期，人们发现了对深度学习高级API的需求。最初，您可以使用Keras作为几个低级框架的前端。到2019年，Keras被集成到TensorFlow生态系统中，并被确定为TensorFlow推荐的高级框架。在PyTorch世界中，没有Keras的精确对应物。PyTorch的整体设计旨在使其比TensorFlow更易于使用，并减少对高级API的需求。尽管如此，有两个高级API抽象了PyTorch的不同方面。fastai专门针对来自其他学科的人士，他们希望使用深度学习来解决他们学科中的问题，其核心伦理是只需几行代码就能定义、训练和练习深度学习模型。相比之下，Lightning抽象了PyTorch的单个方面，即训练循环。建立在Lightning之上的Lightning
    Flash，根据其文档，是“一个用于快速原型设计、基准测试、微调和解决深度学习问题的通用深度学习框架。”虽然fastai和Lightning都有专门的用户社区，但它们在PyTorch世界中的受欢迎程度并没有像Keras在TensorFlow世界中的那样。'
- en: '*Tabular data library*—The low-level framework and high-level API provide an
    environment for deep learning in general. The deep learning libraries provide
    capabilities specifically for dealing with tabular data. As we demonstrated with
    the deep learning solution for the Airbnb NYC price prediction problem in chapter
    3, you don’t need to use a tabular data library to do deep learning with tabular
    data.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*表格数据库*—低级框架和高级API为深度学习提供了一个通用环境。深度学习库提供了专门用于处理表格数据的功能。正如我们在第3章中用深度学习解决方案解决Airbnb纽约市价格预测问题所展示的，您不需要使用表格数据库来对表格数据进行深度学习。'
- en: Two details to note about the tabular data libraries are
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 关于表格数据库的两个需要注意的细节是
- en: Tabular data libraries may be supported for both TensorFlow and PyTorch. TabNet
    is an example of a library that is supported for both low-level deep learning
    frameworks.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格数据库可能同时支持TensorFlow和PyTorch。TabNet是支持这两个低级深度学习框架的库的例子。
- en: fastai is a general-purpose, high-level API as well as a tabular data library.
    fastai fits into both categories because it abstracts some of the complexity of
    PyTorch to make it easier to build and train models on a variety of data types
    (including image and text) and also has facilities aimed specifically at tabular
    data (for example, automatically handling basic operations required for categorical
    features in tabular datasets).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fastai是一个通用型、高级API，同时也是表格数据库。fastai符合这两个类别，因为它将PyTorch的一些复杂性抽象化，使其更容易在多种数据类型（包括图像和文本）上构建和训练模型，同时也提供了专门针对表格数据的设施（例如，自动处理表格数据集中分类特征所需的基本操作）。
- en: 'Now that we have examined the deep learning with tabular data stack, let’s
    look at the stacks that we will examine in this chapter by applying them to solve
    the Airbnb NYC price prediction problem:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经检查了表格数据的深度学习堆栈，让我们看看在本章中我们将应用以解决Airbnb纽约市价格预测问题的堆栈：
- en: '*PyTorch with fastai*—This is the most “traditional” approach since fastai
    is an established framework with tens of thousands of developers using it. fastai
    is the most popular framework that explicitly supports tabular data, according
    to repo stars. fastai is particularly popular with people who are learning about
    deep learning and hobbyists.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch with fastai*—这是最“传统”的方法，因为 fastai 是一个成熟的框架，有数万名开发者在使用它。根据仓库星级，fastai
    是一个明确支持表格数据的最受欢迎的框架。fastai 特别受那些正在学习深度学习和爱好者们的欢迎。'
- en: '*PyTorch with TabNet*—TabNet is the next most popular tabular data library
    after fastai according to repo stars. TabNet is a library for tabular data highlighted
    by Google in its documentation ([https://mng.bz/av1m](https://mng.bz/av1m)). This
    stack demonstrates how a dedicated tabular data library can be used to create
    a model trained on tabular data.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch with TabNet*—TabNet 是根据仓库星级在 fastai 之后最受欢迎的表格数据库。TabNet 是一个由 Google
    在其文档中突出的表格数据库（[https://mng.bz/av1m](https://mng.bz/av1m)）。这个堆栈展示了如何使用专门的表格数据库来创建在表格数据上训练的模型。'
- en: '*Lightning Flash*—PyTorch Lightning is a popular framework that abstracts some
    of the complexity of PyTorch. Lightning Flash is built on top of PyTorch Lightning
    and offers an easily accessible way to create deep learning applications. It also
    includes explicit support for tabular data and thus is an interesting comparison
    point for the other stacks we review in this chapter.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Lightning Flash*—PyTorch Lightning 是一个流行的框架，它抽象了一些 PyTorch 的复杂性。Lightning
    Flash 是建立在 PyTorch Lightning 之上的，提供了一个创建深度学习应用的便捷方式。它还包括对表格数据的显式支持，因此是本章中我们审查的其他堆栈的一个有趣的比较点。'
- en: The next three sections in this chapter describe the solution to the Airbnb
    NYC price prediction problem using each of these three stacks. In each section
    we will review the code for a solution and compare the pros and cons of the solution
    with those of our baseline, the Keras solution from chapter 3.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本章接下来的三个部分描述了使用这三个堆栈中的每一个来解决 Airbnb 纽约价格预测问题的解决方案。在每个部分中，我们将审查解决方案的代码，并比较解决方案的优缺点与第
    3 章中我们的基线，即 Keras 解决方案的优缺点。
- en: 8.2 PyTorch with fastai
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 使用 fastai 的 PyTorch
- en: 'Now let’s take a look at one of the toolkits: PyTorch/fastai. Because we’re
    considering the same dataset and problem we just discussed, we won’t rehash it
    here. Much of the solution is quite similar among the different toolkits. Here,
    we’ll concentrate on the distinctive portions of the PyTorch code. You can find
    the complete solution in the code repository for the book: [https://mng.bz/gaBv](https://mng.bz/gaBv).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看其中一个工具包：PyTorch/fastai。因为我们正在考虑与刚才讨论的相同的数据集和问题，所以我们在这里不会重复。大部分解决方案在不同工具包之间非常相似。在这里，我们将专注于
    PyTorch 代码的独特部分。您可以在本书的代码仓库中找到完整的解决方案：[https://mng.bz/gaBv](https://mng.bz/gaBv)。
- en: 8.2.1 Reviewing the key code aspects of the fastai solution
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 审查 fastai 解决方案的关键代码方面
- en: Now let’s dive into the fastai solution to our Airbnb NYC listing price prediction
    problem. To start with, fastai has a unique set of imports, as shown in listing
    8.2, that get the libraries required to use fastai in a Jupyter notebook.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨 fastai 解决方案来解决 Airbnb 纽约列表价格预测问题。首先，fastai 有一个独特的导入集合，如列表 8.2 所示，它获取在
    Jupyter notebook 中使用 fastai 所需的库。
- en: Listing 8.2 Import statements for the fastai solution
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.2 fastai 解决方案的导入语句
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Installs the libraries for using fastai in a Jupyter notebook
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ① 安装用于在 Jupyter notebook 中使用 fastai 的库
- en: ② Imports the libraries for using fastai in a Jupyter notebook
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ② 导入用于在 Jupyter notebook 中使用 fastai 的库
- en: ③ Imports the libraries for working with tabular datasets in fastai
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 导入用于在 fastai 中处理表格数据集的库
- en: With these libraries imported as shown in listing 8.2, you have the libraries
    required to run a fastai tabular data application in a Jupyter notebook.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表 8.2 所示，导入这些库后，您就有了在 Jupyter notebook 中运行 fastai 表格数据应用所需的库。
- en: Next, fastai needs to have the characteristics of the tabular dataset defined,
    including the column that contains the target for the model (called the *dependent
    variable* in fastai) and the lists for the categorical and continuous columns,
    as shown in the following listing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，fastai 需要定义表格数据集的特征，包括包含模型目标列（在 fastai 中称为*因变量*）的列以及分类和连续列的列表，如下所示。
- en: Listing 8.3 Dataset definition statements for the fastai solution
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.3 fastai 解决方案的表格定义语句
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① Specifies the column in the dataset that contains the target, the value that
    is being predicted by the trained model
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ① 指定包含目标值的列，即训练模型预测的值
- en: ② Specifies the columns in the dataset that are categorical
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ② 指定数据集中哪些列是分类的
- en: ③ Specifies the columns in the dataset that are continuous
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 指定数据集中哪些列是连续的
- en: We’ll use the values defined in listing 8.3 when we define the `TabularDataloaders`
    ([https://mng.bz/5gwO](https://mng.bz/5gwO)) object for this model. The `TabularDatalloaders`
    object encapsulates the samples from the dataset, including the labels, to make
    it easy to work with the dataset.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们定义此模型的 `TabularDataloaders` ([https://mng.bz/5gwO](https://mng.bz/5gwO))
    对象时，我们将使用列表 8.3 中定义的值。`TabularDataloaders` 对象封装了数据集的样本，包括标签，以便于与数据集一起工作。
- en: 'Next, we need to ensure that the target column contains string values:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要确保目标列包含字符串值：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If we don’t do this, we will encounter a subtle problem. To try it for yourself,
    comment out this statement and run the fastai training notebook. You will see
    that the training produces some strange results, as shown in figure 8.4.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不这样做，我们将遇到一个微妙的问题。为了亲自尝试，请注释掉此语句并运行 fastai 训练笔记本。您将看到训练产生了一些奇怪的结果，如图 8.4
    所示。
- en: '![](../Images/CH08_F04_Ryan2.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F04_Ryan2.png)'
- en: Figure 8.4 fastai training results when the target column is not explicitly
    converted to string values
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 当目标列未显式转换为字符串值时的 fastai 训练结果
- en: Figure 8.4 shows the results for each epoch of the training process, including
    the training loss, the validation loss, and the accuracy. The accuracy values
    shown in figure 8.4 are significantly lower than the accuracy we saw in chapter
    3 for the XGBoost and Keras deep learning solutions (between 79% and 81%), and
    accuracy does not improve from one epoch to another. Training for a larger number
    of epochs doesn’t help; the accuracy stays the same. Why does fastai produce such
    disappointing results? There’s a clue in the output of the `learn.loss_func` statement,
    as shown in the following listing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 显示了训练过程的每个时期的训练结果，包括训练损失、验证损失和准确率。图 8.4 中显示的准确率值明显低于第 3 章中 XGBoost 和 Keras
    深度学习解决方案的准确率（在 79% 到 81% 之间），并且准确率从一个时期到另一个时期没有提高。训练更多时期没有帮助；准确率保持不变。为什么 fastai
    会产生如此令人失望的结果？在 `learn.loss_func` 语句的输出中有一个线索，如下所示。
- en: Listing 8.4 Statement to show the loss function used in model training
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.4 显示模型训练中使用的损失函数的语句
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① Statement that returns the loss function used in training the fastai model
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ① 返回用于训练 fastai 模型的损失函数的语句
- en: ② Statement output showing the loss function used in training the fastai model
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ② 显示用于训练 fastai 模型的损失函数的语句输出
- en: The output shown in listing 8.4 shows the loss function being used for the model.
    If you don’t specify a loss function for the fastai model, fastai selects a loss
    function based on the values in the target column. We want to train a classification
    model, so the loss function should be cross-entropy. However, it looks like fastai
    selected a loss function for a regression problem rather than a classification
    problem. That’s why the training results shown in listing 8.4 are bad—fastai is
    trying to solve a classification problem (predicting a continuous value) rather
    than the classification problem we intended (predicting a 0 or a 1 to indicate
    whether the listing has a price above or below the median price).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.4 中显示的输出显示了用于模型的损失函数。如果您没有为 fastai 模型指定损失函数，fastai 将根据目标列中的值选择一个损失函数。我们想要训练一个分类模型，因此损失函数应该是交叉熵。然而，看起来
    fastai 选择了一个用于回归问题的损失函数而不是分类问题。这就是为什么列表 8.4 中显示的训练结果不佳——fastai 正在尝试解决一个分类问题（预测一个连续值）而不是我们想要的分类问题（预测一个
    0 或 1 来指示列表的价格是否高于或低于中位数价格）。
- en: The output of `dls.valid.show_batch()`, as shown in figure 8.5, gives us another
    clue because the values in the `target` column are floating point when they should
    be “0” or “1.”
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`dls.valid.show_batch()` 的输出，如图 8.5 所示，提供了另一个线索，因为当 `target` 列中的值应该是“0”或“1”时，它们是浮点数。'
- en: '![](../Images/CH08_F05_Ryan2.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F05_Ryan2.png)'
- en: Figure 8.5 Sample batch values when the target column is not explicitly converted
    to string values
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 当目标列未显式转换为字符串值时的样本批次值
- en: If we go back and look at the dataset using `merged_data.head()`, as shown in
    figure 8.6, the values in the `target` column all look like 0 or 1.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用 `merged_data.head()` 回到数据集查看，如图 8.6 所示，`target` 列中的值看起来都是 0 或 1。
- en: These values in the `target` column are, in fact, numeric values, which means
    that if we don’t explicitly convert them to strings, then by default fastai will
    assume that if we use this dataset to train a model, the model desired is a regression
    model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 `target` 列中的值实际上是数值，这意味着如果我们没有明确地将它们转换为字符串，那么默认情况下，fastai 将假设如果我们使用此数据集来训练模型，所需的模型是回归模型。
- en: '![](../Images/CH08_F06_Ryan2.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F06_Ryan2.png)'
- en: Figure 8.6 Sample batch values when the target column is explicitly converted
    to string values
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 当目标列明确转换为字符串值时的样本批处理值
- en: Now that we have examined why it’s critical to convert the values in the `target`
    column to string values, let’s review the rest of the code to create a trained
    fastai model. Listing 8.5 shows the block of code that defines the `TabularDataLoaders`
    object. This object is a tabular-data specific wrapper around the PyTorch `DataLoader`
    ([https://mng.bz/6eDe](https://mng.bz/6eDe)) object, which is an iterable encapsulation
    of the samples and labels in a dataset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经探讨了为什么将 `target` 列中的值转换为字符串值是至关重要的，那么让我们回顾一下创建训练好的 fastai 模型的其余代码。列表 8.5
    显示了定义 `TabularDataLoaders` 对象的代码块。该对象是围绕 PyTorch `DataLoader` ([https://mng.bz/6eDe](https://mng.bz/6eDe))
    对象的表格数据特定包装器，它是对数据集中的样本和标签的可迭代封装。
- en: Listing 8.5 Defining the `TabularDataLoaders` object
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.5 定义 `TabularDataLoaders` 对象
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① Sets a placeholder value for the path object
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ① 为路径对象设置占位符值
- en: ② Defines the transformations procedures to be applied to the dataset in the
    implied pipeline
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义在隐式管道中应用于数据集的转换过程
- en: ③ Specifies that the TabularDataLoaders object is based on the merged_data dataframe
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 指定 TabularDataLoaders 对象基于合并后的数据框 merged_data
- en: ④ Specifies the list of transformations to apply with the TabularDataLoaders
    object
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 指定使用 TabularDataLoaders 对象应用的转换列表
- en: ⑤ Specifies the categorical features
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 指定分类特征
- en: ⑥ Specifies the continuous features
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 指定连续特征
- en: ⑦ Specifies the target feature
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 指定目标特征
- en: ⑧ Specifies the subset of the dataset to use for validation in the training
    process
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 指定在训练过程中用于验证的数据集子集
- en: ⑨ Specifies the batch size
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 指定批处理大小
- en: We will use the `TabularDataLoaders` object defined in listing 8.5 to define
    the fastai model shown in listing 8.7.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用列表 8.5 中定义的 `TabularDataLoaders` 对象来定义列表 8.7 中显示的 fastai 模型。
- en: One of the characteristics of fastai is a set of convenience functions that
    makes it easy to examine the dataset through the stages of training. The `show_batch()`
    statement shown in the following listing is an example of such a convenience function.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 的一个特点是提供了一套便利函数，这使得通过训练阶段检查数据集变得容易。以下列表中显示的 `show_batch()` 语句是此类便利函数的一个例子。
- en: Listing 8.6 Statement to show a batch of the training data
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.6 显示训练数据批次的语句
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The statement shown in listing 8.6 makes it easy to see what the data that is
    training the model looks like after the transformations specified in the `procs`
    parameter of the `TabularDataLoaders` definition. Figure 8.7 shows the output
    of this statement.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.6 中的语句使得可以轻松地看到在 `TabularDataLoaders` 定义中 `procs` 参数指定的转换之后，训练模型的数据看起来像什么。图
    8.7 显示了此语句的输出。
- en: '![](../Images/CH08_F07_Ryan2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F07_Ryan2.png)'
- en: Figure 8.7 Output of the `show_batch()` statement
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 `show_batch()` 语句的输出
- en: Now that we have specified the data that will be used to train the model, it’s
    time to define and train the model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经指定了将用于训练模型的数据，是时候定义和训练模型了。
- en: Listing 8.7 Defining and fitting the fastai model
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.7 定义和拟合 fastai 模型
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ① Defines the model as a tabular_learner object using the TabularDataLoaders
    object dls and using accuracy as the performance measurement for training
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ① 使用 TabularDataLoaders 对象 dls 将模型定义为 tabular_learner 对象，并使用准确率作为训练的性能度量
- en: ② Trains the model with three epochs
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ② 使用三个周期训练模型
- en: Note that the statements in listing 8.7 that define and fit the model are much
    simpler than the model definition and fit statements that we saw for the Keras
    model in chapter 3\. In this sense, the code for the fastai solution resembles
    the code for the XGBoost solution that we saw in chapter 3.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，列表 8.7 中定义和拟合模型的语句比我们在第 3 章中看到的 Keras 模型的定义和拟合语句要简单得多。从这个意义上说，fastai 解决方案的代码与我们在第
    3 章中看到的 XGBoost 解决方案的代码相似。
- en: Figure 8.8 shows the output of the fit statement. For each epoch, the training
    loss, validation loss, and accuracy are listed. If we compare the training results
    shown in figure 8.4 (when the target column was not explicitly converted to string
    values) with the training results shown in figure 8.8 (when the target column
    was converted to string values), it’s clear that we get better results when fastai
    treats the problem as a classification problem rather than a regression problem.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 展示了 fit 语句的输出。对于每个 epoch，列出了训练损失、验证损失和准确率。如果我们比较图 8.4（目标列未显式转换为字符串值时的训练结果）和图
    8.8（目标列转换为字符串值时的训练结果）所示的训练结果，很明显，当 fastai 将问题视为分类问题而不是回归问题时，我们得到更好的结果。
- en: '![](../Images/CH08_F08_Ryan2.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F08_Ryan2.png)'
- en: Figure 8.8 Output of the fit statement
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 fit 语句的输出
- en: Before continuing with the rest of the fastai solution, let’s take a moment
    to discuss the relationship between training loss, validation loss, and test loss.
    Figure 8.8 shows the training and validation loss at each epoch. Training loss
    that is lower than validation loss indicates that the model could be underfit
    or that regularization techniques that only apply to training (such as dropout)
    are having an outsize effect. Figure 8.8 shows the validation loss as being lower
    than the training loss in the first epoch. For the subsequent epochs, the training
    loss drops faster than the validation loss until it is lower than the validation
    loss by the final epoch.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讨论 fastai 解决方案的其余部分之前，让我们花点时间讨论训练损失、验证损失和测试损失之间的关系。图 8.8 展示了每个 epoch 的训练和验证损失。训练损失低于验证损失表明模型可能欠拟合，或者仅应用于训练的正则化技术（如
    dropout）产生了过大的影响。图 8.8 显示，在第一个 epoch 中，验证损失低于训练损失。对于后续的 epoch，训练损失下降速度比验证损失快，直到最终
    epoch 低于验证损失。
- en: The following listing confirms that fastai is treating the problem as a classification
    problem because the loss function is `CrossEntropyLoss()`, a loss function that
    is appropriate for a classification problem.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表确认了 fastai 将问题视为分类问题，因为损失函数是 `CrossEntropyLoss()`，这是一个适合分类问题的损失函数。
- en: Listing 8.8 Statement to show the loss function used in model training
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.8 显示模型训练中使用的损失函数的语句
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ① Statement that returns the loss function used in training the fastai model
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ① 返回用于训练 fastai 模型的损失函数的语句
- en: ② Statement output showing the loss function used in training the fastai model
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ② 显示用于训练 fastai 模型的损失函数的语句输出
- en: The output shown in listing 8.8 establishes that we now get the desired loss
    function after setting the target column to contain string values. Now let’s look
    at what layers fastai defines for the model. The following listing shows the `summary()`
    statement, which lets us see the layers that make up the fastai model.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.8 所示的输出表明，在将目标列设置为包含字符串值后，我们现在得到了所需的损失函数。现在让我们看看 fastai 为模型定义了哪些层。以下列表显示了
    `summary()` 语句，它让我们可以看到构成 fastai 模型的层。
- en: Listing 8.9 Statement to get a summary of the fastai model
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.9 获取 fastai 模型摘要的语句
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The output of the statement in listing 8.9 is shown in figure 8.9, which shows
    the output of the `summary()` statement, including the layers that make up the
    model along with the number of parameters in the model and callbacks used.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.9 中语句的输出显示在图 8.9 中，它显示了 `summary()` 语句的输出，包括构成模型的层以及模型中的参数数量和使用的回调。
- en: '![](../Images/CH08_F09_Ryan2.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F09_Ryan2.png)'
- en: Figure 8.9 Output of the `summary()` statement
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 `summary()` 语句的输出
- en: Now that we have examined the key code areas in the fastai solution, let’s revisit
    the stack diagram to see where the fastai stack fits. Figure 8.10 shows the deep
    learning with tabular data stack from the example in this section. Note that the
    figure shows fastai as both a high-level API and a tabular data library since
    fastai plays both roles in the stack.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经检查了 fastai 解决方案中的关键代码区域，让我们回顾堆栈图，看看 fastai 堆栈适合的位置。图 8.10 显示了本节示例中的表格数据深度学习堆栈。请注意，该图显示
    fastai 既是高级 API 也是表格数据库，因为 fastai 在堆栈中扮演这两个角色。
- en: '![](../Images/CH08_F10_Ryan2.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F10_Ryan2.png)'
- en: Figure 8.10 The stack for PyTorch with fastai
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 PyTorch 与 fastai 的堆栈
- en: Now that we have reviewed the code in the fastai solution, in the next section
    we’ll compare this solution to the Keras solution that we saw in chapter 3.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经审查了 fastai 解决方案中的代码，在下一节中，我们将比较本章 3 节中看到的 Keras 解决方案。
- en: 8.2.2 Comparing the fastai solution with the Keras solution
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 比较fastai解决方案与Keras解决方案
- en: 'We have now seen two deep learning solutions to the Airbnb NYC listing price
    prediction problem: the Keras solution and the fastai solution. In this section,
    we’ll compare the two solutions and review the pros and cons of each.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了两个解决 Airbnb 纽约市列表价格预测问题的深度学习解决方案：Keras 解决方案和 fastai 解决方案。在本节中，我们将比较这两个解决方案，并回顾每个解决方案的优缺点。
- en: The fastai and Keras solutions make interesting comparison points because they
    are very different. The Keras solution contains a lot of custom code, and all
    the details are evident. The fastai framework infers details about the model from
    the dataset and makes assumptions about the defaults to use so that there aren’t
    many parameters that we need to specify to get a working model. The benefit of
    this is that the fastai code is much more compact than the Keras code. In particular,
    the Keras solution has multiple lines of code to specify the pipeline and the
    details of the layers that make up the model. In the fastai solution, we get the
    pipeline for free by simply specifying the transformations that we want applied
    to the input data (as shown in listing 8.6), and we don’t need to specify the
    layers that make up the model. The downside of the compactness of the fastai solution
    is that subtle problems can get introduced if we’re not careful. In the previous
    section, we saw that if we don’t explicitly convert the target column to string
    values, then fastai will interpret the values in the target column as continuous
    values and assume we want to train a regression model rather than a classification
    model.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 和 Keras 的解决方案是很有趣的比较点，因为它们非常不同。Keras 的解决方案包含大量的自定义代码，所有细节都一目了然。fastai
    框架从数据集中推断模型的细节，并对默认值做出假设，以便我们不需要指定太多参数就能得到一个可工作的模型。这种做法的好处是 fastai 的代码比 Keras
    的代码更加紧凑。特别是，Keras 的解决方案需要多行代码来指定管道和构成模型的层的细节。在 fastai 的解决方案中，我们只需简单地指定要应用于输入数据的转换（如列表
    8.6 所示），就可以免费获得管道，而且我们不需要指定构成模型的层。fastai 解决方案紧凑性的缺点是，如果我们不小心，可能会引入微妙的问题。在前一节中，我们看到了如果我们没有明确地将目标列转换为字符串值，那么
    fastai 将将目标列中的值解释为连续值，并假设我们想要训练一个回归模型而不是分类模型。
- en: Table 8.1 shows a summary of the pros and cons of the Keras and fastai solutions
    to the Airbnb NYC problem. If we compare the performance of the two solutions,
    the Keras model gets between 70% and 74% accuracy, while the fastai model consistently
    gets around 81% accuracy.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.1 显示了 Keras 和 fastai 解决方案解决 Airbnb 纽约市问题的优缺点总结。如果我们比较两个解决方案的性能，Keras 模型的准确率在
    70% 到 74% 之间，而 fastai 模型始终保持在约 81% 的准确率。
- en: Table 8.1 Summary of the pros and cons of the Keras and fastai solutions
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.1 Keras 和 fastai 解决方案的优缺点总结
- en: '|  | Keras | fastai |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | Keras | fastai |'
- en: '| --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Pro | Model details are transparent.Large community using the framework means
    that it’s easy to find solutions to common problems | Framework includes explicit
    support for tabular data models, which means the code is much more compact.Framework
    automatically defines pipeline.Framework includes convenience functions that make
    it easy to examine the dataset. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 模型细节透明。使用该框架的大型社区意味着可以轻松找到常见问题的解决方案 | 框架包括对表格数据模型的显式支持，这意味着代码更加紧凑。框架自动定义管道。框架包括方便的函数，使检查数据集变得容易。
    |'
- en: '| Con | No built-in support for tabular data, which means we need to define
    custom code to define the pipeline and layers for the model. | Assumptions made
    by the framework can lead to tricky problems that are hard to debug.User community
    is smaller and less involved in deploying production applications than the Keras
    community, which means it can be harder to find solutions to problems. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 缺点 | 没有内置对表格数据的支持，这意味着我们需要定义自定义代码来定义模型的管道和层。 | 框架做出的假设可能导致难以调试的棘手问题。用户社区较小，在部署生产应用程序方面不如
    Keras 社区活跃，这意味着可能更难找到问题的解决方案。 |'
- en: 'Let’s cover one more point of comparison between the Keras solution and the
    fastai solution: the underlying low-level deep learning framework. For Keras,
    the underlying framework is TensorFlow, while fastai is built on top of PyTorch.
    This means we have now reviewed deep learning solutions for tabular data problems
    with both of the major deep learning frameworks.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再比较一下Keras解决方案和fastai解决方案的一个方面：底层低级深度学习框架。对于Keras，底层框架是TensorFlow，而fastai建立在PyTorch之上。这意味着我们现在已经审查了使用两个主要深度学习框架的表格数据问题的深度学习解决方案。
- en: 'One of the similarities between Keras and fastai is that they are both general-purpose
    high-level deep learning APIs. We have seen they can both be used for tabular
    data problems, but they are also designed to deal with a range of data types,
    not just tabular data. In the next section, we look at a deep learning library
    that is specifically designed for tabular data problems: TabNet. We examine a
    solution for the Airbnb NYC problem that uses TabNet and then contrast it with
    the Keras solution.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Keras和fastai之间的一个相似之处是，它们都是通用的高级深度学习API。我们已经看到它们都可以用于表格数据问题，但它们也被设计来处理各种数据类型，而不仅仅是表格数据。在下一节中，我们将探讨一个专门为表格数据问题设计的深度学习库：TabNet。我们将检查一个使用TabNet解决Airbnb
    NYC问题的解决方案，并将其与Keras解决方案进行对比。
- en: 8.3 PyTorch with TabNet
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 PyTorch与TabNet
- en: 'The two tools we’ve considered so far are designed as general deep learning
    libraries. Now, we will try out a purpose-built tabular data library: TabNet.
    Again, we’ll skip the introduction to the problem and concentrate our discussion
    only on the parts of the solution that differ from the previous examples. You
    can find the code for this solution at [https://mng.bz/oK1Z](https://mng.bz/oK1Z).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止考虑的两个工具被设计为通用深度学习库。现在，我们将尝试一个专门为表格数据设计的库：TabNet。同样，我们将跳过问题的介绍，只集中讨论与之前示例不同的解决方案部分。您可以在[https://mng.bz/oK1Z](https://mng.bz/oK1Z)找到此解决方案的代码。
- en: 8.3.1 Key code aspects of the TabNet solution
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 TabNet解决方案的关键代码方面
- en: In this section, we’ll go through the key parts of the code that make up the
    TabNet solution to the Airbnb NYC listing price prediction problem.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过组成TabNet解决Airbnb NYC列表价格预测问题的关键代码部分。
- en: The TabNet solution requires a set of imports, as shown in the following listing.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: TabNet解决方案需要一系列导入，如下所示。
- en: Listing 8.10 Import statements for TabNet
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.10 TabNet的导入语句
- en: '[PRE10]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ① Installs the PyTorch implementation of TabNet
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ① 安装TabNet的PyTorch实现
- en: ② Imports the torch tensor library
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ② 导入torch张量库
- en: ③ Imports the TabNetClassifier library. We will use this library to define the
    model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 导入TabNetClassifier库。我们将使用这个库来定义模型。
- en: Note that, unlike the fastai import statements, the import statements for TabNet
    in listing 8.10 include an explicit statement to import the PyTorch library `torch`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与fastai的导入语句不同，列表8.10中TabNet的导入语句包含一个显式语句来导入PyTorch库`torch`。
- en: Unlike the fastai solution, which does not have any explicit code to define
    the pipeline and has unique code to define the dataset, the TabNet solution uses
    the same code as the Keras and XGBoost solutions up to and including the definition
    of the pipelines. After the pipeline definitions, the TabNet solutions use code
    similar to XGBoost to convert the list of NumPy arrays that comes out of the pipeline
    into a NumPy array of lists, as shown in the following listing.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与没有显式代码定义管道且具有定义数据集的独特代码的fastai解决方案不同，TabNet解决方案使用与Keras和XGBoost解决方案相同的代码，包括管道的定义。在管道定义之后，TabNet解决方案使用类似于XGBoost的代码将管道输出的NumPy数组列表转换为NumPy数组列表，如下所示。
- en: Listing 8.11 Statements to generate NumPy arrays of lists
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.11 生成NumPy数组列表的语句
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ① Defines lists of lists for the training, validation, and test datasets (one
    list for each feature)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ① 定义训练、验证和测试数据集的列表列表（每个特征一个列表）
- en: ② Converts the train list of lists into a NumPy array of lists
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将训练列表的列表转换为NumPy数组列表
- en: ③ Converts the validation list of lists into a NumPy array of lists
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将验证列表的列表转换为NumPy数组列表
- en: ④ Defines variables for the training, validation, and test target sets
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 定义训练、验证和测试目标集的变量
- en: The transformations shown in listing 8.11 are needed because the TabNet solution
    expects the input to the model to be in the form of a NumPy array of lists. Next,
    the TabNet solution includes code to define the model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.11中显示的转换是必需的，因为TabNet解决方案期望模型输入的形式是NumPy数组列表。接下来，TabNet解决方案包括定义模型的代码。
- en: Listing 8.12 Statements to define the TabNet model
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.12 定义TabNet模型的语句
- en: '[PRE12]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ① Defines a TabNetClassifier object as the model for the solution and specify
    an adam optimizer
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将TabNetClassifier对象定义为解决方案的模型并指定adam优化器
- en: ② Sets the learning rate for the model
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ② 设置模型的学习率
- en: ③ Sets parameters for the learning rate scheduler
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 设置学习率调度器的参数
- en: The model definition shown in listing 8.12 specifies a set of hyperparameters,
    including the optimizer and learning rate. Next, the TabNet solution includes
    code to train the model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.12中显示的模型定义指定了一组超参数，包括优化器和学习率。接下来，TabNet解决方案包括训练模型的代码。
- en: Listing 8.13 Statements to train the TabNet model
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.13 训练TabNet模型的语句
- en: '[PRE13]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ① Specifies the training dataset
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ① 指定训练数据集
- en: ② Specifies the validation dataset
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ② 指定验证数据集
- en: ③ Specifies the labels for the training and validation results
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 指定训练和验证结果的标签
- en: ④ Specifies the metric used to track training performance
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 指定用于跟踪训练性能的指标
- en: ⑤ Specifies the number of epochs in the training run and how many epochs to
    run once the model stops improving
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 指定训练运行中的epoch数以及模型停止改进后运行多少个epoch
- en: ⑥ Specifies the batch size
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 指定批量大小
- en: The statement in listing 8.13 that specifies the training for the TabNet model
    includes early stopping setting, including the `patience` parameter that indicates
    how many epochs the training will continue once the model stops improving.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.13中的语句指定了TabNet模型的训练，包括早期停止设置，包括`patience`参数，该参数表示模型停止改进后训练将继续多少个epoch。
- en: The output of the training statement shows the results of each epoch, including
    loss, training accuracy, and validation accuracy, as well as the effect of early
    stopping, as shown in figure 8.11.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 训练语句的输出显示了每个epoch的结果，包括损失、训练准确率和验证准确率，以及早期停止的效果，如图8.11所示。
- en: '![](../Images/CH08_F11_Ryan2.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F11_Ryan2.png)'
- en: Figure 8.11 Output of the TabNet fit statement
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 TabNet fit语句的输出
- en: In the training run output shown in figure 8.11, the maximum number of epochs
    (10) are run because the validation accuracy does not stop improving for more
    than 2 epochs until the maximum number of epochs is reached. This means that the
    `patience` threshold of 3 set in the `fit` statement is never crossed, so the
    training run goes for the maximum number of epochs. Figure 8.12 shows the deep
    learning with tabular data stack from the example in this section.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.11所示的训练运行输出中，运行了最大epoch数（10），因为验证准确率在达到最大epoch数之前没有超过2个epoch的改进。这意味着在`fit`语句中设置的`patience`阈值3从未被越过，因此训练运行进行了最大数量的epoch。图8.12显示了本节示例中的表格数据深度学习堆栈。
- en: '![](../Images/CH08_F12_Ryan2.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F12_Ryan2.png)'
- en: Figure 8.12 The stack for PyTorch with TabNet
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 PyTorch与TabNet的堆栈
- en: Now that we have reviewed the code in the TabNet solution, in the next section
    we’ll compare this solution to the Keras solution that we saw in chapter 3.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经审查了TabNet解决方案中的代码，在下一节中，我们将比较这个解决方案与我们在第3章中看到的Keras解决方案。
- en: 8.3.2 Comparing the TabNet solution with the Keras solution
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 比较TabNet解决方案与Keras解决方案
- en: 'We have now seen three deep learning solutions to the Airbnb NYC listing price
    prediction problem: the Keras solution, the fastai solution, and the TabNet solution.
    In this section we’ll compare the Keras solution with the TabNet solution and
    review the pros and cons of each.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了三个解决Airbnb纽约市列表价格预测问题的深度学习解决方案：Keras解决方案、fastai解决方案和TabNet解决方案。在本节中，我们将比较Keras解决方案与TabNet解决方案，并回顾每个解决方案的优缺点。
- en: The Keras solution and the TabNet solution are interesting to compare because
    they demonstrate some of the strengths and weaknesses of their underlying frameworks,
    TensorFlow and PyTorch. The Keras solution benefits from the simple `summary()`
    statement that gives a compact list of the layers that make up the model. PyTorch
    lacks this elegant feature, so the TabNet solution is also missing that benefit.
    Keras, on the other hand, does not provide built-in control for the training process,
    so you have to define callbacks to ensure that you end up with the optimal model
    from the training run at the end of the run and that you don’t waste resources
    running epochs when the model has stopped improving. PyTorch, on the other hand,
    incorporates early stopping and saving of the optimal model by default, so the
    TabNet solution doesn’t need to include code to explicitly define callbacks to
    optimize the training process. Table 8.2 shows a summary of the pros and cons
    of the Keras and TabNet with PyTorch solutions to the Airbnb NYC problem.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Keras解决方案和TabNet解决方案值得比较，因为它们展示了它们底层框架TensorFlow和PyTorch的一些优点和缺点。Keras解决方案受益于简单的`summary()`语句，该语句提供了一个紧凑的列表，列出了构成模型的层。PyTorch缺乏这个优雅的功能，因此TabNet解决方案也缺少这个好处。另一方面，Keras不提供内置的训练过程控制，因此您必须定义回调以确保您最终从训练运行中获得最佳模型，并且当模型停止改进时，您不会浪费资源运行epochs。另一方面，PyTorch默认包含早期停止和保存最佳模型的功能，因此TabNet解决方案不需要包含代码来显式定义回调以优化训练过程。表8.2显示了Keras和TabNet与PyTorch解决方案对Airbnb纽约市问题的优缺点总结。
- en: Table 8.2 Summary of the pros and cons of the Keras and TabNet solutions
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.2 Keras和TabNet解决方案的优缺点总结
- en: '|  | Keras | TabNet |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | Keras | TabNet |'
- en: '| --- | --- | --- |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Pro | Large community using the framework means that it’s easy to find solutions
    to common problemsSimple summary statement to show the layers in the model | Simple
    statements to define and train the modelDon’t need an explicitly defined callback
    to get the benefit of early stopping |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 使用该框架的大众意味着可以轻松找到常见问题的解决方案简单的总结语句来显示模型中的层 | 简单的语句来定义和训练模型不需要显式定义的回调来获得早期停止的好处
    |'
- en: '| Con | No built-in support for tabular data, which means the model definition
    needs to be hand-coded. | Training process is much slower. The Keras model training
    notebook took ~20 seconds to run. The TabNet training notebook took over 4 minutes.No
    one-stop summary statement to see the structure of the model |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 缺点 | 没有内置对表格数据的支持，这意味着模型定义需要手动编写。 | 训练过程要慢得多。Keras模型训练笔记本运行大约需要20秒。TabNet训练笔记本运行超过4分钟。没有一站式总结语句来查看模型的架构
    |'
- en: 'In this section we reviewed the Airbnb NYC pricing prediction solution for
    PyTorch TabNet. In the next section we will review our final approach to the Airbnb
    problem: PyTorch with Lightning Flash.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了PyTorch TabNet的Airbnb纽约市定价预测解决方案。在下一节中，我们将回顾我们针对Airbnb问题的最终方法：使用Lightning
    Flash的PyTorch。
- en: 8.4 PyTorch with Lightning Flash
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 使用Lightning Flash的PyTorch
- en: 'So far, we’ve considered Keras, fastai, and TabNet PyTorch solutions for the
    Airbnb NYC price prediction problem. Now let’s turn to our final stack: Lightning
    Flash. As a platform designed for fast prototyping, baselining, and fine-tuning,
    along with a clear API and outstanding documentation, Lightning Flash potentially
    offers advantages over the stacks we have explored so far.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经考虑了Keras、fastai和TabNet PyTorch解决方案来解决Airbnb纽约市房价预测问题。现在让我们转向我们的最终堆栈：Lightning
    Flash。作为一个用于快速原型设计、基准测试和微调的平台，它还拥有清晰的API和出色的文档，Lightning Flash可能比我们迄今为止探索的堆栈具有潜在优势。
- en: You can find the code for this solution at [https://mng.bz/vKnp](https://mng.bz/vKnp).
    Figure 8.13 shows the fastai and Tabnet on PyTorch stacks.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://mng.bz/vKnp](https://mng.bz/vKnp)找到此解决方案的代码。图8.13显示了fastai和Tabnet在PyTorch堆栈上的情况。
- en: '![](../Images/CH08_F13_Ryan2.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH08_F13_Ryan2.png)'
- en: Figure 8.13 The fastai and Tabnet on PyTorch stacks
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 fastai和Tabnet在PyTorch堆栈上
- en: 8.4.1 The key code aspects of the Lightning Flash solution
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 Lightning Flash解决方案的关键代码方面
- en: The code for the Lightning Flash solution has many aspects that are different
    from the solutions we have seen so far. In this section, we go through the model
    training notebook ([https://mng.bz/4aDR](https://mng.bz/4aDR)) to highlight the
    most interesting points about this solution.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning Flash解决方案的代码有许多方面与我们迄今为止看到的解决方案不同。在本节中，我们通过模型训练笔记本([https://mng.bz/4aDR](https://mng.bz/4aDR))来突出显示此解决方案最有趣的部分。
- en: To work in Colab, the Lightning Flash solution requires a set of installs done
    in a particular order, as shown in listing 8.14\. The source for this list is
    [https://mng.bz/QDP6](https://mng.bz/QDP6).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Colab中工作，Lightning Flash解决方案需要按照特定的顺序执行一系列安装，如列表8.14所示。此列表的来源为[https://mng.bz/QDP6](https://mng.bz/QDP6)。
- en: Listing 8.14 Installs required to get Lightning Flash to work in Colab
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.14 在Colab中使Lightning Flash工作所需的安装
- en: '[PRE14]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① Series of pip installs to get the required levels of PyTorch Lightning
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ① 系列pip安装以获取所需的PyTorch Lightning级别
- en: ② To eliminate potential conflicts between fastai and Lightning Flash, fastai
    needs to be uninstalled.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ② 为了消除fastai和Lightning Flash之间可能存在的冲突，需要卸载fastai。
- en: ③ Manually applies a fix for a bug in the current release of icevision
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 手动修复当前发布版本icevision中的一个bug
- en: Listing 8.14 includes a long list of installs (and one uninstall) to get Lightning
    Flash to work in Colab. From experience, we know that this very specific list
    of installs is required or there will be conflicts between the levels of libraries
    that Lightning Flash requires and the default library levels for Colab.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.14包含了一系列安装（以及一个卸载）以使Lightning Flash在Colab中工作。根据经验，我们知道这个非常具体的安装列表是必需的，否则Lightning
    Flash所需的库级别与Colab的默认库级别之间将存在冲突。
- en: Next, the libraries required by Lightning Flash need to be imported.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，需要导入Lightning Flash所需的库。
- en: Listing 8.15 Library imports required by Lightning Flash
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.15 Lightning Flash所需的库导入
- en: '[PRE15]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ① Imports the torch tensor library
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ① 导入torch张量库
- en: ② Imports the flash library
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ② 导入flash库
- en: ③ Imports the objects needed for a tabular classification model
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 导入用于表格分类模型的所需对象
- en: Note that the torch import statement in listing 8.15 is the same statement that
    you saw to import torch in listing 8.11 for TabNet.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，列表8.15中的torch导入语句与列表8.11中用于TabNet导入torch的语句相同。
- en: Next, we define the parameters for the dataset that we will use to train the
    model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义用于训练模型的dataset的参数。
- en: Listing 8.16 Setting dataset parameters
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.16 设置数据集参数
- en: '[PRE16]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ① Sets the target field as the value that the trained model will predict
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将目标字段设置为训练模型将预测的值
- en: ② Defines the list of categorical features
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义分类特征的列表
- en: ③ Defines the list of continuous features
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 定义连续特征的列表
- en: The definitions in listing 8.16 should remind you of a similar block of code
    in the fastai solution (listing 8.3), where we defined the target feature along
    with lists for the categorical and continuous features.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.16中的定义应该会让你想起fastai解决方案（列表8.3）中类似的一块代码，在那里我们定义了目标特征以及分类和连续特征的列表。
- en: Next we use the values we just defined to define a `TabularClassificationData`
    object. This object specifies the minimum characteristics of the dataset that
    we will use to train the model.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用刚刚定义的值来定义一个`TabularClassificationData`对象。此对象指定了我们用于训练模型的dataset的最小特征。
- en: Listing 8.17 Defining a `TabularClassificationData`
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.17 定义`TabularClassificationData`
- en: '[PRE17]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ① Defines the categorical features
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ① 定义分类特征
- en: ② Defines the continuous features
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义连续特征
- en: ③ Defines the target feature
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 定义目标特征
- en: ④ Defines the training dataset
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 定义训练数据集
- en: ⑤ Defines the validation dataset
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 定义验证数据集
- en: ⑥ Defines the test dataset
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 定义测试数据集
- en: We should explain why the definition of the `TabularClassificationData` object
    shown in listing 8.17 uses separate CSV files for the train, validation, and test
    datasets. For all the other solutions, the dataset is loaded from a pickle file
    that is the output of the data cleanup notebook ([https://mng.bz/XxN9](https://mng.bz/XxN9)),
    which is then split into train, validation, and test datasets in the model training
    notebook. The Lightning Flash solution is different because it has distinct CSV
    files for each segment of the dataset. The reason for this is that the very specific
    installation requirements shown in listing 8.14 were incompatible with loading
    the pickle file that contains the output dataframe from the data cleanup notebook.
    As a workaround, we loaded that pickle file in a separate notebook into a pandas
    DataFrame and saved the separate CSV files for the training, validation, and test
    that you see in the definition of the `TabularClassificationData` object in listing
    8.17\. As an exercise, you could update the data cleanup notebook for the Lightning
    Flash solution so that it saves the cleaned-up dataset as three separate CSV files
    rather than as a single pickle file.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该解释为什么列表8.17中显示的`TabularClassificationData`对象的定义使用单独的CSV文件来存储训练、验证和测试数据集。对于所有其他解决方案，数据集是从一个pickle文件中加载的，这个pickle文件是数据清理笔记本的输出（[https://mng.bz/XxN9](https://mng.bz/XxN9)），然后在模型训练笔记本中将数据集分割成训练、验证和测试数据集。Lightning
    Flash解决方案是不同的，因为它为数据集的每个部分都有独立的CSV文件。这是因为列表8.14中显示的非常具体的安装要求与加载包含数据清理笔记本输出数据框的pickle文件不兼容。作为权宜之计，我们在一个单独的笔记本中将那个pickle文件加载到一个pandas
    DataFrame中，并保存了训练、验证和测试的单独CSV文件，这些文件在列表8.17中`TabularClassificationData`对象的定义中可以看到。作为一个练习，你可以更新Lightning
    Flash解决方案的数据清理笔记本，使其将清理后的数据集保存为三个单独的CSV文件，而不是一个单独的pickle文件。
- en: Now that we have specified the details about the dataset, we are ready to define
    and train the model, as shown in the following listing.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经指定了数据集的详细信息，我们就可以定义和训练模型了，如下面的列表所示。
- en: Listing 8.18 Setting dataset parameters
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.18 设置数据集参数
- en: '[PRE18]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ① Defines the model using the TabularClassifierData object defined in listing
    8.18
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ① 使用列表8.18中定义的`TabularClassifierData`对象定义模型
- en: ② Defines a Trainer object
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义一个Trainer对象
- en: ③ Fits the model
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 拟合模型
- en: The training code in listing 8.18 generates the output shown in figure 8.14.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.18中的训练代码生成了图8.14所示的输出。
- en: '![](../Images/CH08_F14_Ryan2.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F14_Ryan2.png)'
- en: Figure 8.14 Output of the Lightning Flash training process
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 Lightning Flash训练过程的输出
- en: Note the output includes the validation accuracy and training accuracy for the
    model. Figure 8.15 shows the deep learning with tabular data stack from the example
    in this section.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 注意输出包括模型的验证准确率和训练准确率。图8.15显示了本节示例中的表格数据深度学习堆栈。
- en: '![](../Images/CH08_F15_Ryan2.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F15_Ryan2.png)'
- en: Figure 8.15 The PyTorch with Lightning Flash stack
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 PyTorch with Lightning Flash堆栈
- en: The code for the Lightning Flash solution incorporates some very elegant ideas,
    such as being able to specify the training, validation, and test datasets in the
    same object where you define the overall characteristics of the dataset. Overall,
    the API for Lightning Flash is easy to understand. Unfortunately, these benefits
    are undermined because Lightning Flash requires such specific requirements to
    run in Colab. Otherwise, Lightning Flash could have been a favorite, combining
    the simplicity of fastai with the intuitiveness of Keras.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning Flash解决方案的代码包含了一些非常优雅的想法，例如能够在定义数据集整体特性的同一个对象中指定训练、验证和测试数据集。总的来说，Lightning
    Flash的API易于理解。不幸的是，由于Lightning Flash在Colab中运行需要如此具体的条件，这些好处被削弱了。否则，Lightning Flash可能会成为最受欢迎的解决方案，结合了fastai的简单性和Keras的直观性。
- en: 8.4.2 Comparing the Lightning Flash solution with the Keras solution
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 比较Lightning Flash解决方案与Keras解决方案
- en: 'We have now seen four deep learning solutions to the Airbnb NYC listing price
    prediction problem: the Keras solution, the fastai solution, the TabNet solution,
    and, finally, the Lightning Flash solution. In this section we’ll compare the
    Keras solution with the Lightning Flash solution and review the pros and cons
    of each.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了四种解决Airbnb纽约市列表价格预测问题的深度学习解决方案：Keras解决方案、fastai解决方案、TabNet解决方案，最后是Lightning
    Flash解决方案。在本节中，我们将比较Keras解决方案与Lightning Flash解决方案，并回顾每个解决方案的优缺点。
- en: We’ve seen that Lightning Flash has some real advantages for rolling out a fast,
    simple solution. However, the lack of a beaten path to using Lightning Flash in
    Colab is concerning, and one has to wonder how long the elaborate set of installs
    shown in listing 8.15 will continue to make it possible to run Lightning Flash
    experiments in Colab. Table 8.3 shows a summary of the pros and cons of the Keras
    and Lightning Flash solutions to the Airbnb NYC problem.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到 Lightning Flash 在推出快速、简单的解决方案方面有一些真正的优势。然而，在 Colab 中使用 Lightning Flash
    的缺乏明确路径令人担忧，而且人们不禁要问，展示在列表 8.15 中的复杂安装组合将如何继续使在 Colab 中运行 Lightning Flash 实验成为可能。表
    8.3 显示了 Keras 和 Lightning Flash 解决方案对 Airbnb 纽约市问题的优缺点总结。
- en: Table 8.3 Summary of the pros and cons of the Keras and TabNet solutions
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.3 Keras 和 TabNet 解决方案的优缺点总结
- en: '|  | Keras | Lightning Flash |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  | Keras | Lightning Flash |'
- en: '| --- | --- | --- |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Pro | Large community using the framework means that it’s easy to find solutions
    to common problems.Simple summary statement to show the layers in the model |
    Simple statements to define and train the modelDon’t need to explicitly define
    a pipeline—just need to identify the categorical and continuous columns. |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Pro | 使用该框架的大众社区意味着可以轻松找到常见问题的解决方案。简单的总结语句以显示模型中的层 | 简单的语句来定义和训练模型不需要显式定义管道——只需识别分类和连续列。
    |'
- en: '| Con | No built-in support for tabular data, which means the model definition
    needs to be hand-coded. | To get working in Colab, you need a very specific order
    and level of installs. Does not seem to be widely used, at least not with Colab.Out
    of the box, test accuracy was worse than other solutions. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| Con | 没有内置对表格数据的支持，这意味着模型定义需要手动编码。要在 Colab 中运行，需要非常具体的安装顺序和级别。似乎不太被广泛使用，至少在
    Colab 中不是。开箱即用的测试准确率不如其他解决方案。 |'
- en: So far in this chapter we have applied three deep learning with tabular data
    stacks to solve the Airbnb NYC price prediction problem and compared the pros
    and cons of each solution. In the next section, we review an overall comparison
    of all the stacks we exercised in this chapter.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经应用了三种用于表格数据的深度学习堆栈来解决 Airbnb 纽约市价格预测问题，并比较了每种解决方案的优缺点。在下一节中，我们将回顾本章中我们练习的所有堆栈的整体比较。
- en: 8.5 Overall comparison of the stacks
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 堆栈的整体比较
- en: We have looked at a total of four deep learning for tabular data stacks. Table
    8.4 summarizes the performance of all of these stacks on a default Colab setup,
    with a standard GPU Colab runtime option selected for the deep learning solutions.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总共研究了四种用于表格数据的深度学习堆栈。表 8.4 总结了所有这些堆栈在默认 Colab 设置上的性能，为深度学习解决方案选择了标准的 GPU Colab
    运行时选项。
- en: Table 8.4 Summary of accuracy and running time of the deep learning with tabular
    data stacks (plus XGBoost) for the Airbnb NYC listing price prediction problem
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.4 深度学习与表格数据堆栈（包括 XGBoost）的准确率和运行时间总结（用于 Airbnb 纽约市列表价格预测问题）
- en: '|  | Test Accuracy | Notebook running time |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | 测试准确率 | 笔记本运行时间 |'
- en: '| --- | --- | --- |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| TensorFlow with Keras | 81% | 16 seconds |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow with Keras | 81% | 16 seconds |'
- en: '| fastai with PyTorch | 83% | 69 seconds |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| fastai with PyTorch | 83% | 69 seconds |'
- en: '| TabNet with PyTorch | 81% | 568 seconds |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| TabNet with PyTorch | 81% | 568 seconds |'
- en: '| Lightning Flash with PyTorch | TBD | 14 seconds |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| Lightning Flash with PyTorch | 待定 | 14 seconds |'
- en: '| XGBoost | 79% | 14 seconds |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| XGBoost | 79% | 14 seconds |'
- en: It is important to note here that for the purposes of this comparison we didn’t
    do any tuning of any of the approaches. We wanted to have a genuine “apples-to-apples”
    comparison of how the approaches compare to the Keras baseline without additional
    tuning. In subsequent chapters, we will discuss some of the tuning that can be
    done to get optimal results from a deep learning solution.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，为了进行这种比较，我们没有对任何方法进行任何调整。我们希望有一个真正的“苹果对苹果”的比较，比较方法在没有额外调整的情况下与 Keras
    基线如何比较。在随后的章节中，我们将讨论可以对深度学习解决方案进行的一些调整，以获得最佳结果。
- en: For accuracy, fastai is slightly better than the other stacks. For execution
    time, Lightning Flash is best, and TabNet is the slowest. So what is the best
    stack to use for tabular data? First, if we compare XGBoost with any of the deep
    learning solutions, which is best? We will answer this question in more detail
    in chapter 9, but we can say now that if it’s a straight-up comparison between
    deep learning and gradient boosting, for the sake of simplicity and overall performance
    “out of the box,” gradient boosting approaches like XGBoost are currently better
    than any of the deep learning solutions for most datasets. There are use cases
    where it is worthwhile to explore one of the deep learning solutions, and we will
    review these use cases in chapter 9.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确性，fastai略优于其他堆栈。在执行时间方面，Lightning Flash最佳，而TabNet最慢。那么，用于表格数据的最佳堆栈是什么？首先，如果我们比较XGBoost与任何深度学习解决方案，哪一个更好？我们将在第9章中更详细地回答这个问题，但我们可以现在说，如果是在深度学习和梯度提升之间的直接比较，为了简单性和整体“开箱即用”的性能，“梯度提升”方法如XGBoost目前在大多数数据集上优于任何深度学习解决方案。有些用例值得探索深度学习解决方案之一，我们将在第9章中回顾这些用例。
- en: 'If you do decide to use a deep learning solution for a tabular data problem,
    of the four we explored so far, which one should you use? Here is our overall
    advice:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实决定使用深度学习解决方案来解决表格数据问题，在我们已经探索的四个选项中，你应该使用哪一个？以下是我们的一般建议：
- en: If you are new to deep learning and are primarily interested in exploring a
    solution without needing to immediately implement the solution in production,
    fastai is the best choice. It is the simplest stack to use, and it has a big enough
    user community that you are not likely to be stuck with a problem that nobody
    has seen before. Fastai includes many convenience features to make it easy to
    work with tabular data, so you can rapidly prototype your solution. However, if
    you need to move your solution rapidly to production, fastai is probably not your
    best choice because it is not commonly used in production.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你刚开始接触深度学习，并且主要对探索解决方案感兴趣，而不需要立即在生产环境中实施解决方案，那么fastai是最好的选择。它是使用最简单的堆栈，拥有足够大的用户社区，你不太可能遇到别人从未见过的难题。Fastai包含许多便利功能，使处理表格数据变得容易，因此你可以快速原型化你的解决方案。然而，如果你需要快速将解决方案转移到生产环境中，fastai可能不是你的最佳选择，因为它在生产环境中并不常用。
- en: If you are already comfortable with deep learning and you need to get an application
    into production, we recommend the Keras stack. First, TensorFlow, the low-level
    component of the stack, is the deep learning framework that is used most commonly
    in industry. Second, Keras has a huge user community. While Keras does not yet
    have native support for tabular data the same way that fastai does, Keras is high-level
    enough to lend itself to tabular data problems.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你已经熟悉深度学习，并且需要将应用程序投入生产，我们推荐使用Keras堆栈。首先，堆栈的低级组件TensorFlow是工业界最常用的深度学习框架。其次，Keras拥有庞大的用户社区。虽然Keras还没有像fastai那样对表格数据提供原生支持，但Keras足够高级，可以适用于表格数据问题。
- en: This advice may change as more people use deep learning with tabular data. One
    of the other stacks, such as TabNet on PyTorch, could mature and become the default
    choice for deep learning with tabular data. However, looking at the current state
    of the art, we recommend fastai for beginners and explorers and Keras for people
    who are more experienced and need to proceed to production rapidly.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的人使用表格数据深度学习，这些建议可能会改变。其他堆栈之一，例如PyTorch上的TabNet，可能会成熟并成为表格数据深度学习的默认选择。然而，从当前最先进的技术来看，我们建议初学者和探索者使用fastai，而对于更有经验且需要快速进入生产环境的人来说，推荐使用Keras。
- en: In the next section we will discuss the stacks that we didn’t explore in this
    chapter.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论本章中没有探索的堆栈。
- en: 8.6 The stacks we didn’t explore
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6 我们没有探索的堆栈
- en: You may have asked why we chose three particular stacks (fastai, PyTorch TabNet,
    and Lightning Flash) to solve the Airbnb NYC problem and didn’t explore the other
    options, such as TabNet on TensorFlow, SAINT, or PyTorch Tabular. In this section,
    we’ll look at this question and see what the answer tells us about the options
    that we have for deep learning with tabular data stacks. Figure 8.16 shows the
    deep learning with tabular data stacks that we didn’t explore.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经问过为什么我们选择了三个特定的堆栈（fastai、PyTorch TabNet和Lightning Flash）来解决Airbnb NYC问题，而没有探索其他选项，例如TensorFlow上的TabNet、SAINT或PyTorch
    Tabular。在本节中，我们将探讨这个问题，并看看答案告诉我们关于我们用于表格数据深度学习的堆栈有哪些选项。图8.16显示了我们没有探索的表格数据深度学习堆栈。
- en: '![](../Images/CH08_F16_Ryan2.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F16_Ryan2.png)'
- en: Figure 8.16 The stacks we didn’t explore
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 我们未探索的堆栈
- en: 'There are a couple of characteristics that the unexplored stacks have in common:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 未探索的堆栈有一些共同的特点：
- en: All of the unexplored stacks involve dedicated tabular data libraries.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有未探索的堆栈都涉及专门的表格数据库。
- en: We were not able to get any of the unexplored stacks to work in Colab, the environment
    that we used to exercise the code examples in this book.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们无法在 Colab 中使任何未探索的堆栈工作，这是我们用来练习本书中代码示例的环境。
- en: Our inability to get the unexplored stacks to work in Colab could be due to
    a number of reasons. There could theoretically be some limitations with Colab.
    However, Colab is a very common environment for exploration, so it’s not a good
    sign if a library cannot be coaxed to life in Colab. All of the stacks featured
    “hello world” examples for exercising the stack, and for all the unexplored stacks
    these examples generated errors, mostly to do with contradictory Python library
    prerequisites. It’s possible that if we had been more patient, or looked a little
    harder, we would have been able to work through the errors to get the basic examples
    to work in Colab. Of the stacks that we did explore, Keras, fastai, and PyTorch
    TabNet all worked “out of the box” in Colab. Lighting Flash, on the other hand,
    did require some tweaking before it worked in Colab.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法在 Colab 中使未探索的堆栈工作可能是由多种原因造成的。理论上，Colab 可能存在一些限制。然而，Colab 是一个非常常见的探索环境，所以如果一个库无法在
    Colab 中被激活，这并不是一个好兆头。所有的堆栈都提供了“hello world”示例来练习堆栈，而对于所有未探索的堆栈，这些示例都产生了错误，大多数与矛盾的
    Python 库先决条件有关。可能如果我们更有耐心，或者更深入地调查，我们就能解决这些错误，让基本示例在 Colab 中运行。在我们探索的堆栈中，Keras、fastai
    和 PyTorch TabNet 都能在 Colab 中“即开即用”。另一方面，Lightning Flash 在 Colab 中工作之前确实需要一些调整。
- en: The difference between Lightning Flash and the unexplored stacks is that it
    was clear that other people had tried to get Lightning Flash to work in Colab,
    and we could find informal documentation that showed exactly what we needed to
    do to get it to work in Colab. If your goal is to solve a tabular data problem
    with deep learning, you want to focus on the problem, not on fiddling with conda
    and pip installing boutique levels of libraries to avoid incompatibilities. By
    that criteria, Keras, fastai, PyTorch TabNet, and, to a lesser extent, Lightning
    Flash are viable choices for deep learning with tabular data in Colab. SAINT,
    DeepTables, PyTorch Tabular, and TabNet on TensorFlow are not viable choices for
    exploration in Colab because they don’t work right away, and the recipes to get
    them to work either don’t exist or are not easy to find.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning Flash 与未探索的堆栈之间的区别在于，很明显，其他人曾尝试在 Colab 中使 Lightning Flash 工作，我们可以找到非正式文档，展示了我们为了使其在
    Colab 中工作需要做的一切。如果你的目标是使用深度学习解决表格数据问题，你希望专注于问题，而不是在 conda 和 pip 安装库时纠结于避免不兼容性。根据这个标准，Keras、fastai、PyTorch
    TabNet 以及在一定程度上 Lightning Flash 都是 Colab 中表格数据深度学习的可行选择。SAINT、DeepTables、PyTorch
    Tabular 和 TensorFlow 上的 TabNet 并不是 Colab 中探索的可行选择，因为它们不能立即工作，而且使它们工作的配方要么不存在，要么难以找到。
- en: While it is disappointing that we weren’t able to exercise the Airbnb NYC price
    prediction problem with more of the dedicated deep learning with tabular data
    libraries, we were still able to accomplish the goal of this chapter by exploring
    three deep learning with tabular data stacks. Figure 8.17 shows all the stacks
    that we were able to explore.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们无法使用更多的针对表格数据的专用深度学习库来练习 Airbnb 纽约价格预测问题令人失望，但我们仍然通过探索三个表格数据的深度学习堆栈实现了本章的目标。图
    8.17 显示了我们能够探索的所有堆栈。
- en: '![](../Images/CH08_F17_Ryan2.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH08_F17_Ryan2.png)'
- en: Figure 8.17 The stacks we explored
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 我们探索的堆栈
- en: 'The stacks we explored in this chapter, plus TensorFlow with Keras, present
    a well-rounded set of options:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们探索的堆栈，加上 TensorFlow 与 Keras，提供了一套全面的选项：
- en: TensorFlow with Keras is a rock-solid stack with a huge community of users.
    For just about any problem that you encounter with this stack, you can bet that
    somebody else has hit the problem and posted a solution. The stack works flawlessly
    in Colab, so doing initial investigation is easy. TensorFlow with Keras is commonly
    used in production for all kinds of applications. On the downside, Keras does
    not have built-in support for tabular data, so you need to be prepared to write
    some custom code to tackle tabular data problems.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow with Keras 是一个稳固的堆栈，拥有庞大的用户社区。对于你在这个堆栈中遇到的几乎所有问题，你都可以确信其他人已经遇到过这个问题并发布了解决方案。这个堆栈在
    Colab 中运行得非常完美，因此进行初步调查很容易。TensorFlow with Keras 通常在生产中用于各种应用。然而，Keras 没有内置对表格数据的支持，因此你需要准备好编写一些自定义代码来处理表格数据问题。
- en: PyTorch with fastai is designed to be easy to get started with, and it works
    flawlessly in Colab, so you can expect to prototype deep learning with tabular
    data problems with this stack with minimal hassle. fastai treats tabular data
    as a first-class citizen, so you get built-in support for dealing with categorical
    and continuous features and you don’t need to worry about hand-coding a pipeline
    to ensure that when you feed data to the trained model to get a prediction, the
    data goes through the same transformations as the data used to train the model.
    On the downside, you can pay a price for the simplicity of fastai code. The automated
    steps that fastai takes can lead to some hard-to-debug problems (such as the problem
    we described in this chapter where the wrong kind of model gets trained if the
    target column isn’t explicitly converted to a string type), and you need to be
    prepared to dig deep into the fastai API if you want to go off the beaten path
    provided by fastai’s tabular data structures.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch with fastai 设计得易于上手，并且在 Colab 中运行得非常完美，因此你可以期待用这个堆栈以最小的麻烦原型化深度学习中的表格数据问题。fastai
    将表格数据视为一等公民，因此你获得内置支持以处理分类和连续特征，你不需要担心手动编码一个管道来确保当你向训练好的模型提供数据以获取预测时，数据会经历与训练模型所使用的数据相同的转换。然而，fastai
    代码的简单性可能会付出代价。fastai 自动执行的步骤可能导致一些难以调试的问题（例如，在本章中我们描述的问题，如果目标列没有明确转换为字符串类型，就会训练错误类型的模型），如果你想要偏离
    fastai 表格数据结构提供的既定路径，你需要准备好深入研究 fastai API。
- en: PyTorch with TabNet distinguishes itself among the tabular-data-specific libraries
    by working in Colab without any fuss. Like fastai, with TabNet you can define
    and train a deep learning model on tabular data with just a handful of lines of
    code. Unlike fastai, TabNet uses conventional APIs that are easy for anybody who
    has used Scikit-learn to understand. Compared to the other stacks, TabNet took
    longer to train the model. Also, as a library specifically designed for tabular
    data, TabNet has a smaller user community than fastai and Keras, which means that
    if you run into problems it will be less likely that somebody else has already
    hit them and documented a fix on Stack Overflow.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch with TabNet 通过在 Colab 中无需任何麻烦地工作，在表格数据特定的库中脱颖而出。像 fastai 一样，使用 TabNet，你只需几行代码就可以在表格数据上定义和训练一个深度学习模型。与
    fastai 不同，TabNet 使用的是 Scikit-learn 用户容易理解的常规 API。与其他堆栈相比，TabNet 训练模型所需的时间更长。此外，作为一个专门为表格数据设计的库，TabNet
    的用户社区比 fastai 和 Keras 小，这意味着如果你遇到问题，其他人已经遇到过并已在 Stack Overflow 上记录了修复的可能性较小。
- en: PyTorch with Lightning Flash trains the model quickly and has a simple API,
    once you get it to work. Lightning has a large community—not as big as Keras but
    bigger than fastai. However, the niche of using Lightning Flash on Colab to do
    tabular data problems is not that big, and we were only just able to get Lightning
    Flash to work on Colab.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch with Lightning Flash 可以快速训练模型，并且一旦运行起来，API 就很简单。Lightning 拥有一个庞大的社区——不如
    Keras 那么大，但比 fastai 大。然而，在 Colab 上使用 Lightning Flash 处理表格数据的问题领域并不大，我们刚刚才让 Lightning
    Flash 在 Colab 上运行起来。
- en: In this chapter we have explored a set of deep learning with tabular data stacks,
    compared the pros and cons of each approach, and discussed why we left some other
    stacks unexplored. In the next chapter we are going to review the best practices
    for deep learning with tabular data.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了一系列用于表格数据的深度学习堆栈，比较了每种方法的优缺点，并讨论了为什么我们没有探索一些其他堆栈。在下一章中，我们将回顾用于表格数据的深度学习的最佳实践。
- en: Summary
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'There are two low-level deep learning frameworks: TensorFlow and PyTorch.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个低级深度学习框架：TensorFlow 和 PyTorch。
- en: TensorFlow is used more frequently in industry.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 在工业中应用得更频繁。
- en: PyTorch is the predominant deep learning framework for research.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch 是研究中的主要深度学习框架。
- en: Keras is a high-level API for TensorFlow.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 是 TensorFlow 的高级 API。
- en: fastai is both a general-purpose, high-level API for PyTorch and a tabular data
    library.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fastai 既是 PyTorch 的一般用途、高级 API，也是一个表格数据库。
- en: PyTorch Lightning is a high-level API that abstracts some of the details of
    PyTorch. Lightning Flash is a tabular data library based on Lightning.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch Lightning 是一个高级 API，它抽象了一些 PyTorch 的细节。Lightning Flash 是基于 Lightning
    的表格数据库。
- en: Lightning Flash and fastai each provide some of the same benefits for PyTorch
    that Keras does for TensorFlow by abstracting aspects of the underlying PyTorch
    framework.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lightning Flash 和 fastai 都为 PyTorch 提供了一些与 Keras 为 TensorFlow 提供的相同的好处，通过抽象底层
    PyTorch 框架的一些方面。
- en: TabNet is a tabular data library that is available for both TensorFlow and PyTorch.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TabNet 是一个既适用于 TensorFlow 也适用于 PyTorch 的表格数据库。
- en: SAINT is a tabular data library for TensorFlow.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAINT 是 TensorFlow 的表格数据库。
- en: PyTorch Tabular is a tabular data library for PyTorch.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch Tabular 是 PyTorch 的表格数据库。
- en: Of all the choices available, TensorFlow with Keras, PyTorch with fastai, PyTorch
    with TabNet, and PyTorch with Lightning Flash are all valid options for deep learning
    with tabular data on Colab.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有可用的选择中，TensorFlow 与 Keras、PyTorch 与 fastai、PyTorch 与 TabNet 以及 PyTorch 与
    Lightning Flash 都是 Colab 上进行表格数据深度学习的有效选项。
