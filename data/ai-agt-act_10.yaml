- en: 11 Agent planning and feedback
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 代理规划和反馈
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Planning for an LLM and implementing it in agents and assistants
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在LLMs上规划并在代理和助手中实现它
- en: Using the OpenAI Assistants platform via custom actions
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过自定义操作使用OpenAI助手平台
- en: Implementing/testing a generic planner on LLMs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在LLMs上实现/测试通用规划器
- en: Using the feedback mechanism in advanced models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高级模型中使用反馈机制
- en: Planning, reasoning, evaluation, and feedback in building agentic systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建代理系统中的规划、推理、评估和反馈
- en: Now that we’ve examined how large language models (LLMs) can reason and plan,
    this chapter takes this concept a step further by employing planning within an
    agent framework. Planning should be at the core of any agent/assistant platform
    or toolkit. We’ll start by looking at the basics of planning and how to implement
    a planner through prompting. Then, we’ll see how planning operates using the OpenAI
    Assistants platform, which automatically incorporates planning. From there, we’ll
    build and implement a general planner for LLMs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了大型语言模型（LLMs）如何进行推理和规划，本章通过在代理框架内应用规划来将这一概念进一步深化。规划应该是任何代理/助手平台或工具包的核心。我们将从查看规划的基本知识和如何通过提示实现规划器开始。然后，我们将看到如何使用OpenAI助手平台进行规划，该平台自动整合了规划。从那里，我们将为LLMs构建和实现一个通用规划器。
- en: Planning can only go so far, and an often-unrecognized element is feedback.
    Therefore, in the last sections of the chapter, we explore feedback and implement
    it within a planner. You must be familiar with the content of chapter 10, so please
    review it if you need to, and when you’re ready, let’s begin planning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 规划只能走这么远，一个经常未被认识到的元素是反馈。因此，在本章的最后几节中，我们探讨了反馈并在规划器中实现了它。您必须熟悉第10章的内容，所以如果您需要，请查阅它，准备好后，让我们开始规划。
- en: '11.1 Planning: The essential tool for all agents/assistants'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 规划：所有代理/助手的必备工具
- en: Agents and assistants who can’t plan and only follow simple interactions are
    nothing more than chatbots. As we’ve seen throughout this book, our goal isn’t
    to build bots but rather to build autonomous thinking agents—agents that can take
    a goal, work out how to solve it, and then return with the results.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不能规划而只能进行简单交互的代理和助手不过是聊天机器人。正如我们在整本书中看到的那样，我们的目标不是构建机器人，而是构建自主思考的代理——能够接受目标，找出解决问题的方法，然后返回结果的代理。
- en: Figure 11.1 explains the overall planning process that the agent/assistant will
    undertake. This figure was also presented in chapter 1, but let’s review it now
    in more detail. At the top of the figure, a user submits a goal. In an agentic
    system, the agent takes the goal, constructs the plan, executes it, and then returns
    the results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1解释了代理/助手将执行的整体规划过程。这个图也在第1章中展示过，但现在让我们更详细地回顾一下。在图的顶部，用户提交一个目标。在一个代理系统中，代理接受目标，构建计划，执行它，然后返回结果。
- en: '![figure](../Images/11-1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/11-1.png)'
- en: Figure 11.1 The agent planning process
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.1 代理规划过程
- en: Depending on your interaction with platforms such as ChatGPT and GPTs, Claude,
    and others, you may have already encountered a planning assistant and not even
    noticed. Planning is becoming ubiquitous and is now built into most commercial
    platforms to make the model appear more intelligent and capable. Therefore, in
    the next exercise, we’ll look at an example to set a baseline and differentiate
    between an LLM that can’t plan and an agent that can.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您与ChatGPT、GPTs、Claude等平台互动的方式，您可能已经遇到了规划助手，甚至没有注意到。规划正在变得无处不在，并且现在已集成到大多数商业平台中，以使模型看起来更智能和强大。因此，在下一个练习中，我们将查看一个示例来设定基线，并区分不能规划的LLM和能规划的代理。
- en: For the next exercise, we’ll use Nexus to demonstrate how raw LLMs can’t plan
    independently. If you need assistance installing, setting up, and running Nexus,
    refer to chapter 7\. After you have Nexus installed and ready, we can begin running
    it with the Gradio interface, using the commands shown next.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将使用Nexus来演示原始LLMs无法独立规划。如果您需要安装、设置和运行Nexus的帮助，请参阅第7章。在您安装并准备好Nexus后，我们可以开始使用Gradio界面运行它，使用下面显示的命令。
- en: Listing 11.1 Running Nexus with the Gradio interface
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.1 使用Gradio界面运行Nexus
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Gradio is an excellent web interface tool built to demonstrate Python machine
    learning projects. Figure 11.2 shows the Gradio Nexus interface and the process
    for creating an agent and using an agent engine (OpenAI, Azure, and Groq) of your
    choice. You can’t use LM Studio unless the model/server supports tool/action use.
    Anthropic’s Claude supports internal planning, so for the purposes of this exercise,
    avoid using this model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio 是一个优秀的网络界面工具，旨在展示 Python 机器学习项目。图 11.2 展示了 Gradio Nexus 界面以及创建代理和使用所选代理引擎（OpenAI、Azure
    和 Groq）的过程。除非模型/服务器支持工具/动作的使用，否则您不能使用 LM Studio。Anthropic 的 Claude 支持内部规划，因此为了本练习的目的，请避免使用此模型。
- en: '![figure](../Images/11-2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/11-2.png)'
- en: Figure 11.2 Creating a new agent in Nexus
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.2 在 Nexus 中创建新代理
- en: 'After creating the agent, we want to give it specific actions (tools) to undertake
    or complete a goal. Generally, providing only the actions an agent needs to complete
    its goal is best for a few reasons:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建代理后，我们希望给它提供特定的动作（工具）以执行或完成目标。通常，只提供代理完成其目标所需的动作是最佳做法，原因有几个：
- en: More actions can confuse an agent into deciding which to use or even how to
    solve a goal.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多动作可能会让代理困惑，不知道该使用哪个，甚至不知道如何解决问题。
- en: APIs have limits on the number of tools that can be submitted; at the time of
    writing, hitting this limit is relatively easy.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 对可提交的工具数量有限制；在撰写本文时，达到这个限制相对容易。
- en: Agents may use your actions in ways you didn’t intend unless that’s your goal.
    Be warned, however, that actions can have consequences.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非这是您的目标，否则代理可能会以您未预料到的方式使用您的动作。但是，请警告，动作可能会有后果。
- en: Safety and security need to be considered. LLMs aren’t going to take over the
    world, but they make mistakes and quickly get off track. Remember, these agents
    will operate independently and may perform any action.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性和安全性需要考虑。LLMs 不会接管世界，但它们会犯错误并迅速偏离正轨。记住，这些代理将独立运行并可能执行任何动作。
- en: WARNING  While writing this book and working with and building agents over many
    hours, I have encountered several instances of agents going rogue with actions,
    from downloading files to writing and executing code when not intended, continually
    iterating from tool to tool, and even deleting files they shouldn’t have. Watching
    an agent emerge new behaviors using actions can be fun, but things can quickly
    go astray.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：在撰写本书并花费数小时与构建代理进行工作期间，我遇到了几个代理采取越界行为的实例，从下载文件到在不打算的情况下编写和执行代码，不断从工具到工具迭代，甚至删除它们不应该删除的文件。观察代理通过行为出现新行为可能会很有趣，但事情可能会迅速偏离正轨。
- en: For this exercise, we’ll define the goal described in the following listing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们将定义以下列表中描述的目标。
- en: 'Listing 11.2 Demonstrating planning: The goal'
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.2 展示规划：目标
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This goal will demonstrate the following actions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此目标将演示以下动作：
- en: '`search_wikipedia(topic)`—Searches Wikipedia and returns page IDs for the given
    search term.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`search_wikipedia(topic)`—搜索维基百科并返回给定搜索词的页面 ID。'
- en: '`get_wikipedia_page(page_id)`—Downloads the page content given the page ID.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get_wikipedia_page(page_id)`—根据页面 ID 下载页面内容。'
- en: '`save_file`—Saves the content to a file.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_file`—将内容保存到文件中。'
- en: Set the actions on the agent, as shown in figure 11.3\. You’ll also want to
    make sure the Planner is set to None. We’ll look at setting up and using planners
    soon. You don’t have to click Save; the interface automatically saves an agent’s
    changes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 设置代理上的动作，如图 11.3 所示。您还想要确保规划器设置为 None。我们很快将探讨设置和使用规划器。您不必点击保存；界面会自动保存代理的更改。
- en: '![figure](../Images/11-3.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/11-3.png)'
- en: Figure 11.3 Selecting the actions for the agent and disabling the planner
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.3 选择代理的动作并禁用规划器
- en: 'After you choose the actions and planner, enter the goal in listing 11.2\.
    Then click Create New Thread to instantiate a new conversation. Substitute the
    topic you want to search for in the chat input, and wait for the agent to respond.
    Here’s an example of the goal filled with the topic, but again, use any topic
    you like:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在您选择动作和规划器后，在列表 11.2 中输入目标。然后点击创建新线程以实例化一个新的对话。在聊天输入中替换您想要搜索的主题，并等待代理响应。以下是一个填充了主题的目标示例，但再次提醒，您可以使用任何您喜欢的主题：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Figure 11.4 shows the results of submitting the goal to the plain agent. We
    see the agent executed the tool/action to search for the topic but couldn’t execute
    any steps beyond that. If you recall from our discussion and code example of actions
    in chapter 5, OpenAI, Groq, and Azure OpenAI all support parallel actions but
    not sequential or planned actions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 展示了将目标提交给普通代理的结果。我们看到代理执行了工具/动作以搜索主题，但无法执行该步骤之后的任何步骤。如果你还记得我们在第 5 章中关于动作的讨论和代码示例，OpenAI、Groq
    和 Azure OpenAI 都支持并行动作，但不支持顺序或计划动作。
- en: '![figure](../Images/11-4.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/11-4.png)'
- en: Figure 11.4 The results from trying to get the agent/LLM to complete the goal
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.4 尝试让代理/LLM 完成目标的结果
- en: The LLM can answer reasonably well if you submit a goal with several parallel
    tasks/actions. However, if the actions are sequential, requiring one step to be
    dependent on another, it will fail. Remember, parallel actions are standalone
    actions that can be run alongside others.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你提交一个包含多个并行任务/动作的目标，LLM 可以合理地回答。然而，如果动作是顺序的，需要一步依赖于另一步，它将失败。记住，并行动作是可以与其他动作并行运行的独立动作。
- en: Anthropic’s Claude and OpenAI Assistants support sequential action planning.
    This means both models can be called with sequential plans, and the model will
    execute them and return the results. In the next section, we’ll explore sequential
    planning and then demonstrate it in action.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic 的 Claude 和 OpenAI 助手支持顺序动作规划。这意味着这两个模型都可以使用顺序计划进行调用，模型将执行它们并返回结果。在下一节中，我们将探讨顺序规划并在实际操作中演示。
- en: 11.2 Understanding the sequential planning process
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 理解顺序规划过程
- en: In the next exercise, we’ll ask an OpenAI assistant to solve the same goal.
    If you have Anthropic/Claude credentials and have the engine configured, you can
    also try this exercise with that model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将要求一个 OpenAI 助手解决相同的目标。如果你有 Anthropic/Claude 凭证并且已经配置了引擎，你也可以尝试使用该模型进行这个练习。
- en: Figure 11.5 shows the difference between executing tasks sequentially (planning)
    and using iteration. If you’ve used GPTs, assistants, or Claude Sonnet 3.5, you’ve
    likely already experienced this difference. These advanced tools already incorporate
    planning by prompt annotations, advanced training, or combining both.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 展示了顺序执行任务（规划）和使用迭代之间的区别。如果你使用过 GPTs、助手或 Claude Sonnet 3.5，你可能已经体验过这种区别。这些高级工具已经通过提示注释、高级训练或两者结合的方式实现了规划。
- en: '![figure](../Images/11-5.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/11-5.png)'
- en: Figure 11.5 The difference between iterative and planned execution
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.5 迭代执行和计划执行之间的区别
- en: As LLM and chat services evolve, most models will likely natively support some
    form of planning and tool use. However, most models, including GPT-4o, only support
    action/tool use today.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型和聊天服务的演变，大多数模型可能会原生支持某种形式的规划和使用工具。然而，包括 GPT-4o 在内的大多数模型今天只支持动作/工具的使用。
- en: Let’s open the GPT Assistants Playground to demonstrate sequential planning
    in action. If you need help, refer to the setup guide in chapter 6\. We’ll use
    the same goal but, this time, run it against an assistant (which has built-in
    planning).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开 GPT 助手 Playground 来演示顺序规划的实际操作。如果你需要帮助，请参考第 6 章中的设置指南。我们将使用相同的目标，但这次，我们将运行它针对一个助手（该助手内置了规划）。
- en: After you launch the Playground, create a new assistant, and assign it the `search_
    wikipedia,` `get_wikipedia_page`, and `save_file` actions. Figure 11.6 shows the
    results of entering the goal to the assistant. As you can see, the assistant completed
    all the tasks behind the scenes and responded with the user’s final requested
    output, achieving the goal.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在你启动 Playground 后，创建一个新的助手，并分配给它 `search_wikipedia`、`get_wikipedia_page` 和 `save_file`
    动作。图 11.6 展示了将目标输入助手的成果。正如你所见，助手在幕后完成了所有任务，并以用户最终请求的输出响应，实现了目标。
- en: '![figure](../Images/11-6.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/11-6.png)'
- en: Figure 11.6 The assistant processing the goal and outputting the results
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.6 助手处理目标和输出结果
- en: To demonstrate the effectiveness of the OpenAI Assistant’s planner, we added
    another task, summarizing each page, to the goal. The inserted task didn’t have
    a function/tool, but the assistant was savvy enough to use its ability to summarize
    the content. You can see the output of what the assistant produced by opening
    the `[root` `folder]assistants_working_folder/Wikipedia_{topic}.txt` file and
    reviewing the contents. Now that we understand how LLMs function without planners
    and planning, we can move on to creating our planners in the next section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示OpenAI助手规划器的有效性，我们将另一个任务，即总结每一页，添加到目标中。插入的任务没有函数/工具，但助手足够聪明，能够利用其总结内容的能力。您可以通过打开`[root]assistants_working_folder/Wikipedia_{topic}.txt`文件并查看内容来查看助手产生的输出。现在我们了解了LLM在没有规划器和规划的情况下如何工作，我们可以继续在下一节创建我们的规划器。
- en: 11.3 Building a sequential planner
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 构建顺序规划器
- en: LLM tools such as LangChain and Semantic Kernel (SK) have many planners using
    various strategies. However, writing our planner is relatively easy, and Nexus
    also supports a plugin-style interface allowing you to add other planners from
    tools such as LangChain and SK, or your derivatives.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: LLM工具如LangChain和Semantic Kernel (SK)拥有许多使用各种策略的规划器。然而，编写我们的规划器相对容易，Nexus还支持插件式接口，允许您添加来自LangChain和SK等工具或其他派生工具的其他规划器。
- en: Planners may sound complicated, but they are easily implemented through prompt
    engineering strategies that incorporate planning and reasoning. In chapter 10,
    we covered the basics of reasoning and deriving plans, and now we can put those
    skills to good use.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 规划师可能听起来很复杂，但通过结合规划和推理的提示工程策略，它们很容易实现。在第10章中，我们介绍了推理和制定计划的基础，现在我们可以将这些技能用于实际应用。
- en: Listing 11.3 shows a sequential planner derived from the SK, which is extended
    to incorporate iteration. Prompt annotation planners like those shown in the listing
    can be adapted to fit specific needs or be more general like those shown. This
    planner uses JSON, but planners could use any format an LLM understands, including
    code.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.3展示了从SK派生出的顺序规划器，它扩展了迭代。如列表中所示，提示注释规划器可以适应特定需求或更通用，如所示。此规划器使用JSON，但规划器可以使用LLM理解的任何格式，包括代码。
- en: Listing 11.3 `basic_nexus_planner.py`
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.3 `basic_nexus_planner.py`
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 The preamble instructions telling the agent how to process the examples'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 告诉代理如何处理示例的序言指令'
- en: '#2 Beginning of the three (few-shot) examples'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 三个（少样本）示例的开始'
- en: '#3 Adds the for-each special iterative function'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 添加了for-each特殊迭代函数'
- en: '#4 Available functions are autopopulated from the agent’s list of available
    functions.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 可用函数从代理的可用函数列表自动填充。'
- en: '#5 The goal is inserted here.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 目标在这里插入。'
- en: '#6 Where the agent is expected to place the output'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 代理预期放置输出的位置'
- en: Figure 11.7 shows the process of building and running a planning prompt, from
    building to execution to finally returning the results to the user. Planners work
    by building a planning prompt, submitting it to an LLM to construct the plan,
    parsing and executing the plan locally, returning the results to an LLM to evaluate
    and summarize, and finally returning the final output back to the user.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7展示了构建和运行规划提示的过程，从构建到执行，最后将结果返回给用户。规划师通过构建规划提示，提交给LLM构建计划，本地解析和执行计划，将结果返回给LLM进行评估和总结，并最终将最终输出返回给用户。
- en: '![figure](../Images/11-7.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/11-7.png)'
- en: Figure 11.7 The planning process for creating and executing a plan
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.7 创建和执行计划的规划过程
- en: It’s essential to notice a few subtle details about the planning process. Typically,
    the plan is built in isolation by not adding context history. This is done to
    focus on the goal because most planning prompts consume many tokens. Executing
    the functions within the executor is usually done in a local environment and may
    include calling APIs, executing code, or even running machine learning models.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 注意规划过程中的几个细微细节至关重要。通常，计划是在孤立状态下构建的，没有添加上下文历史。这样做是为了专注于目标，因为大多数规划提示消耗许多标记。在执行器内部执行功能通常是在本地环境中进行的，可能包括调用API、执行代码，甚至运行机器学习模型。
- en: Listing 11.4 shows the code for the `create_plan` function from the `BasicNexusPlanner`
    class; tools such as LangChain and SK use similar patterns. The process loads
    the agent’s actions as a string. The goal and available functions list are then
    inserted into the planner prompt template using the `PromptTemplateManager`, which
    is just a wrapper for the template-handling code. Template handling is done with
    simple regex but can also be more sophisticated using tools such as Jinja2, Handlebars,
    or Mustache.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.4 展示了 `BasicNexusPlanner` 类中 `create_plan` 函数的代码；LangChain 和 SK 等工具使用类似的模式。该过程将代理的动作作为字符串加载。然后使用
    `PromptTemplateManager` 将目标和可用函数列表插入到规划器提示模板中，`PromptTemplateManager` 只是对模板处理代码的包装。模板处理使用简单的正则表达式完成，但也可以使用
    Jinja2、Handlebars 或 Mustache 等工具进行更复杂的处理。
- en: Listing 11.4 `basic_nexus_planner.py` (`create_plan`)
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.4 `basic_nexus_planner.py` (`create_plan`)
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Loads the agent’s available actions and formats the result string for the
    planner'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 加载代理可用的动作，并将结果字符串格式化为规划器'
- en: '#2 The context will be injected into the planner prompt template.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将上下文注入到规划器提示模板中。'
- en: '#3 A simple template manager, similar in concept to Jinja2, Handlebars, or
    Mustache'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 一个简单的模板管理器，在概念上类似于 Jinja2、Handlebars 或 Mustache'
- en: '#4 Sends the filled-in planner prompt to the LLM'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将填充后的规划器提示发送到 LLM'
- en: '#5 The results (the plan) are wrapped in a Plan class and returned for execution.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将结果（计划）封装在 Plan 类中并返回以执行。'
- en: The code to execute the plan, shown in listing 11.5, parses the JSON string
    and executes the functions. When executing the plan, the code detects the particular
    `for-each` function, which iterates through a list and executes each element in
    a function. The results of each function execution are added to the context. This
    context is passed to each function call and returned as the final output.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 执行计划的代码（如列表 11.5 所示）解析 JSON 字符串并执行函数。在执行计划时，代码会检测特定的 `for-each` 函数，该函数遍历列表并执行函数中的每个元素。每个函数执行的结果都添加到上下文中。这个上下文传递给每个函数调用，并作为最终输出返回。
- en: Listing 11.5 `basic_nexus_planner.py` (`execute_plan`)
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.5 `basic_nexus_planner.py` (`execute_plan`)
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Iterates through each subtask in the plan'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 遍历计划中的每个子任务'
- en: '#2 Handles functions that should be iterated over and adds full list of results
    to the context'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 处理应该迭代的函数，并将完整的结果列表添加到上下文中'
- en: '#3 Removes individual for-each context entries'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 移除单独的 for-each 上下文条目'
- en: '#4 General task execution'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 通用任务执行'
- en: '#5 Returns the full context, which includes the results of each function call'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 返回完整上下文，包括每个函数调用的结果'
- en: The returned context from the entire execution is sent in a final call to the
    LLM, which summarizes the results and returns a response. If everything goes as
    planned, the LLM will respond with a summary of the results. If there is an error
    or something is missing, the LLM may try to fix the problem or inform the user
    of the error.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 整个执行返回的上下文在最终调用 LLM 时发送，LLM 总结结果并返回响应。如果一切按计划进行，LLM 将以结果总结的形式响应。如果出现错误或缺少某些信息，LLM
    可能会尝试解决问题或通知用户错误。
- en: Let’s now open Nexus again and test a planner in operation. Load up the same
    agent you used last time, but select the planner under the Advanced options this
    time, as shown in figure 11.8\. Then, enter the goal prompt as you did before,
    and let the agent take it away.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们再次打开 Nexus 并测试一个正在运行的规划器。加载上次使用的相同代理，但这次在高级选项下选择规划器，如图 11.8 所示。然后，像之前一样输入目标提示，让代理去处理。
- en: '![figure](../Images/11-8.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/11-8.png)'
- en: Figure 11.8 The results from requesting to complete the goal in Nexus using
    the basic planner
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.8 使用基本规划器在 Nexus 中请求完成目标的结果
- en: After a few minutes, the agent returns with the saved file, and in some cases,
    it may provide extra information, such as the next steps and what to do with the
    output. This is because the agent was given a high-level overview of what it accomplished.
    Remember, though, that plan execution is done at the local level, and only context,
    plan, and goal were sent to the LLM.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，代理返回保存的文件，在某些情况下，它可能还会提供额外信息，例如下一步操作和如何处理输出。这是因为代理被赋予了对其所完成工作的概述。但请记住，计划执行是在本地级别完成的，并且只向
    LLM 发送了上下文、计划和目标。
- en: This means that plan execution can be completed by any process, not necessarily
    by the agent. Executing a plan outside the LLM reduces the tokens and tool use
    the agent needs to perform. This also means that an LLM doesn’t need to support
    tools usage to use a planner.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着计划执行可以由任何进程完成，而不仅仅是代理。在 LLM 外部执行计划可以减少代理执行所需令牌和工具的使用。这也意味着 LLM 不需要支持工具使用就可以使用规划器。
- en: Internally, when a planner is enabled within Nexus, the agent engine tool is
    bypassed. Instead, the planner completes the action execution, and the agent is
    only aware of the actions through the passing of the output context. This can
    be good for models that support tool use but can’t plan. However, a planner may
    limit functionality for models that support both tool use and planning, such as
    Claude.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Nexus 内部，当启用规划器时，代理引擎工具被绕过。相反，规划器完成动作执行，代理只通过输出上下文的传递来了解动作。这对支持工具使用但不能规划的模式来说可能是个好主意。然而，规划器可能会限制支持工具使用和规划的双重支持模式，如
    Claude。
- en: In general, you’ll want to understand the capabilities of the LLM you’re using.
    If you’re unsure of those details, then a little trial and error can also work.
    Ask the agent to complete a multistep goal with and without planning enabled,
    and then see the results.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你想要了解你所使用的 LLM 的能力。如果你不确定这些细节，那么一点点的尝试和错误也可以工作。要求代理在有和无计划启用的情况下完成多步骤目标，然后查看结果。
- en: Planning allows agents to complete multiple sequential tasks to achieve more
    complex goals. The problem with external or prompt planning is that it bypasses
    the feedback iteration loop, which can help correct problems quickly. Because
    of this, OpenAI and others are now directly integrating reasoning and planning
    at the LLM level, as we’ll see in the next section.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 规划允许代理完成多个顺序任务以实现更复杂的目标。外部或提示规划的问题在于它绕过了反馈迭代循环，这有助于快速纠正问题。正因为如此，OpenAI 和其他人现在正在直接在
    LLM 层面集成推理和规划，正如我们将在下一节中看到的。
- en: '11.4 Reviewing a stepwise planner: OpenAI Strawberry'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 检查步骤式规划器：OpenAI Strawberry
- en: The release of the o1-preview model, code named Strawberry, introduced a dramatic
    shift in the type of LLMs becoming available for agentic systems. Strawberry was
    not only proclaimed to be more efficient at math, science, and general calculation
    tasks but also able to engage in reasoning, planning, evaluation, and feedback
    directly in the LLM.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: o1-preview 模型的发布，代号草莓，为可用于代理系统的 LLM 类型带来了巨大的转变。草莓不仅被宣称为在数学、科学和一般计算任务上更有效率，而且还能在
    LLM 中直接进行推理、规划、评估和反馈。
- en: Consider our time travel problem from chapter 10 and shown again in figure 11.9\.
    If you recall, this problem was difficult to solve using GPT-4 and other similar
    LLMs. However, with the application of reasoning and feedback, we were able to
    produce output that was occasionally correct.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑第 10 章中的时间旅行问题，如图 11.9 所示。如果你还记得，这个问题使用 GPT-4 和其他类似的 LLM 难以解决。然而，通过应用推理和反馈，我们能够偶尔产生正确的输出。
- en: '![figure](../Images/11-9.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/11-9.png)'
- en: Figure 11.9 The time travel problem, revisited
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.9 重新审视时间旅行问题
- en: As an experiment, enter this problem into ChatGPT using the o1-preview model,
    as shown in listing 11.6\. Sit back for a few seconds and wait for the answer.
    Yep, the model still gets it wrong.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作为实验，将此问题输入到 ChatGPT 中，使用 o1-preview 模型，如列表 11.6 所示。坐下来等待几秒钟，等待答案。是的，模型仍然答错了。
- en: Listing 11.6 Time travel reasoning/planning problem
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.6 时间旅行推理/规划问题
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: While it may be somewhat disappointing to see the model get the wrong answer,
    it does, however, do a far better job of breaking down the problem and demonstrating
    its answer. Listing 11.7 shows the sample output from posing the problem in listing
    11.6 to the Strawberry model. Note, you may get a different answer because of
    the stochastic nature of the LLM.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然看到模型给出错误答案可能有些令人失望，但它确实在分解问题和展示其答案方面做得更好。列表 11.7 显示了将列表 11.6 中的问题提出给草莓模型的样本输出。请注意，由于
    LLM 的随机性，你可能会得到不同的答案。
- en: Listing 11.7 o1-preview response to time travel problem
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.7 o1-preview 对时间旅行问题的响应
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 It becomes obvious where the model is making the error.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 模型出错的地方变得明显。'
- en: Because we know the right answer is 27, we know the LLM is wrong, but if we
    didn’t, we could just as easily assume that the work and reasoning were all correct.
    Problems like this can happen when we remove feedback in LLM interactions and
    agentic systems. Feedback can guide the model to correct itself.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们知道正确答案是27，所以我们知道LLM是错误的，但如果我们不知道，我们同样可以假设工作和推理都是正确的。当我们从LLM交互和代理系统中移除反馈时，可能会发生类似的问题。反馈可以引导模型自我纠正。
- en: However, what if we didn’t know the correct answer was 27 (26, if you assume
    he doesn’t spend the day to witness the battle) and assumed the LLM or agent was
    correct? Well, this is a problem we can rectify with a couple of simple prompts
    that can engage the LLM in reasoning and planning feedback. However, these techniques
    are more effective with LLMs or wrappers such as the OpenAI Assistants, which
    provide reasoning and planning within the model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们不知道正确答案是27（如果你假设他没有花一天时间来见证战斗，那么是26），并且假设LLM或代理是正确的呢？嗯，这是一个我们可以通过几个简单的提示来纠正的问题，这些提示可以激发LLM进行推理和规划反馈。然而，这些技术对LLM或像OpenAI助手这样的包装器更有效，它们在模型内部提供推理和规划。
- en: What we want to do is provide feedback to the LLM, but understanding what that
    feedback is will likely be difficult for us. Fortunately, we can elicit feedback
    directly from the LLM, provided we give the correct answer. Listing 11.8 shows
    how to generate constructive feedback from the LLM concerning our time travel
    problem.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要做的是向LLM提供反馈，但理解这个反馈可能对我们来说会很困难。幸运的是，只要我们给出正确的答案，我们就可以直接从LLM中获取反馈。列表11.8展示了如何从LLM中生成有关我们时间旅行问题的建设性反馈。
- en: Listing 11.8 Generating feedback
  id: totrans-111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.8 生成反馈
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Entering this after the model answers the question wrong will generate feedback
    that you can use to guide the model through prompting or as part of system instructions.
    Listing 11.9 shows an example of the feedback provided by o1-preview. You can
    then extract this feedback and augment the instructions the next time you want
    to tackle complex time travel problems.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型回答问题错误之后输入此内容将生成你可以用来通过提示或作为系统指令的一部分来引导模型的反馈。列表11.9展示了o1-preview提供的反馈示例。然后你可以提取这个反馈，并在下一次想要解决复杂的时间旅行问题时增强指令。
- en: Listing 11.9 Generated feedback
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.9 生成反馈
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This feedback technique will consistently work on models such as o1-preview,
    but other models may still struggle to answer correctly, even given this feedback.
    Over time, as models become smarter, this technique will likely generally work
    on most models. However, this feedback mechanism will likely be essential even
    as models get progressively brighter. because language is nuanced, and not every
    problem we challenge LLMs with may have an obvious absolute answer. Take our example
    problem, for instance. This problem is an excellent example of requiring the problem
    solver to make assumptions and draw correlations from the question. There are
    still plenty of areas in science, from geology to behavioral science, where answering
    the same problem may yield a range of answers. Let’s look next at a few techniques
    for how the application of reasoning, planning, evaluation, and feedback can be
    applied to agentic systems.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这种反馈技术将始终适用于o1-preview等模型，但其他模型即使在给出这种反馈的情况下，可能仍然难以正确回答。随着时间的推移，随着模型变得越来越智能，这种技术可能普遍适用于大多数模型。然而，即使模型变得越来越聪明，这种反馈机制可能仍然是必不可少的，因为语言是微妙的，并不是我们向LLM提出的每个问题都有一个明显的绝对答案。以我们的例子问题为例。这个问题是要求问题解决者从问题中做出假设并建立关联的一个很好的例子。在从地质学到行为科学等众多科学领域，回答同一个问题可能会得到一系列答案。接下来，让我们看看如何将推理、规划、评估和反馈的应用应用于代理系统的一些技术。
- en: 11.5 Applying planning, reasoning, evaluation, and feedback to assistant and
    agentic systems
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.5 将规划、推理、评估和反馈应用于辅助和代理系统
- en: In recent chapters, we’ve examined how the agentic components of planning, reasoning,
    feedback, and evaluation can be implemented. Now we look at how, when, and where
    those components can be integrated into assistant and agentic systems for real-time
    production, research, or development.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近几章中，我们探讨了如何实现规划、推理、反馈和评估的代理组件。现在我们来看看这些组件何时、何地可以集成到辅助和代理系统中，以实现实时生产、研究或开发。
- en: While not all of these components may fit the same into every application, it’s
    useful to understand where and when to apply which component. In the next section,
    we look at how planning can be integrated into assistant/agentic systems.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然并非所有这些组件都适合每个应用，但了解何时以及如何应用哪个组件是有用的。在下一节中，我们将探讨如何将规划集成到辅助/代理系统中。
- en: 11.5.1 Application of assistant/agentic planning
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.1 辅助/代理规划的运用
- en: Planning is the component where an assistant or agent can plan to undertake
    a set of tasks, whether they are in series, parallel, or some other combination.
    We typically associate planning with tool use, and, rightfully, any system using
    tools will likely want a capable planner. However, not all systems are created
    equally, so in table 11.1, we’ll review where, when, and how to implement planners.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 规划是辅助工具或代理可以规划执行一系列任务的组件，无论是串联、并行还是其他组合。我们通常将规划与工具使用联系起来，并且，合理地，任何使用工具的系统都可能希望有一个能够胜任的规划器。然而，并非所有系统都是同等创建的，所以在第11.1表中，我们将回顾在哪里、何时以及如何实现规划器。
- en: Table 11.1 When and where planning is employed and used in various applications
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表11.1 规划在各种应用中的运用和实施时间
- en: '| Application | Implemented | Environment | Purpose | Timing | Configuration
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 实现 | 环境 | 目的 | 时间 | 配置 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Personal assistant  | At or within the LLM  | Personal device  | Facilitate
    tool use  | During the response  | As part of the prompt or LLM  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 个人助理 | 在或LLM内部 | 个人设备 | 促进工具使用 | 在响应期间 | 作为提示或LLM的一部分 |'
- en: '| Customer service bot  | Not typical; restricted environment  | Restricted
    environment, no tool use  |  |  |  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务机器人 | 不典型；受限环境 | 受限环境，无工具使用 |  |  |  |'
- en: '| Autonomous agent  | As part of the agent prompt and within the LLM  | Server
    or service  | Facilitate complex tool use and task planning  | As part of constructing
    the agent and/or during the response  | Within the agent or LLM  |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 自主代理 | 作为代理提示和LLM的一部分 | 服务器或服务 | 促进复杂工具使用和任务规划 | 在构建代理和/或响应期间 | 在代理或LLM内部
    |'
- en: '| Collaborative workflows  | As part of the LLM  | Shared canvas or coding  |
    Facilitate complex tool use  | During the response  | Within the LLM  |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 协作工作流程 | 作为LLM的一部分 | 共享画布或编码 | 促进复杂工具使用 | 在响应期间 | 在LLM内部 |'
- en: '| Game AI  | As part of the LLM  | Server or application  | Complex tool use
    and planning  | Before or during the response  | Within the LLM  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 游戏人工智能 | 作为LLM的一部分 | 服务器或应用 | 复杂工具使用和规划 | 在响应之前或期间 | 在LLM内部 |'
- en: '| Research  | Anywhere  | Server  | Facilitate tool use and engage in complex
    task workflows  | Before, during, and after response generation  | Anywhere  |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 任何地方 | 服务器 | 促进工具使用并参与复杂任务工作流程 | 在响应生成之前、期间和之后 | 任何地方 |'
- en: 'Table 11.1 shows several varied application scenarios in which we may find
    an assistant or agent deployed to assist in some capacity. To provide further
    information and guidance, this list provides more details about how planning may
    be employed in each application:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.1展示了我们可能发现辅助工具或代理被部署以协助各种应用场景的几个不同应用场景。为了提供更多信息和建议，此列表提供了关于如何在每个应用中运用规划更详细的说明：
- en: '*Personal assistant*—While this application has been slow to roll out, LLM
    personal assistants promise to surpass Alexa and Siri in the future. Planning
    will be essential to these new assistants/agents to coordinate numerous complex
    tasks and execute tools (actions) in series or parallel.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个人助理*—虽然这项应用推出较慢，但LLM个人助理有望在未来超越Alexa和Siri。规划对于这些新助理/代理来说将至关重要，以协调众多复杂任务并在串联或并行中执行工具（动作）。'
- en: '*Customer service bot*—Due to the controlled nature of this environment, it’s
    unlikely that assistants engaged directly with customers will have controlled
    and very specific tools use. This means that these types of assistants will likely
    not require extensive planning.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户服务机器人*—由于这个环境的可控性，直接与客户互动的助手不太可能使用受控且非常具体的工具。这意味着这类助手可能不需要广泛的规划。'
- en: '*Autonomous agent*—As we’ve seen in previous chapters, agents with the ability
    to plan can complete a series of complex tasks for various goals. Planning will
    be an essential element of any autonomous agentic system.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自主代理*—正如我们在前面的章节中看到的，具有规划能力的代理可以完成一系列复杂任务以实现各种目标。规划将是任何自主代理系统的基本要素。'
- en: '*Collaborative workflows*—Think of these as agents or assistants that sit alongside
    coders or writers. While these workflows are still in early development, think
    of a workflow where agents are automatically tasked with writing and executing
    test code alongside developers. Planning will be an essential part of executing
    these complex future workflows.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协作工作流程*——将这些视为与编码者或作家并肩而坐的代理或助手。虽然这些工作流程仍处于早期开发阶段，但想象一下代理自动被分配与开发者一起编写和执行测试代码的工作流程。规划将是执行这些复杂未来工作流程的一个关键部分。'
- en: '*Game AI*—While applying LLMs to games is still in early stages, it isn’t hard
    to imagine in-game agents or assistants that can assist or challenge the player.
    Giving these agents the ability to plan and execute complex workflows could disrupt
    how and with whom we play games.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏人工智能*——虽然将LLM应用于游戏仍处于早期阶段，但想象游戏中能够协助或挑战玩家的代理或助手并不困难。赋予这些代理规划执行复杂工作流程的能力可能会改变我们玩游戏的方式和对象。'
- en: '*Research*—Similar to collaborative workflows, these agents will be responsible
    for deriving new ideas from existing sources of information. Finding that information
    will likely be facilitated through extensive tool use, which will benefit from
    coordination of planning.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*研究*——与协作工作流程类似，这些代理将负责从现有信息来源中推导出新想法。找到这些信息可能将通过广泛使用工具来促进，这将受益于规划的协调。'
- en: As you can see, planning is an essential part of many LLM applications, whether
    through coordination of tool use or otherwise. In the next section, we look at
    the next component of reasoning and how it can be applied to the same application
    stack.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，规划是许多LLM应用的一个关键部分，无论是通过工具使用的协调还是其他方式。在下一节中，我们将探讨推理的下一个组成部分以及它如何应用于相同的应用堆栈。
- en: 11.5.2 Application of assistant/agentic reasoning
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.2 助手/代理推理的应用
- en: Reasoning, while often strongly associated with planning and task completion,
    is a component that can also stand by itself. As LLMs mature and get smarter,
    reasoning is often included within the LLM itself. However, not all applications
    may benefit from extensive reasoning, as it often introduces a thinking cycle
    within the LLM response. Table 11.2 describes at a high level how the reasoning
    component can be integrated with various LLM application types.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 推理，虽然通常与规划和任务完成紧密相关，但也是一个可以独立存在的组成部分。随着大型语言模型（LLM）的成熟和智能化，推理通常被包含在LLM本身中。然而，并非所有应用都能从广泛的推理中受益，因为它往往在LLM响应中引入一个思考周期。表11.2从高层次描述了推理组件如何与各种LLM应用类型集成。
- en: Table 11.2 When and where reasoning is employed and used in various applications
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表11.2 在各种应用中推理何时何地被使用
- en: '| Application | Implemented | Environment | Purpose | Timing | Configuration
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 实现 | 环境 | 目的 | 时间 | 配置 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Personal assistant  | Within the LLM  | Personal device  | Breaking down
    work into steps  | During the response  | As part of the prompt or LLM  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 个人助理 | 在LLM内部 | 个人设备 | 将工作分解成步骤 | 在响应期间 | 作为提示或LLM的一部分 |'
- en: '| Customer service bot  | Not typical; usually just informational  | Limited
    tool use and need for composite tool use  |  |  |  |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务机器人 | 不典型；通常只是信息性 | 有限工具使用和复合工具使用需求 |  |  |  |'
- en: '| Autonomous agent  | As part of the agent prompt and within the LLM  | Server
    or service  | Facilitate complex tool use and task planning  | As part of LLM,
    external reasoning not well suited  | Within the agent or LLM  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 自主代理 | 作为代理提示和LLM的一部分 | 服务器或服务 | 促进复杂工具使用和任务规划 | 作为LLM的一部分，外部推理不适合 | 在代理或LLM内部
    |'
- en: '| Collaborative workflows  | As part of the LLM  | Shared canvas or coding  |
    Assists in breaking work down  | During the response  | Within the LLM  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 协作工作流程 | 作为LLM的一部分 | 共享画布或编码 | 协助将工作分解 | 在响应期间 | 在LLM内部 |'
- en: '| Game AI  | As part of the LLM  | Server or application  | Essential for undertaking
    complex actions  | Before or during the response  | Within the LLM  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 游戏人工智能 | 作为LLM的一部分 | 服务器或应用 | 承担复杂行动的必要条件 | 在响应之前或期间 | 在LLM内部 |'
- en: '| Research  | Anywhere  | Server  | Understand how to solve complex problems
    and engage in complex task workflows  | Before, during, and after response generation  |
    Anywhere  |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 任何地方 | 服务器 | 理解如何解决复杂问题并参与复杂任务工作流程 | 在响应之前、期间和之后 | 任何地方 |'
- en: 'Table 11.2 shows several varied application scenarios in which we may find
    an assistant or agent deployed to assist in some capacity. To provide further
    information and guidance, this list provides more details about how reasoning
    may be employed in each application:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.2显示了我们在其中可能找到部署以协助某些工作的助手或代理的几个不同应用场景。为了提供更多信息和建议，此列表提供了有关如何在每个应用中应用推理的更多详细信息：
- en: '*Personal assistant*—Depending on the application, the amount of reasoning
    an agent employs may be limited. Reasoning is a process that requires the LLM
    to think through a problem, and this often requires longer response times depending
    on the complexity of the problem and the extent of the prompt. In many situations,
    responses intended to be closer to real-time reasoning may be disabled or turned
    down. While this may limit the complexity at which an agent can interact, limited
    or no reasoning can improve response times and increase user enjoyment.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个人助理*——根据应用的不同，代理使用的推理量可能有限。推理是一个需要LLM思考问题的过程，这通常需要根据问题的复杂性和提示的范围来调整更长的响应时间。在许多情况下，旨在接近实时推理的响应可能被禁用或降低。虽然这可能限制代理可以交互的复杂性，但有限的或没有推理可以提高响应时间并增加用户满意度。'
- en: '*Customer service bot*—Again, because of the controlled nature of this environment,
    it’s unlikely that assistants engaged directly with customers will need to perform
    complex or any form of reasoning.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户服务机器人*——同样，由于这个环境的可控性，直接与客户互动的助手不太可能需要执行复杂或任何形式的推理。'
- en: '*Autonomous agent*—While reasoning is a strong component of autonomous agents,
    we still don’t know how much reasoning is too much. As models such as Strawberry
    become available for agentic workflows, we can gauge at what point extensive reasoning
    may not be needed. This will surely be the case for well-defined autonomous agent
    workflows.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自主代理*——虽然推理是自主代理的一个强大组成部分，但我们仍然不知道推理过多是多少。随着草莓等模型在代理工作流程中变得可用，我们可以判断在什么情况下广泛的推理可能不是必需的。这肯定适用于定义明确的自主代理工作流程。'
- en: '*Collaborative workflows*—Again, applying reasoning creates an overhead in
    the LLM interaction. Extensive reasoning may provide benefits for some workflows,
    while other well-defined workflows may suffer. This may mean that these types
    of workflows will benefit from multiple agents—those with reasoning and those
    without.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协作工作流程*——同样，应用推理会在LLM交互中产生开销。广泛的推理可能对某些工作流程有益，而其他定义明确的工作流程可能会受到影响。这可能意味着这些类型的工作流程将从多个代理中受益——那些具有推理能力和那些没有推理能力的代理。'
- en: '*Game AI*—Similar to other applications, heavy-reasoning applications may not
    be appropriate for most game AIs. Games will especially require LLM response times
    to be quick, and this will surely be the application of reasoning for general
    tactical agents. Of course, that doesn’t preclude the use of other reasoning agents
    that may provide more strategic control.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏人工智能*——与其他应用类似，重推理应用可能不适合大多数游戏人工智能。游戏特别需要LLM响应时间快，这肯定将是推理在通用战术代理中的应用。当然，这并不排除使用其他推理代理，这些代理可能提供更多战略控制。'
- en: '*Research*—Reasoning will likely be essential to any complex research task
    for several reasons. A good example is the application of the Strawberry model,
    which we’ve already seen in research done in mathematics and the sciences.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*研究*——推理可能对任何复杂的研究任务都至关重要，原因有几个。一个很好的例子是草莓模型的应用，我们已经在数学和科学研究中看到过。'
- en: While we often consider reasoning in tandem with planning, there may be conditions
    where the level at which each is implemented may differ. In the next section we
    consider the agent pillar of evaluation of various applications.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们经常将推理与规划一起考虑，但可能存在每种实施水平都不同的条件。在下一节中，我们将考虑各种应用的代理评估支柱。
- en: 11.5.3 Application of evaluation to agentic systems
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.3 评估在代理系统中的应用
- en: Evaluation is the component of agentic/assistant systems that can guide how
    well the system performs. While we demonstrated incorporating evaluation in some
    agentic workflows, evaluation is often an external component in agentic systems.
    However, it’s also a core component of most LLM applications and not something
    that should be overlooked in most developments. Table 11.3 describes at a high
    level how the evaluation component can be integrated with various LLM application
    types.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 评估是代理/助手系统中可以指导系统表现好坏的组件。虽然我们在一些代理工作流程中展示了如何整合评估，但在代理系统中评估通常是一个外部组件。然而，它也是大多数LLM应用的核心组件，并且在大多数开发中不应被忽视。表11.3从高层次描述了评估组件如何与各种LLM应用类型集成。
- en: Table 11.3 When and where evaluation is employed and used in various applications
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表11.3 在各种应用中何时何地使用评估
- en: '| Application | Implemented | Environment | Purpose | Timing | Configuration
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 实现 | 环境 | 目的 | 时间 | 配置 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Personal assistant  | External  | Server  | Determine how well the system
    is working  | After the interaction  | Often developed externally  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 个人助手 | 外部 | 服务器 | 确定系统的工作效果 | 交互后 | 通常外部开发 |'
- en: '| Customer service bot  | External monitor  | Server  | Evaluate the success
    of each interaction  | After the interaction  | External to the agent system  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务机器人 | 外部监控 | 服务器 | 评估每次交互的成功率 | 交互后 | 外部于代理系统 |'
- en: '| Autonomous agent  | External or internal  | Server or service  | Determine
    the success of the system after or during task completion  | After the interaction  |
    External or internal  |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 自主代理 | 外部或内部 | 服务器或服务 | 确定任务完成后的系统成功率 | 交互后 | 外部或内部 |'
- en: '| Collaborative workflows  | External  | Shared canvas or coding  | Evaluate
    the success of the collaboration  | After the interaction  | External service  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 协作工作流程 | 外部 | 共享画布或编码 | 评估协作的成功率 | 交互后 | 外部服务 |'
- en: '| Game AI  | External or internal  | Server or application  | Evaluate the
    agent or evaluate the success of a strategy or action  | After the interaction  |
    External or as part of the agent or another agent  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 游戏人工智能 | 外部或内部 | 服务器或应用 | 评估代理或评估策略或行动的成功率 | 交互后 | 外部或作为代理或另一个代理的一部分 |'
- en: '| Research  | Combined manual and LLM  | Server and human  | Evaluate the output
    of the research developed  | After the generated output  | Depends on the complexity
    of the problem and research undertaken  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 结合人工和LLM | 服务器和人 | 评估研究输出的效果 | 生成输出后 | 取决于问题的复杂性和进行的研究 |'
- en: 'Table 11.3 shows several varied application scenarios in which we may find
    an assistant or agent deployed to assist in some capacity. To provide further
    information and guidance, this list provides more details about how evaluation
    may be employed in each application:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.3展示了我们在各种应用场景中可能找到的助手或代理被部署以协助某些功能的几个不同场景。为了提供更多信息和建议，此列表提供了关于如何在每个应用中使用评估的更多详细信息：
- en: '*Personal assistant*—In most cases, an evaluation component will be used to
    process and guide the performance of agent responses. In systems primarily employing
    retrieval augmented generation (RAG) for document exploration, the evaluation
    indicates how well the assistant responds to information requests.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个人助手*—在大多数情况下，评估组件将被用来处理和指导代理响应的性能。在主要使用检索增强生成（RAG）进行文档探索的系统中，评估表明助手如何响应信息请求。'
- en: '*Customer service bot*—Evaluating service bots is critical to understanding
    how well the bot responds to customer requests. In many cases, a strong RAG knowledge
    element may be an element of the system that will require extensive and ongoing
    evaluation. Again, with most evaluation components, this element is external to
    the main working system and is often run as part of monitoring general performance
    over several metrics.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户服务机器人*—评估服务机器人对于理解机器人如何响应客户请求至关重要。在许多情况下，强大的RAG知识元素可能是系统的一个需要广泛和持续评估的元素。同样，在大多数评估组件中，这个元素是主要工作系统之外的，并且通常作为监控多个指标的一般性能的一部分运行。'
- en: '*Autonomous agent*—In most cases, a manual review of agent output will be a
    primary guide to the success of an autonomous agent. However, in some cases, internal
    evaluation can help guide the agent when it’s undertaking complex tasks or as
    a means of improving the final output. Multiple agent systems, such as CrewAI
    and AutoGen, are examples of autonomous agents that use internal feedback to improve
    the generated output.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自主代理*——在大多数情况下，对代理输出的手动审查将是自主代理成功的主要指导。然而，在某些情况下，内部评估可以帮助指导代理在执行复杂任务时，或作为改进最终输出的手段。CrewAI和AutoGen等多个代理系统是使用内部反馈来改进生成输出的自主代理的例子。'
- en: '*Collaborative workflows*—In most direct cases, manual evaluation is ongoing
    within these types of workflows. A user will often immediately and in near real
    time correct the assistant/agent by evaluating the output. Additional agents could
    be added similarly to autonomous agents for more extensive collaborative workflows.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协作工作流程*——在大多数直接情况下，这些类型的工作流程中会持续进行手动评估。用户通常会立即并在近乎实时的情况下通过评估输出纠正助手/代理。可以添加额外的代理，类似于自主代理，以实现更广泛的协作工作流程。'
- en: '*Game AI*—Evaluation will often be broken down into development evaluation—evaluating
    how the agent interacts with the game—and in-game evaluation, evaluating how well
    an agent succeeded at a task. Implementing the later evaluation form is similar
    to autonomous agents but aims to improve some strategies or execution. Such in-game
    evaluations would also likely benefit from memory and a means of feedback.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏人工智能*——评估通常会被分解为开发评估——评估代理与游戏交互的方式——和在游戏中的评估，评估代理在任务中成功与否。实施后一种评估形式类似于自主代理，但旨在改进某些策略或执行。这种在游戏中的评估也可能从记忆和反馈手段中受益。'
- en: '*Research*—Evaluation at this level generally occurs as a manual effort after
    completing the research task. An agent could employ some form of evaluation similar
    to autonomous agents to improve the generated output, perhaps even contemplating
    internally how evaluation of the output could be extended or further researched.
    Because this is currently a new area for agentic development, how well this will
    be executed remains to be seen.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*研究*——在这个层面上，评估通常是在完成研究任务后作为手动工作进行的。代理可以采用类似于自主代理的某种形式的评估来改进生成的输出，甚至可能在内部思考如何扩展或进一步研究输出的评估。由于这目前是代理发展的一个新领域，其执行效果如何还有待观察。'
- en: Evaluation is an essential element to any agentic or assistant system, especially
    if that system provides real and fundamental information to users. Developing
    evaluation systems for agents and assistants is likely something that could or
    should have its own book. In the final section of this chapter, we’ll look at
    feedback implementation for various LLM applications.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 评估是任何代理或助手系统的基本要素，尤其是当该系统向用户提供真实和基本信息时。为代理和助手开发评估系统可能是可以或应该有自己一本书的内容。在本章的最后部分，我们将探讨各种LLM应用的反馈实现。
- en: 11.5.4 Application of feedback to agentic/assistant applications
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.4 将反馈应用于代理/助手应用
- en: Feedback as a component of agentic systems is often, if not always, implemented
    as an external component—at least for now. Perhaps confidence in evaluation systems
    may improve to the point where feedback is regularly incorporated into such systems.
    Table 11.4 showcases how feedback can be implemented into various LLM applications.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为代理系统组成部分的反馈通常如果不是总是，被实现为一个外部组件——至少目前是这样。也许对评估系统的信心可能会提高，以至于反馈定期被纳入这些系统。表11.4展示了反馈如何被整合到各种LLM应用中。
- en: Table 11.4 When and where feedback is employed and used in various applications
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表11.4 在各种应用中何时何地使用反馈
- en: '| Application | Implemented | Environment | Purpose | Timing | Configuration
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 实现 | 环境 | 目的 | 时间 | 配置 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Personal assistant  | External or by the user  | Aggregated to the server
    or as part of the system  | Provides means of system improvement  | After or during
    the interaction  | Internal and external  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 个人助手 | 外部或由用户 | 聚合到服务器或作为系统的一部分 | 提供系统改进的手段 | 在交互后或交互期间 | 内部和外部 |'
- en: '| Customer service bot  | External monitor  | Aggregated to the server  | Qualifies
    and provides a means for system improvement  | After the interaction  | External
    to the agent system  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务机器人 | 外部监控 | 聚合到服务器 | 确认并提供系统改进的手段 | 交互后 | 代理系统外部 |'
- en: '| Autonomous agent  | External  | Aggregated at the server  | Provides a means
    for system improvement  | After the interaction  | External  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 自主代理 | 外部 | 在服务器端汇总 | 提供系统改进的手段 | 在交互之后 | 外部 |'
- en: '| Collaborative workflows  | While interacting  | Shared canvas or coding  |
    Provides a mechanism for immediate feedback  | During the interaction  | External
    service  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 协作工作流程 | 在交互过程中 | 共享画布或编码 | 提供即时反馈的机制 | 在交互过程中 | 外部服务 |'
- en: '| Game AI  | External or internal  | Server or application  | As part of internal
    evaluation feedback provided for dynamic improvement  | After or during the interaction  |
    External or as part of the agent or another agent  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 游戏人工智能 | 外部或内部 | 服务器或应用 | 作为内部评估反馈的一部分，以提供动态改进 | 在交互之后或交互过程中 | 外部或作为代理或另一个代理的一部分
    |'
- en: '| Research  | Combined manual and LLM  | Server and human  | Evaluate the output
    of the research developed  | After the generated output  | Depends on the complexity
    of the problem and the research undertaken  |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 结合人工和LLM | 服务器和人类 | 评估开发的研究输出 | 在生成输出之后 | 依赖于问题的复杂性和进行的研究 |'
- en: 'Table 11.4 shows several application scenarios in which we may find an assistant
    or agent deployed to assist in some capacity. To provide further information and
    guidance, this list provides more details about how feedback may be employed in
    each application:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.4显示了我们在其中可能找到部署以协助某些功能的助理或代理的几个应用场景。为了提供更多信息和建议，此列表提供了关于如何在每个应用中采用反馈的更多详细信息：
- en: '*Personal assistant*—If the assistant or agent interacts with the user in a
    chat-style interface, direct and immediate feedback can be applied by the user.
    Whether this feedback is sustained over future conversations or interactions,
    it usually develops within agentic memory. Assistants such as ChatGPT now incorporate
    memory and can benefit from explicit user feedback.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个人助理*—如果助理或代理通过聊天式界面与用户互动，用户可以提供直接和即时的反馈。这种反馈是否在未来的对话或互动中持续，通常是在代理记忆中发展的。例如ChatGPT这样的助理现在已经集成了记忆功能，并能从明确用户反馈中受益。'
- en: '*Customer service bot*—User or system feedback is typically provided through
    a survey after the interaction has completed. This usually means that feedback
    is regulated to an external system that aggregates the feedback for later improvements.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户服务机器人*—用户或系统反馈通常在交互完成后通过调查提供。这通常意味着反馈被调节到一个外部系统中，该系统汇总反馈以供后续改进。'
- en: '*Autonomous agent*—Much like bots, feedback within autonomous agents is typically
    regulated to after the agent has completed a task that a user then reviews. The
    feedback mechanism may be harder to capture because many things can be subjective.
    Methods explored in this chapter for producing feedback can be used within prompt
    engineering improvements.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自主代理*—与机器人类似，自主代理中的反馈通常是在代理完成用户随后审查的任务之后进行的。由于许多事情可能是主观的，因此反馈机制可能更难以捕捉。本章探索的用于生成反馈的方法可以用于提示工程改进。'
- en: '*Collaborative workflows*—Similar to the personal assistant, these types of
    applications can benefit from immediate and direct feedback from the user. Again,
    how this information is persisted across sessions is often an implementation of
    agentic memory.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协作工作流程*—与个人助理类似，这些类型的应用可以从用户的即时和直接反馈中受益。同样，如何将此类信息持久化到会话中通常是代理记忆的实现。'
- en: '*Game AI*—Feedback can be implemented alongside evaluation through additional
    and multiple agents. This feedback form may again be single-use and exist within
    the current interaction or may persist as memory. Imagine a game AI that can evaluate
    its actions, improve those with feedback, and remember those improvements. While
    this pattern isn’t ideal for games, it will certainly improve the gameplay experience.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*游戏人工智能*—反馈可以在通过额外和多个代理进行评估的同时实施。这种反馈形式可能是单次使用的，存在于当前交互中，或者可能作为记忆持久存在。想象一下，一个能够评估其行为、根据反馈改进这些行为并记住这些改进的游戏人工智能。虽然这种模式对于游戏来说并不理想，但它肯定会改善游戏体验。'
- en: '*Research*—Similar to evaluation in the context of research, feedback is typically
    performed offline after the output is evaluated. While some development has been
    done using multiple agent systems incorporating agents for evaluation and feedback,
    these systems don’t always perform well, at least not with the current state-of-the-art
    models. Instead, it’s often better to isolate feedback and evaluation at the end
    to avoid the common feedback looping problem.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*研究*—与研究背景下的评估类似，反馈通常在输出评估后离线进行。虽然已经进行了一些使用多个代理系统的研究，这些系统结合了用于评估和反馈的代理，但这些系统并不总是表现良好，至少不是使用当前最先进的模型。相反，通常最好在最后将反馈和评估隔离，以避免常见的反馈循环问题。'
- en: Feedback is another powerful component of agentic and assistant systems, but
    it’s not always required on the first release. However, incorporating rigorous
    feedback and evaluation mechanisms can greatly benefit agentic systems in the
    long term concerning ongoing monitoring and providing the confidence to improve
    various aspects of the system.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈是代理和助手系统的一个强大组件，但并不总是需要在首次发布时包含。然而，纳入严格的反馈和评估机制可以极大地从长远角度有利于代理系统，包括持续监控和提供改进系统各个方面的信心。
- en: How you implement each of these components in your agentic systems may, in part,
    be guided by the architecture of your chosen agentic platform. Now that you understand
    the nuances of each component, you also have the knowledge to guide you in selecting
    the right agent system that fits your application and business use case. Regardless
    of your application, you’ll want to employ several agentic components in almost
    all cases.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何在你的代理系统中实现这些组件，部分可能由你选择的代理平台架构指导。现在你了解了每个组件的细微差别，你也拥有了指导你选择适合你的应用程序和业务用例的正确代理系统的知识。无论你的应用程序如何，你几乎在所有情况下都希望使用几个代理组件。
- en: As agentic systems mature and LLMs themselves get smarter, some of the components
    we today consider external may be closely integrated. We’ve already seen reasoning
    and planning be integrated into a model such as Strawberry. Certainly, as we approach
    the theoretical artificial general intelligence milestone, we may see models capable
    of performing long-term self-evaluation and feedback.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 随着代理系统成熟以及LLM本身变得更智能，我们今天认为的一些外部组件可能会紧密集成。我们已经看到推理和规划被整合到一个如Strawberry这样的模型中。当然，随着我们接近理论上的通用人工智能里程碑，我们可能会看到能够进行长期自我评估和反馈的模型。
- en: In any case, I hope you enjoyed this journey with me into this incredible frontier
    of a new and emerging technology that will certainly alter our perception of work
    and how we undertake it through agents.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，我希望你喜欢与我一起探索这个令人难以置信的新兴技术前沿的旅程，这个技术将无疑改变我们对工作和通过代理进行工作的看法。
- en: 11.6 Exercises
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.6 练习
- en: 'Use the following exercises to improve your knowledge of the material:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来提高你对材料的了解：
- en: '*Exercise 1*—Implement a Simple Planning Agent (Beginner)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*练习1*—实现一个简单的规划代理（入门级）'
- en: '*Objective *—Learn how to implement a basic planning agent using a prompt to
    generate a sequence of actions.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标*—学习如何使用提示生成一系列动作来实现基本规划代理。'
- en: '*Tasks:*'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：*'
- en: Create an agent that receives a goal, breaks it into steps, and executes those
    steps sequentially.
  id: totrans-204
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个代理，它接收一个目标，将其分解成步骤，并按顺序执行这些步骤。
- en: Define a simple goal, such as retrieving information from Wikipedia and saving
    it to a file.
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个简单的目标，例如从维基百科检索信息并将其保存到文件中。
- en: Implement the agent using a basic planner prompt (refer to the planner example
    in section 11.3).
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基本的规划器提示（参考第11.3节中的规划器示例）实现代理。
- en: Run the agent, and evaluate how well it plans and executes each step.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行代理，并评估它在规划和执行每一步时的表现。
- en: '*Exercise 2*—Test Feedback Integration in a Planning Agent (Intermediate)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*练习2*—在规划代理中测试反馈集成（中级）'
- en: '*Objective *—Understand how feedback mechanisms can improve the performance
    of an agentic system.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标*—理解反馈机制如何提高代理系统的性能。'
- en: '*Tasks:*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：*'
- en: Modify the agent from exercise 1 to include a feedback loop after each task.
  id: totrans-211
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改练习1中的代理，在每个任务后包含一个反馈循环。
- en: Use the feedback to adjust or correct the next task in the sequence.
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用反馈来调整或纠正序列中的下一个任务。
- en: Test the agent by giving it a more complex task, such as gathering data from
    multiple sources, and observe how the feedback improves its performance.
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过给它一个更复杂的任务，如从多个来源收集数据，来测试代理，并观察反馈如何提高其性能。
- en: Document and compare the agent’s behavior before and after adding feedback.
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录并比较添加反馈前后代理的行为。
- en: '*Exercise 3*—Experiment with Parallel and Sequential Planning (Intermediate)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*练习 3*—实验并行和顺序规划（中级）'
- en: '*Objective*—Learn the difference between parallel and sequential actions and
    how they affect agent behavior.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标*—学习并行和顺序动作之间的区别以及它们如何影响代理行为。'
- en: '*Tasks:*'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：*'
- en: 'Set up two agents using Nexus: one that executes tasks in parallel and another
    that performs tasks sequentially.'
  id: totrans-218
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Nexus 设置两个代理：一个并行执行任务，另一个顺序执行任务。
- en: Define a multistep goal where some actions depend on the results of previous
    actions (sequential), and some can be done simultaneously (parallel).
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个多步骤目标，其中一些动作依赖于先前动作的结果（顺序），而另一些可以同时进行（并行）。
- en: Compare the performance and output of both agents, noting any errors or inefficiencies
    in parallel execution when sequential steps are required.
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较两个代理的性能和输出，注意在需要顺序步骤时并行执行中的任何错误或不效率。
- en: '*Exercise 4*—Build and Integrate a Custom Planner into Nexus (Advanced)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*练习 4*—在 Nexus 中构建和集成自定义规划器（高级）'
- en: '*Objective *—Learn how to build a custom planner and integrate it into an agent
    platform.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标*—学习如何构建自定义规划器并将其集成到代理平台中。'
- en: '*Tasks:*'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：*'
- en: Write a custom planner using prompt engineering strategies from section 11.3,
    ensuring it supports sequential task execution.
  id: totrans-224
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用第 11.3 节中的提示工程策略编写自定义规划器，确保它支持顺序任务执行。
- en: Integrate this planner into Nexus, and create an agent that uses it.
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将此规划器集成到 Nexus 中，并创建一个使用它的代理。
- en: Test the planner with a complex goal that involves multiple steps and tools
    (e.g., data retrieval, processing, and saving).
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用涉及多个步骤和工具（例如，数据检索、处理和保存）的复杂目标测试规划器。
- en: Evaluate how the custom planner performs compared to built-in planners in Nexus
    or other platforms.
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估自定义规划器与 Nexus 内置规划器或其他平台相比的性能。
- en: '*Exercise 5*—Implement Error Handling and Feedback in Sequential Planning (Advanced)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*练习 5*—在顺序规划中实现错误处理和反馈（高级）'
- en: '*Objective *—Learn how to implement error handling and feedback to refine sequential
    planning in an agentic system.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标*—学习如何在代理系统中实现错误处理和反馈以完善顺序规划。'
- en: '*Tasks:*'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务：*'
- en: Using a sequential planner, set up an agent to perform a goal that may encounter
    common errors (e.g., a failed API call, missing data, or invalid input).
  id: totrans-231
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用顺序规划器，设置一个代理执行可能遇到常见错误的目标（例如，失败的 API 调用、缺失数据或无效输入）。
- en: Implement error-handling mechanisms in the planner to recognize and respond
    to these errors.
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在规划器中实现错误处理机制以识别和响应这些错误。
- en: Add feedback loops to adjust the plan or retry actions based on the error encountered.
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加反馈循环以根据遇到的错误调整计划或重试动作。
- en: Test the system by deliberately causing errors during execution, and observe
    how the agent recovers or adjusts its plan.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在执行过程中故意造成错误来测试系统，并观察代理如何恢复或调整其计划。
- en: Summary
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: Planning is central to agents and assistants, allowing them to take a goal,
    break it into steps, and execute them. Without planning, agents are reduced to
    simple chatbot-like interactions.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划对于代理和助手至关重要，它允许他们接受一个目标，将其分解为步骤，并执行它们。没有规划，代理将简化为类似聊天机器人的交互。
- en: Agents must differentiate between parallel and sequential actions. Many LLMs
    can handle parallel actions, but only advanced models support sequential planning,
    critical for complex task completion.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理必须区分并行和顺序动作。许多大型语言模型可以处理并行动作，但只有高级模型支持顺序规划，这对于复杂任务完成至关重要。
- en: Feedback is crucial in guiding agents to correct their course and improve performance
    over time. This chapter demonstrates how feedback mechanisms can be integrated
    with agents to refine their decision-making processes.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反馈对于指导代理纠正方向并在一段时间内提高性能至关重要。本章展示了如何将反馈机制与代理集成以完善其决策过程。
- en: Platforms such as OpenAI Assistants and Anthropic’s Claude support internal
    planning and can execute complex, multistep tasks. Agents using these platforms
    can use sequential action planning for sophisticated workflows.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如 OpenAI 助手和 Anthropic 的 Claude 这样的平台支持内部规划并能执行复杂的多步骤任务。使用这些平台的代理可以使用顺序动作规划进行复杂的流程。
- en: Properly selecting and limiting agent actions is vital to avoid confusion and
    unintended behavior. Too many actions may overwhelm an agent, while unnecessary
    tools may be misused.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确选择和限制代理动作对于避免混淆和意外行为至关重要。过多的动作可能会压倒代理，而不必要的工具可能会被误用。
- en: Nexus allows for creating and managing agents through a flexible interface,
    where users can implement custom planners, set goals, and assign tools. The chapter
    includes practical examples using Nexus to highlight the difference between a
    raw LLM and a planner-enhanced agent.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nexus 允许通过灵活的界面创建和管理代理，用户可以实施自定义规划器、设定目标和分配工具。本章包括使用 Nexus 的实际示例，以突出原始 LLM 和规划器增强代理之间的差异。
- en: Writing custom planners is straightforward, using prompt engineering strategies.
    Tools such as LangChain and Semantic Kernel offer a variety of planners that can
    be adapted or extended to fit specific agentic needs.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写自定义规划器很简单，可以使用提示工程策略。LangChain 和 Semantic Kernel 等工具提供各种规划器，可以根据特定的代理需求进行适配或扩展。
- en: Models such as OpenAI Strawberry integrate reasoning, planning, evaluation,
    and feedback directly into the LLM, offering more accurate problem-solving capabilities.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，OpenAI Strawberry 这样的模型将推理、规划、评估和反馈直接集成到 LLM 中，提供了更精确的问题解决能力。
- en: Evaluation helps determine how well an agentic system is performing and can
    be implemented internally or externally, depending on the use case.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估有助于确定代理系统表现的好坏，可以根据用例在内部或外部实施。
- en: As LLMs evolve, reasoning, planning, and feedback mechanisms may become deeply
    integrated into models, paving the way for more autonomous and intelligent agent
    systems.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着 LLM 的发展，推理、规划和反馈机制可能将深度集成到模型中，为更自主和智能的代理系统铺平道路。
