- en: Chapter 1\. Getting Started with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。开始使用PyTorch
- en: 'In this chapter we set up all we need for working with PyTorch. Once we’ve
    done that, every chapter following will build on this initial foundation, so it’s
    important that we get it right. This leads to our first fundamental question:
    should you build a custom deep learning computer or just use one of the many cloud-based
    resources available?'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们设置了使用PyTorch所需的一切。一旦我们完成了这一步，随后的每一章都将在这个初始基础上构建，因此很重要我们做对。这导致我们的第一个基本问题：您应该构建一个自定义深度学习计算机，还是只使用众多可用的基于云的资源之一？
- en: Building a Custom Deep Learning Machine
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建自定义深度学习机器
- en: There is an urge when diving into deep learning to build yourself a monster
    for all your compute needs. You can spend days looking over different types of
    graphics cards, learning the memory lanes possible CPU selections will offer you,
    the best sort of memory to buy, and just how big an SSD drive you can purchase
    to make your disk access as fast as possible. I am not claiming any immunity from
    this; I spent a month a couple of years ago making a list of parts and building
    a new computer on my dining room table.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，有一种冲动，想要为自己的计算需求建造一个庞然大物。您可以花费数天时间查看不同类型的显卡，了解可能的CPU选择提供的内存通道，购买最佳类型的内存，以及购买多大的SSD驱动器以尽可能快地访问磁盘。我并不是在宣称自己对此免疫；几年前，我花了一个月的时间列出零件清单，在我的餐桌上组装了一台新电脑。
- en: 'My advice, especially if you’re new to deep learning, is this: don’t do it.
    You can easily spend several thousands of dollars on a machine that you may not
    use all that much. Instead, I recommend that you work through this book by using
    cloud resources (in either Amazon Web Services, Google Cloud, or Microsoft Azure)
    and only then start thinking about building your own machine if you feel that
    you require a single machine for 24/7 operation. You *do not* need to make a massive
    investment in hardware to run any of the code in this book.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议，特别是对于新手来说，是：不要这样做。您可以轻松地在一台您可能不会经常使用的机器上花费数千美元。相反，我建议您通过使用云资源（无论是亚马逊网络服务、谷歌云还是微软Azure）来阅读本书，然后再考虑是否需要为自己建造一台机器，如果您觉得需要一台全天候运行的单机。您*不需要*在硬件上进行巨额投资来运行本书中的任何代码。
- en: You might not ever need to build a custom machine for yourself. There’s something
    of a sweet spot, where it can be cheaper to build a custom rig if you know your
    calculations are always going to be restricted to a single machine (with at most
    a handful of GPUs). However, if your compute starts to require spanning multiple
    machines and GPUs, the cloud becomes appealing again. Given the cost of putting
    a custom machine together, I’d think long and hard before diving in.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能永远不需要为自己建造一台定制机器。有一个甜蜜的点，如果您知道您的计算总是会受限于一台机器（最多几个GPU），那么建造一个定制机器可能会更便宜。然而，如果您的计算开始需要跨越多台机器和GPU，云再次变得有吸引力。考虑到组装一台定制机器的成本，我建议您在深入之前三思而后行。
- en: If I haven’t managed to put you off from building your own, the following sections
    provide suggestions for what you would need to do so.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我还没有劝阻您自己组装机器，接下来的部分将提供您需要做的建议。
- en: GPU
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU
- en: The heart of every deep learning box, the GPU, is what is going to power the
    majority of PyTorch’s calculations, and it’s likely going to be the most expensive
    component in your machine. In recent years, the prices of GPUs have increased,
    and the supplies have dwindled, because of their use in mining cryptocurrency
    like Bitcoin. Thankfully, that bubble seems to be receding, and supplies of GPUs
    are back to being a little more plentiful.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个深度学习盒子的核心，GPU，将为大多数PyTorch的计算提供动力，并且很可能是您机器中最昂贵的组件。近年来，由于它们在挖掘比特币等加密货币中的使用，GPU的价格已经上涨，供应量也在减少。幸运的是，这个泡沫似乎正在消退，GPU的供应量又变得更加充裕。
- en: At the time of this writing, I recommend obtaining the NVIDIA GeForce RTX 2080
    Ti. For a cheaper option, feel free to go for the 1080 Ti (though if you are weighing
    the decision to get the 1080 Ti for budgetary reasons, I again suggest that you
    look at cloud options instead). Although AMD-manufactured GPU cards do exist,
    their support in PyTorch is currently not good enough to recommend anything other
    than an NVIDIA card. But keep a lookout for their ROCm technology, which should
    eventually make them a credible alternative in the GPU space.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，我建议选择NVIDIA GeForce RTX 2080 Ti。如果想要更便宜的选项，可以选择1080 Ti（尽管如果您因预算原因考虑选择1080
    Ti，我再次建议您考虑云选项）。尽管AMD制造的GPU卡确实存在，但它们在PyTorch中的支持目前还不够好，无法推荐除NVIDIA卡以外的其他选择。但请留意他们的ROCm技术，这将最终使它们成为GPU领域的可信替代品。
- en: CPU/Motherboard
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CPU/主板
- en: You’ll probably want to spring for a Z370 series motherboard. Many people will
    tell you that the CPU doesn’t matter for deep learning and that you can get by
    with a lower-speed CPU as long as you have a powerful GPU. In my experience, you’ll
    be surprised at how often the CPU can become a bottleneck, especially when working
    with augmented data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会选择Z370系列主板。许多人会告诉您，CPU对于深度学习并不重要，只要有强大的GPU，您可以使用速度较低的CPU。但根据我的经验，CPU往往会成为瓶颈，尤其在处理增强数据时。
- en: RAM
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAM
- en: More RAM is good, as it means you can keep more data inside without having to
    hit the much slower disk storage (especially important during your training stages).
    You should be looking at a minimum of 64GB DDR4 memory for your machine.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的RAM是好的，因为这意味着您可以将更多数据保存在内存中，而不必访问速度慢得多的磁盘存储（尤其是在训练阶段非常重要）。您应该至少考虑为您的机器配备64GB
    DDR4内存。
- en: Storage
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储
- en: 'Storage for a custom rig should be installed in two classes: first, an M2-interface
    solid-state drive (SSD)—as big as you can afford—for your *hot* data to keep access
    as fast as possible when you’re actively working on a project. For the second
    class of storage, add in a 4TB Serial ATA (SATA) drive for data that you’re not
    actively working on, and transfer to *hot* and *cold* storage as required.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义机箱的存储应该分为两类：首先，一个M2接口固态硬盘（SSD）——尽可能大——用于存储您正在积极工作的项目时保持尽可能快的访问速度的*热*数据。对于第二类存储，添加一个4TB串行ATA（SATA）驱动器，用于您当前不在积极工作的数据，并根据需要转移到*热*和*冷*存储。
- en: I recommend that you take a look at [PCPartPicker](https://pcpartpicker.com)
    to glance at other people’s deep learning machines (you can see all the weird
    and wild case ideas, too!). You’ll get a feel for lists of machine parts and associated
    prices, which can fluctuate wildly, especially for GPU cards.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您查看[PCPartPicker](https://pcpartpicker.com)来浏览其他人的深度学习机器（您还可以看到所有奇怪和疯狂的机箱设计想法！）。您将了解到机器零件清单和相关价格，这些价格可能会大幅波动，尤其是GPU卡的价格。
- en: Now that you’ve looked at your local, physical machine options, it’s time to
    head to the clouds.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经查看了本地的物理机器选项，是时候转向云端了。
- en: Deep Learning in the Cloud
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云端深度学习
- en: 'OK, so why is the cloud option better, you might ask? Especially if you’ve
    looked at the Amazon Web Services (AWS) pricing scheme and worked out that building
    a deep learning machine will pay for itself within six months? Think about it:
    if you’re just starting out, you are not going to be using that machine 24/7 for
    those six months. You’re just not. Which means that you can shut off the cloud
    machine and pay pennies for the data being stored in the meantime.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，那么为什么云端选项更好呢？尤其是如果您已经查看了亚马逊网络服务（AWS）的定价方案，并计算出构建深度学习机器将在六个月内收回成本？想一想：如果您刚开始，您不会在这六个月内全天候使用那台机器。您就是不会。这意味着您可以关闭云端机器，并支付存储数据的几分钱。
- en: And if you’re starting out, you don’t need to go all out and use one of NVIDIA’s
    leviathan Tesla V100 cards attached to your cloud instance straightaway. You can
    start out with one of the much cheaper (sometimes even free) K80-based instances
    and move up to the more powerful card when you’re ready. That is a trifle less
    expensive than buying a basic GPU card and upgrading to a 2080Ti on your custom
    box. Plus if you want to add eight V100 cards to a single instance, you can do
    it with just a few clicks. Try doing that with your own hardware.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您刚开始，您不需要立即使用NVIDIA的庞大Tesla V100卡连接到您的云实例。您可以从更便宜的（有时甚至是免费的）基于K80的实例开始，然后在准备好时升级到更强大的卡。这比在自定义盒子上购买基本GPU卡并升级到2080Ti便宜一点。此外，如果您想在单个实例中添加八张V100卡，您只需点击几下即可。试试用您自己的硬件做到这一点。
- en: The other issue is maintenance. If you get yourself into the good habit of re-creating
    your cloud instances on a regular basis (ideally starting anew every time you
    come back to work on your experiments), you’ll almost always have a machine that
    is up to date. If you have your own machine, updating is up to you. This is where
    I confess that I do have my own custom deep learning machine, and I ignored the
    Ubuntu installation on it for so long that it fell out of supported updates, resulting
    in an eventual day spent trying to get the system back to a place where it was
    receiving updates again. Embarrassing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是维护。如果您养成良好的习惯，定期重新创建云实例（最好每次回来进行实验时都重新开始），您几乎总是会有一个最新的机器。如果您有自己的机器，更新就取决于您。这就是我承认我有自己的定制深度学习机器的地方，我忽视了它上面的Ubuntu安装很长时间，结果是它不再接收支持的更新，最终花了一整天的时间来让系统恢复到可以再次接收更新的状态。令人尴尬。
- en: 'Anyway, you’ve made the decision to go to the cloud. Hurrah! Next: which provider?'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，您已经决定转向云端。万岁！接下来：选择哪个提供商？
- en: Google Colaboratory
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Colaboratory
- en: But wait—before we look at providers, what if you don’t want to do any work
    at all? None of that pesky building a machine or having to go through all the
    trouble of setting up instances in the cloud? Where’s the really lazy option?
    Google has the right thing for you. [*Colaboratory* (or *Colab*)](https://colab.research.google.com)
    is a mostly free, zero-installation-required custom Jupyter Notebook environment.
    You’ll need a Google account to set up your own notebooks. [Figure 1-1](#google-colab-image)
    shows a screenshot of a notebook created in Colab.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等——在我们查看提供商之前，如果您根本不想做任何工作怎么办？不想建立一台机器或者不想费心设置云端实例？哪里有真正懒惰的选择？谷歌为您提供了正确的东西。[*Colaboratory*（或*Colab*）](https://colab.research.google.com)是一个大多数免费、无需安装的定制Jupyter
    Notebook环境。您需要一个谷歌账号来设置您自己的笔记本。[图1-1](#google-colab-image)显示了在Colab中创建的笔记本的屏幕截图。
- en: What makes Colab a great way to dive into deep learning is that it includes
    preinstalled versions of TensorFlow and PyTorch, so you don’t have to do any setup
    beyond typing `import torch`, and every user can get free access to a NVIDIA T4
    GPU for up to 12 hours of continuous runtime. For free. To put that in context,
    empirical research suggests that you get about half the speed of a 1080 Ti for
    training, but with an extra 5GB of memory so you can store larger models. It also
    offers the ability to connect to more recent GPUs and Google’s custom TPU hardware
    in a paid option, but you can pretty much do every example in this book for nothing
    with Colab. For that reason, I recommend using Colab alongside this book to begin
    with, and then you can decide to branch out to dedicated cloud instances and/or
    your own personal deep learning server if needed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Colab之所以成为深度学习的绝佳方式，是因为它包含了预安装的TensorFlow和PyTorch版本，因此您无需进行任何设置，只需键入`import
    torch`，每个用户都可以免费获得长达12小时的连续运行时间的NVIDIA T4 GPU。免费的。从这个角度来看，实证研究表明，您在训练时大约可以获得1080
    Ti速度的一半，但内存额外增加了5GB，因此您可以存储更大的模型。它还提供了连接到更近期的GPU和谷歌定制的TPU硬件的能力，但您几乎可以使用Colab免费完成本书中的每个示例。因此，我建议一开始就使用Colab，并随后根据需要决定是否扩展到专用云实例和/或您自己的个人深度学习服务器。
- en: '![Google Colab](assets/ppdl_0101.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![谷歌Colab](assets/ppdl_0101.png)'
- en: Figure 1-1\. Google Colab(oratory)
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 谷歌Colab（实验室）
- en: Colab is the zero-effort approach, but you may want to have a little more control
    over how things are installed or get Secure Shell (SSH) access to your instance
    on the cloud, so let’s have a look at what the main cloud providers offer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Colab是零工作量的方法，但你可能想要对安装方式或在云端实例上获取安全外壳（SSH）访问有更多控制，因此让我们看看主要云服务提供商提供了什么。
- en: Cloud Providers
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云服务提供商
- en: Each of the big three cloud providers (Amazon Web Services, Google Cloud Platform,
    and Microsoft’s Azure) offers GPU-based instances (also referred to as *virtual
    machines* or *VMs*) and official images to deploy on those instances. They have
    all you need to get up and running without having to install drivers and Python
    libraries yourself. Let’s have a run-through of what each provider offers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 三大云服务提供商（亚马逊网络服务、谷歌云平台和微软的Azure）都提供基于GPU的实例（也称为*虚拟机*或*VMs*）和官方镜像以部署在这些实例上。它们提供了一切你需要的，无需自己安装驱动程序和Python库即可运行。让我们看看每个提供商提供了什么。
- en: Amazon Web Services
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊网络服务
- en: AWS, the 800-pound gorilla of the cloud market, is more than happy to fulfill
    your GPU needs and offers the P2 and P3 instance types to help you out. (The G3
    instance type tends to be used more in actual graphics-based applications like
    video encoding, so we won’t cover it here.) The P2 instances use the older NVIDIA
    K80 cards (a maximum of 16 can be connected to one instance), and the P3 instances
    use the blazing-fast NVIDIA V100 cards (and you can strap eight of those onto
    one instance if you dare).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: AWS，云市场的800磅大猩猩，乐意满足你的GPU需求，并提供P2和P3实例类型来帮助你。（G3实例类型更多用于实际的基于图形的应用程序，如视频编码，所以我们这里不涉及。）P2实例使用较旧的NVIDIA
    K80卡（最多可以连接16个到一个实例），而P3实例使用快速的NVIDIA V100卡（如果你敢的话，你可以在一个实例上连接八个）。
- en: If you’re going to use AWS, my recommendation for this book is to go with the
    `p2.xlarge` class. This will cost you just 90 cents an hour at the time of this
    writing and provides plenty of power for working through the examples. You may
    want to bump up to the P3 classes when you start working on some meaty Kaggle
    competitions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你要使用AWS，我建议选择`p2.xlarge`类。在撰写本书时，这将花费你每小时仅90美分，并为你提供足够的计算能力来完成示例。当你开始参加一些有挑战性的Kaggle比赛时，你可能会想升级到P3类。
- en: 'Creating a running deep learning box on AWS is incredibly easy:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上创建并运行深度学习框非常容易：
- en: Sign into the AWS console.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到AWS控制台。
- en: Select EC2 and click Launch Instance.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择EC2并点击启动实例。
- en: Search for the Deep Learning AMI (Ubuntu) option and select it.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索深度学习AMI（Ubuntu）选项并选择它。
- en: Choose `p2.xlarge` as your instance type.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`p2.xlarge`作为你的实例类型。
- en: Launch the instance, either by creating a new key pair or reusing an existing
    key pair.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动实例，可以创建新的密钥对或重用现有的密钥对。
- en: 'Connect to the instance by using SSH and redirecting port 8888 on your local
    machine to the instance:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用SSH连接并将本地机器上的端口8888重定向到实例来连接到实例：
- en: '[PRE0]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Start Jupyter Notebook by entering `**jupyter notebook**`. Copy the URL that
    gets generated and paste it into your browser to access Jupyter.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入`**jupyter notebook**`来启动Jupyter Notebook。复制生成的URL并粘贴到浏览器中以访问Jupyter。
- en: Remember to shut down your instance when you’re not using it! You can do this
    by right-clicking the instance in the web interface and selecting the Shutdown
    option. This will shut down the instance, and you won’t be charged for the instance
    while it’s not running. However, you *will* be charged for the storage space that
    you have allocated for it even if the instance is turned off, so be aware of that.
    To delete the instance and storage entirely, select the Terminate option instead.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 记得在不使用时关闭你的实例！你可以通过在Web界面中右键单击实例并选择关闭选项来实现这一点。这将关闭实例，并在实例不运行时不会向你收费。然而，即使实例关闭，你仍会被收取为其分配的存储空间费用，所以请注意。要完全删除实例和存储，请选择终止选项。
- en: Azure
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure
- en: Like AWS, Azure offers a mixture of cheaper K80-based instances and more expensive
    Tesla V100 instances. Azure also offers instances based on the older P100 hardware
    as a halfway point between the other two. Again, I recommend the instance type
    that uses a single K80 (NC6) for this book, which also costs 90 cents per hour,
    and move onto other NC, NCv2 (P100), or NCv3 (V100) types as you need them.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与AWS一样，Azure提供了一些更便宜的基于K80的实例和更昂贵的Tesla V100实例。Azure还提供基于较旧的P100硬件的实例，作为其他两种之间的中间点。同样，我建议本书使用单个K80（NC6）的实例类型，这也每小时花费90美分，并根据需要转移到其他NC、NCv2（P100）或NCv3（V100）类型。
- en: 'Here’s how you set up the VM in Azure:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在Azure中设置VM：
- en: Log in to the Azure portal and find the Data Science Virtual Machine image in
    the Azure Marketplace.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到Azure门户，并在Azure Marketplace中找到Data Science Virtual Machine镜像。
- en: Click the Get It Now button.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击立即获取按钮。
- en: Fill in the details of the VM (give it a name, choose SSD disk over HDD, an
    SSH username/password, the subscription you’ll be billing the instance to, and
    set the location to be the nearest to you that offers the NC instance type).
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写VM的详细信息（为其命名，选择SSD磁盘而不是HDD，一个SSH用户名/密码，将实例计费到的订阅，以及将位置设置为最接近你的提供NC实例类型的地点）。
- en: Click the Create option. The instance should be provisioned in about five minutes.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建选项。实例应该在大约五分钟内被配置。
- en: You can use SSH with the username/password that you specified to that instance’s
    public Domain Name System (DNS) name.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用指定给该实例的公共域名系统（DNS）名称的用户名/密码来使用SSH。
- en: Jupyter Notebook should run when the instance is provisioned; navigate to *http://`dns
    name of instance`:8000* and use the username/password combination that you used
    for SSH to log in.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当实例被配置时，Jupyter Notebook应该运行；导航至*http://`实例的DNS名称`:8000*并使用你用于SSH登录的用户名/密码组合登录。
- en: Google Cloud Platform
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谷歌云平台
- en: In addition to offering K80, P100, and V100-backed instances like Amazon and
    Azure, Google Cloud Platform (GCP) offers the aforementioned TPUs for those who
    have tremendous data and compute requirements. You don’t need TPUs for this book,
    and they are pricey, but they *will* work with PyTorch 1.0, so don’t think that
    you have to use TensorFlow in order to take advantage of them if you have a project
    that requires their use.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了像亚马逊和Azure一样提供K80、P100和V100支持的实例外，Google Cloud Platform（GCP）还为那些具有巨大数据和计算需求的人提供了上述的TPUs。您不需要本书中的TPUs，它们价格昂贵，但它们*将*与PyTorch
    1.0一起使用，因此不要认为您必须使用TensorFlow才能利用它们，如果您有一个需要使用它们的项目。
- en: 'Getting started with Google Cloud is also pretty easy:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用Google Cloud也非常简单：
- en: Search for Deep Learning VM on the GCP Marketplace.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GCP Marketplace上搜索Deep Learning VM。
- en: Click Launch on Compute Engine.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Compute Engine上点击启动。
- en: Give the instance a name and assign it to the region closest to you.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为实例命名并将其分配给您最近的区域。
- en: Set the machine type to 8 vCPUs.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将机器类型设置为8个vCPU。
- en: Set GPU to 1 K80.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将GPU设置为1 K80。
- en: Ensure that PyTorch 1.0 is selected in the Framework section.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在框架部分中选择PyTorch 1.0。
- en: Select the “Install NVIDIA GPU automatically on first startup?” checkbox.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“第一次启动时自动安装NVIDIA GPU？”复选框。
- en: Set Boot disk to SSD Persistent Disk.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将启动磁盘设置为SSD持久磁盘。
- en: Click the Deploy option. The VM will take about 5 minutes to fully deploy.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击部署选项。虚拟机将需要大约5分钟才能完全部署。
- en: 'To connect to Jupyter on the instance, make sure you’re logged into the correct
    project in `gcloud` and issue this command:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要连接到实例上的Jupyter，请确保您已登录到`gcloud`中的正确项目，并发出以下命令：
- en: '[PRE1]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The charges for Google Cloud should work out to about 70 cents an hour, making
    it the cheapest of the three major cloud providers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud的费用大约为每小时70美分，是三家主要云服务提供商中最便宜的。
- en: Which Cloud Provider Should I Use?
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应该使用哪个云服务提供商？
- en: If you have nothing pulling you in any direction, I recommend Google Cloud Platform
    (GCP); it’s the cheapest option, and you can scale all the way up to using TPUs
    if required, with a lot more flexibility than either the AWS or Azure offerings.
    But if you have resources on one of the other two platforms already, you’ll be
    absolutely fine running in those environments.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有任何事情吸引您，我建议使用Google Cloud Platform（GCP）；这是最便宜的选择，如果需要，您可以扩展到使用TPUs，比AWS或Azure提供的灵活性更大。但如果您已经在另外两个平台中的一个上拥有资源，那么在这些环境中运行将完全没问题。
- en: Once you have your cloud instance running, you’ll be able to log in to its copy
    of Jupyter Notebook, so let’s take a look at that next.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的云实例运行起来，您将能够登录到其Jupyter Notebook的副本，所以下面让我们来看看。
- en: Using Jupyter Notebook
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Jupyter Notebook
- en: 'If you haven’t come across it before, here’s the lowdown on Jupyter Notebook:
    this browser-based environment allows you to mix live code with text, images,
    and visualizations and has become one of the de facto tools of data scientists
    all over the world. Notebooks created in Jupyter can be easily shared; indeed,
    you’ll find [all the notebooks in this book](https://oreil.ly/iBh4V). You can
    see a screenshot of Jupyter Notebook in action in [Figure 1-2](#jupyter-notebook-image).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您以前没有接触过它，这里是关于Jupyter Notebook的简介：这个基于浏览器的环境允许您将实时代码与文本、图像和可视化混合在一起，已经成为全球数据科学家的事实标准工具之一。在Jupyter中创建的笔记本可以轻松共享；实际上，您会在[本书中的所有笔记本](https://oreil.ly/iBh4V)中找到。您可以在[图1-2](#jupyter-notebook-image)中看到Jupyter
    Notebook的截图。
- en: We won’t be using any advanced features of Jupyter in this book; all you need
    to know is how to create a new notebook and that Shift-Enter runs the contents
    of a cell. But if you’ve never used it before, I suggest browsing the [Jupyter
    documentation](https://oreil.ly/-Yhff) before you get to [Chapter 2](ch02.html#image-classification-with-pytorch).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们不会使用Jupyter的任何高级功能；您只需要知道如何创建一个新的笔记本，以及Shift-Enter如何运行单元格的内容。但如果您以前从未使用过它，我建议在进入[第2章](ch02.html#image-classification-with-pytorch)之前浏览[Jupyter文档](https://oreil.ly/-Yhff)。
- en: '![Jupyter Notebook](assets/ppdl_0102.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Jupyter Notebook](assets/ppdl_0102.png)'
- en: Figure 1-2\. Jupyter Notebook
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2. Jupyter Notebook
- en: 'Before we get into using PyTorch, we’ll cover one last thing: how to install
    everything manually.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用PyTorch之前，我们将讨论最后一件事：如何手动安装所有内容。
- en: Installing PyTorch from Scratch
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始安装PyTorch
- en: Perhaps you want a little more control over your software than using one of
    the preceding cloud-provided images. Or you need a particular version of PyTorch
    for your code. Or, despite all my cautionary warnings, you really want that rig
    in your basement. Let’s look at how to install PyTorch on a Linux server in general.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 也许您想对软件有更多控制，而不是使用之前提供的云镜像之一。或者您需要特定版本的PyTorch来运行您的代码。或者，尽管我发出了所有警告，您真的想要在地下室中安装那台设备。让我们看看如何在Linux服务器上通用安装PyTorch。
- en: Warning
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: You can use PyTorch with Python 2.*x*, but I strongly recommend against doing
    so. While the Python 2.*x* to 3.*x* upgrade saga has been running for over a decade
    now, more and more packages are beginning to drop Python 2.*x* support. So unless
    you have a good reason, make sure your system is running Python 3.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Python 2.*x*与PyTorch一起使用，但我强烈建议不要这样做。尽管Python 2.*x*到3.*x*的升级已经进行了十多年，但越来越多的软件包开始放弃对Python
    2.*x*的支持。因此，除非有充分理由，确保您的系统正在运行Python 3。
- en: Download CUDA
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载CUDA
- en: Although PyTorch can be run entirely in CPU mode, in most cases, GPU-powered
    PyTorch is required for practical usage, so we’re going to need GPU support. This
    is fairly straightforward; assuming you have an NVIDIA card, this is provided
    by their Compute Unified Device Architecture (CUDA) API. [Download the appropriate
    package format](https://oreil.ly/Gx_q2) for your flavor of Linux and install the
    package.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管PyTorch可以完全在CPU模式下运行，但在大多数情况下，需要GPU支持的PyTorch才能实现实际用途，因此我们需要GPU支持。这相当简单；假设您有一张NVIDIA卡，这是由他们的Compute
    Unified Device Architecture（CUDA）API提供的。[下载适合您Linux版本的适当软件包格式](https://oreil.ly/Gx_q2)并安装软件包。
- en: 'For Red Hat Enterprise Linux (RHEL) 7:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Red Hat Enterprise Linux（RHEL）7：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For Ubuntu 18.04:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Ubuntu 18.04：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Anaconda
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Anaconda
- en: Python has a variety of packaging systems, all of which have good and not-so-good
    points. Like the developers of PyTorch, I recommend that you install Anaconda,
    a packaging system dedicated to producing the best distribution of packages for
    data scientists. Like CUDA, it’s fairly easy to install.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Python有各种打包系统，所有这些系统都有好坏之分。与PyTorch的开发人员一样，我建议您安装Anaconda，这是一个专门为数据科学家提供最佳软件包分发的打包系统。与CUDA一样，它相当容易安装。
- en: Head to [Anaconda](https://oreil.ly/9hAxg) and pick out the installation file
    for your machine. Because it’s a massive archive that executes via a shell script
    on your system, I encourage you to run `md5sum` on the file you’ve downloaded
    and check it against [the list of signatures](https://oreil.ly/anuhu) before you
    execute it with `bash Anaconda3-VERSION-Linux-x86_64.sh` to make sure that the
    signature on your machine matches the one on the web page. This ensures that the
    downloaded file hasn’t been tampered with and means it’s safe to run on your system.
    The script will present several prompts about locations it’ll be installing into;
    unless there’s a good reason, just accept the defaults.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 前往[Anaconda](https://oreil.ly/9hAxg)并选择适合您机器的安装文件。因为这是一个通过shell脚本在您的系统上执行的大型存档，我建议您在下载的文件上运行`md5sum`并将其与[签名列表](https://oreil.ly/anuhu)进行比对，然后再使用`bash
    Anaconda3-VERSION-Linux-x86_64.sh`执行以确保您机器上的签名与网页上的签名匹配。这可以确保下载的文件没有被篡改，并且可以安全地在您的系统上运行。脚本将提供有关将要安装的位置的几个提示；除非有充分的理由，否则请接受默认设置。
- en: Note
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You might be wondering, “Can I do this on my MacBook?” Sadly, most Macs come
    with either Intel or AMD GPUs these days and don’t really have the support for
    running PyTorch in GPU-accelerated mode. I recommend using Colab or a cloud provider
    rather than attempting to use your Mac locally.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想：“我能在我的MacBook上做这个吗？”遗憾的是，如今大多数Mac都配备有Intel或AMD GPU，实际上不支持在GPU加速模式下运行PyTorch。我建议您使用Colab或云服务提供商，而不是尝试在本地使用Mac。
- en: Finally, PyTorch! (and Jupyter Notebook)
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后，PyTorch！（和Jupyter Notebook）
- en: 'Now that you have Anaconda installed, getting set up with PyTorch is simple:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经安装了Anaconda，使用PyTorch很简单：
- en: '[PRE4]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This installs PyTorch and the `torchvision` library that we use in the next
    couple of chapters to create deep learning architectures that work with images.
    Anaconda has also installed Jupyter Notebook for us, so we can begin by starting
    it:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装PyTorch和我们在接下来的几章中使用的`torchvision`库，用于创建与图像一起工作的深度学习架构。Anaconda还为我们安装了Jupyter
    Notebook，因此我们可以通过启动它来开始：
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Head to *http://`YOUR-IP-ADDRESS`:8888* in your browser, create a new notebook,
    and enter the following:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中前往*http://`YOUR-IP-ADDRESS`:8888*，创建一个新的笔记本，并输入以下内容：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This should produce output similar to this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生类似于这样的输出：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If `cuda.is_available()` returns `False`, you need to debug your CUDA installation
    so PyTorch can see your graphics card. The values of the tensor will be different
    on your instance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`cuda.is_available()`返回`False`，则需要调试您的CUDA安装，以便PyTorch可以看到您的显卡。在您的实例上，张量的值将不同。
- en: But what is this tensor? Tensors are at the heart of almost everything in PyTorch,
    so you need to know what they are and what they can do for you.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个张量是什么？张量几乎是PyTorch中的一切，因此您需要知道它们是什么以及它们可以为您做什么。
- en: Tensors
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量
- en: 'A *tensor* is both a container for numbers as well as a set of rules that define
    transformations between tensors that produce new tensors. It’s probably easiest
    for us to think about *tensors* as multidimensional arrays. Every tensor has a
    *rank* that corresponds to its dimensional space. A simple scalar (e.g., 1) can
    be represented as a tensor of rank 0, a vector is rank 1, an *n* × *n* matrix
    is rank 2, and so on. In the previous example, we created a rank 2 tensor with
    random values by using `torch.rand()`. We can also create them from lists:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*张量*既是数字的容器，也是定义在产生新张量之间的张量之间的转换规则的集合。对于我们来说，将*张量*视为多维数组可能是最容易的。每个张量都有一个与其维度空间对应的*秩*。一个简单的标量（例如，1）可以表示为秩为0的张量，一个向量是秩为1的，一个*n*×*n*矩阵是秩为2的，依此类推。在前面的示例中，我们使用`torch.rand()`创建了一个具有随机值的秩为2的张量。我们也可以从列表中创建它们：'
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can change an element in a tensor by using standard Python indexing:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用标准的Python索引在张量中更改元素：
- en: '[PRE9]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can use special creation functions to generate particular types of tensors.
    In particular, `ones()` and `zeroes()` will generate tensors filled with 1s and
    0s, respectively:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用特殊的创建函数生成特定类型的张量。特别是，`ones()`和`zeroes()`将分别生成填充有1和0的张量：
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can perform standard mathematical operations with tensors (e.g., adding
    two tensors together):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用张量执行标准的数学运算（例如，将两个张量相加）：
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'And if you have a tensor of rank 0, you can pull out the value with `item()`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有一个秩为0的张量，可以使用`item()`提取值：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Tensors can live in the CPU or on the GPU and can be copied between devices
    by using the `to()` function:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 张量可以存在于CPU或GPU上，并且可以通过使用`to()`函数在设备之间进行复制：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Tensor Operations
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量操作
- en: If you look at the [PyTorch documentation](https://oreil.ly/1Ev0-), you’ll see
    that there are a *lot* of functions that you can apply to tensors—everything from
    finding the maximum element to applying a Fourier transform. In this book, you
    don’t need to know all of those in order to turn images, text, and audio into
    tensors and manipulate them to perform our operations, but you will need some.
    I definitely recommend that you give the documentation a glance, especially after
    finishing this book. Now we’re going to go through all the functions that will
    be used in upcoming chapters.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看[PyTorch文档](https://oreil.ly/1Ev0-)，您会发现有很多函数可以应用于张量——从查找最大元素到应用傅立叶变换等。在本书中，您不需要了解所有这些函数来将图像、文本和音频转换为张量并对其进行操作，但您需要了解一些。我强烈建议您在完成本书后浏览文档。现在我们将逐一介绍将在接下来的章节中使用的所有函数。
- en: First, we often need to find the maximum item in a tensor as well as the *index*
    that contains the maximum value (as this often corresponds to the class that the
    neural network has decided upon in its final prediction). These can be done with
    the `max()` and `argmax()` functions. We can also use `item()` to extract a standard
    Python value from a 1D tensor.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们经常需要找到张量中的最大项以及包含最大值的*索引*（因为这通常对应于神经网络在最终预测中决定的类）。这可以通过`max()`和`argmax()`函数来实现。我们还可以使用`item()`从1D张量中提取标准的Python值。
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Sometimes, we’d like to change the type of a tensor; for example, from a `LongTensor`
    to a `FloatTensor`. We can do this with `to()`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能想要改变张量的类型；例如，从`LongTensor`到`FloatTensor`。我们可以使用`to()`来实现：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Most functions that operate on a tensor and return a tensor create a new tensor
    to store the result. However, if you want to save memory, look to see if an *in-place*
    function is defined, which should be the same name as the original function but
    with an appended underscore (`_`).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数在张量上操作并返回张量的函数会创建一个新的张量来存储结果。然而，如果你想节省内存，可以查看是否定义了一个*原地*函数，它的名称应该与原始函数相同，但在末尾加上下划线(`_`)。
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Another common operation is *reshaping* a tensor. This can often occur because
    your neural network layer may require a slightly different input shape than what
    you currently have to feed into it. For example, the Modified National Institute
    of Standards and Technology (MNIST) dataset of handwritten digits is a collection
    of 28 × 28 images, but the way it’s packaged is in arrays of length 784\. To use
    the networks we are constructing, we need to turn those back into 1 × 28 × 28
    tensors (the leading 1 is the number of channels—normally red, green, and blue—but
    as MNIST digits are just grayscale, we have only one channel). We can do this
    with either `view()` or `reshape()`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的操作是*重塑*张量。这通常是因为你的神经网络层可能需要一个与你当前要输入的形状略有不同的输入形状。例如，手写数字的Modified National
    Institute of Standards and Technology (MNIST)数据集是一组28×28的图像，但它的打包方式是长度为784的数组。为了使用我们正在构建的网络，我们需要将它们转换回1×28×28的张量（前导的1是通道数——通常是红、绿和蓝，但由于MNIST数字只是灰度的，我们只有一个通道）。我们可以使用`view()`或`reshape()`来实现：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Note that the reshaped tensor’s shape has to have the same number of total
    elements as the original. If you try `flat_tensor.reshape(3,28,28)`, you’ll see
    an error like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，重塑后的张量形状必须与原始张量的总元素数相同。如果你尝试`flat_tensor.reshape(3,28,28)`，你会看到这样的错误：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now you might wonder what the difference is between `view()` and `reshape()`.
    The answer is that `view()` operates as a view on the original tensor, so if the
    underlying data is changed, the view will change too (and vice versa). However,
    `view()` can throw errors if the required view is not *contiguous*; that is, it
    doesn’t share the same block of memory it would occupy if a new tensor of the
    required shape was created from scratch. If this happens, you have to call `tensor.contiguous()`
    before you can use `view()`. However, `reshape()` does all that behind the scenes,
    so in general, I recommend using `reshape()` rather than `view()`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能想知道`view()`和`reshape()`之间的区别是什么。答案是`view()`作为原始张量的视图操作，所以如果底层数据发生变化，视图也会发生变化（反之亦然）。然而，如果所需的视图不是*连续*的，`view()`可能会抛出错误；也就是说，如果它不与从头开始创建的具有所需形状的新张量共享相同的内存块。如果发生这种情况，你必须在使用`view()`之前调用`tensor.contiguous()`。然而，`reshape()`在幕后完成所有这些工作，所以一般来说，我建议使用`reshape()`而不是`view()`。
- en: 'Finally, you might need to rearrange the dimensions of a tensor. You will likely
    come across this with images, which often are stored as `[height, width, channel]`
    tensors, but PyTorch prefers to deal with these in a `[channel, height, width]`.
    You can user `permute()` to deal with these in a fairly straightforward manner:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能需要重新排列张量的维度。你可能会在处理图像时遇到这种情况，图像通常以`[height, width, channel]`的张量形式存储，但PyTorch更喜欢以`[channel,
    height, width]`的形式处理。你可以使用`permute()`来以一种相当简单的方式处理这些：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, we’ve just applied `permute` to a `[640,480,3]` tensor, with the arguments
    being the indexes of the tensor’s dimensions, so we want the final dimension (2,
    due to zero indexing) to be at the front of our tensor, followed by the remaining
    two dimensions in their original order.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们刚刚对一个`[640,480,3]`的张量应用了`permute`，参数是张量维度的索引，所以我们希望最终维度（由于从零开始索引，是2）在张量的前面，后面是剩下的两个维度按照原始顺序。
- en: Tensor Broadcasting
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量广播
- en: 'Borrowed from NumPy, *broadcasting* allows you to perform operations between
    a tensor and a smaller tensor. You can broadcast across two tensors if, starting
    backward from their trailing dimensions:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从NumPy借鉴的*广播*允许你在张量和较小张量之间执行操作。如果从它们的尾部维度开始向后看，你可以在两个张量之间进行广播：
- en: The two dimensions are equal.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个维度相等。
- en: One of the dimensions is 1.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个维度是1。
- en: 'In our use of broadcasting, it works because 1 has a dimension of 1, and as
    there are no other dimensions, the 1 can be expanded to cover the other tensor.
    If we tried to add a `[2,2]` tensor to a `[3,3]` tensor, we’d get this error message:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用广播时，它有效是因为1有一个维度是1，而且没有其他维度，1可以扩展到另一个张量。如果我们尝试将一个`[2,2]`张量加到一个`[3,3]`张量上，我们会得到这样的错误消息：
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: But we could add a `[1,3]` tensor to the `[3,3]` tensor without any trouble.
    Broadcasting is a handy little feature that increases brevity of code, and is
    often faster than manually expanding the tensor yourself.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们可以毫无问题地将一个`[1,3]`张量加到一个`[3,3]`张量上。广播是一个方便的小功能，可以增加代码的简洁性，并且通常比手动扩展张量更快。
- en: That wraps up everything concerning tensors that you need to get started! We’ll
    cover a few other operations as we come across them later in the book, but this
    is enough for you to dive into [Chapter 2](ch02.html#image-classification-with-pytorch).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 关于张量的一切你需要开始的内容就到这里了！我们将在书中后面遇到其他一些操作，但这已经足够让你深入[第二章](ch02.html#image-classification-with-pytorch)了。
- en: Conclusion
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Whether it’s in the cloud or on your local machine, you should now have PyTorch
    installed. I’ve introduced the fundamental building block of the library, *the
    tensor*, and you’ve had a brief look at Jupyter Notebook. This is all you need
    to get started! In the next chapter, you use everything you’ve seen so far to
    start building neural networks and classifying images, so make you sure you’re
    comfortable with tensors and Jupyter before moving on.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在云端还是在本地机器上，您现在应该已经安装了PyTorch。我已经介绍了该库的基本构建模块，*张量*，您已经简要了解了Jupyter Notebook。这就是您开始的全部所需！在下一章中，您将利用到目前为止所见的一切来开始构建神经网络和对图像进行分类，所以在继续之前，请确保您对张量和Jupyter感到舒适。
- en: Further Reading
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[Project Jupyter documentation](https://jupyter.org/documentation)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Project Jupyter文档](https://jupyter.org/documentation)'
- en: '[PyTorch documentation](https://pytorch.org/docs/stable)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch文档](https://pytorch.org/docs/stable)'
- en: '[AWS Deep Learning AMIs](https://oreil.ly/G9Ldx)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS深度学习AMI](https://oreil.ly/G9Ldx)'
- en: '[Azure Data Science Virtual Machines](https://oreil.ly/YjzVB)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Azure数据科学虚拟机](https://oreil.ly/YjzVB)'
- en: '[Google Deep Learning VM Image](https://oreil.ly/NFpeG)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google深度学习虚拟机镜像](https://oreil.ly/NFpeG)'
