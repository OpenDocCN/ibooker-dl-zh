- en: '4 Creating with Generative AI: Media Resources'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 使用生成AI创作：媒体资源
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖内容
- en: Generating digital images and video
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成数字图像和视频
- en: Generating AI-assisted video editing and text-to-video
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成AI辅助视频编辑和文本转视频
- en: Generating presentation resources
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成演示资源
- en: Generating audio-to-text and text-to-audio
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成音频到文本和文本到音频
- en: Text and programming code are natural targets for generative AI. After all,
    after binary, those are the languages with which your computer has the most experience.
    So, intuitively, the ability to generate the kinds of resources we discussed in
    the previous chapter was expected.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 文本和编程代码是生成AI的自然目标。毕竟，除了二进制之外，这些是您的计算机具有最丰富经验的语言。因此，直觉上，预计能够生成我们在上一章中讨论的资源类型。
- en: 'But images, audio, and video would be a very different story. That’s because
    visual and audio data:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但图像、音频和视频就会有很不同的情况。这是因为视觉和音频数据：
- en: Are inherently more complex and high-dimensional than text
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比文本本身更加复杂和高维
- en: Lack symbolic representations and have more nuanced meaning making it challenging
    to directly apply traditional programming techniques
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏符号表示，具有更加微妙的意义，这使得直接应用传统编程技术变得困难
- en: Can be highly subjective and ambiguous making it difficult to build automated
    systems that can consistently and accurately interpret such data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能高度主观和模糊，这使得构建能够一致且准确地解释此类数据的自动化系统变得困难
- en: Lack inherent context making it harder for computer systems to confidently derive
    meaning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏固有的上下文，这使得计算机系统更难以自信地推断意义
- en: Require significant computational resources for processing
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要大量的计算资源来处理
- en: Nevertheless, tools for generating media resources have been primary drivers
    of the recent explosion of interest in AI. So the rest of this chapter will be
    dedicated to exploring the practical use of AI-driven digital media creation services.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，用于生成媒体资源的工具一直是近期对AI兴趣爆发的主要推动力。因此，本章的其余部分将致力于探索AI驱动的数字媒体创作服务的实际应用。
- en: 4.1 Generating images
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 生成图像
- en: First off, just how does a large language model (LLM) convert a text prompt
    into a visual artifact? The figure below illustrates the keys steps making up
    the training process that makes this happen.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，一个大型语言模型（LLM）如何将文本提示转换为视觉工件？下图说明了构成使这一过程发生的训练过程的关键步骤。
- en: Figure 4.1 The training process for building a media-generation LLM
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.1 媒体生成LLM的训练过程
- en: '![gai 4 1](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-1.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 1](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-1.png)'
- en: 'Here are the steps of that process in more detail:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是该过程的详细步骤：
- en: Gathering a huge collection of audio, images, and videos to learn from. These
    examples come from all over the internet and cover a wide range of styles and
    topics.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集大量的音频、图像和视频以供学习。这些例子来自互联网各个地方，涵盖了各种风格和主题。
- en: Using the examples to learn patterns. For audio, it learns the different sounds
    and how they relate to each other (like how a melody follows a certain rhythm).
    For images, it learns what different objects look like and how they appear together.
    For videos, it figures out how different shots are put together to tell a story.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用例子来学习模式。对于音频，它学习了不同的声音以及它们之间的关系（比如一个旋律遵循特定的节奏）。对于图像，它学习了不同对象的外观以及它们如何一起出现。对于视频，它找出了不同的镜头是如何组合在一起讲述一个故事的。
- en: Applying mathematical magic to convert the audio, images, and videos into representative
    numbers. These numbers help the system understand the patterns and relationships
    in the content. It’s like the system is translating the art into a language it
    can understand.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用数学魔法将音频、图像和视频转换为代表性数字。这些数字帮助系统理解内容中的模式和关系。这就像系统将艺术转换为它可以理解的语言。
- en: Training the model involves having the LLM search for the best patterns that
    can recreate the audio, images, and videos it’s seen.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型涉及LLM搜索可以重建已见过的音频、图像和视频的最佳模式。
- en: When the LLM creates something, we apply feedback and adjustments by comparing
    it to real examples. The model adjusts its patterns to get better at creating
    content that’s closer to what we want.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当LLM创建某物时，我们通过将其与真实例子进行比较来应用反馈和调整。模型调整其模式以使其更擅长创建更接近我们想要的内容。
- en: The LLM practices (a lot) by creating new audio, images, and videos. With each
    practice round, it gets better and better at understanding the patterns and making
    its own content.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM通过创建新的音频、图像和视频进行（大量）练习。随着每一轮练习，它在理解模式并制作自己的内容方面变得越来越好。
- en: It’s important to note that AI-generated images and videos are nothing more
    than dumb computers' best efforts based on learned patterns from the training
    data and may not always reflect real-world accuracy - which should be obvious
    for those of us who have seen AI-generated humans with 6-10 fingers per hand or
    three arms. For context, "two" is traditionally the maximum number of arms attached
    to any one human. And, no, I have no clue why LLMs get this obvious thing so wrong,
    so often.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，由AI生成的图像和视频只是基于训练数据学到的模式的愚蠢计算机的最佳努力，可能并不总是反映现实世界的准确性 - 对于那些见过AI生成的每只手有6-10根手指或三只手臂的人来说，这一点应该是显而易见的。对于任何一个人来说，“两只”传统上是附在任何一个人身上的手的最大数量。而且，不，我不知道为什么LLM经常在这个显而易见的事情上弄错。
- en: 4.1.1 Providing detailed prompts
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1 提供详细提示
- en: 'Whichever image generation service you use, the way you build your prompts
    will go a long way to determining the quality of the images that come out the
    other end. You’ll want to be descriptive while also defining the style of the
    image you want. Therefore, something like:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用哪种图像生成服务，你构建提示的方式将在很大程度上决定最终输出的图像的质量。你需要描述性地定义你想要的图像风格。因此，类似这样的东西：
- en: '*Some trees*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*一些树木*'
- en: '…​won’t be nearly as effective as:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: …​不如：
- en: '*A sunlit wooded area in the style of John Constable*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*一片阳光明媚的树木区，风格类似约翰·康斯特布尔*'
- en: That example contains a *subject* ("wooded area"), *adjective* ("sunlit") and
    an *artistic style* ("John Constable"). You should try to include at least one
    of each of those three elements in your prompts. Feel free to add details like
    colors and background textures.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那个例子包含了一个*主题*（“树木区”），*形容词*（“阳光明媚”）和一个*艺术风格*（“约翰·康斯特布尔”）。你应该尽量在你的提示中包含这三个元素中的至少一个。可以随意添加颜色和背景纹理等细节。
- en: 'In case you’re curious, here’s what the Stable Diffusion model gave me in response
    to that last prompt:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，这是稳定扩散模型对最后一个提示的响应：
- en: Figure 4.2 A Stable Diffusion image in the style of English Romantic painter,
    John Constable
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.2 以英国浪漫主义画家约翰·康斯特布尔的风格绘制的稳定扩散图像
- en: '![gai 4 2](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-2.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 2](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-2.png)'
- en: 'When it comes to styles, consider adding something from this (partial) list:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到风格时，请考虑从这个（部分）列表中添加一些内容：
- en: Photograph
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄影
- en: Cubist
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 立体派的
- en: Oil painting
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 油画
- en: Matte
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哑光的
- en: Surreal
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超现实主义的
- en: Steampunk
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒸汽朋克
- en: Cute creatures
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可爱的生物
- en: Fantasy worlds
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幻想世界
- en: Cyberpunk
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 赛博朋克
- en: Old
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 古老的
- en: Renaissance painting
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文艺复兴时期的绘画
- en: Abstract
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象的
- en: Realistic
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实的
- en: Expressionism
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表现主义
- en: Comic
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漫画
- en: Ink
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 墨水
- en: 4.1.2 Prompting for images
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2 提示生成图像
- en: Nonetheless, I decided to ignore all that advice about styles and details and
    ask a few AI image creation platforms for possible covers to adorn this book.
    My prompt, as you can see, didn’t provide any specific descriptions. Instead,
    I gave it nothing more than an abstraction (the book title) and assumed the GAI
    will be able to translate the concept hinted to into something graphic.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我决定忽略所有关于风格和细节的建议，并向几个AI图像创作平台询问可能用于装饰这本书的封面。正如你所看到的，我的提示没有提供任何具体的描述。相反，我仅仅给了它一个抽象的概念（书名），并假设GAI将能够将其暗示的概念转化为图形。
- en: Prompt engineering
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提示工程
- en: '*Create a 6:9 cover for a book entitled "The Complete Obsolete Guide to Generative
    Artificial Intelligence" The image should contain no text or alphanumeric characters.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*为一本名为《完全过时的生成式人工智能指南》的书创建一个6:9的封面。图像不应包含任何文本或字母数字字符。*'
- en: It is useful to note how I specified the aspect ratio ("6:9") to tell the software
    what shape the image should take. I also told it not to include any text. AI is
    notoriously *awful* at text.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我如何指定了纵横比（“6:9”）来告诉软件图像应该采取的形状。我还告诉它不要包含任何文本。AI在处理文本方面是臭名昭著的*糟糕*。
- en: In case anyone in the Manning art department is reading, here are a couple of
    the images I got back. This first one came from Dream Studio and looks great,
    although they did seem to miss the memo on aspect ratio.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果曼宁艺术部门的任何人正在阅读，请看一下我收到的一些图像之一。第一个来自梦想工作室，看起来很棒，尽管他们似乎忽略了纵横比的备忘录。
- en: Figure 4.3 A Dream Studio "book cover" image
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.3 一个梦想工作室的“书籍封面”图像
- en: '![gai 4 3](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-3.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 3](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-3.png)'
- en: This image from the Stable Diffusion model hits a lot of the right marks and,
    considering how little I gave it to work with, is pretty impressive.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这张来自 Stable Diffusion 模型的图片符合很多正确的标志，并且考虑到我给它的内容很少，相当令人印象深刻。
- en: Figure 4.4 A Stable Diffusion "book cover" image
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.4 Stable Diffusion 的 "书封" 图像
- en: '![gai 4 4](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-4.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 4](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-4.png)'
- en: 'I find more image generation services every time I look online. But, right
    now, these are particularly big players:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我在网上搜索时都会发现更多的图像生成服务。但是，目前这些是特别重要的参与者：
- en: '**Midjourney** is a bit tricky to get started, but seems to produce a very
    high quality of images. You’ll need to create an account at [midjourney.com](www.midjourney.com.html),
    select a yearly or monthly fee account level, and then add a Midjourney server
    to your Discord account. From Discord, you can select the "Midjourney Bot" that
    should appear within the Direct Messages column in Discord. To get your first
    set of images, enter your prompt after typing `/imagine` in the text field at
    the bottom. Four possible images, once they’re generated, will appear in your
    Midjourney UI. I can’t say I understand why it’s designed that way, but a lot
    of people seem to feel it’s worth the effort.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**Midjourney** 起步有点棘手，但似乎能生成非常高质量的图像。您需要在[midjourney.com](www.midjourney.com.html)创建一个帐户，选择年度或月度费用帐户级别，然后将
    Midjourney 服务器添加到您的 Discord 帐户中。从 Discord 中，您可以在直接消息栏中选择应该出现的 "Midjourney Bot"。要获取您的第一组图像，请在底部的文本字段中键入
    `/imagine` 后输入您的提示。一旦生成，四个可能的图像将显示在您的 Midjourney UI 中。我不能说我理解为什么设计成这样，但很多人似乎觉得值得一试。'
- en: Figure 4.5 Midjourney being accessed within a Discord account
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.5 在 Discord 帐户中访问 Midjourney
- en: '![gai 4 5](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-5.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 5](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-5.png)'
- en: '**DALL-E** - a product of OpenAI - was the first digital image generating tool
    most of us encountered. In its time it was shocking, and brought a lot of attention
    to the underlying technologies and related possibilities. But, perhaps by design,
    it’s never produced images with the same range and photo realism as other competing
    services.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**DALL-E** - 由 OpenAI 提供 - 是大多数人遇到的第一个数字图像生成工具。在它的时代，它令人震惊，并引起了对相关技术和相关可能性的关注。但或许出于设计考虑，它从未像其他竞争服务一样产生过同样范围和照片般逼真的图像。'
- en: Figure 4.6 OpenAI’s DALL-E browser-based interface
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.6 OpenAI 的 DALL-E 基于浏览器的界面
- en: '![gai 4 6](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-6.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 6](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-6.png)'
- en: '**Stable Diffusion** is a freely-available generative model that can be accessed
    through an account with services like [Hugging Face](huggingface.co.html) - a
    hosting service for many AI models, datasets and other AI tools using both free
    and pay-as-you-go levels. If you have a computer with a graphic processor unit
    (GPU) and at least 8GB of video memory, you can actually [install and run your
    own private Stable Diffusion service](stable-diffusion-ui.github.io.html).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**Stable Diffusion** 是一个可以通过像 [Hugging Face](huggingface.co.html) 这样的服务的帐户免费访问的生成模型
    - 这是一个提供许多 AI 模型、数据集和其他 AI 工具的托管服务，使用免费和按使用量付费的级别。如果您有一台带有图形处理器单元 (GPU) 并且至少有
    8GB 视频内存的计算机，您实际上可以[安装和运行自己的私有 Stable Diffusion 服务](stable-diffusion-ui.github.io.html)。'
- en: Figure 4.7 The Stable Diffusion GitHub page
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.7 Stable Diffusion GitHub 页面
- en: '![gai 4 7](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-7.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 7](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-7.png)'
- en: '**DreamStudio** offers image generation through [their website](beta.dreamstudio.ai.html).
    You’re permitted a limited number of credits for free with more available for
    purchase. Currently, usage costs $10 for every 1,000 credits. Costs per image
    depend on size and complexity. DreamStudio is provided by stability.ai - the company
    responsible for Stable Diffusion.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**DreamStudio** 通过[他们的网站](beta.dreamstudio.ai.html)提供图像生成服务。您可以免费获得有限数量的积分，更多积分可供购买。目前，使用每
    1000 积分需要花费 10 美元。每张图片的成本取决于大小和复杂度。DreamStudio 由 stability.ai 提供 - 这是 Stable Diffusion
    的负责公司。'
- en: Figure 4.8 The DreamStudio browser interface
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.8 DreamStudio 浏览器界面
- en: '![gai 4 8](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-8.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![gai 4 8](https://drek4537l1klr.cloudfront.net/clinton6/v-3/Figures/gai-4-8.png)'
- en: 4.2 Generating video
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 生成视频
- en: If GAIs can create images, couldn’t they do the same trick with video, too?
    Well of course they can. But you will have to be a bit more specific about what
    you mean by "video."
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 GAI 能够创建图像，它们也能够用同样的技巧制作视频，是吗？当然可以。但是你必须更具体地说明你所说的 "视频" 是什么意思。
- en: If what you’re looking for is the ability to write a prompt (like the ones we’ve
    been using for images) and a beautiful video suddenly springs to life, well we’re
    not quite there yet. Meta and Google have both loudly announced technologies (Make-a-Video
    for Meta and Imagen Video for Google) that’ll do just that. But bear in mind that
    both those tools will absolutely, certainly, and without a doubt be available…​on
    some unspecified date in the future.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你所期望的是写下一个提示（就像我们一直用于图像的那些）然后一个美丽的视频突然活灵活现地呈现在眼前，那么我们还没有完全达到那一步。Meta 和 Google
    都大声宣布了技术（Meta 的 Make-a-Video 和 Google 的 Imagen Video）将做到这一点。但请记住，这两种工具绝对、肯定、毫无疑问会在未来的某个不确定日期上推出。
- en: RunwayML did release a promising tool with limited access. But, considering
    the current 4-15 second maximums per output clip and the significant rendering
    times, it’s not exactly everything we’re hoping for yet.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: RunwayML 发布了一个有限访问权限的令人期待的工具。但是，考虑到目前每个输出剪辑的最大时长为4-15秒以及显著的渲染时间，它还不是我们所期望的一切。
- en: However, if you can expand your definition of "video" a little bit wider, then
    we might have something to talk about.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你能将“视频”的定义稍微扩展一下，那么我们可能有些东西可以谈论。
- en: 4.2.1 AI-assisted video editing
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 AI辅助视频编辑
- en: One process that most certainly does exist right now involves taking existing
    videos and manipulating them so they tell a very different story.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 目前绝对存在的一个过程涉及采用现有视频并操纵它们，使它们讲述一个完全不同的故事。
- en: Using stylization and masking effects, applications like [RunwayML’s Gen-1](runwayml.com.html)
    and the open source project [Text2Live](omerbt.html) can create things that high-end
    Hollywood studios have been doing for a while. The difference is that those Hollywood
    studios often spent many months and millions of dollars for the equipment and
    experts they needed. We can now get pretty much the same quality in a few seconds
    on a modestly powered laptop. In fact, you can self-host Text2Live by downloading
    it and running it on your own machine.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用样式化和遮罩效果，像 [RunwayML 的 Gen-1](runwayml.com.html) 和开源项目 [Text2Live](omerbt.html)
    可以创建类似于高端好莱坞工作室一直在做的事情。不同之处在于，那些好莱坞工作室通常需要花费数月时间和数百万美元购买他们所需要的设备和专家。我们现在可以在一台性能适中的笔记本电脑上在几秒钟内获得几乎相同的质量。事实上，你可以通过下载并在自己的机器上运行它来自托
    Text2Live。
- en: What can you actually do? I’d recommend you check out both the [Gen-1](runwayml.com.html)
    and [Text2Live](omerbt.html) sites for demo videos. They’ll show you how textures,
    backgrounds, lighting, and other attributes can be swapped in and out to convert
    an existing video of, say, a man running down a driveway, into an astronaut running
    across an alien planet’s surface.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你实际上可以做什么？我建议你查看 [Gen-1](runwayml.com.html) 和 [Text2Live](omerbt.html) 网站的演示视频。它们会向你展示纹理、背景、照明和其他属性如何被替换，以将现有视频，比如一个男人沿着车道跑的视频，转换成一个宇航员在外星球表面奔跑的视频。
- en: 4.2.2 Text to video slide shows
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 文本到视频幻灯片
- en: That’s all great fun. But some of us use video for tasks that live closer to
    the office than outer space. In other words, there’s a huge market for media content
    that’s focused on education, IT training, news services, marketing, and corporate
    communications. Putting together such presentations the traditional way can take
    hours for each minute of video (I know, because I do that for a living). And that’s
    not taking into account the extra equipment and studio costs it’ll take to put
    you directly on-camera.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 那些都非常有趣。但我们中的一些人使用视频的任务更接近办公室而不是外太空。换句话说，针对教育、IT培训、新闻服务、营销和企业通讯等媒体内容的巨大市场存在。以传统方式制作这样的演示文稿可能需要每分钟数小时的时间（我知道，因为我靠这个谋生）。这还没有考虑到为了让你直接上镜头而需要额外的设备和工作室成本。
- en: There are, however, AI-driven services that can take your script and generate
    a professional video consisting of a hyper-realistic computer-generated voice
    (using your choice of male or female, accent, age, and personality) and appropriate
    supporting background images and bullet-point text. You can upload your own images,
    too. The high-end players in this genre will add a human-like avatar who looks
    pretty close to an actual live human being.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前有一些由人工智能驱动的服务可以接受你的脚本，并生成一个由超逼真的计算机生成的声音（使用你选择的男性或女性、口音、年龄和个性）以及相应的支持背景图像和项目符号文本组成的专业视频。你也可以上传自己的图像。这一流派的高端玩家还会添加一个看起来非常接近实际真人的类人化头像。
- en: Add in a script generated using ChatGPT the way we’ve seen in previous chapters,
    and you’ll be going from zero to a complete set of professional videos in minutes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 加上使用 ChatGPT 生成的脚本，就能在几分钟内完成一整套专业视频的制作。
- en: 'What’s the catch? Ah, yes. The catch. Well the high-end stuff isn’t cheap.
    Many of the more professional services currently charge hundreds of dollars a
    year (or more) and limit output to a specified number of minutes of video each
    month. Arguably the leaders in this market include:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有何陷阱？啊，是的。陷阱。嗯，高端的东西并不便宜。目前许多更专业的服务每年收费数百美元（甚至更多），并将输出限制为每月指定数量的视频分钟数。这个市场的领导者可以说是：
- en: '[Synthesia](www.synthesia.io.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Synthesia](www.synthesia.io.html)'
- en: '[Elai](app.elai.io.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Elai](app.elai.io.html)'
- en: '[Steve AI](www.steve.ai.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Steve AI](www.steve.ai.html)'
- en: '[Fliki](fliki.ai.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Fliki](fliki.ai.html)'
- en: '[Synthesys (not to be confused with Synthesia)](synthesys.io.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Synthesys（不要与 Synthesia 混淆）](synthesys.io.html)'
- en: 4.3 Generating presentation resources
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 生成演示文稿资源
- en: There’s something about PowerPoint presentations that inspires both fear and
    loathing. There’s the loathing from meeting participants who are condemned to
    suffer through poorly planned and designed presentations. And then there’s the
    dread experienced by presenters as they face the unwanted task of painstakingly
    building their presentations slide by slide (and then suffering the hatred of
    the victims in their audiences).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PowerPoint 演示文稿有一种特质，激发了人们对恐惧和厌恶的共鸣。会议参与者对经过粗糙计划和设计的演示文稿感到厌恶。而演讲者则面对着不情愿地逐一构建演示文稿（然后遭受观众的仇恨）的任务，感到恐惧。
- en: And, of course, slide decks are about far more than just conference presentations.
    They’re often also the backbone structure of business and educational videos.
    Which is where this chapter’s topic comes in.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，幻灯片演示不仅仅是会议演示。它们通常也是商业和教育视频的主要结构。这就是本章的主题所在。
- en: 'You see, GAI is already perfectly capable of doing all the hard work for you:
    sometimes technological innovations actually do solve problems. At least as far
    as presenters or video creators go. Their poor audiences are still pretty much
    on their own.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道，生成 AI 已经完全能够为你做所有的艰苦工作：有时技术创新确实解决了问题。至少对于演讲者或视频制作者来说是这样。而可怜的观众还是几乎自顾自。
- en: '[Gamma](gamma.app.html) is one of many text-to-presentation-deck services out
    there. I’ll focus on Gamma for this illustration simply because that’s the one
    with which I’ve had the most experience so far.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gamma](gamma.app.html) 是众多文本转演示文稿服务中的一种。我将重点介绍 Gamma，只是因为这是我迄今为止经验最丰富的一个。'
- en: 'Working with some of the free introductory credits I’m allowed, I selected
    the `New with AI` option, followed by their `Text transform` path and entered
    this text in the instructions field (yup: that’s this chapter’s working title):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 利用我被允许的一些免费试用积分，我选择了 `New with AI` 选项，然后选择了他们的 `Text transform` 路径，并在说明字段中输入了这段文本（是的：这就是本章的工作标题）：
- en: '*Generate a presentation on the topic of Creating with Generative AI: Media
    Resources using these headings:*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用以下标题生成有关使用生成 AI 创作：媒体资源的演示文稿：*'
- en: 'I then pasted the following topic headers into the content field:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我将以下主题标题粘贴到内容字段中：
- en: Generating images
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成图像
- en: Generating video
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成视频
- en: AI-assisted video editing
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 辅助视频编辑
- en: Text to video slide shows
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本转视频幻灯片演示
- en: Generating presentation resources
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成演示文稿资源
- en: Generating music
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成音乐
- en: After that, I only had to chose a format from their list and, within a couple
    of minutes, Gamma had generated the text content, layout, and visuals for a really
    attractive presentation. You can see the PDF that was generated [on my website](bootstrap-it.com.html).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我只需从他们的列表中选择一个格式，几分钟之内，Gamma 就为一个非常吸引人的演示文稿生成了文本内容、布局和视觉效果。你可以在[我的网站](bootstrap-it.com.html)上看到生成的
    PDF。
- en: Naturally, I’m free to edit any content that doesn’t fit my needs. But this
    is a game changer for those of us longing to escape PowerPoint Prison.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我可以自由编辑任何不符合我的需求的内容。但对于我们渴望逃离 PowerPoint 地狱的人来说，这是一个游戏规则的改变。
- en: 4.4 Generating voice
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 生成语音
- en: Not happy with your accent or just don’t have a nice, quiet place to record
    your podcast or video narration? There are services that’ll take text content
    and generate audio files with your choice of voice, accent, perfect pacing, and
    no kids screaming in the background. If you’d prefer to be the narrator after
    all, you can also have your voice cloned so *it* can be used to generate your
    audio files.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 不满意您的口音或者只是没有一个好的、安静的地方来录制您的播客或视频解说？有一些服务可以将文本内容转换成您选择的声音、口音、完美的节奏和没有孩子在背景尖叫的音频文件。如果您仍然希望成为叙述者，您也可以克隆您的声音，*它*可以用来生成您的音频文件。
- en: Of course, voice-to-text has been happening for decades. We’ve all heard voicemail
    systems featuring computer generated voices. What’s changing is that advances
    in AI have greatly improved the quality.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，语音转文字已经发展了几十年了。我们都听过有计算机生成声音的语音信箱系统。正在改变的是，人工智能的进步大大提高了质量。
- en: '"Improved," but not necessarily perfected. Try it yourself. Upload some content
    to, say, [Amazon’s Polly service](polly.html) and you’ll be impressed. But after
    listening carefully for at least a minute, and any listener will probably conclude
    that this isn’t really a human being speaking and, as good as it is, it’s quality
    will never be confused for Orson Welles or Winston Churchill.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '"改进了"，但不一定完美。自己试试。将一些内容上传到比如[亚马逊的Polly服务](polly.html)，你会印象深刻。但是仔细听了至少一分钟之后，任何听众都可能会得出结论，这实际上不是一个真正的人在说话，尽管它很好，但它的质量永远不会被误认为是奥森·威尔斯或温斯顿·丘吉尔。'
- en: On the other hand, hiring a human being with that level of oratorical skills
    to record your content would cost you considerably more than the $4.00 for every
    *million* characters Amazon will charge you. So there’s that.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，雇佣一个具有那种口才技巧水平的人来录制您的内容，成本肯定会比亚马逊每*百万*个字符收取的4.00美元高得多。所以就是这样。
- en: Polly is primarily aimed at organizations that need to generate voice in real
    time. Think interactive website support systems. That means Polly’s customers
    are going to want programmatic API connections to script the creation and management
    of their audio. To show you how that’ll work, here’s a sample command using the
    AWS CLI (a command line API access tool) that’ll request an audio .MP3 file generated
    from the text in a local file I called `text.txt`. To make this work, you’ll need
    an AWS account. You’ll also need to have [set up and configured the AWS CLI](userguide.html).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Polly主要面向需要实时生成语音的组织。想象一下交互式网站支持系统。这意味着Polly的客户将希望通过编程方式的API连接来脚本化其音频的创建和管理。为了向您展示这将如何运作，这里有一个使用AWS
    CLI（一种命令行API访问工具）的示例命令，它将请求从我称为`text.txt`的本地文件中生成的文本的音频.MP3文件。为了使其工作，您需要一个AWS账户。您还需要[设置和配置AWS
    CLI](userguide.html)。
- en: '[PRE0]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note how I specified the `Matthew` voice using a US English (`en-US`) accent.
    Polly has dozens of other voices and accent options.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我如何使用美式英语（`en-US`）口音指定了`Matthew`声音。Polly还有数十种其他声音和口音选项。
- en: 'I can download the file from the specified Amazon S3 output bucket once it’s
    generated with this AWS CLI command:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成了指定的Amazon S3输出桶中的文件，我可以使用以下AWS CLI命令下载该文件：
- en: '[PRE1]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: And I can remove remote copies of those files using `s3 rm`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用`s3 rm`删除这些文件的远程副本。
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: …​Because I believe you should always clean up your toys when you’re finished
    playing with them.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我认为玩完玩具后应该始终清理好它们。
- en: Text-to-speech is a crowded market. Besides Polly, other platforms offer API-accessed
    services. Those would include Google Cloud’s cleverly named [Text-to-Speech service](text-to-speech.html)
    and [IBM’s Watson Text to Speech Voices](self-service.html).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 文字转语音是一个竞争激烈的市场。除了Polly，其他平台提供了API访问服务。这些包括谷歌云的巧妙命名的[文字转语音服务](text-to-speech.html)和[IBM的Watson文字转语音声音](self-service.html)。
- en: Besides those, there are also services that’ll let you convert text documents
    to speech one at a time through a website interface. [ElevenLabs](beta.elevenlabs.io.html)
    has a reputation as an over-performer in this field, in particular when it comes
    to creating custom voices or cloning *your* voice. [Speechify](speechify.com.html)
    is another big player.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，还有一些服务将允许您通过网站界面逐个将文本文档转换为语音。[ElevenLabs](beta.elevenlabs.io.html)在这个领域有着表现超常的声誉，特别是在创建定制语音或克隆*您的*声音方面。[Speechify](speechify.com.html)是另一个主要参与者。
- en: 4.5 Audio transcriptions
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 音频转录
- en: That takes care of text-to-audio. But what about audio-to-text (otherwise known
    as *speech recognition*)? There’s no shortage of business uses for transcribing
    existing video or audio files. Can’t think of any offhand? Well how about taking
    the audio from a (boring) two hour video conference that you missed. Even though
    your boss bought your my-dog-ate-my-homework excuse at the time, you still have
    to get back up to speed by watching the recording of the conference.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这解决了文本转音频的问题。但是音频到文本（又称*语音识别*）呢？将现有视频或音频文件转录为文本文件有许多商业用途。想不出任何用途？那么试想一下，从你错过的（无聊的）两小时视频会议中提取音频。尽管当时你老板相信了你的狗吃了我的作业的借口，但你仍然需要通过观看会议的录像来重新掌握情况。
- en: You didn’t get to where you are now without being good and lazy. So here’s how
    you’re going to push back against that evil decree. You’ll submit the recording
    to an audio transcription service which will deliver you a text document containing
    a full script. You’ll then convert the script to a PDF file and upload it to the
    ChatPDF service we’ll discuss in chapter 5\. When the PDF is uploaded, you can
    request a brief but accurate summary of the script.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你没有不努力变得优秀和懒惰。所以这是你要反击那个邪恶命令的方法。你将录音提交给一个音频转录服务，该服务将为您提供包含完整脚本的文本文档。然后，您将脚本转换为
    PDF 文件并将其上传到我们将在第 5 章中讨论的 ChatPDF 服务中。当 PDF 被上传时，您可以请求脚本的简短但准确的摘要。
- en: Better yet, there are services like [mindgrasp’s Video Summarizer](video-summarizer.html)
    that’ll do all that in a single step.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是，还有像[mindgrasp 的视频摘要工具](video-summarizer.html)这样的服务，可以一步完成所有这些。
- en: 'One example of a service that offers simple but effective summaries is [Summarize.tech](www.summarize.tech.html).
    To test them out, I fed the address of [one of my own YouTube videos](www.youtube.com.html)
    into their URL field. Within a few short seconds, I was looking at this brief
    but accurate summary:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提供简单但有效摘要的服务的例子是[Summarize.tech](www.summarize.tech.html)。为了测试它们，我将[我自己的 YouTube
    视频之一的地址](www.youtube.com.html)输入到他们的 URL 字段中。几秒钟后，我就看到了这个简短但准确的摘要：
- en: '*This video discusses the security vulnerabilities that are associated with
    AWS EC2 instances. By default, these instances lack a firewall and have an open
    security group, making them vulnerable to attack. The instructor provides a real-life
    example of launching an EC2 instance with open incoming traffic and receiving
    login attempts within minutes. He stresses the importance of striking a balance
    between server functionality and infrastructure security, which will be the main
    goal of the course.*'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*本视频讨论了与 AWS EC2 实例相关的安全漏洞。默认情况下，这些实例缺乏防火墙并且具有开放的安全组，使其容易受到攻击。讲师提供了一个真实的例子，演示了如何在几分钟内启动具有开放入站流量的
    EC2 实例并收到登录尝试。他强调了在服务器功能和基础设施安全性之间取得平衡的重要性，这将是该课程的主要目标。*'
- en: See? Life isn’t half as horrible as it looked when you rolled out of bed this
    morning.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 看到了吧？生活并不像你今早起床时看起来那么糟糕。
- en: Naturally there are also APIs for transcribing audio. Two of those are [OpenAI’s
    Whisper](openai.html) and [Google’s Speech-to-Text](cloud.google.com.html).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有用于转录音频的 API。其中两个是[OpenAI 的 Whisper](openai.html)和[Google 的语音转文本](cloud.google.com.html)。
- en: Whisper is a dog that does lots of tricks. Among other things, it can handle
    language identification, speech translation, and multilingual speech recognition.
    Like many GPT-based apps, Whisper is built to be installed and run on your own
    computer using a valid OpenAI API key - which, as you’ve already seen, [can be
    acquired on the OpenAI site](account.html).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper 是一个会做很多花招的狗。除其他外，它可以处理语言识别、语音翻译和多语言语音识别等任务。与许多基于 GPT 的应用程序一样，Whisper
    旨在使用有效的 OpenAI API 密钥在您自己的计算机上安装和运行 - 正如您已经看到的那样，[可以在 OpenAI 网站上获取](account.html)。
- en: 'And that’s not going to be half as complicated as you think. Within a Python
    environment, just use `pip` to install the Whisper package:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 并且这并不会像你想象的那么复杂。在 Python 环境中，只需使用`pip`安装`Whisper`包：
- en: '[PRE3]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You’ll also need the open source video/audio management tool, ffmpeg. Here’s
    how installing that into a Debian/Ubuntu-based Linux system will work:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要开源视频/音频管理工具`ffmpeg`。以下是如何将其安装到基于 Debian/Ubuntu 的 Linux 系统中的步骤：
- en: '[PRE4]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And here’s the code that’ll make it work:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使其工作的代码：
- en: '[PRE5]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We’ll use the `base` model, write our transcribed text (based on the `MyAudio.flac`
    input file I was using) to the variable `result`, and then display the result.
    Super simple. And it’s surprisingly accurate!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`base`模型，将我们转录的文本（基于我使用的`MyAudio.flac`输入文件）写入变量`result`，然后显示结果。非常简单。而且非常准确！
- en: Of course you can use all the regular audio *and* video file formats as inputs,
    and select from one of five models (tiny, base, small, medium, and large).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以使用所有常见的音频和视频文件格式作为输入，并从五种模型中选择（tiny、base、small、medium和large）。
- en: 4.6 Generating music
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 生成音乐
- en: I guess I can’t move on without talking about AI-generated music. I’m not just
    talking about ChatGPT-powered lyrics, or even software that outputs sheet music,
    but *actual* music. That means software that lets you specify details like genre,
    the instruments you want playing, the emotional tone, tempo range, time signature,
    key signature, and harmonic repetition and real music comes out the other end.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在没有谈论人工智能生成的音乐之前，我不能继续了。我不仅仅是在谈论ChatGPT驱动的歌词，或者甚至是能够输出乐谱的软件，而是*真正的*音乐。这意味着软件可以让你指定细节，比如流派、你希望演奏的乐器、情感色彩、速度范围、拍子、调号和和声重复，然后会有真正的音乐出现。
- en: As you’ve probably heard, some of those services also make it possible to recreate
    near-perfect sound-alikes of famous singers and have them sing your own new music.
    The exact legal implications of the use of such sound-alikes are not yet clear.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能听说过的，其中一些服务还可以重新创作出著名歌手的几乎完美的声音，并让其演唱你自己的新音乐。使用这种声音的确切法律意义尚不清楚。
- en: Online AI music generation tools - most of which are primarily designed for
    creating background music using various genres - include [AIVA](www.aiva.ai.html),
    [boomy](boomy.com.html), [Soundful](soundful.com.html), and [Mubert](mubert.com.html).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在线AI音乐生成工具-大多数主要用于使用不同的流派创建背景音乐，包括[AIVA](www.aiva.ai.html)、[boomy](boomy.com.html)、[Soundful](soundful.com.html)和[Mubert](mubert.com.html)。
- en: More recently, Meta (the owners of Facebook) has released [two audio generation
    tools as open source](facebookresearch.html).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Meta（Facebook的所有者）已经发布了[两个音频生成工具作为开源项目](facebookresearch.html)。
- en: MusicGen will generate music from text prompts.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MusicGen会根据文本提示生成音乐。
- en: 'AudioGen will give you sound effects (think: "busy street with police car siren"
    or "wind blowing through trees").'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AudioGen会为你提供音效（想象一下："警车鸣笛的繁忙街道"或者"风穿过树木"）。
- en: In addition, they’ve also released the neural audio codec, EnCodec, and the
    diffusion-based decoder, Multi Band Diffusion. You can freely download the code
    but, just like working with image generators, you will need substantial system
    resources to make it work.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，他们还发布了神经音频编解码器EnCodec和基于扩散的解码器Multi Band Diffusion。你可以自由下载代码，但是，就像使用图像生成器一样，你需要大量的系统资源来使其正常工作。
- en: 4.7 Summary
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 总结
- en: We learned about generating digital images (and video) using services like Stable
    Diffusion and MidJourney
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们了解了使用稳定扩散和中途旅程等服务生成数字图像（和视频）的方法。
- en: We learned about tools that can use AI to transform existing video artifacts
    into new media
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们了解了可以使用AI将现有视频工件转换为新媒体的工具
- en: We learned how to use AI tools like Gamma to generate presentation slide stacks
    from text prompts
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们学习了如何使用Gamma等AI工具根据文本提示生成演示文稿堆栈。
- en: We learned about audio-to-text and text-to-audio transcribing using tools like
    Amazon Polly and OpenAI Whisper
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们了解了使用Amazon Polly和OpenAI Whisper等工具进行音频转文本和文本转音频的方法。
- en: 4.8 Try this for yourself
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8 试试看
- en: 'Why not produce an original training video using some of the media generation
    tools we’ve seen in this chapter. Here’s how you might want to go about it:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不使用本章中介绍的一些媒体生成工具制作一部原创培训视频呢？以下是你可能想要采取的步骤：
- en: Pick a topic ("How to make the most out of generative AI tools", perhaps) and
    prompt an LLM for a video transcript (a three minute video will require around
    500 words of text).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个主题（也许是"如何最大限度地利用生成式人工智能工具"），并为视频转录稿提示一个LLM（三分钟的视频将需要大约500个文字）。
- en: As the LLM to summarize the script to give you a set of descriptive bullet points
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为LLM，可以总结脚本，给出一组描述性的要点。
- en: Using [Gamma](gamma.app.html), Select Create new > Text transform and paste
    your bullet points into content field. Then Generate slides.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[Gamma](gamma.app.html)，选择创建新的 > 文本转换，并将你的要点粘贴到内容字段中。然后生成幻灯片。
- en: Using Amazon Polly, generate a narration file out of the script created by your
    LLM.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Amazon Polly，从LLM创建的脚本生成一个解说文件。
- en: Use Mubert to generate background music.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Mubert生成背景音乐。
- en: Assemble your narration, slides, and background music into a video using, say,
    the [Vimeo video maker](create.html).
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的叙述、幻灯片和背景音乐组合成视频，可以使用，比如，[Vimeo 视频制作工具](create.html)。
- en: Finally, just for fun, use Whisper to extract a text transcript from the narration
    track on your video and see how close it is to the original script.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，只是为了好玩，使用 Whisper 从视频的叙述音轨中提取文本转录，并看看它与原始脚本有多接近。
