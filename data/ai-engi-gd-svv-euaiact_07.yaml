- en: Chapter 7\. Toward Trustworthy General-Purpose AI and Generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章\. 向着可信赖的通用人工智能和生成人工智能迈进
- en: 'The EU AI Act, which came into effect in August 2024, is the world’s first
    comprehensive legal framework for AI. Up to this point, this book has focused
    primarily on how the Act’s risk-based approach applies to predictive AI systems.
    However, the Act also includes provisions for *general-purpose AI* (GPAI)—a relatively
    late addition spurred by the rapid rise of large language models (LLMs) such as
    GPT and BERT, along with the broader emergence of generative AI technologies during
    the period when the legislation was being drafted. This addition was intended
    to address a key regulatory challenge: how to govern AI models that are not tied
    to a specific task and can be adapted to a wide range of downstream uses.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案（EU AI Act），于2024年8月生效，是全球首个全面的人工智能法律框架。到目前为止，本书主要关注该法案基于风险的途径如何应用于预测人工智能系统。然而，该法案还包括了针对**通用人工智能**（GPAI）的规定——这一补充是在大语言模型（LLMs）如GPT和BERT的快速崛起以及生成人工智能技术在该法案起草期间更广泛出现之后相对较晚加入的。这一补充旨在解决一个关键的监管挑战：如何治理那些与特定任务无关且可以适应广泛下游用途的人工智能模型。
- en: The EU AI Act aims to balance innovation and risk mitigation by promoting research
    and development while safeguarding fundamental rights. As such, it does not apply
    to GPAI models developed and used solely for prototyping or for research and development
    purposes prior to being placed on the market or put into service. In general,
    the rules for GPAI models and systems are less stringent than those for high-risk
    AI systems—unless they are deemed to present a systemic risk (defined as “a risk
    that is specific to the high-impact capabilities of general-purpose AI models,
    having a significant impact on the Union market due to their reach, or due to
    actual or reasonably foreseeable negative effects on public health, safety, public
    security, fundamental rights, or the society as a whole, that can be propagated
    at scale across the value chain”).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案旨在通过促进研究和开发来平衡创新和风险缓解，同时保护基本权利。因此，它不适用于在投放市场或投入使用之前仅用于原型设计或研究和开发目的的GPAI模型。一般来说，GPAI模型和系统的规则不如高风险人工智能系统严格——除非它们被认为存在系统性风险（定义为“特定于通用人工智能模型的高影响能力，由于它们的范围或由于对公共健康、安全、公共安全、基本权利或整个社会产生的实际或合理可预见的负面影响，这些影响可以在价值链上大规模传播”）。
- en: This chapter lays out the requirements for EU AI Act compliance for GPAI and
    generative AI. It also introduces the concept of GenAIOps—the application of MLOps
    principles to the development and deployment of generative AI applications. As
    in the previous chapters, the focus will be on how AI engineering principles and
    practices can be applied to meet the transparency obligations of the EU AI Act
    in this rapidly evolving domain.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章阐述了欧盟人工智能法案对通用人工智能和生成人工智能合规性的要求。它还介绍了GenAIOps的概念——将MLOps原则应用于生成人工智能应用的开发和部署。与前面的章节一样，重点将放在如何将人工智能工程原理和实践应用于满足欧盟人工智能法案在此快速发展的领域中的透明度义务。
- en: The EU AI Act and Generative AI
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案与生成人工智能
- en: The notion of “general-purpose” AI (also known as “foundation models”) was introduced
    into the EU AI Act relatively late in the negotiations between the European Parliament
    and Council. The rapid emergence and widespread adoption of generative AI systems
    like ChatGPT, DALL·E, and Midjourney during the legislative process revealed that
    the Act’s initial focus on AI systems with specific, identifiable risks stemming
    from clearly defined use cases was too narrow. General-purpose AI was added as
    a distinct category primarily to address concerns around quality control and copyright
    protection related to training data, while also allowing for the assessment of
    systemic risks, as elaborated in Chapter V of the Act. The regulations governing
    these models are relatively limited in scope, focusing mainly on requirements
    for documentation and transparency (Article 53) and obligations for cooperation
    with relevant authorities (Article 91).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: “通用”AI 的概念（也称为“基础模型”）在欧盟 AI 法的谈判过程中相对较晚被引入。在立法过程中，像 ChatGPT、DALL·E 和 Midjourney
    这样的生成式 AI 系统的快速出现和广泛应用揭示了，该法案最初对具有特定、可识别风险的 AI 系统的关注过于狭窄，这些风险源于明确定义的使用案例。通用 AI
    被添加为一个独特的类别，主要是为了解决与训练数据的质量控制和版权保护相关的担忧，同时允许评估系统性风险，如法案第 V 章所述。这些模型的管理规定范围相对有限，主要关注对文档和透明度的要求（第
    53 条）以及与相关当局合作的义务（第 91 条）。
- en: Generative AI, or GenAI, offers numerous potential benefits, including enhanced
    decision making, increased productivity, and the ability to generate novel content.
    GenAI technologies can be used in a wide range of domains, such as education,
    research, and customer service, to automate tasks and improve operational efficiency.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI，或 GenAI，提供了许多潜在的好处，包括增强决策能力、提高生产力和生成新颖内容的能力。GenAI 技术可用于广泛的领域，如教育、研究和客户服务，以自动化任务并提高运营效率。
- en: However, these technologies also pose significant risks. These include the potential
    for bias and discrimination, the generation of inaccurate or misleading information,
    and various form of misuse (e.g., creating deceptive content, or deepfakes). Misuse
    tends to fall into two broad categories:^([1](ch07.html#id616))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些技术也带来了显著的风险。这些风险包括潜在的偏见和歧视、生成不准确或误导性信息，以及各种形式的滥用（例如，创建欺骗性内容或深度伪造）。滥用往往分为两大类：^([1](ch07.html#id616))
- en: Exploitation of GenAI capabilities
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 GenAI 能力
- en: Tactics that leverage the features of GenAI models to create harmful outputs
    or support malicious activities. For example, AI robocalls can imitate real people
    and take actions on their behalf, and synthetic content can be generated to create
    fake social media accounts to promote a specific agenda or to fabricate identification
    documents.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 GenAI 模型的特性来创建有害输出或支持恶意活动的策略。例如，AI 机器人电话可以模仿真实人物并代表他们采取行动，合成内容可以生成以创建虚假社交媒体账户来推广特定议程或伪造身份证明文件。
- en: Compromise of GenAI systems
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对 GenAI 系统的妥协
- en: Tactics that involve attacking or manipulating the GenAI systems, targeting
    model or data integrity vulnerabilities. Examples include prompt injection (manipulating
    model prompts to enable unintended or unauthorized outputs); compromising the
    privacy of training data to extract personal information; bypassing restrictions
    on the model’s safeguards (known as jailbreaking); and model extraction (reverse
    engineering to obtain details on the model’s architecture, parameters, or training
    data).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及攻击或操纵 GenAI 系统、针对模型或数据完整性漏洞的策略。例如，包括提示注入（操纵模型提示以启用非预期或未经授权的输出）；侵犯训练数据的隐私以提取个人信息；绕过对模型安全措施的限制（称为越狱）；以及模型提取（逆向工程以获取有关模型架构、参数或训练数据的详细信息）。
- en: The EU AI Act aims to mitigate these risks by imposing certain obligations on
    the providers of generative and general-purpose AI systems to ensure that they
    are developed and deployed responsibly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟 AI 法旨在通过要求生成式和通用 AI 系统的提供者承担某些义务来减轻这些风险，以确保它们负责任地开发和部署。
- en: GPAI Systems and Transparency Obligations
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPAI 系统和透明度义务
- en: 'GPAI systems that interact directly with humans, including those that generate
    synthetic content, are subject to the following transparency obligations under
    Article 50 of the EU AI Act:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与人类直接交互的 GPAI 系统，包括生成合成内容的那部分，根据欧盟 AI 法第 50 条的规定，需要遵守以下透明度义务：
- en: Informing users of AI interaction
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通知用户 AI 交互
- en: Providers must inform users when they are interacting with an AI system, unless
    it’s reasonably obvious or the system is used for law enforcement purposes (e.g.,
    detecting, preventing, investigating, or prosecuting crimes). This applies to
    chatbots and content-generating tools.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户与AI系统互动时，提供者必须通知用户，除非这是明显合理的或系统用于执法目的（例如，检测、预防、调查或起诉犯罪）。这适用于聊天机器人和内容生成工具。
- en: Marking synthetic content
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 标记合成内容
- en: Providers of AI systems that generate synthetic content (audio, images, video,
    text) must clearly mark these outputs as artificially generated or manipulated.
    The labels should be machine-readable and easily detectable, signaling the content’s
    non-authentic nature. This requirement does not apply to assistive editing tools
    or systems that do not significantly alter the original input.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成合成内容（音频、图像、视频、文本）的AI系统提供者必须明确标记这些输出为人工生成或操纵的。标签应该是机器可读的，并且易于检测，表明内容的非真实性。此要求不适用于辅助编辑工具或未显著改变原始输入的系统。
- en: Disclosing deepfakes
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 深伪影的披露
- en: Providers of AI systems that generate deepfakes (described by Article 3(60)
    as “AI-generated or manipulated image, audio or video content that resembles existing
    persons, objects, places, entities or events and would falsely appear to a person
    to be authentic or truthful”) must clearly label these outputs as artificial.
    The labels should be machine-readable and easily detectable.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 生成深伪影（根据第3(60)条描述为“AI生成或操纵的图像、音频或视频内容，类似于现有的人、物体、地点、实体或事件，并会向个人虚假地呈现为真实或真实”）的AI系统提供者必须明确标记这些输出为人工制品。标签应该是机器可读的，并且易于检测。
- en: Regulating General-Purpose AI
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监管通用人工智能
- en: The EU AI Act introduces specific regulations for GPAI models and systems, focusing
    on transparency, documentation, and risk management. In this section, I’ll first
    define what constitutes a GPAI model or system under the Act and explain the criteria
    for determining whether a GPAI model presents systemic risk. I will then outline
    the obligations for providers of GPAI models and deployers of GPAI systems, including
    the increased obligations for providers of GPAI models deemed to pose systemic
    risks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案为GPAI模型和系统引入了特定的法规，重点关注透明度、文档和风险管理。在本节中，我将首先定义法案下构成GPAI模型或系统的要素，并解释确定GPAI模型是否呈现系统性风险的准则。然后，我将概述GPAI模型提供者和GPAI系统部署者的义务，包括被认为可能带来系统性风险的GPAI模型提供者的增加义务。
- en: Definition and scope
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义和范围
- en: The EU AI Act defines a *GPAI model* as an AI model with significant generality
    that can perform a wide range of distinct tasks. These models are typically trained
    on large amounts of data, often using self-supervised learning techniques, and
    are designed to be integrated into various downstream systems or applications.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案将**GPAI模型**定义为一种具有显著通用性的AI模型，能够执行广泛的独立任务。这些模型通常在大量数据上训练，经常使用自监督学习技术，并设计成可以集成到各种下游系统或应用中。
- en: The Act defines a *GPAI system* as an AI system based on a GPAI model that can
    serve a variety of purposes, either as a standalone application or as a component
    integrated into other AI systems. As a reminder, the Act defines an AI system
    as “a machine-based system that is designed to operate with varying levels of
    autonomy and that may exhibit adaptiveness after deployment, and that, for explicit
    or implicit objectives, infers, from the input it receives, how to generate outputs
    such as predictions, content, recommendations, or decisions that can influence
    physical or virtual environments.”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 法案将**GPAI系统**定义为基于GPAI模型的AI系统，可以服务于各种目的，无论是作为独立应用程序还是作为集成到其他AI系统中的组件。提醒一下，法案将AI系统定义为“一种基于机器的系统，旨在以不同的自主程度运行，并在部署后可能表现出适应性，并且为了明确或隐含的目标，从它接收的输入中推断出如何生成输出，如预测、内容、推荐或决策，这些输出可以影响物理或虚拟环境。”
- en: It’s important to distinguish between the model and the system it powers. The
    Act regulates both providers of GPAI models and deployers who use or integrate
    these models into AI systems. The obligations for deployers of GPAI systems are
    generally the same as for other AI systems, with specific oversight powers granted
    to the AI Office in the European Commission.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 区分模型及其所驱动的系统非常重要。法案规范了GPAI模型的提供者和使用或集成这些模型到AI系统中的部署者。GPAI系统部署者的义务通常与其他AI系统相同，欧洲委员会的AI办公室被授予特定的监管权力。
- en: Systemic risk criteria
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统性风险准则
- en: 'The EU AI Act establishes a two-tiered regulatory approach for GPAI models:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟 AI 法案为 GPAI 模型建立了两级监管方法：
- en: General obligations
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一般义务
- en: All providers of GPAI models must meet baseline transparency and compatibility
    requirements.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 GPAI 模型的提供者都必须满足基线透明度和兼容性要求。
- en: Systemic risk
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 系统风险
- en: If a GPAI model is classified as having systemic risk, it triggers additional
    regulatory oversight and extra obligations. The criteria for this classification
    are outlined in [Table 7-1](#chapter_7_table_1_1748539924522291).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 GPAI 模型被归类为具有系统风险，则将触发额外的监管监督和额外义务。此类分类的标准在[表 7-1](#chapter_7_table_1_1748539924522291)中概述。
- en: Table 7-1\. Criteria for systemic-risk GPAI models
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7-1\. 系统风险 GPAI 模型的标准
- en: '| Criterion | Description of systemic risk |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 标准 | 系统风险的描述 |'
- en: '| --- | --- |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| High-impact capabilities | The model has significant potential to cause harm
    due to its broad range of functionalities. Risks include major accidents, disruption
    of critical infrastructure, threats to public health or safety, impacts on democratic
    processes, national or economic security risks, generation of illegal or discriminatory
    content, lowering barriers to development of chemical, biological, radiological,
    and nuclear (CBRN) weapons technology, or the ability of models to make copies
    of themselves or train other models autonomously. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 高影响能力 | 该模型由于其广泛的功能范围，具有造成重大伤害的显著潜力。风险包括重大事故、关键基础设施的中断、对公共健康或安全的威胁、对民主进程的影响、国家或经济安全风险、生成非法或歧视性内容、降低化学、生物、辐射和核（CBRN）武器技术发展的障碍，或模型复制自身或自主训练其他模型的能力。
    |'
- en: '| FLOPs threshold | The model requires more than 10^(25) floating-point operations
    per second (FLOPs) during training. This indicates a potential for high-impact
    capabilities. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| FLOPs 阈值 | 模型在训练期间需要每秒超过 10^(25) 次浮点运算（FLOPs）。这表明具有高影响能力的潜力。 |'
- en: '| Commission decision based on equivalent capabilities or impact | Even if
    the FLOPs threshold is not met, the European Commission can classify a model as
    posing systemic risk if it demonstrates a potential for high-impact capabilities
    based on the assessment criteria in Annex XIII. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 基于等效能力或影响的委员会决定 | 即使没有达到 FLOPs 阈值，如果欧洲委员会根据附件 XIII 中的评估标准证明模型具有高影响能力的潜力，则可以将其归类为具有系统风险。
    |'
- en: '| Additional factors considered by the Commission | Additional factors that
    are taken into account include the number of parameters, quality and size of the
    training dataset (e.g., number of tokens), computational resources used for training
    (FLOPs, cost, time, energy consumption), input and output modalities, and degree
    of autonomy or scalability. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 委员会考虑的额外因素 | 考虑的额外因素包括参数数量、训练数据集的质量和大小（例如，令牌数量）、用于训练的计算资源（FLOPs、成本、时间、能耗）、输入和输出模式，以及自主程度或可扩展性。
    |'
- en: '| Contesting the presumption of systemic risk | A provider can contest the
    presumption of systemic risk by presenting sufficiently substantiated arguments
    demonstrating that, even if the FLOPs criterion is met, the model does not actually
    present systemic risks due to its specific characteristics. General arguments
    are not sufficient. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 对系统风险假设的质疑 | 提供者可以通过提出充分证明的论据来质疑系统风险的假设，证明即使满足 FLOPs 标准，由于模型的特定特征，该模型实际上并不呈现系统风险。一般论据是不够的。
    |'
- en: Obligations for providers of GPAI models
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPAI 模型提供者的义务
- en: 'All providers of GPAI models, regardless of their systemic risk classification,
    are subject to a set of general obligations under the EU AI Act. These obligations
    are intended to promote transparency, accountability, and responsible development
    of powerful AI models. There are simplified requirements for providers offering
    GPAI models under free and open licenses, provided that these models do not present
    systemic risk. The core obligations (as outlined in [Article 53](https://oreil.ly/Xn8iw)) include:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 GPAI 模型的提供者，无论其系统风险分类如何，都受欧盟 AI 法案下的一系列一般义务约束。这些义务旨在促进强大 AI 模型的透明度、问责制和负责任的发展。对于在免费和开放许可证下提供
    GPAI 模型的提供者，如果这些模型不呈现系统风险，则有一些简化的要求。核心义务（如[第 53 条](https://oreil.ly/Xn8iw)所述）包括：
- en: Technical documentation
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 技术文档
- en: Providers must create and maintain comprehensive technical documentation including
    details about the model’s design specifications, training and testing processes,
    and evaluation results. This documentation must enable regulatory authorities
    to assess the model’s compliance with the EU AI Act and must be provided to the
    AI Office and national competent authorities upon request.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 提供者必须创建和维护全面的技术文档，包括关于模型设计规格、培训和测试过程以及评估结果的详细信息。这些文档必须使监管机构能够评估模型是否符合欧盟AI法案，并在请求时提供给AI办公室和国家主管部门。
- en: Documentation for downstream providers
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 向下游提供者的文档
- en: Given that GPAI models are often integrated into other AI systems, the EU AI
    Act requires providers to furnish downstream providers with documentation that
    enables them to understand the model’s capabilities, limitations, and known risks.
    For example, if the model is known to exhibit bias in certain contexts, this must
    be disclosed so that downstream providers can take appropriate mitigation steps
    in their AI systems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPAI模型通常集成到其他AI系统中，欧盟AI法案要求提供者向下游提供者提供文档，使他们能够了解模型的能力、局限性和已知风险。例如，如果模型在特定环境中已知存在偏差，则必须披露此信息，以便下游提供者在其AI系统中采取适当的缓解措施。
- en: Copyright compliance
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 版权合规
- en: GPAI models are trained on vast amounts of data, often including copyrighted
    material. Consequently, providers must implement a policy to comply with EU copyright
    law (in particular, the [EU Copyright Directive](https://oreil.ly/6l3Hq)), including
    measures to identify and respect any copyright restrictions on the data used to
    train the model and documentation of how such restrictions have been addressed.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: GPAI模型是在大量数据上训练的，通常包括受版权保护的材料。因此，提供者必须实施一项政策，以遵守欧盟版权法（特别是[欧盟版权指令](https://oreil.ly/6l3Hq)），包括识别和尊重用于训练模型的数据的任何版权限制的措施，以及记录如何解决这些限制的文档。
- en: Training data summary
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据摘要
- en: To promote transparency and accountability, providers must publish a detailed
    summary of the data used to train their GPAI models. This should provide information
    about the types and sources of data used, as well as any known limitations or
    biases in the data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为促进透明度和问责制，提供者必须发布其GPAI模型训练所使用数据的详细摘要。这应提供有关使用数据的类型和来源的信息，以及数据中任何已知的局限性或偏差。
- en: EU representative
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟代表
- en: Providers based outside the European Union must appoint an authorized representative
    within the EU. This representative acts as a point of contact for authorities
    and is responsible for ensuring that the provider complies with its obligations
    under the EU AI Act.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟以外地区的提供者必须在欧盟内指定一名授权代表。此代表作为当局的联系人，并负责确保提供者遵守欧盟AI法案下的义务。
- en: Additional obligations for providers of GPAI models with systemic risk
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPAI模型提供者的额外义务
- en: 'GPAI models with systemic risk are subject to more stringent requirements due
    to their potential for causing significant harm. In addition to the general obligations
    outlined in the previous section, providers of these models must comply with the
    following obligations, specified in [Article 55](https://oreil.ly/2fYcc):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPAI模型可能造成重大危害，具有系统性风险的GPAI模型需遵守更严格的要求。除了上一节中概述的一般义务外，这些模型的提供者必须遵守以下义务，具体规定在[第55条](https://oreil.ly/2fYcc)中：
- en: Model evaluation
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估
- en: Conduct regular rigorous evaluations of the models using standardized protocols
    and tools. This includes adversarial testing to identify vulnerabilities and potential
    risks. The goal is to ensure that the model is robust, reliable, and does not
    pose unacceptable risks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 定期使用标准协议和工具对模型进行严格的评估。这包括对抗性测试以识别漏洞和潜在风险。目标是确保模型稳健、可靠，且不构成不可接受的风险。
- en: Risk mitigation
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 风险缓解
- en: Proactively assess and mitigate potential systemic risks associated with use
    of the models. Identify potential harms related to fundamental rights, health
    and safety, or security, and implement documented measures to minimize those risks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 积极评估和减轻与模型使用相关的潜在系统性风险。识别与基本权利、健康和安全或安全相关的潜在危害，并实施记录在案的措施以最小化这些风险。
- en: Incident reporting
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 事件报告
- en: Establish a system for tracking, documenting, and reporting serious incidents
    related to use of the models. Incidents must be reported to the AI Office and
    relevant national authorities, and appropriate corrective actions must be taken
    and documented.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 建立一个跟踪、记录和报告与模型使用相关的严重事件的系统。事件必须报告给人工智能办公室和相关的国家当局，并采取适当的纠正措施并记录在案。
- en: Cybersecurity
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安全
- en: Implement robust safeguards to protect the models and the infrastructure on
    which they operate. This is crucial to prevent unauthorized access, data breaches,
    and malicious use.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 实施强有力的保障措施来保护模型及其运行的基础设施。这对于防止未经授权的访问、数据泄露和恶意使用至关重要。
- en: Obligations for deployers of GPAI models
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPAI模型部署者的义务
- en: 'The EU AI Act applies to all deployers who operate an AI system under their
    own authority in a professional capacity. When deployers integrate GPAI models
    into their AI systems, they may incur additional responsibilities under the Act,
    particularly if the resulting systems are classified as high risk. These obligations
    include:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 欧盟人工智能法案适用于所有在其专业能力下自主运营人工智能系统的部署者。当部署者将GPAI模型集成到其人工智能系统中时，他们可能根据该法案承担额外的责任，尤其是如果生成的系统被归类为高风险时。这些义务包括：
- en: Using the system as intended
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 按预期使用系统
- en: The system must be used in accordance with the provider’s instructions and for
    its intended purpose.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 系统必须按照提供商的说明和预期目的使用。
- en: Human oversight
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 人类监督
- en: Appropriate human oversight mechanisms must be established—for example, human
    review of the system’s outputs, the ability to intervene in the system’s operation,
    and clear assignment of responsibility for the system’s decisions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 必须建立适当的人类监督机制——例如，对系统输出的人类审查、干预系统操作的能力，以及对系统决策责任的明确分配。
- en: Data quality
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量
- en: The input data provided to the system must be relevant, accurate, and representative.
    This is crucial to prevent biased or inaccurate outputs and to ensure that the
    system operates as intended.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给系统的输入数据必须是相关、准确和具有代表性的。这对于防止产生有偏见或不准确的结果，并确保系统按预期运行至关重要。
- en: Monitoring
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 监控
- en: System performance must be monitored and any issues reported to the provider.
    This includes monitoring for unexpected outputs, performance degradation, or other
    indications that the system is not functioning correctly.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 必须监控系统性能，并向提供商报告任何问题。这包括对意外输出、性能下降或其他表明系统未正确运行的迹象进行监控。
- en: Recordkeeping
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 记录保存
- en: System logs must be maintained for the purposes of incident investigation and
    demonstration of regulatory compliance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 必须维护系统日志，用于事故调查和证明合规性。
- en: Transparency
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度
- en: AI systems that generate or manipulate content that is published to inform the
    public on matters of public interest must clearly disclose that the content is
    synthetic.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 生成或操纵发布以向公众通报公共事务内容的人工智能系统必须明确披露该内容是合成的。
- en: Predictive ML Versus GPAI
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测性机器学习与GPAI
- en: Before we turn our attention to operationalizing EU AI Act compliance for GPAI,
    let’s briefly reflect on the differences between predictive and generative AI
    to better understand where generative AI diverges and why the discipline of GenAIOps
    has emerged.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们转向实施欧盟人工智能法案对GPAI的合规性之前，让我们简要地反思预测性和生成性人工智能之间的差异，以便更好地理解生成性人工智能如何偏离以及为什么会出现GenAIOps这一学科。
- en: 'Machine learning is a broad field, but at its core, most models can be categorized
    into two distinct paradigms: predictive ML and GPAI (see Figures [7-1](#chapter_7_figure_1_1748539924514309)
    and [7-2](#chapter_7_figure_2_1748539924514347) for concrete examples of each).
    While both rely on statistical learning, they differ in their goals, methodologies,
    and applications.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个广泛的领域，但就其核心而言，大多数模型可以分为两个不同的范例：预测性机器学习和GPAI（参见[7-1](#chapter_7_figure_1_1748539924514309)和[7-2](#chapter_7_figure_2_1748539924514347)图中的具体示例）。虽然两者都依赖于统计学习，但它们在目标、方法和应用上有所不同。
- en: '![](assets/taie_0701.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/taie_0701.png)'
- en: Figure 7-1\. A visualization of predictive ML—a discriminative model trained
    to predict whether a given image is painted by Vincent van Gogh. Image from the
    book [Generative Deep Learning, 2nd edition](https://oreil.ly/L5njI), by David
    Foster (O’Reilly). Used with permission.
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. 预测性机器学习的一个可视化——一个训练用来预测给定图像是否由文森特·梵高绘制的判别模型。图片来自大卫·福斯特所著的《生成深度学习，第2版》一书（https://oreil.ly/L5njI）。经许可使用。
- en: '![](assets/taie_0702.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/taie_0702.png)'
- en: Figure 7-2\. A visualization of generative AI—a generative model trained to
    generate realistic photos of horses. Image from the book [Generative Deep Learning,
    2nd edition](https://oreil.ly/L5njI), by David Foster (O’Reilly). Used with permission.
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. 生成式AI的视觉展示——一个训练生成马的真实照片的生成模型。图片来自David Foster所著的《生成深度学习，第2版》（https://oreil.ly/L5njI），经O’Reilly授权使用。
- en: At its core, predictive ML is about answering the question “What’s likely?”
    It focuses on estimation, forecasting, and pattern recognition. Predictive models
    analyze historical data to make informed forecasts or decisions. They learn patterns
    from structured datasets and aim to provide numerical outputs, classifications,
    or recommendations on input features.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，预测机器学习是关于回答“可能是什么？”的问题。它专注于估计、预测和模式识别。预测模型通过分析历史数据来做出明智的预测或决策。它们从结构化数据集中学习模式，并旨在为输入特征提供数值输出、分类或推荐。
- en: GPAI, on the other hand, is an umbrella category that includes many generative
    models—particularly foundation models such as LLMs. Generative AI can therefore
    be thought of as a subset of GPAI. Most state-of-the-art generative models (such
    as GPT-4, DALL·E, and Stable Diffusion) are classified as GPAI under the EU AI
    Act. This includes models that are general-purpose (used across many tasks or
    systems) and models that are made available to others for downstream use or fine-tuning.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GPAI，另一方面，是一个包含许多生成模型（尤其是基础模型如LLMs）的范畴。因此，生成式AI可以被视为GPAI的一个子集。大多数最先进的生成模型（如GPT-4、DALL·E和Stable
    Diffusion）根据欧盟AI法案被归类为GPAI。这包括通用模型（用于许多任务或系统）和可供他人用于下游使用或微调的模型。
- en: At its core, generative AI is about answering the question “What’s possible?”
    It moves beyond predictions to creating new content. Instead of mapping inputs
    to predefined outputs, generative models learn the statistical distribution of
    their training data and generate new, plausible data points that fall within that
    learned distribution.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，生成式AI是关于回答“可能是什么？”的问题。它超越了预测，转向创造新的内容。生成模型不是将输入映射到预定义的输出，而是学习其训练数据的统计分布，并生成新的、合理的、落在该学习分布内的数据点。
- en: '[Table 7-2](#chapter_7_table_2_1748539924522329) provides a structured comparison
    of predictive ML and GPAI.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[表7-2](#chapter_7_table_2_1748539924522329)提供了预测机器学习和GPAI的结构化比较。'
- en: Table 7-2\. Predictive ML and GPAI—a side-by-side comparison
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-2\. 预测机器学习和GPAI——并列比较
- en: '| Feature | Predictive ML | GPAI |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 预测机器学习 | GPAI |'
- en: '| --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Primary goal | Solve a well-defined, narrow task (e.g., fraud detection,
    loan scoring) | Provide broad capabilities that can be adapted to many tasks and
    use cases |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 主要目标 | 解决一个定义明确、范围狭窄的任务（例如，欺诈检测、贷款评分） | 提供广泛的能力，可以适应许多任务和用例 |'
- en: '| Data input | Domain-specific structured or unstructured data (e.g., tabular
    data, images) | Massive and diverse cross-domain datasets (e.g., internet text,
    code, audio, images) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 数据输入 | 领域特定的结构化或非结构化数据（例如，表格数据、图像） | 巨大且多样化的跨领域数据集（例如，互联网文本、代码、音频、图像） |'
- en: '| Output | Prediction, classification, regression, or recommendation for a
    specific task | Versatile outputs: text, code, reasoning, vision tasks, language
    understanding, etc. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 输出 | 对特定任务的预测、分类、回归或推荐 | 多样化的输出：文本、代码、推理、视觉任务、语言理解等 |'
- en: '| Downstream use | Purpose-built systems with known users and applications
    | Can be adapted and fine-tuned by third parties for diverse and evolving applications
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 下游使用 | 为已知用户和应用程序量身定制的系统 | 可由第三方适应和微调，用于多样化的和不断发展的应用 |'
- en: '| Examples | Predictive maintenance models, fraud detection systems | GPT-4,
    Gemini, LLaMA, Mistral, DALL·E |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 例子 | 预测性维护模型、欺诈检测系统 | GPT-4、Gemini、LLaMA、Mistral、DALL·E |'
- en: '| Algorithms | Decision trees, XGBoost, CNNs, RNNs | Large-scale Transformer-based
    architectures, foundation models (e.g., LLMs, vision language models) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 决策树、XGBoost、CNNs、RNNs | 基于大型Transformer架构、基础模型（例如，LLMs、视觉语言模型） |'
- en: '| Evaluation | Task-specific metrics: accuracy, F1 score, AUC-ROC, MAE/RMSE
    | Evaluated across a wide range of tasks using general benchmarks (e.g., MMLU,
    HELM), robustness, bias, toxicity |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 评估 | 任务特定指标：准确率、F1分数、AUC-ROC、MAE/RMSE | 在广泛的任务中使用通用基准（例如，MMLU、HELΜ），评估鲁棒性、偏差、毒性
    |'
- en: GenAIOps—Operationalizing EU AI Act Compliance for GPAI
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GenAIOps——实施欧盟AI法案对GPAI的合规性
- en: GenAIOps is the systematic extension of DevOps and MLOps principles to meet
    the unique challenges of developing, deploying, and maintaining GPAI models and
    systems, including LLMs, image and video generators, and other foundation models.
    While traditional MLOps focuses on managing predictive models, GenAIOps must support
    the adaptation and governance of powerful generative models that may be used for
    a wide range of downstream tasks. This includes practices such as prompt engineering,
    retrieval-augmented generation (RAG), foundation model fine-tuning, and real-time
    monitoring for issues like hallucinations, bias, and safety risks. These needs
    introduce additional complexity in areas ranging from data governance to infrastructure,
    safety monitoring, and responsible use—especially in the context of compliance
    with regulatory frameworks like the EU AI Act.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps是DevOps和MLOps原则的系统扩展，以应对开发、部署和维护GPAI模型和系统（包括LLMs、图像和视频生成器以及其他基础模型）的独特挑战。虽然传统的MLOps侧重于管理预测模型，但GenAIOps必须支持用于广泛下游任务的强大生成模型的适应和治理。这包括提示工程、检索增强生成（RAG）、基础模型微调和针对特定下游用例的实时监控，如幻觉、偏差和安全风险。这些需求在数据治理到基础设施、安全监控和负责任使用等方面引入了额外的复杂性——特别是在符合欧盟AI法案等监管框架的背景下。
- en: '[Figure 7-3](#chapter_7_figure_3_1748539924514373) visualizes the operational
    stages for GPAI models and how they map to the CRISP-ML(Q) development phases.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-3](#chapter_7_figure_3_1748539924514373)展示了GPAI模型的操作阶段以及它们如何映射到CRISP-ML(Q)开发阶段。'
- en: '![](assets/taie_0703.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/taie_0703.png)'
- en: Figure 7-3\. CRISP-ML(Q) framework for GPAI models and systems
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. GPAI模型和系统的CRISP-ML(Q)框架
- en: Key Components
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关键组件
- en: GenAIOps integrates automated pipelines, model versioning, and observability
    with inference optimization, safety guardrails, and compliance workflows to create
    a comprehensive framework for responsible GPAI deployment. This approach ensures
    that GPAI models operate with transparency and auditability in production environments
    while addressing concerns about misinformation, synthetic content attribution,
    and compliance with applicable regulatory requirements.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps将自动化管道、模型版本控制、可观察性与推理优化、安全防护和合规工作流程集成，以创建一个全面的责任GPAI部署框架。这种方法确保GPAI模型在生产环境中以透明和可审计的方式运行，同时解决关于虚假信息、合成内容归属和符合适用监管要求的问题。
- en: 'Key components of GenAIOps include the following (summarized in [Figure 7-4](#chapter_7_figure_4_1748539924514393)):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps的关键组件包括以下内容（总结于[图7-4](#chapter_7_figure_4_1748539924514393)）：
- en: Prompt engineering infrastructure
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程基础设施
- en: Tools for managing prompt creation, testing, versioning, and orchestration,
    in particular for complex reasoning chains and RAG systems.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 管理提示创建、测试、版本控制和编排的工具，特别是针对复杂的推理链和RAG系统。
- en: Inference optimization
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 推理优化
- en: Techniques such as quantization, caching, and model distillation to reduce latency,
    cost, and resource usage in deployment environments.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过量化、缓存和模型蒸馏等技术来减少部署环境中的延迟、成本和资源使用。
- en: Continuous evaluation
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 持续评估
- en: Real-time monitoring systems to detect hallucinations and performance drift,
    and mechanisms to collect human feedback for ongoing model refinement.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实时监控系统以检测幻觉和性能漂移，以及收集人类反馈以持续改进模型的机制。
- en: Safety and content controls
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 安全和内容控制
- en: Automated content filtering, watermarking, red-teaming protocols, and risk assessment
    workflows to ensure responsible and secure AI outputs.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 自动内容过滤、水印、红队协议和风险评估工作流程，以确保负责任和安全的AI输出。
- en: Governance and compliance
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 管理和合规
- en: Transparent documentation (e.g., model cards), content provenance systems, and
    comprehensive audit trails to meet evolving regulatory requirements and ethical
    standards.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 透明文档（例如，模型卡片）、内容溯源系统和全面的审计跟踪，以满足不断变化的监管要求和道德标准。
- en: Foundation model adaptation
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型适应
- en: Fine-tuning workflows, reinforcement learning from human feedback (RLHF), and
    parameter-efficient methods (e.g., LoRA) to customize models for specific downstream
    use cases.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 微调工作流程、从人类反馈中进行强化学习（RLHF）和参数高效方法（例如LoRA）以定制特定下游用例的模型。
- en: '![](assets/taie_0704.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/taie_0704.png)'
- en: Figure 7-4\. Key components of GenAIOps
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4\. GenAIOps的关键组件
- en: How GenAIOps Extends MLOps
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAIOps如何扩展MLOps
- en: The core goals of MLOps, which is mainly focused on the lifecycle of predictive
    ML models, are reproducibility, scalability, and continuous delivery. GenAIOps
    retains these goals but adapts them to the specific needs of GPAI. For example,
    generative AI applications must operate on unstructured data at scale, incorporate
    prompt engineering and human-in-the-loop feedback mechanisms, and ensure that
    outputs are not only high quality but also safe, transparent, and appropriately
    labeled. [Table 7-3](#chapter_7_table_3_1748539924522354) outlines key differences
    between MLOps and GenAIOps across several areas, such as data management, model
    training and adaptation, model deployment and inference, monitoring, and ethics
    and regulations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的核心目标，主要关注预测性机器学习模型的生命周期，包括可重复性、可扩展性和持续交付。GenAIOps保留了这些目标，但将其适应于GPAI的具体需求。例如，生成式AI应用必须在规模上处理非结构化数据，整合提示工程和人工反馈机制，并确保输出不仅质量高，而且安全、透明且适当标记。[表7-3](#chapter_7_table_3_1748539924522354)概述了MLOps和GenAIOps在多个领域的关键区别，例如数据管理、模型训练和适应、模型部署和推理、监控以及伦理和法规。
- en: Table 7-3\. Key differences between MLOps and GenAIOps
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-3\. MLOps与GenAIOps的关键区别
- en: '| Aspect | MLOps (predictive ML) | GenAIOps (GPAI) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Aspect | MLOps（预测性ML） | GenAIOps（GPAI）|'
- en: '| --- | --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Data management | Focuses on curated, labeled datasets, feature engineering,
    and versioning of training data pipelines. Data is often structured and tabular
    or limited to task-specific corpora. | Handles massive, unstructured datasets
    (text, images, audio). Embraces synthetic data generation for augmentation and
    requires robust data filtering to remove toxic or biased content from training
    corpora (to avoid amplifying harms). Uses embedding management (vector representations
    of data) in place of traditional feature stores to enable RAG, typically via vector
    databases. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 数据管理 | 专注于精心整理、标记的数据集、特征工程和训练数据管道的版本控制。数据通常是结构化和表格化的，或限于特定任务的语料库。 | 处理大规模、非结构化数据集（文本、图像、音频）。接受合成数据生成以增强数据，并需要强大的数据过滤来从训练语料库中移除有毒或偏见的内容（以避免放大危害）。使用嵌入管理（数据的向量表示）代替传统的特征存储，以实现RAG，通常通过向量数据库实现。|'
- en: '| Model training and adaptation | Models are trained from scratch or with transfer
    learning, with hyperparameter tuning and model selection based on task-specific
    data. Models are typically smaller and trained to converge on labeled data. |
    Starts from large, pretrained foundation models. Uses parameter-efficient fine-tuning
    (e.g., LoRA, adapter layers), prompt engineering, and few-shot learning instead
    of full retraining. Techniques like direct preference optimization (DPO) and RLHF
    are applied to align model behavior with human preferences. Experiment tracking
    must include prompt versions and chain configurations, not just model parameters.
    |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 模型训练和适应 | 从头开始训练模型或使用迁移学习，基于特定任务的数据进行超参数调整和模型选择。模型通常较小，并训练以收敛到标记数据。 | 从大型、预训练的基础模型开始。使用参数高效的微调（例如，LoRA、适配器层）、提示工程和少样本学习，而不是完全重新训练。应用直接偏好优化（DPO）和RLHF等技术，以使模型行为与人类偏好一致。实验跟踪必须包括提示版本和链配置，而不仅仅是模型参数。|'
- en: '| Model deployment and inference | Models are deployed as microservices or
    batch jobs behind REST APIs, using standard scaling, CI/CD, and version control.
    Inference usually involves a single-model prediction call (e.g., a classification
    API). | Deployment requires specialized infrastructure (GPUs or TPUs, high memory
    usage). Focuses on real-time inference for generative outputs, often with streaming
    responses due to longer outputs (e.g., for chatbots). Frequently involves orchestrating
    multiple models and tools and managing prompt pipelines and session context. Optimization
    techniques such as model quantization, caching of outputs, and load balancing
    are applied to manage heavy inference loads. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 模型部署和推理 | 模型作为微服务或REST API背后的批处理作业部署，使用标准扩展、CI/CD和版本控制。推理通常涉及单个模型的预测调用（例如，分类API）。
    | 部署需要专门的硬件基础设施（GPU或TPU，高内存使用）。专注于生成式输出的实时推理，通常由于输出较长（例如，聊天机器人）而有流式响应。经常涉及协调多个模型和工具，以及管理提示管道和会话上下文。应用模型量化、输出缓存和负载均衡等优化技术来管理重推理负载。|'
- en: '| Monitoring and continuous improvement | Model performance (accuracy, latency)
    and data drift are monitored in production. User feedback may trigger periodic
    retraining or model updates. Rollback mechanisms minimize downtime in case of
    failures. When using third-party models, custom evaluation sets may be needed
    to detect behavioral changes between versions. | Output quality and safety risks
    (hallucinations, toxicity, bias) are monitored, in addition to standard performance
    metrics. Requires continuous evaluation loops and human feedback to guide improvements.
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 监控和持续改进 | 在生产中监控模型性能（准确性、延迟）和数据漂移。用户反馈可能触发定期重新训练或模型更新。回滚机制在出现故障时最小化停机时间。当使用第三方模型时，可能需要自定义评估集来检测版本之间的行为变化。
    | 除了标准性能指标外，还监控输出质量和安全风险（幻觉、毒性、偏见）。需要持续评估循环和人工反馈来指导改进。|'
- en: '| Regulatory and ethical considerations | Focuses on fairness, bias mitigation,
    explainability, and compliance in decision-making contexts (e.g., loan approvals).
    Models are accompanied by comprehensive documentation (e.g., model cards, bias
    audits). | Faces new ethical and regulatory challenges: GPAI models can produce
    misinformation, harmful content, and deepfakes and can potentially be used for
    impersonation. Must support emerging requirements, such as labeling AI-generated
    content and ensuring transparency and traceability. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 监管和伦理考量 | 重点关注决策环境（例如，贷款审批）中的公平性、偏见缓解、可解释性和合规性。模型伴随全面的文档（例如，模型卡片、偏见审计）。 |
    面临新的伦理和监管挑战：GPAI模型可能产生错误信息、有害内容、深度伪造，并且可能被用于冒名顶替。必须支持新兴要求，例如标记AI生成内容，并确保透明性和可追溯性。|'
- en: GenAIOps Tools, Workflows, and Frameworks to Support Transparency
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持透明度的GenAIOps工具、工作流程和框架
- en: 'GenAIOps builds on MLOps by adding capabilities like prompt management, chain-of-thought
    orchestration, synthetic data generation, and stringent output controls to address
    the unique demands of GPAI. It’s also essential for ensuring transparency in GPAI
    models and systems, as mandated by regulations like the EU AI Act. The transparency
    obligations outlined in Article 50 of the Act, which we discussed in detail in
    [Chapter 6](ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988),
    apply to both providers and deployers of generative AI systems (as well as predictive
    ML systems). Meeting these obligations and effectively managing GenAI-related
    risks requires cross-disciplinary collaboration among data engineers, model developers,
    user experience designers, and ethics and compliance teams. The following GenAIOps
    tools and workflows can support this effort:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps在MLOps的基础上增加了提示管理、思维链编排、合成数据生成和严格的输出控制等功能，以应对GPAI的独特需求。这对于确保GPAI模型和系统的透明性也至关重要，这是欧盟AI法案等法规所要求的。法案第50条中概述的透明度义务，我们在[第6章](ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988)中详细讨论过，适用于生成式AI系统的提供者和部署者（以及预测性机器学习系统）。满足这些义务并有效管理与GenAI相关的风险需要数据工程师、模型开发者、用户体验设计师和伦理合规团队之间的跨学科合作。以下GenAIOps工具和工作流程可以支持这一努力：
- en: Prompt and chain management
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 即时和链式管理
- en: Frameworks like LangChain and NVIDIA NeMo can be used to orchestrate complex
    prompt workflows and ensure that required system prompts (including AI self-identification)
    are consistently included in user interactions. These tools also support prompt
    versioning, testing, and traceability.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用LangChain和NVIDIA NeMo等框架来编排复杂的提示工作流程，并确保所需系统提示（包括AI自我识别）在用户交互中始终一致。这些工具还支持提示版本控制、测试和可追溯性。
- en: Content watermarking and metadata
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 内容水印和元数据
- en: Libraries and APIs compliant with the C2PA (Content Provenance and Authenticity)
    standard are increasingly being integrated into image and video generation pipelines.
    For example, OpenAI’s DALL·E API [automatically adds C2PA metadata](https://oreil.ly/djcGb)
    to its outputs. There are also third-party services, such as Stability’s Stable
    Diffusion plug-ins or [Steg.AI](https://oreil.ly/PGrpq), that insert invisible
    watermarks into images for later verification. GenAIOps pipelines can call these
    services post-generation. For text-based content, research into statistical watermarking
    is also advancing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 符合C2PA（内容溯源和真实性）标准的库和API正越来越多地集成到图像和视频生成管道中。例如，OpenAI的DALL·E API [自动添加C2PA元数据](https://oreil.ly/djcGb)到其输出中。还有第三方服务，如Stability的Stable
    Diffusion插件或[Steg.AI](https://oreil.ly/PGrpq)，它们将不可见的水印嵌入到图像中，以便稍后进行验证。GenAIOps管道可以在生成后调用这些服务。对于基于文本的内容，统计水印的研究也在不断进步。
- en: Monitoring and detection services
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和检测服务
- en: To complement watermarks, GenAIOps can integratedeepfake detection models and
    content moderation AI into the monitoring stack. For instance, an enterprise might
    deploy a vision model that scans newly uploaded videos for signs of manipulation.
    If AI-generated media lacks the required disclosure, the detection system can
    flag it for review. Cloud providers are beginning to offer APIs for this purpose
    (e.g., Azure’s Video Authenticator and AWS’s Rekognition).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了补充水印，GenAIOps可以将deepfake检测模型和内容审核AI集成到监控堆栈中。例如，企业可能会部署一个视觉模型，用于扫描新上传的视频中的操纵迹象。如果AI生成的媒体缺少必要的披露，检测系统可以将其标记为需要审查。云服务提供商开始提供用于此目的的API（例如，Azure的视频验证器和AWS的Rekognition）。
- en: Guardrails and policy enforcement
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 防护栏和政策执行
- en: Guardrail frameworks such as NVIDIA NeMo Guardrails or the open source Guardrails
    AI library can be used to enforce policy at runtime by intercepting model outputs
    before they reach the user. They can automatically append disclaimers or block
    content that should be labeled as synthetic but isn’t. For example, if a user
    prompts a GPAI model to generate a fake image of a person, a guardrail can attach
    a “Fake Image” label to the output. Similarly, an audible cue can be injected
    into audio content. These enforcement steps are configured directly within the
    inference pipeline.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用NVIDIA NeMo Guardrails或开源Guardrails AI库等防护栏框架，通过在模型输出到达用户之前拦截模型输出来在运行时执行策略。它们可以自动添加免责声明或阻止应标记为合成但未标记的内容。例如，如果用户提示GPAI模型生成一个人的假图像，防护栏可以将“假图像”标签附加到输出上。同样，可以在音频内容中注入可听提示。这些执行步骤直接在推理管道中配置。
- en: Logging and versioning
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 记录和版本控制
- en: Prompts, responses, and content artifacts can be comprehensively logged using
    platforms like MLflow, Weights & Biases, or Arize AI that support GenAIOps features.
    These logs provide a robust audit trail that can verify, for example, whether
    a watermarking function ran and what output it produced.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用支持GenAIOps功能的平台（如MLflow、Weights & Biases或Arize AI）可以全面记录提示、响应和内容工件。这些日志提供了强大的审计跟踪，可以验证，例如，水印功能是否运行以及它产生了什么输出。
- en: In the remainder of this chapter, we’ll explore how the SMACTR framework introduced
    in the previous chapter can be integrated into the different phases of the CRISP-ML(Q)
    lifecycle, providing a practical foundation for operationalizing compliance in
    the development and deployment of GPAI models and systems.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将探讨上一章中引入的SMACTR框架如何集成到CRISP-ML(Q)生命周期的不同阶段，为GPAI模型和系统的开发和部署中的合规性操作提供实际基础。
- en: Aligning AI Engineering with SMACTR and CRISP-ML(Q) for Transparency
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将AI工程与SMACTR和CRISP-ML(Q)对齐以实现透明度
- en: '[Chapter 6](ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988)
    provided a detailed guide for AI engineers on achieving proactive compliance with
    the transparency requirements outlined in Article 50 of the EU AI Act. This section
    applies the same approach to GPAI models and systems, incorporating GenAIOps principles.
    By integrating the SMACTR framework with the CRISP-ML(Q) methodology, teams can
    establish a robust, auditable process for responsible development and deployment
    of general-purpose AI.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988)为AI工程师提供了实现欧盟AI法案第50条规定的透明度要求的主动合规性的详细指南。本节将相同的做法应用于GPAI模型和系统，并纳入GenAIOps原则。通过将SMACTR框架与CRISP-ML(Q)方法相结合，团队可以建立一套稳健、可审计的过程，以负责地开发和部署通用AI。'
- en: Business and Data Understanding Phase
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业和数据理解阶段
- en: GenAIOps is generally broken down into three main operational phases (see [Figure 7-3](#chapter_7_figure_3_1748539924514373)).
    The initial phase encompasses tasks related to use case definition and data requirements
    planning that precede full-scale data engineering. It also includes early data
    engineering activities such as clarifying the application’s purpose and identifying
    data sources. For example, before building an LLM-powered system, teams must define
    the business problem (e.g., “customer support chatbot” versus “code generation
    assistant”) and assess what data and model capabilities are needed to solve it
    efficiently. This aligns closely with the business and data understanding phase
    of the CRISP-ML(Q) methodology.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps通常分为三个主要操作阶段（见[图7-3](#chapter_7_figure_3_1748539924514373)）。初始阶段包括与用例定义和数据需求规划相关的任务，这些任务在全面数据工程之前进行。它还包括早期数据工程活动，如明确应用程序的目的和确定数据来源。例如，在构建一个由LLM驱动的系统之前，团队必须定义业务问题（例如，“客户支持聊天机器人”与“代码生成助手”），并评估解决该问题所需的数据和模型能力。这与CRISP-ML(Q)方法中的业务和数据理解阶段紧密一致。
- en: The first step is translating business goals into ML/LLM objectives—that is,
    determining what you want the model to do, and what data or base models that will
    require. For instance, if the goal is to develop a Q&A chatbot, GenAIOps teams
    must decide whether to use an existing Q&A model or fine-tune a base LLM, and
    identify the relevant domain data. This reflects CRISP-ML(Q)’s emphasis that business
    objectives and data constraints should be considered jointly to avoid building
    “the right answers to the wrong questions.”
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将业务目标转化为机器学习/大型语言模型（LLM）目标——也就是说，确定你希望模型做什么，以及需要哪些数据或基础模型。例如，如果目标是开发一个问答聊天机器人，GenAIOps团队必须决定是使用现有的问答模型还是微调基础LLM，并确定相关的领域数据。这反映了CRISP-ML(Q)强调业务目标和数据约束应共同考虑，以避免构建“对错问题的正确答案”。
- en: Early alignment on objectives, success criteria, and constraints shapes all
    subsequent work. CRISP-ML(Q) calls for success metrics to be defined at the business,
    ML, and system levels. GenAIOps expands this by requiring that user experience
    goals and ethical considerations also be addressed from the start—including expectations
    for model behavior, tone, and safety.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标、成功标准和约束方面的早期一致，塑造了所有后续工作。CRISP-ML(Q)要求在业务、机器学习和系统层面定义成功指标。GenAIOps通过要求从开始就解决用户体验目标和伦理考量来扩展这一点——包括对模型行为、语气和安全性的预期。
- en: Implementation
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施
- en: Integrating CRISP-ML(Q) practices into GenAIOps at this stage means rigorously
    documenting requirements, constraints, and success criteria. In practice, the
    engineering team should convene domain experts, data scientists, and LLM engineers
    to define the scope of the GenAI application before development begins. The success
    criteria will go beyond classic metrics like accuracy or ROI to include measures
    of output quality (e.g., fluency, relevance) and safety (e.g., absence of harmful
    or biased content). An early feasibility assessment is crucial; if a required
    dataset is unavailable or the task is ill-suited to LLMs, that should be determined
    up front.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段将CRISP-ML(Q)实践整合到GenAIOps中意味着严格记录需求、约束和成功标准。在实践中，工程团队应在开发开始之前召集领域专家、数据科学家和LLM工程师，定义GenAI应用程序的范围。成功标准将超越经典指标如准确度或ROI，包括输出质量（例如，流畅性、相关性）和安全性的衡量（例如，不存在有害或偏见的内容）。早期可行性评估至关重要；如果所需的dataset不可用或任务不适合LLM，这一点应在前期确定。
- en: In GenAIOps, this phase often involves selecting an initial base model appropriate
    to the task. For example, the choice between a proprietary LLM like GPT-4 or a
    smaller open source model will depend on business needs and constraints such as
    cost, latency, and data privacy. Similar to algorithm selection in predictive
    ML projects, base model selection in GenAI is a key decision that should be guided
    by the problem scope and data requirements. For example, if the application involves
    sensitive or domain-specific content, a smaller fine-tuned model trained on proprietary
    data might be preferred over a general-purpose LLM. Documenting the decision and
    its rationale will help maintain clarity and transparency as the project progresses.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GenAIOps 中，此阶段通常涉及选择一个适合任务的初始基础模型。例如，选择专有的大型语言模型（LLM）如 GPT-4 或较小的开源模型将取决于业务需求和约束，如成本、延迟和数据隐私。与预测性机器学习项目中的算法选择类似，GenAI
    中的基础模型选择是一个关键决策，应受问题范围和数据需求指导。例如，如果应用涉及敏感或特定领域的内 容，则可能更倾向于使用在专有数据上训练的小型微调模型，而不是通用的大型语言模型。记录决策及其理由将有助于在项目进展过程中保持清晰和透明。
- en: SMACTR integration
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR 集成
- en: The Scoping and Mapping stages from the SMACTR framework are most relevant in
    this initial phase.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR 框架中的范围界定和映射阶段在此初始阶段最为相关。
- en: In the Scoping stage, the team conducts a preliminary risk assessment and an
    ethical review of the intended use cases. For a GenAI project, this involves asking
    how the application might affect users or stakeholders (e.g., “Could the chatbot
    give harmful advice or leak private data?”). Defining the ethical AI principles
    the project will follow is also part of this stage. Key outputs, such as a social
    impact assessment, help ensure the application’s design considers and takes steps
    to mitigate potential harms and aligns with the organization’s values and AI ethics
    guidelines.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在范围界定阶段，团队进行初步风险评估和对预期用例的伦理审查。对于一个 GenAI 项目来说，这包括询问应用可能如何影响用户或利益相关者（例如，“聊天机器人可能会给出有害的建议或泄露私人数据吗？”）。定义项目将遵循的伦理人工智能原则也是此阶段的一部分。关键输出，如社会影响评估，有助于确保应用的设计考虑并采取措施减轻潜在危害，并与组织的价值观和人工智能伦理指南保持一致。
- en: In the Mapping stage, the focus shifts to identifying stakeholders and collaborators.
    In a GenAIOps context, this means mapping who needs to be involved—for example,
    data owners for access to data sources, compliance or legal experts if user data
    or intellectual property is involved, and end-user representatives. This stakeholder
    map promotes accountability and traceability by clarifying who is responsible
    for which inputs and decisions.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在映射阶段，重点转向识别利益相关者和合作者。在 GenAIOps 的背景下，这意味着确定需要参与的人员——例如，数据所有者以获取数据源，如果涉及用户数据或知识产权，则可能需要合规或法律专家，以及最终用户代表。此利益相关者图通过明确谁负责哪些输入和决策，促进了问责制和可追溯性。
- en: Incorporating Scoping and Mapping into the business and data understanding phase
    helps teams working on GenAI projects mitigate strategic risks before any data
    is collected or model work begins, reducing the chances of building a misaligned
    or unsafe product.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 将范围界定和映射纳入业务和数据理解阶段有助于 GenAI 项目团队在收集任何数据或开始模型工作之前减轻战略风险，减少构建不匹配或不安全产品的可能性。
- en: '[Table 7-4](#chapter_7_table_4_1748539924522377) provides an outline of key
    artifacts that should be produced during this phase.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 7-4](#chapter_7_table_4_1748539924522377) 提供了在此阶段应产生的关键工件的概述。'
- en: Table 7-4\. Summary of artifacts produced during the business and data understanding
    phase
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7-4\. 业务和数据理解阶段产生的工件总结
- en: '| SMACTR stage | Key artifacts |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR 阶段 | 关键工件 |'
- en: '| --- | --- |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Scoping |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 范围界定 |'
- en: Preliminary risk assessment
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初步风险评估
- en: Ethical review of intended use cases
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对预期用例的伦理审查
- en: Definition of ethical AI principles for the project
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义项目中的伦理人工智能原则
- en: Statement of alignment with corporate values and AI ethics guidelines
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与企业价值观和人工智能伦理指南的一致性声明
- en: '|'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Mapping |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 映射 |'
- en: Identification of stakeholders and collaborators (e.g., data owners, compliance/legal
    experts, end users)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别利益相关者和合作者（例如，数据所有者、合规/法律专家、最终用户）
- en: Stakeholder map
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利益相关者图
- en: '|'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Data Preparation Phase
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备阶段
- en: CRISP-ML(Q)’s data preparation phase, in a GenAI context, includes steps such
    as gathering large-scale text data, cleaning and filtering it, and preparing it
    for model input (for example, performing tokenization and formatting). If the
    GenAI solution involves fine-tuning an LLM or training a domain-specific model,
    this phase will incorporate assembling the fine-tuning dataset and any prompt
    templates. It may also involve setting up a knowledge base for retrieval-augmented
    generation, which is a unique data component in GenAIOps not typically present
    in traditional ML pipelines. The goal of the data preparation phase remains the
    same—to ensure that the data fed into the model is high quality, relevant, and
    appropriately prepared—whether it’s tabular data for classic ML or unstructured
    text and prompt data for LLMs.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GenAI 的背景下，CRISP-ML(Q) 的数据准备阶段包括收集大规模文本数据、清理和过滤它以及为模型输入做准备（例如，执行分词和格式化）等步骤。如果
    GenAI 解决方案涉及微调 LLM 或训练特定领域的模型，此阶段将包括组装微调数据集和任何提示模板。它还可能涉及设置用于检索增强生成的知识库，这是 GenAIOps
    中独特的数据组件，在传统的机器学习管道中通常不存在。数据准备阶段的目标保持不变——确保输入到模型中的数据是高质量的、相关的且适当准备好的——无论是用于经典机器学习的表格数据还是用于
    LLMs 的非结构化文本和提示数据。
- en: 'Data quality directly affects model success. CRISP-ML(Q) emphasizes robust
    data handling by selecting the right data, cleaning it to remove noise, normalizing
    it, engineering features, and standardizing formats. GenAIOps extends MLOps to
    address the unique challenges of working with GenAI models. One major difference
    is that traditional feature engineering is unnecessary for LLMs. Instead, GenAIOps
    focuses on prompt engineering and data curation—for example, crafting prompt examples
    or structuring input/output pairs to teach the model a task. Another key difference
    is scale and diversity: GenAI applications often require large-scale data collection
    with an emphasis on diversity and representativeness to avoid bias or blind spots.
    If labeling is needed for fine-tuning or RLHF data, GenAIOps might use semi-automated
    techniques such as pre-labeling with another model or active learning.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量直接影响模型的成功。CRISP-ML(Q) 强调通过选择合适的数据、清理以去除噪声、归一化、特征工程和标准化格式来稳健地处理数据。GenAIOps
    将 MLOps 扩展到解决与 GenAI 模型一起工作的独特挑战。一个主要区别是，对于大型语言模型 (LLMs) 来说，传统的特征工程是不必要的。相反，GenAIOps
    专注于提示工程和数据整理——例如，制作提示示例或结构化输入/输出对以教会模型一项任务。另一个关键区别是规模和多样性：GenAI 应用通常需要大规模数据收集，强调多样性和代表性，以避免偏差或盲点。如果需要为微调或
    RLHF 数据进行标记，GenAIOps 可能会使用半自动技术，例如使用另一个模型进行预标记或主动学习。
- en: Implementation
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施
- en: 'Data preparation involves implementing systematic data quality checks and creating
    thorough documentation. In practice, the engineering team should treat the text
    corpora or prompt datasets with the same discipline as curated ML datasets. Key
    activities include:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备涉及实施系统性的数据质量检查和创建详尽的文档。在实践中，工程团队应将文本语料库或提示数据集视为与精心制作的机器学习数据集相同的学科。关键活动包括：
- en: Data selection and sourcing
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 数据选择和来源
- en: Identify and collect data from multiple sources (e.g., internal documents, public
    datasets, web-scraped text) relevant to the use case. GenAIOps emphasizes automating
    this process and continuously ingesting new data if the application requires up-to-date
    information.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从多个来源（例如，内部文档、公共数据集、网络抓取的文本）识别和收集与用例相关的数据。GenAIOps 强调自动化此过程，并在需要最新信息的应用中持续摄取新数据。
- en: Data cleaning
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗
- en: Filter out problematic content, such as profanity, personally identifiable information,
    or offensive text, to prevent the model from learning undesirable patterns. Both
    MLOps and GenAIOps stress the importance of dataset heterogeneity to reduce bias
    and overfitting. Tools like [Data-Juicer](https://oreil.ly/5wr6H) can help with
    auditing dataset diversity.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤掉有问题的内容，例如粗俗语言、个人可识别信息或冒犯性文本，以防止模型学习到不希望的模式。MLOps 和 GenAIOps 都强调数据集异质性的重要性，以减少偏差和过拟合。像
    [Data-Juicer](https://oreil.ly/5wr6H) 这样的工具可以帮助审计数据集的多样性。
- en: Data structuring
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构
- en: In traditional ML, this involves tasks like normalizing values or formatting
    comma-separated values. In GenAI, it includes tokenizing raw text, splitting documents,
    and adding prompt prefixes or suffixes. It can also involve prompt engineering
    at the dataset level—that is, constructing input/output pairs that demonstrate
    the task for fine-tuning or evaluation.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习中，这包括诸如归一化值或格式化逗号分隔值等任务。在生成式AI中，这包括对原始文本进行分词、分割文档以及添加提示前缀或后缀。它还可能涉及数据集级别的提示工程——即构建用于微调或评估的任务输入/输出对。
- en: Embeddings
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入
- en: GenAI data prep should account for dynamic data, meaning that if the application
    will retrieve documents at runtime (RAG), the team will need to set up an indexed
    vector database and pipelines to update it with new content. This is an extra
    operational consideration in GenAIOps to keep a knowledge base fresh.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI数据准备应考虑动态数据，这意味着如果应用程序将在运行时检索文档（RAG），团队将需要设置索引向量数据库和管道以更新新内容。这是GenAIOps中额外的运营考虑因素，以保持知识库的更新。
- en: Documentation
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 文档
- en: For GenAIOps, recording details like data sources, preprocessing steps, and
    known limitations of the dataset is crucial. This supports transparency (e.g.,
    via datasheets for datasets) and helps ensure auditability if issues arise later.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GenAIOps，记录数据来源、预处理步骤和数据集已知限制的细节至关重要。这支持透明度（例如，通过数据集的数据表）并有助于确保在以后出现问题时可审计性。
- en: SMACTR integration
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR集成
- en: The Artifact Collection stage of SMACTR is particularly relevant during data
    preparation. As the team curates the dataset, they should also compile audit artifacts,
    including a comprehensive checklist to verify that all required documentation
    is in place and datasheets that capture data lineage, assumptions, etc. This implements
    quality assurance by design. Before modeling starts, auditors or internal QA reviewers
    should confirm that the dataset meets defined standards and that any potential
    biases or data limitations have been logged. For GenAI projects, this step helps
    surface issues like skewed representation in training data (say, underrepresentation
    of certain user demographics in a chatbot’s training data) so they can be addressed
    (e.g., by augmenting the dataset with more representative samples).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR的工件收集阶段在数据准备期间尤其相关。随着团队整理数据集，他们还应编制审计工件，包括一个全面的清单以验证所有必需的文档都已到位，以及捕获数据来源、假设等的数据表。这通过设计实现质量保证。在建模开始之前，审计员或内部质量保证审查员应确认数据集符合既定标准，以及任何潜在的偏差或数据限制都已记录。对于GenAI项目，这一步骤有助于揭示训练数据中的偏差问题（例如，聊天机器人训练数据中某些用户群体的代表性不足），以便加以解决（例如，通过增加更具代表性的样本来扩充数据集）。
- en: The insights from the Scoping stage also feed into data preparation. For instance,
    if privacy risks were identified, the data pipeline should incorporate appropriate
    mitigation steps such as data minimization or anonymization.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 范围界定阶段的见解也反馈到数据准备中。例如，如果识别出隐私风险，数据管道应纳入适当的缓解步骤，如数据最小化或匿名化。
- en: Finally, the team should begin planning for how data-related risks will be handled
    in testing. SMACTR’s Testing stage often draws on documented issues and failures,
    so any concerns that are identified during the data preparation phase should be
    noted (e.g., “Our dataset might not cover slang—possible failure mode for the
    chatbot”).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，团队应开始规划如何在测试中处理与数据相关的风险。SMACTR的测试阶段通常借鉴已记录的问题和失败案例，因此，在数据准备阶段识别出的任何担忧都应予以记录（例如，“我们的数据集可能不包含俚语——聊天机器人可能的失败模式”）。
- en: '[Table 7-5](#chapter_7_table_5_1748539924522398) summarizes the key artifacts
    that should be produced during the data preparation phase. By treating data as
    an auditable artifact, supported by checklists, datasheets, and bias analysis,
    GenAIOps can incorporate SMACTR’s accountability early in the pipeline.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[表7-5](#chapter_7_table_5_1748539924522398)总结了在数据准备阶段应产生的关键工件。通过将数据视为可审计的工件，并支持清单、数据表和偏差分析，GenAIOps可以在管道早期就纳入SMACTR的问责制。'
- en: Table 7-5\. Summary of key artifacts produced during the data preparation phase
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-5\. 数据准备阶段产生的关键工件概要
- en: '| SMACTR stage | Output |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR阶段 | 输出 |'
- en: '| --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Artifact Collection |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 工件收集 |'
- en: Datasheets (data documentation) detailing data lineage, assumptions, etc.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 详细说明数据来源、假设等的数据表（数据文档）。
- en: Log of identified biases or limitations in the dataset
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中识别出的偏差或限制日志
- en: '|'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Scoping |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 范围界定 |'
- en: Documentation of privacy risks that might require additional data privacy controls
    during preparation or training
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在准备或训练期间可能需要额外数据隐私控制的隐私风险文档
- en: '|'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Testing (planning during data prep) |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 测试（在数据准备期间规划） |'
- en: Notes on potential data-related risks
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于潜在数据相关风险的注意事项
- en: Preliminary plans for how these risks will be handled in testing
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在测试中处理这些风险的初步计划
- en: '|'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Modeling Phase
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模阶段
- en: 'In GenAIOps, during the modeling phase the base model is chosen or built and
    adapted to the task. The base model selection and domain adaptation steps include
    prompt engineering, fine-tuning, or RAG. For a traditional ML project, modeling
    entails selecting algorithms, tuning hyperparameters, and training the model from
    scratch on prepared data. In a GenAI project, you’re usually starting with a preexisting
    model, such as a large pretrained transformer, so “modeling” is more about *adapting*
    that model: choosing which LLM to use as a starting point, deciding whether to
    fine-tune it or use it via prompting, and implementing those adaptations. For
    example, if building a custom chatbot, the team might take a base model like GPT,
    fine-tune it on their domain data, and craft a prompt strategy.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAIOps中，建模阶段会选择或构建基础模型，并将其适应于任务。基础模型选择和领域适应步骤包括提示工程、微调或RAG。对于传统的机器学习项目，建模包括选择算法、调整超参数，并在准备好的数据上从头开始训练模型。在GenAI项目中，你通常从一个预存在的模型开始，例如一个大型预训练的Transformer，因此“建模”更多地关于*适应*该模型：选择哪个LLM作为起点，决定是否微调它或通过提示使用它，并实施这些适应。例如，如果构建一个定制的聊天机器人，团队可能会选择一个基础模型如GPT，在其领域数据上微调它，并制定提示策略。
- en: CRISP-ML(Q) underscores modeling practices such as ensuring reproducibility
    of experiments, trying multiple modeling techniques, and aligning the model choice
    with business objectives. In GenAI application development, the choice of model
    and the corresponding prompt or fine-tuning strategy must align with the use case
    constraints (latency, accuracy, etc.), and experiments should be tracked. A key
    difference in generative modeling is the iterative experimentation with prompts.
    In structured ML, once you choose an algorithm and features, training is relatively
    straightforward. But with LLMs, achieving the desired output often requires interactive
    prompt tuning and tweaking parameters such as temperature settings. This means
    the modeling phase in GenAIOps can be highly iterative and exploratory, often
    interleaving with evaluation. You might prompt the model, observe its output,
    adjust the prompt or use in-context few-shot examples, and repeat. Still, the
    underlying focus remains on optimizing the model’s behavior to meet predefined
    success criteria.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-ML(Q)强调了建模实践，例如确保实验的可重复性、尝试多种建模技术以及将模型选择与业务目标对齐。在GenAI应用开发中，模型的选择以及相应的提示或微调策略必须与用例约束（延迟、准确性等）相一致，并且应该跟踪实验。生成建模中的一个关键区别是使用提示进行迭代实验。在结构化机器学习中，一旦选择了算法和特征，训练相对简单。但与LLMs相比，达到期望的输出通常需要交互式提示调整和调整参数，如温度设置。这意味着GenAIOps中的建模阶段可以非常迭代和探索性，通常与评估交织在一起。你可能提示模型，观察其输出，调整提示或使用上下文中的少量示例，然后重复。尽管如此，基础的关注点仍然是优化模型的行为以满足预定义的成功标准。
- en: 'Another difference from traditional ML is the scale and tooling involved: training
    a classical ML model might involve a scikit-learn pipeline or custom code, whereas
    in GenAIOps, you might leverage specialized frameworks such as Transformers and
    parameter-efficient fine-tuning libraries and utilize distributed training or
    serving if fine-tuning a large model. In addition, the complexity of LLMs means
    that experiment tracking and versioning are even more crucial. Every prompt template
    or fine-tuned checkpoint is a variant that should be carefully managed (to avoid
    the “pipeline jungle” problem).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统机器学习相比，另一个不同之处在于涉及的规模和工具：训练一个经典的机器学习模型可能涉及scikit-learn管道或自定义代码，而在GenAIOps中，你可能可以利用专门的框架，如Transformers和参数高效的微调库，并在微调大型模型时利用分布式训练或服务。此外，LLMs的复杂性意味着实验跟踪和版本控制变得更加关键。每个提示模板或微调检查点都是一个需要仔细管理的变体（以避免“管道丛林”问题）。
- en: GenAIOps treats the model as an artifact to configure (select and tune) rather
    than invent from scratch, emphasizing configuration management and performance
    optimization. For example, model compression and GPU optimization are part of
    “modeling” in GenAIOps.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: GenAIOps将模型视为一个需要配置（选择和调整）的工件，而不是从头开始发明，强调配置管理和性能优化。例如，模型压缩和GPU优化是GenAIOps中“建模”的一部分。
- en: Implementation
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施方案
- en: 'Bringing CRISP-ML(Q)’s discipline into GenAI application development means
    adopting systematic experimentation and robust model management practices that
    support compliance with regulations such as the EU AI Act. Practically, this involves
    several key activities:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 将CRISP-ML(Q)的纪律引入通用人工智能（GenAI）应用开发意味着采用系统实验和稳健的模型管理实践，以支持符合欧盟人工智能法案等法规。实际上，这涉及几个关键活动：
- en: Model selection and establishing a baseline
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择和建立基线
- en: Just as a data scientist might test multiple algorithms, a GenAIOps team should
    evaluate different base LLMs—such as GPT-5, Mistral, or LLaMA-2—on a representative
    sample of tasks. The goal is to select the model that best balances performance
    with business and technical constraints, guided by the success criteria defined
    during the initial phase. The CRISP-ML(Q) approach emphasizes defining baseline
    model performance. In GenAI, that could mean using an off-the-shelf model to generate
    some outputs and evaluating those before customization.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正如数据科学家可能会测试多个算法一样，GenAIOps团队应该在代表性样本的任务上评估不同的基础大型语言模型（LLM），例如GPT-5、Mistral或LLaMA-2。目标是选择在性能与业务和技术约束之间取得最佳平衡的模型，由初始阶段定义的成功标准指导。CRISP-ML(Q)方法强调定义基线模型性能。在GenAI中，这可能意味着使用现成的模型生成一些输出，并在定制之前评估这些输出。
- en: Prompt and fine-tuning experimentation
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和微调实验
- en: If fine-tuning is planned, each training run should be treated as an experiment,
    with proper versioning of training data, code, and resulting model checkpoints.
    Similarly, prompt designs—like few-shot or chain-of-thought designs—should be
    versioned and documented. This will ensure that results can be traced to the exact
    models and configurations that produced them. Tools like Weights & Biases or MLflow
    can be integrated into the GenAIOps pipeline to track prompt parameters and model
    versions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计划进行微调，每次训练运行都应被视为一个实验，对训练数据、代码和结果模型检查点进行适当的版本控制。同样，提示设计（如少样本或思维链设计）也应进行版本控制和文档记录。这将确保结果可以追溯到产生它们的精确模型和配置。可以将像Weights
    & Biases或MLflow这样的工具集成到GenAIOps管道中，以跟踪提示参数和模型版本。
- en: Quality assurance techniques
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 质量保证技术
- en: CRISP-ML(Q) recommends integrating specific quality assurance practices during
    modeling, such as reproducibility checks and model stability assessments. For
    GenAI, this might include unit tests on prompts to verify that a fixed set of
    test inputs consistently produces the expected output formats, or static analysis
    to verify that fine-tuning has not degraded key model capabilities.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-ML(Q)建议在建模期间整合特定的质量保证实践，例如可重复性检查和模型稳定性评估。对于GenAI，这可能包括对提示进行单元测试，以验证一组固定的测试输入是否始终产生预期的输出格式，或进行静态分析以验证微调是否没有降低关键模型能力。
- en: Addressing risks in model design
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 解决模型设计中的风险
- en: If earlier phases flagged certain risks, bias mitigation techniques should be
    applied—for example, embedding alignment, incorporating moderation models into
    the generation pipeline, or choosing a smaller, more controllable model over a
    larger, less interpretable one. In addition, GenAIOps often involves adding guardrails
    at the model interface—such as rules-based filters or rejection sampling—to ensure
    that outputs meet quality and compliance requirements. This aligns with CRISP-ML(Q)’s
    focus on mitigating risks during development.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果早期阶段标识了某些风险，应应用风险缓解技术，例如嵌入对齐、将调节模型纳入生成管道，或选择一个更小、更可控的模型而不是一个更大、更不可解释的模型。此外，GenAIOps通常涉及在模型接口处添加护栏，例如基于规则的过滤器或拒绝采样，以确保输出满足质量和合规性要求。这与CRISP-ML(Q)在开发过程中缓解风险的焦点相一致。
- en: Throughout these steps, maintaining a “transparency trail” is encouraged by
    SMACTR. This means documenting design decisions such as why a specific model or
    prompt strategy was chosen, how configurations were set, and any known trade-offs.
    For example, you might want to create early drafts of model cards capturing the
    intended use, architecture, and limitations of the model.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些步骤中，SMACTR鼓励保持“透明度跟踪”。这意味着记录设计决策，例如为什么选择特定的模型或提示策略，如何设置配置，以及任何已知的权衡。例如，你可能想要创建模型卡的早期草案，以捕捉模型的使用意图、架构和局限性。
- en: By the end of the modeling phase, the engineering team should have not only
    a tuned model and pipeline ready for evaluation but also a comprehensive set of
    documentation and artifacts, guaranteeing that the modeling process is reproducible
    and well understood.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 到建模阶段结束时，工程团队不仅应该有一个调优好的模型和管道准备评估，还应该有一套全面的文档和工件，确保建模过程可重复且易于理解。
- en: SMACTR integration
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR整合
- en: During the modeling phase, the key SMACTR stages to focus on are Artifact Collection
    and Testing (planning). The artifacts should include a design history file or
    similar documentation detailing the modeling decisions. This documentation might
    contain architecture diagrams (especially if the application includes multiple
    components, like an LLM and a vector database), records of hyperparameters or
    prompt scripts, and any ethical considerations incorporated into the model design
    (for instance, “we decided not to fine-tune on user chat logs containing sensitive
    data to preserve privacy”).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模阶段，需要关注的SMACTR关键阶段是**工件收集和测试（规划**）。这些工件应包括设计历史文件或类似的文档，详细说明建模决策。这些文档可能包含架构图（特别是如果应用程序包含多个组件，如LLM和向量数据库），超参数或提示脚本的记录，以及融入模型设计中的任何伦理考量（例如，“我们决定不对包含敏感数据的用户聊天日志进行微调，以保护隐私”）。
- en: SMACTR recommends using an audit checklist to verify that essential model documentation,
    such as model cards and associated data documentation, is complete and accessible.
    By the end of the modeling phase, these artifacts should be largely finalized.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR建议使用审计清单来验证关键模型文档，如模型卡和相关数据文档是否完整且可访问。到建模阶段结束时，这些工件应基本完成。
- en: Although the Testing stage formally begins during the next phase (evaluation),
    preparation for testing should start during modeling. The team should prioritize
    which risks to test based on earlier risk mapping. For example, if a failure mode
    of concern is the model generating toxic language, the modeling phase might incorporate
    a toxicity classification head or plan for adversarial prompt testing. Essentially,
    SMACTR encourages baking in testability by ensuring the model includes hooks or
    supporting tools to facilitate the intensive testing to come.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然测试阶段在下一个阶段（评估）正式开始，但测试的准备应该在建模阶段开始。团队应根据早期的风险映射优先考虑哪些风险进行测试。例如，如果关注的故障模式是模型生成有害语言，建模阶段可能包含毒性分类头或计划进行对抗性提示测试。本质上，SMACTR鼓励通过确保模型包含钩子或支持工具来促进即将到来的密集测试。
- en: To enforce accountability and ownership of quality, individual engineers or
    researchers should be assigned responsibility for various model components or
    experiments, tracing who fine-tuned which version, who designed which prompt set,
    etc.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保质量的责任和所有权，应指派个人工程师或研究人员负责各种模型组件或实验，追踪谁微调了哪个版本，谁设计了哪个提示集等。
- en: By integrating SMACTR into the modeling phase, the GenAI team treats the model
    not as a black box but as a transparently developed component ready for rigorous
    audit and testing. [Table 7-6](#chapter_7_table_6_1748539924522418) summarizes
    the core artifacts produced during this phase.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将SMACTR整合到建模阶段，GenAI团队将模型视为一个透明开发的组件，而不是一个黑盒，准备接受严格的审计和测试。[表7-6](#chapter_7_table_6_1748539924522418)总结了此阶段产生的核心工件。
- en: Table 7-6\. Summary of key artifacts produced during the modeling phase
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-6\. 建模阶段产生的关键工件总结
- en: '| SMACTR stage | Output |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR阶段 | 输出 |'
- en: '| --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Artifact Collection |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 工件收集 |'
- en: Design history file or documentation of modeling decisions (architecture diagrams,
    hyperparameters, prompt scripts, ethical considerations)
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建模决策设计历史文件或文档（架构图、超参数、提示脚本、伦理考量）
- en: Model documentation (model cards)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型文档（模型卡）
- en: Near-complete data documentation
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎完成的数据文档
- en: '|'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Testing (planning during modeling) |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 测试（建模期间的规划）|'
- en: Prioritized risks to test based on earlier risk mapping
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据早期风险映射确定的优先测试风险
- en: Integration of testability features (e.g., toxicity classification head, adversarial
    prompt testing plans)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试性功能集成（例如，毒性分类头，对抗性提示测试计划**）'
- en: Plans for intensive testing
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密集测试计划
- en: '|'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Mapping |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 映射 |'
- en: Identification of individuals responsible for model components or experiments
    (accountability)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责模型组件或实验的个人识别（责任）
- en: '|'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Evaluation Phase
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估阶段
- en: This phase aligns directly with the model evaluation stage in the GenAIOps lifecycle.
    After the model or prompt is developed, a thorough assessment of its performance
    against the previously defined success criteria should be conducted. In GenAIOps,
    evaluation is an ongoing, multifaceted process. It includes quantitative evaluation
    where applicable (e.g., accuracy on a benchmark or BLEU score for a translation
    task) as well as qualitative evaluation such as human judgment of output quality,
    user feedback loops, etc. It may also extend to assessing system behavior through
    techniques like red teaming or probing the model with adversarial or unusual inputs.
    In practice, the evaluation phase for GenAI often overlaps with deployment, involving
    shadow deployments or A/B testing with real users. Here, we’ll focus on the core
    pre-deployment evaluation steps.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 此阶段直接与GenAIOps生命周期中的模型评估阶段相一致。在模型或提示开发完成后，应对其性能与之前定义的成功标准进行彻底评估。在GenAIOps中，评估是一个持续的多方面过程。它包括适用时的定量评估（例如，基准测试的准确性或翻译任务的BLEU分数）以及定性评估，如对输出质量的个人判断、用户反馈循环等。它还可能扩展到通过红队或使用对抗性或异常输入探测模型来评估系统行为。在实践中，GenAI的评估阶段通常与部署重叠，涉及影子部署或与真实用户进行的A/B测试。在此，我们将重点关注核心的预部署评估步骤。
- en: CRISP-ML(Q) frames evaluation as verifying the model’s fitness for purpose by
    assessing its ability to meet the defined success criteria. Similarly, GenAIOps
    must determine whether the GenAI application meets business needs, quality standards,
    and thresholds for technical metrics. Both approaches involve testing on holdout
    datasets or scenarios.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-ML(Q)将评估视为通过评估其满足定义的成功标准的能力来验证模型的目的适应性。同样，GenAIOps必须确定GenAI应用程序是否满足业务需求、质量标准和技术指标的阈值。两种方法都涉及在保留数据集或场景上进行测试。
- en: Traditional ML evaluation typically uses well-defined metrics like accuracy,
    precision, root mean square error (RMSE), and static test datasets. GenAI evaluation
    is more complex, because generative outputs can’t be easily captured by a single
    scalar metric. Evaluation in GenAI remains an unsolved problem. For example, given
    the same inputs, the behavior of the model might change over time, and maintaining
    consistent outputs may require prompt adjustments. GenAI evaluation often involves
    human rating of outputs for correctness or preference, adversarial testing to
    expose failure modes or undesirable behavior, and specialized generative quality
    metrics such as BLEU or ROUGE scores or perplexity.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的机器学习评估通常使用定义良好的指标，如准确性、精确度、均方根误差（RMSE）和静态测试数据集。GenAI的评估更为复杂，因为生成性输出不容易被单个标量指标所捕捉。GenAI的评估仍然是一个未解决的问题。例如，给定相同的输入，模型的行为可能会随时间变化，而保持一致的输出可能需要提示调整。GenAI的评估通常涉及对输出进行人为评分以判断正确性或偏好，进行对抗性测试以暴露故障模式或不良行为，以及使用BLEU或ROUGE分数或困惑度等专门的生成质量指标。
- en: 'GenAI evaluation must also consider ethical and safety dimensions: a model
    might have great accuracy but fail due to biased or toxic outputs. Therefore,
    fairness and safety audits must be incorporated. In CRISP-ML(Q), evaluation is
    iterative; if the model fails to meet the defined criteria, you return to modeling
    or even data prep. But in GenAIOps, evaluation is often continuous due to nondeterministic
    outputs and evolving usage. Techniques like “golden sets”—carefully curated test
    prompts with expected answers for regression testing—are becoming standard.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI的评估也必须考虑伦理和安全维度：一个模型可能具有很高的准确性，但由于存在偏见或有毒的输出而失败。因此，必须纳入公平性和安全性审计。在CRISP-ML(Q)中，评估是迭代的；如果模型未能满足定义的标准，则返回建模甚至数据准备。但在GenAIOps中，由于非确定性输出和不断变化的用途，评估通常是连续的。像“黄金集”这样的技术——精心策划的测试提示，其中包含回归测试的预期答案——正成为标准。
- en: CRISP-ML(Q) demands rigorous validation against objectives. GenAI expands the
    scope of evaluation to include open-ended output quality and ethical risk testing
    alongside traditional performance metrics.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-ML(Q)要求对目标进行严格的验证。GenAI将评估范围扩展到包括开放性输出质量、伦理风险测试以及传统的性能指标。
- en: Implementation
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: 'In the evaluation phase, the engineering team should implement a robust evaluation
    strategy incorporating:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估阶段，工程团队应实施一个稳健的评估策略，包括：
- en: Benchmark testing
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试
- en: Evaluate the LLM on a dataset of questions or tasks with known answers. For
    instance, for a code generation model, maintain a suite of programming problems
    where correct outputs are known and measure success rate. This is analogous to
    a test set in traditional ML. The benchmarks should be versioned so that improvements
    and regressions are tracked over time.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在已知答案的问题或任务数据集上评估LLM。例如，对于代码生成模型，维护一套已知正确输出的编程问题，并测量成功率。这类似于传统机器学习中的测试集。基准应该进行版本控制，以便随着时间的推移跟踪改进和回归。
- en: Quality metrics
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 质量指标
- en: Define quantitative metrics appropriate to the use case. These might include
    BLEU or ROUGE scores for text similarity if a reference output is available, diversity
    metrics, or response latency. Incorporating user satisfaction scores or ratings
    into the evaluation loop is often useful, if the application can gather feedback.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 定义适用于用例的定量指标。这些可能包括如果可用参考输出，则包括BLEU或ROUGE分数用于文本相似度，多样性指标或响应延迟。如果应用程序可以收集反馈，将用户满意度评分或评级纳入评估循环通常很有用。
- en: Human and adversarial evaluation
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 人类和对抗性评估
- en: Given the open-ended nature of generative models, humans should assess a sample
    of outputs for factors like correctness, coherence, and safety. Adversarial testing,
    which involves deliberately testing the model with challenging or sensitive prompts
    to observe its behavior, is also strongly encouraged during the Testing stage.
    For example, a tester might ask a chatbot inappropriate or policy-violating questions
    to see whether it responds with disallowed content. The results can be summarized
    in an ethical risk analysis chart, as suggested by SMACTR, rating failure modes
    by severity and likelihood.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生成模型的开放性，人类应该评估输出样本的正确性、连贯性和安全性等因素。在测试阶段，强烈建议进行对抗性测试，这涉及故意使用具有挑战性或敏感的提示来观察模型的行为。例如，测试人员可能会向聊天机器人提出不适当或违反政策的提问，以查看它是否会以不允许的内容回应。结果可以总结在SMACTR建议的道德风险分析图表中，按严重性和可能性对故障模式进行评级。
- en: Automated monitoring in evaluation
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 评估中的自动化监控
- en: Use automated tools to evaluate outputs at scale. An emerging GenAIOps practice
    is using “watcher models” or classifiers to flag problematic content. For instance,
    toxicity detectors such as Llama Guard or Azure’s Prompt Shields can scan a large
    sample of outputs to estimate the percentage that might be harmful or inappropriate.
    These tools add a layer of quality assurance beyond simple metrics.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自动化工具在规模上评估输出。一种新兴的GenAIOps实践是使用“监视器模型”或分类器来标记问题内容。例如，毒性检测器如Llama Guard或Azure的Prompt
    Shields可以扫描大量输出样本，以估计可能有害或不适当的百分比。这些工具在简单指标之外增加了一层质量保证。
- en: Comparison and validation
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 比较和验证
- en: If multiple model versions or prompt variants were developed, evaluate them
    side by side. A/B testing can be done offline (with evaluators blind to which
    model produced which output) to choose the best version. This resembles ensemble/hyperparameter
    selection in CRISP-ML(Q), but in GenAI it may involve comparing two prompt templates.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果开发了多个模型版本或提示变体，应将它们并列评估。A/B测试可以离线进行（评估者对哪个模型产生了哪个输出一无所知）以选择最佳版本。这类似于CRISP-ML(Q)中的集成/超参数选择，但在GenAI中可能涉及比较两个提示模板。
- en: Documentation
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 文档
- en: Documentation remains critical throughout evaluation. Teams should record what
    tests were run, the outcomes, and the decisions made based on those results. If
    the model fails certain tests, document whether the issues will be addressed or
    accepted with mitigations. For instance, if an LLM occasionally produces outputs
    that are slightly incorrect but harmless, the team might decide that’s acceptable
    for the business context; however, if it sometimes produces a privacy violation,
    that would trigger a model revision.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估过程中，文档仍然至关重要。团队应记录所进行的测试、结果以及基于这些结果所做的决策。如果模型未能通过某些测试，应记录问题是否将被解决或接受缓解措施。例如，如果大型语言模型（LLM）偶尔产生略微不正确但无害的输出，团队可能会决定这在商业环境中是可以接受的；然而，如果它有时产生隐私违规，则可能触发模型修订。
- en: The evaluation phase in GenAIOps is also where “go or no-go” decisions are made
    for deployment. The engineering team should define clear launch criteria, such
    as “fewer than 1% of outputs flagged as offensive” or “at least 85% of test questions
    answered correctly.” If the model fails to meet these thresholds, the process
    loops back to the modeling or even the data preparation phase to address the shortcomings
    through fine-tuning, prompt redesign, or data augmentation.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAIOps中，评估阶段也是做出“部署或放弃”部署决策的地方。工程团队应定义明确的发布标准，例如“输出中标记为冒犯性的少于1%”或“至少85%的测试问题回答正确。”如果模型未能达到这些阈值，则过程将回溯到建模甚至数据准备阶段，通过微调、提示重新设计或数据增强来解决不足之处。
- en: SMACTR integration
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR集成
- en: The Testing stage of SMACTR aligns directly with the evaluation phase. The framework
    recommends techniques such as adversarial testing to assess performance, and the
    production of artifacts such as an ethical risk analysis chart. In a GenAI context,
    this means paying special attention to verifying the model’s compliance with ethical
    and risk-related requirements identified during the Scoping stage. Teams should
    use risk assessment tools like Failure Mode and Effects Analysis (FMEA) to list
    potential failure modes, such as “model gives legal advice” or “model outputs
    biased language,” and implement tests to cover each identified risk.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR的测试阶段与评估阶段直接对应。该框架建议使用对抗性测试等技术来评估性能，并生成如伦理风险分析图等工件。在通用人工智能（GenAI）的背景下，这意味着特别关注验证模型是否符合在范围阶段确定的伦理和风险相关要求。团队应使用如失效模式和影响分析（FMEA）等风险评估工具来列出潜在失效模式，例如“模型提供法律建议”或“模型输出带有偏见的语言”，并实施测试以覆盖每个识别的风险。
- en: The Testing stage also focuses on ethical compliance*.* To evaluate high-priority
    ethical risks or known issues arising from the training data or model design,
    teams may create and execute a checklist of ethical tests, including questions
    like “Does the model hallucinate facts?” or “Does it stereotype?”
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 测试阶段还关注伦理合规性。为了评估高优先级的伦理风险或来自训练数据或模型设计的已知问题，团队可以创建并执行伦理测试清单，包括诸如“模型是否产生事实幻觉？”或“它是否具有刻板印象？”等问题。
- en: This phase also lays the groundwork for the Reflection stage. Gather all evaluation
    results and insights to feed into a mitigation plan. For example, if testing reveals
    that the model struggles with a particular category of inputs, make a note of
    that for post-deployment monitoring or retraining.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段也为反思阶段奠定了基础。收集所有评估结果和见解，以便纳入缓解计划。例如，如果测试显示模型在特定类别的输入上表现不佳，请记录下来，以便在部署后监控或重新训练时参考。
- en: Artifact Collection continues throughout this phase. Evaluation reports, risk
    charts, and test results should be saved as part of the transparency trail. The
    evaluation phase for GenAI applications effectively becomes an audit of the model’s
    readiness. As well as verifying accuracy and performance, you should also test
    for safety, fairness, and robustness, with documented evidence to show stakeholders
    such as regulators that due diligence was done before deployment. [Table 7-7](#chapter_7_table_7_1748539924522437)
    summarizes the key SMACTR artifacts for this stage.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，工件收集持续进行。评估报告、风险图表和测试结果应作为透明度轨迹的一部分保存。对于通用人工智能（GenAI）应用的评估阶段实际上成为了对模型准备情况的审计。除了验证准确性和性能外，还应测试安全性、公平性和鲁棒性，并提供书面证据，以向监管机构等利益相关者表明在部署前已尽职调查。[表7-7](#chapter_7_table_7_1748539924522437)总结了此阶段的关键SMACTR工件。
- en: Table 7-7\. Summary of key artifacts produced during the evaluation phase
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-7. 评估阶段产生的关键工件摘要
- en: '| SMACTR stage | Output |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR阶段 | 输出 |'
- en: '| --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Testing |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 测试 |'
- en: Performance assessment using methods like adversarial testing
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用对抗性测试等方法进行性能评估
- en: Ethical risk analysis chart
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伦理风险分析图
- en: FMEA or similar risk assessment
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FMEA或类似的风险评估
- en: Tests for identified failure modes
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对识别的失效模式进行测试
- en: Checklist of ethical tests (e.g., hallucination, stereotyping)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伦理测试清单（例如，幻觉、刻板印象）
- en: '|'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Reflection |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 反思 |'
- en: Gathered results and insights from evaluation to inform a mitigation plan
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从评估中收集的结果和见解，以制定缓解计划
- en: '|'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Artifact Collection |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 工件收集 |'
- en: Evaluation reports, risk charts, and test results
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估报告、风险图表和测试结果
- en: '|'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Deployment Phase
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署阶段
- en: The CRISP-ML(Q) deployment phase focuses on delivering the model into production
    and making sure it meets business requirements in real-world operation. Other
    key activities include user acceptance testing and producing documentation. In
    GenAIOps, this phase covers multiple operational steps, such as integration and
    orchestration (CI/CD), security and reliability engineering, and the actual model
    deployment. Once a model is considered ready, it must be integrated into the application
    infrastructure, served to end users, and maintained with proper MLOps and GenAIOps
    practices.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-ML(Q)部署阶段侧重于将模型投入生产并确保其在实际操作中满足业务需求。其他关键活动包括用户验收测试和生成文档。在GenAIOps中，此阶段涵盖多个操作步骤，如集成和编排（CI/CD）、安全和可靠性工程以及实际模型部署。一旦模型被认为准备就绪，它必须集成到应用基础设施中，服务于最终用户，并使用适当的MLOps和GenAIOps实践进行维护。
- en: As in traditional MLOps, deployment in GenAIOps involves pushing the model or
    pipeline to production by setting up API endpoints or embedding the model into
    an application. It also includes tasks like continuous delivery of prompt or model
    updates, implementing safety controls such as rate limiting, monitoring for misuse,
    and ensuring the system can scale and remain reliable under load.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的MLOps一样，GenAIOps中的部署涉及通过设置API端点或将模型嵌入到应用中来将模型或流水线推送到生产环境。它还包括持续交付提示或模型更新、实施如速率限制等安全控制、监控滥用以及确保系统在负载下可以扩展并保持可靠。
- en: Given the dynamic nature of GenAI applications, teams may frequently update
    prompts or swap in improved models, making a CI/CD pipeline essential. The security
    and reliability aspects of this stage reflect CRISP-ML(Q)’s quality assurance
    mindset. The main goal is to ensure that the deployed model doesn’t expose vulnerabilities
    (such as prompt injection) and remains robust.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 由于通用人工智能应用的动态性，团队可能会频繁更新提示或替换为改进的模型，这使得CI/CD流水线变得至关重要。这一阶段的安全和可靠性方面反映了CRISP-ML(Q)的质量保证思维。主要目标是确保部署的模型不会暴露漏洞（如提示注入）并保持稳健。
- en: Implementation
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Implementation
- en: 'In practice, deploying a GenAI application with CRISP-ML(Q) principles means
    paying attention to engineering best practices and safety as the model goes live.
    Key considerations in the deployment phase include:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，根据CRISP-ML(Q)原则部署通用人工智能应用意味着在模型上线时关注工程最佳实践和安全。部署阶段的关键考虑因素包括：
- en: CI/CD for prompts and models
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD for prompts and models
- en: Establish automated pipelines to move updated prompts or model versions through
    testing and into production. For example, similar to unit tests in software deployment,
    if a prompt template is updated to improve performance, a CI pipeline should run
    the evaluation suite and promote the change only if it passes. Likewise, infrastructure-as-code
    should be used to deploy model servers or services. This ensures reproducibility
    by creating a consistent environment and provides traceability regarding which
    version of the model or prompt is in use.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 建立自动化流水线，将更新的提示或模型版本通过测试并推入生产。例如，类似于软件部署中的单元测试，如果提示模板更新以提高性能，CI流水线应运行评估套件，并且只有通过测试后才能推广更改。同样，应使用基础设施即代码来部署模型服务器或服务。这通过创建一致的环境确保可重复性，并提供了关于正在使用的模型或提示版本的可追溯性。
- en: System integration and performance optimization
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 系统集成和性能优化
- en: Unlike simple ML deployments, GenAI applications often have multiple components
    (frontend, backend, model APIs, databases, vector stores, etc.). Integration involves
    connecting these and making sure data flows correctly—for instance, a user query
    routes to the LLM, which might call a knowledge base before returning a response.
    Depending on nonfunctional requirements such as cost, speed, and scalability,
    you may need to optimize for latency and throughput. Because large models can
    be expensive or slow to run, you might want to apply techniques like model quantization,
    caching frequent responses, or using smaller distilled models for specific requests.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 与简单的机器学习部署不同，通用人工智能（GenAI）应用通常包含多个组件（前端、后端、模型API、数据库、向量存储等）。集成涉及将这些组件连接起来，并确保数据正确流动——例如，用户查询路由到大型语言模型（LLM），在返回响应之前可能调用知识库。根据非功能性需求，如成本、速度和可扩展性，您可能需要优化延迟和吞吐量。由于大型模型可能成本高昂或运行缓慢，您可能希望应用模型量化、缓存频繁响应或为特定请求使用较小的蒸馏模型等技术。
- en: Monitoring setup
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Monitoring setup
- en: Although monitoring is the next formal phase in CRISP-ML(Q), the groundwork
    is laid during deployment. Implement logging for model inputs and outputs, set
    up dashboards and alerts for key metrics (error rates, response times, etc.),
    and track usage patterns. GenAIOps best practices recommend integrating observability
    from the moment a model is deployed. Tools like Prometheus and Grafana are commonly
    used for infrastructure monitoring, along with custom monitors for model behavior.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然监控是CRISP-ML(Q)中的下一个正式阶段，但基础工作是在部署期间进行的。实现模型输入和输出的日志记录，为关键指标（错误率、响应时间等）设置仪表板和警报，并跟踪使用模式。GenAIOps最佳实践建议从模型部署的那一刻起就集成可观察性。Prometheus和Grafana等工具常用于基础设施监控，以及针对模型行为的自定义监控器。
- en: Safety mechanisms
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 安全机制
- en: 'For GenAI applications, guardrails such as content filters, user authentication
    and authorization, rate limiting, and fallback mechanisms should be put in place
    at deployment time. For instance, if the LLM is part of a user-facing app, you
    might integrate a moderation API or a simple rules engine to check model outputs.
    If an output violates policy (e.g., contains hate speech), the system can block
    or sanitize the response. You should also plan for failover: if the LLM service
    is unavailable, the system should default to a safe fallback such as a simpler
    response or a static message. These safety and reliability measures help ensure
    the live system is resilient and complies with the requirements of the EU AI Act.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通用人工智能（GenAI）应用，应在部署时实施诸如内容过滤器、用户身份验证和授权、速率限制和回退机制等护栏。例如，如果大型语言模型（LLM）是面向用户的APP的一部分，您可能需要集成一个审查API或简单的规则引擎来检查模型输出。如果输出违反政策（例如，包含仇恨言论），系统可以阻止或清理响应。您还应计划故障转移：如果LLM服务不可用，系统应默认回退到更安全的选项，例如更简单的响应或静态消息。这些安全和可靠性措施有助于确保实时系统具有弹性并符合欧盟人工智能法案的要求。
- en: Staged rollouts
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 分阶段推出
- en: Teams may choose to do a shadow deployment, where the model generates outputs
    in response to real user queries without the user seeing them, to collect performance
    data in production-like conditions. This is similar to a pilot or beta test in
    CRISP-ML(Q), providing assurance that the model works as expected before full
    launch.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 团队可以选择进行影子部署，在这种部署中，模型在用户看不到的情况下根据真实用户查询生成输出，以在生产类似条件下收集性能数据。这类似于CRISP-ML(Q)中的试点或beta测试，在全面推出之前确保模型按预期工作。
- en: Documentation and training
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 文档和培训
- en: 'Ensure that the operations team (which may be the same as the development team)
    has clear documentation on how to roll back deployments, how to intervene if something
    goes wrong, and what the known issues are. In CRISP-ML(Q), deployment concludes
    with documentation being delivered to maintainers; in GenAIOps, this may take
    the form of runbooks or playbooks. For example, a playbook might say: “If monitoring
    shows a spike in slow responses, consider disabling complex features or scaling
    up compute resources.”'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 确保操作团队（可能和开发团队相同）有明确的文档说明如何回滚部署，如何在出现问题的情况下介入，以及已知的问题是什么。在CRISP-ML(Q)中，部署以将文档交付给维护者结束；在GenAIOps中，这可能采取运行手册或剧本的形式。例如，一个剧本可能说：“如果监控显示慢响应激增，考虑禁用复杂功能或增加计算资源。”
- en: SMACTR integration
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR集成
- en: The SMACTR framework encourages a “deploy responsibly” mentality, treating deployment
    not as the end goal, but as a moment to verify that everything done so far aligns
    with ethical, quality, and safety standards and to set up mechanisms for ongoing
    vigilance once the model is in production.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR框架鼓励“负责任地部署”的心态，将部署视为一个验证到目前为止所做的一切是否符合伦理、质量和安全标准的时刻，并在模型投入生产后建立持续警惕的机制。
- en: 'In this phase, the Reflection stage of SMACTR should be activated. Before going
    live, the team should reflect on whether the development process met the initial
    ethical and risk-related objectives. Concretely, this means reviewing evaluation
    results and determining whether any remaining risks are unacceptable. For example,
    the Reflection stage might lead to arisk mitigation plan: “We observed that the
    model sometimes gives outdated information. Mitigation: Display a disclaimer or
    schedule regular retraining.”'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，应激活SMACTR的反思阶段。在上线之前，团队应反思开发过程是否满足了最初的伦理和风险相关目标。具体来说，这意味着审查评估结果，并确定是否有任何剩余的风险是不可接受的。例如，反思阶段可能导致风险缓解计划：“我们观察到模型有时会提供过时的信息。缓解措施：显示免责声明或定期重新训练。”
- en: SMACTR’s Reflection stage also calls for producing an algorithmic audit summary
    report, which is a summary of key findings, risk decisions, and ethical considerations
    throughout the project. For a GenAI deployment, this could be distilled into something
    like a model card plus a responsible AI deployment checklist that is filed for
    governance purposes.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR的反思阶段还要求生成一个算法审计总结报告，这是对整个项目期间的关键发现、风险决策和伦理考量的总结。对于一个通用人工智能部署，这可以提炼成一个类似于模型卡片加上一个负责的AI部署清单，用于治理目的。
- en: '[Table 7-8](#chapter_7_table_8_1748539924522457) provides an overview of the
    artifacts that should be produced during the deployment phase, particularly as
    part of the SMACTR framework’s Reflection stage.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '[表7-8](#chapter_7_table_8_1748539924522457)概述了在部署阶段应产生的工件，特别是作为SMACTR框架反思阶段的一部分。'
- en: Table 7-8\. Summary of key artifacts produced during the deployment phase
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-8。部署阶段产生的关键工件摘要
- en: '| SMACTR stage | Output |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR阶段 | 输出 |'
- en: '| --- | --- |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Reflection |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 反思 |'
- en: Review of evaluation results
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估结果的审查
- en: Decision on acceptability of residual risks
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对残余风险的接受性决策
- en: Risk mitigation plan (e.g., disclaimers, retraining schedules)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风险缓解计划（例如，免责声明、再培训时间表）
- en: Algorithmic audit summary report (or model card and responsible AI deployment
    checklist)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法审计总结报告（或模型卡片和负责的AI部署清单）
- en: Plan for periodic post-launch audits (internal reviews)
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期发布后审计计划（内部审查）
- en: Maintenance of traceability (model version, deployment date, evaluation)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护可追溯性（模型版本、部署日期、评估）
- en: '|'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Model Monitoring and Maintenance Phase
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型监控和维护阶段
- en: In GenAIOps, once an LLM-powered application is deployed, teams must continuously
    monitor its performance, capture data on real-world use, and maintain or improve
    the model over time. This phase, often called *model operations*, is analogous
    to the CRISP-ML(Q) monitoring and maintenance phase.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAIOps中，一旦部署了基于LLM的应用程序，团队必须持续监控其性能，收集现实世界使用的数据，并随着时间的推移维护或改进模型。这个阶段，通常被称为*模型运维*，类似于CRISP-ML(Q)的监控和维护阶段。
- en: Maintenance in a GenAI context can take several forms, such as fine-tuning a
    model on new data, switching to a new model version, updating prompts, refreshing
    the knowledge base in a RAG pipeline, or retraining if the domain has changed
    significantly. The monitoring and maintenance phase is specifically intended to
    address the risk of model degradation in evolving environments, where data drift,
    changing user needs, or concept drift may occur post-deployment.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在通用人工智能的背景下，维护可以采取多种形式，例如在新数据上微调模型、切换到新的模型版本、更新提示、刷新RAG管道中的知识库，或者在领域发生重大变化时重新训练。监控和维护阶段特别旨在解决模型在演变环境中退化的风险，其中数据漂移、用户需求的变化或概念漂移可能在部署后发生。
- en: 'In traditional ML, monitoring typically focuses on data drift, model drift,
    and core performance metrics—for instance, detecting if the distribution of the
    input data has changed enough to reduce accuracy and trigger retraining. Some
    of those concepts apply to GenAI as well: user queries may evolve over time, making
    the original model or prompt less relevant. However, GenAI introduces additional
    challenges, such as monitoring the content of outputs to detect inappropriate
    or factually incorrect answers and tracking user interaction patterns to detect
    potential misuse.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习中，监控通常集中在数据漂移、模型漂移和核心性能指标上——例如，检测输入数据的分布是否发生了足够的变化，以至于降低了准确性并触发了再培训。其中一些概念也适用于通用人工智能：用户查询可能会随时间演变，使得原始模型或提示变得不那么相关。然而，通用人工智能引入了额外的挑战，例如监控输出内容以检测不适当或事实错误的答案，以及跟踪用户交互模式以检测潜在的滥用。
- en: 'Feedback loops are especially critical in GenAI: models can be improved using
    techniques like RLHF or fine-tuning based on logged errors and failures. CRISP-ML(Q)
    emphasizes continuous quality control but focuses more on technical degradation
    and planned retraining, whereas GenAI maintenance involves active, sometimes real-time,
    management of model behavior.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环在通用人工智能中尤其关键：可以使用RLHF或基于记录的错误和失败的微调技术来改进模型。CRISP-ML(Q)强调持续质量控制，但更侧重于技术退化和计划中的再培训，而通用人工智能的维护涉及对模型行为的积极、有时是实时管理。
- en: Finally, integrating monitoring throughout the pipeline is essential. Without
    proper monitoring and maintenance, a model’s performance and utility will likely
    decay over time, and safety can quickly degrade. The dynamic, nondeterministic
    nature of GenAI applications makes this phase even more critical and complex.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在整个流程中整合监控至关重要。没有适当的监控和维护，模型的表现和效用可能会随着时间的推移而下降，安全性也可能迅速恶化。生成式AI应用的动态、非确定性特性使得这一阶段更加关键和复杂。
- en: Implementation
  id: totrans-326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施
- en: 'For a GenAI application, the monitoring and maintenance phase involves several
    ongoing practices, many of which parallel classic MLOps but are adapted for GenAI-specific
    challenges and metrics:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生成式AI应用，监控和维护阶段涉及多个持续实践，其中许多与经典的MLOps（机器学习运营）并行，但针对生成式AI特定的挑战和指标进行了调整：
- en: Live performance monitoring
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 实时性能监控
- en: Track the model’s outputs in production, monitoring for quality and reliability.
    This may involve statistical indicators such as the percentage of queries answered
    successfully or user ratings (if available), as well as technical metrics like
    latency and error rates. In a GenAI chatbot, for instance, frequent rephrasing
    of questions by users might signal poor initial responses. Setting up alert thresholds
    is important. For example, if the rate of content flagging by a moderation filter
    doubles overnight, the team should be alerted to investigate potential model drift
    or misuse.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中跟踪模型的输出，监控其质量和可靠性。这可能包括诸如成功回答查询的百分比或用户评分（如果可用）等统计指标，以及如延迟和错误率等技术指标。例如，在一个基于生成式AI的聊天机器人中，用户频繁地重述问题可能表明初始响应不佳。设置警报阈值非常重要。例如，如果内容标记的速率在夜间翻倍，团队应被提醒调查潜在的模型漂移或误用。
- en: Data and usage drift
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和用法漂移
- en: Unlike traditional ML, where input features can be directly compared, GenAI
    may require monitoring embeddings of user queries or clustering them to detect
    topic shifts. In a RAG-based system, for example, monitoring might reveal user
    interest in a new product that isn’t yet in the knowledge base.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的机器学习不同，其中输入特征可以直接比较，生成式AI可能需要监控用户查询的嵌入或对它们进行聚类以检测主题变化。例如，在一个基于RAG的系统（Retrieval-Augmented
    Generation）中，监控可能揭示用户对知识库中尚未出现的新产品的兴趣。
- en: Logging and audit
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 日志和审计
- en: Maintain detailed logs of interactions, with appropriate privacy safeguards,
    to support retrospective analysis and auditing. These logs can feed into a feedback
    dataset. In addition, teams might periodically label a random sample of interactions
    to assess satisfaction or accuracy, helping to build an ongoing evaluation dataset
    to use for quality tracking.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 维护详细的交互日志，同时采取适当的隐私保护措施，以支持回顾性分析和审计。这些日志可以输入到反馈数据集中。此外，团队可能定期对随机样本的交互进行标注，以评估满意度或准确性，帮助构建用于质量跟踪的持续评估数据集。
- en: Retraining or model updates
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 重新训练或模型更新
- en: Decide on a schedule or criteria for when to retrain or update the model. In
    cases where the base model is provided via an API (like OpenAI’s GPT), retraining
    might not be feasible. However, teams can still fine-tune adapters and switch
    to newer model versions as they become available (e.g., upgrading from GPT-3.5
    to GPT-4). Each update should pass through a condensed version of the evaluation
    and deployment lifecycle.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 确定重新训练或更新模型的时间表或标准。在基模型通过API（如OpenAI的GPT）提供的情况下，重新训练可能不可行。然而，团队仍然可以在新版本可用时微调适配器并切换到更新的模型版本（例如，从GPT-3.5升级到GPT-4）。每次更新都应该通过简化的评估和部署生命周期。
- en: Prompt and system maintenance
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和系统维护
- en: Maintenance is also important for the surrounding system. Teams may refine prompt
    templates based on observed performance or introduce new safety rules in response
    to emerging failure cases. Because GenAI applications can be highly sensitive
    to prompt changes, treat these with the same caution as code changes—test before
    rollout and monitor performance closely.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 维护对于周围系统也很重要。团队可能根据观察到的性能优化提示模板或根据新出现的故障案例引入新的安全规则。由于生成式AI应用对提示变化非常敏感，因此应像对待代码更改一样谨慎对待这些更改——在推出前进行测试并密切监控性能。
- en: User feedback and iteration
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 用户反馈和迭代
- en: Provide channels for user feedback (thumbs up/down for responses, reporting
    issues, etc.), and establish a process for analyzing and acting on this feedback
    regularly.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 提供用户反馈的渠道（如对响应的点赞/踩、报告问题等），并建立定期分析和采取行动的反馈流程。
- en: Risk management
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 风险管理
- en: If new misuse patterns emerge—for example, if users find a new way to get the
    model to produce disallowed content—the team should respond quickly, updating
    filters, modifying prompts, or adjusting model behavior to block these vulnerabilities.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现新的滥用模式——例如，如果用户发现一种新的方法让模型产生不允许的内容——团队应迅速响应，更新过滤器，修改提示或调整模型行为以阻止这些漏洞。
- en: SMACTR integration
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMACTR集成
- en: Monitoring and maintenance corresponds to an ongoing cycle of Reflection and
    renewed Scoping in SMACTR terms. While the Reflection stage is originally framed
    as a pre-deployment audit, its core activity—evaluating outcomes against initial
    goals and risks—should continue periodically post-deployment.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和维护对应于SMACTR术语中的持续循环的反思和范围更新。虽然反思阶段最初被界定为部署前的审计，但其核心活动——评估结果与初始目标和风险——应在部署后定期进行。
- en: 'For a GenAI application, this could mean scheduling regular internal audits
    or postmortems. For example, after a month of production use, the team might review
    questions such as:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个生成式人工智能应用，这可能意味着安排定期的内部审计或事后分析。例如，在一个月的生产使用后，团队可能会审查以下问题：
- en: Are there new ethical concerns arising from how the model is being used?
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的使用方式是否产生了新的伦理担忧？
- en: Did our mitigation plan hold up, or do we need new measures?
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的缓解计划是否有效，或者我们需要采取新的措施？
- en: This continuous reflection can lead to updates to the risk mitigation plan and
    may even trigger a fresh round of Scoping if the application’s purpose or usage
    context evolves. For instance, if the system is used in a higher-stakes environment
    than originally intended, the team should revisit and rescope ethical and operational
    risks.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这种持续的反思可能导致风险缓解计划的更新，甚至可能触发一轮新的范围规划，如果应用程序的目的或使用环境发生变化。例如，如果系统被用于比最初预期风险更高的环境中，团队应重新审视和重新规划伦理和运营风险。
- en: SMACTR also calls for documentation of incidents, meaning teams should maintain
    a history of design changes and keep a log of any significant failures and how
    they were addressed. This is analogous to treating the algorithmic use-related
    risk analysis and audit summary report as living documents, updated with real-world
    findings over time.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: SMACTR还要求记录事件，这意味着团队应维护设计变更的历史记录，并记录任何重大失败及其解决方式。这类似于将算法使用相关的风险分析和审计总结报告视为活文件，随着时间的推移更新以反映现实世界的发现。
- en: Additionally, the Mapping stage may need to be revisited if new stakeholders
    emerge. For example, customer support might get involved to handle user reports
    about the system, or legal teams might need to review compliance with regulations
    such as the EU AI Act. Maintenance processes should ensure that these stakeholders
    are identified and looped into governance and oversight activities.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果出现新的利益相关者，可能需要重新访问映射阶段。例如，客户支持可能需要介入处理关于系统的用户报告，或法律团队可能需要审查符合欧盟人工智能法案等法规的情况。维护流程应确保这些利益相关者被识别并纳入治理和监督活动。
- en: Finally, monitoring effectively functions as continuous testing in production.
    The SMACTR framework emphasizes that monitoring and audits help identify emerging
    threats and act quickly. The engineering team should treat monitoring data not
    just as operational information but as audit evidence. Every anomaly should be
    investigated for root causes, every significant output error analyzed for potential
    broader impacts, and oversight responsibilities clearly assigned. This is especially
    important for risk mitigation in GenAI, where issues like model bias or inappropriate
    outputs can lead to reputational or legal consequences.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，监控在有效运作中相当于生产中的持续测试。SMACTR框架强调监控和审计有助于识别新兴威胁并迅速采取行动。工程团队应将监控数据不仅视为运营信息，还视为审计证据。每个异常都应调查其根本原因，每个重要的输出错误都应分析其潜在的更广泛影响，并明确分配监督责任。这对于生成式人工智能（GenAI）的风险缓解尤为重要，其中模型偏差或不当输出可能导致声誉或法律后果。
- en: All notable outputs for the monitoring and maintenance phase for each SMACTR
    stage are outlined in [Table 7-9](#chapter_7_table_9_1748539924522477).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 每个SMACTR阶段监控和维护阶段的显著输出都在[表7-9](#chapter_7_table_9_1748539924522477)中概述。
- en: Table 7-9\. Summary of key artifacts produced during the monitoring and maintenance
    phase
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-9. 监控和维护阶段产生的关键工件摘要
- en: '| SMACTR stage | Output |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| SMACTR阶段 | 输出 |'
- en: '| --- | --- |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Reflection (ongoing) |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 反思（持续） |'
- en: Periodic internal audits or postmortems
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期内部审计或事后分析
- en: Evaluation of results relative to original goals and risks
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与原始目标和风险相对的结果评估
- en: Updates to the risk mitigation plan (living document)
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风险缓解计划的更新（活文档）
- en: Documentation of incidents (design history, failure logs)
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件记录（设计历史、故障日志）
- en: Maintenance of algorithmic use-related risk analysis and audit summary report
    (living documents)
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护与算法使用相关的风险分析及审计摘要报告（活文档）
- en: '|'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Scoping (renewed) |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 重新界定（更新） |'
- en: Rescoping and reassessment of risks if the application’s scope expands or changes
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用程序的范围扩大或改变，重新界定和评估风险
- en: '|'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Mapping (revisited) |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 重新审视映射 |'
- en: Inclusion of new stakeholders (e.g., customer support, legal teams) and clarification
    of their oversight roles
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括新的利益相关者（例如，客户支持、法律团队）并明确他们的监督角色
- en: '|'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Testing (continuous) |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 测试（持续） |'
- en: Monitoring as continuous testing in production
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控作为生产中的持续测试
- en: Identification of emerging threats
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定新兴威胁
- en: Investigation of anomalies and significant output errors
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常和重大输出错误的调查
- en: Clear assignment of oversight responsibility
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确分配监督责任
- en: '|'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Conclusion
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter explored the core aspects of the EU AI Act as they apply to general-purpose
    AI models and systems, along with the practical role of GenAIOps in supporting
    compliance and fostering trustworthy AI. As outlined here, the Act establishes
    a structured regulatory framework for GPAI, requiring documentation, disclosure,
    and risk mitigation measures to be embedded into providers’ workflows. GenAIOps
    extends traditional MLOps practices to meet the unique challenges of GPAI, enabling
    engineering teams to build systems that are compliant with regulatory requirements,
    resilient, scalable, and aligned with societal expectations. By integrating the
    SMACTR framework, organizations can further enhance CRISP-ML(Q) by embedding accountability
    mechanisms that address GPAI-specific risks such as hallucination and ethical
    misalignment.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了欧盟人工智能法案的核心方面，这些方面适用于通用人工智能模型和系统，以及GenAIOps在支持合规性和培养可信赖人工智能中的实际作用。正如这里所概述的，法案为通用人工智能（GPAI）建立了一个结构化的监管框架，要求将文档编制、披露和风险缓解措施嵌入到提供商的工作流程中。GenAIOps将传统的MLOps实践扩展到满足GPAI的独特挑战，使工程团队能够构建符合监管要求、具有弹性、可扩展并与社会期望一致的系统。通过整合SMACTR框架，组织可以进一步通过嵌入解决GPAI特定风险（如幻觉和道德不匹配）的问责机制来增强CRISP-ML(Q)。
- en: Achieving compliance, however, is not a one-time task. It demands a proactive,
    ongoing approach in which transparency, accountability, and ethical reflection
    are integrated throughout the AI development lifecycle. From data preparation
    and model fine-tuning to deployment and continuous monitoring, teams must adopt
    structured, auditable processes to ensure their systems remain reliable and interpretable
    and meet ethical standards. This is particularly crucial for managing risks such
    as bias, misinformation, and unintended model behaviors. GenAIOps provides an
    operational framework that allows organizations to implement these safeguards
    systematically, bridging the gap between regulatory compliance and real-world
    AI development and deployment.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实现合规性并非一次性任务。它需要一种积极主动、持续的方法，在人工智能开发的生命周期中整合透明度、问责制和道德反思。从数据准备和模型微调到部署和持续监控，团队必须采用结构化、可审计的过程，以确保他们的系统保持可靠和可解释，并符合道德标准。这对于管理诸如偏见、错误信息和意外模型行为等风险尤为重要。GenAIOps提供了一个操作框架，允许组织系统地实施这些保障措施，弥合法规合规与实际人工智能开发部署之间的差距。
- en: Final Words and Future of AI Policymaking
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的话和人工智能政策制定的未来
- en: As we conclude our journey through AI governance, engineering practices, and
    the EU AI Act, it’s important to reflect on what has been covered and look to
    the future. We began by exploring the foundational landscape of the EU AI Act’s
    risk-based approach and how it introduces crucial obligations, even for systems
    not classified as high risk. A key insight is that the Act requires transparency
    for all AI systems intended to interact directly with natural persons, regardless
    of their risk level (primarily through Article 50).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们结束对人工智能治理、工程实践以及欧盟人工智能法案的探索之旅，回顾所涵盖的内容并展望未来显得尤为重要。我们首先探讨了欧盟人工智能法案基于风险的方法论的基础格局，以及它如何引入了关键义务，即使是那些未被归类为高风险的系统也不例外。一个关键的见解是，法案要求所有旨在直接与自然人互动的人工智能系统透明度，无论其风险水平如何（主要通过第50条）。
- en: We then turned to the practical world of AI development and deployment, recognizing
    that compliance is not a post-deployment afterthought but a process that must
    be integrated throughout the AI system lifecycle. The adoption of structured methodologies
    such as CRISP-ML(Q), alongside ethical frameworks like SMACTR, emerges as a proactive
    catalyst for responsible and compliant development. By aligning the phases of
    CRISP-ML(Q), from business and data understanding to monitoring and maintenance,
    with SMACTR principles, organizations can systematically address ethical considerations,
    manage risks, and fulfill transparency requirements at every stage.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们转向了人工智能开发和部署的实际世界，认识到合规性不是部署后的后顾之忧，而是一个必须整合到人工智能系统生命周期中的过程。采用结构化方法，如CRISP-ML(Q)，以及像SMACTR这样的伦理框架，成为推动负责任和合规发展的主动催化剂。通过将CRISP-ML(Q)的阶段与SMACTR原则对齐，从业务和数据理解到监控和维护，组织可以系统地解决伦理考量、管理风险并在每个阶段满足透明度要求。
- en: A recurring theme throughout this book has been the critical importance of documentation
    and robust metadata management. These are foundational for traceability, internal
    audits, demonstrating compliance, and fostering transparency. Key artifacts generated
    throughout the development process, such as the project scope document, ethical
    review report, stakeholder map, data quality assessment, and initial transparency
    requirements document, serve as evidence of due diligence and ethical consideration.
    Further documentation, such as data quality reports, feature documentation, evaluation
    reports, compliance verification records, deployment configurations, and monitoring
    logs, helps establish a comprehensive compliance trail.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 本书贯穿的一个主题是文档和稳健元数据管理的重要性。这些是可追溯性、内部审计、证明合规性和促进透明度的基石。在整个开发过程中生成的关键工件，如项目范围文档、伦理审查报告、利益相关者图、数据质量评估和初始透明度要求文档，作为尽职调查和伦理考量的证据。进一步的文档，如数据质量报告、功能文档、评估报告、合规性验证记录、部署配置和监控日志，有助于建立全面的合规轨迹。
- en: The rapid emergence and widespread adoption of GPAI and generative AI models
    during the legislative process introduced new challenges, prompting the EU AI
    Act to incorporate specific provisions to address them. In this evolving landscape,
    the principles of MLOps—extended into GenAIOps—remain vital for managing these
    complex systems. They support transparency, logging, and version control to create
    auditable trails, enabling teams to operationalize compliance while maintaining
    flexibility and performance.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在立法过程中，GPAI和生成式AI模型的快速出现和广泛应用引入了新的挑战，促使欧盟AI法案纳入具体规定来应对这些问题。在这个不断发展的景观中，MLOps的原则——扩展到GenAIOps——对于管理这些复杂系统至关重要。它们支持透明度、日志记录和版本控制，以创建可审计的轨迹，使团队能够在保持灵活性和性能的同时实现合规性。
- en: As you have seen, navigating the landscape of AI regulation requires more than
    just understanding the rules—it demands a fundamental shift in how AI systems
    are engineered and governed. Proactive compliance, embedded within engineering
    workflows and supported by comprehensive documentation, is the path forward.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，在人工智能监管的景观中导航需要不仅仅是理解规则，它要求在人工智能系统的工程和治理方面有一个根本性的转变。主动合规，嵌入到工程工作流程中，并得到全面文档的支持，是前进的道路。
- en: The landscape of AI technologies is evolving at a remarkable pace. An example
    of this is the emergence of retrieval-augmented generation and agent-based architectures.
    To keep pace, we must continually learn about new technologies and stay informed
    about regulatory updates, best practices, and emerging methodologies for AI governance.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能技术的景观正在以惊人的速度发展。这一点的例子就是检索增强生成和基于代理架构的出现。为了跟上步伐，我们必须不断学习新技术，并关注监管更新、最佳实践以及人工智能治理的新兴方法。
- en: 'In the Preface, I quoted Fei-Fei Li, the founding codirector of the Stanford
    Institute for Human-Centered AI (HAI) and CEO and cofounder of World Labs, who
    [remarked](https://oreil.ly/_PUIb): “Now more than ever, AI needs a governance
    framework.” She laid out three fundamental principles for the future of AI policymaking:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在序言中，我引用了斯坦福大学以人为本的人工智能研究所（HAI）的联合创始人和世界实验室的首席执行官兼联合创始人李飞飞的话，她[评论道](https://oreil.ly/_PUIb)：“现在比以往任何时候都更需要一个治理框架。”她为人工智能政策制定的未来概述了三个基本原则：
- en: AI engineering should *prioritize empirical validation over speculation*, ensuring
    models are rigorously tested with real-world data and transparent benchmarks.
    This means engineers should rely on scientifically grounded methods, avoiding
    hype and focusing on practical applications rather than speculative scenarios.
    Standardized frameworks like ISO/IEC AI guidelines, NIST’s AI Risk Management
    Framework, or SMACTR can be integrated into development workflows to promote reliability,
    fairness, and robustness.
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能工程应**优先考虑经验验证而非推测**，确保模型使用真实世界的数据和透明的基准进行严格测试。这意味着工程师应依赖科学依据的方法，避免炒作，专注于实际应用而非推测性场景。可以将标准化框架如ISO/IEC人工智能指南、NIST的人工智能风险管理框架或SMACTR整合到开发工作流程中，以促进可靠性、公平性和鲁棒性。
- en: Engineers must *adopt risk-aware, pragmatic development practices, balancing
    innovation with responsible deployment* by integrating continuous monitoring and
    adherence to ethical standards. This includes incorporating risk assessment early
    in development, leveraging iterative prototyping to surface and address unintended
    consequences, and continuous post-deployment monitoring to detect bias or misuse.
    AI systems should be designed with built-in safeguards and governance mechanisms,
    especially in high-stakes areas like defense or healthcare.
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工程师必须通过整合持续监控和遵守伦理标准，采取**风险意识、务实的开发实践**，在创新与负责任的部署之间取得平衡。这包括在开发早期进行风险评估，利用迭代原型来揭示和解决意外后果，以及持续部署后的监控以检测偏差或滥用。人工智能系统应设计内置的安全保障和治理机制，特别是在高风险领域如国防或医疗保健领域。
- en: Lastly, *collaboration and open access* should be central, promoting open source
    contributions, knowledge sharing, and cross-sector partnerships to strengthen
    the AI ecosystem while maintaining accountability. Engineers can support this
    by sharing research findings, building reusable frameworks, and creating or contributing
    to tools that lower barriers to entry for startups and academic institutions.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，**协作和开放访问**应该是核心，促进开源贡献、知识共享和跨行业合作，以加强人工智能生态系统同时保持问责制。工程师可以通过分享研究成果、构建可重用框架以及创建或贡献降低初创企业和学术机构进入壁垒的工具来支持这一点。
- en: Ultimately, building trustworthy  AI is both a technical challenge and a responsibility
    shared by the whole organization. As engineers, researchers, and practitioners,
    we shape not only what AI can do, but how it affects the world. By embedding ethics,
    transparency, and accountability into every stage of development, we can ensure
    that the systems we create are not only powerful, but worthy of the trust placed
    in them.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，构建值得信赖的人工智能既是技术挑战，也是整个组织共同承担的责任。作为工程师、研究人员和从业者，我们不仅塑造了人工智能能够做什么，还塑造了它如何影响世界。通过将伦理、透明度和问责制嵌入到开发的每个阶段，我们可以确保我们创建的系统不仅强大，而且值得人们对其所赋予的信任。
- en: '^([1](ch07.html#id616-marker)) For more information, see the paper [“Generative
    AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data”](https://oreil.ly/DDpPc)
    by Nahema Marchal et al.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](ch07.html#id616-marker)) 更多信息，请参阅Nahema Marchal等人撰写的论文《“生成式人工智能滥用：策略分类和来自真实世界数据的见解”》（[“Generative
    AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data”](https://oreil.ly/DDpPc)）。'
