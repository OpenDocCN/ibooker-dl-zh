- en: Chapter 4\. Designing LLM Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章. 设计 LLM 应用程序
- en: The previous two chapters laid the foundations for the remainder of the book.
    [Chapter 2](ch02.html#ch02_understanding_llms_1728407258904677) showed in detail
    how LLMs function, and we demonstrated that at the end of the day, they are effectively
    document completion models that predict content one token at a time. [Chapter 3](ch03.html#ch03a_moving_toward_chat_1728432131625250)
    explained how the chat API is built upon the LLMs of [Chapter 2](ch02.html#ch02_understanding_llms_1728407258904677).
    With some syntactic sugar at the API level and a healthy dose of fine-tuning,
    the document completion model is used to complete conversations between the user
    and an imagined assistant. When you get down to it, the chat model is really still
    a document completion model—it’s just that the documents it completes are all
    conversation transcripts.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前两章为本书的其余部分奠定了基础。[第二章](ch02.html#ch02_understanding_llms_1728407258904677) 详细介绍了
    LLM 的工作原理，并证明它们最终实际上是逐个预测内容的文档完成模型。[第三章](ch03.html#ch03a_moving_toward_chat_1728432131625250)
    解释了聊天 API 是如何建立在第二章的 LLM 之上的。通过在 API 层面上添加一些语法糖和适量的微调，文档完成模型被用于完成用户和想象中的助手之间的对话。当你深入思考时，聊天模型实际上仍然是一个文档完成模型——只是它完成的文档都是对话记录。
- en: From this point forward in the book, you’ll learn everything you need to know
    about how to build LLM applications to solve problems on behalf of your company
    and your users. This chapter serves as a gateway to that content. In this chapter,
    we’ll dive into the LLM *application*, which you’ll see is actually a transformation
    layer between the user’s problem domain and the model’s text domain. Furthermore,
    the LLM application is a transformation layer with a purpose—solving problems!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的这一部分开始，你将学习到构建 LLM 应用程序以解决公司及其用户问题的所有必要知识。本章是进入这一内容的门户。在本章中，我们将深入探讨 LLM
    的 *应用*，你会发现这实际上是在用户问题域和模型文本域之间的一个转换层。此外，LLM 应用程序是一个具有目的的转换层——解决问题！
- en: The Anatomy of the Loop
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环的解剖结构
- en: In [Figure 4-1](#ch04_figure_1_1728407230608910), the LLM application is represented
    as a *loop*, meaning an interaction back and forth between the user and the model.
    The domains of the model and the user are often quite different. The user may
    be doing any number of things, such as writing an email and looking for just the
    right wording to communicate their point. Or they may be doing something complicated,
    such as organizing group travel, booking travel tickets, and procuring lodging.
    Perhaps the user isn’t directly in contact with the LLM application; for instance,
    they could have set up a recurring analysis that the LLM application performs
    periodically as new data becomes available. The point is that the user can be
    doing a great variety of things.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 4-1](#ch04_figure_1_1728407230608910) 中，LLM 应用程序被表示为一个 *循环*，意味着用户和模型之间的交互往返。模型和用户的领域通常相当不同。用户可能在进行各种事情，例如撰写电子邮件并寻找恰当的措辞来表达他们的观点。或者他们可能在进行一些复杂的事情，例如组织团队旅行、预订旅行票务和安排住宿。也许用户并没有直接与
    LLM 应用程序接触；例如，他们可能设置了一个定期进行的重复分析，当有新数据可用时，LLM 应用程序会执行。重点是用户可以从事各种各样的活动。
- en: The model, on the other hand, does only one thing—it completes documents. But
    this capability affords you a great deal of flexibility when building the LLM
    application. The ability to complete documents gives the model the ability to
    write emails, code, stories, documentation, and (in principle) anything else that
    a human might write. As we showed in the previous chapter, a chat app is an LLM
    application that completes *transcript* documents, and tool execution is simply
    going one step farther and completing a specialized transcript document that includes
    a function calling syntax. With their ability to complete text, engage in chat,
    and execute tools, LLMs can be applied to an almost unlimited number of use cases.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，模型只做一件事——完成文档。但这一能力在构建 LLM 应用程序时为你提供了很大的灵活性。完成文档的能力使模型能够撰写电子邮件、代码、故事、文档，以及（原则上）任何人类可能撰写的内容。正如我们在上一章所展示的，聊天应用程序是一个完成
    *记录* 文档的 LLM 应用程序，而工具执行只是进一步完成一个包含函数调用语法的专用记录文档。凭借其完成文本、参与聊天和执行工具的能力，LLM 可以应用于几乎无限数量的用例。
- en: '![](assets/pefl_0401.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0401.png)'
- en: Figure 4-1\. LLM-based applications implement the loop, which conveys information
    from the user domain to the LLM’s text domain and then back
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 基于 LLM 的应用实现了循环，它将用户领域的信息传递到 LLM 的文本领域，然后再返回
- en: The loop implements the transformation between the user domain and the model
    domain. It takes the user’s problem and converts it into the document or transcript
    that the model must complete. Once the model has responded, the loop transforms
    the model output back into the user domain in the form of a solution to the user’s
    problem (or at least a step in the right direction).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 循环实现了用户领域和模型领域之间的转换。它将用户的问题转换为模型必须完成的文档或记录。一旦模型做出回应，循环将模型输出转换回用户领域，以用户问题的解决方案（或至少是正确方向的一步）的形式。
- en: The LLM application may involve just one iteration of the loop. For instance,
    if the user is writing an email and wants to convert a bulleted list of points
    into prose, then you need only one iteration through this loop—once the model
    returns the prose, the job of the application is complete. The user can run the
    application again if they want, but in each case, the loop retains no state from
    the previous run.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 应用可能只涉及循环的一次迭代。例如，如果用户正在撰写电子邮件并希望将点列表转换为散文，那么只需通过这个循环一次——一旦模型返回散文，应用的工作就完成了。如果用户想要再次运行应用，可以这样做，但在每种情况下，循环都不会保留前一次运行的状态。
- en: Alternatively, the LLM application may run the loop several times in a row,
    as is the case for a chat assistant. Or, the LLM application may run iteratively,
    refer to a vast amount of state, and modify the loop as the problem changes shape.
    A travel planning app is a good example of this. Initially, the application would
    help brainstorm travel ideas; then, it would move on to making the actual travel
    arrangements; and finally, it would set up reminders and travel tips.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，LLM 应用可能连续多次运行循环，如聊天助手的情况。或者，LLM 应用可能迭代运行，参考大量状态，并根据问题形状的变化修改循环。旅行规划应用是这种情况的一个好例子。最初，应用会帮助构思旅行想法；然后，它会转向实际旅行安排；最后，它会设置提醒和旅行提示。
- en: In the following sections, we’ll take you for one trip around the loop of [Figure 4-1](#ch04_figure_1_1728407230608910).
    We will discuss the user’s problem domain, convert that problem to the model domain,
    collect the completion, and convert it back into a solution for the user.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将带您环游[图 4-1](#ch04_figure_1_1728407230608910)的循环。我们将讨论用户问题领域，将该问题转换为模型领域，收集完成内容，并将其转换回用户的解决方案。
- en: The User’s Problem
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户的问题
- en: 'The loop starts with the user and the problem they are trying to solve. [Table 4-1](#ch04_table_1_1728407230620664)
    illustrates how the user’s problem domain can vary among several dimensions and
    can range from simple to complex. These dimensions include the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 循环从用户和他们试图解决的问题开始。[表 4-1](#ch04_table_1_1728407230620664)说明了用户问题领域在多个维度上的变化，可以从简单到复杂。这些维度包括以下内容：
- en: The medium in which the problem is conveyed (with text being the most natural
    for LLMs)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传达问题的媒介（对于 LLM 来说，文本是最自然的）
- en: The level of abstraction (with higher abstraction requiring more complex reasoning)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽象级别（更高的抽象需要更复杂的推理）
- en: The context information required (with most domains requiring retrieval of additional
    information besides what is supplied by the user)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要的上下文信息（大多数领域需要检索用户提供的额外信息）
- en: How stateful the problem is (with more complex problem domains requiring memory
    of past interactions and user preferences)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题状态的多变性（更复杂的问题领域需要记住过去的交互和用户偏好）
- en: As you can see in [Table 4-1](#ch04_table_1_1728407230620664), user problem
    domains have various levels of complexity in several dimensions. For example,
    a proofreading application would be low complexity in all dimensions, while a
    travel planning assistant would be quite complex. When you’re building an LLM
    application, you’ll deal with all these forms of complexity in different ways.
    We’ll give you a glimpse into these approaches in this chapter and then greater
    detail on them throughout the rest of this book.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[表 4-1](#ch04_table_1_1728407230620664)中看到的，用户问题领域在多个维度上具有不同的复杂程度。例如，校对应用在所有维度上都是低复杂度，而旅行规划助手则相当复杂。当您构建
    LLM 应用时，您将以不同的方式处理这些复杂形式。在本章中，我们将向您展示这些方法，并在本书的其余部分提供更多细节。
- en: Table 4-1\. Three problem domains (in the columns) in four dimensions of complexity
    (in the rows)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-1\. 复杂性四个维度（行）中的三个问题域（列）
- en: '|   | *Increasing complexity ➜* |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '|   | *复杂性增加➜* |'
- en: '| --- | --- |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|   | Proofreading | IT support assistance | Travel planning |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '|   | 校对 | IT 技术支持协助 | 旅行计划 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ***Medium of the problem*** | Text | Voice over the phone | Complex interactions
    on the website, text input from the user, and interactions with APIs. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| ***问题媒介*** | 文本 | 电话语音 | 网站上的复杂交互、用户输入的文本和与 API 的交互。 |'
- en: '| ***Level of abstraction*** | The problem is concrete, well-defined, and small.
    | A large abstract problem space and a large solution space, but constrained by
    available documentation | The problem involves understanding the user’s subjective
    tastes and objective constraints in order to coordinate a complex solution. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| ***抽象层次*** | 问题具体、定义明确且规模小。 | 一个大的抽象问题空间和大的解决方案空间，但受限于可用的文档 | 涉及理解用户的主体偏好和客观约束，以便协调复杂的解决方案。
    |'
- en: '| ***Context required*** | Nothing more than the text submitted by the user.
    | Searchable access to technical documentation and example support transcripts
    | Access to calendars, airlines APIs, recent news articles, government travel
    recommendations, Wikipedia, etc. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| ***所需上下文*** | 不仅仅是用户提交的文本。 | 可搜索的技术文档和示例支持转录本 | 访问日历、航空公司 API、最近的新闻文章、政府旅行建议、维基百科等。
    |'
- en: '| ***Statefulness*** | No statefulness—every call to the API contains a distinct
    problem statement. | Must track the conversation history and solutions attempted
    | Must track interaction across weeks of planning, different mediums of interaction,
    and aborted branches of planning. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| ***有状态性*** | 无状态性——每次对 API 的调用都包含一个独特的问题陈述。 | 必须跟踪对话历史和尝试过的解决方案 | 必须跟踪跨周的计划、不同的交互媒介和计划中断的分支。
    |'
- en: Converting the User’s Problem to the Model Domain
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将用户问题转换为模型域
- en: 'The next stop on the loop from [Figure 4-1](#ch04_figure_1_1728407230608910)
    is inside the application, where the user’s problem is converted into the domain
    of the model. The crux of prompt engineering lies in this step. The goal is to
    create a prompt so that its completion contains information that can be used to
    address the user’s problem. Crafting just the right prompt is quite a tall order,
    and the application must satisfy the following criteria simultaneously:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从[图 4-1](#ch04_figure_1_1728407230608910)的循环中的下一个停靠点是应用程序内部，在这里用户的问题被转换为模型的域。提示工程的核心在于这一步。目标是创建一个提示，使其完成包含可用于解决用户问题的信息。仅仅构建一个恰到好处的提示是一项相当艰巨的任务，应用程序必须同时满足以下标准：
- en: The prompt must closely resemble content from the training set.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示必须与训练集中的内容非常相似。
- en: The prompt must include all the information relevant to addressing the user’s
    problem.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示必须包含解决用户问题所需的所有相关信息。
- en: The prompt must lead the model to generate a completion that addresses the problem.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提示必须引导模型生成一个解决该问题的完成内容。
- en: The completion must have a reasonable end point so that generation comes to
    a natural stop.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成必须有一个合理的终点，以便生成自然停止。
- en: Let’s dig into each of these criteria. First and foremost, the prompt must closely
    resemble documents from the training set. We call this the *Little Red Riding
    Hood principle*. You remember that story, right? A naive girl dressed in fashionable
    red attire walks along a forest path to visit her ailing grandmother. Despite
    her mother’s stern warnings, the girl strays from the path and has an encounter
    with a wolf (big and bad), and then the story really goes south—much gore...*much
    gore*. It’s really crazy that we tell this story to children.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨这些标准中的每一个。首先，提示必须与训练集中的文档非常相似。我们称之为*小红帽原则*。你还记得这个故事吗？一个穿着时尚红衣的纯真女孩沿着森林小径去探望生病的祖母。尽管母亲严厉警告，女孩还是偏离了道路，遇到了一只（大而坏）狼，然后故事真的变得糟糕——血腥……*血腥*。我们真的不可思议地给孩子们讲这个故事。
- en: 'But for our purposes, the point is simple: don’t stray far from the path upon
    which the model was trained. The more realistic and familiar you make the prompt
    document and the more similar it is to documents from the training set, the more
    likely it is that the completion will be predictable and stable. The Little Red
    Riding Hood principle is one that we will revisit several times in this book.
    For now, suffice to say that you should always mimic common patterns found in
    training data.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 但就我们的目的而言，要点很简单：不要偏离模型训练的路径太远。你使提示文档越真实、越熟悉，它与训练集中文档的相似度越高，那么完成的结果就越有可能预测和稳定。小红帽原则是我们将在本书中多次回顾的原则。现在，只需说，你应该始终模仿训练数据中发现的常见模式。
- en: Tip
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Most of the best LLMs are tight-lipped about their training data, and for good
    reason. If you know exactly how their training documents are formatted, then you
    have a leg up on manipulating the prompt and, say, finding a new jailbreaking
    strategy. However, if you want to see what kinds of documents the models are familiar
    with, then the easiest thing to do is—*just ask*. As an example, try this request:
    `**"What types of formal documents are useful for specifying financial information
    about a company?"**` You should see a large selection of documents to pattern
    your request after. Next, ask the model to generate an example document and see
    if it’s what you need.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数最好的LLM对它们的训练数据守口如瓶，这是有充分理由的。如果你确切知道它们的训练文档是如何格式化的，那么你在操纵提示和，比如说，寻找新的越狱策略上就占有了优势。然而，如果你想看看模型熟悉哪些类型的文档，那么最简单的事情就是——*直接询问*。例如，尝试以下请求：`**"哪些类型的正式文档对于指定公司的财务信息是有用的?"**`你应该会看到一大堆可以模仿你请求的文档。接下来，要求模型生成一个示例文档，看看它是否符合你的需求。
- en: Fortunately, there are endless types of documents and motifs to draw from. For
    completion models, see if you can make the prompt resemble computer programs,
    news articles, tweets, markdown documents, communication transcripts, etc. For
    chat models, the overall document is decided for you—for OpenAI, this is a ChatML
    document that starts with an instructive system message followed by back-and-forth
    exchanges between the user and the assistant character. But you can still use
    the Little Red Riding Hood principle by including common motifs within the user
    messages. For instance, make use of markdown syntax to help the model understand
    the structure of the content. Use a hash sign (`#)` to delimit sections, backticks
    ([PRE0]) [PRE1]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有无数种文档和图案可以借鉴。对于完成模型，看看你是否可以使提示类似于计算机程序、新闻文章、推文、Markdown文档、通信记录等。对于聊天模型，整体文档由你决定——对于OpenAI，这是一个以指导性系统消息开始，随后是用户和助手角色之间来回交流的ChatML文档。但你可以通过在用户消息中包含常见图案来使用小红帽原则。例如，利用Markdown语法来帮助模型理解内容的结构。使用井号（`#`）来分隔部分，反引号([PRE0])
    [PRE1]
- en: Leisure, Travel, and Tourism Studies 101 - Homework Assignment
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 休闲、旅游与旅游研究101 - 家庭作业
- en: Provide answers for the following three problems. Each answer should
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为以下三个问题提供答案。每个答案都应该
- en: be concise, no more than a sentence or two.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要简洁，不超过一两个句子。
- en: Problem 1
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题1
- en: What are the top three golf destinations to recommend to customers?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以向客户推荐哪些是前三名的高尔夫目的地？
- en: Provide the answer as a short sentence.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以简短的句子提供答案。
- en: Solution 1
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案1
- en: St. Andrews, Scotland; Pebble Beach, California; and Augusta, Georgia,
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 圣安德鲁斯，苏格兰；佩布尔滩，加利福尼亚；以及奥古斯塔，乔治亚，
- en: USA (Augusta National Golf Club) are great destinations for golfing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 美国（奥古斯塔国家高尔夫俱乐部）是高尔夫旅行的绝佳目的地。
- en: Problem 2
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题2
- en: Let's say a customer approaches you to help them with *travel plans
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一位客户来找你帮助他们制定*旅行计划
- en: for Pyongyang, North Korea.*
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 朝鲜平壤。*
- en: You check the State Department recommendations, and they advise
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你查看国务院的建议，他们建议
- en: '*"Do not travel to North Korea due to the continuing serious risk'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*"由于持续存在的严重风险，不要前往朝鲜"*'
- en: of arrest and long-term detention of US nationals. Exercise increased
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 美国公民的逮捕和长期拘留。
- en: caution in travel to North Korea due to the critical threat of wrongful
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对朝鲜的旅行存在严重的非法威胁，请谨慎行事。
- en: detention."*
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 拘留。"*
- en: 'You check the recent news and see these headlines:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你查看最近的新闻，看到以下标题：
- en: '- *"North Korea fires ballistic missile, Japan says"*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '- *"朝鲜发射弹道导弹，日本表示"*'
- en: '- *"Five-day COVID-19 lockdown imposed in Pyongyang"*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '- *"平壤实施五天COVID-19封锁"*'
- en: '- *"Yoon renews efforts to address dire North Korean human rights"*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '- *"尹俊熙再次努力解决朝鲜严重的人权问题"*'
- en: Please provide the customer with a short recommendation for travel to
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请为顾客提供一份简短的旅行推荐。
- en: their desired destination. What would you tell the customer?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 顾客希望的目的地。你会告诉顾客什么？
- en: Solution 2
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案 2
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Perhaps North Korea isn't a great destination right now.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 也许现在朝鲜不是一个很好的目的地。
- en: But I bet we could find some nice place to visit in South Korea.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 但我敢打赌我们可以在韩国找到一个不错的旅游地点。
- en: '```'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '```'
- en: '|'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: First, notice how the prompt obeys the Little Red Riding Hood principle—this
    is a homework problem, a type of document that you are likely to find regularly
    in training data. Moreover, the document is formatted in Markdown, a common markup
    language. This will encourage the model to format the document in a predictable
    way, with section headings and syntax indicating bold or italicized words. At
    the most basic level, the document uses proper grammar. This is important, as
    sloppy grammar will encourage the model to generate text in a similar, sloppy
    style. Clearly, we are solidly on the path to Grandmother’s house.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，注意提示如何遵循小红帽原则——这是一个家庭作业问题，这种类型的文档你很可能在训练数据中经常看到。此外，文档以 Markdown 格式编写，这是一种常见的标记语言。这将鼓励模型以可预测的方式格式化文档，使用部分标题和语法来指示加粗或斜体字。在最基本层面上，文档使用正确的语法。这很重要，因为糟糕的语法会鼓励模型以类似的方式生成文本。显然，我们正稳步走向奶奶家。
- en: 'Next, take a look at how the prompt incorporates the context that the LLM will
    need to understand the problem; this context appears in italics in [Table 4-2](#ch04_table_2_1728407230620704).
    First is the actual user problem. Probably, the user has just selected North Korea
    from a drop-down menu on the travel website; they may have even selected it by
    mistake. Nevertheless, it is added to the prompt as the first bold text snippet.
    The subsequent scraps of bold text are pulled from other relevant resources: State
    Department travel recommendations and recent news article headings. For our example,
    this is enough information to make a travel recommendation.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，看看提示如何结合 LLM 需要理解问题的上下文；这个上下文在 [表 4-2](#ch04_table_2_1728407230620704) 中以斜体形式出现。首先是实际的用户问题。可能用户刚刚从旅行网站的下拉菜单中选择了朝鲜；他们甚至可能不小心选了它。尽管如此，它被添加到提示中作为第一个加粗文本片段。随后的加粗文本片段是从其他相关资源中提取的：国务院旅行建议和最近的新闻文章标题。对于我们的例子，这些信息足以做出旅行推荐。
- en: 'There are several ways in which this prompt leads the model toward a definite
    solution, rather than toward further elaboration of the problem. In the first
    line, we condition the model toward the type of response we hope to see—something
    within the domain of leisure, travel, and tourism. Next, we include an example
    problem. This has nothing to do with the user’s current request, but it establishes
    a pattern for the model: the problem will begin with `## Problem N` and will be
    followed by a solution starting with `## Solution N`.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方式可以引导模型走向明确的解决方案，而不是进一步阐述问题。在第一行，我们引导模型向希望看到的响应类型——休闲、旅行和旅游领域内的某种内容。接下来，我们包括一个示例问题。这与用户当前请求无关，但它为模型建立了一个模式：问题将以
    `## 问题 N` 开头，随后将以 `## 解决方案 N` 开头提供解决方案。
- en: 'Problem 1 also encourages the use of a certain voice for the subsequent answers—concise
    and polite. The fact that solution 1 is a short sentence further encourages the
    continuation of this pattern in the completion. With this pattern in place, problem
    2 is the actual user problem. We set up the problem, insert the context, and make
    the ask: `What would you tell the customer?` With the text `## Solution 2`, we
    then indicate that the problem statement is over and it’s time for the answer.
    If we had omitted this, then the model would likely have continued elaborating
    upon the problem by confabulating more information about North Korea.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1 还鼓励在随后的答案中使用某种语气——简洁且礼貌。由于解决方案 1 是一个简短的句子，这进一步鼓励在完成过程中继续这种模式。有了这种模式，问题
    2 就是实际的用户问题。我们设定了问题，插入上下文，并提出问题：`你会告诉顾客什么？` 使用文本 `## 解决方案 2`，我们表明问题陈述已经结束，现在是回答的时候。如果我们省略了这一点，那么模型可能会继续通过虚构更多关于朝鲜的信息来详细阐述问题。
- en: 'The last task is to insist upon a firm stop. Since every new section of markdown
    begins with ##, we have a pattern that we can capitalize upon. If the model begins
    to confabulate a third problem, then we can cut off the model completion by specifying
    stop text, which tells the model to halt generation as soon as this text is produced.
    In this case, a reasonable choice for stop text is `\n#`, which indicates that
    the model has completed the current solution and is beginning a new section, possibly
    the start of a confabulated problem 3.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的任务是坚持一个明确的停止点。由于每个新的Markdown部分都以##开头，我们有一个可以利用的模式。如果模型开始编造第三个问题，那么我们可以通过指定停止文本来切断模型生成，告诉模型一旦产生这个文本就停止生成。在这种情况下，一个合理的停止文本选择是`\n#`，这表示模型已经完成了当前解决方案，并开始了一个新的部分，可能是编造问题的第3部分。
- en: Chat models versus completion models
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聊天模型与生成模型
- en: In the preceding example, we’ve relied on a completion model to demonstrate
    the criteria for converting between the user domain and the model domain. With
    the introduction of chat models, much of this is simplified. The chat APIs ensure
    that the input into the models will closely resemble the fine-tuning data because
    the messages will be internally formed into a transcript document (criterion 1
    from the beginning of this section). The model is highly conditioned to provide
    a response that addresses the user’s problem (criterion 3), and the model will
    always stop at a reasonable point—at the end of the assistant’s message (criterion
    4).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们依靠一个生成模型来展示用户域与模型域之间转换的标准。随着聊天模型的引入，许多过程都得到了简化。聊天API确保输入到模型中的数据将非常接近微调数据，因为消息将被内部形成为一个转录文档（本节开头的第1个标准）。模型高度条件化，能够提供解决用户问题的响应（第3个标准），并且模型将在合理的位置停止——即在助手消息的结尾（第4个标准）。
- en: But this doesn’t mean that you, as the prompt engineer, are off the hook! You’re
    fully responsible for including all the relevant information for addressing the
    user’s problem (criterion 2). You must craft the text within the chat so that
    it resembles characteristics of documents in training (criterion 1). Most importantly,
    you must shape the transcript, system message, and function definitions so that
    the model can successfully address the problem and come to a stopping point (criteria
    3 and 4).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不意味着你，作为提示工程师，就可以免责！你必须完全负责包括解决用户问题所需的所有相关信息（第2个标准）。你必须编写聊天中的文本，使其类似于训练文档的特征（第1个标准）。最重要的是，你必须塑造转录、系统消息和功能定义，以便模型能够成功解决问题并达到停止点（第3和第4个标准）。
- en: Using the LLM to Complete the Prompt
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LLM完成提示
- en: Referring back to [Figure 4-1](#ch04_figure_1_1728407230608910), in the next
    stage of the LLM-application loop, you submit the prompt to the model and retrieve
    the completion. If you’ve played with only one particular model, such as ChatGPT,
    you might be under the impression that there are no decisions to make here—just
    send the model a prompt and wait for the completion, just as we showed in the
    example. However, all models are *not* alike!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[图4-1](#ch04_figure_1_1728407230608910)，在LLM应用循环的下一阶段，你将提示提交给模型并检索生成内容。如果你只玩过一种特定的模型，比如ChatGPT，你可能会认为这里没有需要做的决定——只需将提示发送给模型并等待生成内容，就像我们在示例中展示的那样。然而，所有模型并不相同！
- en: You’ll have to decide how big your model should be. Typically, the larger the
    model is, the higher quality its completions will be. But there are some very
    important trade-offs, such as cost. At the time of writing this book, running
    GPT-4 can be *20 times* more expensive than running gpt-3.5-turbo. Is the quality
    improvement worth the order-of-magnitude increase in price? Sometimes, it is!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你将不得不决定你的模型应该有多大。通常，模型越大，其生成内容的质量越高。但有一些非常重要的权衡，比如成本。在撰写这本书的时候，运行GPT-4的成本可能是运行gpt-3.5-turbo的*20倍*。这种质量提升是否值得价格上数量级的增加？有时候，是值得的！
- en: Also of importance is the latency. Bigger models require more computation, and
    more computation might require more time than your users can spare. In the early
    days of GitHub Copilot, we decided to use an OpenAI model called Codex, which
    is small, *sufficiently* smart, and lightning fast. If we had used GPT-4, then
    users would have rarely been inclined to wait for the completion, no matter how
    good it was.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要因素是延迟。更大的模型需要更多的计算，而更多的计算可能需要比用户能提供的更多时间。在GitHub Copilot的早期阶段，我们决定使用一个名为Codex的OpenAI模型，它体积小、*足够智能*且速度极快。如果我们使用了GPT-4，那么无论补全结果有多好，用户很少会愿意等待。
- en: Finally, you should consider whether or not you can gain better performance
    through fine-tuning. At GitHub, we’re experimenting with fine-tuning Codex models
    to provide higher quality results for less common languages. In general, fine-tuning
    can be useful when you want the model to provide information that is unavailable
    in the public datasets that the model was originally trained on, or when you want
    the model to exhibit behavior that is different from the behavior of the original
    model. The process of fine-tuning is beyond the scope of this book, but we’re
    confident that fine-tuning models will become simpler and more commonplace, so
    it’s definitely a tool you should have in your belt.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你应该考虑是否可以通过微调来获得更好的性能。在GitHub上，我们正在尝试微调Codex模型，以提供对不常见语言的高质量结果。一般来说，当您希望模型提供在模型最初训练的公共数据集中不可用的信息，或者希望模型表现出与原始模型不同的行为时，微调是有用的。微调的过程超出了本书的范围，但我们相信微调模型将变得更加简单和普遍，因此这绝对是一个你应该拥有的工具。
- en: Transforming Back to User Domain
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换回用户领域
- en: Let’s dig into the final phase of the loop from [Figure 4-1](#ch04_figure_1_1728407230608910).
    The LLM completion is a blob of text. If you’re making a simple chat app of some
    sort, then maybe you’re done—just send the text back to the client and present
    it directly to the user. But more often, you will need to transform the text or
    harvest information from it to make it useful to the end user.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨[图4-1](#ch04_figure_1_1728407230608910)的循环的最后一阶段。LLM的补全是一个文本块。如果你正在制作某种简单的聊天应用，那么你可能已经完成了——只需将文本发送回客户端并直接呈现给用户。但更常见的情况是，你需要转换文本或从中提取信息，使其对最终用户有用。
- en: With the original completion models, this often meant asking the model to present
    specific data with a very specific format and then to parse that information out
    and present it back to the user. For instance, you might have asked the model
    to read a document and then generate tabular information that would have been
    extracted and represented back to the user.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始的补全模型，这通常意味着要求模型以非常特定的格式呈现特定数据，然后解析这些信息并将其呈现给用户。例如，你可能要求模型阅读一份文档，然后生成表格信息，这些信息将被提取并呈现给用户。
- en: However, since the appearance of function-calling models, converting model output
    into information that’s useful to the user has become quite a bit easier. For
    these models, the prompt engineer lays out the user’s problem, gives the model
    a list of functions, and then asks the model to generate text. The generated text
    then represents a function call.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，自从函数调用模型出现以来，将模型输出转换为对用户有用的信息变得容易得多。对于这些模型，提示工程师概述用户的问题，给模型提供一个函数列表，然后要求模型生成文本。生成的文本代表一个函数调用。
- en: For instance, in a travel app, you might provide the model with functions that
    can look up airline flights and a description of a user’s travel goals. The model
    might then generate a function call requesting tickets for a particular date with
    the user’s requested origin and destination. An LLM application can use this to
    call the actual airline’s API, retrieve available flights, and present them to
    the user—back in the user’s domain.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个旅行应用中，你可能为模型提供查找航班和描述用户旅行目标的功能。然后，模型可能会生成一个函数调用，请求特定日期的机票，以及用户请求的出发地和目的地。LLM应用可以使用这个功能调用实际的航空公司API，检索可用航班，并将它们呈现给用户——在用户的领域内。
- en: You can go further by giving the model functions that actually create a change
    in the real world. For instance, you can provide the model with functions that
    actually purchase tickets. When the model generates a function call to purchase
    tickets, the application can double-check with the user that this is OK and then
    complete the transaction. Thus, you have translated from the model domain—text
    representing a function call—to the user domain in the form of an actual purchase
    on the user’s behalf. We will go into more detail about this in Chapters [8](ch08.html#ch08_01_conversational_agency_1728429579285372)
    and [9](ch09.html#ch09_llm_workflows_1728407155661595).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过给模型提供实际上能改变现实世界的函数来更进一步。例如，你可以向模型提供实际上能购买票的函数。当模型生成一个购买票的函数调用时，应用程序可以与用户双重检查这是否可以，然后完成交易。因此，你将模型领域——表示函数调用的文本——转化为用户领域，形式是代表用户进行的实际购买。我们将在第
    [8](ch08.html#ch08_01_conversational_agency_1728429579285372) 章和第 [9](ch09.html#ch09_llm_workflows_1728407155661595)
    章中更详细地介绍这一点。
- en: Finally, when transforming back to the user domain, you may change the medium
    of communication entirely. The model generates in text, but if the user is speaking
    to an automated tech support system over their phone, then the model completions
    will need to be converted into speech. If the user is using an application with
    a complicated UI, then the model completions might represent events that modify
    elements of the UI.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当转换回用户领域时，你可能需要完全改变沟通的媒介。模型生成文本，但如果用户通过电话与自动技术支持系统交谈，那么模型完成结果需要转换为语音。如果用户使用具有复杂
    UI 的应用程序，那么模型完成结果可能代表修改 UI 元素的事件。
- en: And even if the user’s domain is text, it might still be necessary to modify
    the presentation of the model completions. For instance, Copilot code completion
    is represented as a grayed-out code snippet in the IDE, which the user can accept
    by pressing Tab. But when you use Copilot chat to ask for a code change, the results
    are presented as a red/green text diff.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 即使用户的领域是文本，也可能仍然需要修改模型完成结果的呈现方式。例如，Copilot 代码补全在 IDE 中表示为灰色代码片段，用户可以通过按 Tab
    键接受。但是，当你使用 Copilot 聊天请求代码更改时，结果将以红/绿文本差异的形式呈现。
- en: Zooming In to the Feedforward Pass
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 放大前向传递
- en: Let’s spend some more time examining the LLM-application loop from [Figure 4-1](#ch04_figure_1_1728407230608910)—specifically,
    the *feedforward pass*, which is the part of the loop where you convert the user
    problem into the domain of the model. Almost all of the remaining chapters in
    this book will go into great detail about just *how* we achieve high-quality completions.
    But before we get into the nitty-gritty, let’s lay down some foundational ideas
    that we’ll build on in coming chapters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花更多时间检查 [图 4-1](#ch04_figure_1_1728407230608910) 中的 LLM-应用程序循环——特别是*前向传递*，这是循环中将用户问题转化为模型领域的那部分。本书剩余的大部分章节将详细讨论我们如何实现高质量完成。但在我们深入细节之前，让我们确定一些基础思想，这些思想将在接下来的章节中加以构建。
- en: Building the Basic Feedforward Pass
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建基本前向传递
- en: The feedforward pass is composed of several basic steps that allow you to translate
    the user’s problem into the text domain (see [Figure 4-2](#fig-4-2)). The middle
    chapters of this book will cover these steps in detail.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前向传递由几个基本步骤组成，这些步骤允许你将用户问题转化为文本领域（见图 4-2）。本书的中间章节将详细介绍这些步骤。
- en: '![A diagram of a application process  Description automatically generated](assets/pefl_0402.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![应用程序流程图  描述自动生成](assets/pefl_0402.png)'
- en: Figure 4-2\. Typical basic steps for translating the user’s problem into the
    domain of the LLM
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 将用户问题转化为 LLM 领域的典型基本步骤
- en: Context retrieval
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文检索
- en: The first thing you do to build the feedforward pass is create or retrieve the
    raw text that serves as the context information for the prompt. One way to think
    through this problem is to consider context in terms of how *direct* or *indirect*
    it is.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 构建前向传递的第一件事是创建或检索作为提示上下文信息的原始文本。思考这个问题的方法之一是将上下文视为它是多么的*直接*或*间接*。
- en: The *most* *direct* context comes straight from the user as they describe their
    problem. If you’re building a tech support assistant, this is the text that the
    user types directly into the help box; with GitHub Copilot, this is the code block
    that the user is editing right now.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的上下文直接来自用户，因为他们描述他们的问题时。如果你正在构建一个技术支持助手，这就是用户直接输入到帮助框中的文本；在 GitHub Copilot
    中，这就是用户正在编辑的代码块。
- en: Indirect context comes from relevant sources nearby. If you’re building a tech
    support app, for example, you might search documentation for excerpts that address
    the user’s problem. For Copilot, the indirect context comes largely from other
    open tabs in the developer’s IDE because these files often include snippets relevant
    to the user’s current problem. The least direct context corresponds to the boilerplate
    text that is used to shape the response of the model. For a tech support app,
    this could be the message at the top of the prompt that says, “This is an IT support
    request. We do whatever it takes to help users solve their problems.”
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 间接上下文来自附近的有关来源。例如，如果你正在构建一个技术支持应用，你可能需要搜索文档以找到解决用户问题的摘录。对于Copilot来说，间接上下文主要来自开发者在IDE中的其他打开的标签页，因为这些文件通常包含与用户当前问题相关的片段。最间接的上下文对应于用于塑造模型响应的模板文本。对于一个技术支持应用来说，这可能就是提示符顶部的消息：“这是一个IT支持请求。我们尽一切努力帮助用户解决问题。”
- en: Boilerplate text at the top of the prompt is used to introduce the general problem.
    Later in the prompt, it acts as a glue to connect the bits of direct context in
    such a way that it makes sense to the model. For instance, the nonbolded text
    in [Table 4-2](#ch04_table_2_1728407230620704) is boilerplate. The boilerplate
    at the top of the table introduces the travel problem, and the boilerplate farther
    down allows us to incorporate information directly from the user regarding travel
    plans as well as relevant information pulled from news and government sources.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 提示符顶部的模板文本用于介绍一般问题。在提示符的后续部分，它充当粘合剂，以连接直接上下文中的各个部分，使其对模型有意义。例如，[表4-2](#ch04_table_2_1728407230620704)中的非粗体文本就是模板文本。表格顶部的模板文本介绍了旅行问题，而表格下方的模板文本则允许我们直接从用户那里获取有关旅行计划的信息，以及从新闻和政府来源获取的相关信息。
- en: Snippetizing context
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 片段化上下文
- en: Once the relevant context has been retrieved, it must be snippetized and prioritized.
    *Snippetizing* means breaking down the context into the chunks most relevant for
    the prompt. For instance, if your IT support application issues a documentation
    search and returns with pages of results, then you must extract only the most
    relevant passages; otherwise, we may exceed the prompt’s token budget.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦检索到相关上下文，就必须将其片段化并优先排序。*片段化*意味着将上下文分解成与提示符最相关的块。例如，如果你的IT支持应用执行文档搜索并返回多页结果，那么你必须只提取最相关的段落；否则，我们可能会超出提示符的令牌预算。
- en: Sometimes, snippetizing means creating text snippets by converting context information
    from a different format. For instance, if the tech support application is a phone
    assistant, then you need to transcribe the user’s request from voice to text.
    If your context retrieval calls out to a JSON API, then it might be important
    to format the response as natural language so that the model will not incorporate
    JSON fragments into its response.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，片段化意味着通过将上下文信息从不同格式转换为文本片段。例如，如果技术支持应用是一个电话助手，那么你需要将用户的语音请求转录为文本。如果你的上下文检索调用JSON
    API，那么将响应格式化为自然语言可能很重要，这样模型就不会将其响应中包含JSON片段。
- en: Scoring and prioritizing snippets
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评分和优先排序片段
- en: The token window of the original GPT-3.5 models was a measly 4,096 tokens, so
    running out of space was once a pressing concern in any LLM application. Now,
    with token windows upward of 100,000 tokens, it’s less likely that you’ll run
    out of space in your prompt. However, it’s still important to keep your prompts
    as trim as possible because long blobs of irrelevant text will confuse the model
    and lead to worse completions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 原始GPT-3.5模型的令牌窗口仅为4,096个令牌，因此在任何LLM应用中，空间不足曾经是一个紧迫的问题。现在，随着令牌窗口超过100,000个令牌，在提示符中空间不足的可能性降低了。然而，仍然非常重要，尽可能保持提示符简洁，因为大量无关的文本会混淆模型并导致更差的完成结果。
- en: To pick the best content, once you’ve gathered a set of snippets, you should
    assign each snippet either a priority or a score corresponding to how important
    that snippet will be for the prompt. We have very specific definitions of scores
    and priorities. *Priorities* can be thought of as integers that establish tiers
    of snippets based upon how important they are and how they function in the prompt.
    When assembling the prompt, you’ll make sure that all snippets from a higher tier
    are utilized before dipping into the snippets from the next tier. *Scores*, on
    the other hand, can be thought of as floating-point values that emphasize the
    shades of difference between snippets. Some snippets within the same priority
    tier are more relevant than others and should be used first.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了挑选最佳内容，一旦你收集了一组片段，你应该为每个片段分配一个优先级或分数，以反映该片段对提示的重要性。我们对分数和优先级有非常具体的定义。*优先级*可以被视为整数，根据片段的重要性和在提示中的作用建立层级。在组装提示时，你将确保在深入下一层级的片段之前，先利用所有更高层级的片段。另一方面，*分数*可以被视为浮点值，强调片段之间差异的细微差别。在同一优先级层级的某些片段比其他片段更相关，应该首先使用。
- en: Prompt assembly
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示组装
- en: 'In the last step, all of this snippet fodder gets assembled into the final
    prompt. You have many goals during this step: you must clearly convey the user’s
    problem and pack the prompt as full of the best supporting context as possible—and
    you must *make sure* not to exceed the token budget, because all you’ll get back
    from the model in that case is an error message.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，所有这些片段素材被组装成最终的提示。在这个过程中，你有许多目标：你必须清楚地传达用户的问题，尽可能地将提示填充最佳支持上下文——并且你必须*确保*不要超过令牌预算，因为在这种情况下，你从模型那里得到的将只是一个错误信息。
- en: It’s at this point where accounting comes heavily into play. You must make sure
    that all your boilerplate instructions fit in the prompt context, make sure that
    the user’s request fits, and then collect as much supporting context as possible.
    Sometimes, during this step, you might want to make a last-minute effort to shorten
    the context. For instance, if you know that a full code file is relevant to the
    user’s answer but doesn’t fit, you have an option during this step to elide (remove)
    less relevant lines of code until the document fits. If you have a long document,
    you can also employ summarization.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 正是在这一点上，会计工作变得尤为重要。你必须确保所有你的模板指令都适合提示上下文，确保用户的要求适合，然后尽可能收集更多的支持上下文。有时，在这个过程中，你可能想要在最后一刻努力缩短上下文。例如，如果你知道整个代码文件与用户的答案相关，但又不适合，那么在这个步骤中，你可以选择省略（删除）不那么相关的代码行，直到文档适合。如果你有一个很长的文档，你也可以使用摘要。
- en: In addition to making sure all the pieces fit, you must ensure they are assembled
    into their proper order. Then, the final prompt document should read like a document
    you might find in the training data (leading Little Red Riding Hood on the path
    directly to Grandma’s house).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 除了确保所有部件都适合外，你还必须确保它们被组装成正确的顺序。然后，最终的提示文档应该像你可能在训练数据中找到的文档一样（引领小红帽直接走向奶奶家）。
- en: Exploring the Complexity of the Loop
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索循环的复杂性
- en: 'The previous section focused on the simplest type of LLM application—one that
    does all of its work in a single request to the model and then returns the completion
    to the user. Such a simple application is important to understand because it serves
    as the starting point. It presents basic principles upon which applications of
    increasing complexity are built. As applications get more complex, there are several
    dimensions along which this complexity comes into play:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节重点介绍了最简单的LLM应用类型——这种类型在向模型发出单个请求完成所有工作后，然后将完成的内容返回给用户。这种简单的应用很重要，因为它是一个起点。它提出了构建越来越复杂应用的基本原则。随着应用的复杂化，有几个维度在这个复杂性中发挥作用：
- en: More application state
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的应用状态
- en: More external content
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多外部内容
- en: More complex reasoning
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更复杂的推理
- en: More complex interaction with the world outside of the model
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与模型外部世界的更复杂交互
- en: Persisting application state
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持久化应用状态
- en: The feedforward application from the previous section holds no persistent state.
    It simply takes the user’s input, adds on some *hopefully* relevant context, passes
    it on to the model, and then passes the model’s response back to the user. In
    this simple world, if the user makes another request, the application has no recollection
    of the previous exchange. Copilot code completion is an application that works
    exactly this way.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中的前馈应用没有持久的状态。它只是接受用户的输入，添加一些*希望*相关的上下文，将其传递给模型，然后将模型的响应传递回用户。在这个简单的世界中，如果用户再次请求，应用不会记得之前的交流。Copilot代码补全就是一个按照这种方式工作的应用。
- en: More complex LLM applications usually require state to be maintained between
    requests. For instance, even the most basic chat application must maintain a record
    of the conversation. During the middle of a chat session, when the user submits
    a new message to the application, the application looks up this conversation thread
    in a database and uses the previous exchanges as further context for the next
    prompt.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的LLM应用通常需要在请求之间保持状态。例如，即使是最基本的聊天应用也必须维护对话记录。在聊天过程中，当用户向应用提交新消息时，应用会在数据库中查找这个对话线程，并使用之前的交流作为下一个提示的进一步上下文。
- en: If a user’s interactions are long running, then you may need to abridge the
    history to fit it into the prompt. The easiest way to accomplish this is by just
    truncating the conversation and cutting off the earlier exchanges. This won’t
    always work, though! Sometimes, the content is too important to cut, so another
    approach is to summarize earlier parts of the conversation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户的交互过程较长，你可能需要缩减历史记录以适应提示。最简单的方法就是截断对话并切断早期的交流。但这并不总是可行的！有时，内容过于重要而不宜删减，因此另一种方法是总结对话的早期部分。
- en: External context
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 外部上下文
- en: LLMs—even the best ones—don’t have *all* the answers. How could they? They’ve
    been trained only on publicly available data, and they have no clue about recent
    events and information that is hidden behind a corporate, government, or personal
    privacy wall. If you ask a model about information that it does not possess, then
    *ideally*, it will apologize and explain that it doesn’t have access to that information.
    This doesn’t lead to user satisfaction, but it’s infinitely better than the alternative—the
    model confidently hallucinating an answer and telling the user something that
    is completely false.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs——即使是最好的——也不是全能的。他们怎么可能呢？他们只接受了公开可用的数据训练，对隐藏在公司、政府或个人隐私墙背后的最近事件和信息一无所知。如果你询问模型它不具备的信息，那么理想情况下，它会道歉并解释它无法访问该信息。这不会导致用户满意，但比起另一种情况——模型自信地编造一个答案并向用户传达完全错误的信息——要好得多。
- en: For this reason, many LLM applications employ retrieval augmented generation
    (RAG). With RAG, you augment the prompt with context drawn from sources that were
    unavailable to the model during training. This could be anything from your corporate
    documentation to your user’s medical records to recent news events and recently
    published papers.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，许多大型语言模型（LLM）应用都采用了检索增强生成（RAG）技术。在RAG中，你通过从模型训练期间不可用的来源中提取的上下文来增强提示。这可以是公司文档、用户的医疗记录、最近发生的事件以及最近发表的论文等任何内容。
- en: This information is indexed into a search engine of some sort. Lots of people
    have been using embedding models to convert documents (or document fragments)
    into vectors that can be stored in a vector store (like Pinecone). However, you
    shouldn’t turn up your nose at good old-fashioned search indexes (such as Elasticsearch)
    because they tend to be relatively simple to manage and much easier to debug with
    when you don’t seem to be finding the documents that you’re looking for.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息被索引到某种搜索引擎中。许多人一直在使用嵌入模型将文档（或文档片段）转换为可以存储在向量存储（如Pinecone）中的向量。然而，你不应该对传统的搜索索引（如Elasticsearch）嗤之以鼻，因为它们通常相对简单易管理，并且在你似乎找不到所需文档时更容易调试。
- en: Actually retrieving the context usually follows a spectrum of possible approaches.
    The simplest is to directly use the user’s request as the search query. However,
    if your user’s request is a long run-on paragraph, then it might have extraneous
    content that causes spurious matches to come back from the index. In this case,
    you can ask the LLM what it thinks a good search will be and just use its response
    text to search the index. Finally, if your application is in some sort of long
    chat with a user, it might not at all be apparent when it’s worth even searching
    for something; you can’t retrieve documents for every comment they have because
    they might still be talking about documents related to their last comment. In
    this case, you can introduce a *search tool* to the assistant and let the assistant
    choose when to make a search and what search terms to use. (We’ll introduce tool
    usage just a bit further on.)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 实际检索上下文通常遵循一系列可能的方法。最简单的是直接使用用户的请求作为搜索查询。然而，如果用户的请求是一个长的连续段落，那么它可能包含一些无关的内容，这会导致索引返回虚假匹配。在这种情况下，你可以询问LLM它认为一个好的搜索会是什么，然后只需使用它的响应文本来搜索索引。最后，如果你的应用程序与用户进行某种形式的长时间聊天，那么可能根本不明显何时值得搜索某些内容；你不能为他们的每个评论检索文档，因为他们可能还在谈论与他们的最后评论相关的文档。在这种情况下，你可以向助手引入一个*搜索工具*，让助手选择何时进行搜索以及使用什么搜索词。（我们将在稍后介绍工具的使用。）
- en: Increasing reasoning depth
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增加推理深度
- en: As we covered in [Chapter 1](ch01.html#ch01_1_introduction_to_prompt_engineering_1728408393615260),
    the really spectacular thing about the larger LLMs starting with GPT-2 was that
    they began to generalize much more broadly than their predecessors. The paper
    entitled [“Language Models are Unsupervised Multitask Learners”](https://oreil.ly/MEw4b)
    makes just this point—GPT-2, trained on millions of web pages, was able to beat
    benchmarks in several categories that had until that point required very specialized
    model training.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](ch01.html#ch01_1_introduction_to_prompt_engineering_1728408393615260)中提到的，从GPT-2开始的更大LLMs真正令人惊叹的事情是，它们开始比前辈更广泛地泛化。标题为“[“语言模型是无监督的多任务学习者”](https://oreil.ly/MEw4b)”的论文正是这个观点——在数百万个网页上训练的GPT-2能够击败之前需要非常专业模型训练的几个类别的基准。
- en: For instance, to get GPT-2 to summarize text, you could append the string `**TL;DR**`
    to the end of the text, et voilà! And to get GPT-2 to translate text from English
    to French, you could just provide it with one example translation and then subsequently
    provide the English sentence to be translated. The model would pick up on the
    pattern and translate accordingly. It was as if the model were actually in some
    way *reasoning* about the text in the prompt. In subsequent years, we’ve found
    ways to elicit more sophisticated patterns of reasoning from the LLMs. One simple
    but effective approach is to insist that the model show its step-by-step thought
    process *before* providing the answer to the problem. This is called *chain-of-thought*
    prompting. The intuition behind this is that, unlike humans, LLMs have no internal
    monologue, so they can’t really think *about* a problem before answering.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要使GPT-2总结文本，你可以在文本末尾附加字符串`**TL;DR**`，然后就是！要使GPT-2将文本从英语翻译成法语，你只需提供一个示例翻译，然后提供要翻译的英语句子。模型会注意到这个模式并相应地进行翻译。这就像模型实际上以某种方式在*推理*提示中的文本一样。在随后的几年里，我们发现了一些从LLMs中引发更复杂推理模式的方法。一种简单但有效的方法是坚持要求模型在提供问题的答案之前展示其逐步的思考过程。这被称为*思维链*提示。这种直觉背后的想法是，与人类不同，LLMs没有内部独白，因此它们在回答之前不能真正地*思考*问题。
- en: Instead, each token is mechanically generated as a function of every token that
    preceded it. Therefore, if you want to have the model “think” about a problem
    before answering, the thinking must be done “out loud” in the completion. Afterward,
    when subsequent tokens are calculated, the model will predict tokens that are
    as consistent as possible with the preceding tokens and therefore consistent with
    their “thought process.” This often leads to much better-reasoned answers.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，每个标记都是作为前一个标记的函数机械生成的。因此，如果你想让模型在回答问题之前“思考”一下，这种思考必须在完成过程中“大声”进行。之后，当计算后续标记时，模型将预测与先前标记尽可能一致的标记，因此与它们的“思考过程”一致。这通常会导致推理更加合理的答案。
- en: As LLM applications require more complicated work to be completed, the prompt
    engineer must find clever ways to break the problem down and elicit the right
    step-by-step thinking for each component to drive the model to a better solution.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM应用需要完成更复杂的工作，提示工程师必须找到巧妙的方法来分解问题，并激发每个组件的正确逐步思考，以驱动模型达到更好的解决方案。
- en: Tool usage
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工具使用
- en: By themselves, LLMs act in a closed world—they know nothing about the outside
    world and have no ability to effect change in the outside world. This constraint
    seriously limits the utility of LLM applications. In response to this weakness,
    most frontier LLMs are now able to interact with the world through *tools*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 单独来看，大型语言模型在封闭世界中行动——它们对现实世界一无所知，并且无法对现实世界产生影响。这种限制严重限制了LLM应用的实用性。为了应对这种弱点，现在大多数前沿的LLM都能够通过*工具*与世界互动。
- en: Take a look at the *tool loop* in [Figure 4-3](#ch04_figure_3_1728407230608987).
    The idea is simple. In the prompt, you make the model aware of one or more tools
    that it has access to. The tools will look like functions including a name, several
    arguments, and descriptions for the name and arguments. During a conversation,
    the model can choose to execute these tools—basically by calling one of the functions
    with an appropriate set of arguments.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看[图 4-3](#ch04_figure_3_1728407230608987)中的*工具循环*。其想法很简单。在提示中，你让模型意识到它可以使用的一个或多个工具。这些工具将看起来像包括名称、几个参数以及名称和参数描述的函数。在对话中，模型可以选择执行这些工具——基本上是通过调用一个具有适当参数集的函数。
- en: '![](assets/pefl_0403.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0403.png)'
- en: Figure 4-3\. A more complicated application loop that includes an internal tool
    loop
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 包含内部工具循环的更复杂的应用循环
- en: Note that LLM-applications can become quite complex. Conversations are stateful,
    and the context must be preserved from one request to the next. Information from
    external APIs is used to augment the data, and the tool execution loop may iterate
    several times back and forth between the application and the model before information
    can be returned to the user*.*
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，LLM应用可能会变得相当复杂。对话是有状态的，上下文必须从一次请求保留到下一次请求。来自外部API的信息用于增强数据，工具执行循环可能在应用和模型之间来回迭代多次，信息才能返回给用户*。
- en: Naturally, the model has no ability to actually execute code, so it is the responsibility
    of the LLM application to intercept this function call from the model and execute
    a real-world API and the appended information from the response to the prompt.
    Because of this, on the next turn, the model can use that information to reason
    about the problem at hand.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，模型本身没有能力实际执行代码，因此拦截模型从LLM应用中执行该函数调用的责任就落在了LLM应用上，并执行现实世界的API以及从提示中附加的信息。正因为如此，在下一轮中，模型可以使用这些信息来对当前的问题进行推理。
- en: 'One of the earlier papers to consider tool usage was [“ReAct: Synergizing Reasoning
    and Acting in Language Models”](https://arxiv.org/abs/2210.03629) (2022). It introduced
    three tools: `search`, `lookup`, and `finish`, which, respectively, allowed the
    model to search through Wikipedia, look up relevant blocks of text within a Wikipedia
    page, and return the answer to the user. This shows how tool usage can overlap
    with RAG—namely, if you provide the model with search tools, it will be able to
    make its own determination of when it needs external information and how to find
    it.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '考虑工具使用的早期论文之一是[“ReAct: 在语言模型中协同推理和行动”](https://arxiv.org/abs/2210.03629) (2022)。它介绍了三个工具：`search`、`lookup`和`finish`，分别允许模型在维基百科中搜索、查找维基百科页面中的相关文本块，并向用户返回答案。这展示了工具使用如何与RAG重叠——即，如果你向模型提供搜索工具，它将能够自行决定何时需要外部信息以及如何找到它。'
- en: Search, though, is a read-only behavior. Similarly, tools connected to external
    APIs that check the temperature, determine if you have any new emails, or retrieve
    recent LinkedIn posts are all read-only. Where things get really interesting is
    when we allow them to write changes out into the real world. Since tools give
    models access to any real-world API imaginable, you’ll be able to create LLM-based
    assistants that can write code and create pull-requests, help you plan travel
    and reserve airfare and lodging, and so much more. Naturally, *with great power
    comes great* *responsibility*. Models are probabilistic and *often* make mistakes,
    so don’t let the LLM application book a trip to Greece just because the user said
    they would love to visit someday!
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，搜索是一种只读行为。同样，连接到外部API的工具，如检查温度、确定你是否收到了新邮件或检索最近的LinkedIn帖子，也都是只读的。真正有趣的地方在于，当我们允许它们将更改写入现实世界时。由于工具使模型能够访问任何可想象的现实世界API，你将能够创建基于LLM的助手，这些助手可以编写代码和创建拉取请求，帮助你规划旅行并预订机票和住宿，等等。当然，*权力越大，责任越大*。模型是概率性的，*经常*会出错，所以不要让LLM应用仅因为用户表示他们有一天想去希腊就预订旅行！
- en: Evaluating LLM Application Quality
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估LLM应用质量
- en: Again, we say that LLMs are probabilistic and *often* make mistakes. Therefore,
    when designing and productionizing an LLM application, it is imperative that you
    constantly evaluate application quality. Before you ship a new LLM-based feature,
    take time to prototype the functionality and gather some quantitative metrics
    about how the model will react. And then, once a feature ships, your application
    should be recording telemetry so that you can keep an eye on both the model’s
    and the users’ behavior so that you can quickly ascertain any degradation in the
    quality of the application.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，LLM是概率性的，*经常*会出错。因此，在设计并生产化LLM应用时，持续评估应用质量至关重要。在你发布新的基于LLM的功能之前，花时间原型化功能并收集一些关于模型如何反应的定量指标。然后，一旦功能发布，你的应用应该记录遥测数据，这样你就可以密切关注模型和用户的行为，以便快速确定应用质量的任何下降。
- en: Offline Evaluation
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线下评估
- en: '*Offline evaluation* is all about trying new ideas for your LLM application
    *before* exposing your users to an untested new experience. If anything, offline
    evaluation is even more complex than online evaluation, which we described later
    in this section. Since, before shipping a feature to production, you don’t have
    any customers to tell you “good” or “bad,” you have to figure out some simulated
    proxy for this evaluation.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*线下评估* 是在将新想法应用于你的LLM应用之前，向用户展示未经测试的新体验。实际上，线下评估甚至比我们在本节后面描述的在线评估更为复杂。因为，在将一个功能发布到生产之前，你没有任何客户告诉你“好”或“坏”，你必须找出一些模拟的代理来评估这一点。'
- en: Sometimes, you get lucky. For example, with Copilot code completions, a good
    proxy for user satisfaction is whether or not the code is functional and complete.
    In the case of code, this is actually quite easy to measure—if you can delete
    fragments of working code and then generate a completion that still passes the
    tests, then the code works and your users will likely be happy with similar completions
    in production. This is exactly how we evaluated changes prior to shipping them—we
    grabbed a few hundred repos, made sure their tests ran, surgically deleted and
    generated fragments of code, and then saw whether or not the tests still ran.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你会很幸运。例如，对于Copilot代码补全，用户满意度的良好代理是代码是否功能完整。在代码的情况下，这实际上很容易衡量——如果你可以删除工作代码的片段，然后生成一个仍然通过测试的补全，那么代码就是有效的，你的用户可能会对生产中的类似补全感到满意。这正是我们在发布之前评估更改的方式——我们抓取了数百个仓库，确保它们的测试运行，然后外科手术般地删除并生成代码片段，然后查看测试是否仍然运行。
- en: Often, you won’t be this lucky. How do you evaluate a scheduling assistant that
    is expected to create real-world interactions, and how do you evaluate a general
    chat application that engages users in open-ended dialogue? One emerging approach
    is to make an LLM act as a judge, much like a human judge, and review chat transcripts
    and determine which variant is best. The judgment can be an answer to a basic
    question like “Which version is better?” However, for a more nuanced score, you
    can give the judge a checklist of criteria to review for each variant.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你不会这么幸运。你如何评估一个预期创建真实世界交互的调度助手，以及如何评估一个让用户参与开放式对话的通用聊天应用？一种新兴的方法是让LLM充当法官，就像人类法官一样，审查聊天记录并确定哪个变体最好。判断可以是对基本问题的回答，例如“哪个版本更好？”然而，为了得到更细致的评分，你可以给法官一份清单，列出每个变体需要审查的标准。
- en: However you choose to evaluate your LLM application, always try to engage as
    much of the application as possible in the evaluation. It might be easier to fake
    the context-gathering step of the application and test only the prompt assembly
    and prompt boilerplate; sometimes, mocking the context is even unavoidable. But
    often, the context-gathering steps become more important in building a quality
    LLM application. If you sidestep context gathering or any other aspect of your
    application, it will be at the peril of application quality assurance, and you
    might be in for a nasty surprise when the new feature goes into production.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你选择如何评估你的LLM应用，始终尝试尽可能多地让应用参与到评估中。可能更容易伪造应用的上下文收集步骤并仅测试提示组装和提示模板；有时，模拟上下文甚至不可避免。但通常，上下文收集步骤在构建高质量LLM应用时变得更加重要。如果你回避上下文收集或应用的任何其他方面，那么应用质量保证将处于危险之中，当新功能投入生产时，你可能会遇到令人不快的惊喜。
- en: Online Evaluation
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线评估
- en: With online evaluation, you’re looking for user feedback on whether the application
    provides a good experience. Feedback doesn’t have to involve filling out long
    forms, though. The lifeblood of online evaluation is telemetry data—so measure
    *everything*.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在在线评估中，你寻找的是用户对应用是否提供良好体验的反馈。反馈不必涉及填写长表，但在线评估的生命线是遥测数据——所以测量*一切*。
- en: One obvious way to assess quality is to ask users directly. In ChatGPT and other
    chat-based LLM experiences, you’ve probably seen the little thumbs-up or thumbs-down
    buttons next to each assistant message. While this seems to be a clear metric
    for quality, you have to account for bias. It might be that only the really angry
    users ever vote—and they always vote thumbs-down. And besides this, proportionally
    speaking, not much traffic gets any interaction with the up/down buttons. So unless
    your application is really high traffic, you might not get enough data from up/down
    buttons.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 评估质量的一个明显方法就是直接询问用户。在ChatGPT和其他基于聊天的LLM体验中，你可能看到每个助手消息旁边的小点赞或点踩按钮。虽然这似乎是质量的一个明确指标，但你必须考虑到偏见。可能只有真正愤怒的用户才会投票——他们总是投反对票。而且，从比例上来说，与上下/下按钮互动的流量并不多。所以除非你的应用流量真的很大，否则你可能无法从上下/下按钮中获得足够的数据。
- en: Clearly, we have to get more creative with our measurements—so you must consider
    *implicit* indicators of quality. For GitHub Copilot code completions, we measure
    how often completions are accepted and we check to see if users are going back
    and modifying our completions after accepting them. For your own applications,
    you’ll probably find your own ways of implicitly measuring quality. Be cautious
    about how you interpret implicit feedback. If you are building an LLM-based scheduling
    assistant and users are interacting and quickly leaving, then it might be because
    they are accomplishing their tasks efficiently (Yay!), but it could also be that
    users are frustrated and are abandoning the experience altogether.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们必须在测量方法上更加富有创意——因此你必须考虑*隐含*的质量指标。对于GitHub Copilot代码补全，我们测量补全被接受的程度，并检查用户在接受补全后是否返回并修改我们的补全。对于你自己的应用，你可能会找到自己隐含测量质量的方法。在解释隐含反馈时要谨慎。如果你正在构建一个基于LLM的调度助手，并且用户互动后迅速离开，那么这可能是因为他们高效地完成了任务（太好了！），但也可能是用户感到沮丧，完全放弃了体验。
- en: Measure something that matters—something that demonstrates a productivity boost
    for your customers. Copilot chose the acceptance rate as the key metric [because
    it correlated most highly with the user’s productivity gains](https://oreil.ly/Do5qI).
    For a scheduling assistant, rather than measuring session length, which is ambiguous,
    look for successfully created calendar events and also keep track of how often
    users change the details of the events after the fact.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 测量一些有意义的事情——一些能够展示为你的客户带来生产力提升的事情。Copilot选择了接受率作为关键指标[因为它与用户的效率提升高度相关](https://oreil.ly/Do5qI)。对于一个日程安排助手，与其测量会话长度，这本身就不明确，不如寻找成功创建的日历事件，并跟踪用户在事后更改事件细节的频率。
- en: Conclusion
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: After you learned about how an LLM works in the previous chapters, in this chapter,
    you learned that the LLM application is effectively a transformation layer between
    the user’s problem domain and the document domain where the LLM does its work.
    We zoomed in on the feedforward part of the loop, and you learned about how the
    prompt is formed by collecting context related to the user’s problem, extracting
    the most important parts, and assembling them into the boilerplate text of the
    prompt document. We then zoomed out and looked at how complex prompt engineering
    can become as it requires state management, integration with external context,
    increasingly sophisticated reasoning, and interaction with external tools.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章学习了LLM的工作原理之后，在本章中，你了解到LLM应用实际上是在用户问题域和LLM工作的文档域之间的一个转换层。我们聚焦于循环的前馈部分，并学习了提示是如何通过收集与用户问题相关的上下文、提取最重要的部分并将它们组装成提示文档的模板文本来形成的。然后，我们退后一步，观察了复杂提示工程可能变得多么复杂，因为它需要状态管理、与外部上下文的集成、日益复杂的推理以及与外部工具的交互。
- en: In this chapter, we’ve touched on every topic in the domain of LLM application
    development—but only at a very high level. In the next chapters, we’ll dig deeply
    into all of the topics introduced in this chapter. You’ll learn more about *where*
    to pull context from, *how* to create snippets and prioritize them, and *how*
    to build a prompt that is effective in addressing the user’s needs. Then, in later
    chapters, we’ll dig into more advanced applications and go into detail about how
    you can use these basic concepts to create conversational agency and complicated
    workflows.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要地涉及了LLM应用开发领域的每一个主题。但在下一章中，我们将深入探讨本章中介绍的所有主题。你将了解到*从哪里*获取上下文，*如何*创建片段并对其进行优先排序，以及*如何*构建一个能够有效解决用户需求的提示。然后，在后续章节中，我们将深入研究更高级的应用，并详细说明如何使用这些基本概念来创建对话代理和复杂的流程。
