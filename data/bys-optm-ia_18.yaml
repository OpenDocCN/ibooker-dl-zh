- en: Appendix. Solutions to the exercises
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录。 练习的解决方案
- en: 'A.1 Chapter 2: Gaussian processes as distributions over functions'
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '第2章A.1: 高斯过程作为函数分布'
- en: 'In this exercise, we train a GP on a real-world dataset we saw in chapter 1\.
    The solution is included in the CH02/02 - Exercise.ipynb notebook. Complete the
    following steps:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们对我们在第1章看到的真实数据集进行了GP训练。 解决方案包含在CH02/02 - Exercise.ipynb笔记本中。 完成以下步骤：
- en: Create the four-dimensional dataset.
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四维数据集。
- en: 'We first import the necessary libraries: PyTorch for array/tensor manipulation,
    GPyTorch for GP modeling, and Matplotlib for visualization:'
  id: totrans-4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的库：PyTorch用于数组/张量操作，GPyTorch用于GP建模，Matplotlib用于可视化：
- en: '[PRE0]'
  id: totrans-5
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then store the numbers in the table in two PyTorch tensors, `train_x` and
    `train_y`, which, respectively, contain the features and labels of our dataset:'
  id: totrans-6
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们将表中的数字存储在两个PyTorch张量中，`train_x` 和 `train_y`，分别包含数据集的特征和标签：
- en: '[PRE1]'
  id: totrans-7
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Normalize the fifth column by subtracting the mean from all values and dividing
    the results by their standard deviation.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从所有值中减去均值并将结果除以它们的标准差来标准化第五列。
- en: 'We normalize the labels as follows:'
  id: totrans-9
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们按如下方式标准化标签：
- en: '[PRE2]'
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When printed out, `train_y` should contain the following values: `tensor([-0.4183,`
    `1.4974,` `-0.5583,` `-0.5207])`.'
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印出时，`train_y` 应该包含以下值：`tensor([-0.4183,` `1.4974,` `-0.5583,` `-0.5207])`。
- en: Treat the first four columns as features and the fifth as labels. Train a GP
    on this data.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前四列视为特征，第五列为标签。 在这个数据上训练一个GP。
- en: 'We reimplement our GP model class as follows:'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们如下重新实现我们的GP模型类：
- en: '[PRE3]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We then initialize an object of this class with our training data:'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们用我们的训练数据初始化这个类的对象：
- en: '[PRE4]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Create a test dataset containing compositions with zero percent germanium and
    manganese.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含百分之零锗和锰的组合的测试数据集。
- en: 'To assemble our test dataset, we first create a mesh grid for the first and
    second columns that spans over the unit square:'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要组装我们的测试数据集，我们首先为第一列和第二列创建一个跨越单位正方形的网格：
- en: '[PRE5]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'These first two columns are stored in `grid_x1` and `grid_x2`. We then append
    two additional, all-zero columns to `grid_x1` and `grid_x2`, completing the test
    set with four columns:'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这前两列存储在 `grid_x1` 和 `grid_x2` 中。 然后，我们在 `grid_x1` 和 `grid_x2` 中附加两个额外的全零列，完成了具有四列的测试集：
- en: '[PRE6]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ First column
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 第一列
- en: ❷ Second column
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 第二列
- en: ❸ Third column, containing all zeros
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 第三列，包含全零
- en: ❹ Forth column, containing all zeros
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 第四列，包含全零
- en: Predict the mixing temperature on this test set.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测这个测试集的混合温度。
- en: 'To make predictions on this test set, we simply pass `xs` through our GP model
    under the `torch.no_grad()` context:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在这个测试集上进行预测，我们只需在`torch.no_grad()`上下文中通过我们的GP模型传递 `xs`：
- en: '[PRE7]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Visualize the predictions.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化预测。
- en: 'To visualize these predictions, we first create a figure with two panels (that
    is, two Matplotlib subplots):'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要可视化这些预测，我们首先创建一个具有两个面板（即，两个Matplotlib子图）的图：
- en: '[PRE8]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We then use `plt.imshow()` to visualize the mean and standard deviation vectors
    as heat maps, making sure to reshape the two vectors into square matrices:'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们使用`plt.imshow()`将均值和标准差向量可视化为热图，确保将这两个向量重塑为方阵：
- en: '[PRE9]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Heat map for the predictive mean
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 预测均值的热图
- en: ❷ Heat map for the predictive standard deviation
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 预测标准差的热图
- en: This will create plots similar to those in figure A.1.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将创建类似于图A.1中的图。
- en: '![](../../OEBPS/Images/A-01.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-01.png)'
- en: Figure A.1 Predictions made by a GP on a 2-dimensional space
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.1 GP在二维空间上的预测
- en: Note If you are using a different GP implementation, it’s entirely possible
    to produce heat maps that are slightly different from those in figure A.1\. As
    long as the general trend of the heat maps is the same, your solution is correct.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 如果您使用不同的GP实现，则完全有可能生成与图A.1中略有不同的热图。 只要热图的一般趋势相同，您的解决方案就是正确的。
- en: 'A.2 Chapter 3: Incorporating prior knowledge with the mean and covariance functions'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '第3章A.2: 使用均值和协方差函数结合先验知识'
- en: 'This exercise provides practice for implementing a GP model with automatic
    relevance determination (ARD). The solution is included in CH03/03 - Exercise.ipynb.
    Complete the following steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该练习提供了使用自动相关性确定（ARD）的GP模型的实践。 解决方案包含在CH03/03 - Exercise.ipynb中。 完成以下步骤：
- en: Implement the two-dimensional function in Python using PyTorch.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用PyTorch在Python中实现二维函数。
- en: 'We first import the necessary libraries—PyTorch for array/tensor manipulation,
    GPyTorch for GP modeling, and Matplotlib for visualization:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的库——PyTorch用于数组/张量操作，GPyTorch用于GP建模，Matplotlib用于可视化：
- en: '[PRE10]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We then implement the objective function using the given formula:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后使用给定的公式实现目标函数：
- en: '[PRE11]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Visualize the function over the domain [`0,` `2`]².
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在域[`0,` `2`]²上可视化函数。
- en: 'To visualize the function, we need to create a mesh grid the domain. We store
    this grid in `xs`:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要可视化函数，我们需要创建一个网格来表示域。我们将这个网格存储在`xs`中：
- en: '[PRE12]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ One-dimensional grid
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 一维网格
- en: ❷ Two-dimensional grid
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 二维网格
- en: 'We then can obtain the function values over this grid by passing `xs` to `f()`.
    The results are stored in `ys`:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们可以通过将`xs`传递给`f()`来在这个网格上获取函数值。结果存储在`ys`中：
- en: '[PRE13]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We use `plt.imshow()` to visualize `ys` as a heat map:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用`plt.imshow()`将`ys`可视化为热图：
- en: '[PRE14]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Randomly draw 100 data points from the domain [`0,` `2`]². This will be used
    as our training data.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从域[`0,` `2`]²中随机抽取100个数据点。这将作为我们的训练数据。
- en: 'To randomly sample 100 points within the domain, we use `torch.rand()` to sample
    from the unit square, and then we multiply the result by 2 to scale it to our
    domain:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在域内随机抽取100个点，我们使用`torch.rand()`从单位正方形中进行抽样，然后将结果乘以2以将其缩放到我们的域中：
- en: '[PRE15]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The function values of these points can be obtained by calling `f(train_x)`:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些点的函数值可以通过调用`f(train_x)`来获取：
- en: '[PRE16]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Implement a GP model with a constant mean function and a Matérn 5/2 kernel
    with an output scale implemented as a `gpytorch.kernels.ScaleKernel` object. We
    implement our GP model as specified:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用常数均值函数和作为`gpytorch.kernels.ScaleKernel`对象实现输出尺度的Matérn 5/2核来实现一个GP模型。我们按照如下指定实现我们的GP模型：
- en: '[PRE17]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Set to None to disable ARD and 2 to enable ARD.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 设置为None以禁用ARD，设置为2以启用ARD。
- en: Don’t specify the `ard_num_dims` parameter when initializing the kernel object
    or set the parameter to `None`.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在初始化核对象时不要指定`ard_num_dims`参数，或者将参数设置为`None`。
- en: This is done in the previous code.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是在先前的代码中完成的。
- en: Train the hyperparameters of the GP model using gradient descent, and inspect
    the length scale after training.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用梯度下降训练GP模型的超参数，并在训练后检查长度尺度。
- en: 'We initialize our GP and train it using gradient descent for 500 iterations
    as follows:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们初始化我们的GP并使用梯度下降进行500次迭代训练，如下所示：
- en: '[PRE18]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Enables the training model
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 启用训练模型
- en: ❷ Gradient descent to optimize the GP’s hyperparameters
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 梯度下降来优化GP的超参数
- en: ❸ Enables the prediction model
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 启用预测模型
- en: 'After these 500 iterations, we inspect the length scale by printing out the
    following value:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经过这500次迭代，我们通过打印以下数值来检查长度尺度：
- en: '[PRE19]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In other words, the optimized length scale is equal to roughly 1.15.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 换句话说，优化的长度尺度大约等于1.15。
- en: Redefine the GP model class, this time setting `ard_num_dims` `=` `2`.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义GP模型类，这次将`ard_num_dims`设置为`2`。
- en: 'Setting `ard_num_dims=2` in the `GPModel` class and rerunning all the code
    cells, we obtain the following values for the length scales:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在`GPModel`类中设置`ard_num_dims=2`，然后重新运行所有代码单元格，我们得到以下长度尺度的数值：
- en: '[PRE20]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, the length scale of the first dimension is large (roughly 1.70), while
    the length scale of the second dimension is small (roughly 0.87). This corresponds
    to the fact that the objective function varies more along the second dimension.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，第一维的长度尺度很大（大约1.70），而第二维的长度尺度很小（大约0.87）。这对应于目标函数沿第二维变化更多的事实。
- en: 'A.3 Chapter 4: Refining the best result with improvement-based policies'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.3 第4章：使用基于改进的策略优化最佳结果
- en: 'There are two exercises in this chapter:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章节有两个练习：
- en: The first covers a way of refining the Probability of Improvement (PoI) policy,
    allowing it to better explore the search space.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个涵盖了改进概率提高（PoI）策略的方法，使其能够更好地探索搜索空间。
- en: The second applies the two BayesOpt policies we have learned to a simulated
    real-world task of hyperparameter tuning.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个将我们学到的两个BayesOpt策略应用于一个模拟的真实世界的超参数调整任务。
- en: 'A.3.1 Exercise 1: Encouraging exploration with Probability of Improvement'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.3.1 练习1：使用概率提高鼓励探索
- en: 'This exercise, implemented in the CH04/02 - Exercise 1.ipynb notebook, walks
    us through how to modify PoI to encourage exploration. Complete the following
    steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习在CH04/02 - Exercise 1.ipynb笔记本中实现，引导我们如何修改PoI以鼓励探索。完成以下步骤：
- en: Recreate the BayesOpt loop in the CH04/01 - BayesOpt loop notebook, which uses
    the one-dimensional Forrester function as the optimization objective.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在CH04/01 - BayesOpt loop笔记本中重新创建BayesOpt循环，该循环使用一维Forrester函数作为优化目标。
- en: 'Before the `for` loop that implements BayesOpt, declare a variable named `epsilon`:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实现BayesOpt的`for`循环之前，声明一个名为`epsilon`的变量：
- en: '[PRE21]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Inside the `for` loop, initialize the PoI policy as before, but this time,
    specify that the incumbent threshold, set by the `best_f` argument, is the incumbent
    value *plus* the value stored in `epsilon`:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `for` 循环内，像以前一样初始化 PoI 策略，但这次指定由 `best_f` 参数设置的现任阈值是现任值 *加上* 存储在 `epsilon`
    中的值：
- en: '[PRE22]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Rerun the notebook, and observe whether this modification leads to better optimization
    performance than the original PoI policy by encouraging more exploration, as shown
    in figure A.2.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新运行笔记本，并观察是否此修改比原始 PoI 策略更好地优化性能，通过鼓励更多探索，如图 A.2 所示。
- en: '![](../../OEBPS/Images/A-02.png)'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-02.png)'
- en: Figure A.2 Optimization progress of the modified PoI at the last iteration.
    The policy has found the optimum.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.2 修改后 PoI 在最后一次迭代中的优化进展。策略已经找到了最优解。
- en: Here, the modified PoI has found the optimum.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，修改后的 PoI 已经找到了最优解。
- en: How much more explorative PoI becomes heavily depends on the minimum improvement
    threshold stored in `epsilon`. Setting this variable to 0.001 doesn’t sufficient
    encourage exploration, and the policy once again gets stuck. Setting this variable
    to 0.5 works well.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PoI 变得更加探索性取决于存储在 `epsilon` 中的最小改进阈值的大小。将此变量设置为 0.001 并不足以鼓励探索，策略再次陷入困境。将此变量设置为
    0.5 效果很好。
- en: 'Implement a relative minimum improvement threshold with a 110% improvement
    requirement:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个相对最小改进阈值，要求改进达到 110%：
- en: '[PRE23]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Omitted
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 省略
- en: ❷ Relative improvement
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 相对改进
- en: 'A.3.2 Exercise 2: BayesOpt for hyperparameter tuning'
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.3.2 练习 2：超参数调优的 BayesOpt
- en: 'This exercise, implemented in CH04/03 - Exercise 2.ipynb, applies BayesOpt
    to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task. Complete the following steps:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习在 CH04/03 - Exercise 2.ipynb 中实现，将 BayesOpt 应用于模拟支持向量机模型在超参数调优任务中的准确度曲面的目标函数。完成以下步骤：
- en: Recreate the BayesOpt loop in CH04/01 - BayesOpt loop.ipynb. Our objective function
    is implemented as
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 CH04/01 - BayesOpt loop.ipynb 中重新创建 BayesOpt 循环。我们的目标函数实现为
- en: '[PRE24]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Declare the corresponding test data with `xs` for a two-dimensional grid representing
    the domain and `ys` for the function values of `xs`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `xs` 声明相应的测试数据，表示域的二维网格和 `xs` 的函数值的 `ys`：
- en: '[PRE25]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Modify the helper function that visualizes optimization progress. We declare
    this function as `visualize_progress_and_policy()`, which only needs to take in
    a policy object and `next_x` as the next point to query. First, the function computes
    the acquisition scores for the test data `xs`:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改可视化优化进展的辅助函数。我们将此函数声明为 `visualize_progress_and_policy()`，该函数只需要一个策略对象和 `next_x`
    作为要查询的下一个点。首先，函数计算测试数据 `xs` 的获取分数：
- en: '[PRE26]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ To be continued
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 待续
- en: 'Next, we declare the two Matplotlib subplots and, for the first, plot the ground
    truth stored in `ys`:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们声明两个 Matplotlib 子图，并且对于第一个子图，绘制存储在 `ys` 中的真实情况：
- en: '[PRE27]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Heat map showing the ground truth
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 显示真实情况的热图
- en: ❷ Scattered points showing labeled data
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 显示标记数据的散点图
- en: 'Finally, we plot another heat map in the second subplot, showing the acquisition
    scores:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们在第二个子图中绘制另一个热图，显示获取分数：
- en: '[PRE28]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Heat map showing the acquisition scores
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 显示获取分数的热图
- en: 'We optionally show `next_x`:'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以选择显示 `next_x`：
- en: '[PRE29]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Copy the GP class from the exercise in chapter 3, which implements a Matérn
    2.5 kernel with ARD. Further modify this class to make it integratable with BoTorch:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从第 3 章的练习中复制 GP 类，该类实现了具有 ARD 的 Matérn 2.5 核。进一步修改此类以使其与 BoTorch 集成：
- en: '[PRE30]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ BoTorch-related modifications
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ BoTorch 相关修改
- en: ❷ Matérn 2.5 kernel with ARD
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 具有 ARD 的 Matérn 2.5 核
- en: ❸ Omitted
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 省略
- en: 'Reuse the helper function `fit_gp_model()` and the `for` loop that implements
    BayesOpt. We copy `fit_gp_model()` and declare the initial dataset:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重用辅助函数 `fit_gp_model()` 和实现 BayesOpt 的 `for` 循环。我们复制 `fit_gp_model()` 并声明初始数据集：
- en: '[PRE31]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We then declare the BayesOpt loop:'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们声明 BayesOpt 循环：
- en: '[PRE32]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Placeholder for policy initialization
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 策略初始化的占位符
- en: ❷ Making the search more exhaustive
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 使搜索更加穷举
- en: ❸ Calling the new visualization helper function
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 调用新的可视化辅助函数
- en: Run the PoI policy on this objective function. Observe that the policy once
    again gets stuck at a local optimum. Replace the line that initializes the BayesOpt
    policy with
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个目标函数上运行 PoI 策略。观察到该策略再次陷入局部最优。将初始化 BayesOpt 策略的行替换为
- en: '[PRE33]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Running the entire notebook shows that the policy once again gets stuck at a
    local optimum, as shown in figure A.3.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行整个笔记本，显示策略再次陷入局部最优，如图 A.3 所示。
- en: '![](../../OEBPS/Images/A-03.png)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-03.png)'
- en: Figure A.3 Optimization progress of PoI at the last iteration. The policy is
    stuck at a local optimum.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.3显示了PoI在最后一次迭代中的优化进度。该策略被困在了一个局部最优解中。
- en: Run the modified version of PoI, where the minimum improvement threshold is
    set at 0.1\. Replace the line that initializes the BayesOpt policy with
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行修改后的PoI版本，其中最小改进阈值设置为0.1。将初始化BayesOpt策略的行替换为：
- en: '[PRE34]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This policy is more explorative and outperforms regular PoI. Figure A.4 shows
    the progress of this policy at iteration 17, where it first achieves an accuracy
    of at least 90%.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该策略更具探索性，表现优于常规PoI。图A.4显示了该策略在第17次迭代时的进展，其中它首次达到至少90%的准确率。
- en: '![](../../OEBPS/Images/A-04.png)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-04.png)'
- en: Figure A.4 Optimization progress of the modified PoI at iteration 17, where
    the policy first achieves an accuracy of at least 90%
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.4显示了修改版PoI在第17次迭代中的优化进度，在该次迭代中，该策略首次达到至少90%的准确率。
- en: Here, C = 1.6770 and *γ* = 1.9039 are the parameters giving this accuracy.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，C = 1.6770，*γ* = 1.9039是提供此准确度的参数。
- en: Run the Expected Improvement (EI) policy on this objective function. Replace
    the line that initializes the BayesOpt policy with
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此目标函数上运行Expected Improvement（EI）策略。用初始化BayesOpt策略的行替换：
- en: '[PRE35]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This policy performs well on our objective function, finding an accuracy of
    at least 90% at iteration 15, as shown in figure A.5.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该策略在我们的目标函数上表现良好，如图A.5所示，在第15次迭代中找到了至少90%的准确率。
- en: '![](../../OEBPS/Images/A-05.png)'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-05.png)'
- en: Figure A.5 Optimization progress of EI at iteration 4, where the policy first
    achieves an accuracy of at least 90%
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.5显示了EI在第4次迭代中的优化进度，在该次迭代中，该策略首次达到至少90%的准确率。
- en: Here, *C* = 1.6331 and *γ* = 1.8749 are the parameters giving this accuracy.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，*C* = 1.6331，*γ* = 1.8749是提供此准确度的参数。
- en: 'Implement repeated experiments, and visualize the average incumbent values
    and error bars across 10 experiments. We first put the code that implements our
    BayesOpt loop in an outer loop that iterates over multiple experiments. We store
    the best-seen value at each step across the experiments in `incumbents`:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实施重复实验，并可视化10个实验中的平均incumbent值和误差条。我们首先将实现BayesOpt循环的代码放入一个外部循环中，该循环迭代多个实验。我们在`incumbents`中的每一步跨实验存储每次最好的值：
- en: '[PRE36]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: ❶ Uniformly samples a data point in the search space as the starting point
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶在搜索空间中均匀采样一个数据点作为起始点
- en: ❷ Keeps track of the best-seen value
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷跟踪最佳值
- en: ❸ The mitted code is the same as before.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸省略的代码与之前相同。
- en: ❹ Saves results to a file so that we can visualize them later
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹将结果保存到文件中，以便稍后可视化。
- en: 'We then implement a helper function that plots the average incumbent values
    and error bars. This function reads in a PyTorch tensor saved at `path`, which
    should be the saved version of `incumbents` in the previous step:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们实现一个帮助函数，绘制平均incumbent值和误差条。该函数读取保存在`path`中的PyTorch tensor，该tensor应是前一步中`incumbents`的保存版本：
- en: '[PRE37]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Helper subfunction to compute the error bars
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶计算误差条的辅助子函数
- en: ❷ Loads saved optimization results
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷加载保存的优化结果
- en: ❸ Computes the mean results and error bars
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸计算结果的平均值和误差条
- en: ❹ Visualizes the mean results and error bars
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹可视化结果平均值和误差条
- en: 'We then can run the preceding policies we have in the previous code and compare
    their performance:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们可以运行我们在前面代码中拥有的策略，并比较它们的表现：
- en: '[PRE38]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This generates figure A.6, which shows the optimization performance of PoI,
    the modified version of PoI, and EI.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这生成了图A.6，显示了PoI、修改版PoI和EI的优化性能。
- en: '![](../../OEBPS/Images/A-06.png)'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-06.png)'
- en: Figure A.6 Optimization progress of various policies, aggregated across 10 repeated
    experiments
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.6显示了10个重复实验中各种策略的优化进度。
- en: We see that figure A.6 gives us more insight than inspecting the policies in
    a single run. Here, not only does PoI perform worse than the other two policies,
    but its performance is also less robust, as seen from the large error bars. The
    modified PoI and EI perform comparably, and it’s hard to tell if one is better
    than the other, as their error bars overlap.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们发现图A.6比单次运行中的策略更具见解。在这里，PoI的表现不如其他两个策略，而且其性能也不太稳健，从大的误差条中可以看出来。修改版PoI和EI表现相当，很难判断哪个更好，因为它们的误差条重叠。
- en: 'A.4 Chapter 5: Exploring the search space with bandit-style policies'
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.4 第5章：使用赌博工具风格的策略探索搜索空间
- en: 'There are two exercises in this chapter:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中有两个练习：
- en: The first exercise explores a potential method to set the tradeoff parameter
    for the UCB policy that considers how far along we are in optimization.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个练习探索了一种为UCB策略设置权衡参数的潜在方法，该方法考虑了我们在优化中的进展情况。
- en: The second exercise applies the two policies we have learned in this chapter
    to the hyperparameter tuning problem seen in previous chapters.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个练习将本章学到的两种策略应用于以前章节中看到的超参数调整问题。
- en: 'A.4.1 Exercise 1: Setting an exploration schedule for Upper Confidence Bound'
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.4.1 练习1：为上置信界限设置探索计划
- en: 'This exercise, implemented in CH05/02 - Exercise 1.ipynb, discusses a strategy
    of adaptively setting the value of the tradeoff parameter β of the UCB policy.
    Complete the following steps:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习实现在CH05/02 - Exercise 1.ipynb中，讨论了自适应设置UCB策略权衡参数β值的策略。完成以下步骤：
- en: Recreate the BayesOpt loop in CH04/02 - Exercise 1.ipynb, which uses the one-dimensional
    Forrester function as the optimization objective.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在CH04/02 - Exercise 1.ipynb中重新创建BayesOpt循环，该循环将一维Forrester函数作为优化目标。
- en: 'Since there are 10 iterations in the BayesOpt loop, β is multiplied by the
    multiplier *m* 10 times to go from 1 to 10\. That is, 1 × *m*10 = 10\. Solving
    this equation gives the code for the multiplier:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于BayesOpt循环中有10次迭代，β乘以倍数*m* 10次，从1到10。也就是说，1 × *m*10 = 10。解决这个方程得到了倍数的代码：
- en: '[PRE39]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Implement this scheduling logic, and observe the resulting optimization performance.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现这个调度逻辑，并观察结果的优化性能。
- en: 'We modify the BayesOpt loop as follows:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对BayesOpt循环进行如下修改：
- en: '[PRE40]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: ❶ Obtains the trained GP
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 获得训练好的GP
- en: ❷ Finds the point that maximizes the acquisition score, queries the objective
    function, and updates the training data
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 找到最大化获取分数的点，查询目标函数，并更新训练数据
- en: This code produces figure A.7.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码生成图A.7。
- en: '![](../../OEBPS/Images/A-07.png)'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-07.png)'
- en: Figure A.7 Progress made by the adaptive version of the UCB policy. The policy
    is able to escape the local optimum and get closer to the global optimum.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.7 自适应UCB策略的进展。该策略能够摆脱局部最优解，并接近全局最优解。
- en: We see that the policy inspects a local optimum at the fifth iteration but ultimately
    is able to escape and get closer to the global optimum at the end.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到该策略在第五次迭代时检查了局部最优解，但最终能够逃脱并在最后接近全局最优解。
- en: 'A.4.2 Exercise 2: BayesOpt for hyperparameter tuning'
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.4.2 练习2：用于超参数调整的BayesOpt
- en: 'This exercise, implemented in CH05/03 - Exercise 2.ipynb, applies BayesOpt
    to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task. Complete the following steps:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习实现在CH05/03 - Exercise 2.ipynb中，将BayesOpt应用于模拟超参数调整任务中支持向量机模型准确率表面的目标函数。完成以下步骤：
- en: Recreate the BayesOpt loop in CH04/03 - Exercise 2.ipynb, including the outer
    loop that implements repeated experiments.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在CH04/03 - Exercise 2.ipynb中重新创建BayesOpt循环，包括实施重复实验的外部循环。
- en: Run the UCB policy, setting the value of the tradeoff parameter to β ∈ { 1,
    3, 10, 30 }, and observe the values’ aggregated performance.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行UCB策略，将权衡参数的值设置为β ∈ { 1, 3, 10, 30 }，并观察值的聚合性能。
- en: 'The value of the tradeoff parameter can be set when the policy object is initialized:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以在初始化策略对象时设置权衡参数的值：
- en: '[PRE41]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Figure A.8 shows the optimization performance of the four versions of UCB. We
    see that when β *=* 1, the policy is too exploitative and achieves the worst performance.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.8显示了四个版本UCB的优化性能。我们看到当β = 1时，策略过于探索，性能最差。
- en: '![](../../OEBPS/Images/A-08.png)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-08.png)'
- en: Figure A.8 Progress made by the various UCB policies
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.8 不同UCB策略的进展
- en: As the value of the tradeoff parameter increases, performance increases, but
    when β = 30, over-exploration causes UCB to be slower at locating an accuracy
    of 90%. Overall, β = 10 achieves the best performance.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着权衡参数值的增加，性能也增加，但当 β = 30 时，过度探索导致UCB在定位90%准确度时变慢。总体而言，β = 10 达到了最佳性能。
- en: Run the adaptive version of UCB (see Exercise 1).
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行UCB的自适应版本（见练习1）。
- en: 'We modify the BayesOpt loop as follows:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对BayesOpt循环进行如下修改：
- en: '[PRE42]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ Randomly generates the initial training data
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 随机生成初始训练数据
- en: ❷ Records the incumbent value and retrains the model
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 记录现有值并重新训练模型
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 找到最大化获取分数的点，查询目标函数，并更新训练数据
- en: Figure A.9 shows the optimization performance of the two adaptive versions against
    the best performing fixed value β = 10.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.9 展示了两种自适应版本相对于最佳性能固定值 β = 10 的优化性能。
- en: '![](../../OEBPS/Images/A-09.png)'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-09.png)'
- en: Figure A.9 Progress made by two adaptive versions of the UCB policy. The policy
    is robust against the end value of the tradeoff parameter.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.9 两种 UCB 策略的自适应版本的进展。该策略对交易参数的结束值具有鲁棒性。
- en: These versions are comparable, and changing the end value from 10 to 30 doesn’t
    affect optimization performance much.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些版本是可比较的，将结束值从 10 更改为 30 并不会对优化性能产生太大影响。
- en: Run the Thompson sampling (TS) policy, and observe its aggregated performance.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 Thompson 抽样（TS）策略，并观察其综合性能。
- en: 'We implement TS as follows:'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们按照以下方式实现 TS：
- en: '[PRE43]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: ❶ Randomly generates the initial training data
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 随机生成初始训练数据
- en: ❷ Records the incumbent value and retrains the model
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 记录现任价值并重新训练模型
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 找到最大化收益分数的点，查询目标函数并更新训练数据
- en: Figure A.10 shows the optimization performance of TS. We see that the policy
    makes significant progress at the beginning and is comparable to EI from chapter
    6 and slightly worse than the best version of UCB.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.10 展示了 TS 的优化性能。我们看到该策略在开始时取得了显著进展，并且与第 6 章的 EI 相当，并且略逊于 UCB 的最佳版本。
- en: '![](../../OEBPS/Images/A-10.png)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-10.png)'
- en: Figure A.10 Progress made by TS. The policy is comparable to EI and slightly
    worse than the best version of UCB.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.10 TS 的进展。该策略与 EI 相当，并略逊于 UCB 的最佳版本。
- en: 'A.5 Chapter 6: Using information theory with entropy-based policies'
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.5 第 6 章：使用信息论与基于熵的策略
- en: 'There are two exercises in this chapter:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中有两个练习：
- en: The first exercise covers a variant of binary search in which prior information
    can be taken into account when making decisions.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个练习涵盖了二分搜索的变体，其中在做出决策时可以考虑先验信息。
- en: The second walks us through the process of implementing Max-value Entropy Search
    (MES) in the hyperparameter tuning problem seen in previous chapters.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个练习将引导我们通过在前几章中看到的超参数调整问题中实现最大值熵搜索（MES）的过程。
- en: 'A.5.1 Exercise 1: Incorporating prior knowledge into entropy search'
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.5.1 练习 1：将先验知识纳入熵搜索
- en: 'This exercise, implemented in CH06/02 - Exercise 1.ipynb, shows us an instance
    of using different priors when finding the information-theoretically optimal decision
    and will ultimately help us further appreciate the elegance and flexibility of
    entropy search as a generic decision-making-under-uncertainty procedure:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习，实现在 CH06/02 - Exercise 1.ipynb 中，展示了在找到信息论最优决策时使用不同先验的一个实例，最终将帮助我们进一步欣赏熵搜索作为一种通用决策在不确定性下的过程的优雅和灵活性：
- en: Prove that *Pr*(*X* = 1) + *Pr*(*X* = 2) + ... + *Pr*(*X* = 10) = 1.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 证明 *Pr*(*X* = 1) + *Pr*(*X* = 2) + ... + *Pr*(*X* = 10) = 1。
- en: 'We can do this by simply adding the probabilities together:'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过简单地将概率相加来实现这一点：
- en: 1 / 2 + 1 / 4 + ... + 1 / 2⁹ + 1 / 2⁹ = 1 / 2 + 1 / 4 + ... + 1 / 2⁸ + 1 / 2⁸
    = ... = 1 / 2 + 1 / 2 = 1.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1 / 2 + 1 / 4 + ... + 1 / 2⁹ + 1 / 2⁹ = 1 / 2 + 1 / 4 + ... + 1 / 2⁸ + 1 / 2⁸
    = ... = 1 / 2 + 1 / 2 = 1。
- en: Calculate the entropy of this prior distribution.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算这个先验分布的熵。
- en: 'Remember the formula for the entropy is –Σ*[i]**p[i]* log *p[i]*. We can write
    a Python function that computes this sum:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请记住熵的公式为 –Σ*[i]**p[i]* log *p[i]*。我们可以编写一个计算此和的 Python 函数：
- en: '[PRE44]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ❶ Get the current probability.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 获取当前概率。
- en: ❷ Sum over the terms.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 对项求和。
- en: This function takes `first` and `last` as parameters, which correspond to the
    smallest and biggest numbers *X* could be (which start out as 1 and 10), respectively.
    We then iterate through the numbers between `first` and `last` and add up the
    –*p[i]* log *p[i]* terms. Here, `marginal_probability()` is a helper function
    that computes *Pr*(*X* = *n*), which we implement as
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此函数将 `first` 和 `last` 作为参数，它们对应于 *X* 可能的最小和最大值（起始值为 1 和 10），分别。然后我们遍历 `first`
    和 `last` 之间的数字，并累加 –*p[i]* log *p[i]* 项。这里，`marginal_probability()` 是一个计算 *Pr*(*X*
    = *n*) 的辅助函数，我们实现如下：
- en: '[PRE45]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: ❶ An edge case when the floor is the highest possible floor
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 当底层是可能的最高层时的边缘情况
- en: Running `compute_entropy(1,` `10)` gives us 1.99609375\. This is the entropy
    of the prior distribution for *X*.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行 `compute_entropy(1,` `10)` 将给出 1.99609375\. 这是 *X* 先验分布的熵。
- en: Given the prior distribution defined between 1 and 10, what is the probability
    the phone will break when dropped from the second floor? What is this probability
    for the fifth floor? How about the first floor?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鉴于在1到10之间定义的先验分布，从二楼掉落时手机会损坏的概率是多少？从第五层呢？第一层呢？
- en: The probability that the phone will break when dropped from the second floor
    is exactly *Pr*(*X* = 1), which is 0.5.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 手机从二楼掉落时损坏的概率恰好是*Pr*(*X* = 1)，即0.5。
- en: The probability that the phone will break from the fifth floor is the probability
    that *X* ≤ 4, which is *Pr*(*X* = 1) + *Pr*(*X* = 2) + *Pr*(*X* = 3) + *Pr*(*X*
    = 4) = 15/16 = 0.9375.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 手机从第五层掉落损坏的概率是*X* ≤ 4的概率，即*Pr*(*X* = 1) + *Pr*(*X* = 2) + *Pr*(*X* = 3) + *Pr*(*X*
    = 4) = 15/16 = 0.9375。
- en: 'These two calculations could be implemented as a function:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这两个计算可以作为一个函数来实现：
- en: '[PRE46]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: ❶ Sum over the probabilities for X less than the threshold.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 对于小于阈值的*X*的概率求和
- en: Since our prior knowledge dictates that the phone won’t break if dropped from
    the first floor, this probability is 0.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们的先验知识规定，如果从一楼掉落，手机不会损坏，这个概率为0。
- en: Compute the entropy of the fictitious posterior distribution in the two cases
    where we conduct a trial on the fifth floor.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算在我们在第五层进行试验的两种情况下的虚拟后验分布的熵。
- en: 'Using the `compute_entropy()` function we implemented, we can compute the entropy
    in two cases. If the phone breaks, we set `first` `=` `1` and `last` `=` `4`;
    otherwise, we set `first` `=` `5` and `last` `=` `10`:'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用我们实现的`compute_entropy()`函数，我们可以计算两种情况下的熵。如果手机损坏，我们将`first`设为`1`，`last`设为`4`；否则，我们将`first`设为`5`，`last`设为`10`：
- en: '[PRE47]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Given the prior distribution, compute the expected posterior entropy after you
    conduct a trial on the fifth floor.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鉴于先验分布，计算在第五层进行试验后的预期后验熵。
- en: We have already done the necessary calculations for this expected posterior
    entropy computation. First, the probability that the phone will break from the
    fifth floor is 0.9375, in which case the posterior entropy is 1.75\. Second, the
    probability that the phone won’t break from the fifth floor is 1 – 0.9375 = 0.0625,
    in which case the posterior entropy is 1.9375.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于这个预期后验熵计算，我们已经进行了必要的计算。首先，手机从第五层掉落损坏的概率是0.9375，在这种情况下，后验熵是1.75。其次，手机从第五层掉落不损坏的概率是1
    - 0.9375 = 0.0625，在这种情况下，后验熵是1.9375。
- en: Taking the average of the two cases gives (0.9375) 1.75 + (0.0625) 1.9375 =
    1.76171875\. This is the expected posterior entropy after you conduct a trial
    on the fifth floor.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对两种情况取平均值得到 (0.9375) 1.75 + (0.0625) 1.9375 = 1.76171875。这是你在第五层进行试验后的预期后验熵。
- en: Compute this expected posterior entropy for other floors.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算其他楼层的这个预期后验熵。
- en: 'We can implement a function that does the calculation we just went over:'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以实现一个函数来进行我们刚刚讨论的计算：
- en: '[PRE48]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: ❶ The probability that the phone will break from a given floor
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 从给定楼层手机损坏的概率
- en: ❷ Takes the average of the two cases
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 对两种情况取平均值
- en: Using this function, we can plot out the expected posterior entropy for numbers
    between 1 and 10.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用这个函数，我们可以绘制出在1到10之间数字的预期后验熵。
- en: This plot is shown in figure A.11, which tells us that the information-theoretically
    optimal location for our first trial is the second floor, since 2 gives us the
    lowest expected posterior entropy (and, therefore, uncertainty).
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个图表显示在图 A.11 中，告诉我们我们第一次试验的信息论最佳地点是二楼，因为2给出了最低的预期后验熵（因此，不确定性最低）。
- en: '![](../../OEBPS/Images/A-11.png)'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-11.png)'
- en: Figure A.11 The expected posterior entropy as a function of the location to
    conduct the trial
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.11 预期后验熵作为试验地点的函数
- en: 'We see that this is not the same as the decision binary search suggests, 5\.
    This is a direct effect of the domain knowledge we are encoding using the prior
    distribution for *X*: since there’s a high chance that *X* = 2 (50%), it’s actually
    better to simply try out that number first in case we can immediately find our
    answer if the phone breaks.'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们看到这与决策二进制搜索建议的不同，5。这是我们使用先验分布对*X*进行编码的领域知识的直接影响：因为*X* = 2的可能性很高（50%），如果手机损坏，直接尝试这个数字可能会更好，因为这样我们可能会立即找到答案。
- en: Interestingly, dropping the phone from the first floor gives us no reduction
    in entropy. This is because we know for sure that the phone won’t break from this
    floor, so our knowledge of the world won’t change after conducting this trial.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有趣的是，从一楼掉下手机不会减少熵。这是因为我们确定手机不会从这一层摔坏，所以在进行这次试验之后，我们对世界的认知不会改变。
- en: 'A.5.2 Exercise 2: BayesOpt for hyperparameter tuning'
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.5.2 练习2：超参数调优的BayesOpt
- en: 'This exercise, implemented in the CH06/03 - Exercise 2.ipynb notebook, applies
    BayesOpt to an objective function that simulates the accuracy surface of a support-vector
    machine model in a hyperparameter tuning task:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习在CH06/ 03- Exercise 2.ipynb笔记本中实现，将BayesOpt应用于模拟超参数调整任务中支持向量机模型的精度曲面的目标函数：
- en: Recreate the BayesOpt loop in CH04/03 - Exercise 2.ipynb, including the outer
    loop that implements repeated experiments.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在CH04/ 03- Exercise 2.ipynb中重新创建BayesOpt循环，包括实现重复实验的外部循环。
- en: Run the MES policy.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行MES策略。
- en: 'Since our objective function is two-dimensional, we should set the size of
    the Sobol sequence used by MES as 2,000:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑到我们的目标函数具有两个维度，我们应将MES使用的Sobol序列的大小设置为2,000：
- en: '[PRE49]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: ❶ Randomly generates the initial training data
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 随机生成初始训练数据
- en: ❷ Records the incumbent value and retrains the model
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 记录现任值并重新训练模型
- en: ❸ Finds the point maximizing the acquisition score, queries the objective function,
    and updates the training data
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 寻找最大化收获值的点，查询目标函数，并更新训练数据
- en: Figure A.12 shows the optimization performance of MES. We see that the policy
    is competitive against all the BayesOpt policies we have learned thus far.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.12显示了MES的优化效果。我们可以看到，该策略在迄今为止学到的所有BayesOpt策略中都具有竞争力。
- en: '![](../../OEBPS/Images/A-12.png)'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS /Images/A-12.png)'
- en: Figure A.12 Progress made by MES. The policy performs the best of the four policies
    shown.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.12展示了MES的优化效果。该策略在所显示的四个策略中表现最佳。
- en: 'A.6 Chapter 7: Maximizing throughput with batch optimization'
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.6 第七章：通过批量优化最大化吞吐量
- en: 'There are two exercises in this chapter:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含两个练习：
- en: The first covers the implementation of TS under the batch setting.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个部分涵盖了在批量设置下实现TS的方法。
- en: The second shows us how to run BayesOpt policies on a four-dimensional aerostructural
    optimization problem.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个部分介绍了如何在一个四维气动结构优化问题上运行BayesOpt策略。
- en: 'A.6.1 Exercise 1: Extending TS to the batch setting via resampling'
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.6.1 练习1：通过重新采样将TS扩展到批量设置
- en: 'Remember that TS in the sequential setting, which we learned in section 5.3,
    draws one sample from the current GP belief about the objective function and queries
    the data point that maximizes that sample. In the batch setting, we simply repeat
    this process of sampling from the GP and maximizing the sample multiple times
    to assemble a batch of queries of the desired size. The code for this exercise
    can be found in the CH07/02 - Exercise 1.ipynb notebook:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在我们在第5.3节学到的顺序设置中，TS是从当前GP关于目标函数的信念中抽取一个样本，并查询最大化该样本的数据点。在批次设置中，我们只需重复此过程多次，从而多次采样GP并最大化样本，以组装所需大小的批次查询。此练习的代码可以在CH07/
    02- Exercise 1.ipynb笔记本中找到：
- en: Recreate the batch BayesOpt loop in CH05/01 - BayesOpt loop.ipynb notebook.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建CH05 / 01- BayesOpt loop.ipynb笔记本中的批次BayesOpt循环。
- en: Implement TS with a Sobol sampler, as described in section 5.3.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据第5.3节介绍的方法，使用Sobol采样器实现TS。
- en: 'We implement the policy as follows, where we use a 2,000-element Sobol sequence
    and specify the number of samples as the batch size:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们按照以下方式实施该策略，其中我们使用2,000元素的Sobol序列，并指定样本数作为批次大小：
- en: '[PRE50]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: ❶ Specifies the length of the Sobol sequence
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 指定Sobol序列的长度
- en: ❷ Randomly picks the initial training data
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 随机选择初始训练数据
- en: ❸ Retrains the GP
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 重新训练GP
- en: ❹ Initializes the Sobol sequence
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 初始化Sobol序列
- en: ❺ Draws multiple samples from the GP
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❺ 从GP中绘制多个样本
- en: ❻ Queries the objective function and updates the training data
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❻ 查询目标函数并更新训练数据
- en: Run this TS policy on the hyperparameter tuning objective function, and observe
    its performance.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此TS策略对超参数调整目标函数进行观察其性能。
- en: After running batch TS, we can plot the progress made by the policy against
    other policies we have learned, as shown in figure A.13\. Here, TS is able to
    make significant progress after only the first batch of queries.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行批次TS后，我们可以绘制该策略对我们所学到的其他策略的进展，如图A.13所示。在仅进行第一批查询之后，TS就能取得显著进展。
- en: '![](../../OEBPS/Images/A-13.png)'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-13.png)'
- en: Figure A.13 Progress made by batch TS in the hyperparameter tuning example.
    The policy makes significant progress after only the first batch of queries.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.13 批处理 TS 在超参数调整示例中的进展。只查询了第一批后，该策略就取得了显著进展。
- en: 'A.6.2 Exercise 2: Optimizing airplane designs'
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'A.6.2 练习 2: 优化飞机设计'
- en: 'This exercise provides an objective function that simulates this process of
    benchmarking the performance of an airplane design. The code is provided in the
    CH07/04 - Exercise 2.ipynb notebook. Complete the following steps:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习提供了一个目标函数，用于模拟基准测试飞机设计的过程。代码提供在 CH07/04 - Exercise 2.ipynb 笔记本中。完成以下步骤：
- en: Implement the objective function that simulates the performance benchmarking.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现模拟性能基准测试的目标函数。
- en: 'The code for the objective function is already provided, so we simply copy
    and paste it in our program:'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标函数的代码已经提供，所以我们只需将其复制粘贴到程序中：
- en: '[PRE51]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Implement a GP model with a constant mean function and a Matérn 2.5 kernel with
    an output scale implemented as a `gpytorch.kernels.ScaleKernel` object.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一个常数均值函数和 Matérn 2.5 核实现一个 GP 模型，输出范围由一个 `gpytorch.kernels.ScaleKernel` 对象实现。
- en: 'The class implementation of this GP model is mostly the same as before, except
    that we need to specify the correct number of dimensions in the ARD kernel:'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个 GP 模型的类实现和之前大部分相同，只需要在 ARD 核中指定正确的维度数：
- en: '[PRE52]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: ❶ A Matérn 2.5 kernel for four dimensions
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 四维的 Matérn 2.5 核
- en: Implement a helper function that trains the GP on a given training dataset.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个辅助函数，用于在给定的训练数据集上训练 GP。
- en: We can simply copy the same helper function `fit_gp_model()` from other notebooks
    in this chapter, namely 02 - Exercise 1.ipynb, as we don’t need to modify anything
    in this helper function.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以直接从本章其他笔记本（即 02 - Exercise 1.ipynb）中复制相同的辅助函数 `fit_gp_model()`，因为我们不需要在此辅助函数中进行修改。
- en: Define the settings of our optimization problem.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义优化问题的设置。
- en: 'We first define the bounds of our search space:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们先定义搜索空间的边界：
- en: '[PRE53]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We then specify how many queries can be made, the batch size, and the number
    of experiments to repeat for each policy:'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们指定可以进行的查询数量、批次大小和每个策略要重复的实验次数：
- en: '[PRE54]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Run each batch BayesOpt policy we learn in this chapter on the objective function
    implemented previously.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行本章学习的每个批处理 BayesOpt 策略在先前实现的目标函数上。
- en: 'We first use this code to implement the optimization loop and the outer loop
    that repeats the experiments for each policy. Specifically, for each individual
    experiment, we randomly sample one data point inside the search space and then
    run each BayesOpt policy until we run out of queries. We see how each policy is
    defined in the next step:'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先使用这段代码实现优化循环和重复每个策略实验的外部循环。具体来说，对于每个单独的实验，我们随机在搜索空间内取一个数据点，然后运行每个 BayesOpt
    策略，直到我们用完查询次数。下一步我们将看到每个策略是如何定义的：
- en: '[PRE55]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: ❶ Randomly initializes the training data
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 随机初始化训练数据
- en: ❷ Keeps track of optimization progress and updates the predictive model
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 跟踪优化进展并更新预测模型
- en: ❸ Defines the policy and finds the next batch to query
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 定义策略并查找下一个要查询的批次
- en: ❹ Queries the points recommended by the policy and updates the training data
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 查询策略推荐的点并更新训练数据
- en: 'For the PoI policy, we use the following code:'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 PoI 策略，我们使用以下代码：
- en: '[PRE56]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'For the EI policy, we use the following code:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 EI 策略，我们使用以下代码：
- en: '[PRE57]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'For the UCB policy, we use the following code:'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 UCB 策略，我们使用以下代码：
- en: '[PRE58]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'These three policies can then be optimized using the helper function `optimize_
    acqf()` as follows:'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '然后可以使用以下代码对这三个策略进行优化： '
- en: '[PRE59]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Otherwise, for either TS or MES, we first need to define the Sobol sequence:'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 否则，对于 TS 或 MES，我们需要先定义 Sobol 序列：
- en: '[PRE60]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: ❶ Specifies the number of dimensions to be 4
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 指定维度数为 4
- en: 'For the TS policy, we use the following code:'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 TS 策略，我们使用以下代码：
- en: '[PRE61]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'For the MES, we use the following code, which uses the helper function `optimize_acqf_cyclic()`
    to implement cyclic optimization. Note that we are specifying that cyclic optimization
    should only take a maximum of 5 iterations:'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 MES，我们使用以下代码来实现循环优化，其中使用了辅助函数 `optimize_acqf_cyclic()`。请注意，我们指定循环优化的最大迭代次数为
    5：
- en: '[PRE62]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: ❶ Specifies the maximum number of iterations in cyclic optimization
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 指定循环优化的最大迭代次数
- en: Plot the optimization progress of the BayesOpt policies we have run and observe
    their performance.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制我们运行的 BayesOpt 策略的优化进展并观察其性能。
- en: Figure A.14 shows the optimization results obtained by the policies we’ve implemented.
    We see that most policies are comparable, except for TS; batch PoI has a slight
    edge.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.14 显示了我们实现的策略得到的优化结果。我们看到大多数策略是可比的，除了 TS；批量 PoI 稍微领先一点。
- en: '![](../../OEBPS/Images/A-14.png)'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-14.png)'
- en: Figure A.14 Progress made by various BayesOpt policies in the airplane design
    optimization example. Most policies are comparable, except for TS.
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.14 各种 BayesOpt 策略在飞机设计优化示例中的进展。大多数策略是可比的，除了 TS。
- en: 'A.7 Chapter 8: Satisfying extra constraints with constrained optimization'
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.7 第 8 章：通过受限优化满足额外约束
- en: 'There are two exercises in this chapter:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有两个练习：
- en: The first verifies that the result we obtain from BoTorch’s implementation of
    the constrained EI policy is the same as the product of the regular EI score and
    the probability of feasibility.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个验证我们从 BoTorch 对受限 EI 策略的实现得到的结果是否与常规 EI 分数和可行性概率的乘积相同。
- en: The second shows us how to run constrained BayesOpt on a four-dimensional aerostructural
    optimization problem.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二部分向我们展示了如何在一个四维气动结构优化问题上运行受限 BayesOpt。
- en: 'A.7.1 Exercise 1: Manual computation of constrained EI'
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.7.1 练习 1：受限 EI 的手动计算
- en: 'The acquisition score of the constrained EI policy is the product of the EI
    score and the probability of feasibility. Although the `ConstrainedExpectedImprovement`
    class from BoTorch provides an implementation of the constrained EI score, we
    can, in fact, perform the computation manually. In this exercise, we explore this
    manual computation and verify our result against that of the `ConstrainedExpectedImprovement`
    class. The solution of this exercise is in the CH08/02 - Exercise 1.ipynb notebook
    amd can be explained as follows:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 受限 EI 策略的获取分数是 EI 分数和可行性概率的乘积。虽然 BoTorch 的 `ConstrainedExpectedImprovement`
    类提供了受限 EI 分数的实现，但实际上我们可以手动执行计算。在这个练习中，我们探索这种手动计算，并将我们的结果与 `ConstrainedExpectedImprovement`
    类的结果进行验证。此练习的解决方案在 CH08/02 - Exercise 1.ipynb 笔记本中，并可以解释如下：
- en: Recreate the constrained BayesOpt problem used in CH08/01 - Constrained optimization.ipynb,
    including the objective function, the cost function, the GP implementation, and
    the helper function that trains a GP on some training data `fit_gp_model()`.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建 CH08/01 - Constrained optimization.ipynb 中使用的受限 BayesOpt 问题，包括目标函数、成本函数、GP
    实现以及在一些训练数据上训练 GP 的辅助函数 `fit_gp_model()`。
- en: 'Create a PyTorch tensor that is a dense grid between -5 and 5\. This tensor
    will act as our test set. We use `torch.linspace()` to create a dense grid:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 PyTorch 张量，它是在 -5 到 5 之间的密集网格。这个张量将作为我们的测试集。我们使用 `torch.linspace()` 来创建一个密集网格：
- en: '[PRE63]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Create a toy training dataset by randomly sampling three data points from our
    search space (between –5 and 5), and evaluate the objective and cost functions
    at these points. We use `torch.rand()` to randomly sample between 0 and 1 and
    scale the samples to our search space:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过从我们的搜索空间中随机抽样三个数据点（在 -5 到 5 之间）来创建一个玩具训练数据集，并在这些点上评估目标和成本函数。我们使用 `torch.rand()`
    在 0 和 1 之间随机采样，然后将样本缩放到我们的搜索空间：
- en: '[PRE64]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: ❶ Fixes the seed for reproducibility
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 为了可重现性而固定种子
- en: ❷ Samples between 0 and 1 and then scales the samples to our search space
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 在 0 和 1 之间进行采样，然后将样本缩放到我们的搜索空间
- en: Train a GP on the data from the objective function and another GP on the data
    from the cost function using the helper function `fit_gp_model()`.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用辅助函数 `fit_gp_model()` 在目标函数数据和成本函数数据上训练一个 GP。
- en: '[PRE65]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: ❶ Trains a GP on the objective function’s data
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 在目标函数数据上训练一个 GP
- en: ❷ Trains a GP on the cost function’s data
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 在成本函数的数据上训练一个 GP
- en: Use the GP trained on the data from the cost function to compute the probability
    of feasibility for each point in the test set.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用在成本函数数据上训练的 GP 来计算测试集中每个点的可行性概率。
- en: 'We first compute the predictive distribution of the cost GP on our test set:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先计算成本 GP 在我们的测试集上的预测分布：
- en: '[PRE66]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We then initialize a normal distribution object, with the mean and standard
    deviation corresponding to the means and standard deviations of `cost_pred_dist`:'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们初始化一个正态分布对象，其均值和标准差对应于 `cost_pred_dist` 的均值和标准差：
- en: '[PRE67]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Finally, we call the `cdf()` method on this object to compute the probability
    of feasibility. The argument this method takes is the upper bound of our cost
    constraint, which is 0:'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们在这个对象上调用 `cdf()` 方法来计算可行性的概率。这个方法所取的参数是我们成本约束的上限，即 0：
- en: '[PRE68]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Initialize a regular EI policy, with the `model` argument being the GP trained
    on the data from the objective function and the `best_f` argument being the current
    feasible incumbent.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化常规 EI 策略，其中 `model` 参数是在目标函数数据上训练的 GP，而 `best_f` 参数是当前的可行入围者。
- en: 'We compute the current feasible incumbent with `train_utility[train_cost` `<=`
    `0].max()`:'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用 `train_utility[train_cost <= 0].max()` 计算当前的可行入围者：
- en: '[PRE69]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We then compute the EI score by calling the EI policy object on `xs[:,` `None,`
    `None]`, which is the test dense grid reshaped to make sure it’s of appropriate
    shape:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，通过在 `xs[:, None, None]` 上调用 EI 策略对象来计算 EI 分数，该对象是为确保其形状适当而重新塑造的测试密集网格：
- en: '[PRE70]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Initialize a constrained EI policy, and compute the constrained EI score for
    each point in the test set:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化受限 EI 策略，并为测试集中的每个点计算受限 EI 分数：
- en: '[PRE71]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We also compute the constrained EI score with the reshaped test set:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还使用重塑后的测试集计算受限 EI 分数：
- en: '[PRE72]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Compute the product of the EI scores and the probabilities of feasibility,
    and verify that this manual computation leads to the same results as those from
    BoTorch’s implementation. Run an assertion to make sure all corresponding terms
    match up:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 EI 分数和可行性概率的乘积，并验证这种手动计算是否与 BoTorch 的实现结果相同。 运行断言以确保所有相应的术语匹配：
- en: '[PRE73]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Plot the EI scores and the constrained EI scores in a graph, and visually verify
    that the former is always greater than or equal to the latter. Prove this is the
    case.
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在图中绘制 EI 分数和受限 EI 分数，并直观地验证前者始终大于或等于后者。 证明这是正确的。
- en: 'We plot out the scores we have computed thus far as follows:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们如下绘制迄今为止计算的分数：
- en: '[PRE74]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: This code generates figure A.15, which shows that the EI score is, indeed, always
    at least the constrained EI score.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此代码生成图 A.15，显示 EI 分数确实始终至少等于受限 EI 分数。
- en: '![](../../OEBPS/Images/A-15.png)'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-15.png)'
- en: Figure A.15 The acquisition score of EI (solid line) and constrained EI (dashed
    line). The former is always greater than or equal to the latter.
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.15 EI 的获取分数（实线）和受限 EI（虚线）。 前者始终大于或等于后者。
- en: We can mathematically prove this by noting that the constrained EI score is
    equal to the regular EI score multiplied by the probability of feasibility. This
    probability of feasibility is always a maximum of 1, so the EI score is always
    greater than or equal to the constrained EI score.
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过注意到受限 EI 分数等于正常 EI 分数乘以可行性概率来数学证明这一点。 可行性概率始终最大为 1，因此 EI 分数始终大于或等于受限 EI
    分数。
- en: 'A.7.2 Exercise 2: Constrained optimization of airplane design'
  id: totrans-370
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.7.2 练习 2：飞机设计的受限优化
- en: 'In this exercise, we tackle a constrained optimization problem using the airplane-utility
    objective function in exercise 2 of chapter 7\. This process allows us to run
    constrained BayesOpt on a higher-dimensional problem in which it’s not obvious
    where the feasibility optimal solution is. The solution to this exercise is included
    in the CH08/03 - Exercise 2.ipynb notebook:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们使用第 7 章练习 2 中的飞机效用目标函数来解决一个受限制的优化问题。 这个过程允许我们在一个高维问题上运行受限 BayesOpt，在这个问题中，不明显的是可行性最优解在哪里。
    这个练习的解决方案包含在 CH08/03 - Exercise 2.ipynb 笔记本中：
- en: Recreate the BayesOpt problem used in the CH07/04 - Exercise 2.ipynb notebook,
    including the airplane-utility objective function named `flight_utility()`, the
    bounds of our search space (the four-dimensional unit hypercube), the GP implementation,
    and the helper function that trains a GP on some training data `fit_gp_model()`.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新创建在 CH07/04 - Exercise 2.ipynb 笔记本中使用的 BayesOpt 问题，包括名为 `flight_utility()`
    的飞机效用目标函数、我们搜索空间的边界（四维单位超立方体）、GP 实现以及在一些训练数据上训练 GP 的辅助函数 `fit_gp_model()`。
- en: 'Implement the following cost function, which simulates the cost of making the
    airplane design specified by a four-dimensional input:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现以下成本函数，模拟制造由四维输入指定的飞机设计的成本：
- en: '[PRE75]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Our goal is to maximize the objective function `flight_utility()`, while following
    the constraint that the cost, as computed by `flight_cost()`, is less than or
    equal to 0.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的目标是在遵循成本小于或等于 0 的约束条件的情况下最大化目标函数 `flight_utility()`。
- en: 'To this end, we set the number of queries a BayesOpt policy can make in each
    experiment as 50, and designate that each policy needs to run 10 repeated experiments:'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为此，我们将 BayesOpt 策略每个实验的查询次数设置为 50，并指定每个策略需要运行 10 次重复实验：
- en: '[PRE76]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The default value quantifying optimization progress if no feasible solution
    is found should be set to –2.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果找不到可行解，则默认值量化优化进度应设置为-2。
- en: '[PRE77]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Run the constrained EI policy as well as the regular EI policy on this problem;
    visualize and compare their average progress (along with error bars).
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此问题上运行受限EI策略以及常规EI策略；可视化并比较它们的平均进展（以及误差线）。
- en: 'We implement the constrained EI policy in the same way as we did in chapter
    8, where we set `best_f` to be either the current feasible incumbent if a feasible
    solution has been found or the default value –2 otherwise. Our model list contains
    the objective GP, which has an index of 0, and the cost GP, which has an index
    of 1:'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们以与第8章相同的方式实现了受限EI策略，其中我们将`best_f`设置为当前可行的最优解（如果找到了可行解）或默认值-2（如果没有找到可行解）。我们的模型列表包含目标GP，其索引为0，和成本GP，其索引为1：
- en: '[PRE78]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: ❶ Finds the appropriate value of the current incumbent
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 找到当前最优解的适当值
- en: ❷ The list of GP models
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ GP模型列表
- en: ❸ Index of the objective model
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 目标模型的索引
- en: ❹ Index of the constraint model and the lower and upper bounds
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 约束模型的索引和下限和上限
- en: 'We implement the regular EI policy as follows:'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们如下实现常规EI策略：
- en: '[PRE79]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Figure A.16 shows the optimization results obtained by the two preceding policies
    we implemented. We see that constrained EI completely dominates the regular EI
    policy by accounting for the cost constraint we impose.
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.16显示了我们实现的两个先前策略获得的优化结果。我们看到，受限EI通过考虑我们施加的成本约束完全支配了常规EI策略。
- en: '![](../../OEBPS/Images/A-16.png)'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-16.png)'
- en: Figure A.16 Progress made by various Bayesian optimization policies in the constrained
    airplane design optimization example. Compared to the regular EI, the constrained
    variant finds a more feasible solution on average.
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.16各种贝叶斯优化策略在受限飞机设计优化示例中所取得的进展。与常规EI相比，受限变体平均找到更可行的解决方案。
- en: 'A.8 Chapter 9: Balancing utility and cost with multifidelity optimization'
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.8 第9章：用多信度优化平衡效用和成本
- en: 'There are two exercises in this chapter:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有两个练习：
- en: Exercise 1 walks through the process of measuring and visualizing the average
    performance of an optimization policy across multiple experiments.
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 练习1介绍了跨多个实验测量和可视化优化策略平均性能的过程。
- en: Exercise 2 applies the optimization policies we know to a two-dimensional problem
    with three functions we can query from.
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 练习2将我们所知的优化策略应用于具有三个可查询函数的二维问题。
- en: 'A.8.1 Exercise 1: Visualizing average performance in multifidelity optimization'
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.8.1 练习1：在多信度优化中可视化平均性能
- en: 'In this exercise, we run the optimization loop multiple times and learn how
    to take the average performance to obtain a more holistic comparison:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们多次运行优化循环，并学习如何取得平均性能以获得更全面的比较：
- en: Copy the problem setup and the multifidelity optimization loop from the CH09/03
    - Measuring performance.ipynb notebook, and add another variable denoting the
    number of experiments we want to run (10, by default).
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制CH09/03 - 测量性能.ipynb笔记本中的问题设置和多信度优化循环，并添加另一个变量，表示我们要运行的实验次数（默认为10次）。
- en: 'To facilitate repeated experiments, add an outer loop to the optimization loop
    code. This should be a `for` loop with 10 iterations, where a different random
    observation is generated each time:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了方便重复实验，在优化循环代码中添加一个外部循环。这应该是一个具有10次迭代的`for`循环，每次生成一个不同的随机观察值：
- en: '[PRE80]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: ❶ Repeats the experiment 10 times
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 重复实验10次
- en: ❷ Generates a random initial training set specific to the current iteration
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 生成特定于当前迭代的随机初始训练集
- en: ❸ The inner loop that runs optimization until we exhaust our budget
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 内循环，直到我们耗尽预算
- en: 'Make each of the variables `recommendations` and `spent_budget` a list of lists,
    where each inner-list keeps track of optimization performance of an individual
    experiment. We add to the code for the nested loop in the previous step as follows:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将变量`recommendations`和`spent_budget`的每个变量都设为一个列表的列表，其中每个内部列表跟踪单个实验的优化性能。我们将上一步中嵌套循环的代码添加如下所示：
- en: '[PRE81]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: ❶ Each variable is a (currently empty) list of lists.
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 每个变量都是一个（当前为空的）列表的列表。
- en: ❷ Appends an empty list to each list of lists for the next experiment
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 向每个列表的列表添加一个空列表，以供下一个实验使用
- en: ❸ Adds the optimization progress statistics to the newest list in each variable
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 将优化进度统计信息添加到每个变量的最新列表中
- en: Run the multifidelity MES policy and its single-fidelity version on our optimization
    problem.
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的优化问题上运行多保真度 MES 策略及其单保真度版本。
- en: 'We first make the regular grid and the currently empty interpolated recommended
    values that we will fill in later:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先制作正则网格和当前空白的插值推荐值，稍后我们将填写其中：
- en: '[PRE82]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We then iterate through each list in `recommendations` (renamed to `incumbents`
    in our code) and `spend_budget`, compute the linear interpolation, and then fill
    in the values in `interp_incumbents`:'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们遍历 `recommendations` 中的每个列表（在我们的代码中重命名为 `incumbents`）和 `spend_budget`，计算线性插值，然后填写
    `interp_incumbents` 中的值：
- en: '[PRE83]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Use the linearly interpolated values to plot the average performance and error
    bars of the two policies we ran and compare their performance. The comparison
    is visualized in figure A.17, where we see that the multifidelity MES policy greatly
    outperforms its single-fidelity competitor.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用线性插值值绘制我们运行的两个策略的平均性能和误差条，并比较它们的性能。比较可视化在图 A.17 中展示，我们可以看到多保真度 MES 策略大大优于其单保真度竞争对手。
- en: '![](../../OEBPS/Images/A-17.png)'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-17.png)'
- en: Figure A.17 Average optimization progress of the single- and multifidelity MES
    policies on the Forrester function across 10 experiments. The multifidelity policy
    greatly outperforms the single-fidelity one.
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.17 显示了在 10 次实验中单一保真度和多保真度 MES 策略在 Forrester 函数上的平均优化进展。多保真度策略大大优于单保真度策略。
- en: Plot the linearly interpolated curves representing individual runs’ optimization
    progress, along with the average performance and error bars. The comparison is
    visualized in figure A.18\. Indeed, our optimization progress in each run, as
    measured by the maximum posterior mean recommendation, is not monotonically increasing.
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制线性插值曲线，代表各个运行的优化进展，以及平均性能和误差条。比较可视化在图 A.18 中呈现。事实上，我们每次运行的优化进展，由最大后验平均推荐值来衡量，并不是单调递增的。
- en: '![](../../OEBPS/Images/A-18.png)'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-18.png)'
- en: Figure A.18 Linearly interpolated curves representing individual runs' optimization
    progress across 10 experiments. Our optimization progress in each run, as measured
    by the maximum posterior mean recommendation, is not monotonically increasing.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.18 线性插值曲线代表了在 10 次实验中各个运行的优化进展。我们每次运行的优化进展，由最大后验平均推荐值来衡量，并不是单调递增的。
- en: 'A.8.2 Exercise 2: Multifidelity optimization with multiple low-fidelity approximations'
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.8.2 练习 2：使用多个低保真度近似进行多保真度优化
- en: 'This exercise shows us that our multifidelity Max-value Entropy Search policy
    can balance between multiple low-fidelity functions. The solution, found in the
    CH09/05 - Exercise 2.ipynb notebook, can be explained as follows:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习向我们展示了我们的多保真度最大值熵搜索策略可以在多个低保真度函数之间平衡。解决方案，可以在 CH09/05 - Exercise 2.ipynb
    笔记本中找到，解释如下：
- en: Implement the objective function. The code for this step has already been provided
    in the instructions.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现目标函数。该步骤的代码已在说明中提供。
- en: 'Define the bounds of our search space as the unit square:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将我们的搜索空间的边界定义为单位正方形：
- en: '[PRE84]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Declare the `fidelities` variable that stores the correlation values of the
    different functions we can query:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明存储我们可以查询的不同函数的相关值的 `fidelities` 变量：
- en: '[PRE85]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Set the fixed cost of the linear cost model to 0.2 and the weight to 1:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将线性成本模型的固定成本设置为 0.2，权重设置为 1：
- en: '[PRE86]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Set the limit of our budget in each experiment to 10 and the number of repeated
    experiments to 10 as well:'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将每次实验中我们的预算限制设置为 10，并且重复实验的次数也设置为 10：
- en: '[PRE87]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Set the number of candidates drawn from the Sobol sequence to 5,000, and use
    100 restarts and 500 raw samples when using helper functions to optimize the acquisition
    score of a given policy:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Sobol 序列中绘制的候选者数量设置为 5,000，并在使用辅助函数优化给定策略的收购分数时，使用 100 次重启和 500 次原始样本：
- en: '[PRE88]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Redefine the helper function `get_final_recommendation` that finds the posterior
    mean maximizer:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义辅助函数 `get_final_recommendation`，以找到后验平均值最大化器：
- en: '[PRE89]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: ❶ The necessary changes
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 必要的更改
- en: Run the multifidelity MES policy and its single-fidelity version on our optimization
    problem, and plot the average optimization progress and error bars of each policy,
    using the method described in exercise 1\. Figure A.19 shows the comparison between
    the two policies.
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的优化问题上运行多保真度 MES 策略及其单保真度版本，并使用练习 1 中描述的方法绘制每个策略的平均优化进展和误差条。图 A.19 显示了两种策略之间的比较。
- en: '![](../../OEBPS/Images/A-19.png)'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-19.png)'
- en: Figure A.19 Average optimization progress of the single- and multifidelity MES
    policy on the Branin function across 10 experiments. The multifidelity policy,
    once again, outperforms the single-fidelity one.
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.19 显示了单一和多层次 MES 策略在 Branin 函数上的平均优化进展。多层次策略再次优于单一层次策略。
- en: 'A.9 Chapter 11: Optimizing multiple objectives at the same time'
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.9 第 11 章：同时优化多个目标
- en: 'In this exercise, we apply the multiobjective optimization techniques we have
    learned to the problem of optimizing the aerostructural design of an airplane.
    This exercise allows us to observe the performance of the Expected Hypervolume
    Improvement (EHVI) policy in a multidimensional problem:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将我们学到的多目标优化技术应用于优化飞机的气动结构设计问题。这个练习让我们能够观察多维问题中 Expected Hypervolume
    Improvement (EHVI) 策略的表现：
- en: 'We copy the code for the objective functions as follows:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照以下方式复制了目标函数的代码：
- en: '[PRE90]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: ❶ The first objective function
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 第一个目标函数
- en: ❷ The second objective function, negated from the code in exercise 2 of chapter
    8
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 第二个目标函数，来自第 8 章练习 2 中的代码取反
- en: 'We implement the helper function as follows:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照以下方式实现辅助函数：
- en: '[PRE91]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'We declare the bounds of the search space:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们声明搜索空间的边界：
- en: '[PRE92]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We declare the reference point:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们声明参考点：
- en: '[PRE93]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The class implementation and helper function can be implemented using the same
    code as, for example, in CH08/03 - Exercise 2.ipynb.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类实现和辅助函数可以使用与 CH08/03 - 练习 2.ipynb 中相同的代码实现。
- en: 'We set the experimental settings:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置实验设置：
- en: '[PRE94]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: We implement the two BayesOpt policies in the same way as in CH11/02 - Multi-objective
    BayesOpt loop.ipynb. Figure A.20 shows the performance of the two policies aggregated
    across 10 experiments. EHVI, once again, outperforms the alternating EI policy.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照 CH11/02 - 多目标 BayesOpt loop.ipynb 中相同的方式实现了两种 BayesOpt 策略。图 A.20 展示了两种策略在
    10 个实验中的综合表现。EHVI 策略再次优于交替 EI 策略。
- en: '![](../../OEBPS/Images/A-20.png)'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-20.png)'
- en: Figure A.20 Average hypervolume and error bars as a function of the number of
    queries made by two Bayesian optimization policies. EHVI consistently outperforms
    the alternating EI policy.
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.20 显示两个贝叶斯优化策略根据查询次数的平均超体积和误差棒。EHVI 策略始终优于交替 EI 策略。
- en: 'A.10 Chapter 12: Scaling Gaussian processes to large data sets'
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.10 第 12 章：将高斯过程扩展到大数据集
- en: This exercise demonstrates the improvement in efficiency when going from a regular
    GP model to a VGP one on a real-life dataset of housing prices in California.
    Our goal is to observe the computational benefits of a VGP—this time, in a real-world
    setting.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习展示了在真实数据集加利福尼亚州房价上从普通 GP 模型转换为 VGP 模型时的效率提升。我们的目标是观察 VGP 在真实世界环境中的计算优势。
- en: 'Complete the following steps:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 完成以下步骤：
- en: 'We use the Pandas library to read in the dataset:'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 Pandas 库读入数据集：
- en: '[PRE95]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Once read in, the Pandas dataframe should look similar to the output in figure
    A.21.
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将 Pandas dataframe 读入后，应该与图 A.21 中的输出类似。
- en: '![](../../OEBPS/Images/A-21.png)'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-21.png)'
- en: Figure A.21 The housing price dataset shown as a Pandas dataframe. This is the
    training set for this exercise.
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.21 显示了房价数据集作为 Pandas dataframe。这是本练习的训练集。
- en: 'We create the scatter plot as follows:'
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建散点图如下所示：
- en: '[PRE96]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: The visualization should look similar to figure A.22.
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化应该类似于图 A.22。
- en: '![](../../OEBPS/Images/A-22.png)'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/A-22.png)'
- en: Figure A.22 The housing price dataset shown as a scatter
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.22 房价数据集显示为散点图
- en: 'To extract our training features, we use the `torch.from_numpy()` method to
    convert a NumPy array to a PyTorch tensor:'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了提取我们的训练特征，我们使用 `torch.from_numpy()` 方法将 NumPy 数组转换为 PyTorch 张量：
- en: '[PRE97]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'We similarly do this for the log of the house prices, which are our training
    labels:'
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们同样对房价的对数进行了这样的操作，这是我们的训练标签：
- en: '[PRE98]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'We normalize the training labels `train_y` as follows:'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将训练标签 `train_y` 标准化如下：
- en: '[PRE99]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'We implement the GP model as follows:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如下实现 GP 模型：
- en: '[PRE100]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: ❶ The constant mean function
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 常数均值函数
- en: ❷ An ARD Matern 5/2 kernel with an output scale
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 具有输出比例的 ARD Matern 5/2 核函数
- en: 'Make a likelihood whose noise is constrained to be at least 0.1, using the
    following code:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码制作一个噪声至少为 0.1 的似然函数：
- en: '[PRE101]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: ❶ The constraint forces the noise to be at least 0.1.
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 约束强制噪声至少为 0.1。
- en: 'We train the previously implemented GP model using gradient descent as follows:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用梯度下降训练先前实现的 GP 模型如下：
- en: '[PRE102]'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: ❶ The gradient descent optimizer Adam
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 梯度下降优化器 Adam
- en: ❷ The (negative) marginal log likelihood loss function
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ （负）边际对数似然损失函数
- en: ❸ Enable training mode
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 启用训练模式
- en: The total training time was 24 seconds on a MacBook.
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 MacBook 上，总训练时间为 24 秒。
- en: 'We implement the VGP model as follows:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按以下步骤实现了 VGP 模型：
- en: '[PRE103]'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: ❶ Variational parameters
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 变分参数
- en: ❷ The same as the GP
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 与 GP 相同
- en: 'This VGP is trained as follows:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个 VGP 是这样训练的：
- en: '[PRE104]'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: ❶ Randomly picks 100 points as the initial inducing points
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❶ 随机选择 100 个点作为初始感兴趣点
- en: ❷ Prepares the mini batches
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❷ 准备小批量数据
- en: ❸ Natural gradient descent for variational parameters
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❸ 对变分参数使用自然梯度下降
- en: ❹ Adam for the other parameters
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ❹ 使用 Adam 更新其他参数
- en: On the same MacBook, training took 6 seconds—a 400% improvement in speed.
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一台 MacBook 上，训练时间缩短到 6 秒，速度提升了 400%。
- en: The solution is included in the CH12/02 - Exercise.ipynb notebook.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案包含在 CH12/02 - Exercise.ipynb 笔记本中。
