- en: 1 Introducing AI-powered search
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 介绍人工智能搜索
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: What is AI-powered search?
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是人工智能搜索？
- en: Understanding user intent
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解用户意图
- en: How AI-powered search works
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能搜索的工作原理
- en: Content and behavioral intelligence
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容和行为智能
- en: Architecting an AI-powered search engine
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建人工智能搜索引擎
- en: The search box has become the default user interface for interacting with data
    in most modern applications. If you think of every major app or website you use
    daily, one of the first things you likely do on each visit is enter a query to
    find the content or actions most relevant to you.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索框已经成为大多数现代应用程序中与数据交互的默认用户界面。如果你想到你每天使用的每一个主要应用程序或网站，你可能在每次访问时做的第一件事就是输入一个查询来找到对你最相关的内容或操作。
- en: When you’re not explicitly searching, you may instead be consuming streams of
    content customized to your tastes and interests. Whether these be video recommendations,
    items for purchase, prioritized emails, news articles, or other content, you’re
    likely still looking at filtered or ranked results and given the option to either
    page through or explicitly filter the content with your own query.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当你没有明确搜索时，你可能会消费定制到你口味和兴趣的内容流。无论是视频推荐、购买物品、优先电子邮件、新闻文章或其他内容，你很可能仍在查看过滤或排名的结果，并有机会通过自己的查询浏览或明确过滤内容。
- en: For most people, the phrase “search engine” brings up thoughts of a website
    like Google, Bing, or Baidu that enables queries based on a crawl of the entire
    public internet. However, the reality is that search is now available in nearly
    all our digital interactions every day across the numerous websites and applications
    we use.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数人来说，“搜索引擎”这个短语会让人联想到像Google、Bing或Baidu这样的网站，这些网站通过爬取整个公共互联网来允许基于搜索的查询。然而，现实情况是，现在搜索几乎已经融入到我们每天与众多网站和应用进行数字互动的每一个环节中。
- en: These search engines are far from static. We’re seeing commercial technologies
    like OpenAI’s ChatGPT, Anthropic’s Claude, and Google’s Gemini, as well as hundreds
    of other more open large language models (LLMs), like Meta’s Llama and Mistral’s
    Mixtral, with source code and model weights published for public use. These all
    serve as models of the world’s information that can generate interpretations and
    responses to arbitrary queries. These models are being actively integrated into
    major search engines and will continue to heavily influence the evolution of AI-powered
    search.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些搜索引擎远非静态。我们看到像OpenAI的ChatGPT、Anthropic的Claude和Google的Gemini这样的商业技术，以及数百个其他更开放的大型语言模型（LLMs），如Meta的Llama和Mistral的Mixtral，它们的源代码和模型权重已公开发布供公众使用。这些都作为世界信息的模型，可以生成对任意查询的解释和响应。这些模型正在积极集成到主要搜索引擎中，并将继续对人工智能搜索的演变产生重大影响。
- en: While the expected response from a search box may have historically been to
    return “ten blue links”—a list of ranked documents for a user to investigate further
    to find information in response to their query—expectations for the intelligence
    level of search technologies have skyrocketed in recent years.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然搜索框的预期响应可能历史性地是返回“十个蓝色链接”——一个按排名排列的文档列表，供用户进一步调查以找到他们查询的信息——但近年来对搜索技术智能水平的期望已经急剧上升。
- en: Users today expect search technology to be
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 用户今天期望搜索技术能够
- en: '*Domain-aware*—Search technology should understand the entities, terminology,
    categories, and attributes of each specific use case and corpus of documents,
    not just use generic statistics on strings of text.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*领域感知*——搜索技术应该理解每个特定用例和文档集合中的实体、术语、类别和属性，而不仅仅是使用字符串文本的通用统计数据。'
- en: '*Contextual and personalized*—It should be able to take into account user context
    (location, last search, profile, previous interactions, user recommendations,
    and user classification), query context (other keywords, similar searches), and
    domain context (inventory, business rules, domain-specific terminology) to better
    interpret user intent.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情境化和个性化*——它应该能够考虑到用户情境（位置、上次搜索、个人资料、先前互动、用户推荐和用户分类），查询情境（其他关键词、类似搜索）和领域情境（库存、业务规则、领域特定术语），以便更好地解释用户意图。'
- en: '*Conversational*—It should be able to interact in natural language and guide
    users through a multi-step discovery process while learning and remembering relevant
    new information along the way.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对话式*——它应该能够用自然语言进行交互，并在学习并记住相关新信息的同时，引导用户通过多步骤的发现过程。'
- en: '*Multi-modal*—It should be able to resolve queries issued by text, voice, images,
    video, or other content types, and to use those queries to also search across
    the other content types.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多模态*—它应该能够解决由文本、语音、图像、视频或其他内容类型提出的查询，并使用这些查询在跨其他内容类型中进行搜索。'
- en: '*Intelligent*—It should be able to deliver predictive type-ahead and to understand
    what users mean (spelling correction, phrase and attribute detection, intent classification,
    conceptual searching) to deliver the right answers at the right time and to constantly
    get smarter.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*智能*—它应该能够提供预测性自动补全，并理解用户的意思（拼写纠正、短语和属性检测、意图分类、概念搜索），以便在正确的时间提供正确的答案，并不断变得更聪明。'
- en: '*Assistive*—It should move beyond delivering just links to delivering answers,
    summaries, explanations, and available actions.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*辅助*—它应该超越仅仅提供链接，提供答案、摘要、解释和可用的操作。'
- en: Many of these capabilities are enabled by LLMs, while others are driven by analyzing
    user behavior and building domain-specific personalization profiles, knowledge
    graphs, and ranking models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些功能都是由大型语言模型（LLMs）实现的，而其他功能则是由分析用户行为和构建特定领域的个性化配置文件、知识图谱和排名模型驱动的。
- en: Search interfaces are also evolving to include more chatbot and conversational
    information discovery sessions as LLMs become more ubiquitous, but even today’s
    best models struggle with hallucinating (making up bad answers) and going off
    the rails unless tethered to an actual information source, such as a search engine
    index, to reliably find and return information from trusted sources. *Retrieval
    augmented generation (RAG)*, the technique of using a search engine or vector
    database as a knowledge source to provide LLMs accurate and up-to-date information
    as context, is one of the most reliable techniques for improving the accuracy
    of generative AI models today.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLMs的普及，搜索界面也在不断发展，包括更多的聊天机器人和会话信息发现会话，但即使是目前最好的模型，在没有连接到实际的信息源（如搜索引擎索引）的情况下，也难以避免胡编乱造（提供错误的答案）和偏离轨道，除非连接到可靠的信息源。*检索增强生成（RAG）*，即使用搜索引擎或向量数据库作为知识源，为LLMs提供准确和最新的信息作为上下文，是目前提高生成人工智能模型准确性的最可靠技术之一。
- en: The goal of AI-powered search is to use automated machine learning techniques
    to deliver on all these desired capabilities. While many organizations start with
    basic text search and spend many years trying to manually optimize synonym lists,
    business rules, ontologies, field weights, and countless other aspects of their
    search configuration, some are beginning to realize that most of this process
    can be automated.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能搜索的目标是利用自动机器学习技术来实现所有这些期望的功能。虽然许多组织从基本的文本搜索开始，花费多年时间尝试手动优化同义词列表、业务规则、本体、字段权重以及搜索配置的无数其他方面，但一些组织开始意识到，这个过程的大部分可以自动化。
- en: Throughout the book, you’ll learn to implement many key AI-powered search techniques,
    such as
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，你将学习到实现许多关键人工智能搜索技术，例如
- en: Using LLMs for query interpretation, embeddings, question answering, and results
    summarization
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLMs进行查询解释、嵌入、问答和结果摘要
- en: Fine-tuning LLMs for search and question answering
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调LLMs以进行搜索和问答
- en: Collecting and using user signals for crowdsourced relevance
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集和使用用户信号以进行众包相关性
- en: Signals-boosting models
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号增强模型
- en: Knowledge graph learning from both signals and content
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从信号和内容中学习知识图谱
- en: Semantic knowledge graphs
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义知识图谱
- en: Query intent classification and query-sense disambiguation
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询意图分类和查询意义消歧
- en: Personalized search and recommendations
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化搜索和推荐
- en: Machine-learned ranking (learning to rank)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习排名（学习排名）
- en: Click models for implicit relevance feedback
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于隐式相关性反馈的点击模型
- en: Avoiding bias in ranking models through active learning
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过主动学习避免排名模型中的偏差
- en: Hybrid search and multimodal search across text, images, and mixed content types
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本、图像和混合内容类型的混合搜索和多模态搜索
- en: Semantic search using both knowledge graphs and LLMs
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用知识图谱和LLMs进行语义搜索
- en: This book is an example-driven guide through the most applicable machine learning
    algorithms and techniques commonly used to build intelligent search systems. We’ll
    not only walk through key concepts but will also provide reusable code examples
    to cover data collection and processing techniques, as well as the self-learning
    query interpretation and relevance strategies employed to deliver AI-powered search
    capabilities across today’s leading organizations—hopefully soon to include your
    own!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是一个以实例为导向的指南，介绍了构建智能搜索系统最常用的机器学习算法和技术。我们不仅会讲解关键概念，还会提供可重用的代码示例，涵盖数据收集和处理技术，以及用于提供AI驱动的搜索能力的自我学习查询解释和相关性策略，希望很快也能包括您自己的组织！
- en: 1.1 What is AI-powered search?
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 什么是AI驱动的搜索？
- en: Prior to November 2022, when OpenAI released ChatGPT to the world as a generalizable
    algorithm that non-technical users could talk with to solve many problems, the
    definition of “artificial intelligence” was a bit nebulous to the general public.
    It was understood to include things like self-driving cars, autonomous robots,
    and other futuristic technologies that made computers appear to be intelligent,
    but AI appeared to many to be more of a marketing buzzword than a well-defined
    term. A more concrete definition has existed in the software industry for years,
    however.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年11月之前，当OpenAI将ChatGPT作为一个可通用的算法发布给世界，让非技术用户可以通过它来解决许多问题时，“人工智能”的定义对公众来说有些模糊。人们理解它包括自动驾驶汽车、自主机器人和其他使计算机看起来具有智能的未来技术，但对许多人来说，AI似乎更像是一个营销术语，而不是一个定义明确的术语。然而，在软件行业，多年来一直存在一个更具体的定义。
- en: In the context of software development, the term *artificial intelligence* generally
    describes any computer program that can perform a task that previously required
    human intelligence. That program often includes machine learning techniques, allowing
    it to learn from data and improve its performance over time. That said, even rules-based
    systems that do not involve machine learning techniques but generate human-like
    feedback have also traditionally been considered “AI” systems. We’ll adopt this
    more general definition of AI in this book, though we’ll be primarily discussing
    the machine-learning aspects of AI.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件开发背景下，术语*人工智能*通常指任何能够执行以前需要人类智能的任务的计算机程序。该程序通常包括机器学习技术，使其能够从数据中学习并随着时间的推移提高其性能。尽管如此，即使不涉及机器学习技术但能生成类似人类反馈的基于规则的系统也一直被视为“人工智能”系统。在这本书中，我们将采用这种更广泛的AI定义，尽管我们主要会讨论AI的机器学习方面。
- en: The term *search* (or *search engine*) is likewise considered by the general
    public to refer to web search engines like Google or Bing. In software development,
    the term is also used to describe any technology that enables users to query for
    and find information. Search typically involves at least two critical steps—finding
    documents that match a query (*matching*) and then ordering those documents by
    relevance to the query (*ranking*). Search can also include many preprocessing
    steps to better understand the query, and postprocessing steps to extract answers
    or summarize results from the matched documents. Search is often the primary way
    users find information, whether conducting general web search, product search,
    enterprise search, video/image search, or any of hundreds of other common use
    cases for finding and ranking information. It is also the primary way generative
    AI systems quickly find updated factual content to use as context for their prompts.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*搜索*（或*搜索引擎*）同样被公众认为是像Google或Bing这样的网络搜索引擎。在软件开发中，这个术语也用来描述任何能够使用户查询和找到信息的任何技术。搜索通常至少涉及两个关键步骤——找到与查询匹配的文档（*匹配*）然后根据查询的相关性对这些文档进行排序（*排名*）。搜索还可以包括许多预处理步骤来更好地理解查询，以及后处理步骤从匹配的文档中提取答案或总结结果。搜索通常是用户找到信息的主要方式，无论是进行一般网络搜索、产品搜索、企业搜索、视频/图像搜索，还是数百种其他常见的信息查找和排名用例。它也是生成式AI系统快速找到更新的事实内容作为其提示上下文的主要方式。
- en: But what is AI-powered search, and how does it differ from traditional “search”?
    Many buzzwords such as “AI”, “machine learning”, “data science”, and “deep learning”
    are often thrown around interchangeably, and it’s important to understand the
    distinctions and how they overlap with AI-powered search. Figure 1.1 demonstrates
    the important relationships between these related areas.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 但什么是人工智能驱动的搜索，它与传统的“搜索”有何不同？许多流行词汇，如“人工智能”、“机器学习”、“数据科学”和“深度学习”，常常被互换使用，了解它们之间的区别以及它们如何与人工智能驱动的搜索重叠是很重要的。图
    1.1 展示了这些相关领域之间的重要关系。
- en: '![figure](../Images/CH01_F01_Grainger.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F01_Grainger.png)'
- en: Figure 1.1 AI-powered search includes all the technologies and techniques at
    the intersection of the fields of search and AI. These overlap heavily with and
    use the fields of data science, machine learning, and deep learning.
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.1 人工智能驱动的搜索包括搜索和人工智能领域的交叉点上的所有技术和技巧。这些技术与数据科学、机器学习和深度学习领域重叠很大，并使用这些领域。
- en: '*Machine learning* is a subset of AI that focuses on using data to train models
    to perform tasks based on insights learned from the training data. Deep learning
    is a further subset of machine learning that focuses on training artificial neural
    networks—algorithms that partially mimic the structure of the human brain—to learn
    to solve complex problems. In figure 1.1, notice that deep learning is a fully
    contained subset of machine learning, which is then a fully contained subset of
    artificial intelligence. Data science is a discipline that overlaps heavily with
    AI and search, but it also contains other distinct focus areas, so it is not completely
    a superset or subset of either.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习*是人工智能的一个子集，它专注于使用数据来训练模型，根据从训练数据中学习到的见解执行任务。深度学习是机器学习的一个进一步子集，它专注于训练人工神经网络——部分模仿人类大脑结构的算法——以学习解决复杂问题。在图
    1.1 中，请注意深度学习是机器学习的一个完全包含的子集，而机器学习又是人工智能的一个完全包含的子集。数据科学是一个与人工智能和搜索重叠很大的学科，但它还包含其他独特的关注领域，因此它既不是另一个学科的完全超集也不是子集。'
- en: Our focus in this book is specifically on the intersection of search (also known
    as *information retrieval*) and AI, and in particular on the application of machine
    learning and deep learning techniques to improve the relevance of search results
    and to automate the process of tuning search relevance. Building AI-powered search
    involves many well-known machine learning techniques, but also many that are specific
    to information retrieval and the search domain. Figure 1.2 provides a categorized
    list of some key AI-powered search techniques we’ll cover in this book, broken
    down by whether they are deep learning techniques, other machine learning techniques
    not requiring deep learning, or other artificial intelligence techniques not requiring
    machine learning.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本书关注的重点是搜索（也称为*信息检索*）与人工智能的交叉点，特别是将机器学习和深度学习技术应用于提高搜索结果的相关性以及自动化调整搜索相关性的过程。构建人工智能驱动的搜索涉及许多众所周知的机器学习技术，但也涉及许多特定于信息检索和搜索领域的技术。图
    1.2 提供了本书将涵盖的一些关键人工智能驱动的搜索技术的分类列表，按是否为深度学习技术、不需要深度学习的其他机器学习技术或不需要机器学习的其他人工智能技术分类。
- en: '![figure](../Images/CH01_F02_Grainger.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F02_Grainger.png)'
- en: Figure 1.2 Specific AI-powered search techniques, broken down by whether they
    are deep learning techniques, other machine learning techniques not requiring
    deep learning, or other artificial intelligence techniques not requiring machine
    learning
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.2 按是否为深度学习技术、不需要深度学习的其他机器学习技术或不需要机器学习的其他人工智能技术分类的具体人工智能驱动的搜索技术
- en: In the AI-only category, question-answering systems, virtual assistants, chatbots,
    and rules-based relevancy are all examples of AI techniques that are often built
    using machine learning, but which do not *require* machine learning. Many have
    built chatbots based entirely on rules to understand different user utterances
    and intents, and likewise question-answering systems can be built solely on rules
    and ontologies. That said, machine learning is often used to learn these kinds
    of rules and ontologies, so the lines between these categories are often blurred.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在仅限人工智能的类别中，问答系统、虚拟助手、聊天机器人和基于规则的关联性都是通常使用机器学习构建但不需要机器学习的人工智能技术的例子。许多人基于规则构建聊天机器人来理解不同的用户话语和意图，同样，问答系统也可以仅基于规则和本体来构建。但即便如此，机器学习通常用于学习这些规则和本体，因此这些类别之间的界限往往模糊不清。
- en: When algorithms begin to use data to train models, we enter into the machine
    learning subcategory of AI-powered search. We use behavioral signals from search
    engine users (clicks, likes, add-to-carts, purchases, etc.) to build models that
    can learn to better rank documents. This can include signals-boosting models (top
    documents per query or category), collaborative filtering models that generate
    recommendations or personalize search results, and ranking classifiers (learning
    to rank) that learn from content and behavioral signals to better rank results.
    Machine learning is also used to learn knowledge graphs, which are graphs of entities,
    concepts, and their relationships that can be used to better understand the domain
    and to better interpret user queries. Semantic search (search on meaning, not
    just keywords) can be enabled by such knowledge graphs, along with traditional
    natural language processing approaches, query intent classification, document
    clustering, and other techniques driven by user queries, documents, and user behavioral
    signals.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法开始使用数据来训练模型时，我们就进入了人工智能搜索的机器学习子类别。我们使用搜索引擎用户的（点击、点赞、加入购物车、购买等）行为信号来构建能够学习更好地对文档进行排序的模型。这可以包括信号增强模型（每个查询或类别的顶级文档）、生成推荐或个性化搜索结果的协同过滤模型，以及从内容和行为信号中学习以更好地排序结果的排序分类器（学习排序）。机器学习还用于学习知识图谱，这些图谱是实体、概念及其关系的图，可用于更好地理解领域并更好地解释用户查询。语义搜索（基于意义而非仅关键词的搜索）可以通过此类知识图谱以及传统的自然语言处理方法、查询意图分类、文档聚类和其他由用户查询、文档和用户行为信号驱动的技术来实现。
- en: 'Finally, in the deep learning subcategory of AI-powered search, we see the
    use of neural networks to build models that can understand user queries and documents,
    as well as rank and summarize search results. Here, text is used to train LLMs
    to understand the meaning of words and phrases, to generate answers to questions,
    and to generate summaries of documents. LLMs are a type of *foundation model*
    that can interpret text content and are often trained on massive amounts of text
    from the internet. Foundation models can also be trained on other types of content
    beyond just text (images, audio, video) to enable multimodal search across those
    content types: text-to-image search, text-to-audio, image-to-video, and so on.
    LLMs are also used to generate *embeddings*, which are vector representations
    of content that represent the content’s meaning. Since a search engine’s primary
    job is to find and rank content similar to an incoming query, these embeddings
    enable a sophisticated ability to search on a query’s meaning and significantly
    improve query understanding and ranking. Further fine-tuning of foundation models
    on specific goals or domain-specific datasets will also make them significantly
    better at understanding the nuances of those domains or use cases.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在人工智能搜索的深度学习子类别中，我们看到使用神经网络来构建能够理解用户查询和文档、排序和总结搜索结果的模型。在这里，文本用于训练大型语言模型（LLMs）以理解词语和短语的含义，生成问题的答案，以及生成文档的摘要。LLMs是一种可以解释文本内容的*基础模型*，通常在互联网上的大量文本上进行训练。基础模型还可以在除了文本之外的其他类型的内容上进行训练（如图像、音频、视频），以实现跨这些内容类型的**多模态搜索**：文本到图像搜索、文本到音频、图像到视频等。LLMs还用于生成**嵌入**，这是内容的向量表示，代表内容的含义。由于搜索引擎的主要任务是找到并排序与进入查询相似的内容，这些嵌入使得在查询的意义上进行搜索的能力更加复杂，并显著提高了查询理解和排序。在特定目标或特定领域的数据集上进一步微调基础模型也将使它们在理解这些领域的细微差别或用例方面变得更好。
- en: Foundation models compress a large amount of human knowledge (often much of
    the internet), providing them with a broad understanding across most domains.
    This compression of knowledge, however, is a lossy compression—the original data
    is not stored, and specific facts and concepts can be easily confused. Foundation
    models are well known to hallucinate answers to questions, making them generally
    unreliable for answering factual questions. As a result, in addition to search
    engines using foundation models to improve query understanding and ranking, we’re
    also seeing them used heavily for RAG—where search serves as a knowledge source
    that foundation models can rely on for accurate and up-to-date information as
    context for generative AI tasks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型压缩了大量的人类知识（通常包括大部分互联网），使它们在大多数领域拥有广泛的理解。然而，这种知识压缩是有损压缩——原始数据没有存储，具体事实和概念很容易混淆。基础模型因能够对问题产生幻觉答案而闻名，这使得它们在回答事实问题时通常不可靠。因此，除了搜索引擎使用基础模型来改进查询理解和排名之外，我们还在看到它们被大量用于RAG——其中搜索作为知识源，为生成式人工智能任务提供准确和最新的信息作为上下文。
- en: We’ll cover each of these AI-powered search techniques in detail throughout
    this book. But first, let’s discuss the goals of AI-powered search and how it
    differs from traditional search.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在整本书中详细介绍这些人工智能驱动的搜索技术。但首先，让我们讨论人工智能驱动的搜索的目标以及它与传统搜索的不同之处。
- en: 1.2 Understanding user intent
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 理解用户意图
- en: To deliver AI-powered search, we’ll need a cohesive understanding of the dimensions
    involved in interpreting user intent and returning content matching that intent.
    Within the field of information retrieval, search engines and recommendation engines
    are the two most popular technologies employed to deliver the relevant content
    required to satisfy users’ information need. Many organizations think of search
    engines and recommendation engines as separate technologies solving different
    use cases. Commonly, different teams within the same organization—often with different
    skill sets—work independently on separate search engines and recommendation engines.
    In this section, we’ll discuss why separating search and recommendations into
    independent functions and teams can often lead to less-than-ideal outcomes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要提供人工智能驱动的搜索，我们需要对涉及解释用户意图和返回匹配内容维度的整体理解。在信息检索领域，搜索引擎和推荐引擎是两种最流行的技术，用于提供满足用户信息需求的相关内容。许多组织认为搜索引擎和推荐引擎是不同的技术，解决不同的用例。通常，同一组织内的不同团队——通常具有不同的技能集——独立工作在不同的搜索引擎和推荐引擎上。在本节中，我们将讨论为什么将搜索和推荐分离成独立的功能和团队往往会导致不太理想的结果。
- en: 1.2.1 What is a search engine?
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 什么是搜索引擎？
- en: A search engine is typically thought of as a technology for explicitly entering
    queries and receiving a response (figure 1.3). It is usually exposed to end users
    through a text box into which a user can enter keywords or questions. The results
    are often returned in a list, alongside additional filtering options that enable
    further refinement of the initial query. Using this mechanism, search is used
    as a tool for direct discovery of relevant content. When a user is finished with
    their search session, they can usually issue a new query and start with a blank
    slate, ignoring the context of previous searches.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎通常被视为一种明确输入查询并接收响应的技术（图1.3）。它通常通过一个文本框暴露给最终用户，用户可以在其中输入关键词或问题。结果通常以列表形式返回，并列有额外的过滤选项，这些选项可以进一步细化初始查询。使用这种机制，搜索被用作直接发现相关内容的工具。当用户完成他们的搜索会话后，他们通常可以发出新的查询，并从一张白纸开始，忽略之前搜索的上下文。
- en: '![figure](../Images/CH01_F03_Grainger.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F03_Grainger.png)'
- en: Figure 1.3 A typical search experience, with a user entering a query and seeing
    search results with filtering options to support further refinement of the search
    results
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3 一个典型的搜索体验，用户输入查询并看到带有过滤选项的搜索结果，以支持进一步细化搜索结果
- en: A search engine is one of the most cross-functional kinds of systems within
    the software engineering world. Most underlying search engine technology is designed
    to operate in a massively scalable way, serving large volumes of queries against
    millions, billions, or even trillions of documents, and delivering results in
    hundreds of milliseconds or less. In many cases, real-time processing and near-real-time
    searching on newly ingested data is required, and all of this must be parallelizable
    across numerous servers to scale out and meet such high-performance requirements.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎是软件工程世界中功能最全面的一种系统。大多数底层搜索引擎技术被设计成以大规模可扩展的方式运行，针对数百万、数十亿甚至数万亿的文档处理大量查询，并在数百毫秒或更短的时间内提供结果。在许多情况下，对新摄入的数据进行实时处理和近实时搜索是必需的，所有这些都必须在多个服务器上并行化以扩展并满足如此高的性能要求。
- en: Implementing search engines also requires substantial work building search-specific
    data structures like an inverted index or ANN-based vector store, an understanding
    of linear algebra and vector similarity scoring, experience with text analysis
    and natural language processing, and knowledge of numerous search-specific types
    of data models and capabilities (spell checking, autosuggest, faceting, text highlighting,
    embeddings, and so on).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 实现搜索引擎还需要大量工作来构建特定的搜索数据结构，如倒排索引或基于ANN的向量存储，理解线性代数和向量相似度评分，具备文本分析和自然语言处理的经验，以及了解众多特定的搜索类型的数据模型和能力（拼写检查、自动建议、细分、文本高亮、嵌入等）。
- en: For a search engine to fully interpret user intent, it’s critical that you combine
    a thorough understanding of your content, your users, and your domain. We’ll revisit
    why this is important after briefly discussing the related topic of recommendation
    engines.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让搜索引擎完全理解用户意图，你结合对内容、用户和领域的彻底理解至关重要。在简要讨论了相关主题推荐引擎之后，我们将重新审视为什么这一点很重要。
- en: 1.2.2 What do recommendation engines offer?
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 推荐引擎提供了什么？
- en: Most people think of recommendation engines (or “recommendation systems”) as
    systems that don’t accept direct user input and instead deliver content based
    upon what the engine learns about them, calculating best matches for their interests
    and behaviors. These interests are inferred in a variety of ways through user
    preferences, user behavior, viewed content, and so on. This lack of direct user
    input for recommendation engines stands in direct contrast with search engines,
    which are traditionally thought of as technology that requires explicit user-driven
    queries.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人认为推荐引擎（或称为“推荐系统”）是不接受直接用户输入，而是根据引擎从他们那里学到的信息来提供内容，计算与他们的兴趣和行为最佳匹配的系统。这些兴趣通过用户偏好、用户行为、查看的内容等多种方式推断出来。对于推荐引擎来说，缺乏直接用户输入与搜索引擎形成鲜明对比，后者传统上被认为是一种需要明确用户驱动的查询的技术。
- en: If you routinely visit Amazon.com or any other major e-commerce website, you
    are no doubt familiar with recommendation engine sections stating that “based
    on your interest in this item, you may also like . . .” or otherwise just recommending
    a list of items based upon your collective browsing and purchase history, like
    the example in figure 1.4\. These recommendations often drive significant revenue
    for companies, and they help customers discover relevant, personalized, and related
    content that often complements what they are searching for explicitly.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你经常访问Amazon.com或其他任何主要电子商务网站，你无疑熟悉那些声称“根据你对这个物品的兴趣，你可能还会喜欢……”或其他基于你的集体浏览和购买历史推荐物品列表的推荐引擎部分，如图1.4中的示例。这些推荐往往为公司带来显著收入，并帮助客户发现相关、个性化且相关的内容，这些内容通常补充了他们明确搜索的内容。
- en: '![figure](../Images/CH01_F04_Grainger.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F04_Grainger.png)'
- en: Figure 1.4 Recommendations based upon users expressing interest in similar items
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4 基于用户对相似物品表示兴趣的推荐
- en: 'Recommendation algorithms can roughly be divided into three categories:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐算法大致可以分为三类：
- en: '*Content-based recommenders*—These match based on attributes of items or users'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于内容的推荐器*—这些推荐器基于物品或用户的属性进行匹配。'
- en: '*Behavior-based recommenders*—These match based upon the overlap of interactions
    from similar users with similar items'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于行为的推荐器*—这些推荐器基于相似用户与相似物品之间的交互重叠进行匹配。'
- en: '*Multimodal recommenders*—These perform hybrid matching based on both similar
    content-based attributes and overlapping behavior-based interactions.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多模态推荐器*—这些推荐器基于相似的内容属性和重叠的行为交互进行混合匹配。'
- en: 1.2.3 The personalization spectrum between search and recommendations
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 搜索和推荐之间的个性化范围
- en: The key difference between search engines and recommendation engines is that
    search engines are typically guided by users and match the users’ explicitly entered
    queries, whereas recommendation engines typically accept no direct user input
    and instead recommend—based upon already-known or inferred knowledge—what a user
    may want to see next.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎和推荐引擎之间的关键区别在于，搜索引擎通常由用户引导，匹配用户明确输入的查询，而推荐引擎通常不接受任何直接用户输入，而是基于已知或推断的知识推荐用户可能想要看到的内容。
- en: But these two systems are really two sides of the same coin, and treating them
    as separate systems creates a false dichotomy. The goal, in both cases, is to
    understand what a user is looking for and to deliver relevant results to meet
    that user’s information need. A broad range of personalization capabilities lies
    within the spectrum between search and recommendation systems.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 但这两个系统实际上是同一枚硬币的两面，将它们视为独立的系统会创造一个虚假的二分法。在两种情况下，目标都是理解用户在寻找什么，并交付相关结果以满足用户的信息需求。在搜索和推荐系统之间存在着广泛个性化的能力范围。
- en: 'Assuming you have both explicit queries and a user-specific personalization
    profile available when trying to find content for your end users, you can do any
    of the following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在尝试为你的最终用户寻找内容时，既有明确的查询又有用户特定的个性化资料可用，你可以做以下任何一项：
- en: '*Traditional keyword search*—Ignore the profile and only use explicit inputs.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*传统关键词搜索*—忽略个人资料，仅使用明确输入。'
- en: '*Personalized search*—Use the profile implicitly along with other explicit
    user input.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个性化搜索*—隐式使用个人资料，并结合其他明确用户输入。'
- en: '*User-guided recommendations*—Use the profile explicitly and provide the user
    with the ability to adjust it.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户引导推荐*—明确使用个人资料，并赋予用户调整它的能力。'
- en: '*Traditional recommendations*—Use the profile explicitly with no ability for
    a user to adjust it.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*传统推荐*—明确使用个人资料，但用户无法调整。'
- en: Figure 1.5 shows this personalization spectrum.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5展示了这一个性化范围。
- en: '![figure](../Images/CH01_F05_Grainger.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F05_Grainger.png)'
- en: Figure 1.5 The personalization spectrum, showing traditional keyword search
    and traditional recommendations as two ends of a larger continuum
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5个性化范围，展示了传统关键词搜索和传统推荐作为更大连续体两端。
- en: While the two ends of this personalization spectrum represent the extremes,
    they are also the two most common approaches. Unfortunately, one of the biggest
    mistakes we see in many organizations is teams built around the belief that search
    and recommendations are separate problems. This often leads to data science teams
    building complicated personalization and segmentation models only capable of recommendations
    and not search, and engineering teams building large-scale keyword matching engines
    that can’t easily take advantage of the robust models built by the recommendations
    teams.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管个性化范围的两端代表了极端，但它们也是两种最常见的方法。不幸的是，我们在许多组织中看到的一个最大的错误是围绕搜索和推荐是独立问题的信念构建团队。这通常导致数据科学团队构建复杂的个性化分段模型，这些模型只能进行推荐而不能进行搜索，以及工程团队构建大规模关键词匹配引擎，这些引擎难以利用推荐团队构建的强大模型。
- en: More often than not, the recommendation teams are staffed by data scientists
    with minimal information retrieval background, and the search teams are often
    staffed by engineers with minimal data science background. Due to Conway’s law
    (“organizations which design systems … are constrained to produce designs which
    are copies of the communication structures of these organizations”), this ultimately
    results in challenges solving problems along the personalization spectrum (particularly
    in the middle) that need the best from both teams. In this book, we focus on the
    shared techniques that make it possible for search to become smarter and for recommendations
    to become more flexible through a unified approach. AI-powered search platforms
    need to be able to continuously learn from both your users and your content and
    then enable your users to guide the results so they continue to improve.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的时候，推荐团队由具有最少信息检索背景的数据科学家组成，而搜索团队通常由具有最少数据科学背景的工程师组成。由于康威定律（“设计系统的组织……受限于产生的设计是这些组织沟通结构的复制品”），这最终导致在个性化范围（尤其是中间部分）解决问题的挑战，需要两个团队的最佳表现。在这本书中，我们专注于共享技术，通过统一方法使搜索变得更智能，使推荐变得更灵活。AI驱动的搜索平台需要能够从您的用户和内容中持续学习，并使您的用户能够引导结果，以便它们持续改进。
- en: 1.2.4 Semantic search and knowledge graphs
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 语义搜索和知识图谱
- en: We presented search and recommendations as a personalization spectrum in figure
    1.5, with personalized search and user-guided recommendations in between, but
    there’s one more dimension that is critical for building a good AI-powered search
    system—a deep understanding of the given domain. It’s not enough to match on keywords
    and to recommend content based upon how users collectively interact with documents.
    The engine must also learn as much as it can about the domain. This includes
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图1.5中将搜索和推荐作为个性化范围呈现，个性化搜索和用户引导推荐位于其中，但还有一个对于构建良好的AI驱动搜索系统至关重要的维度——对给定领域的深入理解。仅仅匹配关键词和根据用户如何集体互动文档来推荐内容是不够的。引擎还必须尽可能多地了解该领域。这包括
- en: Learning all the important domain-specific phrases, synonyms, and related terms
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习所有重要的特定领域短语、同义词和相关术语
- en: Identifying entities in documents and queries
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在文档和查询中识别实体
- en: Generating a knowledge graph that relates those entities
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个关联这些实体的知识图谱
- en: Disambiguating the many nuanced meanings represented by domain-specific terminology
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消除由特定领域术语表示的许多细微含义的歧义
- en: Being able to effectively parse, interpret, and conceptually match the nuanced
    intent of users within your domain.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够有效地解析、解释和概念上匹配您领域内用户细微的意图。
- en: Figure 1.6 shows an example of semantic parsing of a query, with the goal being
    to search for “things” (known entities) instead of “strings” (just text matching).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6展示了查询语义解析的一个示例，目标是搜索“事物”（已知实体）而不是“字符串”（仅仅是文本匹配）。
- en: '![figure](../Images/CH01_F06_Grainger.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F06_Grainger.png)'
- en: Figure 1.6 Semantic parsing of a query, demonstrating an understanding of the
    entities (“things”) represented by query terms
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.6展示了查询的语义解析，展示了理解由查询术语表示的实体（“事物”）
- en: 'To make their searches smarter, many companies spend considerable money employing
    large teams to manually create dictionaries and knowledge graphs to identify the
    relationships between entities in their users’ queries. This book focuses on a
    more scalable approach: building an AI-powered search engine that can automatically
    learn these relationships continuously. We also dive into additional techniques
    for semantic search, including dense vector search on embeddings and generative
    search using LLMs.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使他们的搜索更智能，许多公司花费大量资金雇佣大型团队手动创建词典和知识图谱，以识别用户查询中实体之间的关系。本书侧重于一种更可扩展的方法：构建一个能够自动持续学习这些关系的AI驱动搜索引擎。我们还深入探讨了语义搜索的附加技术，包括在嵌入上进行密集向量搜索和使用LLMs进行生成搜索。
- en: 1.2.5 Understanding the dimensions of user intent
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.5 理解用户意图的维度
- en: 'We’ve discussed the important roles of traditional keyword search, recommendations,
    and the personalization spectrum in between. We also discussed the need for semantic
    search to provide domain-specific understanding of your content and your users’
    queries. All of these are key pillars of a singular, larger goal: fully understanding
    user intent. Figure 1.7 demonstrates the interplay between each of these key pillars
    of user intent.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了传统关键词搜索、推荐和个性化范围之间的重要作用。我们还讨论了需要语义搜索以提供对您的内容和用户查询的特定领域理解的需求。所有这些都是实现一个更大目标的关键支柱：完全理解用户意图。图1.7展示了这些用户意图关键支柱之间的相互作用。
- en: The top-left circle in figure 1.7 represents *content understanding*—the ability
    to find the right content based on keywords, language patterns, and known attribute
    matching. The top-right circle represents *user understanding*—the ability to
    understand each user’s specific preferences and use those to return more personalized
    results. Finally, the lower circle represents *domain understanding*—the ability
    to interpret words, phrases, concepts, entities, and nuanced interpretations and
    relationships between each of these within your own domain-specific context.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7中左上角的圆圈代表*内容理解*——基于关键词、语言模式和已知属性匹配找到正确内容的能力。右上角的圆圈代表*用户理解*——理解每个用户的特定偏好，并使用这些偏好返回更个性化的结果。最后，下方的圆圈代表*领域理解*——在您自己的特定领域背景下解释单词、短语、概念、实体以及这些实体之间的细微解释和关系的能力。
- en: '![figure](../Images/CH01_F07_Grainger.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH01_F07_Grainger.png)'
- en: 'Figure 1.7 The dimensions of user intent: a combination of content understanding,
    user understanding, and domain understanding'
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.7 用户意图的维度：内容理解、用户理解和领域理解的组合
- en: A query only in the content understanding circle represents traditional *keyword
    search*, enabling matching on keywords but without using any domain or user-specific
    context. A query only in the user understanding circle would be recommendations
    from collaborative filtering, with no ability for the user to override the inputs
    and no understanding of the domain or content of the underlying documents. A query
    only in the domain understanding circle might be a structured query on known tags,
    categories, or entities, or even a browse-like interface that allowed for exploration
    of a *knowledge graph* of these domain-specific entities and their relationships,
    but without any user-specific personalization or ability to find arbitrary terms,
    phrases, and content.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在内容理解圈中的查询代表传统的*关键词搜索*，它能够基于关键词进行匹配，但不使用任何领域或用户特定的上下文。仅在用户理解圈中的查询将是基于协同过滤的推荐，用户无法覆盖输入，也不理解底层文档的领域或内容。仅在领域理解圈中的查询可能是对已知标签、类别或实体的结构化查询，甚至是一个类似浏览器的界面，允许探索这些特定领域实体的*知识图谱*及其关系，但没有任何针对用户的个性化或找到任意术语、短语和内容的能力。
- en: 'When traditional keyword search and recommendations overlap, we get *personalized
    search* or guided recommendations. When traditional keyword search and knowledge
    graphs overlap, we get *semantic search*: a smart, domain-specific search experience.
    Finally, when recommendations and knowledge graphs overlap, we get smarter *domain-aware
    recommendations* that match on crowdsourced user interactions across similar documents
    and also on a domain-specific understanding of the important attributes of those
    documents.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当传统关键词搜索和推荐重叠时，我们得到*个性化搜索*或引导推荐。当传统关键词搜索和知识图谱重叠时，我们得到*语义搜索*：一种智能的、特定领域的搜索体验。最后，当推荐和知识图谱重叠时，我们得到更智能的*领域感知推荐*，它可以在类似文档的众包用户交互以及这些文档的特定领域理解的重要属性上进行匹配。
- en: 'The holy grail for AI-powered search is to harness the intersection of all
    three categories: semantic search, personalized search, and domain-aware recommendations.
    That is to say, to truly understand user intent, we need all of the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能搜索的圣杯是利用所有三个类别的交集：语义搜索、个性化搜索和领域感知推荐。也就是说，要真正理解用户意图，我们需要以下所有内容：
- en: An expert understanding of the domain the user is searching
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对用户搜索领域的专家理解
- en: An expert understanding of the user and their preferences
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对用户及其偏好的专家理解
- en: An expert ability to match and rank arbitrary queries against any content
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够匹配和排序任意查询与任何内容的专家能力
- en: AI-powered search starts with the three pillars of user intent (content, domain,
    and user), and then employs intelligent algorithms to constantly learn and improve
    in each of these areas. This learning includes techniques like automatically learning
    ranking criteria, automatically learning user preferences, and automatically learning
    knowledge graphs and language models of the represented domain. At the end of
    the day, a balanced combination of these three approaches provides the key to
    optimal understanding of users and their query intent, which is the end goal of
    our AI-powered search system.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能搜索始于用户意图（内容、领域和用户）的三个支柱，然后采用智能算法在这些领域不断学习和改进。这种学习包括自动学习排名标准、自动学习用户偏好以及自动学习代表领域的知识图谱和语言模型等技术。最终，这三个方法的平衡组合是理解用户及其查询意图的关键，这也是我们人工智能搜索系统的最终目标。
- en: 1.3 How does AI-powered search work?
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 人工智能搜索是如何工作的？
- en: We laid out our end goal of matching user intent through content understanding,
    user understanding, and domain understanding. With that background established,
    let’s wrap up this chapter with an overview of the actual components needed to
    deliver an AI-powered search platform. Search intelligence typically matures along
    a predictable progression iteratively over time, as shown in figure 1.8\. Basic
    keyword search is a typical starting point for organizations. Once in production,
    they realize their search relevancy needs to be improved, and they start manually
    tuning field weights, boosts, text and language analysis, and introducing additional
    features and functions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们明确了我们的最终目标，即通过内容理解、用户理解和领域理解来匹配用户意图。在建立这个背景之后，让我们以对实际所需组件的概述来结束本章，这些组件用于提供人工智能搜索平台。搜索智能通常随着时间的推移，以可预测的迭代方式成熟，如图1.8所示。基本关键词搜索是组织的一个典型起点。一旦投入生产，他们意识到他们的搜索相关性需要改进，于是开始手动调整字段权重、提升、文本和语言分析，并引入额外的功能和功能。
- en: '![figure](../Images/CH01_F08_Grainger.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F08_Grainger.png)'
- en: Figure 1.8 The typical search intelligence progression, from basic keyword search
    to a full self-learning search platform
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.8 典型的搜索智能进步，从基本关键词搜索到完整的自我学习搜索平台
- en: Eventually, they realize they need to inject domain understanding into their
    search capabilities, at which point organizations begin to invest in synonym lists,
    taxonomies, lists of known entities, and domain-specific business rules. While
    these all help, organizations eventually also discover that relevant search is
    very much dependent upon successfully interpreting user queries and understanding
    user intent, so they begin investing in techniques for query classification, semantic
    query parsing, knowledge graphs, personalization, and other attempts to correctly
    interpret user queries.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，他们意识到他们需要将领域理解注入到他们的搜索能力中，此时组织开始投资于同义词列表、分类法、已知实体列表以及特定领域的业务规则。虽然这些都很有帮助，但组织最终也发现，相关的搜索在很大程度上取决于成功解释用户查询和理解用户意图，因此他们开始投资于查询分类、语义查询解析、知识图谱、个性化以及其他正确解释用户查询的尝试。
- en: Because these tasks yield improvements, this success often results in the creation
    of large teams investing significant time manually tuning lists and parameters,
    and eventually organizations may realize that it is possible (and more expedient)
    to automate as much of that process as possible through learning from user signals,
    user testing (A/B testing, offline relevancy simulations, and active learning),
    and building of machine-learned relevancy models. The end goal is to completely
    automate each of these steps along the search intelligence progression and enable
    the engine to be self-learning.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些任务会产生改进，这种成功通常会导致创建大型团队投入大量时间手动调整列表和参数，最终组织可能会意识到，通过从用户信号、用户测试（A/B测试、离线相关性模拟和主动学习）以及构建机器学习相关性模型中学习，可以尽可能自动化这一过程。最终目标是完全自动化搜索智能进步过程中的每个步骤，并使引擎能够自我学习。
- en: 1.3.1 The core search foundation
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 核心搜索基础
- en: The first step in building a search platform is almost always to get traditional
    keyword search working (the “content understanding” part in figure 1.7). Teams
    often spend years tuning and improving this step, and a whole discipline called
    *relevance engineering* has arisen that has historically focused significant effort
    into understanding content; improving content for search; adjusting boosts, query
    parameters, and query functions; and otherwise trying to maximize the relevance
    of the traditional search experience. For a deep dive into this world of relevance
    engineering and tuning traditional keyword search relevance, we recommend the
    book *Relevant Search* by Doug Turnbull and John Berryman (Manning, 2016).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 构建搜索平台的第一步几乎总是要使传统的关键词搜索工作（图1.7中的“内容理解”部分）。团队通常会花费数年时间调整和改进这一步骤，一个名为*相关性工程*的整个学科也因此产生，它历史上一直致力于理解内容；改进搜索中的内容；调整提升、查询参数和查询函数；以及其他尝试最大化传统搜索体验的相关性。对于深入了解这个相关性工程和调整传统关键词搜索相关性的世界，我们推荐道格·特恩布尔和约翰·贝里曼（Manning，2016年）所著的《相关搜索》一书。
- en: As relevance engineers become more sophisticated, their work often moves into
    the realms of user understanding and recommendations, as well as into domain-understanding
    and semantic search. The rise of large language models has made it easy in recent
    years to implement out-of-the-box semantic search, but getting to the next level
    in optimizing the relevance and matching requires much more sophisticated approaches,
    as you’ll learn throughout this book. Our focus in *AI-Powered Search* will be
    on automating the process of learning and optimizing search relevance so it operates
    as a continuous feedback loop. We essentially want to automate much of the relevance
    engineer’s job, relying on algorithms, where possible, to continually learn optimal
    matching and ranking strategies.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 随着相关性工程师变得更加复杂，他们的工作往往进入用户理解、推荐以及领域理解和语义搜索的领域。近年来，大型语言模型的出现使得实现即插即用的语义搜索变得容易，但要达到优化相关性和匹配的下一级水平，需要更加复杂的方法，正如你将在本书中学到的。在《人工智能驱动的搜索》中，我们的重点是自动化学习和优化搜索相关性的过程，使其作为一个连续的反馈循环运行。我们本质上希望自动化相关性工程师的大部分工作，尽可能依赖算法来不断地学习最优匹配和排名策略。
- en: So, what characteristics differentiate a well-tuned search engine from an AI-powered
    search engine? A well-tuned search engine is the foundation upon which AI-powered
    search is built, but AI-powered search goes far beyond that, continuously learning
    and improving through reflected intelligence. *Reflected intelligence* is the
    idea of using continual feedback loops of user input, content updates, and user
    interactions with content to continually learn and improve the quality of your
    search application.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么特征区分了一个调校良好的搜索引擎和一个人工智能驱动的搜索引擎？一个调校良好的搜索引擎是人工智能驱动的搜索的基础，但人工智能驱动的搜索远远超出了这一点，它通过反映智能不断地学习和改进。*反映智能*的概念是利用用户输入、内容更新和用户与内容的交互的持续反馈循环，以不断地学习和改进搜索应用的质量。
- en: 1.3.2 Reflected intelligence through feedback loops
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 通过反馈循环反映的智能
- en: 'Feedback loops are critical to building an AI-powered search solution. Imagine
    if your entire education (elementary school through to your highest degree) had
    consisted of nothing more than you reading textbooks: no teachers to ask questions,
    no exams to test your knowledge and provide feedback, and no classmates or others
    with which to interact, study, or collaborate. You would have probably hit endless
    walls where you were unable to fully grasp certain concepts or even understand
    what you were reading, and you would have understood many ideas incorrectly and
    never had the opportunity to realize this or to adjust your assumptions.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环对于构建人工智能驱动的搜索解决方案至关重要。想象一下，如果你的整个教育（从小学到最高学位）都只是阅读教科书：没有老师提问，没有考试来测试你的知识并提供反馈，也没有同学或其他人与你互动、学习或合作。你可能会在无法完全理解某些概念甚至不理解你所阅读的内容的地方遇到无尽的障碍，你可能会错误地理解许多想法，并且从未有机会意识到这一点或调整你的假设。
- en: Search engines often operate this same way. Smart engineers push data to the
    search engine and tune certain features and feature weights, but the engine just
    reads those configurations and acts upon them the same way every time for repeated
    user queries. Search engines are the perfect kind of system for interactive learning,
    however, when we introduce feedback loops.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎通常以这种方式运行。聪明的工程师将数据推送到搜索引擎，并调整某些特性和特征权重，但引擎只是读取这些配置并以相同的方式对每次重复的用户查询做出反应。然而，当我们引入反馈循环时，搜索引擎是交互式学习的完美系统。
- en: Figure 1.9 shows the typical flow of information through a search feedback loop.
    First, a user issues a query. This query executes a search, which returns results,
    such as a specific answer, a list of answers, or a list of links to pages, to
    an end user. Once presented with the list, the user then takes one or more actions.
    These actions usually start with clicks on documents, but those clicks can ultimately
    lead to adding an item to a shopping cart and purchasing it (e-commerce), giving
    the item a thumbs up or thumbs down (media consumption website), liking or commenting
    on the result (social media website), or any number of other context-specific
    actions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9显示了搜索反馈循环中信息流动的典型流程。首先，用户提出一个查询。这个查询执行搜索，返回结果，如特定答案、答案列表或指向页面的链接列表，给最终用户。一旦呈现列表，用户就会采取一个或多个行动。这些行动通常从点击文档开始，但这些点击最终可能导致将商品添加到购物车并购买（电子商务）、对商品点赞或踩（媒体消费网站）、喜欢或评论结果（社交媒体网站），或任何其他上下文特定的行动。
- en: '![figure](../Images/CH01_F09_Grainger.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F09_Grainger.png)'
- en: Figure 1.9 Reflected intelligence through feedback loops
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.9 反馈循环中的反射智能
- en: These actions can then be used to generate an improved relevance ranking model
    for future searches. Your search application can automatically adjust the ranking
    of future search results, delivering an improved search experience for the next
    user’s search.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行动可以用来生成改进的未来搜索的相关性排名模型。您的搜索应用可以自动调整未来搜索结果的排名，为下一个用户的搜索提供改进的搜索体验。
- en: 1.3.3 Signals boosting, collaborative filtering, and learning to rank
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 信号增强、协同过滤和排序学习
- en: The searches, clicks, likes, add to carts, purchases, comments, and other interactions
    with your search application are critical data that you need to capture. We collectively
    refer to these data points as *signals*. Signals provide a constant stream of
    feedback to your search application, recording every meaningful interaction with
    your end users. These digital moments can then be used by machine learning algorithms
    to generate models to power user understanding, content understanding, and domain
    understanding.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您的搜索应用中的搜索、点击、点赞、添加到购物车、购买、评论以及其他与您的搜索应用的互动都是您需要捕获的关键数据。我们把这些数据点统称为*信号*。信号为您的搜索应用提供持续的反馈流，记录与最终用户每次有意义的互动。这些数字时刻可以由机器学习算法用来生成模型，以驱动用户理解、内容理解和领域理解。
- en: Figure 1.10 shows the data flow for the collection and processing of signals
    in a typical AI-powered search application. You can see signals being collected
    for each search, as well as resulting clicks and purchases. Unique signals can
    also be recorded for any other kind of user interaction (add-to-cart, facet click,
    bookmark, hover, or even page dwell time).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10显示了典型AI驱动搜索应用中信号收集和处理的流程。你可以看到每个搜索都会收集信号，以及产生的点击和购买。还可以记录任何其他类型的用户交互的独有信号（如添加到购物车、分类点击、书签、悬停或甚至页面停留时间）。
- en: '![figure](../Images/CH01_F10_Grainger.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F10_Grainger.png)'
- en: Figure 1.10 Signal collection and processing data flow
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.10 信号收集和处理数据流
- en: Signals are one of the two sources of data that power the intelligence engine
    of an AI-powered search application, with the other being content. Many AI-powered
    search algorithms incorporate signals feedback loops to build reflected intelligence
    models. Some of these key types of reflected intelligence algorithms include
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 信号是驱动AI驱动搜索应用智能引擎的两个数据源之一，另一个是内容。许多AI驱动搜索算法结合信号反馈循环来构建反射智能模型。这些关键类型的反射智能算法包括
- en: Popularized relevance—*Signals-boosting* algorithms create models that use aggregated
    signals to boost the rankings of the most important documents for your most popular
    queries.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行相关性——*信号增强*算法创建使用聚合信号来提升您最常用查询的最重要文档排名的模型。
- en: Personalized relevance—*Collaborative filtering* algorithms create models using
    matrix factorization or similar techniques that use signals to generate recommendations
    and user profiles to personalize search results for each user.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化相关性——*协同过滤*算法使用矩阵分解或类似技术创建模型，利用信号生成推荐和用户配置文件，以个性化每个用户的搜索结果。
- en: Generalized relevance—*Learning to rank* algorithms train *ranking classifiers*
    to perform machine-learned ranking based on relevance judgments generated from
    user-signals-based click models. This process learns a set of features and ranking
    weights that can be applied generally to all queries—even ones that have not been
    previously seen.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义相关性——*学习排名*算法训练*排名分类器*，根据基于用户点击模型的用户信号生成的相关性判断进行机器学习排名。这个过程学习到一组特征和排名权重，可以普遍应用于所有查询——即使是之前未见过的查询。
- en: These algorithms enable your search application to learn from user interactions
    and to automatically adjust rankings for future search results, delivering an
    improved search experience for the next users’ searches.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法使您的搜索应用能够从用户交互中学习，并自动调整未来搜索结果的排名，为下一批用户的搜索提供改进的搜索体验。
- en: 1.3.4 Content and domain intelligence
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.4 内容和领域智能
- en: While signals provide a constant stream of usage and feedback data to your search
    application, your content is also a rich source of information that can be incorporated
    in your feedback loops. For example, if someone searches for a particular keyword,
    the other keywords and top categories in the documents returned serve as valuable
    data points. Those data points can be used to tag or categorize the query and
    can be shown to other end users (as facets, for example), leading to further interactions
    that generate signals from which the engine can learn.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然信号为您的搜索应用提供了一连串的使用和反馈数据，但您的文档也是一个丰富的信息来源，可以纳入反馈循环中。例如，如果有人搜索特定的关键词，返回的文档中的其他关键词和顶级类别可以作为有价值的数据点。这些数据点可以用来标记或分类查询，并可以展示给其他最终用户（例如，作为维度），从而产生进一步的交互，这些交互会生成信号，搜索引擎可以从中学到东西。
- en: The content of your documents forms a representative textual model of your domain.
    Entities, domain-specific terminology, and the sentences contained within your
    documents serve as a rich, semantic graph. That graph can be utilized to drive
    powerful conceptual and semantic search that better understands your domain. We’ll
    dive more deeply into understanding your content in chapter 2, and into semantic
    search capabilities using this rich semantic knowledge graph (SKG) in chapter
    5\.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您文档的内容构成了您领域的一个代表性的文本模型。实体、领域特定术语以及您文档中包含的句子构成了一个丰富、语义的图。该图可以被用来驱动强大的概念和语义搜索，更好地理解您的领域。我们将在第2章中更深入地了解您的内容，在第5章中深入探讨使用这个丰富的语义知识图谱（SKG）的语义搜索能力。
- en: In recent years, LLMs have revolutionized how search engines can interpret queries
    and responses. LLMs are deep neural networks trained on massive amounts of text
    data. They can recognize, translate, summarize, predict, and generate new data
    based on incoming prompts and any additional context provided. Often, LLMs are
    trained on text, receive a prompt as text, and return a response as text, though
    similar multimodal models can also be trained on images, audio, other data, or
    all the above. LLMs often contain billions of parameters within the neural network,
    and this number is likely to continue to grow in the future so long as model performance
    continues to improve with more parameters.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）彻底改变了搜索引擎如何解释查询和响应的方式。LLMs 是在大量文本数据上训练的深度神经网络。它们可以根据接收到的提示和任何额外的上下文识别、翻译、总结、预测和生成新数据。通常，LLMs
    在文本上训练，以文本形式接收提示，并以文本形式返回响应，尽管类似的多元模型也可以在图像、音频、其他数据或所有上述数据上训练。LLMs 在神经网络中通常包含数十亿个参数，并且只要模型性能随着参数的增加而持续提高，这个数字很可能会继续增长。
- en: Today’s most successful LLMs are based on the Transformer architecture, introduced
    by Google researchers in 2017, which applies the concept of “attention” to language
    learning (“Attention is All You Need”, Ashish Vaswani et al.). Massive amounts
    of textual data are fed into a neural network, and a representation of the words
    and their relationships within each context are modeled using unsupervised learning.
    Once the model is built, it’s able to interpret an incoming string of text, a
    *prompt*, as a context and to encode the context into embeddings, which are numerical
    vector representations of the meaning of the prompt. In addition to being able
    to encode prompts into embeddings, Transformers also contain a decoder layer,
    which can convert embeddings back into text. Transformers can be used to solve
    many kinds of problems, from similarity search on embeddings (text search, image
    search, etc.), to question answering, to classification, to summarization of content,
    and even to generation of new content (writing, code, poems, images, etc.).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 今天最成功的语言模型是基于2017年由谷歌研究人员提出的变换器架构，该架构将“注意力”的概念应用于语言学习（“Attention is All You
    Need”，Ashish Vaswani等人）。大量的文本数据被输入到神经网络中，使用无监督学习对单词及其在每个上下文中的关系进行建模。一旦模型构建完成，它就能够将输入的文本字符串，即**提示**，解释为上下文，并将上下文编码到嵌入中，嵌入是提示意义的数值向量表示。除了能够将提示编码到嵌入中，变换器还包含一个解码层，可以将嵌入转换回文本。变换器可以用于解决许多类型的问题，从嵌入上的相似性搜索（文本搜索、图像搜索等），到问答，到分类，到内容摘要，甚至到生成新内容（写作、代码、诗歌、图像等）。
- en: 'Transformers are context-sensitive. An LLM tuned for question answering might
    respond to the prompt “What is the difference between a capital and capitol?”
    with the answer “A capital is a city or town that serves as the seat of government
    for a state or country. A capitol is a building in which a state legislature meets.”
    However, the same LLM may respond to the question “What is the difference between
    a capital and lowercase word?” with the following context-based answer: “The difference
    between a capital and lowercase word is that a capital letter is used at the beginning
    of a sentence or proper nouns, while a lowercase letter is used for all other
    letters in a word.”'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器是上下文敏感的。一个针对问答任务调整过的语言模型可能会对提示“首都和州首府的区别是什么？”的回答是：“首都是一个城市或城镇，作为州或国家的政府所在地。州首府是一个州立法机构所在的建筑。”然而，同一个语言模型在回答“大写字母和小写字母的区别是什么？”这个问题时，可能会给出以下基于上下文的回答：“大写字母和小写字母的区别在于，大写字母用于句子的开头或专有名词，而小写字母用于单词中的其他字母。”
- en: Many LLMs are open sourced, but for optimal output quality, LLMs benefit from
    being fine-tuned for the task at hand with domain-specific content and prompts.
    Fine-tuning is the act of taking a pretrained model, which already has a strong
    general understanding of language and general concepts, and “teaching” it about
    new content and tasks. The original pretrained models are often referred to as
    *foundation models*, as they form the foundation upon which the domain-specific
    fine-tuning will be applied. The process of fine-tuning usually takes a small
    fraction of the time necessary to train the original LLM. Some LLMs have been
    trained on so much data and such a wide variety of data (such as a comprehensive
    web crawl of the internet) that they can perform quite well without retraining,
    but retraining for the task at hand almost always improves performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 许多语言模型是开源的，但为了获得最佳输出质量，语言模型需要针对特定任务进行微调，使用特定领域的内容和提示。微调是指使用已经对语言和一般概念有强大理解能力的预训练模型，并“教授”它关于新内容和任务的知识。原始预训练模型通常被称为**基础模型**，因为它们构成了特定领域微调的基础。微调的过程通常只需要训练原始语言模型所需时间的一小部分。一些语言模型在大量数据和广泛多样的数据（如互联网的全面爬取）上进行了训练，因此它们在无需重新训练的情况下可以表现得相当好，但针对特定任务进行重新训练几乎总是可以提高性能。
- en: 1.3.5 Generative AI and retrieval augmented generation
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.5 生成式AI和检索增强生成
- en: Generative AI is accelerating at a rapid pace, and search engines both benefit
    from it and serve as a key component of generative AI systems. LLMs (and other
    foundation models) serve as reasoning engines, having enough knowledge of the
    world to interpret language and generally reason about most concepts, but without
    the ability to reliably recall factual information without the risk of hallucinating
    (making up false information).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI正在以极快的速度发展，搜索引擎既从中受益，又作为生成式AI系统的一个关键组件。LLMs（以及其他基础模型）作为推理引擎，拥有足够的世界知识来解释语言，并且通常可以就大多数概念进行推理，但它们没有可靠回忆事实信息的能力，而不会出现幻觉（编造虚假信息）的风险。
- en: As a result, search engines are used in retrieval augmented generation (RAG)
    pipelines as a knowledge source for LLMs, allowing relevant context to be retrieved
    and passed to the LLM to ensure it has up-to-date and accurate data from which
    to answer. This entire book is effectively about using AI to optimize the “retrieval”
    part of RAG, and we’ll cover the “generative” part in chapter 15\.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，搜索引擎在检索增强生成（RAG）管道中用作LLMs的知识源，允许检索相关上下文并将其传递给LLMs，以确保它有最新和准确的数据来回答问题。整本书实际上都是关于使用AI来优化RAG中的“检索”部分，我们将在第15章中介绍“生成”部分。
- en: While RAG makes search engines a critical component of generative AI systems,
    LLMs also serve as critical components of search engines. LLMs can be used to
    interpret queries, generate embeddings for vector search, generate summaries of
    search results, and even generate answers to questions directly from search results.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 RAG 使搜索引擎成为生成式AI系统的一个关键组件，但LLMs 也作为搜索引擎的关键组件。LLMs 可以用来解释查询，为向量搜索生成嵌入，生成搜索结果的摘要，甚至可以直接从搜索结果中生成问题的答案。
- en: The transition from traditional information retrieval to these new *generative
    search* capabilities is shown in figure 1.11\. For decades, traditional search
    has returned a list of search results (“ten blue links”), showing the top-ranked
    documents most relevant for a query. For queries on entities and well-known topics,
    search engines often show precalculated info boxes with summary information or
    show predetermined answers to known questions. Search engines often also extract
    words, sentences, or paragraph snippets out of search results to answer questions
    instead of forcing users to open and read the search results to find the answer.
    This process is known as *extractive question answering*, and it is a more targeted
    form of search, since it additionally searches and ranks answers found within
    documents.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从传统的信息检索过渡到这些新的*生成式搜索*能力在图1.11中展示。几十年来，传统的搜索返回一系列搜索结果（“十个蓝色链接”），显示与查询最相关的顶级文档。对于实体和知名主题的查询，搜索引擎通常会显示预先计算的包含总结信息的信息框或显示对已知问题的预定答案。搜索引擎通常还会从搜索结果中提取单词、句子或段落片段来回答问题，而不是强迫用户打开和阅读搜索结果来找到答案。这个过程被称为*抽取式问答*，它是一种更具有针对性的搜索形式，因为它还会在文档中搜索和排名找到的答案。
- en: '![figure](../Images/CH01_F11_Grainger.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F11_Grainger.png)'
- en: Figure 1.11 The transition from traditional information retrieval to generative
    search
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.11 从传统信息检索到生成式搜索的过渡
- en: However, there’s a fine line between extracting answers from search results
    and synthesizing new content to return in the results, and this is where we transition
    into the realm of generative search. *Results summarization* is the process of
    rewriting search results into a more concise and readable format, often combining
    information from multiple sources and even providing citations for the sources
    within the summarized response. *Abstractive question answering* is the process
    of generating answers to questions by synthesizing information from one or more
    ranked search results into an answer to a user’s question. The difference between
    extractive question answering and abstractive question answering is that extractive
    question answering finds relevant content within documents to return as answers
    (“extracting it”), whereas abstractive question answering writes a synthesized
    response by interpreting results and generating an answer that may look different
    than what’s written in any of the documents. *New content generation* is also
    possible within a generative search experience, such as responding to queries
    with creative new prose, code, poems, images, or other content, based on the keywords
    or prompts being submitted by users.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从搜索结果中提取答案和综合新内容以返回结果之间存在一条细线，这就是我们过渡到生成式搜索领域的时刻。*结果摘要*是将搜索结果重写为更简洁、更易读的格式的过程，通常结合来自多个来源的信息，甚至在摘要响应中为来源提供引用。*抽象式问答*是通过综合一个或多个排名搜索结果的信息来生成问题的答案的过程。与提取式问答相比，抽象式问答是从文档中找到相关内容作为答案（“提取它”），而抽象式问答通过解释结果并生成一个可能不同于任何文档中写的内容的答案来编写综合响应。在生成式搜索体验中，*新内容生成*也是可能的，例如，根据用户提交的关键词或提示，以创意新散文、代码、诗歌、图像或其他内容来响应查询。
- en: In summary, generative AI and AI-powered search are tightly intertwined. Generative
    AI is a critical component of “AI-powered search” (powering answer generation
    and results summarization), and AI-powered search is a critical component of “search-powered
    AI” (RAG). Both heavily utilize LLMs and other foundation models, and both are
    critical components of intelligent and accurate AI systems.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，生成式AI和AI驱动的搜索紧密相连。生成式AI是“AI驱动的搜索”（提供答案生成和结果摘要）的一个关键组件，而AI驱动的搜索是“搜索驱动的AI”（RAG）的一个关键组件。两者都大量使用LLMs和其他基础模型，并且都是智能和准确AI系统的关键组件。
- en: 1.3.6 Curated vs. black-box AI
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.6 精选AI与黑盒AI
- en: Like LLMs, many modern AI techniques rely heavily on deep learning based on
    artificial neural networks. Unfortunately, it is often challenging for a human
    to understand the specific factors that go into any particular prediction or output
    from a deep learning model due to the internal complexity of the learned model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于LLMs，许多现代AI技术严重依赖于基于人工神经网络的深度学习。不幸的是，由于学习模型的内部复杂性，人类往往难以理解任何特定预测或深度学习模型输出的具体因素。
- en: This sometimes results in a “black-box AI” system, where the results may be
    correct or impressive, but they are not easy to debug or correct when the model
    makes an incorrect judgment. An entire field of *explainable AI* (sometimes called
    *interpretable AI* or *transparent AI*) has arisen out of a need to be able to
    understand, curate, and trust these models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这有时会导致一个“黑盒AI”系统，其中结果可能是正确或令人印象深刻的，但当模型做出错误判断时，它们并不容易调试或纠正。为了能够理解、整理和信任这些模型，一个名为*可解释AI*（有时称为*可解释AI*或*透明AI*）的整个领域应运而生。
- en: In this book, we’ll cover deep learning approaches to search, such as dense
    vector search on embeddings, question answering, synthetic training data generation,
    and results summarization using LLMs. We’ll mostly focus our efforts, however,
    on creating intelligence that can be expressed in human terms and then corrected
    and augmented by human intelligence. You can think of this as “AI-assisted human
    curation”, or as “human-assisted AI”, but either way, the overriding philosophy
    of this book is to use AI to automate the process of search intelligence while
    keeping the human in the loop with the ability to take control and augment or
    override the system.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将介绍搜索的深度学习方法，例如在嵌入上进行密集向量搜索、问答、使用大型语言模型生成合成训练数据以及使用LLMs进行结果摘要。然而，我们主要将精力集中在创建可以用人类术语表达并随后由人类智能进行纠正和增强的智能。你可以将其视为“AI辅助的人类编辑”，或者“人类辅助的AI”，但无论如何，本书的总体哲学是使用AI自动化搜索智能的过程，同时保持人类在循环中，具有控制能力，并能够增强或覆盖系统。
- en: As a learning exercise, this approach also leads to a deeper, intuitive understanding
    of how search ranking and relevance work, and how you can integrate many different
    AI-driven approaches without forfeiting control of the system.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为学习练习，这种方法也导致了对搜索排名和相关性工作原理的更深入、直观的理解，以及如何在不放弃系统控制权的情况下集成许多不同的AI驱动方法。
- en: 1.3.7 Architecture for an AI-powered search engine
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.7 AI驱动搜索引擎的架构
- en: 'The architecture for an AI-powered search engine often requires numerous building
    blocks to be assembled to form a smart end-to-end system. You start with a core
    search engine like Apache Solr, OpenSearch, or one of the other search engines
    or vector databases identified in appendix B. You then feed your searchable content
    into the engine, running various transformations to make it more useful. These
    index-time transformations might include changes like these:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: AI驱动搜索引擎的架构通常需要组装许多构建块以形成一个智能端到端系统。你从一个核心搜索引擎开始，如Apache Solr、OpenSearch或附录B中确定的其它搜索引擎或向量数据库。然后，将你的可搜索内容输入到引擎中，运行各种转换使其更有用。这些索引时间转换可能包括以下变化：
- en: Interpreting the meaning of your documents into embeddings using LLMs
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用大型语言模型将你文档的意义转换为嵌入
- en: Classifying the document, adding the classification as a field
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对文档进行分类，将分类作为字段添加
- en: Normalizing field values
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化字段值
- en: Extracting entities from text, adding entities in separate fields
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中提取实体，将实体添加到单独的字段中
- en: Clustering content, adding clusters as a field
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对内容进行聚类，将聚类作为字段添加
- en: Detecting and annotating phrases
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别和注释短语
- en: Pulling in additional data from a knowledge graph, external API, or other data
    source
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从知识图谱、外部API或其他数据源中拉取额外数据
- en: Performing part of speech (POS) detection and other natural language processing
    steps
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行词性（POS）检测和其他自然语言处理步骤
- en: Extracting facts (such as RDF triples)
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取事实（如RDF三元组）
- en: Applying other machine learning models or ETL rules to enrich the document
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用其他机器学习模型或ETL规则来丰富文档
- en: Once the data is in the engine, your goal is to make it available for searching.
    This requires query pipelines, which can interpret incoming queries; identify
    concepts, phrases, and entities; correct misspellings; expand the query to include
    related terms, synonyms, concepts, or embedding representations; and then rewrite
    the query so your core engine can find the most relevant results. Individual search
    documents may then be returned to the end user, summaries of results may be generated
    from language models, or answers may be explicitly extracted from the results.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据进入引擎，你的目标就是使其可供搜索。这需要查询管道，它可以解析传入的查询；识别概念、短语和实体；纠正拼写错误；扩展查询以包括相关术语、同义词、概念或嵌入表示；然后重写查询，以便你的核心引擎可以找到最相关的结果。然后，可以返回单个搜索文档给最终用户，也可以从语言模型生成结果摘要，或者明确地从结果中提取答案。
- en: Much of this query intelligence requires a robust understanding of your domain,
    however. This requires running batch jobs on your content and user signals to
    learn patterns and derive domain-specific intelligence. What are the most common
    misspellings from your users, and what do they choose as the correct spelling
    among multiple candidates? When a user searches for specific queries, which documents
    should be boosted as the most popular? For unknown queries, what is the ideal
    ranking among all the attributes or features available for matching?
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多查询智能需要你对领域有稳健的理解。这需要在你内容和用户信号上运行批量作业，以学习模式和推导出特定领域的智能。用户最常见的拼写错误是什么，他们在多个候选者中选择哪个作为正确的拼写？当用户搜索特定查询时，哪些文档应该被提升为最流行的？对于未知查询，所有可用于匹配的属性或特征的理想排名是什么？
- en: We need access to most of these answers at query time (either precomputed or
    quickly computable) because we expect queries to return within milliseconds to
    seconds. This requires a job processing framework (we use Apache Spark in this
    book) and a workflow scheduling mechanism to keep the jobs running in sequence.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在查询时（无论是预先计算的还是快速可计算的）获取这些答案，因为我们期望查询在毫秒到秒内返回。这需要一个作业处理框架（本书中使用Apache Spark）和一个工作流程调度机制，以保持作业按顺序运行。
- en: You’ll also need a mechanism for collecting the constant stream of incoming
    user signals (capturing them on the frontend application and then storing them
    in your search engine or other backend datastore).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要一个机制来收集不断流入的用户信号（在前端应用程序中捕获它们，然后存储在您的搜索引擎或其他后端数据存储中）。
- en: The signals will then be used to generate all kinds of models—from signals boosting
    models that boost the most popular items for top queries, to learning to rank
    models that apply a generalizable ranking function to all queries, to personalization
    models that output user-specific recommendations and personalization preferences
    for each user or segment of users.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信号将被用来生成各种模型——从增强最流行项目的信号增强模型，到学习排名模型，该模型将可推广的排名函数应用于所有查询，再到输出针对每个用户或用户群体的特定推荐和个性化偏好的个性化模型。
- en: 'AI-powered search is way more than just using the latest LLM to interpret queries.
    It’s about engineering an end-to-end system for continuous learning. Ultimately,
    you’ll end up with a system that receives constant streams of document changes
    and user signals, continually processes those streams to improve models, and then
    constantly adjusts future search results and measures the effect of changes in
    order to deliver more intelligent results. That is the key behind AI-powered search:
    implementing a process of continual learning and improvement based upon real user
    interactions, updating content patterns, and evolving models to optimally understand
    current user intent and to deliver an ever-improving search experience.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 由人工智能驱动的搜索远不止是使用最新的LLM来解释查询。它关乎构建一个端到端系统以实现持续学习。最终，你将拥有一个系统，该系统接收不断变化的文档流和用户信号，持续处理这些流以改进模型，然后不断调整未来的搜索结果并衡量变化的影响，以便提供更智能的结果。这就是人工智能驱动搜索的关键：基于真实用户交互、更新内容模式和演变模型，以最佳方式理解当前用户意图并提供不断改进的搜索体验。
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Expectations for search sophistication are evolving with the rise of LLMs, with
    end users expecting search to now be domain-aware, contextual and personalized,
    conversational, multimodal, intelligent, and assistive.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）的兴起，对搜索复杂度的期望正在演变，最终用户现在期望搜索能够具备领域感知、情境化、个性化、对话式、多模态、智能和辅助功能。
- en: Search and recommendations are the two extreme ends of a continuous personalization
    spectrum within information retrieval, and it’s important to consider the opportunities
    in between to optimize relevance.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索和推荐是信息检索中个性化连续光谱的两个极端，考虑两者之间的机会以优化相关性非常重要。
- en: Correctly interpreting user intent requires simultaneous understanding of your
    content, your user and their preferences, and the knowledge domain in which your
    platform operates.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确理解用户意图需要同时理解你的内容、你的用户及其偏好，以及你的平台运营的知识领域。
- en: Optimal search relevance lies at the intersection of personalized search (traditional
    keyword search plus collaborative recommendations), semantic search (traditional
    keyword search plus knowledge graphs), and domain-aware recommendations (collaborative
    recommendations plus knowledge graphs).
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳搜索相关性位于个性化搜索（传统关键词搜索加上协同推荐）、语义搜索（传统关键词搜索加上知识图谱）和领域感知推荐（协同推荐加上知识图谱）的交汇处。
- en: 'AI-powered search operates on and learns from two key types of data: content
    and user signals.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能驱动的搜索在两种关键类型的数据上运行并从中学习：内容和用户信号。
- en: Search and generative AI go hand in hand. Generative search capabilities, such
    as RAG, are a critical component of modern generative AI systems (to prevent hallucinations);
    and generative AI capabilities, such as results summarization, are critical components
    of modern search engines (to return better answers).
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索和生成式人工智能相辅相成。生成式搜索能力，如RAG，是现代生成式人工智能系统（防止幻觉）的关键组成部分；而生成式人工智能能力，如结果摘要，是现代搜索引擎（提供更好的答案）的关键组成部分。
- en: Reflected intelligence—the use of feedback loops to continually collect signals,
    tune results, and measure improvements—is the engine that enables AI-powered search
    to learn and constantly improve.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反射式智能——利用反馈循环持续收集信号、调整结果和衡量改进——是使人工智能驱动的搜索能够学习和不断改进的引擎。
