- en: 12 Improving training with metrics and augmentation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 通过指标和增强改进训练
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Defining and computing precision, recall, and true/false positives/negatives
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义和计算精确率、召回率以及真/假阳性/阴性
- en: Using the F1 score versus other quality metrics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用F1分数与其他质量指标
- en: Balancing and augmenting data to reduce overfitting
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡和增强数据以减少过拟合
- en: Using TensorBoard to graph quality metrics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorBoard绘制质量指标图
- en: The close of the last chapter left us in a predicament. While we were able to
    get the mechanics of our deep learning project in place, none of the results were
    actually useful; the network simply classified everything as non-nodule! To make
    matters worse, the results seemed great on the surface, since we were looking
    at the overall percent of the training and validation sets that were classified
    correctly. With our data heavily skewed toward negative samples, blindly calling
    everything negative is a quick and easy way for our model to score well. Too bad
    doing so makes the model basically useless!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章的结束让我们陷入了困境。虽然我们能够将深度学习项目的机制放置好，但实际上没有任何结果是有用的；网络只是将一切都分类为非结节！更糟糕的是，结果表面看起来很好，因为我们正在查看训练和验证集中被正确分类的整体百分比。由于我们的数据严重倾向于负样本，盲目地将一切都视为负面是我们的模型快速得分的一种简单而快速的方法。太糟糕了，这样做基本上使模型无用！
- en: That means we’re still focused on the same part of figure 12.1 as we were in
    chapter 11\. But now we’re working on getting our classification model working
    *well* instead of *at all*. This chapter is all about how to measure, quantify,
    express, and then improve on how well our model is doing its job.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们仍然专注于与第11章相同的图12.1的同一部分。但现在我们正在努力使我们的分类模型工作*良好*而不是*只是工作*。本章重点讨论如何衡量、量化、表达，然后改进我们的模型执行工作的能力。
- en: '![](../Images/CH12_F01_Stevens2_GS.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F01_Stevens2_GS.png)'
- en: 'Figure 12.1 Our end-to-end lung cancer detection project, with a focus on this
    chapter’s topic: step 4, classification'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 我们的端到端肺癌检测项目，重点放在本章的主题上：第4步，分类
- en: 12.1 High-level plan for improvement
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 改进的高层计划
- en: While a bit abstract, figure 12.2 shows us how we are going to approach that
    broad set of topics.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有点抽象，图12.2向我们展示了我们将如何处理那些广泛的主题。
- en: 'Let’s walk through this somewhat abstract map of the chapter in detail. We
    will be dealing with the issues we’re facing, like excessive focus on a single,
    narrow metric and the resulting behavior being useless in the general sense. In
    order to make some of this chapter’s concepts a bit more concrete, we’ll first
    employ a metaphor that puts our troubles in more tangible terms: in figure 12.2,
    (1) Guard Dogs and (2) Birds and Burglars.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细地走过本章的这张有些抽象的地图。我们将处理我们面临的问题，比如过度关注单一、狭窄的指标以及由此产生的行为在一般意义上是无用的。为了使本章的一些概念更具体化，我们将首先使用一个比喻来将我们的困境更具体化：在图12.2中，（1）看门狗和（2）鸟和窃贼。
- en: '![](../Images/CH12_F02_Stevens2_GS.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F02_Stevens2_GS.png)'
- en: Figure 12.2 The metaphors we’ll use to modify the metrics measuring our model
    to make it magnificent
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 我们将使用的比喻来修改衡量我们模型的指标，使其变得出色
- en: 'After that, we will develop a graphical language to represent some of the core
    concepts needed to formally discuss the issues with the implementation from the
    last chapter: (3) Ratios: Recall and Precision. Once we have those concepts solidified,
    we’ll touch on some math using those concepts that will encapsulate a more robust
    way of grading our model’s performance and condensing it into a single number:
    (4) New Metric: F1 Score. We will implement the formula for those new metrics
    and look at the how the resulting values change epoch by epoch during training.
    Finally, we’ll make some much-needed changes to our `LunaDataset` implementation
    with an aim at improving our training results: (5) Balancing and (6) Augmentation.
    Then we will see if those experimental changes have the expected impact on our
    performance metrics.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将开发一个图形语言来代表上一章实施中所需的核心概念：（3）比率：召回率和精确率。一旦我们将这些概念巩固下来，我们将涉及一些使用这些概念的数学，这将包括一种更健壮的评估我们模型性能的方式，并将其压缩为一个数字：（4）新指标：F1分数。我们将实施这些新指标的公式，并查看在训练过程中每个时期这些结果值如何变化。最后，我们将对我们的`LunaDataset`实现进行一些急需的更改，以改善我们的训练结果：（5）平衡和（6）增强。然后我们将看看这些实验性的更改是否对我们的性能指标产生了预期的影响。
- en: 'By the time we’re through with this chapter, our trained model will be performing
    much better: (7) Workin’ Great! While it won’t be ready to drop into clinical
    use just yet, it will be capable of producing results that are clearly better
    than random. This will mean we have a workable implementation of step 4, nodule
    candidate classification; and once we’re finished, we can begin to think about
    how to incorporate steps 2 (segmentation) and 3 (grouping) into the project.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们训练的模型将表现得更好：（7）工作得很棒！虽然它还没有准备好立即投入临床使用，但它将能够产生明显优于随机的结果。这意味着我们已经有了可行的第4步实现，结节候选分类；一旦完成，我们可以开始考虑如何将第2步（分割）和第3步（分组）纳入项目中。
- en: '12.2 Good dogs vs. bad guys: False positives and false negatives'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 好狗与坏家伙：假阳性和假阴性
- en: Instead of models and tumors, we’re going to consider the two guard dogs in
    figure 12.3, both fresh out of obedience school. They both want to alert us to
    burglars--a rare but serious situation that requires prompt attention.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不再考虑模型和肿瘤，而是考虑图12.3中的两只看门狗，它们刚从服从学校毕业。它们都想警告我们有窃贼——这是一种罕见但严重的情况，需要及时处理。
- en: '![](../Images/CH12_F03_Stevens2_GS.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F03_Stevens2_GS.png)'
- en: Figure 12.3 The set of topics for this chapter, with a focus on the framing
    metaphor
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 本章的主题集，重点放在框架比喻上
- en: Unfortunately, while both dogs are good dogs, neither is a good *guard* dog.
    Our terrier (Roxie) barks at just about everything, while our old hound dog (Preston)
    barks almost exclusively at burglars--but only if he happens to be awake when
    they arrive.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，虽然两只狗都是好狗，但都不是好的*警卫*狗。我们的梗犬（Roxie）对几乎所有事情都会吠，而我们的老猎犬（Preston）几乎只会对入室者吠叫——但前提是他在他们到达时恰好醒着。
- en: Roxie *will* alert us to a burglar just about every time. She will also alert
    us to fire engines, thunderstorms, helicopters, birds, the mail carrier, squirrels,
    passersby, and so on. If we follow up on every bark, we’ll almost never get robbed
    (only the sneakiest of sneak-thieves can slip past). Perfect! ... Except that
    being that diligent means we aren’t really saving any work by having a guard dog.
    Instead, we’ll be up every couple of hours, flashlight in hand, due to Roxie having
    smelled a cat, or heard an owl, or seen a late bus wander by. Roxie has a problematic
    number of false positives.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Roxie几乎每次都会警告我们有入室者。她还会警告我们有消防车、雷暴、直升机、鸟、邮递员、松鼠、路人等。如果我们对每次吠叫进行跟进，我们几乎永远不会被抢劫（只有最狡猾的偷窃者才能溜过）。完美！...
    除了那么勤奋意味着我们实际上并没有通过养警卫狗节省任何工作。相反，我们每隔几个小时就会起床，手持手电筒，因为Roxie闻到了猫的气味，或者听到了猫头鹰的叫声，或者看到了一辆晚点的公共汽车经过。Roxie有一个问题性的假阳性数量。
- en: A *false positive* is an event that is classified as of interest or as a member
    of the desired class (positive as in “Yes, that’s the type of thing I’m interested
    in knowing about”) but that in truth is *not* really of interest. For the nodule-detection
    problem, it’s when an actually uninteresting candidate is flagged as a nodule
    and, hence, in need of a radiologist’s attention. For Roxie, these would be fire
    engines, thunderstorms, and so on. We will use an image of a cat as the canonical
    false positive in the next section and the figures that follow throughout the
    rest of the chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*假阳性*是被分类为感兴趣或所需类别的成员（阳性表示“是的，这是我感兴趣了解的类型”）的事件，但实际上并不是真正感兴趣的。对于结节检测问题，当一个实际上无趣的候选者被标记为结节，因此需要放射科医生的关注时，就会发生假阳性。对于Roxie来说，这些可能是消防车、雷暴等。在接下来的章节和随后的图中，我们将使用一张猫的图片作为典型的假阳性。'
- en: 'Contrast false positives with *true positives*: items of interest that are
    classified correctly. These will be represented in the figures by a human burglar.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 将假阳性与*真阳性*进行对比：被正确分类的感兴趣项目。这些将在图中由一个人类强盗表示。
- en: Meanwhile, if Preston barks, call the police, since that means someone has almost
    certainly broken in, the house is on fire, or Godzilla is attacking. Preston is
    a deep sleeper, however, and the sound of an in-progress home invasion isn’t likely
    to rouse him, so we’ll still get robbed just about every time someone tries. Again,
    while it’s better than nothing, we’re not really ending up with the peace of mind
    that motivated us to get a dog in the first place. Preston has a problematic number
    of false negatives.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，如果Preston吠叫，请立即报警，因为这意味着几乎肯定有人闯入，房子着火了，或者哥斯拉在袭击。然而，Preston睡得很沉，正在进行家庭入侵的声音不太可能唤醒他，所以每当有人尝试时，我们几乎总是会被抢劫。虽然比没有好，但我们并没有真正获得最初让我们养狗的平静心态。Preston有一个问题性的假阴性数量。
- en: A *false negative* is an event that is classified as not of interest or not
    a member of the desired class (negative as in “No, that’s not the type of thing
    I’m interested in knowing about”) but that in truth *is* actually of interest.
    For the nodule-detection problem, it’s when a nodule (that is, a potential cancer)
    goes undetected. For Preston, these would be the robberies that he sleeps through.
    We’ll get a bit creative here and use a picture of a *rodent* burglar for false
    negatives. They’re sneaky!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*假阴性*是被分类为不感兴趣或不是所需类别的成员（阴性表示“不，这不是我感兴趣了解的类型”）的事件，但实际上确实是感兴趣的。对于结节检测问题，当一个结节（即潜在的癌症）未被检测到时，就会发生假阴性。对于Preston来说，这些将是他睡过的抢劫案。在这里我们将有点创意，使用一张*啮齿*强盗的图片来代表假阴性。它们很狡猾！'
- en: 'Contrast false negatives with *true negatives*: uninteresting items that are
    correctly identified as such. We’ll go with a picture of a bird for these.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 将假阴性与*真阴性*进行对比：正确识别为无趣项目的项目。我们将用一只鸟的图片来代表这些。
- en: Just to complete the metaphor, chapter 11’s model is basically a cat that refuses
    to meow at anything that isn’t a can of tuna (while stoically ignoring Roxie).
    Our focus at the end of the last chapter was on the percent correct for the overall
    training and validation sets. Clearly, that wasn’t a great way to grade ourselves,
    and as we can see from each of our dogs’ myopic focus on a single metric--like
    the number of true positives or true negatives--we need a metric with a broader
    focus to capture our overall performance.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个比喻，第11章的模型基本上是一只拒绝对不是金鱼罐的任何东西发出喵声的猫（同时坚定地忽视Roxie）。我们在上一章末尾的重点是整体训练和验证集的正确百分比。显然，这不是一个很好的评分方式，正如我们从我们每只狗对单一指标的近视关注——比如真阳性或真阴性的数量——可以看出的那样，我们需要一个更广泛关注的指标来捕捉我们的整体表现。
- en: 12.3 Graphing the positives and negatives
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 绘制阳性和阴性
- en: Let’s start developing the visual language we’ll use to describe true/false
    positives/ negatives. Please bear with us if our explanation gets repetitive;
    we want to make sure you develop a solid mental model for the ratios we’re going
    to discuss. Consider figure 12.4, which shows events that might be of interest
    to one of our guard dogs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始制定我们将用来描述真/假阳性/阴性的视觉语��。如果我们的解释变得重复，请耐心等待；我们希望确保您对我们将要讨论的比率形成坚实的心理模型。考虑图12.4，显示了可能对我们其中一只警卫狗感兴趣的事件。
- en: '![](../Images/CH12_F04_Stevens2_GS.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F04_Stevens2_GS.png)'
- en: Figure 12.4 Cats, birds, rodents, and robbers make up our four classification
    quadrants. They are separated by a human label and the dog classification threshold.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4中的猫、鸟、啮齿动物和强盗构成了我们的四个分类象限。它们由人类标签和狗的分类阈值分隔。
- en: We’ll use two thresholds in figure 12.4\. The first is the human-decided dividing
    line that separates burglars from harmless animals. In concrete terms, this is
    the label that is given for each training or validation sample. The second is
    the dog-determined *classification threshold* that determines whether the dog
    will bark at something. For a deep learning model, this is the predicted value
    that the model produces when considering a sample.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在图12.4中，我们将使用两个阈值。第一个是人为决定的将入室盗窃犯与无害动物分开的分界线。具体来说，这是为每个训练或验证样本分配的标签。第二个是狗确定的*分类阈值*，它决定了狗是否会对某物吠叫。对于深度学习模型，这是在考虑样本时模型产生的预测值。
- en: 'The combination of these two thresholds divides our events into quadrants:
    true/false positives/negatives. We will shade the events of concern with a darker
    background (what with those bad guys sneaking around in the dark all the time).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个阈值的组合将我们的事件分成四个象限：真/假阳性/阴性。我们将关注的事件用较深的背景色进行阴影处理（因为那些坏家伙总是在黑暗中潜行）。
- en: Of course, reality is far more complicated. There is no Platonic ideal of a
    burglar, and no single point relative to the classification threshold at which
    all burglars will be located. Instead, figure 12.5 shows us that some burglars
    will be particularly sneaky, and some birds will be particularly annoying. We
    will also go ahead and enclose our instances in a graph. Our X-axis will remain
    the bark-worthiness of each event, as determined by one of our guard dogs. We’re
    going to have the Y-axis represent some vague set of qualities that we as humans
    are able to perceive, but our dogs cannot.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，现实要复杂得多。并不存在一个关于入室盗窃犯的柏拉图理想，也没有一个相对于分类阈值的单一点，所有入室盗窃犯都会在那里。相反，图12.5向我们展示了一些入室盗窃犯会特别狡猾，一些鸟类会特别烦人。我们还将把我们的实例放在一个图中。我们的X轴将保持每个事件的吠声价值，由我们的一只看门狗确定。我们将让Y轴代表我们作为人类能够感知的一些模糊特质，但我们的狗却无法感知。
- en: Since our model produces a binary classification, we can think of the prediction
    threshold as comparing a single-numerical-value output to our classification threshold
    value. This is why we will require that the classification threshold line to be
    perfectly vertical in figure 12.5.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的模型产生二元分类，我们可以将预测阈值视为将单一数值输出与我们的分类阈值值进行比较。这就是为什么我们要求图12.5中的分类阈值线是完全垂直的。
- en: '![](../Images/CH12_F05_Stevens2_GS.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F05_Stevens2_GS.png)'
- en: Figure 12.5 Each type of event will have many possible instances that our guard
    dogs will need to evaluate.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 每种事件都会有许多可能的实例，我们的看门狗需要评估。
- en: 'Each possible burglar is different, so our guard dogs will need to evaluate
    many different situations, and that means more opportunities to make mistakes.
    We can see the clear diagonal line that separates the birds from the burglars,
    but Preston and Roxie can only perceive the X-axis here: they have a muddled,
    overlapped set of events in the middle of our graph. They must pick a vertical
    bark-worthiness threshold, which means it’s impossible for either one of them
    to do so perfectly. Sometimes the person hauling your appliances to their van
    is the repair person you hired to fix your washing machine, and sometimes burglars
    show up in a van that says “Washing Machine Repair” on the side. Expecting a dog
    to pick up on those nuances is bound to fail.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每个可能的入室盗窃犯都是不同的，因此我们的看门狗将需要评估许多不同的情况，这意味着更多犯错的机会。我们可以看到明显的对角线将鸟类与入室盗窃犯分开，但普雷斯顿和洛克西只能在这里感知X轴：他们在我们的图中间有一组混乱、重叠的事件。他们必须选择一个垂直的吠声价值阈值，这意味着他们中的任何一个都不可能完美地做到。有时候把你的家电搬到他们的货车上的人是你雇来修理洗衣机的维修人员，有时候入室盗窃犯会开着一辆侧面写着“洗衣机维修”的货车出现。期望狗能够察觉到这些微妙之处注定会失败。
- en: The actual input data we’re going to use has high dimensionality--we need to
    consider a ton of CT voxel values, along with more abstract things like candidate
    size, overall location in the lungs, and so on. The job of our model is to map
    each of these events and respective properties into this rectangle in such a way
    that we can separate those positive and negative events cleanly using a single
    vertical line (our classification threshold). This is done by the `nn.Linear`
    layers at the end of our model. The position of the vertical line corresponds
    exactly to the `classificationThreshold_float` we saw in section 11.6.1\. There,
    we chose the hardcoded value 0.5 as our threshold.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要使用的实际输入数据具有高维度--我们需要考虑大量CT体素值，以及更抽象的事物，如候选大小、在肺部的整体位置等等。我们模型的工作是将每个事件及其属性映射到这个矩形中，以便我们可以使用单一垂直线（我们的分类阈值）清晰地分离这些正面和��面事件。这是通过我们模型末端的`nn.Linear`层完成的。垂直线的位置与我们在第11.6.1节中看到的`classificationThreshold_float`完全对应。在那里，我们选择了硬编码值0.5作为我们的阈值。
- en: 'Note that in reality, the data presented is not two-dimensional; it goes from
    very-high-dimensional after the second-to-last layer, to one-dimensional (here,
    our X-axis) at the output--just a single scalar per sample (which is then bisected
    by the classification threshold). Here, we use the second dimension (the Y-axis)
    to represent per-sample features that our model cannot see or use: things like
    age or gender of the patient, location of the nodule candidate in the lung, or
    even local aspects of the candidate that the model hasn’t utilized. It also gives
    us a convenient way to represent confusion between non-nodule and nodule samples.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，实际上，所呈现的数据不是二维的；在倒数第二层之后，它变成了非常高维度，到输出时变成了一维（这里是我们的X轴）--每个样本只有一个标量（然后被分类阈值二分）。在这里，我们使用第二维（Y轴）来表示我们的模型无法看到或使用的每个样本特征：例如患者的年龄或性别，结节候选在肺部的位置，甚至模型尚未利用的候选局部特征。它还为我们提供了一种方便的方式来表示非结节和结节样本之间的混淆。
- en: The quadrant areas in figure 12.5 and the count of samples contained in each
    will be the values we use to discuss model performance, since we can use the ratios
    between these values to construct increasingly complex metrics that we can use
    to objectively measure how well we are doing. As they say, “the proof is in the
    proportions.”[¹](#pgfId-1012296) Next, we’ll use ratios between these event subsets
    to start defining better metrics.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5中的象限区域和每个区域中包含的样本数将是我们用来讨论模型性能的值，因为我们可以使用这些值之间的比率来构建越来越复杂的指标，以客观地衡量我们的表现。正如他们所说，“证据在于比例。”[¹](#pgfId-1012296)
    接下来，我们将使用这些事件子集之间的比率来开始定义更好的指标。
- en: 12.3.1 Recall is Roxie’s strength
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 召回率是罗克西的优势
- en: Recall is basically “Make sure you never miss any interesting events!” Formally,
    *recall* is the ratio of the true positives to the union of true positives and
    false negatives. We can see this depicted in figure 12.6.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率基本上是“确保你永远不会错过任何有趣的事件！”正式地说，*召回率*是真阳性与真阳性和假阴性的并集的比率。我们可以在图12.6中看到这一点。
- en: '![](../Images/CH12_F06_Stevens2_GS.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F06_Stevens2_GS.png)'
- en: Figure 12.6 Recall is the ratio of the true positives to the union of true positives
    and false negatives. High recall minimizes false negatives.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 召回率是真阳性与真阳性和假阴性的并集的比率。高召回率可以最小化假阴性。
- en: '*Note* In some contexts, recall is referred to as *sensitivity*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*注* 在某些情境中，召回率被称为*敏感性*。'
- en: To improve recall, minimize false negatives. In guard dog terms, that means
    if you’re unsure, bark at it, just in case. Don’t let any rodent thieves sneak
    by on your watch!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高召回率，要尽量减少假阴性。在看门狗的术语中，这意味着如果你不确定，就叫一声，以防万一。不要让任何啮齿动物小偷在你的监视下溜走！
- en: Roxie accomplishes having an incredibly high recall by pushing her classification
    threshold all the way to the left, such that it encompasses nearly all of the
    positive events in figure 12.7\. Note how doing so means her recall value is near
    1.0, which means 99% of robbers are barked at. Since that’s how Roxie defines
    success, in her mind, she’s doing a great job. Never mind the huge expanse of
    false positives!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 罗克西通过将分类阈值推到最左边，使其包含图12.7中几乎所有的正面事件，从而实现了极高的召回率。请注意，这样做意味着她的召回值接近1.0，即99%的盗贼都会被叫唤。由于这是罗克西定义成功的方式，在她看来，她做得很好。不要在意大量的假阳性！
- en: '![](../Images/CH12_F07_Stevens2_GS.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F07_Stevens2_GS.png)'
- en: Figure 12.7 Roxie’s choice of threshold prioritizes minimizing false negatives.
    Every last rat is barked at . . . and cats, and most birds.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 罗克西选择的阈值优先考虑减少假阴性。每只老鼠都会被叫唤……还有猫，大多数鸟。
- en: 12.3.2 Precision is Preston’s forte
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 精确性是普雷斯顿的长处
- en: Precision is basically “Never bark unless you’re sure.” To improve precision,
    minimize false positives. Preston won’t bark at something unless he’s certain
    it’s a burglar. More formally, *precision* is the ratio of the true positives
    to the union of true positives and false positives, as shown in figure 12.8.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 精确性基本上是“除非你确定，否则不要叫。”为了提高精确性，要尽量减少假阳性。普雷斯顿不会对某事物叫唤，除非他确定那是一个盗贼。更正式地说，*精确性*是真阳性与真阳性和假阳性的并集的比率，如图12.8所示。
- en: '![](../Images/CH12_F08_Stevens2_GS.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F08_Stevens2_GS.png)'
- en: Figure 12.8 Precision is the ratio of the true positives to the union of true
    positives and false positives. High precision minimizes false positives.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 精确性是真阳性与真阳性和假阳性的并集的比率。高精确性可以最小化假阳性。
- en: 'Preston accomplishes having an incredibly high precision by pushing his classification
    threshold all the way to the right, such that it excludes as many uninteresting,
    negative events as he can manage (see figure 12.9). This is the opposite of Roxie’s
    approach and means Preston has a precision of nearly 1.0: 99% of the things he
    barks at are robbers. This also matches his definition of being a good guard dog,
    even though a large number of events pass undetected.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 普雷斯顿通过将分类阈值推到最右边，排除尽可能多的无趣、负面事件，从而实现了极高的精确性（见图12.9）。这与罗克西的方法相反，意味着普雷斯顿的精确性接近1.0：他叫的99%的事物都是盗贼。尽管有大量事件未被检测到，但这也符合他作为一只好看门狗的定义。
- en: While neither precision nor recall can be the single metric used to grade our
    model, they are both useful numbers to have on hand during training. Let’s calculate
    and display these as part of our training program, and then we’ll discuss other
    metrics we can employ.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然精确性和召回率都不能作为评估我们模型的单一指标，但它们在训练过程中是有用的数字。让我们计算并显示这些作为我们训练程序的一部分，然后我们将讨论其他可以使用的指标。
- en: '![](../Images/CH12_F09_Stevens2_GS.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F09_Stevens2_GS.png)'
- en: Figure 12.9 Preston’s choice of threshold prioritizes minimizing false positives.
    Cats get left alone; only burglars are barked at!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 普雷斯顿选择的阈值优先考��减少假阳性。猫被放过，只有盗贼会被叫唤！
- en: 12.3.3 Implementing precision and recall in logMetrics
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 在logMetrics中实现精确性和召回率
- en: Both precision and recall are valuable metrics to be able to track during training,
    since they provide important insight into how the model is behaving. If either
    of them drops to zero (as we saw in chapter 11!), it’s likely that our model has
    started to behave in a degenerate manner. We can use the exact details of the
    behavior to guide where to investigate and experiment with getting training back
    on track. We’d like to update the `logMetrics` function to add precision and recall
    to the output we see for each epoch, to complement the loss and correctness metrics
    we already have.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，精确性和召回率都是有价值的指标，因为它们提供了关于模型行为的重要见解。如果它们中的任何一个降至零（正如我们在第11章中看到的！），那么我们的模型可能已经开始表现出退化的方式。我们可以使用行为的确切细节来指导我们在哪里进行调查和实验，以使训练重新回到正轨。我们希望更新`logMetrics`函数，以在每个时期的输出中添加精确性和召回率，以补充我们已经拥有的损失和正确性指标。
- en: We’ve been defining precision and recall in terms of “true positives” and the
    like thus far, so we will continue to do so in the code. It turns out that we
    are already computing some of the values we need, though we had named them differently.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在以“真阳性”等术语定义精确度和召回率，因此我们将在代码中继续这样做。事实证明，我们已经计算了一些我们需要的值，尽管我们给它们起了不同的名称。
- en: Listing 12.1 training.py:315, `LunaTrainingApp.logMetrics`
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.1 training.py:315，`LunaTrainingApp.logMetrics`
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, we can see that `neg_correct` is the same thing as `trueNeg_count`! That
    actually makes sense, since non-nodule is our “negative” value (as in “a negative
    diagnosis”), and if the classifier gets the prediction correct, then that’s a
    true negative. Similarly, correctly labeled nodule samples are true positives.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到`neg_correct`与`trueNeg_count`是相同的！这其实是有道理的，因为非结节是我们的“负面”值（如“负面诊断”），如果分类器预测正确，那么这就是真阴性。同样，正确标记的结节样本是真阳性。
- en: We do need to add the variables for our false positive and false negative values.
    That’s straightforward, since we can take the total number of benign labels and
    subtract the count of the correct ones. What’s left is the count of non-nodule
    samples misclassified *as positive*. Hence, they are false positives. Again, the
    false negative calculation is of the same form, but uses nodule counts.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实需要添加我们的假阳性和假阴性值的变量。这很简单，因为我们可以取良性标签的总数并减去正确的计数。剩下的是被误分类为*阳性*的非结节样本的计数。因此，它们是假阳性。同样，假阴性计算形式相同，但使用结节计数。
- en: With those values, we can compute `precision` and `recall` and store them in
    `metrics _dict`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些数值，我们可以计算`precision`和`recall`，并将它们存储在`metrics_dict`中。
- en: Listing 12.2 training.py:333, `LunaTrainingApp.logMetrics`
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.2 training.py:333，`LunaTrainingApp.logMetrics`
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Note the double assignment: while having separate `precision` and `recall`
    variables isn’t strictly necessary, they improve the readability of the next section.
    We also extend the logging statement in `logMetrics` to include the new values,
    but we skip the implementation for now (we’ll revisit logging later in the chapter).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 注意双重赋值：虽然有单独的`precision`和`recall`变量并不是绝对必要的，但它们提高了下一节的可读性。我们还扩展了`logMetrics`中的日志语句以包括新值，但我们暂时跳过实现（我们将在本章稍后重新讨论日志记录）。
- en: '12.3.4 Our ultimate performance metric: The F1 score'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.4 我们的终极性能指标：F1分数
- en: While useful, neither precision nor recall entirely captures what we need in
    order to be able to evaluate a model. As we’ve seen with Roxie and Preston, it’s
    possible to game either one individually by manipulating our classification threshold,
    resulting in a model that scores well on one or the other but does so at the expense
    of any real-world utility. We need something that combines both of those values
    in a way that prevents such gamesmanship. As we can see in figure 12.10, it’s
    time to introduce our ultimate metric.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有用，但精确度和召回率都无法完全捕捉我们评估模型所需的内容。正如我们在 Roxie 和 Preston 中看到的，通过操纵我们的分类阈值，可能会单独操纵其中一个，导致模型在其中一个上得分良好，但以牺牲任何实际效用为代价。我们需要一种以防止这种操纵的方式结合这两个值的东西。正如我们在图
    12.10 中看到的，现在是引入我们的终极指标的时候了。
- en: The generally accepted way of combining precision and recall is by using the
    F1 score ([https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score)).
    As with other metrics, the F1 score ranges between 0 (a classifier with no real-world
    predictive power) and 1 (a classifier that has perfect predictions). We will update
    `logMetrics` to include this as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通常接受的结合精确度和召回率的方法是使用 F1 分数（[https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score)）。与其他指标一样，F1
    分数的范围在 0（没有真实世界预测能力的分类器）和 1（具有完美预测的分类器）之间。我们将更新`logMetrics`以包括这一点。
- en: Listing 12.3 training.py:338, `LunaTrainingApp.logMetrics`
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.3 training.py:338，`LunaTrainingApp.logMetrics`
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: At first glance, this might seem more complicated than we need, and it might
    not be immediately obvious how the F1 score behaves when trading off precision
    for recall or vice versa. This formula has a lot of nice properties, however,
    and it compares favorably to several other, simpler alternatives that we might
    consider.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，这可能比我们需要的更复杂，当在精确度和召回率之间进行权衡时，F1 分数的行为可能不会立即显而易见。然而，这个公式有很多好的性质，并且与我们可能考虑的几种其他更简单的替代方案相比较有利。
- en: '![](../Images/CH12_F10_Stevens2_GS.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F10_Stevens2_GS.png)'
- en: Figure 12.10 The set of topics for this chapter, with a focus on the final F1
    score metric
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 本章的主题集，重点是最终的 F1 分数指标
- en: One immediate possibility for a scoring function is to average the values for
    precision and recall together. Unfortunately, this gives both `avg(p=1.0, r=0.0)`
    and `avg(p=0.5, r=0.5)` the same score of 0.5, and as we discussed earlier, a
    classifier with either precision or recall of zero is usually worthless. Giving
    something useless the same nonzero score as something useful disqualifies averaging
    as a meaningful metric immediately.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一个立即可能的评分函数是将精确度和召回率的值平均起来。不幸的是，这使得`avg(p=1.0, r=0.0)`和`avg(p=0.5, r=0.5)`都得到相同的
    0.5 分数，正如我们之前讨论的，精确度或召回率为零的分类器通常是无用的。将无用的东西与有用的东西赋予相同的非零分数，立即使平均成为一个没有意义的指标。
- en: Still, let’s visually compare averaging and F1 in figure 12.11\. A few things
    stand out. First, we can see a lack of a curve or elbow in the contour lines for
    averaging. That’s what lets our precision or recall skew to one side or the other!
    There will *never* be a situation where it doesn’t make sense to maximize the
    score by having 100% recall (the Roxie approach) and then eliminate whichever
    false positives are easy to eliminate. That puts a floor on the addition score
    of 0.5 right out of the gate! Having a quality metric that is trivial to score
    at least 50% on doesn’t feel right.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，让我们在图 12.11 中直观比较平均和 F1。有几件事引人注目。首先，我们可以看到平均值的等高线中没有曲线或拐点。这就是让我们的精确度或召回率偏向一侧的原因！永远不会出现这样的情况，即通过使召回率达到
    100%（Roxie 方法）然后消除任何容易消除的假阳性来最大化分数是没有意义的。这就为添加分数至少为 0.5 设置了一个底线！拥有一个质量指标，可以轻松获得至少
    50% 的分数，感觉不对劲。
- en: '![](../Images/CH12_F11_Stevens2_GS.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F11_Stevens2_GS.png)'
- en: Figure 12.11 Computing the final score with `avg(p, r)`. Lighter values are
    closer to 1.0.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 使用`avg(p, r)`计算最终分数。较浅的值接近1.0。
- en: '*Note* What we are actually doing here is taking the *arithmetic mean* ([https://en.wikipedia.org/wiki/Arithmetic_mean](https://en.wikipedia.org/wiki/Arithmetic_mean))
    of the precision and recall, both of which are *rates* rather than countable scalar
    values. Taking the arithmetic mean of rates doesn’t typically give meaningful
    results. The F1 score is another name for the *harmonic mean* ([https://en.wikipedia.org/wiki/
    Harmonic_mean](https://en.wikipedia.org/wiki/Harmonic_mean)) of the two rates,
    which is a more appropriate way of combining those kinds of values.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 我们实际上在这里做的是取精确度和召回率的*算术平均值*（[https://en.wikipedia.org/wiki/Arithmetic_mean](https://en.wikipedia.org/wiki/Arithmetic_mean)），这两者都是*比率*而不是可计数的标量值。取比率的算术平均值通常不会给出有意义的结果。F1分数是两个比率的*调和平均值*（[https://en.wikipedia.org/wiki/Harmonic_mean](https://en.wikipedia.org/wiki/Harmonic_mean)）的另一个名称，这是结合这些值的更合适的方式。'
- en: 'Contrast that with the F1 score: when recall is high but precision is low,
    trading off a lot of recall for even a little precision will move the score closer
    to that balanced sweet spot. There’s a nice, deep elbow that is easy to slide
    into. That encouragement to have balanced precision and recall is what we want
    from our grading metric.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与F1分数相比：当召回率高而精确度低时，为了将分数移动到平衡的甜蜜点，牺牲很多召回率以换取一点精确度将使分数更接近。有一个漂亮、深刻的拐点，很容易滑入其中。鼓励具有平衡精确度和召回率是我们希望从我们的评分指标中得到的。
- en: Let’s say we still want a simpler metric, but one that doesn’t reward skew at
    all. In order to correct for the weakness of addition, we might take the minimum
    of precision and recall (figure 12.12).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们仍然希望有一个更简单的指标，但不会奖励任何偏斜。为了纠正加法的弱点，我们可能会取精确度和召回率的最小值（图12.12）。
- en: '![](../Images/CH12_F12_Stevens2_GS.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F12_Stevens2_GS.png)'
- en: Figure 12.12 Computing the final score with `min(p, r)`
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 使用`min(p, r)`计算最终分数
- en: This is nice, because if either value is 0, the score is also 0, and the only
    way to get a score of 1.0 is to have both values be 1.0\. However, it still leaves
    something to be desired, since making a model change that increased the recall
    from 0.7 to 0.9 while leaving precision constant at 0.5 wouldn’t improve the score
    at all, nor would dropping recall down to 0.6! Although this metric is certainly
    penalizing having an imbalance between precision and recall, it isn’t capturing
    a lot of nuance about the two values. As we have seen, it’s easy to trade one
    off for the other simply by moving the classification threshold. We’d like our
    metric to reflect those trades.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，因为如果任一值为0，分数也为0，而要获得1.0的分数的唯一方法是两个值都为1.0。然而，它仍然有待改进，因为使召回率从0.7提高到0.9而将精确度保持在0.5不会改善分数，降低召回率到0.6也不会改善分数！尽管这个指标肯定惩罚了精确度和召回率之间的不平衡，但它并没有捕捉到关于这两个值的许多细微差别。正如我们所见，通过简单地移动分类阈值，很容易将一个值换成另一个值。我们希望我们的指标能反映这些交易。
- en: We’ll have to accept at least a bit more complexity to better meet our goals.
    We could multiply the two values together, as in figure 12.13\. This approach
    keeps the nice property that if either value is 0, the score is 0, and a score
    of 1.0 means both inputs are perfect. It also favors a balanced trade-off between
    precision and recall at low values, though when it gets closer to perfect results,
    it becomes more linear. That’s not great, since we really need to push both up
    to have a meaningful improvement at that point.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地实现我们的目标，我们将不得不接受至少更复杂一点。我们可以将这两个值相乘，如图12.13所示。这种方法保持了一个很好的特性，即如果任一值为0，分数也为0，而分数为1.0意味着两个输入都完美。它还有利于在低值处精确度和召回率之间的平衡折衷，尽管当接近完美结果时，它变得更加线性。这并不好，因为我们真的需要将两者都提高才能在那一点上有意义的改进。
- en: '![](../Images/CH12_F13_Stevens2_GS.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F13_Stevens2_GS.png)'
- en: Figure 12.13 Computing the final score with `mult(p, r)`
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 使用`mult(p, r)`计算最终分数
- en: '*Note* Here we’re taking the *geometric mean* ([https://en.wikipedia.org/wiki/
    Geometric_mean](https://en.wikipedia.org/wiki/Geometric_mean)) of two rates, which
    also doesn’t produce meaningful results.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 在这里我们正在取两个比率的*几何平均值*（[https://en.wikipedia.org/wiki/Geometric_mean](https://en.wikipedia.org/wiki/Geometric_mean)），这也不会产生有意义的结果。'
- en: There’s also the issue of having almost the entire quadrant from (0, 0) to (0.5,
    0.5) be very close to zero. As we’ll see, having a metric that’s sensitive to
    changes in that region is important, especially in the early stages of our model
    design.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个问题，几乎整个象限从（0, 0）到（0.5, 0.5）都非常接近于零。正如我们将看到的，拥有一个对该区域的变化敏感的指标是重要的，特别是在我们模型设计的早期阶段。
- en: While using multiplication as our scoring function is feasible (it doesn’t have
    any immediate disqualifications the way the previous scoring functions did), we
    will be using the F1 score to evaluate our classification model’s performance
    going forward.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然将乘法作为我们的评分函数是可行的（它没有任何立即淘汰的资格，就像之前的评分函数一样），但我们将使用F1分数��评估我们的分类模型的性能。
- en: Updating the logging output to include precision, recall, and F1 score
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更新日志输出以包括精确度、召回率和F1分数
- en: Now that we have our new metrics, adding them to our logging output is pretty
    straightforward. We’ll include precision, recall, and F1 in our main logging statement
    for each of our training and validation sets.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了新的指标，将它们添加到我们的日志输出中非常简单。我们将在我们的训练和验证集的主要日志声明中包括精确度、召回率和F1。
- en: Listing 12.4 training.py:341, `LunaTrainingApp.logMetrics`
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4 training.py:341, `LunaTrainingApp.logMetrics`
- en: '[PRE3]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Format string updated
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 格式字符串已更新
- en: In addition, we’ll include exact values for the count of correctly identified
    and the total number of samples for each of the negative and positive samples.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们将为每个负样本和正样本的正确识别计数和总样本数包括精确值。
- en: Listing 12.5 training.py:353, `LunaTrainingApp.logMetrics`
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.5 training.py:353, `LunaTrainingApp.logMetrics`
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The new version of the positive logging statement looks much the same.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 新版本的正日志声明看起来基本相同。
- en: 12.3.5 How does our model perform with our new metrics?
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.5 我们的模型如何使用我们的新指标？
- en: 'Now that we’ve implemented our shiny new metrics, let’s take them for a spin;
    we’ll discuss the results after we show the results of the Bash shell session.
    You might want to read ahead while your system does its number crunching; this
    could take perhaps half an hour, depending on your system.[²](#pgfId-1024858)
    Exactly how long it takes will depend on your system’s CPU, GPU, and disk speeds;
    our system with an SSD and GTX 1080 Ti took about 20 minutes per full epoch:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经实施了闪亮的新指标，让我们试试它们；我们将在展示Bash shell会话结果后讨论结果。在您的系统进行数字计算时，您可能想提前阅读；这可能需要大约半个小时，具体时间取决于您的系统。实际所需时间取决于您的系统的CPU、GPU和磁盘速度；我们的系统配备SSD和GTX
    1080 Ti，每个完整时期大约需要20分钟：
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ The exact count and line numbers of these RuntimeWarning lines might be different
    from run to run.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些RuntimeWarning行的确切计数和行号可能会因运行而异。
- en: Bummer. We’ve got some warnings, and given that some of the values we computed
    were `nan`, there’s probably a division by zero happening somewhere. Let’s see
    what we can figure out.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕。我们收到了一些警告，考虑到我们计算的一些值是`nan`，可能在某处发生了除零操作。让我们看看我们能找出什么。
- en: First, since *none* of the positive samples in the training set are getting
    classified as positive, that means both precision and recall are zero, which results
    in our F1 score calculation dividing by zero. Second, for our validation set,
    `truePos_count` and `falsePos_count` are both zero due to *nothing* being flagged
    as positive. It follows that the denominator of our `precision` calculation is
    also zero; that makes sense, as that’s where we’re seeing another `RuntimeWarning`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，由于训练集中没有一个正样本被分类为正，这意味着精确度和召回率都为零，导致我们的F1分数计算除以零。其次，对于我们的验证集，由于没有任何东西被标记为正，`truePos_count`和`falsePos_count`都为零。这导致我们的`precision`计算的分母也为零；这是合理的，因为这就是我们看到另一个`RuntimeWarning`的地方。
- en: A handful of negative training samples are classified as positive (494735 of
    494743 are classified as negative, so that leaves 8 samples misclassified). While
    that might seem odd at first, recall that we are collecting our training results
    *throughout the epoch*, rather than using the model’s end-of-epoch state as we
    do for the validation results. That means the first batch is literally producing
    random results. A few of the samples from that first batch being flagged as positive
    isn’t surprising.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 少数负训练样本被分类为正（494743个中有494735个被分类为负，因此有8个样本被错误分类）。虽然一开始可能看起来很奇怪，但请记住我们是*在整个时期内*收集我们的训练结果，而不是像我们对验证结果那样使用模型的时期末状态。这意味着第一批次实际上产生了随机结果。其中一些来自第一批次的样本被标记为正并不奇怪。
- en: '*Note* Due to both the random initialization of the network weights and the
    random ordering of the training samples, individual runs will likely exhibit slightly
    different behavior. Having exactly reproducible behavior can be desirable but
    is out of scope for what we’re trying to do in part 2 of this book.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 由于网络权重的随机初始化和训练样本的随机排序，单独的运行可能会表现出略有不同的行为。确切可重现的行为可能是可取的，但超出了我们在本书第2部分中所尝试的范围。'
- en: Well, that was somewhat painful. Switching to our new metrics resulted in going
    from A+ to “Zero, if you’re lucky”--and if we’re not lucky, the score is so bad
    that *it’s not even a number*. Ouch.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，那有点痛苦。切换到我们的新指标导致从A+降至“零，如果你幸运的话”--如果我们不幸运，分数会很糟糕，*甚至不是一个数字*。哎呀。
- en: That said, in the long run, this is good for us. We’ve known that our model’s
    performance was garbage since chapter 11\. If our metrics told us anything *but*
    that, it would point to a fundamental flaw in the metrics!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，在长期来看，这对我们是有利的。自第11章以来，我们就知道我们的模型性能很差。如果我们的指标告诉我们除了那个，那将指向指标中的一个基本缺陷！
- en: 12.4 What does an ideal dataset look like?
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 理想数据集是什么样的？
- en: Before we start crying into our cups over the current sorry state of affairs,
    let’s instead think about what we actually want our model to do. Figure 12.14
    says that first we need to balance our data so that our model can train properly.
    Let’s build up the logical steps needed to get us there.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们为当前糟糕的情况哭泣之前，让我们想想我们实际上希望我们的模型做什么。图12.14说，首先我们需要平衡我们的数据，以便我们的模型能够正确训练。让我们建立起达到这个目标所需的逻辑步骤。
- en: '![](../Images/CH12_F14_Stevens2_GS.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F14_Stevens2_GS.png)'
- en: Figure 12.14 The set of topics for this chapter, with a focus on balancing our
    positive and negative samples
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14 本章主题集，重点关注平衡我们的正负样本
- en: Recall figure 12.5 earlier, and the following discussion of classification thresholds.
    Getting better results by moving the threshold has limited effectiveness--there’s
    just too much overlap between the positive and negative classes to work with.[³](#pgfId-1025238)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下之前的图12.5，并讨论分类阈值。通过移动阈值来获得更好的结果具有有限的效果--正负类之间有太多重叠无法处理。
- en: Instead, we want to see an image like figure 12.15\. Here, our label threshold
    is nearly vertical. That’s what we want, because it means the label threshold
    and our classification threshold can line up reasonably well. Similarly, most
    of the samples are concentrated at either end of the diagram. Both of these things
    require that our data be easily separable and that our model have the capacity
    to perform that separation. Our model currently has enough capacity, so that’s
    not the issue. Instead, let’s take a look at our data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们想看到一个类似图12.15的图像。在这里，我们的标签阈值几乎是垂直的。这就是我们想要的，因为这意味着标签阈值和我们的分类阈值可以相当好地对齐。同样，大多数样本集中在图表的两端。这两件事都要求我们的数据易于分离，并且我们的模型具有执行该分离的能力。我们的模型目前具有足够的容量，所以问题不在于此。相反，让我们看看我们的数据。
- en: '![](../Images/CH12_F15_Stevens2_GS.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F15_Stevens2_GS.png)'
- en: Figure 12.15 A well-trained model can cleanly separate data, making it easy
    to pick a classification threshold with few trade-offs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.15 一个训练良好的模型可以清晰地分离数据，使得很容易选择一个具有少量折衷的分类阈值。
- en: '![](../Images/CH12_F16_Stevens2_GS.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F16_Stevens2_GS.png)'
- en: Figure 12.16 An imbalanced dataset that roughly approximates the imbalance in
    our LUNA classification data
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.16 一个大致近似我们LUNA分类数据中不平衡的数据集
- en: Recall that our data is wildly imbalanced. There’s a 400:1 ratio of positive
    samples to negative ones. That’s *crushingly* imbalanced! Figure 12.16 shows what
    that looks like. No wonder our “actually nodule” samples are getting lost in the
    crowd!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的数据极度不平衡。正样本与负样本的比例为400:1。这是*极端*不平衡的！图12.16展示了这种情况。难怪我们的“实际结节”样本在人群中被忽略！
- en: 'Now, let’s be perfectly clear: when we’re done, our model will be able to handle
    this kind of data imbalance just fine. We could probably even train the model
    all the way there without changing the balancing, assuming we were willing to
    wait for a gajillion epochs first.[⁴](#pgfId-1025323) But we’re busy people with
    things to do, so rather than cook our GPU until the heat death of the universe,
    let’s try to make our training data look more ideal by changing the class balance
    we are training with.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们非常清楚：当我们完成时，我们的模型将能够很好地处理这种数据不平衡。我们甚至可以在不改变平衡的情况下训练模型到最后，假设我们愿意等待无数个纪元。但我们是忙碌的人，有很多事情要做，所以与其等到GPU烧毁到宇宙的热死亡，不如尝试通过改变我们训练的类平衡使我们的训练数据看起来更理想。
- en: 12.4.1 Making the data look less like the actual and more like the “ideal”
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.1 使数据看起来不那么实际，更像“理想”的方法
- en: The best thing to do would be to have relatively more positive samples. During
    the initial epoch of training, when we’re going from randomized chaos to something
    more organized, having so few training samples be positive means they get drowned
    out.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的做法是有相对更多的正样本。在训练的初始时期，当我们从随机混乱过渡到更有组织的状态时，由于正样本太少，它们会被淹没。
- en: The method by which this happens is somewhat subtle, however. Recall that since
    our network weights are initially randomized, the per-sample output of the network
    is also randomized (but clamped to the range [0-1]).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种情况发生的方式有些微妙。请记住，由于我们的网络权重最初是随机的，网络每个样本的输出也是随机的（但被夹在[0-1]范围内）。
- en: '*Note* Our loss function is `nn.CrossEntropyLoss`, which technically operates
    on the raw logits rather than the class probabilities. For our discussion, we’ll
    ignore that distinction and assume the loss and the label-prediction deltas are
    the same thing.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 我们的损失函数是`nn.CrossEntropyLoss`，严格来说是在原始logits上操作，而不是类概率。在我们的讨论中，我们将忽略这一区别，假设损失和标签预测之间的差异是相同的。'
- en: 'The predictions numerically close to the correct label do not result in much
    change to the weights of the network, while predictions that are significantly
    different from the correct answer are responsible for a much greater change to
    the weights. Since the output is random when the model is initialized with random
    weights, we can assume that of our ~500k training samples (495,958, to be exact),
    we’ll have the following approximate groups:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 预测与正确标签数值接近的结果对网络权重几乎没有影响，而与正确答案明显不同的预测结果会导致权重发生更大的变化。由于模型在随机权重初始化时输出是随机的，我们可以假设在我们约500k个训练样本（准确地说是495,958个）中，我们将有以下近似组：
- en: 250,000 negative samples will be predicted to be negative (0.0 to 0.5) and result
    in at most a small change to the network weights toward predicting negative.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 250,000个负样本将被预测为负面（0.0到0.5），并最多对网络权��产生一点朝向预测负面的变化。
- en: 250,000 negative samples will be predicted to be positive (0.5 to 1.0) and result
    in a large swing toward the network weights predicting negative.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 250,000个负样本将被预测为正面（0.5到1.0），并导致网络权重向预测负面的方向发生大幅变化。
- en: 500 positive samples will be predicted to be negative and result in a swing
    toward the network weights predicting positive.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 500个正样本将被预测为负面，并导致网络权重向预测正面的方向发生变化。
- en: 500 positive samples will be predicted to be positive and result in almost no
    change to the network weights.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 500个正样本将被预测为正面，并几乎不会对网络权重产生任何变化。
- en: '*Note* Keep in mind that the actual predictions are real numbers between 0.0
    and 1.0 inclusive, so these groups won’t have strict delineations.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 请记住，实际预测是介于0.0和1.0之间的实数，因此这些组没有严格的界限。'
- en: 'Here’s the kicker, though: groups 1 and 4 can be *any size*, and they will
    continue to have close to zero impact on training. The only thing that matters
    is that groups 2 and 3 can counteract each other’s pull enough to prevent the
    network from collapsing to a degenerate “only output one thing” state. Since group
    2 is 500 times larger than group 3 and we’re using a batch size of 32, roughly
    500/32 = 15 batches will go by before seeing a single positive sample. That implies
    that 14 out of 15 training batches will be 100% negative and will only pull all
    model weights toward predicting negative. That lopsided pull is what produces
    the degenerate behavior we’ve been seeing.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键是：1组和4组可以是*任意大小*，它们对训练几乎没有影响。唯一重要的是2组和3组能够相互抵消，防止网络崩溃到退化的“只输出一种结果”的状态。由于2组比3组大500倍，我们使用的批量大小为32，大约需要经过500/32
    = 15批次才能看到一个正样本。这意味着15个训练批次中有14个将是100%负面的，只会将所有模型权重拉向预测负面的方向。这种不平衡的拉力产生了我们一直看到的退化行为。
- en: Instead, we’d like to have just as many positive samples as negative ones. For
    the first part of training, then, half of both labels will be classified incorrectly,
    meaning that groups 2 and 3 should be roughly equal in size. We also want to make
    sure we present batches with a mix of negative and positive samples. Balance would
    result in the tug-of-war evening out, and the mixture of classes per batch will
    give the model a decent chance of learning to discriminate between the two classes.
    Since our LUNA data has only a small, fixed number of positive samples, we’ll
    have to settle for taking the positive samples that we have and presenting them
    repeatedly during training.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们希望正样本和负样本数量相同。因此，在训练的第一部分中，一半的标签将被错误分类，这意味着第2组和第3组的大小应该大致相等。我们还希望确保我们呈现的批次中包含负样本和正样本的混合。平衡将导致拉锯战平衡，每个批次中的类别混合将使模型有很好的机会学会区分这两个类别。由于我们的LUNA数据只有少量固定数量的正样本，我们将不得不接受我们拥有的正样本并在训练期间重复呈现它们。
- en: Discrimination
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 歧视
- en: Here, we define discrimination as “the ability to separate two classes from
    each other.” Building and training a model that can tell “actually nodule” candidates
    from normal anatomical structures is the entire point of what we’re doing in part
    2.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将歧视定义为“将两个类别彼此分开的能力”。构建和训练一个能够将“实际结节”候选者与正常解剖结构区分开的模型是我们在第2部分所做的全部工作的重点。
- en: Some other definitions of discrimination are more problematic. While out of
    scope for the discussion of our work here, there is a larger issue with models
    trained from real-world data. If that real-world dataset is collected from sources
    that have a real-world-discriminatory bias (for example, racial bias in arrest
    and conviction rates, or anything collected from social media), and that bias
    is not corrected for during dataset preparation or training, then the resulting
    model will continue to exhibit the same biases present in the training data. Just
    as in humans, racism is learned.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 歧视的一些其他定义更具问题性。虽然超出了我们在这里讨论工作的范围，但从真实世界数据训练的模型存在更大的问题。如果真实世界数据集是从存在真实世界歧视性偏见的来源收集的（例如，种族偏见在逮捕和定罪率中，或者从社交媒体收集的任何内容），并且在数据集准备或训练期间没有纠正这种偏见，那么生成的模型将继续表现出训练数据中存在的相同偏见。就像在人类中一样，种族主义是被学习的。
- en: This means almost any model trained from internet-at-large data sources will
    be compromised in some fashion, unless extreme care is taken to scrub those biases
    from the model. Note that like our goal in part 2, this is considered an unsolved
    problem.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着几乎任何从互联网大数据源训练的模型都会在某种程度上受到损害，除非极端小心地清除这些模型中的偏见。请注意，就像我们在第2部分的目标一样，这被认为是一个未解决的问题。
- en: Recall our professor from chapter 11 who had a final exam with 99 false answers
    and 1 true answer. The next semester, after being told “You should have a more
    even balance of true and false answers,” the professor decided to add a midterm
    with 99 true answers and 1 false one. “Problem solved!”
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们在第11章中提到的教授，他的期末考试有99个错误答案和1个正确答案。下学期，在被告知“你应该有更平衡的真假答案”后，教授决定增加一次期中考试，其中有99个正确答案和1个错误答案。“问题解决了！”
- en: Clearly, the correct approach is to intermix true and false answers in a way
    that doesn’t allow the students to exploit the larger structure of the tests to
    answer things correctly. Whereas a student would pick up on a pattern like “odd
    questions are true, even questions are false,” the batching system used by PyTorch
    doesn’t allow the model to “notice” or utilize that kind of pattern. Our training
    dataset will need to be updated to alternate between positive and negative samples,
    as in figure 12.17.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，正确的方法是以一种不允许学生利用测试的更大结构来回答问题的方式交替真实和错误答案。虽然学生可能会注意到“奇数问题是真实的，偶数问题是错误的”这样的模式，但PyTorch使用的批处理系统不允许模型“注意到”或利用那种模式。我们的训练数据集将需要更新，以在正样本和负样本之间交替，就像图12.17中那样。
- en: The unbalanced data is the proverbial needle in the haystack we mentioned at
    the start of chapter 9\. If you had to perform this classification work by hand,
    you’d probably start to empathize with Preston.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 不平衡数据就像我们在第9章开始提到的草堆中的针。如果您必须手动执行这项分类工作，您可能会开始同情普雷斯顿。
- en: '![](../Images/CH12_F17_Stevens2_GS.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F17_Stevens2_GS.png)'
- en: Figure 12.17 Batch after batch of imbalanced data will have nothing but negative
    events long before the first positive event, while balanced data can alternate
    every other sample.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.17 不平衡数据的批次将在第一个正事件之前只有负事件，而平衡数据可以每隔一个样本交替出现。
- en: We will not be doing any balancing for validation, however. Our model needs
    to function well in the real world, and the real world is imbalanced (after all,
    that’s where we got the raw data!).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不会为验证进行任何平衡。我们的模型需要在现实世界中表现良好，而现实世界是不平衡的（毕竟，这就是我们获取原始数据的地方！）。
- en: How should we accomplish this balancing? Let’s discuss our choices.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该如何实现这种平衡？让我们讨论我们的选择。
- en: Samplers can reshape datasets
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 取样器可以重塑数据集
- en: One of the optional arguments to `DataLoader` is `sampler=...` . This allows
    the data loader to override the iteration order native to the dataset passed in
    and instead shape, limit, or reemphasize the underlying data as desired. This
    can be incredibly useful when working with a dataset that isn’t under your control.
    Taking a public dataset and reshaping it to meet your needs is far less work than
    reimplementing that dataset from scratch.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoader` 的一个可选参数是`sampler=...`。这允许数据加载器覆盖传入数据集的本机迭代顺序，而是根据需要塑造、限制或重新强调底层数据。当使用一个不受您控制的数据集时，这可能非常有用。将公共数据集重新塑造以满足您的需求比从头开始重新实现该数据集要少得多。'
- en: The downside is that many of the mutations we could accomplish with samplers
    require that we break encapsulation of the underlying dataset. For example, let’s
    assume we have a dataset like CIFAR-10 ([www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html))
    that consists of 10 equally weighted classes, and we want to instead have 1 class
    (say, “airplane”) now make up 50% of all of the training images. We could decide
    to use `WeightedRandomSampler` ([http://mng.bz/8plK](http://mng.bz/8plK)) and
    weight each of the “airplane” sample indexes higher, but constructing the `weights`
    argument requires that we know in advance which indexes are airplanes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 不足之处在于，我们可以通过采样器实现的许多变异需要我们打破底层数据集的封装。例如，假设我们有一个类似于 CIFAR-10（[www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)）的数据集，由10个权重相同的类组成，我们想要让1个类（比如“飞机”）现在占所有训练图像的50%。我们可以决定使用`WeightedRandomSampler`（[http://mng.bz/8plK](http://mng.bz/8plK)）并将每个“飞机”样本索引的权重提高，但构建`weights`参数需要我们事先知道哪些索引是飞机。
- en: As we discussed, the `Dataset` API only specifies that subclasses provide `__len__`
    and `__getitem__`, but there is nothing direct we can use to ask “Which samples
    are airplanes?” We’d either have to load up every sample beforehand to inquire
    about the class of that sample, or we’d have to break encapsulation and hope the
    information we need is easily obtained from looking at the internal implementation
    of the `Dataset` subclass.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的那样，`Dataset` API只规定子类提供`__len__`和`__getitem__`，但我们无法直接询问“哪些样本是飞机？”我们要么事先加载每个样本以查询该样本的类别，要么打破封装并希望我们需要的信息可以轻松从查看`Dataset`子类的内部实现中获得。
- en: Since neither of those options is particularly ideal in cases where we have
    control over the dataset directly, the code for part 2 implements any needed data
    shaping inside the `Dataset` subclasses instead of relying on an external sampler.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在我们可以直接控制数据集的情况下，这两种选项都不是特别理想的，因此第2部分的代码在`Dataset`子类内部实现任何所需的数据整形，而不依赖外部采样器。
- en: Implementing class balancing in the dataset
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在数据集中实现类平衡
- en: We are going to directly change our `LunaDataset` to present a balanced, one-to-one
    ratio of positive and negative samples for training. We will keep separate lists
    of negative training samples and positive training samples, and alternate returning
    samples from each of those two lists. This will prevent the degenerate behavior
    of the model scoring well by simply answering “false” to every sample presented.
    In addition, the positive and negative classes will be intermixed so that the
    weight updates are forced to discriminate between the classes.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接更改我们的`LunaDataset`，以呈现平衡的正负样本比例进行训练。我们将保留负训练样本和正训练样本的分开列表，并交替从这两个列表中返回样本。这将防止模型通过简单地回答每个呈现的样本为“false”而得分良好的退化行为。此外，正负类别将交错排列，以便权重更新被迫区分类别。
- en: Let’s add a `ratio_int` to `LunaDataset` that will control the label for the
    *N*th sample as well as keep track of our samples separated by label.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在`LunaDataset`中添加一个`ratio_int`，用于控制第*N*个样本的标签，并跟踪我们按标签分开的样本。
- en: Listing 12.6 dsets.py:217, `class` `LunaDataset`
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6 dsets.py:217，`class` `LunaDataset`
- en: '[PRE6]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ We will call this at the top of each epoch to randomize the order of samples
    being presented.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们将在每个周期的开头调用这个函数，以随机化呈现的样本顺序。
- en: 'With this, we now have dedicated lists for each label. Using these lists, it
    becomes much easier to return the label we want for a given index into the dataset.
    In order to make sure we’re getting the indexing right, we should sketch out the
    ordering we want. Let’s assume a `ratio_int` of 2, meaning a 2:1 ratio of negative
    to positive samples. That would mean every third index should be positive:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们现在为每个标签都有专门的列表。使用这些列表，更容易根据数据集中的索引返回我们想要的标签。为了确保我们的索引正确，我们应该勾画出我们想要的排序。假设`ratio_int`为2，意味着负样本与正样本的比例为2:1。这意味着每三个索引应该是正样本：
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The relationship between the dataset index and the positive index is simple:
    divide the dataset index by 3 and then round down. The negative index is slightly
    more complicated, in that we have to subtract 1 from the dataset index and then
    subtract the most recent positive index as well.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集索引与正索引之间的关系很简单：将数据集索引除以3然后向下取整。负索引稍微复杂一些，因为我们必须从数据集索引中减去1，然后再减去最近的正索引。
- en: Implemented in our `LunaDataset` class, that looks like the following.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`LunaDataset`类中实现，看起来像下面这样。
- en: Listing 12.7 dsets.py:286, `LunaDataset.__getitem__`
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7 dsets.py:286，`LunaDataset.__getitem__`
- en: '[PRE8]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ A ratio_int of zero means use the native balance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 零的`ratio_int`意味着使用本地平衡。
- en: ❷ A nonzero remainder means this should be a negative sample.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 非零余数表示这应该是一个负样本。
- en: ❸ Overflow results in wraparound.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 溢出导致环绕。
- en: ❹ Returns the Nth sample if not balancing classes
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 如果不平衡类别，则返回第N个样本
- en: That can get a little hairy, but if you desk-check it out, it will make sense.
    Keep in mind that with a low ratio, we’ll run out of positive samples before exhausting
    the dataset. We take care of that by taking the modulus of `pos_ndx` before indexing
    into `self.pos_list`. While the same kind of index overflow should never happen
    with `neg_ndx` due to the large number of negative samples, we do the modulus
    anyway, just in case we later decide to make a change that might cause it to overflow.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能有点复杂，但如果你仔细检查一下，就会明白。请记住，如果比率较低，我们会在用尽数据集之前用完正样本。我们通过在索引到`self.pos_list`之前取`pos_ndx`的模来处理这个问题。虽然由于大量负样本的存在，`neg_ndx`不太可能发生相同类型的索引溢出，但我们仍然执行模运算，以防以后做出可能导致溢出的更改。
- en: We’ll also make a change to our dataset’s length. Although this isn’t strictly
    necessary, it’s nice to speed up individual epochs. We’re going to hardcode our
    `__len__` to be 200,000.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将对数据集的长度进行更改。虽然这并非绝对必要，但加快单个周期的速度是很好的。我们将硬编码我们的`__len__`为200,000。
- en: Listing 12.8 dsets.py:280, `LunaDataset.__len__`
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.8 dsets.py:280，`LunaDataset.__len__`
- en: '[PRE9]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We’re no longer tied to a specific number of samples, and presenting “a full
    epoch” doesn’t really make sense when we would have to repeat positive samples
    many, many times to present a balanced training set. By picking 200,000 samples,
    we reduce the time between starting a training run and seeing results (faster
    feedback is always nice!), and we give ourselves a nice, clean number of samples
    per epoch. Feel free to adjust the length of an epoch to meet your needs.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不再受限于特定数量的样本，并且提供“完整的一轮”在我们必须多次重复正样本以呈现平衡的训练集时并不是很有意义。通过选择20万个样本，我们减少了开始训练运行并看到结果之间的时间（更快的反馈总是不错！），并且我们给��己一个漂亮、清晰的每轮样本数。随时调整一轮的长度以满足您的需求。
- en: For completeness, we also add a command-line parameter.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整起见，我们还添加了一个命令行参数。
- en: Listing 12.9 training.py:31, `class` `LunaTrainingApp`
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.9 training.py:31，`class` `LunaTrainingApp`
- en: '[PRE10]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Then we pass that parameter into the `LunaDataset` constructor.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将该参数传递给`LunaDataset`构造函数。
- en: Listing 12.10 training.py:137, `LunaTrainingApp.initTrainDl`
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.10 training.py:137，`LunaTrainingApp.initTrainDl`
- en: '[PRE11]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Here we rely on python’s `True` being convertible to a `1`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这里我们依赖于Python的`True`可转换为`1`。
- en: We’re all set. Let’s run it!
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备就绪。让我们运行它！
- en: 12.4.2 Contrasting training with a balanced LunaDataset to previous runs
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.2 将平衡的LunaDataset与之前的运行进行对比
- en: 'As a reminder, our unbalanced training run had results like these:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们不平衡的训练运行结果如下：
- en: '[PRE12]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'But when we run with `--balanced`, we see the following:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 但是当我们使用`--balanced`运行时，我们看到以下情况：
- en: '[PRE13]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This seems much better! We’ve given up about 5% correct answers on the negative
    samples to gain 86% correct positive answers. We’re back into a solid B range
    again![⁵](#pgfId-1027111)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来好多了！我们放弃了大约5%的负样本正确答案，以获得86%的正确正样本答案。我们又回到了一个扎实的B范围内！[⁵](#pgfId-1027111)
- en: As in chapter 11, however, this result is deceptive. Since there are 400 times
    as many negative samples as positive ones, even getting just 1% wrong means we’d
    be incorrectly classifying negative samples as positive four times more often
    than there are actually positive samples in total!
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，就像第11章一样，这个结果是具有欺骗性的。由于负样本比正样本多400倍，即使只有1%的错误，也意味着我们会将负样本错误地分类为正样本，比实际正样本总数多四倍！
- en: 'Still, this is clearly better than the outright wrong behavior from chapter
    11 and much better than a random coin flip. In fact, we’ve even crossed over into
    being (almost) legitimately useful in real-world scenarios. Recall our overworked
    radiologist poring over each and every speck of a CT: well, now we’ve got something
    that can do a reasonable job of screening out 95% of the false positives. That’s
    a huge help, since it translates into about a tenfold increase in productivity
    for the machine-assisted human.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这显然比第11章的完全错误行为要好得多，比随机抛硬币要好得多。事实上，我们甚至已经进入了（几乎）在实际场景中有用的领域。回想一下我们过度劳累的放射科医生仔细检查每一个CT上的每一个斑点：现在我们有了一些可以合理地筛除95%的假阳性的东西。这是一个巨大的帮助，因为这意味着机器辅助人类的生产力增加了大约十倍。
- en: 'Of course, there’s still that pesky issue of the 14% of positive samples that
    were missed, which we should probably deal with. Perhaps some additional epochs
    of training would help. Let’s see (and again, expect to spend at least 10 minutes
    per epoch):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有那令人讨厌的14%被错过的正样本问题，我们可能需要处理一下。也许增加一些额外的训练轮次会有所帮助。让我们看看（再次提醒，每轮至少需要花费10分钟）：
- en: '[PRE14]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Ugh. That’s a lot of text to scroll past to get to the numbers we’re interested
    in. Let’s power through and focus on the `val_mal XX.X% correct` numbers (or skip
    ahead to the TensorBoard graph in the next section.) After epoch 2, we were at
    87.5%; on epoch 5, we peaked with 92.6%; and then by epoch 20 we dropped down
    to 86.8%--*below* our second epoch!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀。要滚动到我们感兴趣的数字，需要滚过很多文本。让我们坚持下去，专注于`val_mal XX.X% correct`数字（或者直接跳到下一节的TensorBoard图表）。第2轮之后，我们达到了87.5%；第5轮时，我们达到了92.6%的峰值；然后到了第20轮，我们下降到了86.8%--*低于*我们的第二轮！
- en: '*Note* As mentioned earlier, expect each run to have unique behavior due to
    random initialization of network weights and random selection and ordering of
    training samples per epoch.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 正如前面提到的，由于网络权重的随机初始化和每轮训练样本的随机选择和排序，预计每次运行都会有独特的行为。'
- en: The training set numbers don’t seem to be having the same problem. Negative
    training samples are classified correctly 98.8% of the time, and positive samples
    are 99.1% correct. What’s going on?
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集的数字似乎没有同样的问题。负训练样本被正确分类的概率为98.8%，正样本则为99.1%。发生了什么？
- en: 12.4.3 Recognizing the symptoms of overfitting
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.3 识别过拟合的症状
- en: What we are seeing are clear signs of overfitting. Let’s take a look at the
    graph of our loss on positive samples, in figure 12.18.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所看到的是过拟合的明显迹象。让我们看一下我们在正样本上的损失图，见图12.18。
- en: '![](../Images/CH12_F18_Stevens2_GS.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F18_Stevens2_GS.png)'
- en: Figure 12.18 Our positive loss showing clear signs of overfitting, as the training
    loss and validation loss are trending in different directions
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.18 我们的正损失显示出明显的过拟合迹象，因为训练损失和验证损失趋势不同。
- en: Here, we can see that the training loss for our positive samples is nearly zero--each
    positive training sample gets a nearly perfect prediction. Our validation loss
    for positive samples is *increasing*, though, and that means our real-world performance
    is likely getting worse. At this point, it’s often best to stop the training script,
    since the model is no longer improving.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的正样本的训练损失几乎为零--每个正样本训练样本都得到了几乎完美的预测。然而，我们的正样本的验证损失却在增加，这意味着我们的实际表现可能正在变差。在这一点上，最好停止训练脚本，因为模型不再改进。
- en: '*tip* Generally, if your model’s performance is improving on your training
    set while getting worse on your validation set, the model has started overfitting.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示* 通常，如果您的模型在训练集上的表现正在提高，而在验证集上表现变差，那么模型已经开始过拟合。'
- en: We must take care to examine the right metrics, however, since this trend is
    only happening on our *positive* loss. If we take a look at our overall loss,
    everything seems fine! That’s because our validation set is not balanced, so the
    overall loss is dominated by our negative samples. As shown in figure 12.19, we
    are not seeing the same divergent behavior for our negative samples. Instead,
    our negative loss looks great! That’s because we have 400 times more negative
    samples, so it’s much, much harder for the model to remember individual details.
    Our positive training set has only 1,215 samples, though. While we repeat those
    samples multiple times, that doesn’t make them harder to memorize. The model is
    shifting from generalized principles to essentially memorizing quirks of those
    1,215 samples and claiming that anything that’s not one of those few samples is
    negative. This includes both negative training samples and everything in our validation
    set (both positive and negative).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须注意检查正确的指标，因为这种趋势只发生在我们的*正*损失上。如果我们看一下我们的整体损失，一切似乎都很好！这是因为我们的验证集不平衡，所以整体损失被我们的负样本所主导。正如图12.19所示，我们在我们的负样本中没有看到相同的发散行为。相反，我们的负损失看起来很好！这是因为我们有400倍的负样本，所以模型要记住个别细节要困难得多。然而，我们的正训练集只有1,215个样本。虽然我们多次重复这些样本，但这并不会使它们更难记忆。模型正在从泛化原则转变为基本上记住这1,215个样本的怪癖，并声称不属于这几个样本之一的任何东西都是负样本。这包括负训练样本和我们验证集中的所有内容（正负样本都有）。
- en: '![](../Images/CH12_F19_Stevens2_GS.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F19_Stevens2_GS.png)'
- en: Figure 12.19 Our negative loss showing no signs of overfitting
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.19 我们的负损失没有显示过拟合的迹象
- en: Clearly, some generalization is still going on, since we are classifying about
    70% of the positive validation set correctly. We just need to change how we’re
    training the model so that our training set and validation set both trend in the
    right direction.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，仍然存在一些泛化，因为我们大约正确分类了70%的正验证集。我们只需要改变我们训练模型的方式，使我们的训练集和验证集都朝着正确的方向发展。
- en: 12.5 Revisiting the problem of overfitting
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 重新审视过拟合问题
- en: We touched on the concept of overfitting in chapter 5, and now it’s time to
    take a closer look at how to address this common situation. Our goal with training
    a model is to teach it to recognize the *general properties* of the classes we
    are interested in, as expressed in our dataset. Those general properties are present
    in some or all samples of the class and can be *generalized* and used to predict
    samples that haven’t been trained on. When the model starts to learn *specific
    properties* of the training set, overfitting occurs, and the model starts to lose
    the ability to generalize. In case that’s a bit too abstract, let’s use another
    analogy.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第5章中提到了过拟合的概念，现在是时候更仔细地看看如何解决这种常见情况了。我们训练模型的目标是教会它识别我们感兴趣的类别的*一般属性*，如我们数据集中所表达的那样。这些一般属性存在于该类别的一些或所有样本中，并且可以*泛化*并用于预测未经训练的样本。当模型开始学习训练集的*特定属性*时，就会发生过拟合，模型开始失去泛化的能力。如果这有点抽象，让我们使用另一个类比。
- en: 12.5.1 An overfit face-to-age prediction model
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.1 一个过拟合的人脸到年龄预测模型
- en: Let’s pretend we have a model that takes an image of a human face as input and
    outputs a predicted age in years. A good model would pick up on age signifiers
    like wrinkles, gray hair, hairstyle, clothing choices, and similar, and use those
    to build a general model of what different ages look like. When presented with
    a new picture, it would consider things like “conservative haircut” and “reading
    glasses” and “wrinkles” to conclude “around 65 years old.”
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个模型，它以人脸图像作为输入，并输出预测的年龄。一个好的模型会注意到年龄的特征，如皱纹、白发、发型、服装选择等，并利用这些建立不同年龄看起来的一般模型。当呈现一张新图片时，它会考虑“保守的发型”、“眼镜”和“皱纹”等因素，得出“大约65岁”的结论。
- en: An overfit model, by contrast, instead remembers specific people by remembering
    identifying details. “That haircut and those glasses mean it’s Frank. He’s 62.8
    years old”; “Oh, that scar means it’s Harry. He’s 39.3”; and so on. When shown
    a new person, the model won’t recognize the person and will have absolutely no
    idea what age to predict.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比，过拟合模型则是通过记住识别细节来记住特定的人。“那个发型和那副眼镜意味着那是弗兰克。他62.8岁了”；“哦，那个伤疤意味着那是哈里。他39.3岁了”；等等。当展示一个新的人时，模型将无法识别这个人，也完全不知道该预测多少岁。
- en: Even worse, if shown a picture of Frank Jr. (the spittin’ image of his dad,
    at least when he’s wearing his glasses!), the model will say, “I think that’s
    Frank. He’s 62.8 years old.” Never mind that Junior is 25 years younger!
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，如果展示弗兰克的儿子的照片（看起来像他爸爸，至少戴着眼镜时是这样！），模型会说：“我认为那是弗兰克。他62.8岁了。”���管小弗兰克实际上年轻了25岁！
- en: Overfitting is usually due to having too few training samples when compared
    to the ability of the model to just memorize the answers. The median human can
    memorize the birthdays of their immediate family but would have to resort to generalizations
    when predicting the ages of any group larger than a small village.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合通常是由于训练样本太少，与模型仅仅记住答案的能力相比。普通人可以记住自己家人的生日，但在预测比一个小村庄规模更大的群体的年龄时，就必须求助于概括。
- en: Our face-to-age model has the capacity to simply memorize the photos of anyone
    who doesn’t look exactly their age. As we discussed in part 1, model capacity
    is a somewhat abstract concept, but is roughly a function of the number of parameters
    of the model times how efficiently those parameters are used. When a model has
    a high capacity relative to the amount of data needed to memorize the hard samples
    from the training set, it’s likely that the model will begin to overfit on those
    more difficult training samples.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的人脸到年龄模型有能力简单地记住那些看起来不完全符合其年龄的照片。正如我们在第1部分中讨论的，模型容量是一个有点抽象的概念，但大致是模型参数数量乘以这些参数的有效使用方式。当模型的容量相对于需要记住训练集中难样本的数据量很高时，模型很可能会开始过拟合这些更难的训练样本。
- en: 12.6 Preventing overfitting with data augmentation
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 通过数据增强防止过拟合
- en: It’s time to take our model training from good to great. We need to cover one
    last step in figure 12.20.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候将我们的模型训练从好到优秀了。我们需要完成图 12.20 中的最后一步。
- en: '![](../Images/CH12_F20_Stevens2_GS.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F20_Stevens2_GS.png)'
- en: Figure 12.20 The set of topics for this chapter, with a focus on data augmentation
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.20 本章的主题集，重点是数据增强
- en: We *augment* a dataset by applying synthetic alterations to individual samples,
    resulting in a new dataset with an effective size that is larger than the original.
    The typical goal is for the alterations to result in a synthetic sample that remains
    representative of the same general class as the source sample, but that cannot
    be trivially memorized alongside the original. When done properly, this augmentation
    can increase the training set size beyond what the model is capable of memorizing,
    resulting in the model being forced to increasingly rely on generalization, which
    is exactly what we want. Doing so is especially useful when dealing with limited
    data, as we saw in section 12.4.1.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过对单个样本应用合成的改变来*增强*数据集，从而得到一个有效大小比原始数据集更大的新数据集。典型的目标是使改变导致合成样本仍然代表与源样本相同的一般类别，但不能与原始样本一起轻松记忆。当正确执行时，这种增强可以将训练集大小增加到模型能够记忆的范围之外，从而迫使模型越来越依赖泛化，这正是我们想要的。在处理有限数据时，这种增强尤其有用，正如我们在第
    12.4.1 节中看到的。
- en: Of course, not all augmentations are equally useful. Going back to our example
    of a face-to-age prediction model, we could trivially change the red channel of
    the four corner pixels of each image to a random value 0-255, which would result
    in a dataset 4 billion times larger the original. Of course, this wouldn’t be
    particularly useful, since the model can pretty trivially learn to ignore the
    red dots in the image corners, and the rest of the image remains as easy to memorize
    as the single, unaugmented original image. Contrast that approach with flipping
    the image left to right. Doing so would only result in a dataset twice as large
    as the original, but each image would be quite a bit more useful for training
    purposes. The general properties of aging are not correlated left to right, so
    a mirrored image remains representative. Similarly, it’s rare for facial pictures
    to be perfectly symmetrical, so a mirrored version is unlikely to be trivially
    memorized alongside the original.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并非所有的增强都同样有用。回到我们的面部年龄预测模型的例子，我们可以轻松地将每个图像的四个角像素的红色通道更改为随机值 0-255，这将导致数据集比原始数据集大
    40 亿倍。当然，这并不特别有用，因为模型可以相当轻松地学会忽略图像角落的红点，而图像的其余部分仍然像单个未经增强的原始图像一样容易记忆。将这种方法与左右翻转图像进行对比。这样做只会使数据集比原始数据集大两倍，但每个图像对于训练目的来说会更有用。年龄的一般属性与左右无关，因此镜像图像仍然具有代表性。同样，面部图片很少是完全对称的，因此镜像版本不太可能与原始版本轻松记忆。
- en: 12.6.1 Specific data augmentation techniques
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.6.1 具体的数据增强技术
- en: 'We are going to implement five specific types of data augmentation. Our implementation
    will allow us to experiment with any or all of them, individually or in aggregate.
    The five techniques are as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现五种特定类型的数据增强。我们的实现将允许我们单独或合并地对任何一种或全部进行实验。这五种技术如下：
- en: Mirroring the image up-down, left-right, and/or front-back
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像上下、左右和/或前后镜像
- en: Shifting the image around by a few voxels
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像移动几个体素
- en: Scaling the image up or down
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像放大或缩小
- en: Rotating the image around the head-foot axis
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像围绕头-脚轴旋转
- en: Adding noise to the image
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加噪声到图像
- en: For each technique, we want to make sure our approach maintains the training
    sample’s representative nature, while being different enough that the sample is
    useful to train with.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种技术，我们希望确保我们的方法保持训练样本的代表性，同时又足够不同，以便样本用于训练时是有用的。
- en: We’ll define a function `getCtAugmentedCandidate` that is responsible for taking
    our standard chunk-of-CT-with-candidate-inside and modifying it. Our main approach
    will define an affine transformation matrix ([http://mng.bz/Edxq](http://mng.bz/Edxq))
    and use it with the PyTorch `affine_grid` ([https://pytorch.org/docs/stable/nn.html#affine-grid](https://pytorch.org/docs/stable/nn.html#affine-grid))
    and `grid _sample` ([https://pytorch.org/docs/stable/nn.html#torch.nn.functional.grid_sample](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.grid_sample))
    functions to resample our candidate.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义一个函数 `getCtAugmentedCandidate`，负责获取我们标准的 CT 块并对其中的候选进行修改。我们的主要方法将定义一个仿射变换矩阵（[http://mng.bz/Edxq](http://mng.bz/Edxq)），并将其与
    PyTorch 的 `affine_grid`（[https://pytorch.org/docs/stable/nn.html#affine-grid](https://pytorch.org/docs/stable/nn.html#affine-grid)）和
    `grid_sample`（[https://pytorch.org/docs/stable/nn.html#torch.nn.functional.grid_sample](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.grid_sample)）函数一起使用，以对我们的候选进行重新采样。
- en: Listing 12.11 dsets.py:149, `def` `getCtAugmentedCandidate`
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.11 dsets.py:149, `def` `getCtAugmentedCandidate`
- en: '[PRE15]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We first obtain `ct_chunk`, either from the cache or directly by loading the
    CT (something that will come in handy once we are creating our own candidate centers),
    and then convert it to a tensor. Next is the affine grid and sampling code.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先获取 `ct_chunk`，可以从缓存中获取，也可以直接通过加载 CT 获取（这在我们创建自己的候选中会很方便），然后将其转换为张量。接下来是仿射网格和采样代码。
- en: Listing 12.12 dsets.py:162, `def` `getCtAugmentedCandidate`
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.12 dsets.py:162, `def` `getCtAugmentedCandidate`
- en: '[PRE16]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Modifications to transform_tensor will go here.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 转换 transform_tensor 的修改将在这里进行。
- en: Without anything additional, this function won’t do much. Let’s see what it
    takes to add in some actual transforms.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何额外的东西，这个函数不会有太多作用。让我们看看需要添加一些实际变换的步骤。
- en: '*Note* It’s important to structure your data pipeline such that your caching
    steps happen *before* augmentation! Doing otherwise will result in your data being
    augmented once and then persisted in that state, which defeats the purpose.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 重要的是要构建数据流水线，使得缓存步骤发生在增强之前！否则将导致数据被增强一次，然后保留在那种状态，这违背了初衷。'
- en: Mirroring
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 镜像
- en: When mirroring a sample, we keep the pixel values exactly the same and only
    change the orientation of the image. Since there’s no strong correlation between
    tumor growth and left-right or front-back, we should be able to flip those without
    changing the representative nature of the sample. The index-axis (referred to
    as *Z* in patient coordinates) corresponds to the direction of gravity in an upright
    human, however, so there’s a possibility of a difference in the top and bottom
    of a tumor. We are going to assume it’s fine, since quick visual investigation
    doesn’t show any gross bias. Were we working toward a clinically relevant project,
    we’d need to confirm that assumption with an expert.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当镜像一个样本时，我们保持像素值完全相同，只改变图像的方向。由于肿瘤生长与左右或前后没有强烈的相关性，我们应该能够在不改变样本代表性质的情况下翻转它们。指数轴（在患者坐标中称为*Z*）对应于直立人体中的重力方向，然而，肿瘤的顶部和底部可能存在差异的可能性。我们将假设这没问题，因为快速的视觉调查并没有显示任何明显的偏差。如果我们正在进行一个临床相关的项目，我们需要向专家确认这一假设。
- en: Listing 12.13 dsets.py:165, `def` `getCtAugmentedCandidate`
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.13 dsets.py:165，`def` `getCtAugmentedCandidate`
- en: '[PRE17]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `grid_sample` function maps the range [-1, 1] to the extents of both the
    old and new tensors (the rescaling happens implicitly if the sizes are different).
    This range mapping means that to mirror the data, all we need to do is multiply
    the relevant element of the transformation matrix by -1\.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`grid_sample` 函数将范围 [-1, 1] 映射到旧张量和新张量的范围（如果大小不同，则会隐式地进行重新缩放）。这个范围映射意味着为了镜像数据，我们只需要将变换矩阵的相关元素乘以
    -1。'
- en: Shifting by a random offset
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过随机偏移进行移动
- en: Shifting the nodule candidate around shouldn’t make a huge difference, since
    convolutions are translation independent, though this will make our model more
    robust to imperfectly centered nodules. What will make a more significant difference
    is that the offset might not be an integer number of voxels; instead, the data
    will be resampled using trilinear interpolation, which can introduce some slight
    blurring. Voxels at the edge of the sample will be repeated, which can be seen
    as a smeared, streaky section along the border.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 将结节候选物体移动一下不会产生很大的影响，因为卷积是独立于平移的，尽管这会使我们的模型对不完全居中的结节更加稳健。更重要的是，偏移量可能不是整数个体素数；相反，数据将使用三线性插值重新采样，这可能会引入一些轻微的模糊。样本边缘的体素将被重复，这可以看作是沿边界的一部分呈现出模糊、条纹状的区域。
- en: Listing 12.14 dsets.py:165, `def` `getCtAugmentedCandidate`
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.14 dsets.py:165，`def` `getCtAugmentedCandidate`
- en: '[PRE18]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note that our `'offset'` parameter is the maximum offset expressed in the same
    scale as the [-1, 1] range the grid sample function expects.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们的 `'offset'` 参数是以与网格采样函数期望的 [-1, 1] 范围相同的比例表示的最大偏移量。
- en: Scaling
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 缩放
- en: Scaling the image slightly is very similar to mirroring and shifting. Doing
    so can also result in the same repeated edge voxels we just mentioned when discussing
    shifting the sample.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '稍微缩放图像与镜像和移动非常相似。这样做也会导致我们刚刚讨论的在移动样本时提到的相同重复边缘体素。 '
- en: Listing 12.15 dsets.py:165, `def` `getCtAugmentedCandidate`
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.15 dsets.py:165，`def` `getCtAugmentedCandidate`
- en: '[PRE19]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Since `random_float` is converted to be in the range [-1, 1], it doesn’t actually
    matter if we add `scale_float * random_float` to or subtract it from 1.0\.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `random_float` 被转换为在范围 [-1, 1]，所以实际上无论我们将 `scale_float * random_float` 添加到
    1.0 还是从 1.0 中减去它都没有关系。
- en: Rotating
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 旋转
- en: Rotation is the first augmentation technique we’re going to use where we have
    to carefully consider our data to ensure that we don’t break our sample with a
    conversion that causes it to no longer be representative. Recall that our CT slices
    have uniform spacing along the rows and columns (X- and Y-axes), but in the index
    (or Z) direction, the voxels are non-cubic. That means we can’t treat those axes
    as interchangeable.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转是我们将使用的第一种增强技术，我们必须仔细考虑我们的数据，以确保我们不会通过导致其不再具有代表性的转换来破坏我们的样本。请记住，我们的 CT 切片在行和列（X
    和 Y 轴）上具有均匀间距，但在指数（或 Z）方向上，体素是非立方体的。这意味着我们不能将这些轴视为可互换的。
- en: One option is to resample our data so that our resolution along the index-axis
    is the same as along the other two, but that’s not a true solution because the
    data along that axis would be very blurry and smeared. Even if we interpolate
    more voxels, the fidelity of the data would remain poor. Instead, we’ll treat
    that axis as special and confine our rotations to the X-Y plane.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一种选择是重新采样我们的数据，使得我们沿指数轴的分辨率与其他两个轴的分辨率相同，但这并不是一个真正的解决方案，因为沿着那个轴的数据会非常模糊和模糊。即使我们插入更多的体素，数据的保真度仍然很差。相反，我们将把这个轴视为特殊轴，并将我们的旋转限制在
    X-Y 平面上。
- en: Listing 12.16 dsets.py:181, `def` `getCtAugmentedCandidate`
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.16 dsets.py:181，`def` `getCtAugmentedCandidate`
- en: '[PRE20]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Noise
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 噪音
- en: Our final augmentation technique is different from the others in that it is
    actively destructive to our sample in a way that flipping or rotating the sample
    is not. If we add too much noise to the sample, it will swamp the real data and
    make it effectively impossible to classify. While shifting and scaling the sample
    would do something similar if we used extreme input values, we’ve chosen values
    that will only impact the edge of the sample. Noise will have an impact on the
    entire image.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终增强技术与其他技术不同，因为它在某种程度上对我们的样本进行了积极破坏，而翻转或旋转样本则没有这种情况。如果我们向样本添加太多噪音，它将淹没真实数据，并使其实际上无法分类。虽然如果我们使用极端输入值，移动和缩放样本也会产生类似的效果，但我们选择的值只会影响样本的边缘。噪音将对整个图像产生影响。
- en: Listing 12.17 dsets.py:208, `def` `getCtAugmentedCandidate`
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.17 dsets.py:208，`def` `getCtAugmentedCandidate`
- en: '[PRE21]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The other augmentation types have increased the effective size of our dataset.
    Noise makes our model’s job *harder*. We’ll revisit this once we see some training
    results.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 其他增强类型已经增加了我们数据集的有效大小。噪音使我们模型的工作*更加困难*。一旦我们看到一些训练结果，我们将重新审视这一点。
- en: Examining augmented candidates
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 检查增强候选物体
- en: We can see the result of our efforts in figure 12.21\. The upper-left image
    shows an un-augmented positive candidate, and the next five show the effect of
    each augmentation type in isolation. Finally, the bottom row shows the combined
    result three times.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图12.21中看到我们努力的结果。左上角的图像显示了一个未增强的正候选样本，接下来的五个图像显示了每种增强类型的效果。最后，底部行显示了三次组合结果。
- en: '![](../Images/CH12_F21_Stevens2_GS.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F21_Stevens2_GS.png)'
- en: Figure 12.21 Various augmentation types performed on a positive nodule sample
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.21 在正结节样本上执行的各种增强类型
- en: Since each `__getitem__` call to the augmenting dataset reapplies the augmentations
    randomly, each image on the bottom row looks different. This also means it’s nearly
    impossible to generate an image exactly like this again! It’s also important to
    remember that sometimes the `'flip'` augmentation will result in *no* flip. Returning
    always-flipped images is just as limiting as not flipping in the first place.
    Now let’s see if any of this makes a difference.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对增强数据集的每次`__getitem__`调用都会随机重新应用增强，底部行的每个图像看起来都不同。这也意味着几乎不可能再次生成完全相同的图像！还要记住，有时`'flip'`增强会导致*没有*翻转。始终返回翻转图像与一开始不翻转一样限制。现在让我们看看这是否有所不同。
- en: 12.6.2 Seeing the improvement from data augmentation
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.6.2 从数据增强中看到改进
- en: We are going to train additional models, one per augmentation type discussed
    in the last section, with an additional model training run that combines all of
    the augmentation types. Once they’re finished, we’ll take a look at our numbers
    in TensorBoard.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练额外的模型，每种增强类型一个，还有一个将所有增强类型组合在一起的额外模型训练运行。一旦它们完成，我们将在TensorBoard中查看我们的数据。
- en: In order to be able to turn our new augmentation types on and off, we need to
    expose the construction of `augmentation_dict` to our command-line interface.
    Arguments to our program will be added by `parser.add_argument` calls (not shown,
    but similar to the ones our program already has), which will then be fed into
    code that actually constructs `augmentation_dict`.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够打开和关闭我们的新增强类型，我们需要将`augmentation_dict`的构建暴露给我们的命令行界面。程序的参数将通过`parser.add_argument`调用添加（未显示，但类似于我们的程序已经具有的那些），然后将被馈送到实际构建`augmentation_dict`的代码中。
- en: Listing 12.18 training.py:105, `LunaTrainingApp.__init__`
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.18 training.py:105，`LunaTrainingApp.__init__`
- en: '[PRE22]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ These values were empirically chosen to have a reasonable impact, but better
    values probably exist.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这些值是经验选择的，具有合理的影响，但可能存在更好的值。
- en: 'Now that we have those command-line arguments ready, you can either run the
    following commands or revisit p2_run_everything.ipynb and run cells 8 through
    16\. Either way you run it, expect these to take a significant time to finish:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好这些命令行参数，您可以运行以下命令，或者重新查看p2_run_everything.ipynb并运行第8到16个单元格。无论如何运行，都需要花费相当长的时间才能完成：
- en: '[PRE23]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ You only need to prep the cache once per chapter.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 您每章只需要准备一次缓存。
- en: ❷ You might have this run from earlier in the chapter; in that case there’s
    no need to rerun it!
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 您可能在本章的早些时候运行过这个；在这种情况下，无需重新运行！
- en: 'While that’s running, we can start TensorBoard. Let’s direct it to only show
    these runs by changing the `logdir` parameter like so: `../path/to/tensorboard
    --logdir runs/p2ch12`.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在此期间，我们可以启动TensorBoard。让我们通过更改`logdir`参数来指示它仅显示这些运行，如下所示：`../path/to/tensorboard
    --logdir runs/p2ch12`。
- en: Depending on the hardware you have at your disposal, the training might take
    a long time. Feel free to skip the `flip`, `shift`, and `scale` training jobs
    and reduce the first and last runs to 11 epochs if you need to move things along
    more quickly. We chose 20 runs because that helps them stand out from the other
    runs, but 11 should work as well.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您手头的硬件情况，训练可能需要很长时间。如果需要加快进度，可以跳过`flip`、`shift`和`scale`训练任务，并将第一次和最后一次运行减少到11个周期。我们选择了20次运行，因为这有助于使它们脱颖而出，但11次也可以。
- en: If you let everything run to completion, your TensorBoard should have data like
    that shown in figure 12.22\. We’re going to deselect everything except the validation
    data, to reduce clutter. When you’re looking at your data live, you can also change
    the smoothing value, which can help clarify the trend lines. Take a quick look
    at the figure, and then we’ll go over it in some detail.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '如果让所有内容运行到完成，您的TensorBoard应该有类似图12.22所示的数据。我们将取消选择除验证数据之外的所有内容，以减少混乱。当您实时查看数据时，还可以更改平滑值，这有助于澄清趋势线。快速查看一下图，然后我们将详细介绍它。 '
- en: '![](../Images/CH12_F22_Stevens2_GS.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F22_Stevens2_GS.png)'
- en: Figure 12.22 Percent correctly classified, loss, F1 score, precision, and recall
    for the validation set from networks trained with a variety of augmentation schemes
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.22 用各种增强方案训练的网络在验证集上正确分类的百分比、损失、F1分数、精度和召回率
- en: 'The first thing to notice in the upper-left graph (“tag: correct/all”) is that
    the individual augmentation types are something of a jumble. Our unaugmented and
    fully augmented runs are on opposite sides of that jumble. That means when combined,
    our augmentation is more than the sum of its parts. Also of interest is that our
    fully augmented run gets many more wrong answers. While that’s bad generally,
    if we look at the right column of images (which focus on the positive candidate
    samples we actually care about--the ones that are really nodules), we see that
    our fully augmented model is *much* better at finding the positive candidate samples.
    The recall for the fully augmented model is great! It’s also much better at not
    overfitting. As we saw earlier, our unaugmented model gets worse over time.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在左上角的图表中第一件要注意的事情（“标签：正确/全部”）是各个增强类型有些混乱。我们的未增强和完全增强的运行位于该混乱的两侧。这意味着当结合时，我们的增强效果超过了其各部分之和。还有一个有趣的地方是，我们的完全增强运行得到了更多错误答案。虽然这通常是不好的，但如果我们看一下右侧的图像列（重点是我们实际关心的正候选样本--那些真正的结节），我们会发现我们的完全增强模型在查找正候选样本方面*要好得多*。完全增强模型的召回率很高！它也更不容易过拟合。正如我们之前看到的，我们的未增强模型随着时间的推移变得更糟。
- en: One interesting thing to note is that the noise-augmented model is *worse* at
    identifying nodules than the unaugmented model. This makes sense if we remember
    that we said noise makes the model’s job harder.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一点是，噪声增强模型在识别结节方面比未增强模型*更差*。如果我们记得我们说过噪声会让模型的工作变得更困难，这就说得通了。
- en: Another interesting thing to see in the live data (it’s somewhat lost in the
    jumble here) is that the rotation-augmented model is nearly as good as the fully
    augmented model when it comes to recall, and it has much better precision. Since
    our F1 score is precision limited (due to the higher number of negative samples),
    the rotation-augmented model also has a better F1 score.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时数据中看到的另一个有趣的事情（在这里有点混乱）是，旋转增强模型在召回方面几乎与完全增强模型一样好，并且在精度上有很大提高。由于我们的F1分数受精度限制（由于负样本数量较高），旋转增强模型的F1分数也更高。
- en: We’ll stick with the fully augmented model going forward, since our use case
    requires high recall. The F1 score will still be used to determine which epoch
    to save as the best. In a real-world project, we might want to devote extra time
    to investigating whether a different combination of augmentation types and parameter
    values could yield better results.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 未来我们将继续使用完全增强的模型，因为我们的用例需要高召回率。F1分数仍将用于确定哪个时期保存为最佳��在实际项目中，我们可能希望花费额外的时间来调查不同的增强类型和参数值组合是否能产生更好的结果。
- en: 12.7 Conclusion
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.7 结论
- en: We spent a lot of time and energy in this chapter reformulating how we think
    about our model’s performance. It’s easy to be misled by poor methods of evaluation,
    and it’s crucial to have a strong intuitive understanding of the factors that
    feed into evaluating a model well. Once those fundamentals are internalized, it’s
    much easier to spot when we’re being led astray.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们花了很多时间和精力重新构思我们对模型性能的看法。通过糟糕的评估方法很容易被误导，而且对评估模型的因素有强烈的直觉理解至关重要。一旦这些基本原理内化，就更容易发现我们何时被误导。
- en: We’ve also learned about how to deal with data sources that aren’t sufficiently
    populated. Being able to synthesize representative training samples is incredibly
    useful. Situations where we have too much training data are rare indeed!
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了如何处理数据源不足的情况。能够合成代表性的训练样本非常有用。确实很少有太多的训练数据的情况！
- en: Now that we have a classifier that is performing reasonably, we’ll turn our
    attention to automatically finding candidate nodules to classify. Chapter 13 will
    start there; then, in chapter 14, we will feed those candidates back into the
    classifier we developed here and venture into building one more classifier to
    tell malignant nodules from benign ones.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个表现合理的分类器，我们将把注意力转向自动查找候选结节进行分类。第13章将从那里开始；然后，在第14章中，我们将把这些候选者反馈到我们在这里开发的分类器中，并着手构建另一个分类器来区分恶性结节和良性结节。
- en: 12.8 Exercises
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.8 练习
- en: The F1 score can be generalized to support values other than 1.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F1分数可以推广支持除1以外的值。
- en: Read [https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score),
    and implement F2 and F0.5 scores.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读[https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score)，并实现F2和F0.5分数。
- en: Determine which of F1, F2, and F0.5 makes the most sense for this project. Track
    that value, and compare and contrast it with the F1 score. [⁶](#pgfId-1076133)
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定F1、F2和F0.5中哪个对这个项目最有意义。跟踪该值，并与F1分数进行比较和对比。[⁶](#pgfId-1076133)
- en: Implement a `WeightedRandomSampler` approach to balancing the positive and negative
    training samples for `LunaDataset` with `ratio_int` set to `0`.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现`WeightedRandomSampler`方法来平衡`LunaDataset`的正负训练样本，`ratio_int`设置为`0`。
- en: How did you get the required information about the class of each sample?
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您如何获取每个样本类别的所需信息？
- en: Which approach was easier? Which resulted in more readable code?
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种方法更容易？哪种导致更易读的代码？
- en: Experiment with different class-balancing schemes.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试不同的类平衡方案。
- en: What ratio results in the best score after two epochs? After 20?
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个时期后哪个比例得分最高？20个时期后呢？
- en: What if the ratio is a function of `epoch_ndx`?
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果比例是`epoch_ndx`的函数会怎样？
- en: Experiment with different data augmentation approaches.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试不同的数据增强方法。
- en: Can any of the existing approaches be made more aggressive (noise, offset, and
    so on)?
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可以使任何现有方法更具侵略性（噪声、偏移等）？
- en: Does the inclusion of noise augmentation help or hinder your training results?
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 噪声增强的包含是否有助于或妨碍您的训练结果？
- en: Are there other values that change this result?
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有其他值会改变这个结果？
- en: Research data augmentation that other projects have used. Are any applicable
    here?
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 研究其他项目使用的数据增强方法。这里有哪些适用的？
- en: Implement “mixup” augmentation for positive nodule candidates. Does it help?
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为正结节候选实现“mixup”增强。这有帮助吗？
- en: Change the initial normalization from `nn.BatchNorm` to something custom, and
    retrain the model.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将初始归一化从`nn.BatchNorm`更改为自定义内容，并重新训练模型。
- en: Can you get better results using fixed normalization?
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用固定归一化能获得更好的结果吗？
- en: What normalization offset and scale make sense?
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么归一化偏移和比例是有意义的？
- en: Do nonlinear normalizations like square roots help?
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非线性归一化如平方根是否有帮助？
- en: What other kinds of data can TensorBoard display besides those we’ve covered
    here?
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorBoard除了我们在这里介绍的内容之外还可以显示哪些其他数据？
- en: Can you have it display information about the weights of your network?
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能让它显示有关网络权重的信息吗？
- en: What about intermediate results from running your model on a particular sample?
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行模型对特定样本的中间结果时有什么？
- en: Does having the backbone of the model wrapped in an instance of `nn.Sequential`
    help or hinder this effort?
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型的骨干包装在`nn.Sequential`的实例中是否有助于或妨碍这一努力？
- en: 12.9 Summary
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.9 总结
- en: 'A binary label and a binary classification threshold combine to partition the
    dataset into four quadrants: true positives, true negatives, false negatives,
    and false positives. These four quantities provide the basis for our improved
    performance metrics.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制标签和二进制分类阈值结合在一起，将数据集分成四个象限：真正阳性、真正阴性、假阴性和假阳性。这四个量为我们改进的性能指标提供了基础。
- en: Recall is the ability of a model to maximize true positives. Selecting every
    single item guarantees perfect recall--because all the correct answers are included--but
    also exhibits poor precision.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回忆是模型最大化真正阳性的能力。选择每一个项目都能保证完美的回忆——因为所有正确答案都包括在内——但也表现出较低的精度。
- en: Precision is the ability of a model to minimize false positives. Selecting nothing
    guarantees perfect precision--because no incorrect answers are included--but also
    exhibits poor recall.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精度是模型最小化假阳性的能力。不选择任何内容保证了完美的精度——因为没有错误答案被包括在内——但也表现出较低的回忆。
- en: The F1 score combines precision and recall into a single metric that describes
    model performance. We use the F1 score to determine what impact changes to training
    or the model have on our performance.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1分数将精度和回忆结合成一个描述模型性能的单一指标。我们使用F1分数来确定对训练或模型进行的更改对我们的性能有何影响。
- en: Balancing the training set to have an equal number of positive and negative
    samples during training can result in the model performing better (defined as
    having a positive, increasing F1 score).
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练过程中平衡训练集，使得正负样本数量相等，可以使模型表现更好（定义为具有正的、增加的F1分数）。
- en: Data augmentation takes existing organic data samples and modifies them such
    that the resulting augmented sample is non-trivially different from the original,
    but remains representative of samples of the same class. This allows additional
    training without overfitting in situations where data is limited.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据增强是指采用现有的有机数据样本并对其进行修改，使得生成的增强样本与原始样本有明显不同，但仍代表同一类别的样本。这样可以在数据有限的情况下进行额外的训练而不会过拟合。
- en: Common data augmentation strategies include changes in orientation, mirroring,
    rescaling, shifting by an offset, and adding noise. Depending on the project,
    other more specific strategies may also be relevant.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的数据增强策略包括改变方向、镜像、重新缩放、偏移、添加噪音。根据项目的不同，其他更具体的策略也可能相关。
- en: '* * *'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)No one actually says this.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1.)没有人实际说过这个。
- en: ^(2.)If it’s taking longer than that, make sure you’ve run the `prepcache` script.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ^(2.)如果花费的时间超过这个时间，请确保您已运行`prepcache`脚本。
- en: ^(3.)Keep in mind that these images are just a representation of the classification
    space and do not represent ground truth.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ^(3.)请记住，这些图像只是分类空间的一种表示，不代表真实情况。
- en: ^(4.)It’s not clear if this is actually true, but it’s plausible, and the loss
    *was* getting better . . .
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ^(4.)目前尚不清楚这是否属实，但这是有可能的，而且损失*确实*在改善中……
- en: ^(5.)And remember that this is after only the 200,000 training samples presented,
    not the 500,000+ of the unbalanced dataset, so we got there in less than half
    the time.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ^(5.)请记住，这是在仅呈现了200,000个训练样本之后，而不是不平衡数据集的500,000+个样本之后，所以我们用了不到一半的时间就达到了这个结果。
- en: ^(6.)Yep, that’s a hint it’s not the F1 score!
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ^(6.)是的，这是一个暗示，这不是F1分数！
