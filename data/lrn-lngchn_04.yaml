- en: Chapter 4\. Using LangGraph to Add Memory to Your Chatbot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章\. 使用LangGraph为您的聊天机器人添加记忆
- en: In [Chapter 3](ch03.html#ch03_rag_part_ii_chatting_with_your_data_1736545666793580),
    you learned how to provide your AI chatbot application with up-to-date and relevant
    context. This enables your chatbot to generate accurate responses based on the
    user’s input. But that’s not enough to build a production-ready application. How
    can you enable your application to actually “chat” back and forth with the user,
    while remembering prior conversations and relevant context?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html#ch03_rag_part_ii_chatting_with_your_data_1736545666793580)中，你学习了如何为你的AI聊天机器人应用程序提供最新和相关的上下文。这使得你的聊天机器人能够根据用户的输入生成准确的响应。但这还不足以构建一个生产就绪的应用程序。你如何使你的应用程序能够真正地与用户“聊天”来回，同时记住先前的对话和相关的上下文？
- en: Large language models are *stateless*, which means that each time the model
    is prompted to generate a new response it has no memory of the prior prompt or
    model response. In order to provide this historical information to the model,
    we need a robust memory system that will keep track of previous conversations
    and context. This historical information can then be included in the final prompt
    sent to the LLM, thus giving it “memory.” [Figure 4-1](#ch04_figure_1_1736545668257395)
    illustrates this.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型是无状态的，这意味着每次模型被提示生成新的响应时，它都没有先前的提示或模型响应的记忆。为了向模型提供这些历史信息，我们需要一个稳健的记忆系统来跟踪之前的对话和上下文。然后，这些历史信息可以包含在发送给LLM的最终提示中，从而给它“记忆”。[图4-1](#ch04_figure_1_1736545668257395)展示了这一点。
- en: '![A diagram of a brain  Description automatically generated](assets/lelc_0401.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![大脑的图示  自动生成的描述](assets/lelc_0401.png)'
- en: Figure 4-1\. Memory and retrieval used to generate context-aware answers from
    an LLM
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1\. 用于从LLM生成上下文感知答案的记忆和检索
- en: In this chapter, you’ll learn how to build this essential memory system using
    LangChain’s built-in modules to make this development process easier.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何使用LangChain的内置模块构建这个基本记忆系统，以使开发过程更加容易。
- en: Building a Chatbot Memory System
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建聊天机器人记忆系统
- en: 'There are two core design decisions behind any robust memory system:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 任何稳健的记忆系统背后都有两个核心设计决策：
- en: How state is stored
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态是如何存储的
- en: How state is queried
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态是如何查询的
- en: 'A simple way to build a chatbot memory system that incorporates effective solutions
    to these design decisions is to store and reuse the history of all chat interactions
    between the user and the model. The state of this memory system can be:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个聊天机器人记忆系统，该系统包含对这些设计决策的有效解决方案的简单方法是将用户和模型之间所有聊天交互的历史存储并重用。这个记忆系统的状态可以是：
- en: Stored as a list of messages (refer to [Chapter 1](ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004)
    to learn more about messages)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储为消息列表（参考[第1章](ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004)了解更多关于消息的信息）
- en: Updated by appending recent messages after each turn
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每一轮之后附加最近的消息进行更新
- en: Appended into the prompt by inserting the messages into the prompt
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将消息插入到提示中附加到提示中
- en: '[Figure 4-2](#ch04_figure_2_1736545668257433) illustrates this simple memory
    system.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-2](#ch04_figure_2_1736545668257433)展示了这个简单的记忆系统。'
- en: '![A diagram of a memory  Description automatically generated](assets/lelc_0402.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![记忆的图示  自动生成的描述](assets/lelc_0402.png)'
- en: Figure 4-2\. A simple memory system utilizing chat history in prompts to generate
    model answers
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-2\. 利用提示中的聊天历史生成模型答案的简单记忆系统
- en: 'Here’s a code example that illustrates a simple version of this memory system
    using LangChain:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个代码示例，展示了使用LangChain的简单版本的这个记忆系统：
- en: '*Python*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*JavaScript*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*The output:*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note how the incorporation of the previous conversation in the chain enabled
    the model to answer the follow-up question in a context-aware manner.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，将之前的对话纳入链中使模型能够以上下文感知的方式回答后续问题。
- en: 'While this is simple and it works, when taking your application to production,
    you’ll face some more challenges related to managing memory at scale, such as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这很简单并且有效，但当你的应用程序投入生产时，你将面临一些与大规模管理记忆相关的更多挑战，例如：
- en: You’ll need to update the memory after every interaction, atomically (i.e.,
    don’t record only the question or only the answer in the case of failure).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要在每次交互后更新记忆，原子性地（即在失败的情况下不要只记录问题或只记录答案）。
- en: You’ll want to store these memories in durable storage, such as a relational
    database.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会想将这些记忆存储在持久存储中，例如关系数据库。
- en: You’ll want to control how many and which messages are stored for later, and
    how many of these are used for new interactions.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能希望控制存储以备后用的消息数量和类型，以及这些消息中有多少用于新的交互。
- en: You’ll want to inspect and modify this state (for now, just a list of messages)
    outside a call to an LLM.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能希望在调用 LLM 之外检查和修改此状态（目前只是一个消息列表）。
- en: We’ll now introduce some better tooling, which will help with this and all later
    chapters.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将介绍一些更好的工具，这些工具将有助于本章节和后续章节。
- en: Introducing LangGraph
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 LangGraph
- en: For the remainder of this chapter and the following chapters, we’ll start to
    make use of [LangGraph](https://oreil.ly/TKCb6), an open source library authored
    by LangChain. LangGraph was designed to enable developers to implement multiactor,
    multistep, stateful cognitive architectures, called *graphs*. That’s a lot of
    words packed into a short sentence; let’s take them one at a time. [Figure 4-3](#ch04_figure_3_1736545668257457)
    illustrates the multiactor aspect.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分和接下来的章节中，我们将开始使用 [LangGraph](https://oreil.ly/TKCb6)，这是一个由 LangChain
    编写的开源库。LangGraph 被设计用来使开发者能够实现多参与者、多步骤、状态化的认知架构，称为 *图*。这句话中包含了大量的词汇；让我们逐个解释。![图
    4-3](#ch04_figure_3_1736545668257457) 展示了多参与者方面。
- en: '![A diagram of a computer  Description automatically generated](assets/lelc_0403.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![计算机图  自动生成描述](assets/lelc_0403.png)'
- en: Figure 4-3\. From single-actor applications to multiactor applications
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 从单参与者应用到多参与者应用
- en: 'A team of specialists can build something together that none of them could
    build alone. The same is true of LLM applications: an LLM prompt (great for answer
    generation and task planning and many more things) is much more powerful when
    paired up with a search engine (best at finding current facts), or even when paired
    with different LLM prompts. We have seen developers build some amazing applications,
    like [Perplexity](https://oreil.ly/bVlu7) or [Arc Search](https://oreil.ly/NPOlF),
    when they combine those two building blocks (and others) in novel ways.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一支专家团队可以共同构建出他们单独无法完成的东西。对于 LLM 应用也是如此：一个 LLM 提示（非常适合答案生成和任务规划以及更多功能）当与搜索引擎（擅长查找当前事实）配对时，或者甚至与不同的
    LLM 提示配对时，会更有力量。我们已经看到开发者通过以新颖的方式结合这两个构建块（以及其他）构建了一些惊人的应用，例如 [Perplexity](https://oreil.ly/bVlu7)
    或 [Arc Search](https://oreil.ly/NPOlF)。
- en: 'And just as a human team needs more coordination than one person working by
    themselves, an application with multiple actors needs a coordination layer to
    do these things:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如一个团队需要比一个人单独工作更多的协调一样，一个具有多个参与者的应用需要一个协调层来完成这些事情：
- en: Define the actors involved (the nodes in a graph) and how they hand off work
    to each other (the edges in that graph).
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义涉及的参与者（图中的节点）以及它们如何相互传递工作（图中边的处理方式）。
- en: Schedule execution of each actor at the appropriate time—in parallel if needed—with
    deterministic results.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在适当的时间安排每个参与者的执行——如果需要，可以并行执行，并确保结果确定性。
- en: '[Figure 4-4](#ch04_figure_4_1736545668257478) illustrates the multistep dimension.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4-4](#ch04_figure_4_1736545668257478) 展示了多步骤维度。'
- en: '![A screenshot of a computer screen  Description automatically generated](assets/lelc_0404.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成描述](assets/lelc_0404.png)'
- en: Figure 4-4\. From multiactor to multistep applications
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 从多参与者到多步骤应用
- en: As each actor hands off work to another (for example, an LLM prompt asking a
    search tool for the results of a given search query), we need to make sense of
    the back-and-forth between multiple actors. We need to know what order it happens
    in, how many times each actor is called, and so on. To do this, we can model the
    interaction between the actors as happening across multiple discrete steps in
    time. When one actor hands off work to another actor, it results in the scheduling
    of the next step of the computation, and so on, until no more actors hand off
    work to others, and the final result is reached.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每个参与者将工作传递给另一个参与者（例如，一个 LLM 提示请求搜索工具提供特定搜索查询的结果），我们需要理解多个参与者之间的来回交互。我们需要知道它发生的顺序，每个参与者被调用的次数，等等。为此，我们可以将参与者之间的交互建模为在多个离散的时间步骤中发生。当一个参与者将工作传递给另一个参与者时，它会导致计算的下一步调度，依此类推，直到没有更多的参与者将工作传递给他人，最终结果达成。
- en: '[Figure 4-5](#ch04_figure_5_1736545668257500) illustrates the stateful aspect.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4-5](#ch04_figure_5_1736545668257500) 展示了状态化的方面。'
- en: '![A screenshot of a computer  Description automatically generated](assets/lelc_0405.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成描述](assets/lelc_0405.png)'
- en: Figure 4-5\. From multistep to stateful applications
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 从多步骤到状态化应用
- en: 'Communication across steps requires tracking some state—otherwise, when you
    call the LLM actor the second time, you’d get the same result as the first time.
    It is very helpful to pull this state out of each of the actors and have all actors
    collaborate on updating a single central state. With a single central state, we
    can:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤之间的通信需要跟踪一些状态——否则，当您第二次调用LLM演员时，您会得到与第一次相同的结果。将此状态从每个演员中提取出来，并让所有演员共同更新一个单一的中心状态非常有帮助。有了单一的中心状态，我们可以：
- en: Snapshot and store the central state during or after each computation.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每次计算期间或之后快照并存储中心状态。
- en: Pause and resume execution, which makes it easy to recover from errors.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暂停和恢复执行，这使得从错误中恢复变得容易。
- en: Implement human-in-the-loop controls (more on this in [Chapter 8](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600)).
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现人机交互控制（更多内容请参阅[第8章](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600)）。
- en: 'Each *graph* is then made up of the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每个*图*由以下内容组成：
- en: State
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 状态
- en: The data received from outside the application, modified and produced by the
    application while it’s running.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从应用程序外部接收的数据，在应用程序运行时由应用程序修改和生成。
- en: Nodes
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 节点
- en: Each step to be taken. Nodes are simply Python/JS functions, which receive the
    current state as input and can return an update to that state (that is, they can
    add to it and modify or remove existing data).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 每个要采取的步骤。节点只是Python/JS函数，它们接收当前状态作为输入，并可以返回对那个状态的更新（即，它们可以添加到它并修改或删除现有数据）。
- en: Edges
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 边
- en: The connections between nodes. Edges determine the path taken from the first
    node to the last, and they can be fixed (that is, after Node B, always visit node
    D) or conditional (evaluate a function to decide the next node to visit after
    node C).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 节点之间的连接。边决定了从第一个节点到最后一个节点所采取的路径，它们可以是固定的（即，在节点B之后，总是访问节点D）或条件性的（评估一个函数以决定在节点C之后访问的下一个节点）。
- en: LangGraph offers utilities to visualize these graphs and numerous features to
    debug their workings while in development. These graphs can then easily be deployed
    to serve production workloads at high scale.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: LangGraph提供了可视化这些图和许多在开发期间调试其工作方式的特性的工具。然后可以轻松地将这些图部署到以高规模处理生产工作负载。
- en: 'If you followed the instructions in [Chapter 1](ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004),
    you’ll already have LangGraph installed. If not, you can install it by running
    one of the following commands in your terminal:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遵循了[第1章](ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004)中的说明，您已经安装了LangGraph。如果没有，您可以在终端运行以下命令之一来安装它：
- en: '*Python*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*JavaScript*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To help get you familiar with using LangGraph, we’ll create a simple chatbot
    using LangGraph, which is a great example of the LLM call architecture with a
    single use of an LLM. This chatbot will respond directly to user messages. Though
    simple, it does illustrate the core concepts of building with LangGraph.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您熟悉使用LangGraph，我们将使用LangGraph创建一个简单的聊天机器人，LangGraph是一个使用单个LLM调用的LLM调用架构的绝佳示例。这个聊天机器人将直接响应用户的消息。虽然简单，但它确实展示了使用LangGraph构建的核心概念。
- en: Creating a StateGraph
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建状态图
- en: 'Start by creating a `StateGraph`. We’ll add a node to represent the LLM call:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个`StateGraph`。我们将添加一个节点来表示LLM调用：
- en: '*Python*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*JavaScript*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The first thing you do when you define a graph is define the state of the graph.
    The *state* consists of the shape, or schema, of the graph state, as well as reducer
    functions that specify how to apply updates to the state. In this example, the
    state is a dictionary with a single key: `messages`. The `messages` key is annotated
    with the `add_messages` reducer function, which tells LangGraph to append new
    messages to the existing list, rather than overwrite it. State keys without an
    annotation will be overwritten by each update, storing the most recent value.
    You can write your own reducer functions, which are simply functions that receive
    as arguments—argument 1 is the current state, and argument 2 is the next value
    being written to the state—and should return the next state, that is, the result
    of merging the current state with the new value. The simplest example is a function
    that appends the next value to a list and returns that list.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当你定义一个图时，你首先定义图的初始状态。*状态*由图的形状或模式以及指定如何应用更新到状态的还原器函数组成。在这个例子中，状态是一个包含单个键的字典：`messages`。`messages`键用`add_messages`还原器函数进行了注释，它告诉LangGraph将新消息追加到现有列表中，而不是覆盖它。没有注释的状态键将被每个更新覆盖，存储最新的值。你可以编写自己的还原器函数，这些函数只是接收作为参数的函数——参数1是当前状态，参数2是要写入状态的新值——并应该返回下一个状态，即合并当前状态和新值的结果。最简单的例子是一个函数，它将下一个值追加到列表中并返回该列表。
- en: 'So now our graph knows two things:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此现在我们的图知道了两件事：
- en: Every `node` we define will receive the current `State` as input and return
    a value that updates that state.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义的每个`node`都将接收当前的`State`作为输入，并返回一个更新该状态的值。
- en: '`messages` will be *appended* to the current list, rather than directly overwritten.
    This is communicated via the prebuilt [`add_messages`](https://oreil.ly/sK-Ry)
    function in the `Annotated` syntax in the Python example or the reducer function
    for the JavaScript example.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages`将被*追加*到当前列表中，而不是直接覆盖。这通过Python示例中的预构建的`add_messages`函数或JavaScript示例中的还原器函数来传达。'
- en: 'Next, add the `chatbot` node. Nodes represent units of work. They are typically
    just functions:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，添加`chatbot`节点。节点代表工作单元。它们通常是函数：
- en: '*Python*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*JavaScript*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This node receives the current state, does one LLM call, and then returns an
    update to the state containing the new message produced by the LLM. The `add_messages`
    reducer appends this message to the messages already in the state.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个节点接收当前状态，进行一次LLM调用，然后返回一个包含LLM产生的新消息的状态更新。`add_messages`还原器函数将此消息追加到状态中已有的消息列表。
- en: 'And finally let’s add the edges:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们添加边：
- en: '*Python*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*JavaScript*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This does a few things:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这会做几件事：
- en: It tells the graph where to start its work each time you run it.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次运行它时，它都会告诉图从哪里开始工作。
- en: This instructs the graph where it should exit (this is optional, as LangGraph
    will stop execution once there’s no more nodes to run).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这指示图在哪里应该退出（这是可选的，因为LangGraph会在没有更多节点可以运行时停止执行）。
- en: It compiles the graph into a runnable object, with the familiar `invoke` and
    `stream` methods.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将图编译成一个可运行的对象，具有熟悉的`invoke`和`stream`方法。
- en: 'We can also draw a visual representation of the graph:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以绘制出该图的视觉表示：
- en: '*Python*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*JavaScript*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The graph we just made looks like [Figure 4-6](#ch04_figure_6_1736545668257524).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚创建的图看起来像[图 4-6](#ch04_figure_6_1736545668257524)。
- en: '![A diagram of a chatbot  Description automatically generated](assets/lelc_0406.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![聊天机器人的示意图  自动生成的描述](assets/lelc_0406.png)'
- en: Figure 4-6\. A simple chatbot
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. 一个简单的聊天机器人
- en: 'You can run it with the familiar `stream()` method you’ve seen in earlier chapters:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用熟悉的`stream()`方法运行它，你已经在前面的章节中见过：
- en: '*Python*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*JavaScript*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*The output:*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice how the input to the graph was in the same shape as the `State` object
    we defined earlier; that is, we sent in a list of messages in the `messages` key
    of a dictionary. In addition, the `stream` function streams the full value of
    the state after each step of the graph.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到输入到图中的数据与我们在前面定义的`State`对象具有相同的形状；也就是说，我们通过字典的`messages`键发送了一个消息列表。此外，`stream`函数在图的每一步之后都会流式传输状态的完整值。
- en: Adding Memory to StateGraph
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将内存添加到StateGraph
- en: 'LangGraph has built-in persistence, which is used in the same way for the simplest
    graph to the most complex. Let’s see what it looks like to apply it to this first
    architecture. We’ll recompile our graph, now attaching a *checkpointer*, which
    is a storage adapter for LangGraph. LangGraph ships with a base class that any
    user can subclass to create an adapter for their favorite database; at the time
    of writing, LangGraph ships with several adapters maintained by LangChain:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LangGraph 内置了持久化功能，这种功能适用于从最简单的图到最复杂的图，使用方式相同。让我们看看将其应用于第一个架构会是什么样子。我们将重新编译我们的图，现在附加一个
    *checkpointer*，这是一个 LangGraph 的存储适配器。LangGraph 随附一个基类，任何用户都可以扩展它来为他们的首选数据库创建适配器；在撰写本文时，LangGraph
    随附由 LangChain 维护的几个适配器：
- en: An in-memory adapter, which we’ll use for our examples here
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个内存中的适配器，我们将用它来展示我们的示例
- en: A SQLite adapter, using the popular in-process database, appropriate for local
    apps and testing
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个使用流行的进程内数据库 SQLite 的适配器，适用于本地应用程序和测试
- en: A Postgres adapter, optimized for the popular relational database and appropriate
    for large-scale applications.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个针对流行的关系型数据库优化的 Postgres 适配器，适用于大型应用程序。
- en: 'Many developers have written adapters for other database systems, such as Redis
    or MySQL:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者已经为其他数据库系统编写了适配器，例如 Redis 或 MySQL：
- en: '*Python*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE16]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*JavaScript*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This returns a runnable object with the same methods as the one used in the
    previous code block. But now, it stores the state at the end of each step, so
    every invocation after the first doesn’t start from a blank slate. Any time the
    graph is called, it starts by using the checkpointer to fetch the most recent
    saved state, if any, and combines the new input with the previous state. And only
    then does it execute the first nodes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了一个具有与上一个代码块中使用的相同方法的可运行对象。但现在，它在每个步骤结束时存储状态，因此第一次调用之后的每次调用都不从空白状态开始。每次调用图时，它首先使用检查点器获取最新的保存状态（如果有的话），并将新输入与之前的状态结合。然后才执行第一个节点。
- en: 'Let’s see the difference in action:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实际操作中的区别：
- en: '*Python*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*JavaScript*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice the object `thread1`, which identifies the current interaction as belonging
    to a particular history of interactions—which are called *threads* in LangGraph.
    Threads are created automatically when first used. Any string is a valid identifier
    for a thread (usually, Universally Unique Identifiers [UUIDs] are used). The existence
    of threads helps you achieve an important milestone in your LLM application; it
    can now be used by multiple users with independent conversations that are never
    mixed up.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 注意对象 `thread1`，它标识当前交互属于特定的交互历史——在 LangGraph 中这些交互历史被称为 *threads*。当首次使用时，会自动创建线程。任何字符串都是线程的有效标识符（通常，使用通用唯一识别码
    [UUIDs]）。线程的存在有助于你在你的 LLM 应用程序中实现一个重要的里程碑；现在它可以被多个用户使用，每个用户都有独立的对话，这些对话永远不会混淆。
- en: As before, the `chatbot` node is first called with a single message (the one
    we just passed in) and returns another message, both of which are then saved in
    the state.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`chatbot` 节点首先被调用，带有一条消息（我们刚刚传递的），然后返回另一条消息，这两条消息随后都保存在状态中。
- en: 'The second time we execute the graph on the same thread, the `chatbot` node
    is called with three messages, the two saved from the first execution, and the
    next question from the user. This is the essence of memory: the previous state
    is still there, which makes it possible, for instance, to answer questions about
    something said before (and do many more interesting things, of which we will see
    more later).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次我们在同一线程上执行图时，`chatbot` 节点被调用，带有三条消息，两条是从第一次执行中保存的，以及用户提出的下一个问题。这就是记忆的本质：前一个状态仍然存在，这使得例如回答关于之前所说的事情的问题（以及做更多有趣的事情）成为可能。
- en: 'You can also inspect and update the state directly; let’s see how:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以直接检查和更新状态；让我们看看如何：
- en: '*Python*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*JavaScript*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This returns the current state of this thread.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了此线程的当前状态。
- en: 'And you can update the state like this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像这样更新状态：
- en: '*Python*'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE22]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*JavaScript*'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This would add one more message to the list of messages in the state, to be
    used the next time you invoke the graph on this thread.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在状态中的消息列表中添加一条新消息，以便在下一次你在该线程上调用图时使用。
- en: Modifying Chat History
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改聊天历史
- en: 'In many cases, the chat history messages aren’t in the best state or format
    to generate an accurate response from the model. To overcome this problem, we
    can modify the chat history in three main ways: trimming, filtering, and merging
    messages.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，聊天历史中的消息可能不是最佳状态或格式，无法从模型生成准确的响应。为了克服这个问题，我们可以通过三种主要方式修改聊天历史：修剪、过滤和合并消息。
- en: Trimming Messages
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修剪消息
- en: LLMs have limited *context windows*; in other words, there is a maximum number
    of tokens that LLMs can receive as a prompt. As such, the final prompt sent to
    the model shouldn’t exceed that limit (particular to each mode), as models will
    either refuse an overly long prompt or truncate it. In addition, excessive prompt
    information can distract the model and lead to hallucination.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 有有限的 *上下文窗口*；换句话说，LLMs 可以作为提示接收的最大令牌数是有限的。因此，发送给模型的最终提示不应超过该限制（针对每个模式特定），因为模型要么拒绝过长的提示，要么将其截断。此外，过多的提示信息可能会分散模型的注意力并导致幻觉。
- en: An effective solution to this problem is to limit the number of messages that
    are retrieved from chat history and appended to the prompt. In practice, we need
    only to load and store the most recent messages. Let’s use an example chat history
    with some preloaded messages.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 解决此问题的有效方法是对从聊天历史中检索并附加到提示中的消息数量进行限制。在实践中，我们只需要加载和存储最新的消息。让我们使用一个带有一些预加载消息的示例聊天历史。
- en: Fortunately, LangChain provides the built-in `trim_messages` helper that incorporates
    various strategies to meet these requirements. For example, the trimmer helper
    enables specifying how many tokens we want to keep or remove from chat history.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，LangChain 提供了内置的 `trim_messages` 辅助函数，它包含各种策略以满足这些要求。例如，修剪器辅助函数允许指定我们想要从聊天历史中保留或删除的令牌数量。
- en: 'Here’s an example that retrieves the last `max_tokens` in the list of messages
    by setting a strategy parameter to `"last"`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，通过将策略参数设置为 `"last"` 来检索列表中最后 `max_tokens` 的消息：
- en: '*Python*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '*JavaScript*'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE25]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '*The output:*'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出结果：*'
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Note the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下内容：
- en: The parameter `strategy` controls whether to start from the beginning or the
    end of the list. Usually, you’ll want to prioritize the most recent messages and
    cut older messages if they don’t fit. That is, start from the end of the list.
    For this behavior, choose the value `last`. The other available option is `first`,
    which would prioritize the oldest messages and cut more recent messages if they
    don’t fit.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 `strategy` 控制是否从列表的开始或结束处开始。通常，您会希望优先考虑最新的消息，并在消息不合适时删除较旧的消息。也就是说，从列表的末尾开始。为此行为，选择值
    `last`。另一个可用的选项是 `first`，这将优先考虑最旧的消息，并在消息不合适时删除较新的消息。
- en: The `token_counter` is an LLM or chat model, which will be used to count tokens
    using the tokenizer appropriate to that model.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token_counter` 是一个 LLM 或聊天模型，它将使用适合该模型的分词器来计数令牌。'
- en: We can add the parameter `include_system=True` to ensure that the trimmer keeps
    the system message.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以添加参数 `include_system=True` 来确保修剪器保留系统消息。
- en: The parameter `allow_partial` determines whether to cut the last message’s content
    to fit within the limit. In our example, we set this to `false`, which completely
    removes the message that would send the total over the limit.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 `allow_partial` 决定是否截断最后一条消息的内容以适应限制。在我们的示例中，我们将此设置为 `false`，这将完全删除会导致总数超过限制的消息。
- en: The parameter `start_on="human"` ensures that we never remove an `AIMessage`
    (that is, a response from the model) without also removing a corresponding `HumanMessage`
    (the question for that response).
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数 `start_on="human"` 确保我们永远不会在没有删除相应的 `HumanMessage`（即对该响应的问题）的情况下删除 `AIMessage`（即模型的响应）。
- en: Filtering Messages
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过滤消息
- en: As the list of chat history messages grows, a wider variety of types, subchains,
    and models may be utilized. LangChain’s `filter_messages` helper makes it easier
    to filter the chat history messages by type, ID, or name.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 随着聊天历史消息列表的增长，可能会使用更多种类的类型、子链和模型。LangChain 的 `filter_messages` 辅助函数使得通过类型、ID
    或名称过滤聊天历史消息变得更容易。
- en: 'Here’s an example where we filter for human messages:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，其中我们过滤出人类消息：
- en: '*Python*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE27]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*JavaScript*'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*The output:*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出结果：*'
- en: '[PRE29]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s try another example where we filter to exclude users and IDs, and include
    message types:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试另一个示例，其中我们过滤以排除用户和 ID，并包括消息类型：
- en: '*Python*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE30]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '*JavaScript*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE31]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `filter_messages` helper can also be used imperatively or declaratively,
    making it easy to compose with other components in a chain:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter_messages` 辅助函数也可以用命令式或声明式的方式使用，这使得与其他组件链式组合变得容易：'
- en: '*Python*'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE32]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '*JavaScript*'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Merging Consecutive Messages
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合并连续消息
- en: 'Certain models don’t support inputs, including consecutive messages of the
    same type (for instance, Anthropic chat models). LangChain’s `merge_message_runs`
    utility makes it easy to merge consecutive messages of the same type:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 某些模型不支持输入，包括相同类型的连续消息（例如，Anthropic聊天模型）。LangChain的`merge_message_runs`实用工具使得合并相同类型的连续消息变得容易：
- en: '*Python*'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE34]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '*JavaScript*'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE35]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '*The output:*'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE36]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Notice that if the contents of one of the messages to merge is a list of content
    blocks, then the merged message will have a list of content blocks. And if both
    messages to merge have string contents, then those are concatenated with a newline
    character.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果要合并的消息之一的内容是内容块列表，则合并后的消息将有一个内容块列表。如果两个要合并的消息都有字符串内容，则它们将使用换行符连接。
- en: 'The `merge_message_runs` helper can be used imperatively or declaratively,
    making it easy to compose with other components in a chain:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`merge_message_runs`辅助函数可以用命令式或声明式方式使用，这使得它很容易与其他组件链式组合：'
- en: '*Python*'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE37]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '*JavaScript*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE38]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered the fundamentals of building a simple memory system that
    enables your AI chatbot to remember its conversations with a user. We discussed
    how to automate the storage and updating of chat history using LangGraph to make
    this easier. We also discussed the importance of modifying chat history and explored
    various strategies to trim, filter, and summarize chat messages.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了构建一个简单的记忆系统的基本原理，该系统能够让你的AI聊天机器人记住与用户的对话。我们讨论了如何使用LangGraph自动化存储和更新聊天历史，使其更容易实现。我们还讨论了修改聊天历史的重要性，并探讨了修剪、过滤和总结聊天消息的各种策略。
- en: 'In [Chapter 5](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774),
    you’ll learn how to enable your AI chatbot to do more than just chat back: for
    instance, your new model will be able to make decisions, pick actions, and reflect
    on its past outputs.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)，你将学习如何让你的AI聊天机器人不仅仅能进行聊天：例如，你的新模型将能够做出决策、选择动作，并对其过去的输出进行反思。
