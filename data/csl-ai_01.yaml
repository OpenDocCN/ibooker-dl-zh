- en: 1 Why causal AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 为什么因果AI
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Defining causal AI and its benefits
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义因果AI及其益处
- en: Incorporating causality into machine learning models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将因果纳入机器学习模型
- en: A simple example of applying causality to a machine learning model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将因果应用到机器学习模型的一个简单例子
- en: Subscription streaming platforms like Netflix are always looking for ways to
    optimize various indicators of performance. One of these is their *churn rate*,
    meaning the rate at which they lose subscribers. Imagine that you are a machine
    learning engineer or data scientist at Netflix tasked with finding ways of reducing
    churn. What are the types of *causal questions* (questions that require causal
    thinking) you might ask with respect to this task?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅流媒体平台如Netflix总是在寻找优化各种性能指标的方法。其中之一就是他们的*流失率*，即他们失去订阅者的速度。想象一下，你是一名Netflix的机器学习工程师或数据科学家，负责寻找减少用户流失的方法。针对这项任务，你可能会问哪些类型的*因果问题*（需要因果思考的问题）？
- en: '*Causal discovery*—Given detailed data on who churned and who did not, can
    you analyze that data to find causes of the churn? *Causal discovery* investigates
    what causes what.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果发现*——给定关于谁流失和谁没有流失的详细数据，你能分析这些数据以找到导致流失的原因吗？*因果发现*研究什么原因导致什么。'
- en: '*Estimating average treatment effects* (ATEs)—Suppose the algorithm that recommends
    content to the user is a cause of the churn; a better choice of algorithm might
    reduce churn, but by how much? The task of quantifying how much, on average, a
    cause drives an effect is the *ATE estimation*. For example, some users could
    be exposed to a new version of the algorithm, and you could measure how much this
    affects churn, relative to the baseline algorithm.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*估计平均处理效应*（ATEs）——假设向用户推荐内容的算法是导致用户流失的原因；选择更好的算法可能会减少用户流失，但减少多少呢？量化平均而言，一个原因如何驱动一个效果的任务就是*ATE估计*。例如，一些用户可能接触到算法的新版本，你可以测量这相对于基线算法对用户流失的影响有多大。'
- en: Let’s go a bit deeper. The mockumentary *The Office* (the American version)
    was one of the most popular shows on Netflix. Later, Netflix learned that NBCUniversal
    was planning to stop licensing the show to Netflix to stream in the US, so that
    US streaming of The Office would be exclusive to NBCUniversal’s rival streaming
    platform, Peacock. Given the popularity of the show, churn was certainly affected,
    but by how much?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入一点。纪录片*办公室*（美国版）是Netflix上最受欢迎的节目之一。后来，Netflix了解到NBCUniversal计划停止向Netflix许可该节目在美国流媒体播放，因此美国对*办公室*的流媒体播放将独家属于NBCUniversal的竞争对手流媒体平台Peacock。鉴于该节目的受欢迎程度，流失率肯定受到影响，但影响有多大？
- en: '*Estimating conditional average treatment effects* (CATEs) —The effect of losing
    *The Office* would be more pronounced for some subscriber segments than others,
    but what attributes define these segments? One attribute is certainly having watched
    the show, but there are others (demographics, other content watched, etc.). *CATE
    estimation* is the task of quantifying how much a cause drives an effect for a
    particular segment of the population. Indeed, there are likely multiple segments
    we could define, each with a different within-segment ATE. Part of the task of
    CATE estimation is finding distinct segments of interest.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*估计条件平均处理效应*（CATEs）——失去*办公室*的影响对某些订阅者群体可能比其他群体更明显，但定义这些群体的属性是什么？一个属性当然是看过这个节目，但还有其他属性（人口统计信息、观看的其他内容等）。*CATE估计*的任务是量化一个原因对特定人口群体中一个效果的影响程度。实际上，我们可能定义了多个群体，每个群体有不同的组内ATE。CATE估计任务的一部分是找到感兴趣的特定群体。'
- en: Suppose you had reliable data on subscribers who quit Netflix and signed up
    for Peacock to continue watching *The Office*. For some of these users, the recommendation
    algorithm failed to show them possible substitutes for *The Office*, like the
    mockumentary *Parks and Recreation*. That may lead to a different type of question.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你拥有关于那些退出Netflix并注册Peacock以继续观看*办公室*的订阅者的可靠数据。对于这些用户中的某些人，推荐算法未能向他们展示*办公室*的可能替代品，如纪录片*公园与游憩*。这可能会引出不同类型的问题。
- en: '*Counterfactual reasoning and attribution*—If the algorithm had placed *Parks
    and Recreation* more prominently in those users’ dashboards, would they have stayed
    on with Netflix? These *counterfactual questions* (“counter” to the “fact” that
    the show wasn’t prominent in their dashboard) are essential for *attribution*
    (assigning a root cause and credit/blame for an outcome).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*反事实推理和归因*——如果算法在那些用户的仪表板上更突出地放置了*《公园与游憩》*，他们是否会继续使用Netflix？这些*反事实问题*（“反”对“事实”即该节目在他们的仪表板上并不突出）对于*归因*（分配根本原因和结果的责任/责备）至关重要。'
- en: 'Netflix worked with Steve Carrel (star of *The Office*) and Greg Daniels (writer,
    director, and producer of *The Office*) to create the show *Space Force* as Netflix
    original content. The show was released just months before *The Office* moved
    to Peacock. Suppose that this show was Netflix’s attempt to create content to
    retain subscribers who were fans of *The Office*. Consider the decisions that
    would go into the creation of such a show:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix与史蒂夫·卡瑞尔（*《办公室》*明星）和格雷格·丹尼尔斯（*《办公室》*的编剧、导演和制片人）合作，创建了Netflix原创内容《太空部队》。该剧在*《办公室》*移至Peacock几个月前发布。假设这部剧是Netflix试图为*《办公室》*粉丝保留订阅者的内容尝试。考虑创作此类节目会涉及到的决策：
- en: '*Causal decision theory*—What actors/directors/writers would tempt *The Office*
    fans to stay subscribed? What themes and content?'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果决策理论*——哪些演员/导演/编剧会吸引*《办公室》*粉丝继续订阅？哪些主题和内容？'
- en: '*Causal machine learning*—How could we use generative AI, such as large language
    models to create scripts and pilots for the show in such a way that optimizes
    for the objective of reducing churn amongst fans of *The Office*?'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果机器学习*——我们如何利用生成式AI，例如大型语言模型，来创建节目脚本和试点，从而优化减少《办公室》粉丝流失的目标？'
- en: '*Causal* *inference* is about breaking down a problem into these types of specific
    *causal queries*, and then using data to answer these queries. *Causal AI* is
    about building algorithms that automate this analysis. We’ll tackle both of these
    problem areas in this book.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果推断*是将问题分解为这些类型的特定*因果查询*，然后使用数据来回答这些查询。*因果AI*是关于构建自动化这种分析的算法。本书我们将探讨这两个问题领域。'
- en: 1.1 What is causal AI?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 什么是因果AI？
- en: To understand what causal AI is, we’ll start with the basic ideas of causality
    and causal inference, and work our way up. Then we’ll review the kinds of problems
    we can solve with causal AI.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解因果AI是什么，我们将从因果性和因果推断的基本概念开始，逐步深入。然后我们将回顾我们可以用因果AI解决的问题类型。
- en: '*Causal reasoning* is a crucial element of how humans understand, explain,
    and make decisions about the world. Anytime we think about cause (“Why did that
    happen?”) or effect (“What will happen if I do this?”), we are practicing causal
    reasoning.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果推理*是人类理解、解释和关于世界做出决策的关键要素。每当我们在思考原因（“为什么会发生这样的事情？”）或结果（“如果我这样做会发生什么？”）时，我们都在进行因果推理。'
- en: In statistics and machine learning, we use data to lend statistical rigor to
    our causal reasoning. But while cause-and-effect relationships drive the data,
    statistical correlation alone is insufficient to draw causal conclusions from
    data. For this, we must turn to *causal inference*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和机器学习中，我们使用数据为我们的因果推理提供统计严谨性。但尽管因果关系驱动数据，仅凭统计相关性本身不足以从数据中得出因果结论。为此，我们必须转向*因果推断*。
- en: Statistical (non-causal) inference relies on statistical assumptions. This is
    true even in deep learning, where assumptions are often called “inductive bias.”
    Similarly, causal inference relies on causal assumptions; causal inference refers
    to a body of theory and practical methods that constrain statistical analysis
    with causal assumptions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 统计（非因果）推断依赖于统计假设。即使在深度学习中，假设通常被称为“归纳偏差”，这也是正确的。同样，因果推断依赖于因果假设；因果推断指的是一系列理论和实用方法，这些方法通过因果假设来约束统计分析。
- en: '*Causal AI* refers to the automation of causal inference. We can leverage machine
    learning algorithms, which have developed robust approaches to automating statistical
    analyses and scale up to large amounts of data of different modalities.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*因果AI*指的是因果推断的自动化。我们可以利用机器学习算法，这些算法已经发展出自动化统计分析的稳健方法，并能够扩展到不同模态的大量数据。'
- en: The goal of AI is automating reasoning tasks that until now have required human
    intelligence to solve. Humans rely heavily on causal reasoning to navigate the
    world, and while we are better at causal reasoning than statistical reasoning,
    our cognitive biases still make our causal reasoning highly error prone. Improving
    our ability to answer causal questions has been the work of millennia of philosophers,
    centuries of scientists, and decades of statisticians. But now, a convergence
    of statistical and computational advances has shifted the focus from discourse
    to algorithms that we can train on data and deploy to software. It is a fascinating
    time to learn how to build causal AI.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的目标是自动化需要人类智能解决的问题的推理任务。人类在导航世界时严重依赖因果推理，尽管我们在因果推理上比在统计推理上更擅长，但我们的认知偏差仍然使我们的因果推理高度易出错。提高我们回答因果问题的能力是哲学家千年来的工作，科学家数百年的工作，以及统计学家数十年的工作。但现在，统计和计算进步的融合已经将重点从话语转向了我们可以基于数据进行训练并在软件中部署的算法。这是一个学习如何构建因果AI的迷人时期。
- en: Key definitions underpinning causal AI
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 构建因果AI的基础关键定义
- en: '*Inference*—Drawing conclusions from observations and data'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*推理*—从观察和数据中得出结论'
- en: '*Assumptions*—Constraints that guide inferences'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*假设*—指导推理的约束'
- en: '*Inductive biases*—Another word for *assumptions*, often used to refer to assumptions
    implicit in the choice of machine learning algorithm'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*归纳偏差*—假设的另一种说法，通常用来指代机器学习算法选择中隐含的假设'
- en: '*Statistical model*—A framework using statistical assumptions to analyze data'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*统计模型*—使用统计假设来分析数据的框架'
- en: '*Data science*—An interdisciplinary field that uses statistical models along
    with other algorithms and techniques to extract insights and knowledge from structured
    and unstructured data'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据科学*—一个跨学科领域，使用统计模型以及其他算法和技术从结构化和非结构化数据中提取见解和知识'
- en: '*Causal inference*—Techniques that use causal assumptions to guide conclusions'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果推理*—使用因果假设来指导结论的技术'
- en: '*Causal model*—A statistical model built on causal assumptions about data generation'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果模型*—基于数据生成因果假设的统计模型'
- en: '*Causal data science*—Data science that employs causal models to extract causal
    insights'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果数据科学*—使用因果模型提取因果见解的数据科学'
- en: '*Causal AI*—Algorithms that automate causal inference tasks using causal models'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因果AI*—使用因果模型自动执行因果推理任务的算法'
- en: 1.2 How this book approaches causal inference
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 本书如何处理因果推理
- en: 'The goal of this book is the fusion of two powerful domains: causality and
    AI. By the end of this journey, you’ll be equipped with the skills to'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是两个强大领域的融合：因果性和AI。通过这次旅程的结束，你将具备以下技能：
- en: '*Design AI systems with causal capabilities*—Harness the power of AI, but with
    an added layer of causal reasoning.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设计具有因果能力的AI系统*—利用AI的力量，但增加一层因果推理。'
- en: '*Use machine learning frameworks for causal inference*—Utilize tools like PyTorch
    and other Python libraries to seamlessly integrate causal modeling into your projects.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用机器学习框架进行因果推理*—利用PyTorch和其他Python库等工具，无缝地将因果建模集成到您的项目中。'
- en: '*Build tools for automated causal decision-making*—Implement causal decision-making
    algorithms, including causal reinforcement learning algorithms.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建自动化因果决策工具*—实现因果决策算法，包括因果强化学习算法。'
- en: Historically, causality and AI evolved from different bodies of research, they
    have been applied to different problems, and they have led to experts with different
    skill sets, books that use different languages, and libraries with different abstractions.
    This book is for anyone who wants to connect these domains into one comprehensive
    skill set.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，因果性和AI来自不同的研究领域，它们被应用于不同的问题，导致了具有不同技能集的专家、使用不同语言的书籍和具有不同抽象的库。本书是为任何希望将这些领域连接成一个综合技能集的人而写的。
- en: There are many books on causal inference, including books that focus on causal
    inference in Python. The following subsections discuss some features that make
    this book unique.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于因果推理有许多书籍，包括专注于Python中因果推理的书籍。以下小节讨论了使本书独特的某些特点。
- en: 1.2.1 Emphasis on AI
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 重视AI
- en: This book focuses on causal AI. We’ll cover not just the relevance of causal
    inference to AI, or how machine learning can scale up causal inference, but also
    focus on implementation. Specifically, we’ll integrate causal models with conventional
    models and training procedures from probabilistic machine learning.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本书专注于因果人工智能。我们将不仅涵盖因果推理对人工智能的相关性，或者机器学习如何扩展因果推理，还将关注实施。具体来说，我们将把因果模型与概率机器学习中的传统模型和训练程序相结合。
- en: 1.2.2 Focus on tech, retail, and business
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 专注于技术、零售和商业
- en: Practical causal inference methods have developed from econometrics, public
    health, social sciences, and other domains where it is difficult to run randomized
    experiments. As a result, examples in most books tend to come from those domains.
    In contrast, this book leans heavily into examples from tech, retail, and business.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 实践中的因果推理方法已从计量经济学、公共卫生、社会科学和其他难以进行随机实验的领域发展而来。因此，大多数书籍中的例子往往来自这些领域。相比之下，本书大量引用了来自技术、零售和商业的例子。
- en: 1.2.3 Parallel world counterfactuals and other queries beyond causal effects
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 平行世界反事实及其他超越因果效应的查询
- en: When many think of “causal inference,” they think of estimating causal effects,
    namely average treatment effects (ATEs) and conditional average treatment effects
    (CATEs). These are certainly important queries, but there are other kinds of causal
    queries as well. This book gives due attention to these other types.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当许多人想到“因果推理”时，他们会想到估计因果效应，即平均处理效应（ATEs）和条件平均处理效应（CATEs）。这些当然很重要，但也有其他类型的因果查询。本书对这些其他类型给予了适当的关注。
- en: For example, this book provides in-depth coverage of the *parallel worlds* account
    of counterfactuals. In this approach, when some cause and some effect occur, we
    imagine a parallel universe where the causal event was different. For example,
    suppose you asked, “I married for money and now I’m sad. Would I have been happier
    had I married for love?” With our parallel worlds approach, you’d use your experience
    of marrying for money and being sad as inputs to a causal model-based probabilistic
    simulation of your happiness in a parallel universe where you married for love.
    This type of reasoning is useful in decision-making. For example, it might help
    you choose a better spouse next time.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，本书深入探讨了反事实的“平行世界”解释。在这种方法中，当某些原因和某些效果发生时，我们想象一个因果事件不同的平行宇宙。例如，假设你问，“我为了钱而结婚现在很伤心。如果我为了爱情而结婚，我会更快乐吗？”在我们的平行世界方法中，你会用你为了钱而结婚并感到悲伤的经历作为输入，对你在爱情婚姻的平行宇宙中的幸福感进行基于因果模型概率模拟。这种推理在决策中很有用。例如，它可能帮助你下次选择更好的伴侣。
- en: Hopefully this example of love and regret illustrates how fundamental this kind
    of “what could have been” thinking is to human cognition (we’ll see more applied
    examples in chapters 8 and 9). It therefore makes sense to learn how to build
    AI with the same capabilities. But although they’re useful, some counterfactual
    inferences are hard or impossible to verify (you *can’t* prove you would have
    been happier if you had married for love). Most causal inference books only focus
    on the narrow set of counterfactuals we can verify with data and experiments,
    which misses many interesting, cognitive science-aligned, and practical use cases
    of counterfactual reasoning. This book leans into those use cases.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个关于爱情和遗憾的例子说明了这种“可能发生什么”的思考对人类认知的基本性（我们将在第8章和第9章看到更多应用实例）。因此，学习如何构建具有相同能力的AI是有意义的。但尽管它们很有用，一些反事实推理很难或无法验证（你*不能*证明如果你为了爱情而结婚你会更快乐）。大多数因果推理书籍只关注我们可以用数据和实验验证的狭隘的反事实集合，这忽略了反事实推理的许多有趣、认知科学相关和实际的应用案例。本书深入探讨这些用例。
- en: 1.2.4 An assumption of commodification of inference
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 推理商品化的假设
- en: Many causal inference books go deep into the statistical inference nuts and
    bolts of various causal effect estimators. But a major trend in the last decade
    of developing deep learning frameworks is the *commodification of inference*.
    This refers to how libraries like PyTorch abstract away the difficult aspects
    of estimation and inference—if you can define your estimation/inference problem
    in terms minimizing a differentiable loss function, PyTorch will handle the rest.
    The commodification of inference frees up the user to focus on creating ever more
    nuanced and powerful models, such as models that represent the causal structure
    of the data-generating process.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 许多因果推断书籍深入探讨了各种因果效应估计器的统计推断螺钉和螺栓。但过去十年中开发深度学习框架的一个主要趋势是*推断的商品化*。这指的是像PyTorch这样的库如何抽象掉估计和推断的困难方面——如果你能以最小化可微损失函数的术语定义你的估计/推断问题，PyTorch将处理其余部分。推断的商品化使用户能够专注于创建更加精细和强大的模型，例如表示数据生成过程因果结构的模型。
- en: In this book, we’ll focus on leveraging frameworks for inference so that you
    can learn a universal view of modeling techniques. Once you find the right modeling
    approach for your domain, you can use other resources to go deep into any statistical
    algorithm of interest.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将专注于利用推理框架，以便你可以学习建模技术的通用观点。一旦你为你的领域找到正确的建模方法，你就可以使用其他资源深入研究任何感兴趣的统计算法。
- en: 1.2.5 Breaking down theory with code
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.5 用代码分解理论
- en: One of the standout features of this book is its approach to advanced topics
    in causal inference theory. Many introductory texts shy away from subjects like
    identification, the do-calculus, and the causal hierarchy theorem because they
    are difficult. The problem is that if you want to create causal-capable AI algorithms,
    you need an intuition for these concepts.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的一个突出特点是它对因果推断理论中高级主题的处理方法。许多入门文本回避像识别、do-演算和因果层次定理这样的主题，因为它们很难。问题是，如果你想创建具有因果能力的AI算法，你需要对这些概念有直觉。
- en: In this book, we’ll make these topics accessible by relying on Python libraries
    that implement their basic abstractions and algorithms. We’ll build intuition
    for these advanced topics by working with these primitives in code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将通过依赖实现其基本抽象和算法的Python库，使这些主题易于理解。我们将通过在代码中操作这些原语来培养对这些高级主题的直觉。
- en: 1.3 Causality’s role in modern AI workflows
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 因果性在现代人工智能工作流程中的作用
- en: There is great value in positioning ourselves to build future versions of AI
    with causal capabilities, but the topics covered in this book will also have an
    impact on applications common today. In this section, we’ll review how causality
    can enhance some of these applications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建具有因果能力的AI的未来版本中定位自己具有很大的价值，但本书涵盖的主题也将对当今常见的应用产生影响。在本节中，我们将回顾因果性如何增强这些应用中的某些方面。
- en: 1.3.1 Better data science
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 更好的数据科学
- en: Big tech and tech-powered retail organizations have recognized the significance
    of causal inference, offering premium salaries to those proficient in it. This
    is because the essence of data science—deriving actionable insights from data—is
    inherently causal.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 大型科技公司和科技驱动的零售组织已经认识到因果推断的重要性，为精通此领域的人提供高薪。这是因为数据科学的本质——从数据中提取可操作的见解——本质上具有因果性。
- en: When a data scientist examines the correlation between a feature on an e-commerce
    site and sales, they do so because they want to know whether the feature causally
    drives sales. Causal inference can help answer this question in several ways.
    First, it can help them design an experiment that will quantify the causal effect
    of the feature on sales, especially in the case where a perfect randomized experiment
    is not possible. Second, if a proposed experiment is not feasible, the data scientist
    can use past observational data and data from related but different past experiments
    to infer the value of the causal effect that would result from the proposed experiment
    without actually running it. Finally, even if the data scientist has complete
    freedom in running experiments, causal inference can help select which experiment
    to run and what variables to measure, minimizing the opportunity cost of running
    wasteful or uninformative experiments.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家检查电子商务网站上某个特征与销售额之间的相关性时，他们这样做是因为他们想知道该特征是否因果地推动了销售额。因果推断可以通过几种方式帮助回答这个问题。首先，它可以帮助他们设计一个实验来量化特征对销售额的因果效应，尤其是在无法进行完美随机实验的情况下。其次，如果提议的实验不可行，数据科学家可以使用过去的观察数据和来自相关但不同过去实验的数据来推断提议实验将产生的因果效应的价值，而无需实际运行该实验。最后，即使数据科学家在运行实验方面有完全的自由，因果推断也可以帮助选择要运行的实验和要测量的变量，从而最小化运行浪费或不具信息量的实验的机会成本。
- en: 1.3.2 Better attribution, credit assignment, and root cause analysis
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 更好的归因、信用分配和根本原因分析
- en: 'Causal inference also supports attribution. The “attribution problem” in marketing
    is perhaps best articulated by a quote credited to advertising pioneer John Wanamaker:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因果推断也支持归因。营销中的“归因问题”可能最好由一句归因于广告先驱约翰·万纳梅克的引言来阐述：
- en: Half the money I spend on advertising is wasted; the trouble is I don’t know
    which half.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我花在广告上的钱有一半是浪费的；麻烦的是我不知道是哪一半。
- en: In other words, it is difficult to know what advertisement, promotion, or other
    action *caused* a specific customer behavior, sales number, or other key business
    outcome. Even in online marketing, where the data has gotten much richer and more
    granular than in Wanamaker’s time, attribution remains a challenge. For example,
    a user may have clicked after seeing an ad, but was it that single ad view that
    led to the click? Or were they going to click anyway? Perhaps there was a cumulative
    effect of all the nudges to click that they received over multiple channels. Causal
    modeling addresses the attribution problem by using formal causal logic to answer
    “why” questions, such as “why did this user click?”
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，很难知道是什么广告、促销或其他行动导致了特定的客户行为、销售额或其他关键业务结果。即使在万纳梅克时代数据比那时更丰富、更细粒度的在线营销中，归因仍然是一个挑战。例如，用户可能在看到广告后点击，但这是否是导致点击的单个广告浏览？或者他们无论如何都会点击？也许他们在多个渠道收到的所有点击推动的累积效应导致了点击。因果建模通过使用正式的因果逻辑来回答“为什么”问题，如“为什么这个用户点击？”来解决归因问题。
- en: Attribution goes by other names in other domains, such as “credit assignment”
    and “root cause analysis.” The core meaning is the same; we want to understand
    why a particular event outcome happened. We know what the causes are in general,
    but we want to know how much a particular cause is to blame in a given instance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 归因在其他领域也有其他名称，如“信用分配”和“根本原因分析”。核心意义是相同的；我们想了解为什么某个特定事件的结果发生了。我们知道一般的原因是什么，但想知道在特定情况下，某个特定原因在多大程度上应该受到责备。
- en: 1.3.3 More robust, decomposable, and explainable models
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 更稳健、可分解和可解释的模型
- en: For organizations that use machine learning to build software, incorporating
    causal modelling can improve both the process and the product. In particular,
    causality adds value by making machine learning more robust, decomposable, and
    explainable.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用机器学习来构建软件的组织，结合因果建模可以改善过程和产品。特别是，因果性通过使机器学习更加稳健、可分解和可解释来增加价值。
- en: More robust machine learning
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更稳健的机器学习
- en: 'Machine learning models lack robustness when differences between the environment
    where the model was trained and the environment where the model is deployed cause
    the model to break down. Causality can address the lack of robustness in the following
    ways:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型训练的环境和模型部署的环境之间存在差异导致模型崩溃时，机器学习模型缺乏稳健性。因果性可以通过以下方式解决稳健性的不足：
- en: '*Overfitting*—Overfitting occurs when learning algorithms place too much weight
    on spurious statistical patterns in the training data. Causal approaches can orient
    machine learning models toward learning statistical patterns that are rooted in
    causal relationships.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*过拟合*—当学习算法过分重视训练数据中的虚假统计模式时，就会发生过拟合。因果方法可以将机器学习模型导向学习根植于因果关系的统计模式。'
- en: '*Underspecification*—Underspecification occurs when there are many equivalent
    configurations of a model that perform equivalently on test data but perform differently
    in the deployment environment. One sign of underspecification is sensitivity to
    arbitrary elements of the model’s configuration, such as a random seed. Causal
    inference can tell you when a causal prediction is “identified” (i.e., not “underspecified”),
    meaning a unique answer exists given the assumptions and the data.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*欠指定*—当模型存在许多等效配置，在测试数据上表现相同但在部署环境中表现不同时，就会发生欠指定。欠指定的一个迹象是对模型配置的任意元素敏感，例如随机种子。因果推断可以告诉你何时因果预测是“识别”的（即，“未欠指定”），这意味着在假设和数据给定的情况下存在一个独特的答案。'
- en: '*Data drift*—As time passes, the characteristics of the data in the environment
    where you deploy the model differ or “drift” from the characteristics of the training
    data. Causal modeling addresses this by capturing causal invariance underlying
    the data. For example, suppose you train a model that uses elevation to predict
    average temperature. If you train with data only from high-elevation cities, it
    should still work well in low-elevation cities if the model successfully fit the
    underlying physics-based causal relationship between altitude and temperature.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据漂移*—随着时间的推移，你在部署模型的环境中的数据特征与训练数据特征不同或“漂移”。因果建模通过捕捉数据背后的因果不变性来解决这个问题。例如，假设你训练了一个使用海拔来预测平均温度的模型。如果你只使用来自高海拔城市的训练数据，如果模型成功拟合了海拔和温度之间的基于物理的因果关系，那么它应该仍然在低海拔城市中表现良好。'
- en: This is why leading tech companies deploy causal machine learning techniques—they
    can make their machine learning services more robust. It is also why notable deep
    learning researchers are pursuing research that combines deep learning with causal
    reasoning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么领先的科技公司部署因果机器学习技术——它们可以使他们的机器学习服务更加稳健。这也是为什么著名的深度学习研究人员正在追求将深度学习与因果推理相结合的研究。
- en: More decomposable machine learning
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更可分解的机器学习
- en: Causal models decompose into components, specifically tuples of effects and
    their direct causes, which I’ll define formally in chapter 3\. To illustrate,
    let’s consider a simple machine learning problem of predicting whether an individual
    who sees a digital ad will go on to make a purchase.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因果模型分解为组件，具体来说是效应及其直接原因的元组，我将在第3章中正式定义。为了说明，让我们考虑一个简单的机器学习问题，即预测看到数字广告的个人是否会进行购买。
- en: We could use various characteristics of the ad impression (e.g., the number
    of times the ad was seen, the duration of the view, the ad category, the time
    of day, etc.) as the feature vector, and predict the purchase using a neural network,
    as depicted in figure 1.1\. The weights in the hidden layers of the model are
    mutually dependent, so the model cannot be reduced to smaller independent components.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用广告印象的各种特征（例如，广告被看到的次数、观看持续时间、广告类别、一天中的时间等）作为特征向量，并使用神经网络预测购买，如图1.1所示。模型隐藏层的权重相互依赖，因此模型不能简化为更小的独立组件。
- en: '![figure](../Images/CH01_F01_Ness.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F01_Ness.png)'
- en: Figure 1.1 A simple multilayer perceptron neural network that uses features
    associated with ad impressions to predict whether a purchase will result
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1 使用与广告印象相关的特征来预测购买结果的简单多层感知器神经网络
- en: 'On the other hand, if we take a causal view of the problem, we might reason
    that an ad impression drives engagement, and that the engagement drives whether
    an individual makes a purchase. Using engagement metrics as another feature vector,
    we could instead train the model shown in figure 1.2\. This model aligns with
    the causal structure of the domain (i.e., ad impressions causing engagement, and
    engagement causing purchases). As such, it decomposes into two components: {ad
    impression, engagement} and {engagement, purchase}.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们从因果关系的角度看待这个问题，我们可能会推断出一个广告印象可以驱动参与度，而参与度又决定了个人是否会进行购买。使用参与度指标作为另一个特征向量，我们可以训练图1.2中所示的模式。这个模型与领域的因果关系结构相一致（即广告印象导致参与度，参与度导致购买）。因此，它分解为两个组件：{广告印象，参与度}和{参与度，购买}。
- en: '![figure](../Images/CH01_F02_Ness.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F02_Ness.png)'
- en: Figure 1.2 A model that captures how ad impressions drive engagement, which
    in turn drives purchases. This model decomposes into {ad impression, engagement}
    and {engagement, purchase}.
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.2 一个捕捉广告印象如何驱动参与度，进而驱动购买的模型。该模型分解为{广告印象，参与度}和{参与度，购买}。
- en: 'There are several benefits of this decomposability:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种可分解性有几个好处：
- en: Components of the model can be tested and validated independently.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的组件可以独立测试和验证。
- en: Components of the model can be executed separately, enabling more efficient
    use of modern cloud computing infrastructure and enabling edge computing.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的组件可以单独执行，从而更有效地利用现代云计算基础设施，并支持边缘计算。
- en: When additional training data is available, only the components relevant to
    the data need retraining.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当有额外的训练数据可用时，只有与数据相关的组件需要重新训练。
- en: Components of old models can be reused in new models targeting new problems.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旧模型的组件可以用于针对新问题的新模型。
- en: There is less sensitivity to suboptimal model configuration and hyperparameter
    settings, because components can be optimized separately.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于组件可以单独优化，因此对子优化的模型配置和超参数设置不太敏感。
- en: The components of the causal model correspond to concepts in the domain that
    you are modeling. This leads to the next benefit, explainability.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因果模型的组件对应于你正在建模的领域的概念。这导致了下一个好处，即可解释性。
- en: More explainable machine learning
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更可解释的机器学习
- en: Many machine learning algorithms, particularly deep learning algorithms, can
    be quite “black box,” meaning the internal workings are not easily interpretable,
    and the process by which the model produces an output for a given input is not
    easily explainable.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法，尤其是深度学习算法，可以相当“黑盒”，这意味着内部工作方式不易理解，模型对给定输入产生输出的过程也不易解释。
- en: In contrast, causal models are eminently explainable because they directly encode
    easy-to-understand causal relationships in the modeling domain. Indeed, causality
    is the core of explanation; explaining an event means describing the event’s causes
    and how they led to the event occurring. Causal models provide explanations in
    the language of the domain you are modeling (semantic explanations) rather than
    in terms of the model’s architecture (such as syntactic explanations of “nodes”
    and “activations”).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，因果模型是高度可解释的，因为它们直接在建模领域中编码易于理解的因果关系。事实上，因果关系是解释的核心；解释一个事件意味着描述事件的起因以及它们是如何导致事件发生的。因果模型以你正在建模的领域的语言（语义解释）而不是以模型的架构（如“节点”和“激活”的句法解释）来提供解释。
- en: Consider the examples in figures 1.1 and 1.2\. In figure 1.1, only the input
    features and output are interpretable in terms of the domain; the internal workings
    of the hidden layers are not. Thus, given a particular ad impression, it is difficult
    to explain how the model arrives at a particular purchase outcome. In contrast,
    the example in figure 1.2 explicitly provides engagement to explain how we get
    from an ad impression to a purchase outcome.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑图1.1和图1.2中的示例。在图1.1中，只有输入特征和输出在领域内是可解释的；隐藏层的内部工作方式是不可解释的。因此，给定一个特定的广告印象，很难解释模型是如何得出特定的购买结果的。相比之下，图1.2中的示例明确提供了参与度来解释我们是如何从一个广告印象到一个购买结果的。
- en: The connections between engagement and ad impression, and between purchase and
    engagement, are still black boxes, but if we need to, we can make additional variables
    in those black boxes explicit. We just need to make sure we do so in a way that
    is aligned with our assumptions about the causal structure of the problem.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 参与度与广告印象之间，以及购买与参与度之间的联系仍然是黑箱，但如果我们需要的话，我们可以在那些黑箱中添加额外的变量。我们只需要确保这样做的方式与我们对问题因果结构的假设相一致。
- en: 1.3.4 Fairer AI
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.4 更公平的AI
- en: Suppose Bob applies for a business loan. A machine learning algorithm predicts
    that Bob would be a bad loan candidate, so Bob is rejected. Bob is a man, and
    he got ahold of the bank’s loan data, which shows that men are less likely to
    have their loan applications approved. Was this an “unfair” outcome?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 假设鲍勃申请了一笔商业贷款。一个机器学习算法预测鲍勃可能是一个不良贷款候选人，因此鲍勃被拒绝了。鲍勃是一个男性，他获取了银行的贷款数据，数据显示男性获得贷款申请批准的可能性较低。这是否是一个“不公平”的结果？
- en: 'We might say the outcome is “unfair” if, for example, the algorithm made that
    prediction *because* Bob is a man. To be a “fair” prediction, it would need to
    be formulated from factors relevant to Bob’s ability to pay back the loan, such
    as his credit history, his line of business, or his available collateral. Bob’s
    dilemma is another example of why we’d like machine learning to be explainable:
    so that we can analyze what factors in Bob’s application led to the algorithm’s
    decision.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们说结果“不公平”，是因为算法做出预测是因为鲍勃是男性。为了成为一个“公平”的预测，它需要从与鲍勃偿还贷款能力相关的因素中制定，例如他的信用记录、他的业务领域或他可提供的抵押品。鲍勃的困境是另一个例子，说明了我们为什么希望机器学习是可解释的：这样我们就可以分析鲍勃申请中哪些因素导致了算法的决定。
- en: Suppose the training data came from a history of decisions from loan officers,
    some of whom harbored a gender prejudice that hurt men. For example, they might
    have read studies that show men are more likely to default in times of financial
    difficulty. Based on those studies, they decided to deduct points from their rating
    if the applicant was a man.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设训练数据来自贷款官员的历史决策，其中一些官员持有损害男性的性别偏见。例如，他们可能阅读了显示在财务困难时期男性更有可能违约的研究。基于这些研究，他们决定如果申请人是男性，就从他们的评分中扣除分数。
- en: Furthermore, suppose that when the data was collected, the bank advertised the
    loan program on social media. When we look at the campaign results, we notice
    that the men who responded to the ad were, on average, less qualified than the
    women who clicked on the ad. This discrepancy might have been because the campaign
    was better targeted toward women, or because the average bid price in online ad
    auctions was lower when the ad audience was composed of less-qualified men. Figure
    1.3 plots various factors that might influence the loan approval process, and
    it distinguishes fair from unfair causes. The factors are plotted in a directed
    acyclic graph (DAG), a popular and effective way to represent causal relationships.
    We’ll use DAGs as our workhorse for causal reasoning throughout the book.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，假设在收集数据时，银行在社交媒体上宣传了贷款计划。当我们查看活动结果时，我们注意到回应广告的男性平均资格低于点击广告的女性。这种差异可能是因为该活动更好地针对了女性，或者因为在线广告拍卖中，当广告受众由资格较低的男性组成时，平均出价价格更低。图1.3绘制了可能影响贷款审批流程的各种因素，并区分了公平和不公平的原因。这些因素被绘制在一个有向无环图（DAG）中，这是一种表示因果关系的流行且有效的方法。我们将在整个书中使用DAG作为因果推理的主要工具。
- en: '![figure](../Images/CH01_F03_Ness.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F03_Ness.png)'
- en: Figure 1.3 A causal directed acyclic graph (DAG) showing how statistical bias
    against a particular gender could come from an algorithm directly penalizing that
    gender (unfair) and indirectly through gender discrepancies in applicants targeted
    by digital advertising algorithms (fair). Causal inference can parse the bias
    into fair and unfair sources.
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3 一个因果有向无环图（DAG），展示了统计上对特定性别的偏见可能来自算法直接惩罚该性别（不公平）以及通过数字广告算法针对的申请人的性别差异间接产生（公平）。因果推断可以将偏见分解为公平和不公平的来源。
- en: Thus, we have two possible sources of statistical bias against men in the data.
    One source of bias is from the online ad that attracted men who were, on average,
    less qualified, leading to a higher rejection rate for men. The other source of
    statistical bias comes from the prejudice of loan officers. One of these sources
    of bias is arguably “fair” (it’s hard to blame the bank for the targeting behavior
    of digital advertising algorithms), and one of the sources is “unfair” (we *can*
    blame the bank for sexist loan policies). But when we only look at the training
    data without this causal context, all we see is statistical bias against men.
    The learning algorithm reproduced this bias when it made its decision about Bob.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据中存在针对男性的两种可能的统计偏差来源。一种偏差来源是吸引到平均资质较低男性的在线广告，导致男性的拒绝率较高。另一种统计偏差来源是贷款官员的偏见。其中一种偏差来源可以说是“公平的”（很难责怪银行对数字广告算法的定位行为），而另一种来源是“不公平的”（我们可以责怪银行对性别歧视的贷款政策）。但当我们只看没有这种因果背景的训练数据时，我们看到的只是针对男性的统计偏差。学习算法在做出关于鲍勃的决定时复制了这种偏差。
- en: One naive solution to this problem is simply to remove gender labels from the
    training data. But even if those sexist loan officers didn’t see an explicit indication
    of the person’s gender, they could infer it from elements of the application,
    such as the person’s name. Those loan officers encode their prejudicial views
    in the form of a statistical correlation between those proxy variables for gender
    and loan outcome. The machine learning algorithm would discover this statistical
    pattern and use it to make predictions. As a result, you could have a situation
    where the algorithm produces two different predictions for two individuals who
    had the same repayment risk but differed in gender, even if gender wasn’t a direct
    input to the prediction. Deploying this algorithm would effectively scale up the
    harm caused by those loan officers’ prejudicial views.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的简单方法之一就是从训练数据中移除性别标签。但即使那些性别歧视的贷款官员没有看到关于个人性别的明确指示，他们也能从申请中的某些元素，如个人姓名中推断出来。这些贷款官员将他们的偏见观点编码成性别代理变量与贷款结果之间的统计相关性。机器学习算法会发现这种统计模式，并利用它来做出预测。结果，你可能会遇到算法对两个具有相同还款风险但性别不同的个体产生不同预测的情况，即使性别并不是预测的直接输入。部署这种算法实际上会放大那些贷款官员的偏见观点所造成的伤害。
- en: For these reasons, we can see how many fears about the widespread deployment
    of machine learning algorithms are justified. Without corrections, these algorithms
    could adversely impact our society by magnifying the unfair outcomes captured
    in the data that our society produces.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，我们可以看到人们对广泛部署机器学习算法的许多担忧是有道理的。如果没有纠正，这些算法可能会通过放大我们社会产生的不公平结果来对我们社会产生负面影响。
- en: Causal analysis is instrumental in parsing these kinds of algorithmic fairness
    issues. In this example, we could use causal analysis to parse the statistical
    bias into “unfair” bias due to sexism and bias due to external factors like how
    the digital advertising service targets ads. Ultimately, we could use causal modeling
    to build a model that only considers variables *causally relevant* to whether
    an individual can repay a loan.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 因果分析在解析这类算法公平性问题方面是很有用的。在这个例子中，我们可以使用因果分析将统计偏差分解为“不公平”的性别歧视偏差和由于外部因素（如数字广告服务如何定位广告）导致的偏差。最终，我们可以使用因果建模来构建一个只考虑与个人是否能够偿还贷款有因果关系的变量的模型。
- en: It is important to note that causal inference alone is insufficient to solve
    algorithmic fairness. Causal inference can help parse statistical bias into what
    is fair and what’s not. And yet, even that depends on all parties involved agreeing
    on definitions of concepts and outcomes, which is often a tall order. To illustrate,
    suppose that the social media ad campaign served the loan ad to more men because
    the cost of serving an ad to men is cheaper. Thus, an ad campaign can win the
    online ad spot auctions with lower bids when the impression is coming from a man,
    and, as a result, more men see the ad, though many of these men are not good matches
    for the loan program. Was this process unfair? Is the result unfair? What is the
    fairness tradeoff between balanced outcomes across genders and pricing fairness
    to advertisers? Should some advertisers have to pay more due to pricing mechanisms
    designed to encourage balanced outcomes? Causal analysis can’t solve these questions,
    but it can help understand them in technical detail.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，仅仅因果推理不足以解决算法公平性问题。因果推理可以帮助将统计偏差分解为公平和不公平的部分。然而，即使这样，这也取决于所有相关方就概念和结果的定义达成一致，这通常是一项艰巨的任务。为了说明这一点，假设社交媒体广告活动向更多男性推送贷款广告，因为向男性推送广告的成本更低。因此，当印象来自男性时，广告活动可以通过较低的出价赢得在线广告位拍卖，结果导致更多男性看到广告，尽管其中许多男性并不适合贷款项目。这个过程是否不公平？结果是否不公平？在性别平衡结果和广告定价公平性之间，公平性的权衡是什么？是否应该让某些广告商因为旨在鼓励平衡结果的价格机制而支付更多？因果分析无法解决这些问题，但它可以帮助在技术细节上理解这些问题。
- en: 1.4 How causality is driving the next AI wave
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 因果性如何推动下一波人工智能浪潮
- en: Incorporating causal logic into machine learning is leading to new advances
    in AI. Three trending areas of AI highlighted in this book are representation
    learning, reinforcement learning, and large language models. These trends in causal
    AI are reminiscent of the early days of deep learning. People already working
    with neural networks when the deep learning wave was gaining momentum enjoyed
    first dibs on new opportunities in this space, and access to opportunities begets
    access to more opportunities. The next wave of AI is still taking shape, but it
    is clear it will fundamentally incorporate some representation of causality. The
    goal of this book is to help you ride that wave.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 将因果逻辑纳入机器学习正在引领人工智能的新进展。本书突出了人工智能的三个趋势领域：表示学习、强化学习和大型语言模型。这些因果人工智能的趋势让人联想到深度学习的早期阶段。当深度学习浪潮兴起时，已经与神经网络一起工作的人们在这个领域享受了新的机会，而机会的获取会带来更多机会的获取。下一波人工智能仍在形成中，但很明显，它将从根本上纳入因果性的某种表示。本书的目标是帮助您驾驭这股浪潮。
- en: 1.4.1 Causal representation learning
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 因果表示学习
- en: Many state-of-the-art deep learning methods attempt to learn geometric representations
    of the objects being modeled. However, these methods struggle with learning causally
    meaningful representations. For example, consider a video of a child holding a
    helium-filled balloon on a string. Suppose we had a corresponding vector representation
    of that image. If the vector representation were causally meaningful, then manipulating
    the vector to remove the child and converting the manipulated vector to a new
    video would result in a depiction of the balloon rising upwards. Causal representation
    learning is a promising area of deep representation learning that’s still in its
    early stages. This book provides several examples in different chapters of causal
    models built upon deep learning architectures, providing an introduction to the
    fundamental ideas used in this exciting new growth area of causal AI.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 许多最先进的深度学习方法试图学习被建模对象的几何表示。然而，这些方法在学习因果上有意义的表示方面存在困难。例如，考虑一个孩子用绳子拿着充满氦气的气球的视频。假设我们有一个对应图像的向量表示。如果向量表示具有因果意义，那么通过操纵向量去除孩子，并将操纵后的向量转换为新的视频，就会得到气球向上升起的描绘。因果表示学习是深度表示学习中的一个有希望的研究领域，目前仍处于早期阶段。本书在多个章节中提供了基于深度学习架构构建的因果模型示例，为因果AI这一令人兴奋的新增长领域的根本思想提供了介绍。
- en: 1.4.2 Causal reinforcement learning
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.2 因果强化学习
- en: In canonical reinforcement learning, learning agents ingest large amounts of
    data and learn like Pavlov’s dog; they learn actions that correlate positively
    with good outcomes and negatively with bad outcomes. However, as we all know,
    correlation does not imply causation. Causal reinforcement learning can highlight
    cases where the action that causes a higher reward differs from the action that
    correlates most strongly with high rewards. Further, it addresses the problem
    of credit assignment (correctly attributing rewards to actions) with counterfactual
    reasoning (i.e., asking questions like “how much reward would the agent have received
    had they been using a different policy?”). Chapter 12 is devoted to causal reinforcement
    learning and other areas of causal decision-making.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典的强化学习中，学习代理摄入大量数据，像巴甫洛夫的狗一样学习；它们学习与良好结果正相关、与不良结果负相关的动作。然而，众所周知，相关性并不等同于因果性。因果强化学习可以突出那些导致更高奖励的动作与与高奖励最强烈相关的动作不同的案例。此外，它通过反事实推理（即提出像“如果代理使用不同的策略，他们将获得多少奖励？”这样的问题）解决了归因问题（即正确地将奖励归因于动作）。第12章致力于因果强化学习和其他因果决策领域。
- en: 1.4.3 Large language models and foundation models
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.3 大型语言模型和基础模型
- en: Large language models (LLMs) such as OpenAI’s GPT, Google’s Gemini, and Meta’s
    Llama are deep neural language models with many billions of parameters trained
    on vast amounts of text and other data. These models can generate highly coherent
    natural language, code, and content of other modalities. They are foundation models,
    meaning they provide a foundation for building more domain-specific machine learning
    models and products. These products, such as Microsoft 365 Copilot, are already
    having a tremendous business impact.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）如OpenAI的GPT、Google的Gemini和Meta的Llama，是经过大量文本和其他数据训练的具有数十亿参数的深度神经网络语言模型。这些模型可以生成高度连贯的自然语言、代码和其他模态的内容。它们是基础模型，意味着它们为构建更特定领域的机器学习模型和产品提供了基础。这些产品，如Microsoft
    365 Copilot，已经产生了巨大的商业影响。
- en: A new area of investigation and product development investigates LLMs’ ability
    to answer causal questions and perform causal analysis. Another line of investigation
    is using causal methods to design and train new LLMs with optimized causal capabilities.
    In chapter 13, we’ll explore the intersection of LLMs and causality.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一项新的研究领域和产品开发调查了大型语言模型（LLMs）回答因果问题和执行因果分析的能力。另一条研究路线是使用因果方法设计和训练具有优化因果能力的新LLMs。在第13章中，我们将探讨LLMs与因果关系的交汇点。
- en: 1.5 A machine learning-themed primer on causality
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 因果关系的机器学习入门
- en: 'Now that you’ve seen the many ways that causal inference can improve machine
    learning, let’s look at the process of incorporating causality into AI models.
    To do this, we will use a popular benchmark dataset often used in machine learning:
    the MNIST dataset of images of handwritten digits, each labeled with the actual
    digit represented in the image. Figure 1.4 illustrates multiple examples of the
    digits in MNIST.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到了因果推理如何改善机器学习的多种方式，让我们看看将因果性融入AI模型的过程。为此，我们将使用在机器学习中经常使用的流行基准数据集：手写数字图像的MNIST数据集，每个图像都标有图像中实际代表的数字。图1.4展示了MNIST中数字的多个示例。
- en: '![figure](../Images/CH01_F04_Ness.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F04_Ness.png)'
- en: Figure 1.4 Each image in the MNIST dataset is an image of a written digit, and
    each image is labeled with the digit it represents.
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4 MNIST数据集中的每一张图像都是一个手写数字的图像，并且每张图像都标有它所代表的数字。
- en: MNIST is essentially the “Hello World” of machine learning. It is primarily
    used to experiment with different machine learning algorithms and to compare their
    relative strengths. The basic prediction task is to take the matrix of pixels
    representing each image as input and return the correct image label as output.
    Let’s start the process of incorporating causal thinking into a probabilistic
    machine learning model applied to MNIST images.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST基本上是机器学习的“Hello World”。它主要用于实验不同的机器学习算法，并比较它们的相对强度。基本的预测任务是接受代表每个图像的像素矩阵作为输入，并返回正确的图像标签作为输出。让我们开始将因果思维融入应用于MNIST图像的概率机器学习模型的过程。
- en: 1.5.1 Queries, probabilities, and statistics
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 查询、概率和统计学
- en: First, we’ll look at the basic process without including causal inference. Machine
    learning can use probability in analyses about quantities of interest. To do so,
    a probabilistic machine learning model learns a probabilistic representation of
    all the variables in that system. We can make predictions and decisions with probabilistic
    machine learning models using a three-step process.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将查看不包括因果推断的基本过程。机器学习可以使用关于感兴趣数量的概率进行分析。为此，概率机器学习模型学习该系统中所有变量的概率表示。我们可以使用三步过程，利用概率机器学习模型进行预测和决策。
- en: '*Pose the question*—What is the question you want to answer?'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*提出问题*——你想要回答什么问题？'
- en: '*Write down the math*—What probability (or probability-related quantity) will
    answer the question, given the evidence or data?'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*写下数学公式*——什么概率（或与概率相关的量）将回答给定证据或数据的问题？'
- en: '*Do the statistical inference*—What statistical analysis will give you (or
    will *estimate*) that quantity?'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*进行统计分析*——哪种统计分析将给你（或估计）那个量？'
- en: There is more formal terminology for these steps (*query*, *estimand*, and *estimator*)
    but we’ll avoid the jargon for now. Instead, we’ll start with a simple statistical
    example problem. Your step 1 might be “How tall are Bostonians?” For step 2, you
    might decide that knowing the *mean* height (in probability terms, the “expected
    value”) of everyone who lives in Boston will answer your question. Step 3 might
    involve randomly selecting 100 Bostonians and taking their average height; statistical
    theorems guarantee that this sample average is a close estimate of the true population
    mean.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤（*查询*、*估计量*和*估计值*）有更正式的术语，但我们现在将避免使用行话。相反，我们将从一个简单的统计示例问题开始。你的第一步可能是“波士顿人的身高是多少？”对于第二步，你可能会决定知道波士顿所有居民的*平均身高*（在概率术语中，称为“期望值”）将回答你的问题。第三步可能涉及随机选择100名波士顿人并测量他们的平均身高；统计定理保证这个样本平均数是真实总体平均数的一个接近估计。
- en: Let’s extend that workflow to modeling MNIST images.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个工作流程扩展到MNIST图像建模。
- en: 'Step 1: Pose the question'
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第一步：提出问题
- en: Suppose we are looking at the MNIST image in figure 1.5, which could be a “4”
    or could be a “9”. In step 1, we articulate a question, such as “given this image,
    what is the digit represented in this image?”
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在查看图1.5中的MNIST图像，它可能是“4”也可能是“9”。在第一步中，我们明确地提出一个问题，例如“给定这个图像，图像中代表的是哪个数字？”
- en: '![figure](../Images/CH01_F05_Ness.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F05_Ness.png)'
- en: Figure 1.5 Is this an image of the digit 4 or 9? The canonical task of the MNIST
    dataset is to classify the digit label given the image.
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5 这是一张数字4或9的图像吗？MNIST数据集的典型任务是给定图像对数字标签进行分类。
- en: 'Step 2: Write down the math'
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二步：写下数学公式
- en: In step 2, we want to find some probabilistic quantity that answers the question,
    given the evidence or data. In other words, we want to find something we can write
    down in probability math notation that can answer the question from step 1\. For
    our example with figure 1.5, the “evidence” or “data” is the image. Is the image
    a 4 or a 9? Let the variable *I* represent the image and *D* represent the digit.
    In probability notation, we can write the probability that the digit is a 4, given
    the image, as *P*(*D*=4|*I*=![figure](../Images/CH01_F05_Ness.png))*,* where *I*=![figure](../Images/CH01_F05_Ness.png)
    is shorthand for *I* being equal to some vector representation of the image. We
    can compare this probability to *P*(*D*=9|*I*=![figure](../Images/CH01_F05_Ness.png)),and
    choose the value of *D* that has the higher probability. Generalizing to all ten
    digits, the mathematical quantity we want in step 2 is shown in figure 1.6.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，我们想要找到一个概率量，它能回答给定证据或数据的问题。换句话说，我们想要找到一个可以用概率数学符号写下来的东西，它能回答第一步中的问题。对于图1.5的例子，证据或数据是图像。图像是4还是9？让变量*I*代表图像，*D*代表数字。在概率符号中，我们可以写出给定图像*I*是![figure](../Images/CH01_F05_Ness.png)时，数字是4的概率为*P*(*D*=4|*I*=![figure](../Images/CH01_F05_Ness.png))，其中*I*=![figure](../Images/CH01_F05_Ness.png)是*I*等于某个图像向量表示的简写。我们可以将这个概率与*P*(*D*=9|*I*=![figure](../Images/CH01_F05_Ness.png))进行比较，并选择具有更高概率的*D*值。将这一过程推广到所有十个数字，第二步中我们想要的数学量如图1.6所示。
- en: '![figure](../Images/CH01_F06_Ness.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F06_Ness.png)'
- en: Figure 1.6 Choose the digit with the highest probability, given the image.
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.6 根据图像选择概率最高的数字。
- en: In plain English, this is “the value *d* that maximizes the probability that
    *D* equals *d,* given the image,” where *d* is one of the ten digits (0–9).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 用普通英语来说，这就是“值*d*，它最大化了给定图像时*D*等于*d*的概率，”其中*d*是十个数字（0-9）中的一个。
- en: 'Step 3: Do the statistical inference'
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第3步：进行统计分析
- en: Step 3 uses statistical analysis to assign a number to the quantity we identified
    in step 2\. There are any number of ways we can do this. For example, we could
    train a deep neural network that takes in the image as an input and predicts the
    digit as an output; we could design the neural net to assign a probability to
    *D*=*d* for every value *d*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步使用统计分析来为我们在第2步中识别的数量分配一个数字。我们可以用无数种方法来做这件事。例如，我们可以训练一个深度神经网络，它以图像作为输入并预测数字作为输出；我们也可以设计神经网络为每个值*d*分配一个概率，即*D*=*d*。
- en: 1.5.2 Causality and MNIST
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.2 因果关系与MNIST
- en: 'So how could causality feature in the previous section’s three-step analysis?
    Yann LeCun is a Turing Award winner (computer science’s equivalent of the Nobel
    prize) for his work on deep learning, and he’s director of AI research at Meta.
    He is also one of the three researchers behind the creation of MNIST. He discusses
    the *causal* backstory of the MNIST data on his personal website, [https://yann.lecun.com/exdb/mnist/index.xhtml](https://yann.lecun.com/exdb/mnist/index.xhtml):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，因果关系如何在前一节的三个步骤分析中发挥作用呢？Yann LeCun是深度学习工作的图灵奖得主（计算机科学的诺贝尔奖），同时也是Meta人工智能研究部门的负责人。他也是MNIST创建背后的三位研究人员之一。他在个人网站上讨论了MNIST数据的*因果关系*背景，[https://yann.lecun.com/exdb/mnist/index.xhtml](https://yann.lecun.com/exdb/mnist/index.xhtml)：
- en: The MNIST database was constructed from NIST’s Special Database 3 and Special
    Database 1 which contain binary images of handwritten digits. NIST originally
    designated SD-3 as their training set and SD-1 as their test set. However, SD-3
    is much cleaner and easier to recognize than SD-1\. The reason for this can be
    found on the fact that SD-3 was collected among Census Bureau employees, while
    SD-1 was collected among high-school students. Drawing sensible conclusions from
    learning experiments requires that the result be independent of the choice of
    training set and test among the complete set of samples. Therefore, it was necessary
    to build a new database by mixing NIST’s datasets.
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: MNIST数据库是由NIST的特别数据库3和特别数据库1构建的，其中包含手写数字的二值图像。NIST最初将SD-3指定为训练集，SD-1指定为测试集。然而，SD-3比SD-1更干净、更容易识别。原因在于SD-3是在人口普查局员工中收集的，而SD-1是在高中生中收集的。从学习实验中得出合理的结论需要确保结果不受整个样本集中训练集和测试集选择的影响。因此，有必要通过混合NIST的数据集来构建一个新的数据库。
- en: In other words, the authors mixed the two datasets because they argue that if
    they trained a machine learning model solely on digits drawn by high schoolers,
    it would underperform when applied to digits drawn by bureaucrats. However, in
    real-world settings, we want robust models that can learn in one scenario and
    predict in another, even when those scenarios differ. For example, we want a spam
    filter to keep working when the spammers switch from Nigerian princes to Bhutanese
    princesses. We want our self-driving cars to stop even when there is graffiti
    on the stop sign. Shuffling the data like a deck of cards is a luxury not easily
    afforded in real-world settings.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，作者混合了这两个数据集，因为他们认为，如果他们仅用高中生绘制的数字来训练机器学习模型，那么在应用于公务员绘制的数字时表现会不佳。然而，在现实世界的设置中，我们希望模型具有鲁棒性，能够在一种场景中学习并在另一种场景中预测，即使这些场景不同。例如，我们希望垃圾邮件过滤器在垃圾邮件发送者从尼日利亚王子转变为不丹公主时仍然有效。我们希望我们的自动驾驶汽车即使在停车标志上涂鸦时也能停下来。像洗牌一样洗数据在现实世界的设置中并不是轻易就能负担得起的奢侈。
- en: Causal modeling leverages knowledge about the causal mechanisms underlying how
    the digits are drawn that will help models generalize beyond high school students
    and bureaucrats in the training data to high schoolers in the test data. Figure
    1.7 illustrates a causal DAG representing this system.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 因果建模利用了关于数字绘制背后的因果机制的知识，这将帮助模型在训练数据中的高中生和公务员之外，推广到测试数据中的高中生。图1.7展示了表示这一系统的因果DAG。
- en: '![figure](../Images/CH01_F07_Ness.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F07_Ness.png)'
- en: Figure 1.7 An example causal DAG representing the generation of MNIST images.
    The nodes represent objects in the data generating process, and edges correspond
    to causal relationships between those objects.
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.7 表示MNIST图像生成过程的示例因果DAG。节点代表数据生成过程中的对象，边对应这些对象之间的因果关系。
- en: This particular DAG imagines that the writer determines the thickness and curviness
    of the drawn digits, and that high schoolers tend to have a different handwriting
    style than bureaucrats. The graph also assumes that the writer’s classification
    is a cause of what digits they draw. Perhaps bureaucrats write more 1s, 0s, and
    5s, as these numbers occur more frequently in census work, while high schoolers
    draw other digits more often because they do more long division in math classes
    (this is a similar idea to how, in topic models, “topics” *cause* the frequency
    of words in a document). Finally, the DAG assumes that age is a common cause of
    writer type and image; you have to be below a certain age to be in high school
    and above a certain age to be a census official.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的有向无环图（DAG）设想作者决定了所绘数字的粗细和弯曲度，并且高中生倾向于有与公务员不同的书写风格。该图还假设作者的分类是导致他们所绘数字的原因。也许公务员写更多的1、0和5，因为这些数字在人口普查工作中出现得更频繁，而高中生在数学课上做更多长除法时更常绘制其他数字（这与主题模型中“主题”*导致*文档中单词频率的类似想法）。最后，DAG假设年龄是作者类型和图像的共同原因；你必须低于一定年龄才能上高中，高于一定年龄才能成为人口普查官员。
- en: A causal modeling approach would use this causal knowledge to train a predictive
    model that could extrapolate from the high school training data to the bureaucrat
    test data. Such a model would generalize better to new situations where the distributions
    of writer type and other variables are different than in the training data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一种因果建模方法将使用这种因果知识来训练一个预测模型，该模型可以从高中训练数据外推到公务员测试数据。这样的模型将更好地推广到新的情况，其中作者类型和其他变量的分布与训练数据不同。
- en: 1.5.3 Causal queries, probabilities, and statistics
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.3 因果查询、概率和统计学
- en: 'At the beginning of this chapter, I discussed various types of causal questions
    we can pose, such as causal discovery, quantifying causal effects, and causal
    decision-making. We can answer these and various other questions with a causal
    variation on our previous three-step analysis (pose the question, write down the
    math, do the statistical inference):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我讨论了我们可以提出的各种因果问题，例如因果发现、量化因果效应和因果决策。我们可以通过我们对之前三步分析（提出问题、写下数学、进行统计分析）的因果变体来回答这些问题以及其他各种问题：
- en: '*Pose the causal question*—What is the question you want to answer?'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*提出因果问题*——你想要回答的问题是什么？'
- en: '*Write down the causal math*—What probability (or expectation) will answer
    the causal question, given the evidence or data?'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*写下因果数学*——给定证据或数据，什么概率（或期望）将回答因果问题？'
- en: '*Do the statistical inference*—What statistical analysis will give you (or
    “estimate”) that causal quantity?'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*进行统计分析*——哪种统计分析将给你（或“估计”）那个因果量？'
- en: Note that the third step is the same as in the original three steps. The causal
    nuance occurs in the first and second steps.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第三步与原始三步相同。因果的细微差别出现在第一步和第二步。
- en: 'Step 1: Pose the causal question'
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第1步：提出因果问题
- en: 'These are examples of some causal questions we could ask about our causal MNIST
    model:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们关于我们的因果MNIST模型可以提出的一些因果问题的例子：
- en: “How much does the writer’s type (high schooler vs. bureaucrat) affect the look
    of an image of the digit 4 with level 3 thickness?”(*Conditional average treatment
    effect estimation* is discussed in chapter 11).
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “作者类型（高中生与公务员）对具有3级厚度的数字4的图像外观有多大影响？”（第11章中讨论了*条件平均处理效应估计*）。
- en: Assuming that stroke thickness is a cause of the image, we might ask, “What
    would a 2 look like if it were as curvy as possible?” (This is *intervention prediction*,
    discussed in chapter 7).
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设笔画粗细是图像的一个原因，我们可能会问：“如果尽可能弯曲，2看起来会是什么样子？”（这是第7章中讨论的*干预预测*）。
- en: “Given an image, how would it have turned out differently if the stroke curviness
    were heavier?” (See *counterfactual reasoning*, discussed in chapters 8 and 9).
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “给定一个图像，如果笔画弯曲度更重，它会有什么不同？”（参见第8章和第9章中讨论的*反事实推理*）。
- en: “What should the stroke curviness be to get an aesthetically ideal image?” (*Causal
    decision-making* is discussed in chapter 12).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “为了得到一个美学上理想的图像，笔画弯曲度应该是多少？”（第12章中讨论了*因果决策*）。
- en: Let’s consider the CATE in the first item. CATE estimation is a common causal
    inference question applied to ordinary tabular data, but rarely do we see it in
    the applied in the context of an AI computer vision problem.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑第一个项目中的CATE。CATE估计是应用于普通表格数据的常见因果推断问题，但在AI计算机视觉问题的应用中却很少见到。
- en: 'Step 2: Write down the causal math'
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第2步：写下因果数学
- en: 'Causal inference theory tells us how to mathematically formalize our causal
    question. Using special causal notation, we can mathematically formalize our CATE
    query as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 因果推断理论告诉我们如何用数学方法形式化我们的因果问题。使用特殊的因果符号，我们可以将我们的CATE查询用以下方式数学形式化：
- en: '![figure](../Images/ness-ch1-eqs-0x.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch1-eqs-0x.png)'
- en: where *E*(.) is an expectation operator. We’ll review expectation in the next
    chapter, but for now we can think of it as an averaging of pixels across images.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *E*(.) 是一个期望算子。我们将在下一章回顾期望，但就现在而言，我们可以将其视为对图像像素的平均值。
- en: The preceding use of subscripts is a special notation called “counterfactual
    notation” that represents an *intervention*. A random assignment in an experiment
    is a real-world intervention, but there are many experiments we can’t run in the
    real world. For example, it wouldn’t be feasible to run a trial where you randomly
    assign participants to either be a high school student or be a census bureau official.
    Nonetheless, we want to know how the writer type causally impacts the images,
    and thus we rely on a causal model and its ability to represent interventions.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的下标使用是一种特殊的符号，称为“反事实符号”，它代表了一种**干预**。实验中的随机分配是一种现实世界的干预，但有许多实验我们无法在现实世界中运行。例如，不可能进行一项试验，随机分配参与者要么成为高中生，要么成为人口普查局官员。尽管如此，我们想知道作者类型如何因果影响图像，因此我们依赖于因果模型及其表示干预的能力。
- en: 'To illustrate, figure 1.8 visualizes what CATE might look like. The challenge
    is deriving the differential image at the right of figure 1.8\. Causal inference
    theory helps us address potential age-related “confounding” bias in quantifying
    how much writer type drives the image. For example, the *do-calculus* (chapter
    10) is a set of graph-based rules that allows us to take this DAG and algorithmically
    derive the following equation:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，图1.8可视化了CATE可能的样子。挑战在于推导出图1.8右侧的差分图像。因果推断理论帮助我们解决量化作者类型如何驱动图像时可能存在的年龄相关的“混杂”偏差。例如，**do-calculus**（第10章）是一组基于图的规则，允许我们从这个DAG算法性地推导出以下方程：
- en: '![figure](../Images/ness-ch1-eqs-1x.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch1-eqs-1x.png)'
- en: The left side of this equation defines the expectations used in the CATE definition
    in the second step—it is a theoretical construct that captures the hypothetical
    condition “if writer type were set to ‘w’”. But the right side is actionable;
    it is composed entirely of terms we could estimate using machine learning methods
    on a hypothetical version of NIST image data labeled with the writers’ ages.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程的左侧定义了在第二步中用于CATE定义的期望——它是一个理论结构，捕捉了假设条件“如果作者类型被设置为‘w’”。但右侧是可操作的；它完全由我们可以使用机器学习方法在假设的NIST图像数据版本上标记作者年龄的术语组成。
- en: '![figure](../Images/CH01_F08_Ness.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F08_Ness.png)'
- en: Figure 1.8 Visualization of an example CATE of writer type on an image. It is
    the pixel-by-pixel difference of the expected image under one intervention (*W=*["high
    school"]) minus the expected image under another intervention (*W=*["bureaucrat"]),
    with both expectations conditional on being images of the digit 4 with a certain
    level of thickness.
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.8展示了作者类型在图像上的一个示例CATE的可视化。它是单一干预（*W*=["high school"）下期望图像与另一种干预（*W*=["bureaucrat"）下期望图像的像素级差异，两种期望都是在数字4的特定厚度下的图像。
- en: 'Step 3: Do the statistical inference'
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第3步：进行统计推断
- en: Step 3 does the statistical estimation, and there are several ways we could
    estimate the quantities on the right side of that equation. For example, we could
    use a convolutional neural network to model *E*(*I*|*W*=*w*, *A*=*a*, *D*=*d*,
    *T*=*t*), and build a probability model of the joint distribution *P*(*A*, *D*,
    *T*). The choice of statistical modeling approach involves the usual statistical
    trade-offs, such as ease-of-use, bias and variance, scalability to large data,
    and parallelizability.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步进行统计估计，并且有几种方法可以估计该方程右侧的量。例如，我们可以使用卷积神经网络来建模 *E*(*I*|*W*=*w*, *A*=*a*, *D*=*d*,
    *T*=*t*)，并构建联合分布 *P*(*A*, *D*, *T*) 的概率模型。统计建模方法的选择涉及通常的统计权衡，例如易用性、偏差和方差、可扩展性到大量数据以及并行化。
- en: 'Other books go into great detail on preferred statistical methods for step
    3\. I take the strongly opinionated view that we should rely on the “commodification
    of inference” trend in statistical modeling and machine learning frameworks to
    handle step 3, and instead focus on honing our skills on steps 1 and 2: figuring
    out the right questions to ask, and representing the possible causes mathematically.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 其他书籍对第三步中首选的统计方法进行了详细阐述。我持强烈的观点，我们应该依赖统计建模和机器学习框架中的“推理商品化”趋势来处理第三步，而将重点放在提高第一步和第二步的技能上：弄清楚要问的正确问题，并以数学方式表示可能的因果关系。
- en: As you’ve seen in this section, our journey into causal AI is scaffolded by
    a three-step process, and the essence of causal thinking emerges prominently in
    the first two steps. Step 1 invites us to frame the right causal questions, while
    step 2 illuminates the mathematics behind these questions. Step 3 leverages patterns
    we’re well-accustomed to in traditional statistical prediction and inference.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在本节所见，我们对因果人工智能的探索是通过一个三步过程来构建的，因果思维的精髓在前两个步骤中尤为突出。第一步邀请我们构建正确的因果问题，而第二步则阐明了这些问题背后的数学原理。第三步利用了我们在传统统计预测和推理中非常熟悉的模式。
- en: Using this structured approach, we’ll transition in the coming chapters from
    purely predictive machine learning models—like the deep latent variable models
    you might be familiar with from MNIST—to causal machine learning models that offer
    deeper insights into and answers to our causal questions. First, we will review
    the underlying mathematics and machine learning foundations. Then, in part 2 of
    the book, we’ll delve into crafting the right questions and articulating them
    mathematically for steps 1 and 2\. For step 3, we’ll harness the power of contemporary
    tools like PyTorch and other advanced libraries to bridge the causal concepts
    with cutting-edge statistical learning algorithms.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种结构化方法，在接下来的章节中，我们将从纯粹的预测机器学习模型——例如您可能从MNIST中熟悉的深度潜在变量模型——过渡到因果机器学习模型，这些模型能为我们提供对因果问题的更深入见解和答案。首先，我们将回顾基础数学和机器学习原理。然后，在本书的第二部分，我们将深入探讨如何为第一步和第二步构建正确的问题并从数学上阐述它们。对于第三步，我们将利用PyTorch和其他先进库的力量，将因果概念与最前沿的统计学习算法相结合。
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Causal AI seeks to augment statistical learning and probabilistic reasoning
    with causal logic.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果人工智能旨在通过因果逻辑增强统计学习和概率推理。
- en: Causal inference helps data scientists extract more causal insights from observational
    data (the vast majority of data in the world) and experimental data.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果推断帮助数据科学家从观察数据（世界上绝大多数数据）和实验数据中提取更多的因果见解。
- en: When data scientists can’t run experiments, causal models can simulate experiments
    from observational data.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当数据科学家无法进行实验时，因果模型可以从观察数据中模拟实验。
- en: They can use these simulations to make causal inferences, such as estimating
    causal effects, and even to prioritize interesting experiments to run in real
    life.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们可以使用这些模拟来进行因果推断，例如估计因果效应，甚至优先考虑在现实生活中运行的有趣实验。
- en: Causal inference also helps data scientists improve decision-making in their
    organizations through algorithmic counterfactual reasoning and attribution.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果推断通过算法反事实推理和归因帮助数据科学家改善他们组织中的决策。
- en: Causal inference also makes machine learning more *robust*, *decomposable*,
    and *explainable*.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果推断还使机器学习更加**稳健**、**可分解**和**可解释**。
- en: Causal analysis is useful for formally analyzing *fairness* in predictive algorithms
    and for building fairer algorithms by parsing ordinary statistical bias into its
    causal sources.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果分析有助于正式分析预测算法中的**公平性**，并通过将普通统计偏差分解为其因果来源来构建更公平的算法。
- en: The *commodification of inference* is a trend in machine learning that refers
    to how universal modeling frameworks like PyTorch continuously automate the nuts
    and bolts of statistical learning and probabilistic inference. The trend reduces
    the need for the modeler to be an expert at the formal and statistical details
    of causal inference and allows them to focus on turning domain expertise into
    better causal models of their problem domain.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理的商品化**是机器学习中的一个趋势，指的是像PyTorch这样的通用建模框架如何持续自动化统计学习和概率推理的细节。这一趋势减少了模型构建者对因果推理的正式和统计细节的专家知识需求，使他们能够专注于将领域专业知识转化为更好的问题域因果模型。'
- en: Types of causal inference tasks include *causal discovery*, *intervention prediction*,
    *causal effect estimation*, c*ounterfactual reasoning*, *explanation*, and *attribution*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果推理任务的类型包括*因果发现*、*干预预测*、*因果效应估计*、*反事实推理*、*解释*和*归因*。
- en: The way we build and work with probabilistic machine learning models can be
    extended to causal generative models implemented in probabilistic machine learning
    tools such as PyTorch.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们构建和使用概率机器学习模型的方式可以扩展到在概率机器学习工具（如PyTorch）中实现的因果生成模型。
