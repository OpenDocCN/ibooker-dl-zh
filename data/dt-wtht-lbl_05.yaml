- en: 4 Association rules
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 关联规则
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Association rules
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则
- en: Different types of algorithms for association rules
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则的多种算法类型
- en: Implementation of different algorithms for association rules
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则不同算法的实现
- en: Sequence learning using SPADE
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SPADE进行序列学习
- en: The power of association is stronger than the power of beauty; therefore, the
    power of association is the power of beauty.—John Ruskin
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关联的力量比美的力量更强；因此，关联的力量是美的力量。——约翰·拉斯金
- en: Congratulations on finishing the first part of the book! You explored the basics
    of unsupervised learning and algorithms like k-means clustering, hierarchical
    clustering, DBSCAN, principal component analysis, and others. It is expected that
    you have covered the mathematical concepts in the first part and created the Python
    codes to solve the exercise given at the end of each chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了本书的第一部分！你探索了无监督学习的基础以及k-means聚类、层次聚类、DBSCAN、主成分分析等算法。预期你已经掌握了第一部分中的数学概念，并创建了Python代码来解决每章末尾给出的练习题。
- en: Welcome to the second part of the book where we use the concepts learned in
    the first part and explore slightly more complex topics. We start with association
    rules in this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本书的第二部分，我们将在这里应用第一部分学到的概念，并探索一些稍微复杂的话题。本章我们将从关联规则开始。
- en: 'Next time you visit a nearby grocery store, look around inside the store and
    notice the arrangements of various items. You would find shelves with items like
    milk, eggs, bread, sugar, washing powder, soaps, fruits, vegetables, cookies,
    and various other items neatly stacked. Have you ever wondered about the logic
    of these arrangements and how these items are laid out? Why are certain products
    kept near each other while others are quite far from one another? Obviously, the
    arrangement cannot be done in a random manner, and there has to be scientific
    reasoning behind it. Or do you wonder: How does Netflix recommend movies to you
    based on your movie history like a sequence? We are going to find the answers
    to these questions in this chapter. Like always, we study the concepts first.
    We go through the mathematical logic for different algorithms, the pros and cons
    of each, and practical implementations using Python. A business case study is
    provided at the end of the chapter to complement the knowledge. Welcome to the
    fourth chapter and all the very best!'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 下次当你访问附近的杂货店时，环顾店内，注意各种商品的摆放。你会发现牛奶、鸡蛋、面包、糖、洗衣粉、肥皂、水果、蔬菜、饼干以及各种其他商品整齐地堆叠。你是否曾想过这些摆放的逻辑以及这些商品是如何布局的？为什么某些产品被放在彼此附近，而其他产品则相隔甚远？显然，这种摆放不能是随机的，背后必须有科学的推理。或者你可能会想：Netflix是如何根据你的观影历史像序列一样向你推荐电影的？我们将在本章中找到这些问题的答案。像往常一样，我们首先研究概念。我们通过不同算法的数学逻辑、每个算法的优缺点以及使用Python的实际应用来学习。本章末尾提供了一个商业案例研究来补充知识。欢迎来到第四章，祝大家一切顺利！
- en: 4.1 Technical toolkit
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 技术工具包
- en: We will continue to use the same version of Python and Jupyter Notebook we have
    used so far. The codes and datasets used in this chapter have been checked in
    at the same Github location.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用迄今为止所使用的相同版本的Python和Jupyter Notebook。本章中使用的代码和数据集已在相同的GitHub位置进行检查。
- en: You will need to install a few Python libraries for this chapter, including
    `apyori`, `pyECLAT`, `fpgrowth_py`, and  `pyspade`. Along with this, you will
    need `numpy` and `pandas`. Using libraries, we can implement the algorithms very
    quickly. Otherwise, coding these algorithms from scratch is quite a time-consuming
    and painstaking task.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本章的学习，你需要安装几个Python库，包括`apyori`、`pyECLAT`、`fpgrowth_py`和`pyspade`。除此之外，你还需要`numpy`和`pandas`。使用这些库，我们可以非常快速地实现算法。否则，从头开始编写这些算法将是一项耗时且费力的任务。
- en: Let’s get started with association rules.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从关联规则开始吧。
- en: 4.2 Association rule overview
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 关联规则概述
- en: You might have heard the famous “beer and diaper story.” As per this anecdote,
    customers (mostly young men) in a supermarket who buy diapers also buy beer in
    the same invoice. In other words, young men who are buying diapers for their babies
    have quite a high probability of buying beer in the same transaction. We will
    not comment on the authenticity of the story, but *association rule learning*
    can be attributed as the logic derived from this story.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过著名的“啤酒和尿布故事”。根据这个轶事，在超市购买尿布的顾客（大多是年轻人）也会在同一张发票上购买啤酒。换句话说，为婴儿购买尿布的年轻人有相当高的概率在同一笔交易中购买啤酒。我们不会对故事的真实性发表评论，但*关联规则学习*可以归因于从这个故事中得出的逻辑。
- en: Formally put, association rules can be used to find compelling relationships
    between the variables that are present in the datasets. We can use association
    rules for measuring the correlations and co-occurrences between the variables
    in a dataset. In the example given here (assuming the story is true), one could
    analyze the daily customer transactions. And if a relationship emerges between
    beer and diapers, it is a very strong insight for the supermarket, which can allow
    it to customize their placements of beer and diapers or tailor the marketing strategy
    or even alter the prices.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正式来说，关联规则可以用来发现数据集中存在的变量之间的有力关系。我们可以使用关联规则来衡量数据集中变量之间的相关性和共现性。在给出的例子中（假设故事是真实的），可以分析每日顾客交易。如果啤酒和尿布之间出现关系，这对超市来说是一个非常强烈的洞察，它可以使超市定制啤酒和尿布的摆放，调整营销策略，甚至改变价格。
- en: We can understand by a different example in a supermarket. Assume that by analyzing
    five invoices generated in a supermarket, we get the data as shown in table 4.1\.
    In this example, in invoice number 1001 milk is purchased and thus has a value
    of 1, whereas cheese is not purchased and thus is 0.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过超市中的另一个例子来理解。假设通过分析超市生成的五张发票，我们得到如表4.1所示的数据。在这个例子中，发票编号1001中购买了牛奶，因此其值为1，而奶酪没有购买，因此为0。
- en: Table 4.1 Examples of invoices generated in a supermarket
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.1超市生成的发票示例
- en: '| Invoice number | Milk | Eggs | Bread | Cheese |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 发票编号 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1001  | 1  | 1  | 1  | 0  |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 1  | 1  | 0  |'
- en: '| 1002  | 0  | 0  | 0  | 1  |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 0  | 0  | 0  | 1  |'
- en: '| 1003  | 1  | 1  | 1  | 0  |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 1  | 1  | 1  | 0  |'
- en: '| 1004  | 0  | 1  | 0  | 1  |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 0  | 1  | 0  | 1  |'
- en: '| 1005  | 1  | 1  | 0  | 1  |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 1005  | 1  | 1  | 0  | 1  |'
- en: So, in invoice number 1001, milk, eggs, and bread are purchased while in invoice
    number 1002, only cheese is purchased. Here we can see that whenever milk and
    eggs are purchased together, bread is always purchased in the same invoice. It
    is an important discovery indeed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在发票编号1001中购买了牛奶、鸡蛋和面包，而在发票编号1002中只购买了奶酪。从这里我们可以看到，每当牛奶和鸡蛋一起购买时，面包总是在同一张发票中购买。这确实是一个重要的发现。
- en: Now scale up this understanding to thousands of transactions made in a day.
    It will lead to very strong relationships that human eyes are generally oblivious
    to, but association rule algorithms can uncover them for us. This can lead to
    better product placements, better prices on the products, and much more optimized
    marketing spending. Such patterns will enhance the customer experience and prove
    quite handy to improve overall customer satisfaction.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将这种理解扩展到一天内进行的数千笔交易。这将导致人类眼睛通常无法察觉的非常强烈的关系，但关联规则算法可以为我们揭示它们。这可以导致更好的产品摆放，更好的产品价格，以及更多优化的营销支出。这样的模式将增强客户体验，并证明对提高整体客户满意度非常有帮助。
- en: We can visualize association rules as shown in figure 4.1\. Here there are some
    incoming variables represented as nodes 1, 2, 3, 4, etc. These nodes are related
    to each other as shown by the arrows. This relationship between them gives rise
    to rules A and B. If we relate back to the beer/diaper story we mentioned at the
    start of this section, rule A can be that when a young male customer buys diapers,
    they also often buy beer, while rule B can be that when milk and eggs are purchased,
    often bread is bought too.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将关联规则可视化，如图4.1所示。这里有一些表示为节点1、2、3、4等的输入变量。这些节点通过箭头相互关联。它们之间的关系产生了规则A和规则B。如果我们回顾本节开头提到的啤酒/尿布故事，规则A可以是当年轻男性顾客购买尿布时，他们通常也会购买啤酒，而规则B可以是当购买牛奶和鸡蛋时，通常也会购买面包。
- en: '![figure](../Images/CH04_F01_Verdhan.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F01_Verdhan.png)'
- en: Figure 4.1 An association rule can be visualized as the relationship between
    various variables in the dataset. These variables are linked to each other, and
    significant relationships are established between them.
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1 关联规则可以可视化成数据集中各种变量之间的关系。这些变量相互关联，并在它们之间建立了显著的关系。
- en: The example of the supermarket is sometimes referred to as *market basket analysis.*
    But association rules are applicable not only in grocery retail. Their utility
    has been proven in other sectors like bioinformatics, the medical industry, intrusion
    detection, etc. They can be utilized by Netflix or Spotify to analyze historical
    user behavior and then recommend the content the user most likely is going to
    like. Web developers can analyze the historical clicks and usages of the customers
    on their websites. By identifying the patterns, they can find out what users tend
    to click and which features will maximize their engagement. Medical practitioners
    can use association rules to better diagnose patients. The doctors can compare
    the probability of the symptoms in relationship with other symptoms and provide
    more accurate diagnoses. The use cases occur across multiple business domains
    and business functions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 超市的例子有时被称为*市场篮子分析*。但关联规则不仅适用于杂货零售。它们在其他领域如生物信息学、医疗行业、入侵检测等也得到了证明。Netflix或Spotify可以利用这些规则来分析历史用户行为，然后推荐用户最可能喜欢的内。网站开发者可以分析客户在其网站上的历史点击和使用情况。通过识别模式，他们可以找出用户倾向于点击哪些内容，以及哪些功能将最大化他们的参与度。医疗从业者可以使用关联规则来更好地诊断患者。医生可以比较症状与其他症状之间的概率关系，并提供更准确的诊断。这些用例发生在多个商业领域和商业功能中。
- en: 4.3 The building blocks of association rules
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 关联规则的基本构建块
- en: 'We covered the definition of an association rule in the last section. Now let’s
    understand the mathematical concept behind association rules. Assume that we have
    the following datasets in a retail store:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一个章节中介绍了关联规则的定义。现在让我们来理解关联规则背后的数学概念。假设我们有一个零售店中的以下数据集：
- en: Let X = {x[1], x[2], x[3], x[4], x[5] …., x[*n*]} are the *n* items available
    in the retail store. For example, they can be milk, eggs, bread, cheese, apples,
    and so on.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设X = {x[1], x[2], x[3], x[4], x[5]……，x[*n*]}是零售店中可用的*n*个商品。例如，它们可以是牛奶、鸡蛋、面包、奶酪、苹果等等。
- en: Let Y = {y[1], y[2], y[3], y[4], y[5] …., y[*m*]} are the *m* transactions generated
    in that retail store. Each transaction could have all or some items from the retail
    store.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设Y = {y[1], y[2], y[3], y[4], y[5]……，y[*m*]}是零售店中生成的*m*个交易。每个交易可能包含零售店的所有或部分商品。
- en: Obviously, each item in the transaction will be bought from the retail store
    only. In other words, every item in transactions in set Y will be a subset of
    items in set X. At the same time, each item would have a unique identifier attached
    to it, and each transaction would have a unique invoice number attached to it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，交易中的每个商品都只会从零售店购买。换句话说，集合Y中的每个商品都将属于集合X的子集。同时，每个商品都会附有一个唯一的标识符，每个交易都会附有一个唯一的发票号码。
- en: Now we are interested in analyzing the patterns and discovering the relationships.
    This will be used to generate any rule or insight. So let’s define the meaning
    of the rule first.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对分析模式和发现关系感兴趣。这将用于生成任何规则或洞察。所以让我们首先定义规则的意义。
- en: 'Assume that we find a rule that whenever items in list P are bought, items
    in list Q are also bought. This rule can be written as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们找到一个规则，即每当列表P中的商品被购买时，列表Q中的商品也会被购买。这个规则可以写成以下形式：
- en: The rule is P -> Q. It means that whenever items defined in P are bought, it
    leads to a purchase in Q too.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规则是P -> Q。这意味着每当P中定义的商品被购买时，也会导致Q中的购买。
- en: Items in P will be a subset of X or P Í X.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P中的商品将是X的子集或P Í X。
- en: Similarly, items in Q will be a subset of X or Q Í X.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，Q中的商品也将是X的子集或Q Í X。
- en: P and Q cannot have any common element or P Ç Q = 0
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P和Q不能有任何共同元素或P Ç Q = 0
- en: Now let’s understand these mathematical concepts with a real-world example.
    Assume that X = {milk, bananas, eggs, cheese, apples, bread, salt, sugar, cookies,
    butter, cold drinks, water}. These are the total items available in the retail
    shop.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过一个现实世界的例子来理解这些数学概念。假设X = {牛奶，香蕉，鸡蛋，奶酪，苹果，面包，盐，糖，饼干，黄油，冷饮，水}。这些都是零售店中可用的全部商品。
- en: Y = {1001, 1002, 1003, 1004, 1005} are the five invoices generated in that retail
    store. The respective items purchased in each of these invoices are given in figure
    4.2. Note how for each invoice, we have 0 and 1 associated for each of the items.
    These invoices are just for illustration purposes. In the actual invoices, the
    number of items can be much more. Using this dataset, let’s assume we create two
    rules that {milk, bananas} -> {eggs} and {milk, bananas} -> {bread}.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Y = {1001, 1002, 1003, 1004, 1005} 是在那个零售店生成的五个发票。在这些发票中分别购买的项目在图 4.2 中给出。注意，对于每个发票，每个项目都关联着
    0 和 1。这些发票只是为了说明目的。在实际的发票中，项目的数量可能要多得多。使用这个数据集，我们假设创建了两个规则：{牛奶，香蕉} -> {鸡蛋} 和 {牛奶，香蕉}
    -> {面包}。
- en: '![figure](../Images/CH04_F02_Verdhan.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F02_Verdhan.png)'
- en: Figure 4.2 Example of five invoices generated in a retail store
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.2 零售店生成的五个发票示例
- en: The first rule means that whenever milk and bananas are bought together, eggs
    are also purchased in the same transaction. The second rule means that whenever
    milk and bananas are bought together, bread is also bought in the same transaction.
    By analyzing the dataset, we can clearly see that rule 1 is always true whereas
    rule 2 is not.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条规则意味着每当牛奶和香蕉一起购买时，鸡蛋也会在同一笔交易中购买。第二条规则意味着每当牛奶和香蕉一起购买时，面包也会在同一笔交易中购买。通过分析数据集，我们可以清楚地看到规则
    1 总是正确的，而规则 2 则不是。
- en: NOTE  The items on the left side of a rule are called the *antecedent* or the
    LHS and the ones on the right side of a rule are called the *consequents* or the
    RHS.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：规则左侧的项目被称为**前件**或 LHS，而规则右侧的项目被称为**后件**或 RHS。
- en: In the real world, for any such rule to have significance, the same pattern
    must repeat itself across several hundreds and thousands of transactions. Only
    then would we conclude that the rule is indeed true and can be generalized across
    the entire database.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，对于任何这样的规则要具有意义，相同的模式必须在数百甚至数千笔交易中重复出现。只有这样，我们才能得出结论，该规则确实是正确的，并且可以在整个数据库中泛化。
- en: At the same time, there can be many such rules. In a retail shop where thousands
    of invoices are generated daily, there can be hundreds of such rules. How can
    we find out which rules are significant and which are not? This can be understood
    using the concepts of *support, confidence, lift,* and *conviction,* which we
    will study in the next section.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，可能存在许多这样的规则。在一个每天生成数千张发票的零售店中，可能有数百条这样的规则。我们如何找出哪些规则是重要的，哪些不是？这可以通过使用 *支持度、置信度、提升度*
    和 *确信度* 的概念来理解，我们将在下一节中学习这些概念。
- en: 4.3.1 Support, confidence, lift, and conviction
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 支持度、置信度、提升度和确信度
- en: We identified the meaning of a rule in an association rule in the last section.
    We also understand that there can be hundreds of rules based on the transactional
    dataset. In this section, we will explore how we can measure the effectiveness
    of such rules and shortlist the most interesting ones. This can be achieved using
    the concepts of support, confidence, lift, and conviction.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个章节中，我们探讨了关联规则中规则的意义。我们也了解到，基于事务数据集可能会有数百条规则。在本节中，我们将探讨如何衡量这类规则的有效性，并筛选出最有趣的规则。这可以通过使用支持度、置信度、提升度和确信度的概念来实现。
- en: Recall in the last section we discussed the generalization of a rule. Support,
    confidence, lift, and conviction allow us to measure the level of generalization.
    In simple terms, using these four parameters, we can determine how useful the
    rule can be in our pragmatic real-world business. After all, if a rule is not
    useful or is not powerful enough, it is not required to be implemented. Support,
    confidence, lift, and conviction are the parameters to check the efficacy of the
    rule. We look at these concepts in detail next.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在上一个章节中我们讨论了规则的泛化。支持度、置信度、提升度和确信度允许我们衡量泛化的程度。简单来说，通过使用这四个参数，我们可以确定规则在我们实际应用中的实用性。毕竟，如果一个规则没有用或者不够强大，那么它就不需要被实施。支持度、置信度、提升度和确信度是检查规则有效性的参数。我们将在下一节中详细探讨这些概念。
- en: We will use the dataset in table 4.2 to understand the concepts of support,
    confidence, lift, and conviction. The first invoice, 1001, has milk, eggs, and
    bread while cheese is not purchased. Again, for the sake of this example, we have
    taken only four items in total.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用表 4.2 中的数据集来理解支持度、置信度、提升度和确信度的概念。第一张发票，1001，有牛奶、鸡蛋和面包，而奶酪没有购买。为了这个例子，我们总共只选取了四个项目。
- en: Table 4.2 Dataset to understand the concept of support, confidence, lift, and
    conviction
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.2：用于理解支持度、置信度、提升和确信度的数据集
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 发票编号 | 牛奶 | 鸡蛋 | 面包 | 奶酪 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1001  | 1  | 1  | 1  | 0  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 1  | 1  | 0  |'
- en: '| 1002  | 0  | 1  | 1  | 1  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 0  | 1  | 1  | 1  |'
- en: '| 1003  | 1  | 1  | 1  | 0  |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 1  | 1  | 1  | 0  |'
- en: '| 1004  | 0  | 1  | 0  | 1  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 0  | 1  | 0  | 1  |'
- en: '| 1005  | 0  | 1  | 1  | 0  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 1005  | 0  | 1  | 1  | 0  |'
- en: Here, for an invoice, 1 represents if an item is present in that invoice while
    0 shows that the item was not purchased in that particular invoice. For example,
    invoice number 1001 has milk, eggs, and bread while 1002 has eggs, bread, and
    cheese.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，对于一张发票，1表示该发票中是否有项目，而0表示在该特定发票中没有购买该项目。例如，发票编号1001有牛奶、鸡蛋和面包，而1002有鸡蛋、面包和奶酪。
- en: Support
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 支持度
- en: Support measures the frequency percentage of the items in the datasets. In simpler
    terms, it measures the percentage of transactions in which the items are occurring
    in the dataset.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度衡量数据集中项目的频率百分比。简单来说，它衡量在数据集中发生项目的交易百分比。
- en: 'Support can be denoted as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度可以表示如下：
- en: '![figure](../Images/verdhan-ch4-eqs-0x.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/verdhan-ch4-eqs-0x.png)'
- en: Refer to table 4.2\. Say we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three items (milk,
    eggs, and bread) are present. The total number of transactions is five. This means
    that the support for the rule is 2/5, which is 0.4 or 40%.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表4.2。假设我们对规则{牛奶，鸡蛋} -> {面包}感兴趣。在这种情况下，有两个交易包含这三个项目（牛奶、鸡蛋和面包）。交易总数是五个。这意味着该规则的支持度为2/5，即0.4或40%。
- en: Now say we are interested in the rule {bread, eggs} -> {cheese}. In such a scenario,
    there is only one transaction in which all three items are present. The total
    number of transactions is five. This means that the support for the rule is 1/5,
    which is 0.2 or 20%.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们对规则{面包，鸡蛋} -> {奶酪}感兴趣。在这种情况下，只有一个交易包含这三个项目。交易总数是五个。这意味着该规则的支持度为1/5，即0.2或20%。
- en: NOTE  The higher the support for a rule, the better it is. Generally, we put
    a minimum threshold to get support. A minimum threshold is generally determined
    in consultation with the business stakeholders.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：规则的支持度越高，越好。通常，我们会设定一个最低阈值以获得支持。最低阈值通常是在与业务利益相关者协商后确定的。
- en: Confidence
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 置信度
- en: Confidence measures how often the rule is true; that is, it measures the percentage
    of transactions that contain antecedents that also contain consequents.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 置信度衡量规则为真的频率；也就是说，它衡量包含前件也包含后件的交易的百分比。
- en: 'So if we wish to measure the confidence of the rule A -> B:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想测量规则A -> B的置信度：
- en: '![figure](../Images/verdhan-ch4-eqs-1x.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/verdhan-ch4-eqs-1x.png)'
- en: Here, the numerator is supported when both *A* and *B* are present in the transaction,
    while the denominator refers to the support only for *A*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，分子是在交易中同时存在A和B时支持的，而分母是指仅对A的支持。
- en: Refer to table 4.2\. Again, say we are interested in the rule {milk, eggs} ->
    {bread}. In such a scenario, there are two transactions in which both milk and
    eggs are present. Hence, the support is 2/5 = 0.4\. It is the denominator. There
    are two transactions in which all three (milk, eggs, bread) are present. Hence,
    support is 2/5 = 0.4, which is the numerator. Putting in the preceding equation,
    the confidence for the rule {milk, eggs} -> {bread} is 0.4/0.4 = 1.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表4.2。再次假设我们对规则{牛奶，鸡蛋} -> {面包}感兴趣。在这种情况下，有两个交易包含牛奶和鸡蛋。因此，支持度为2/5 = 0.4。这是分母。有两个交易包含所有三个（牛奶、鸡蛋、面包）。因此，支持度为2/5
    = 0.4，这是分子。将它们放入前面的方程中，规则{牛奶，鸡蛋} -> {面包}的置信度为0.4/0.4 = 1。
- en: Now say we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there are four transactions in which (eggs, bread) are present. The total number
    of transactions is five. This means that the support is 4/5, which is 0.8\. There
    is only one transaction in which all three items (eggs, bread, cheese) are present.
    So the support is 1/5 = 0.2\. Hence the confidence for the rule {eggs, bread}
    -> {cheese} is 0.2/0.8 = 0.25.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们对规则{鸡蛋，面包} -> {奶酪}感兴趣。在这种情况下，有四个交易包含（鸡蛋，面包）。交易总数是五个。这意味着支持度为4/5，即0.8。只有一个交易包含所有三个项目（鸡蛋、面包、奶酪）。因此，支持度为1/5
    = 0.2。因此，规则{鸡蛋，面包} -> {奶酪}的置信度为0.2/0.8 = 0.25。
- en: NOTE  The higher the confidence in the rule, the better it is. Like support,
    we put a minimum threshold on confidence.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：规则的置信度越高，越好。和支撑度一样，我们对置信度也设定了一个最小阈值。
- en: Sometimes this is also referred to as the *conditional probability* of *A* on
    *B*. It can be understood as the probability of *B* occurring provided *A* has
    already occurred and can be written as *P*(*A*|*B*). So, in the preceding examples,
    the probability of cheese to be bought provided eggs, bread is already bought
    is 25% while the probability of bread to be purchased, provided milk, eggs are
    already purchased is 100%.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有时这也被称为 *A* 在 *B* 上的 *条件概率*。它可以理解为在 *A* 已经发生的情况下 *B* 发生的概率，可以表示为 *P*(*A*|*B*)。所以，在前面的例子中，在已经购买了鸡蛋和面包的情况下购买奶酪的概率是
    25%，而购买面包的概率，在已经购买了牛奶和鸡蛋的情况下是 100%。
- en: Lift and conviction
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提升和说服力
- en: Lift is a very important measurement criterium for a rule. Lift for a rule *A*
    -> *B* can be defined as
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是规则的一个重要测量标准。规则 *A* -> *B* 的提升可以定义为
- en: '![figure](../Images/verdhan-ch4-eqs-2x.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/verdhan-ch4-eqs-2x.png)'
- en: Here the numerator is supported when both *A* and *B* are present in the transaction,
    while the denominator refers to the support for *A* multiplied by the support
    for *B*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，当交易中同时存在 *A* 和 *B* 时，分子得到支持，而分母指的是对 *A* 的支持乘以对 *B* 的支持。
- en: Again, refer to table 4.2 and say we are interested in the rule {milk, eggs}
    -> {bread}. In such a scenario, there are two transactions in which all three
    (milk, eggs, bread) are present. Hence, support is again 2/5 = 0.4, which is the
    numerator. There are two transactions in which only (milk, eggs) are present,
    so the support is 2/5 = 0.4\. There are four transactions in which bread is present,
    hence the support is 4/5 = 0.8\. Putting in the preceding equation, the lift for
    the rule {milk, eggs} -> {bread} is 0.4/(0.4 x 0.8) = 1.25.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，参考表 4.2，假设我们感兴趣的规则是 {milk, eggs} -> {bread}。在这种情况下，有两个交易同时包含所有三个（牛奶、鸡蛋、面包）。因此，支撑度再次是
    2/5 = 0.4，这是分子。有两个交易只包含（牛奶、鸡蛋），所以支撑度是 2/5 = 0.4。有四个交易包含面包，因此支撑度是 4/5 = 0.8。将前面的方程代入，规则
    {milk, eggs} -> {bread} 的提升是 0.4/(0.4 x 0.8) = 1.25。
- en: Then say we are interested in the rule {eggs, bread} -> {cheese}. In such a
    scenario, there is only one transaction in which (eggs, bread, cheese) are present.
    The total number of transactions is five. This means that the support is 1/5,
    which is 0.2\. There are two transactions in which (cheese) is present. So the
    support is 2/5 = 0.4\. There are four transactions in which (eggs, bread) are
    present, so the support is 4/5 = 0.8\. Putting in the preceding equation, the
    lift for the rule {eggs, bread} -> {cheese} is 0.2/(0.4 x 0.8) = 0.625.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，假设我们感兴趣的规则是 {eggs, bread} -> {cheese}。在这种情况下，只有一个交易包含（鸡蛋、面包、奶酪）。交易总数是五个。这意味着支撑度是
    1/5，即 0.2。有两个交易包含（奶酪），所以支撑度是 2/5 = 0.4。有四个交易包含（鸡蛋、面包），所以支撑度是 4/5 = 0.8。将前面的方程代入，规则
    {eggs, bread} -> {cheese} 的提升是 0.2/(0.4 x 0.8) = 0.625。
- en: If the value of the lift is *equal to 1*, it means that the antecedent and precedent
    are independent of each other, and no rule can be drawn from it.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升的值 *等于 1*，这意味着前件和后件彼此独立，从中无法得出任何规则。
- en: If the value of lift is *greater than 1*, it means that the antecedent and precedent
    are dependent on each other. This rule can be used for predicting the antecedent
    in future transactions. This is the insight we want to draw from the dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升的值 *大于 1*，这意味着前件和后件彼此依赖。这个规则可以用于预测未来交易中的前件。这是我们想要从数据集中得出的见解。
- en: If the value of lift is *less than 1*, it means that the antecedent and precedent
    are substitutes of each other. The presence of one can have a negative effect
    on the other. It is also an important insight that can be used by the business
    teams for strategic planning.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升的值 *小于 1*，这意味着前件和后件是彼此的替代品。一个的存在可能对另一个产生负面影响。这也是商业团队可以用于战略规划的重要见解。
- en: While we evaluate any rule using the lift, it is imperative that we apply domain
    knowledge to it. For example, if we evaluate the rule {eggs, bread} -> {cheese}
    and if we find that eggs, bread can be a substitute for cheese, we know that it
    is not true in real life. Hence, in such a scenario we cannot make any decision
    for this role. We must use domain knowledge to draw any conclusions for this rule.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用提升度评估任何规则时，应用领域知识是至关重要的。例如，如果我们评估规则{鸡蛋，面包} -> {奶酪}，并且我们发现鸡蛋和面包可以是奶酪的替代品，我们知道在现实生活中这不是真的。因此，在这种情况下，我们不能对这个规则做出任何决定。我们必须使用领域知识来为这个规则得出任何结论。
- en: At the same time, rule {milk, eggs} -> {bread} might be a rule that can be true
    many times. For many customers, when they purchase milk and eggs together, it
    is highly likely that bread will be purchased in the same transaction. Hence this
    rule makes much more sense for such customers. The objective is to have a strong
    business logic to either support or disapprove a rule identified using the algorithm.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，规则{牛奶，鸡蛋} -> {面包}可能是一个可以多次成立的规则。对于许多客户来说，当他们一起购买牛奶和鸡蛋时，购买面包的可能性非常高。因此，这个规则对这类客户来说更有意义。目标是有一个强大的业务逻辑来支持或反对使用算法识别出的规则。
- en: 'Conviction is another important parameter, which is given by the following
    formula:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 确信度是另一个重要参数，由以下公式给出：
- en: '![figure](../Images/verdhan-ch4-eqs-3x.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/verdhan-ch4-eqs-3x.png)'
- en: Refer to table 4.2\. Again, say we are interested in the rule {eggs, bread}
    -> {cheese}. In such a scenario, there is only one transaction in which (cheese)
    is present. The total number of transactions is five. So, it means that the support
    is 1/5, which is 0.2 and will be used in the numerator. We have already calculated
    the confidence as 0.625\. Putting back in the formula, we can calculate conviction
    as (1 – 0.2)/(1 – 0.625) = 2.13
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 参考表4.2。再次，假设我们感兴趣的规则是{鸡蛋，面包} -> {奶酪}。在这种情况下，只有一个交易中包含（奶酪）。总交易数为五。所以，这意味着支持度为1/5，即0.2，将用于分子。我们已经计算出置信度为0.625。将这个值代入公式，我们可以计算出确信度为(1
    – 0.2)/(1 – 0.625) = 2.13
- en: 'We can interpret the conviction as: the rule {eggs, bread} -> {cheese} would
    be incorrect 2.13 times more often if the association between {eggs, bread, cheese}
    was purely chosen at random.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将确信度解释为：规则{鸡蛋，面包} -> {奶酪}如果{鸡蛋，面包，奶酪}之间的关联完全是随机选择的，那么这个规则将错误地出现2.13倍。
- en: In most of the business scenarios, lift is the measurement criteria used. There
    are other measurement parameters, too, like leverage, collective strength, etc.
    But most of the time, confidence, support, lift, and conviction are used to measure
    the effectiveness of any rule.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数商业场景中，提升度是使用的测量标准。还有其他测量参数，例如杠杆、集体强度等。但大多数情况下，置信度、支持度、提升度和确信度用于衡量任何规则的有效性。
- en: Exercise 4.1
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习4.1
- en: 'Answer these questions to check your understanding:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 回答这些问题以检查你的理解：
- en: Support measures how often the rule is present in the dataset. True or False?
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 支持度衡量规则在数据集中出现的频率。对或错？
- en: If the lift is greater than 1, it means that the two items are independent of
    each other. True or False?
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果提升度大于1，这意味着两个项目是相互独立的。对或错？
- en: The lower the value of confidence, the better the rule. True or False?
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 置信度值越低，规则越好。对或错？
- en: While we evaluate any rule while analyzing the dataset, most of the time, we
    set a threshold for the confidence, support, lift, and conviction. It allows us
    to reduce the number of rules and filter out the irrelevant ones. In other words,
    we are interested in only the rules that are very frequent. We will study this
    in more detail when we create a Python solution for a dataset.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在分析数据集时评估任何规则时，大多数情况下，我们会为置信度、支持度、提升度和确信度设置一个阈值。这使我们能够减少规则的数目并过滤掉不相关的规则。换句话说，我们只对非常频繁的规则感兴趣。当我们为数据集创建Python解决方案时，我们将更详细地研究这个问题。
- en: 4.4 Apriori algorithm
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 Apriori算法
- en: The Apriori algorithm is one of the most popular algorithms used for association
    rules. It was proposed by Agrawal and Shrikant in 1994\. The link to the paper
    is given at the end of the chapter.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori算法是用于关联规则的最流行算法之一。它在1994年由Agrawal和Shrikant提出。论文链接在章节末尾给出。
- en: Apriori is used to understand and analyze the frequent items in a transactional
    database. It utilizes a “bottom-up” approach where the first candidates are generated
    based on the frequency of the subsets. Let us understand the entire process by
    means of an example. We will use the same dataset we have discussed earlier (see
    table 4.2). The process used in the Apriori algorithm will look like figure 4.3.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori 用于理解和分析事务数据库中的频繁项。它采用“自下而上”的方法，首先根据子集的频率生成候选项。让我们通过一个例子来理解整个过程。我们将使用之前讨论过的相同数据集（见表
    4.2）。Apriori 算法中使用的流程将类似于图 4.3。
- en: '![figure](../Images/CH04_F03_Verdhan.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F03_Verdhan.png)'
- en: Figure 4.3 The Apriori algorithm process
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.3 Apriori 算法过程
- en: Let us say we wish to analyze the relationship of bread with all the other items
    in the dataset. In this case, level 1 is bread, and we find its frequency of occurrence.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望分析数据集中面包与其他所有商品之间的关系。在这种情况下，第一级是面包，我们找到其出现的频率。
- en: 'Then we move to the next layer, which is layer 2\. Now we find the relationship
    of bread with each of the other items: milk, eggs, and cheese, which are at layer
    2\. Here again we find the respective frequencies of occurrence for all the possible
    combinations, which are {bread, milk}, {bread, eggs}, and {bread, cheese}. See
    figure 4.4.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们转向下一层，即第二层。现在我们找到面包与第二层中每个其他商品的关系：牛奶、鸡蛋和奶酪。在这里，我们再次找到所有可能组合的相应频率，这些组合是 {面包,
    牛奶}、{面包, 鸡蛋} 和 {面包, 奶酪}。见图 4.4。
- en: '![figure](../Images/CH04_F04_Verdhan.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F04_Verdhan.png)'
- en: Figure 4.4 We have bread at level 1 while the other items (milk, eggs, and cheese)
    are kept at level 2\. Bread is kept at level 1 since we wish to analyze the relationship
    of bread with all the other items.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.4 我们在第一级放置面包，而其他商品（牛奶、鸡蛋和奶酪）保持在第二级。面包保持在第一级，因为我们希望分析面包与其他所有商品的关系。
- en: After layer 2 has been analyzed, we move to the third layer and fourth layer
    and so on. This process continues until we reach the last layer wherein all the
    items have been exhausted.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析完第二层之后，我们转向第三层和第四层，依此类推。这个过程一直持续到我们达到最后一层，其中所有商品都已耗尽。
- en: As a result of this process, we can calculate the support for all the possible
    combinations. For example, we would know the support for
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个过程，我们可以计算出所有可能组合的支持度。例如，我们会知道
- en: '{bread} -> {milk},'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {牛奶}，'
- en: '{bread} -> {eggs}, and'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {鸡蛋}，并且'
- en: '{bread} -> {cheese}.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包} -> {奶酪}。'
- en: For the next level, we would also get the support for
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下一级，我们也会得到支持度
- en: '{bread, milk} -> {eggs},'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 牛奶} -> {鸡蛋}，'
- en: '{bread, eggs} -> {milk},'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 鸡蛋} -> {牛奶}，'
- en: '{bread, milk} -> {cheese},'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 牛奶} -> {奶酪}，'
- en: '{bread, cheese} -> {milk},'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 奶酪} -> {牛奶},'
- en: '{bread, cheese} -> {eggs}, and'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 奶酪} -> {鸡蛋}，并且'
- en: '{bread, eggs} -> {cheese}.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '{面包, 鸡蛋} -> {奶酪}。'
- en: Now, using the same process, all the possible combinations for the next level
    are calculated. For example, {bread, eggs, milk} -> {cheese}, {bread, eggs, cheese}
    -> {milk}, and so on.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用相同的过程，计算下一级的所有可能组合。例如，{面包, 鸡蛋, 牛奶} -> {奶酪}，{面包, 鸡蛋, 奶酪} -> {牛奶}，依此类推。
- en: When all the item sets have been exhausted, the process will stop. The complete
    architecture can look like figure 4.5.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有商品集都耗尽后，过程将停止。完整的架构可以像图 4.5 那样。
- en: Now we can easily understand that the possible number of combinations is quite
    high, which is one of the challenges with Apriori. But Apriori is quite a powerful
    algorithm and is very popular too. Now it’s time to implement Apriori using Python.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以很容易地理解，可能的组合数量相当高，这是 Apriori 的一大挑战。但 Apriori 是一个非常强大的算法，也非常受欢迎。现在是时候使用
    Python 实现 Apriori 了。
- en: '![figure](../Images/CH04_F05_Verdhan.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F05_Verdhan.png)'
- en: Figure 4.5 The complete architecture for the Apriori algorithm. Here we would
    have calculated support for all the possible combinations. The relationships between
    all the items are explored, and because of this entire database scan, the speed
    of Apriori gets hampered.
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.5 Apriori 算法的完整架构。在这里，我们将计算所有可能组合的支持度。探索所有商品之间的关系，由于整个数据库扫描，Apriori 的速度会受到影响。
- en: 4.4.1 Python implementation
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 Python 实现
- en: We will now proceed with Python implementation of the Apriori algorithm. The
    dataset and Python Jupyter Notebook are checked in at the GitHub repository. You
    might have to install `apyori`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进行 Apriori 算法的 Python 实现。数据集和 Python Jupyter Notebook 已存入 GitHub 仓库。你可能需要安装
    `apyori`。
- en: 'To install the libraries, simply do the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装库，只需执行以下操作：
- en: '[PRE0]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The steps are as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Import the necessary libraries for the use case. We are importing `numpy` and
    `pandas`. For implementing Apriori, we have a library called `apyori`, which is
    also imported:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入使用案例所需的库。我们正在导入 `numpy` 和 `pandas`。为了实现 Apriori，我们有一个名为 `apyori` 的库，也进行了导入：
- en: '[PRE1]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '2\. Import the dataset `store_data.csv` file:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. 导入数据集文件 `store_data.csv`：
- en: '[PRE2]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You are also advised to have a look at the dataset by opening the .csv file.
    It will look like the screenshot in figure 4.6\. The first 25 rows are shown in
    the screenshot. Each row represents an invoice.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 还建议您通过打开 .csv 文件查看数据集。它将看起来像图4.6中的截图。截图显示了前 25 行。每一行代表一张发票。
- en: '![figure](../Images/CH04_F06_Verdhan.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F06_Verdhan.png)'
- en: Figure 4.6 Screenshot of the .csv file
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.6 .csv 文件的截图
- en: '3\. Next we perform some basic checks on the data by the `.info` and`.head`
    commands (see figure 4.7):'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3. 接下来，我们通过 `.info` 和 `.head` 命令对数据进行一些基本检查（见图4.7）：
- en: '[PRE3]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![figure](../Images/CH04_UN01_Verdhan.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_UN01_Verdhan.png)'
- en: '[PRE4]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![figure](../Images/CH04_F07_Verdhan.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F07_Verdhan.png)'
- en: Figure 4.7 Output for `.info` and `.head` commands
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.7 `.info` 和 `.head` 命令的输出
- en: '4\. Here we can see that the first transaction has been considered the header
    by the code. Hence, we would import the data again, but this time we would specify
    that headers are equal to `None`:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. 在这里，我们可以看到代码已经将第一个事务视为标题。因此，我们将再次导入数据，但这次我们会指定标题等于 `None`：
- en: '[PRE5]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '5\. Let’s look at the head again (see figure 4.8). This time it looks correct:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5. 让我们再次查看头部（见图4.8）。这次看起来是正确的：
- en: '[PRE6]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![figure](../Images/CH04_F08_Verdhan.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F08_Verdhan.png)'
- en: Figure 4.8 Correct results for `.head()`
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.8 `.head()` 的正确结果
- en: '6\. The library we are using for the code accepts the dataset as a list of
    lists. The entire dataset must be a big list while each transaction is an inner
    list in the big list. So, to achieve it, we first convert our `store_dataset`
    dataframe into a list:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6. 我们使用的库接受数据集作为列表的列表。整个数据集必须是一个大列表，而每个事务都是大列表中的一个内部列表。因此，为了实现这一点，我们首先将我们的 `store_dataset`
    数据框转换为列表：
- en: '[PRE7]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 7\. Next, we implement the Apriori algorithm.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 7. 接下来，我们实现 Apriori 算法。
- en: For the algorithm, we are working on the `all_records` list we created in step
    6\. The minimum support specified is 0.5 or 50%, the minimum confidence is 25%,
    the minimum lift is 4, and the minimum length of the rule is 2.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法，我们正在使用我们在第 6 步中创建的 `all_records` 列表。指定的最小支持度为 0.5 或 50%，最小置信度为 25%，最小提升度为
    4，规则的最小长度为 2。
- en: 'The output of this step is the `apriori_rules` class object. This object is
    then converted into a list that we can understand. Finally, we print this list:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的输出是 `apriori_rules` 类对象。然后，我们将此对象转换为我们可以理解的列表。最后，我们打印这个列表：
- en: '[PRE8]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The output of the code will be 0\. This means that no such rules exist that
    satisfy the condition we have set for the rules.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出将是 0。这意味着不存在满足我们设定的规则条件的规则。
- en: 'We again try to execute the same code, albeit by reducing the minimum support
    to 25%:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次尝试执行相同的代码，尽管将最小支持度降低到 25%：
- en: '[PRE9]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Again, no rules are generated and the output is 0\. Even reducing the minimum
    support to 10% does not lead to any rules:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，没有生成规则，输出为 0。即使将最小支持度降低到 10% 也不会产生任何规则：
- en: '[PRE10]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we reduce the minimum lift to 2\. This time we get 200 as the output. This
    means that there are 200 such rules that fulfill the criteria:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将最小提升度降低到 2。这次输出为 200。这意味着有 200 条这样的规则满足标准：
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '8\. Let’s look at the first rule (see figure 4.9):'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 8. 让我们查看第一条规则（见图4.9）：
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![figure](../Images/CH04_F09_Verdhan.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F09_Verdhan.png)'
- en: Figure 4.9 Output from `print(apriori_rules[0])`
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.9 `print(apriori_rules[0])` 的输出
- en: The rule explains the relationship between almonds and burgers. The support
    is .005, and the confidence is 0.25\. Lift, which is 2.92, indicates that this
    rule is quite strong.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 该规则解释了杏仁和汉堡之间的关系。支持度为 .005，置信度为 0.25。提升度，为 2.92，表明此规则相当强大。
- en: '9\. We will now look at all the rules in detail. For that, loop through the
    rules and extract information from each of the iterations. Each of the rules has
    the items constituting the rule and respective values for support, confidence,
    lift, and conviction. We have shown an example in step 8\. Now, in step 9, we
    are just extracting that information for all the rules using a `for` loop:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 9. 现在，我们将详细查看所有规则。为此，遍历规则并从每个迭代中提取信息。每个规则都有构成规则的项以及支持度、置信度、提升度和确信度的相应值。我们在第
    8 步中展示了一个示例。现在，在第 9 步中，我们只是使用 `for` 循环提取所有规则的信息：
- en: '[PRE13]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The output for this step is shown in figure 4.10\. Here we can observe each
    rule is listed along with the respective values of support, confidence, lift,
    and conviction.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤的输出如图4.10所示。在这里，我们可以观察到每条规则及其相应的支持度、置信度、升值和确信度。
- en: '![figure](../Images/CH04_F10_Verdhan.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F10_Verdhan.png)'
- en: Figure 4.10 Output for step 9
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.10 第9步的输出
- en: We can interpret the rules easily. For example, the rule almonds -> burgers
    has a lift of 2.92 with a confidence of 25.49% and support of 0.51%. This concludes
    our implementation using Python. This example can be extended to any other real-world
    business dataset.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地解释这些规则。例如，规则杏仁 -> 汉堡的升值为2.92，置信度为25.49%，支持度为0.51%。这标志着我们使用Python实现的结束。这个例子可以扩展到任何其他现实世界的商业数据集。
- en: NOTE  Not all the rules generated are not worth using. We will examine how to
    get the best rules from all the rules generated when we deal with the case study
    in the last section of the chapter.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：并非所有生成的规则都值得使用。当我们处理本章最后部分的案例研究时，我们将探讨如何从所有生成的规则中获取最佳规则。
- en: The Apriori algorithm is a robust and very insightful algorithm. But, like any
    other solution, it has a few shortcomings.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori算法是一个强大且非常有洞察力的算法。但，像任何其他解决方案一样，它也有一些缺点。
- en: 4.4.2 Challenges with the Apriori algorithm
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 Apriori算法的挑战
- en: As we have seen, the number of subsets generated in the Apriori algorithm is
    quite high (see figure 4.5). It is very tedious to generate candidates’ item sets,
    and hence it becomes quite cumbersome to analyze the dataset. Apriori scans the
    entire dataset multiple times, and hence it requires the database to be loaded
    in the memory. We can safely deduce that it requires a lot of time to make the
    computations. This problem is magnified when we are dealing with a very large
    dataset. In fact, for real-world problems where millions of transactions are generated,
    quite a huge number of candidate item sets are generated, and it is very time-consuming
    to use Apriori on the entire dataset.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，Apriori算法生成的子集数量相当高（见图4.5）。生成候选项集非常繁琐，因此分析数据集变得相当麻烦。Apriori算法多次扫描整个数据集，因此需要将数据库加载到内存中。我们可以安全地推断，这需要大量的时间来计算。当我们处理非常大的数据集时，这个问题会变得更加严重。实际上，对于生成数百万笔交易的现实世界问题，会生成大量的候选项集，使用Apriori在整个数据集上运行会非常耗时。
- en: Due to this very reason, generally, a minimum value of support is set to reduce
    the number of possible rules. In the previous example, we can calculate the support
    for level 1 combinations, as shown in table 4.3\. Here, if we set the minimum
    value of support as 0.5, only one rule will be shortlisted. Support is calculated
    for each of the combination of the items. For example, for milk and bread, the
    number of transactions is 2, while the total number of transactions is 5\. So
    the support is 2/5, which is 0.4.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，通常，我们设置一个最小支持度值以减少可能的规则数量。在先前的例子中，我们可以计算1级组合的支持度，如表4.3所示。在这里，如果我们设置最小支持度值为0.5，则只有一条规则会被筛选出来。支持度会计算每个物品组合。例如，对于牛奶和面包，交易数量为2，而总交易数量为5。因此，支持度为2/5，即0.4。
- en: Table 4.3 Support for level 1 combinations
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.3 1级组合的支持度
- en: '| Combination | Number of transactions | Total transactions | Support |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 组合 | 交易数量 | 总交易数量 | 支持度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Milk, Eggs  | 2  | 5  | 0.4  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 | 2 | 5 | 0.4 |'
- en: '| Milk, Bread  | 2  | 5  | 0.4  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，面包 | 2 | 5 | 0.4 |'
- en: '| Milk, Cheese  | 0  | 5  | 0  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，奶酪 | 0 | 5 | 0 |'
- en: '| Eggs, Bread  | 4  | 5  | 0.8  |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包 | 4 | 5 | 0.8 |'
- en: '| Eggs, Cheese  | 2  | 5  | 0.4  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，奶酪 | 2 | 5 | 0.4 |'
- en: '| Bread, Cheese  | 1  | 5  | 0.2  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 面包，奶酪 | 1 | 5 | 0.2 |'
- en: Setting up a minimum value of support is hence an intelligent tactic to make
    the rules much more manageable. It reduces the time and generates rules that are
    much more significant. After all, the rules generated from the analysis should
    be generalizable enough so that they can be implemented across the entire database.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，设置一个最小支持度值是一种明智的策略，可以使规则更容易管理。它减少了时间并生成了更具意义的规则。毕竟，从分析中生成的规则应该足够通用，以便可以在整个数据库中实施。
- en: Exercise 4.2
  id: totrans-191
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习4.2
- en: 'Answer these questions to check your understanding:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 回答以下问题以检查你的理解：
- en: The Apriori algorithm scans the database only once. True or False?
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Apriori算法只扫描数据库一次。对还是错？
- en: If bananas are present in 5 transactions out of a total of 12 transactions,
    it means the support for bananas is 5/12\. True or False?
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果香蕉在总共12笔交易中的5笔交易中出现，这意味着香蕉的支持度是5/12。对还是错？
- en: But the Apriori algorithm is indeed a great solution. It is still highly popular
    and generally one of the very first algorithms brought up whenever association
    rules are discussed.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 但Apriori算法确实是一个伟大的解决方案。它仍然非常受欢迎，并且在讨论关联规则时通常是最先提出的算法之一。
- en: NOTE  Data preparation is one of the key steps and quite a challenge. We will
    explore this challenge during the case study in section 4.8\.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：数据准备是关键步骤之一，也是一个相当大的挑战。我们将在第4.8节中的案例研究中探讨这个挑战。
- en: 4.5 Equivalence class clustering and bottom-up lattice traversal
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 等价类聚类和自底向上的格遍历
- en: We will now study the equivalence class clustering and bottom-up lattice traversal
    algorithm (ECLAT), which sometimes is considered better than Apriori in terms
    of speed and ease of implementation. ECLAT uses a depth-first search approach.
    This means that ECLAT performs the search in a vertical fashion throughout the
    dataset. It starts at the root node and then goes one level deep and continues
    until it reaches the first terminal note. Let’s say the terminal node is at level
    *X*. Once the terminal node is reached, the algorithm then takes a step back and
    reaches level (*X* – 1) and continues until it finds a terminal node again. Let’s
    understand this process by means of a tree diagram, as shown in figure 4.11.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将研究等价类聚类和自底向上格遍历算法（ECLAT），它在速度和易于实现方面有时被认为比Apriori更好。ECLAT使用深度优先搜索方法。这意味着ECLAT在整个数据集上以垂直方式执行搜索。它从根节点开始，然后深入一层，并继续直到达到第一个终端节点。假设终端节点在级别*X*。一旦达到终端节点，算法就后退一步，达到级别(*X*
    – 1)，并继续直到再次找到终端节点。让我们通过图4.11所示的树状图来理解这个过程。
- en: '![figure](../Images/CH04_F11_Verdhan.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F11_Verdhan.png)'
- en: Figure 4.11 Tree diagram to understand the process of the ECLAT algorithm. It
    starts with 1 and ends at 16.
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.11展示了理解ECLAT算法过程的树状图。它从1开始，到16结束。
- en: 'ECLAT will take the following steps:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT将采取以下步骤：
- en: The algorithm starts at the root node 1\.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法从根节点1开始。
- en: It then goes one level deep to root node 2\.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它深入一层到达根节点2。
- en: It will then continue one more level deep until it reaches terminal node 11\.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将再深入一层，直到达到终端节点11。
- en: Once it reaches terminal node 11, it then takes a step back and goes to node
    5\.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦达到终端节点11，它就后退一步，到达节点5。
- en: The algorithm then searches if there is any node available that can be used.
    At node 5 we can see that there is no such node available.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法接着搜索是否有可用的节点。在节点5我们可以看到没有这样的节点可用。
- en: Hence, the algorithm again takes a step back and reaches node 2\.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，算法再次后退一步，达到节点2。
- en: At node 2, the algorithm explores again. It finds that it is possible to go
    to node 6\.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在节点2，算法再次探索。它发现可以进入节点6。
- en: So, the algorithm goes to node 6 and starts exploring again until it reaches
    terminal node 12\.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，算法进入节点6并再次开始探索，直到达到终端节点12。
- en: This process continues until all the combinations have been exhausted.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此过程会继续进行，直到所有组合都被耗尽。
- en: Obviously, the speed of computation depends on the total number of distinct
    items present in the dataset. This is because the number of distinct items defines
    the width of the tree. The items purchased in each of the transactions would define
    the relationship between each node.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，计算速度取决于数据集中不同项目的总数。这是因为不同项目的数量定义了树的宽度。每个交易中购买的项目将定义每个节点之间的关系。
- en: During the execution time of ECLAT, each item (either individually or in a pair)
    is analyzed. Let us use the same example we have used for Apriori to understand
    ECLAT better. Refer to table 4.2.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在ECLAT的执行时间内，每个项目（无论是单独还是成对）都会被分析。让我们使用我们之前为Apriori使用的相同示例来更好地理解ECLAT。参见表4.2。
- en: 'ECLAT will undergo the following steps to analyze the dataset:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ECLAT将采取以下步骤来分析数据集：
- en: In the first run, ECLAT will find the invoice numbers for all single items.
    In other words, it will find the invoice numbers for all the items individually.
    It is shown in table 4.4, wherein milk is present in invoice numbers 1001 and
    1003, while eggs are present in all five invoices.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次运行中，ECLAT将找到所有单个项目的发票号码。换句话说，它将找到所有项目的单独发票号码。这显示在表4.4中，其中牛奶出现在发票号码1001和1003中，而鸡蛋出现在所有五张发票中。
- en: Table 4.4 Respective invoices in which each item is present
  id: totrans-215
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.4 包含每个项目各自的发票
- en: '| Item | Invoice numbers |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 发票编号 |'
- en: '| --- | --- |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Milk  | 1001, 1003  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶 | 1001, 1003 |'
- en: '| Eggs  | 1001, 1002, 1003, 1004, 1005  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 | 1001, 1002, 1003, 1004, 1005 |'
- en: '| Bread  | 1001, 1002, 1003, 1005  |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 面包 | 1001, 1002, 1003, 1005 |'
- en: '| Cheese  | 1002, 1004  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 | 1002, 1004 |'
- en: 2\. In the next step, all the two-item datasets are explored as shown in table
    4.5\. For example, milk and eggs are present in invoice numbers 1001 and 1003,
    while milk and cheese are not present in any invoice.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. 在下一步中，所有包含两个项目的数据集都按表 4.5 所示进行探索。例如，牛奶和鸡蛋存在于发票编号 1001 和 1003 中，而牛奶和奶酪不存在于任何发票中。
- en: Table 4.5 Two-item datasets
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.5 两项数据集
- en: '| Item | Invoice numbers |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 发票编号 |'
- en: '| --- | --- |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Milk, Eggs  | 1001 ,1003  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 | 1001 ,1003 |'
- en: '| Milk, Bread  | 1001, 1003  |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，面包 | 1001, 1003 |'
- en: '| Milk, Cheese  | —  |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，奶酪 | — |'
- en: '| Eggs, Bread  | 1001, 1002, 1003, 1005  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包 | 1001, 1002, 1003, 1005 |'
- en: '| Eggs, Cheese  | 1002, 1004  |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，奶酪 | 1002, 1004 |'
- en: '| Bread, Cheese  | 1002  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 面包，奶酪 | 1002 |'
- en: 3\. In the next step, all three-item datasets are explored, as shown in table
    4.6\. Here we have two combinations only.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3. 在下一步中，所有包含三个项目的数据集都按表 4.6 所示进行探索。这里我们只有两种组合。
- en: Table 4.6 Three-item datasets
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.6 三项数据集
- en: '| Item | Invoice numbers |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 发票编号 |'
- en: '| --- | --- |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Milk, Eggs, Bread  | 1001, 1003  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋，面包 | 1001, 1003 |'
- en: '| Eggs, Bread, Cheese  | 1002  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋，面包，奶酪 | 1002 |'
- en: 4\. There are no invoices present in our dataset that contain four items.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. 在我们的数据集中没有包含四个项目的发票。
- en: 5\. Now, depending on the threshold we set for the value of the support count,
    we can choose the rules. So, if we want the minimum number of transactions in
    which the rule should be true to be three, then only one rule qualifies, which
    is {eggs, bread}. If we decide the threshold for the minimum number of transactions
    is two, then rules like {milk, eggs, bread}, {milk, eggs}, {milk, bread}, {eggs,
    bread}, and {eggs, cheese} qualify as the rules.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5. 现在，根据我们为支持计数值设定的阈值，我们可以选择规则。所以，如果我们想规则为真的最小交易数量是三个，那么只有一个规则符合条件，即 {鸡蛋，面包}。如果我们决定最小交易数量的阈值是两个，那么像
    {牛奶，鸡蛋，面包}，{牛奶，鸡蛋}，{牛奶，面包}，{鸡蛋，面包} 和 {鸡蛋，奶酪} 这样的规则都符合规则。
- en: We will now create a Python solution for ECLAT.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将为 ECLAT 创建一个 Python 解决方案。
- en: 4.5.1 Python implementation
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.1 Python 实现
- en: We will now work on the execution of ECLAT using Python. We use the `pyECLAT`
    library here. The dataset looks like figure 4.12\.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用 Python 执行 ECLAT。在这里，我们使用 `pyECLAT` 库。数据集看起来像图 4.12。
- en: '![figure](../Images/CH04_F12_Verdhan.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F12_Verdhan.png)'
- en: Figure 4.12 ECLAT for the `pyECLAT` library using Python
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.12 使用 Python 的 `pyECLAT` 库的 ECLAT
- en: 'The steps are as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Import the libraries:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库：
- en: '[PRE14]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '2\. Import the dataset:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. 导入数据集：
- en: '[PRE15]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '3\. Generate an ECLAT instance:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3. 生成 ECLAT 实例：
- en: '[PRE16]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: There are some properties of ECLAT instance `eclat` generated in the last step
    like `eclat.df_bin`, which is a binary dataframe, and `eclat.uniq_`, which is
    a list of all the unique items.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步生成的 ECLAT 实例 `eclat` 中有一些属性，如 `eclat.df_bin`，它是一个二进制数据框，以及 `eclat.uniq_`，它是一个包含所有唯一项目的列表。
- en: '4\. Fit the model. We give a minimum support of 0.02 here. After that, we print
    the support:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. 拟合模型。我们这里给出最小支持度为 0.02。之后，我们打印支持度：
- en: '[PRE17]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output is shown in figure 4.13.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图 4.13 所示。
- en: '![figure](../Images/CH04_F13_Verdhan.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F13_Verdhan.png)'
- en: Figure 4.13 Output for step 4
  id: totrans-257
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.13 第 4 步的输出
- en: We can interpret the results provided based on the support. For each of the
    items and combination of items, we are getting the value of the support. For example,
    for french fries and eggs, the value of support is 3.43%.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据支持度解释提供的结果。对于每个项目和项目的组合，我们都会得到支持度的值。例如，对于薯条和鸡蛋，支持度的值是 3.43%。
- en: ECLAT has some advantages over the Apriori algorithm. Since it uses a depth-search
    approach, it is faster than Apriori and requires less memory to compute. It does
    not scan the dataset iteratively, and that makes it even faster than Apriori.
    We will compare these algorithms once more after we have studied the last algorithm.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Apriori 算法相比，ECLAT 有一些优势。因为它使用深度搜索方法，所以比 Apriori 快，并且计算所需的内存更少。它不迭代地扫描数据集，这使得它甚至比
    Apriori 更快。在我们研究完最后一个算法之后，我们将再次比较这些算法。
- en: 4.6 F-P algorithm
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 F-P 算法
- en: The F-P algorithm is the third algorithm we discuss in this chapter. It is an
    improvement over the Apriori algorithm. Recall in Apriori we face the challenges
    of time-consuming and costly computations. F-P resolves these problems by representing
    the database in the form of a tree called a *frequent pattern tree* or *FP tree*.
    Because of this frequent pattern, there is no need to generate the candidates
    as done in the Apriori algorithm. Let’s discuss F-P in detail now.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: F-P算法是本章讨论的第三个算法。它是对Apriori算法的改进。回想一下，在Apriori算法中，我们面临着耗时和昂贵的计算挑战。F-P通过将数据库表示为一种称为**频繁模式树**或**FP树**的树形结构来解决这些问题。由于这种频繁模式，我们不需要像在Apriori算法中那样生成候选项。现在让我们详细讨论F-P算法。
- en: An F-P tree is a tree-shaped structure, and it mines the most frequent items
    in the datasets. This is visualized in figure 4.14\.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: F-P树是一种树形结构，它挖掘数据集中的最频繁项目。这在图4.14中得到了可视化。
- en: '![figure](../Images/CH04_F14_Verdhan.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F14_Verdhan.png)'
- en: Figure 4.14 An F-P algorithm can be depicted in a tree-diagram structure. Each
    node represents a unique item. The root node is `NULL`.
  id: totrans-264
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.14 F-P算法可以用树形图结构表示。每个节点代表一个独特的项目。根节点是`NULL`。
- en: Each node represents a unique item in the dataset. The root node of the tree
    is generally kept as `NULL`. The other nodes in the tree are the items in the
    dataset. The nodes are connected with each other if they are in the same invoice.
    We will study the entire process in a step-by-step fashion.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点代表数据集中的独特项目。树的根节点通常保持为`NULL`。树中的其他节点是数据集中的项目。如果它们在同一发票中，则节点之间相互连接。我们将逐步研究整个过程。
- en: Assume we are using the dataset shown in table 4.7\. So we have the unique items
    as Apples, Milk, Eggs, Cheese, and Bread. There are nine transactions, and the
    respective items in each of the transactions are shown in table 4.7\.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在使用表4.7中所示的数据集。因此，我们有苹果，牛奶，鸡蛋，奶酪和面包这些独特项目。有九个事务，每个事务中的相应项目在表4.7中显示。
- en: Table 4.7 Dataset to understand the F-P algorithm
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.7 用于理解F-P算法的数据集
- en: '| Transactions | Item sets |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 事务 | 项目集 |'
- en: '| --- | --- |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| T1  | Apples, Milk, Eggs  |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| T1  | 苹果，牛奶，鸡蛋  |'
- en: '| T2  | Milk, Cheese  |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| T2  | 牛奶，奶酪  |'
- en: '| T3  | Milk, Bread  |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| T3  | 牛奶，面包  |'
- en: '| T4  | Apples, Milk, Cheese  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| T4  | 苹果，牛奶，奶酪  |'
- en: '| T5  | Apples, Bread  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| T5  | 苹果，面包  |'
- en: '| T6  | Milk, Bread  |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| T6  | 牛奶，面包  |'
- en: '| T7  | Apples, Bread  |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| T7  | 苹果，面包  |'
- en: '| T8  | Apples, Milk, Bread, Eggs  |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| T8  | 苹果，牛奶，面包，鸡蛋  |'
- en: '| T9  | Apples, Milk, Bread  |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| T9  | 苹果，牛奶，面包  |'
- en: 'Let’s apply the F-P algorithm on this dataset now. The steps are as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将F-P算法应用于这个数据集。步骤如下：
- en: Like Apriori, the entire dataset is scanned first. Occurrences for each of the
    items is counted, and a frequency is generated. The results are suggested in table
    4.8\. We have arranged the items in descending order of the frequency or the respective
    support count in the entire dataset. For example, apples have been purchased in
    six transactions.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与Apriori类似，首先扫描整个数据集。计算每个项目的出现次数，并生成频率。结果在表4.8中建议。我们已按整个数据集中频率或相应支持计数的降序排列项目。例如，苹果在六次交易中被购买。
- en: Table 4.8 Respective frequency for each of the item sets
  id: totrans-281
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.8 各项目集的相应频率
- en: '| Item | Frequency or support count |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 频率或支持计数 |'
- en: '| --- | --- |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Milk  | 7  |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶  | 7  |'
- en: '| Apples  | 6  |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 苹果  | 6  |'
- en: '| Bread  | 6  |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 面包  | 6  |'
- en: '| Cheese  | 2  |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪  | 2  |'
- en: '| Eggs  | 2  |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋  | 2  |'
- en: If two items have exactly same frequency, either can be ordered first. In the
    example here, Bread and Apples have the same frequency. So we can keep either
    Bread or Apples as the first one.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个项目的频率完全相同，则可以按任意顺序排列。在这个例子中，面包和苹果的频率相同。因此，我们可以保持面包或苹果作为第一个项目。
- en: 2\. Start the construction of the F-P tree. We start with creating the root
    node, which is generally the `NULL` node, in figure 4.15.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2\. 开始构建F-P树。我们从创建根节点开始，这在图4.15中通常是`NULL`节点。
- en: '![figure](../Images/CH04_F15_Verdhan.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F15_Verdhan.png)'
- en: Figure 4.15 The root node for the tree is generally kept NULL.
  id: totrans-292
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.15 树的根节点通常保持为`NULL`。
- en: 3\. Analyze the first transaction, T1\. Here we have Apples, Milk, and Eggs
    in the first transaction. Out of these three, Milk has the highest support count,
    which is 7\. So a connection is extended from the root node to Milk, and we denote
    it as Milk:1 (see figure 4.16).
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3\. 分析第一个事务，T1。在这里，第一个事务中有苹果，牛奶和鸡蛋。在这三个中，牛奶的支持计数最高，为7。因此，从根节点延伸出一条连接到牛奶的路径，我们将其表示为Milk:1（见图4.16）。
- en: '![figure](../Images/CH04_F16_Verdhan.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F16_Verdhan.png)'
- en: Figure 4.16 Connection from the root node to Milk. Milk has the highest support;
    hence we have chosen Milk.
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.16 从根节点到牛奶的连接。牛奶具有最高的支持度；因此我们选择了牛奶。
- en: 4\. Now look at the other items in T1\. Apples has a support count of 6 and
    Eggs have a support count of 2\. So we will extend the connection from Milk to
    Apples and name it Apples:1 and then from Apples to Eggs and call it Eggs:1 (see
    figure 4.17).
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. 现在看看 T1 中的其他项目。苹果的支持计数为 6，鸡蛋的支持计数为 2。因此，我们将从牛奶扩展到苹果的连接，并命名为苹果:1，然后从苹果到鸡蛋，并命名为鸡蛋:1（见图
    4.17）。
- en: 5\. Look at T2 now. It has Milk and Cheese. Milk is already connected to the
    root node. So the count for Milk becomes 2, and it becomes Milk:2\. Next, we will
    create a branch from Milk to Cheese and name it Cheese:1\. The addition is shown
    in figure 4.18\.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5. 现在看看 T2。它有牛奶和奶酪。牛奶已经连接到根节点。因此，牛奶的计数变为 2，变为牛奶:2。接下来，我们将从牛奶创建一个分支到奶酪，并命名为奶酪:1。添加情况如图
    4.18 所示。
- en: '![figure](../Images/CH04_F17_Verdhan.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F17_Verdhan.png)'
- en: Figure 4.17 Step 4 of the process where we have finished all the items in T1\.
    All the items—Milk, Apples, and Eggs—are now connected.
  id: totrans-299
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.17 过程的第 4 步，我们已经完成了 T1 中的所有项目。所有项目——牛奶、苹果和鸡蛋——现在都已连接。
- en: '![figure](../Images/CH04_F18_Verdhan.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F18_Verdhan.png)'
- en: Figure 4.18 Step 5 of the process where we started to analyze T2\. Milk is already
    connected, so its count increases by 2 while Cheese gets added to the tree.
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.18 过程的第 5 步，我们开始分析 T2。牛奶已经连接，所以其计数增加 2，而奶酪被添加到树中。
- en: 6\. Consider T3\. T3 has Milk and Bread. So, similar to step 5, the count for
    Milk is 3, and it becomes Milk:3\. And, similar to step 5, we add another connection
    from Milk to Bread and call it Bread:1\. The updated tree is shown in figure 4.19.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6. 考虑 T3。T3 有牛奶和面包。因此，类似于第 5 步，牛奶的计数为 3，变为牛奶:3。同样，类似于第 5 步，我们添加另一个从牛奶到面包的连接，并命名为面包:1。更新的树如图
    4.19 所示。
- en: '![figure](../Images/CH04_F19_Verdhan.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F19_Verdhan.png)'
- en: Figure 4.19 In step 6, T3 is analyzed. Milk’s count increased by 1 more and
    becomes 3, while Bread is added as a new connection.
  id: totrans-304
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.19 在第 6 步中，分析 T3。牛奶的计数增加了 1，变为 3，同时面包作为新的连接被添加。
- en: 7\. In T4, we have Apples, Milk, and Cheese. The count for Milk becomes 4; for
    Apples it is now 2\. Then we create a branch from Apples to Cheese, calling it
    Cheese:1 (see figure 4.20).
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 7. 在 T4 中，我们有苹果、牛奶和奶酪。牛奶的计数变为 4；苹果现在是 2。然后我们创建一个从苹果到奶酪的分支，命名为奶酪:1（见图 4.20）。
- en: '![figure](../Images/CH04_F20_Verdhan.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F20_Verdhan.png)'
- en: Figure 4.20 In step 7 of the process, T4 is being analyzed. The count of Milk
    becomes 4, for Apples it increases to 2, and a new branch from Apples to Cheese
    is added.
  id: totrans-307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.20 在过程的第 7 步中，正在分析 T4。牛奶的计数变为 4，苹果增加到 2，并添加了一个从苹果到奶酪的新分支。
- en: 8\. We find in T5 that we have Apples and Bread. Both are not directly connected
    to the root node and have an equal frequency of 6\. So we can take either to be
    connected to the root node. The figure gets updated to figure 4.21\.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 8. 在 T5 中，我们发现我们有苹果和面包。它们都没有直接连接到根节点，并且频率相等，都是 6。因此，我们可以选择任何一个连接到根节点。图被更新为图
    4.21。
- en: '![figure](../Images/CH04_F21_Verdhan.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F21_Verdhan.png)'
- en: Figure 4.21 After analyzing T5, the diagram changes, as shown here. We have
    Apples and Bread, which get added to the tree.
  id: totrans-310
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.21 分析 T5 后，图表发生变化，如图所示。我们添加了苹果和面包到树中。
- en: 9\. This process continues until we exhaust all the transactions, resulting
    in the final figure as shown in figure 4.22\.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 9. 这个过程会继续进行，直到我们耗尽所有事务，最终得到如图 4.22 所示的最终图。
- en: '![figure](../Images/CH04_F22_Verdhan.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F22_Verdhan.png)'
- en: Figure 4.22 The final tree once we have exhausted all the possible combinations
  id: totrans-313
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.22 当我们耗尽所有可能的组合后得到的最终树
- en: Great job so far! But there are more steps after this. So far, we have created
    only the tree. Now we need to generate the dataset as shown in table 4.9\. This
    is the output we wish to generate.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，做得很好！但之后还有更多步骤。到目前为止，我们只创建了树。现在我们需要生成如表 4.9 所示的数据集。这是我们希望生成的输出。
- en: Table 4.9 Table for the F-P algorithm
  id: totrans-315
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.9 F-P 算法表
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件 F-P 树 | 生成频繁模式 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Cheese  |  |  |  |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪 |  |  |  |'
- en: '| Bread  |  |  |  |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 面包 |  |  |  |'
- en: '| Eggs  |  |  |  |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋 |  |  |  |'
- en: '| Apples  |  |  |  |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 苹果 |  |  |  |'
- en: You might be wondering why there are only four items listed. Since Milk has
    directly originated from the root node and there is no other way to reach it,
    we need not have a separate row for Milk.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道为什么只列出了四个项目。由于牛奶直接来自根节点，没有其他方式到达它，因此我们不需要为牛奶单独列出行。
- en: 10\. Before continuing, we must fix the minimum support count as 2 for any rule
    to be acceptable. We do this for simplicity’s sake as the dataset is quite small.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 10. 在继续之前，我们必须将任何规则的最低支持计数设置为2，以便该规则可接受。我们这样做是为了简化，因为数据集相当小。
- en: NOTE  For real-life business problems, you are advised to test with multiple
    and even much higher values for the support counts; otherwise, the number of rules
    generated can be very high.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于现实生活中的商业问题，建议您测试支持计数的多重甚至更高的值；否则，生成的规则数量可能会非常高。
- en: Let’s start with Cheese as the first item. We can reach cheese through {NULL-Milk-Cheese}
    and {NULL-Milk-Apples-Cheese}. For both paths, the count of Cheese is 1\. Hence,
    (if we ignore NULL) our conditional pattern base is {Milk-Cheese} or {Milk:1}
    and {Milk-Apples:Cheese} or {Milk-Apples:1}. The complete conditional pattern
    base becomes {{Milk:1}, {Milk-Apples:1}}. This information is added to the second
    column of table 4.10\.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从奶酪作为第一个项目开始。我们可以通过{NULL-牛奶-奶酪}和{NULL-牛奶-苹果-奶酪}到达奶酪。对于这两条路径，奶酪的计数都是1。因此，（如果我们忽略NULL）我们的条件模式基是{牛奶-奶酪}或{牛奶:1}和{牛奶-苹果-奶酪}或{牛奶-苹果:1}。完整的条件模式基变为{{牛奶:1},
    {牛奶-苹果:1}}。此信息被添加到表4.10的第二列中。
- en: Table 4.10 Step 10 of the process where we have filled the first cell for Cheese
  id: totrans-326
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.10：过程步骤10，我们已填充奶酪的第一个单元格
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件F-P树 | 生成的频繁模式 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  |  |  |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪  | {{牛奶:1}, {牛奶-苹果:1}}  |  |  |'
- en: '| Bread  |  |  |  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 面包  |  |  |  |'
- en: '| Eggs  |  |  |  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋  |  |  |  |'
- en: '| Apples  |  |  |  |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 苹果  |  |  |  |'
- en: 11\. Now if we add the two values in a conditional pattern base, we would get
    Milk as 2 and Apples as 1\. Since we have set up a threshold for the frequency
    count of 2, we will ignore the count of Apples. The value for the conditional
    F-P tree, which is the third column in the table, becomes {Milk:2}. Now we simply
    add the original item to this, which becomes the frequent patten generated or
    column 4\. See table 4.11\.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 11. 现在如果我们将条件模式基中的两个值相加，我们会得到牛奶为2，苹果为1。由于我们已经为频率计数设置了2的阈值，我们将忽略苹果的计数。条件F-P树的价值，即表中的第三列，变为{牛奶:2}。现在我们只需将原始项添加到其中，这样就变成了生成的频繁模式或第4列。见表4.11。
- en: Table 4.11 Step 11 of the process where we have finished the details for the
    item Cheese
  id: totrans-334
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.11：过程步骤11，我们已完成奶酪的详细信息
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件F-P树 | 生成的频繁模式 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  | {Milk:2}  | {Milk-Cheese:2}  |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪  | {{牛奶:1}, {牛奶-苹果:1}}  | {牛奶:2}  | {牛奶-奶酪:2}  |'
- en: '| Bread  |  |  |  |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| 面包  |  |  |  |'
- en: '| Eggs  |  |  |  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋  |  |  |  |'
- en: '| Apples  |  |  |  |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 苹果  |  |  |  |'
- en: 12\. In a similar fashion, all the other cells are filled in the table, resulting
    in the final table (table 4.12).
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 12. 以类似的方式，表中所有其他单元格都被填充，从而得到最终的表格（表4.12）。
- en: Table 4.12 Final table after we have analyzed all the combinations for the items
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.12：分析所有项目组合后得到的最终表格
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 条件模式基 | 条件F-P树 | 生成的频繁模式 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  | {Milk:2}  | {Milk-Cheese:2}  |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 奶酪  | {{牛奶:1}, {牛奶-苹果:1}}  | {牛奶:2}  | {牛奶-奶酪:2}  |'
- en: '| Bread  | {{Milk-Apples:2}, {Milk:2}, {Apples:2}}  | {{Milk:4, Apples:2},
    {Apples:2}}  | {{Milk-Bread:4}, {Apples-Bread:4}, {Milk-Apples-Bread:2}}  |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 面包  | {{牛奶-苹果:2}, {牛奶:2}, {苹果:2}}  | {{牛奶:4, 苹果:2}, {苹果:2}}  | {{牛奶-面包:4},
    {苹果-面包:4}, {牛奶-苹果-面包:2}}  |'
- en: '| Eggs  | {{Milk-Apples:1}, {Milk-Apples-Bread:1}}  | {Milk:2, Apples:2}  |
    {{Milk-Eggs:2}, {Milk-Apples:2}, {Milk-Apples:2}}  |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋  | {{牛奶-苹果:1}, {牛奶-苹果-面包:1}}  | {牛奶:2, 苹果:2}  | {{牛奶-鸡蛋:2}, {牛奶-苹果:2},
    {牛奶-苹果:2}}  |'
- en: '| Apples  | {Milk:4}  | {Milk:4}  | {Milk-Apples:4}  |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 苹果  | {牛奶:4}  | {牛奶:4}  | {牛奶-苹果:4}  |'
- en: It is a complex process indeed. But once the steps are clear, it is straightforward.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个复杂的过程。但一旦步骤清晰，它就很简单了。
- en: As a result of this exercise, we have received the final set of rules as depicted
    in the final column Frequent Pattern Generated.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这个练习的结果，我们得到了最终的一组规则，如最终列“生成的频繁模式”所示。
- en: NOTE  Notice that none of the rules are similar to each other.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项：请注意，没有任何一条规则是彼此相似的。
- en: We will use the final column, Frequent Pattern Generated, as the rules for our
    dataset.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用最后一列“频繁模式生成”作为我们数据集的规则。
- en: The Python implementation for the F-P growth algorithm is quite simple and is
    easy to compute using the libraries. In the interest of space, we have uploaded
    the Jupyter notebook to the GitHub repository of the chapter.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: F-P增长算法的Python实现相当简单，并且可以使用库轻松计算。为了节省空间，我们已经将Jupyter笔记本上传到本章的GitHub仓库。
- en: 'We will now explore another interesting topic: sequence rule mining. It is
    a very powerful solution that allows a business to tailor its marketing strategies
    and product recommendations to the customers.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将探讨另一个有趣的主题：序列规则挖掘。这是一个非常强大的解决方案，允许企业根据客户定制其营销策略和产品推荐。
- en: 4.7 Sequence rule mining
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 序列规则挖掘
- en: 'Consider this: Netflix has a transactional database of all the movies ordered
    by customers over time. If it analyzes and finds that 65% of customers who viewed
    a war movie *X* also viewed a romantic comedy *Y* in the following month, then
    this is very insightful and actionable information. It will allow Netflix to recommend
    its offerings to customers and customize its marketing strategy.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这一点：Netflix有一个所有客户随时间订购的电影的交易数据库。如果它分析和发现65%的客户在接下来的一个月观看了战争电影X，也观看了浪漫喜剧Y，那么这将是非常有见地和可操作的信息。它将允许Netflix向客户推荐其产品并定制其营销策略。
- en: So far in the chapter, we have covered three algorithms for association rules.
    But all the data points were limited to the same dataset, and there was no sequencing
    involved. Sequential pattern mining allows us to analyze a dataset that has a
    sequence of events happening. By analyzing the dataset, we can find statistically
    relevant patterns, which allows us to decipher the entire sequence of events.
    Obviously, the sequence of events is in a particular order, which is a very important
    property to be considered during sequence rule mining.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经介绍了三种关联规则算法。但所有数据点都限于同一个数据集，并且没有涉及序列。序列模式挖掘允许我们分析发生事件序列的数据集。通过分析数据集，我们可以找到具有统计学意义的模式，这使我们能够解码整个事件序列。显然，事件序列是有特定顺序的，这是在序列规则挖掘中需要考虑的一个重要属性。
- en: NOTE  Sequence rule mining is different from time-series analysis. To learn
    more about time-series analysis, refer to the appendix.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项：序列规则挖掘与时间序列分析不同。要了解更多关于时间序列分析的信息，请参阅附录。
- en: Sequence rule mining is utilized across multiple domains and functions. It can
    be used in biology to extract information during DNA sequencing, or it can be
    used to understand the online search pattern of a user. Sequence rule mining would
    help us understand what the user is going to search next. During the discussion
    of association rules, we used the transactions in which milk, bread, and eggs
    were purchased in the same transaction. Sequence rule mining is an extension to
    that wherein we analyze consecutive transactions and try to decipher the sequence
    present, if any.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 序列规则挖掘被广泛应用于多个领域和功能。它可以用于生物学中提取DNA测序过程中的信息，或者可以用来理解用户的在线搜索模式。序列规则挖掘将帮助我们了解用户接下来将要搜索的内容。在讨论关联规则时，我们使用了牛奶、面包和鸡蛋在同一笔交易中购买的事务。序列规则挖掘是对此的扩展，其中我们分析连续的事务并试图解码存在的任何序列。
- en: While studying the Sequential Pattern Discovery Using Equivalence classes (SPADE)
    algorithm, we cover the mathematical concepts that form the base of the algorithm.
    These concepts are a little tricky and might require more than one reading to
    grasp.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究使用等价性进行序列模式发现（SPADE）算法时，我们涵盖了构成算法基础的数学概念。这些概念有点棘手，可能需要阅读多次才能掌握。
- en: 4.7.1 Sequential Pattern Discovery Using Equivalence
  id: totrans-361
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7.1 使用等价性进行序列模式发现
- en: We now explore sequence rule mining using SPADE. It was suggested by Mohammed
    J. Zaki; the link to the paper is at the end of this chapter.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用SPADE探索序列规则挖掘。它是由Mohammed J. Zaki提出的；论文链接在本章末尾。
- en: So we wish to analyze a sequence of events. For example, a customer bought a
    mobile phone and a charger. After a week, they bought earphones, and after two
    weeks, they bought a mobile phone cover and screen guard. So, in each of the transactions,
    there were items purchased. And each transaction can be called an event. Let’s
    understand it in more detail.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望分析一个事件序列。例如，一位顾客购买了一部手机和充电器。一周后，他们购买了耳机，两周后，他们购买了手机壳和屏幕保护膜。所以，在每个交易中都有购买的项目。每个交易都可以称为一个事件。让我们更详细地了解它。
- en: Let us assume we have the complete list of items for the discussion. It will
    contain items like i[1], i[2], i[3], i[4], i[5], and so on. So we can write *I*
    = {i[1], i[2], i[3], i[4], i[5]………, i[*n*]} where we have *n* distinct items in
    total.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设我们有一个用于讨论的项目完整列表。它将包含像 i[1]，i[2]，i[3]，i[4]，i[5] 等项目。因此，我们可以写出 *I* = {i[1]，i[2]，i[3]，i[4]，i[5]………，i[*n*]}，其中我们总共有
    *n* 个不同的项目。
- en: Items can be anything. If we consider the same example of a grocery store, items
    can be milk, eggs, cheese, bread, and so on.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 项目可以是任何东西。如果我们考虑同样的杂货店例子，项目可以是牛奶、鸡蛋、奶酪、面包等等。
- en: An event will be a collection of items in the same transaction. An event can
    contain items like (i[1], i[5], i[4], i[8]). For example, an event can contain
    items bought in the same transaction (milk, sugar, cheese, bread). We will denote
    an event by ⍺.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一个事件将是同一交易中的项目集合。一个事件可以包含像 (i[1], i[5], i[4], i[8]) 这样的项目。例如，一个事件可以包含在同一交易中购买的项目（牛奶，糖，奶酪，面包）。我们将事件表示为
    ⍺。
- en: Next, let’s understand a sequence. A sequence is nothing but events in an order.
    In other words, ⍺[1] -> ⍺[2] -> ⍺[3] -> ⍺[4] can be termed a sequence of events.
    For example, (Milk, Cheese) -> (Bread, Eggs) -> (Cheese, Bread, Sugar) -> (Milk,
    Bread) is a sequence of transactions. It means that in the first transaction,
    milk and cheese were bought. In the following transaction, bread and eggs were
    bought, and so on.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解一个序列。序列不过是按顺序排列的事件。换句话说，⍺[1] -> ⍺[2] -> ⍺[3] -> ⍺[4] 可以被称作事件序列。例如，(牛奶，奶酪)
    -> (面包，鸡蛋) -> (奶酪，面包，糖) -> (牛奶，面包) 是一个事务序列。这意味着在第一个事务中，购买了牛奶和奶酪。在随后的交易中，购买了面包和鸡蛋，依此类推。
- en: A sequence with *k* items is a k-item sequence. For example, sequence (Milk,
    Bread) -> (Eggs) contains three items. Now let’s explore the SPADE algorithm step
    by step.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 *k* 项的序列是一个 k-项序列。例如，序列（牛奶，面包）-> （鸡蛋）包含三个项。现在让我们一步一步地探索 SPADE 算法。
- en: Let’s say we have the following sequences generated. In the first sequence,
    ID 1001, Milk is bought in the very first transaction. In the second one, Milk,
    Eggs, and Bread are bought. They are followed by Milk and Bread. In the fourth
    one, only Sugar is purchased. In the fifth and final transaction of sequence 1001,
    Bread and Apples are purchased; this is applicable to all the respective sequences.
    For example, in sequence ID 1001, we have multiple events. In the first purchase,
    Milk is bought. Then (Milk, Eggs, Bread) are bought and so on. See table 4.13.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们生成了以下序列。在第一个序列中，ID 1001，在第一个交易中就购买了牛奶。在第二个序列中，购买了牛奶、鸡蛋和面包。随后又购买了牛奶和面包。在第四个序列中，只购买了糖。在序列1001的最后一个交易中，购买了面包和苹果；这适用于所有相应的序列。例如，在序列ID
    1001中，我们有多个事件。在第一次购买中，购买了牛奶。然后购买了（牛奶，鸡蛋，面包）等等。参见表4.13。
- en: Table 4.13 The dataset for sequence mining
  id: totrans-370
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.13 序列挖掘的数据集
- en: '| Sequence ID | Sequence |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 序列 |'
- en: '| --- | --- |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1001  | <(Milk) (Milk, Eggs, Bread) (Milk, Bread) (Sugar) (Bread, Apples)>  |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | <(牛奶) (牛奶，鸡蛋，面包) (牛奶，面包) (糖) (面包，苹果)>  |'
- en: '| 1002  | <(Milk, Sugar) (Bread) (Eggs, Bread) (Milk, Cheese)>  |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | <(牛奶，糖) (面包) (鸡蛋，面包) (牛奶，奶酪)>  |'
- en: '| 1003  | <(Cheese, Apples) (Milk, Eggs) (Sugar, Apples) (Bread) (Eggs)>  |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | <(奶酪，苹果) (牛奶，鸡蛋) (糖，苹果) (面包) (鸡蛋)>  |'
- en: '| 1004  | <(Cheese, Bananas) (Milk, Apples) (Bread) (Eggs) (Bread)>  |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | <(奶酪，香蕉) (牛奶，苹果) (面包) (鸡蛋) (面包)>  |'
- en: Table 4.13 can be converted into a vertical data format as shown in table 4.14\.
    In this step, we calculate the frequencies for one-sequence items, which are sequences
    with only one item. For this, only a single database scan is required. We simply
    have the sequence ID and element ID for each of the items.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.13 可以转换为如图表4.14所示的垂直数据格式。在这一步中，我们计算了一序列项的频率，这些是一序列项只有一项的序列。为此，只需要进行一次数据库扫描。我们只需为每个项目有序列ID和元素ID。
- en: Table 4.14 Vertical format for table 4.13
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.14 表4.13的垂直格式
- en: '| Sequence ID | Element ID | Items |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 元素ID | 项目 |'
- en: '| --- | --- | --- |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1001  | 1  | Milk  |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 牛奶  |'
- en: '| 1001  | 2  | Milk, Eggs, Bread  |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 2  | 牛奶，鸡蛋，面包  |'
- en: '| 1001  | 3  | Milk, Bread  |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 3  | 牛奶，面包  |'
- en: '| 1001  | 4  | Sugar  |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 4  | 糖  |'
- en: '| 1001  | 5  | Bread, Apples  |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 5  | 面包，苹果  |'
- en: '| 1002  | 1  | Milk, Sugar  |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 1  | 牛奶，糖  |'
- en: '| 1002  | 2  | Bread  |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 2  | 面包  |'
- en: '| 1002  | 3  | Eggs, Bread  |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 3  | 鸡蛋，面包  |'
- en: '| 1002  | 4  | Milk, Cheese  |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 4  | 牛奶，奶酪  |'
- en: '| 1003  | 1  | Cheese, Apples  |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 1  | 奶酪，苹果  |'
- en: '| 1003  | 2  | Milk, Eggs  |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 2  | 牛奶，鸡蛋  |'
- en: '| 1003  | 3  | Sugar, Apples  |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 3  | 糖，苹果  |'
- en: '| 1003  | 4  | Bread  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 4  | 面包  |'
- en: '| 1003  | 5  | Eggs  |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 5  | 鸡蛋  |'
- en: '| 1004  | 1  | Cheese, Bananas  |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 1  | 奶酪，香蕉  |'
- en: '| 1004  | 2  | Milk, Apples  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 2  | 牛奶，苹果  |'
- en: '| 1004  | 3  | Bread  |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 3  | 面包  |'
- en: '| 1004  | 4  | Eggs  |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 4  | 鸡蛋  |'
- en: '| 1004  | 5  | Bread  |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 5  | 面包  |'
- en: Table 4.14 is nothing but a vertical tabular representation of table 4.13\.
    For example, in sequence ID 1001, at the element ID 1 we have Milk. For sequence
    ID 1001, at the element ID 2 we have Milk, Eggs, Bread, and so on.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.14 实际上是表 4.13 的垂直表格表示。例如，在序列 ID 1001 中，元素 ID 1 我们有牛奶。对于序列 ID 1001，元素 ID
    2 我们有牛奶、鸡蛋、面包等等。
- en: For the purpose of explanation, we are considering only two items—0 Milk and
    Eggs—and the support threshold of 2\.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释的目的，我们只考虑两个项目——0 牛奶和鸡蛋——以及支持阈值 2。
- en: Then, in the next step, we will break it down for each of the items. For example,
    Milk appears in sequence ID 1001 and element ID 1, sequence ID 1001 and element
    ID 2, sequence ID 1001 and element ID 3, sequence ID 1002 and element ID 1, and
    so on. It results in a table like table 4.15 where we have shown Milk and Eggs.
    It needs to be applied to all the items in the dataset.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在下一步中，我们将对每个项目进行分解。例如，牛奶出现在序列 ID 1001 和元素 ID 1，序列 ID 1001 和元素 ID 2，序列 ID
    1001 和元素 ID 3，序列 ID 1002 和元素 ID 1，等等。这导致了一个像表 4.15 那样的表格，其中我们展示了牛奶和鸡蛋。这需要应用于数据集中的所有项目。
- en: Table 4.15 Respective sequence IDs for Milk and Eggs
  id: totrans-403
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.15 牛奶和鸡蛋的相应序列 ID
- en: '| Milk | Eggs |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶 | 鸡蛋 |'
- en: '| --- | --- |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Sequence ID | Element ID | Sequence ID | Element ID |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID | 序列 ID | 元素 ID |'
- en: '| --- | --- | --- | --- |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1001  | 1  | 1001  | 2  |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 1001  | 2  |'
- en: '| 1001  | 2  | 1002  | 3  |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 2  | 1002  | 3  |'
- en: '| 1001  | 3  | 1003  | 2  |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 3  | 1003  | 2  |'
- en: '| 1002  | 1  | 1003  | 5  |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 1  | 1003  | 5  |'
- en: '| 1002  | 4  | 1004  | 4  |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 4  | 1004  | 4  |'
- en: '| 1003  | 2  |  |  |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 2  |  |  |'
- en: '| 1004  | 2  |  |  |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 2  |  |  |'
- en: 'Now we wish to count two sequences or those with two-item sequences. We can
    have two sequences: either Milk -> Eggs or Eggs -> Milk. Let’s first take Milk
    -> Eggs.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们希望计算两个序列或具有两个项目序列的序列。我们可以有两个序列：要么是牛奶 -> 鸡蛋，要么是鸡蛋 -> 牛奶。让我们先从牛奶 -> 鸡蛋开始。
- en: For Milk -> Eggs, we need to have Milk in front of Eggs. For the same sequence
    ID, if the element ID of Milk is less than the element ID of Eggs, then it is
    an eligible sequence. In the preceding example, for sequence ID 1001, the element
    ID of Milk is 1, while the element ID of Eggs is 2\. So we can add that as the
    first eligible pair, as shown in the first row of table 4.16\. The same is true
    for sequence ID 1002\. In table 4.15, row 4, we have sequence ID 1002\. The element
    ID of Milk is 1, while that of Eggs in row 2 is 3\. Again, the element ID of Milk
    is lesser than the element ID of Eggs, so it becomes the second entry, and the
    process continues. The key point is to have the same sequence ID while comparing
    the respective element IDs of Milk and Eggs.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 对于牛奶 -> 鸡蛋，我们需要在鸡蛋前面有牛奶。对于相同的序列 ID，如果牛奶的元素 ID 小于鸡蛋的元素 ID，则它是一个合格的序列。在上面的例子中，对于序列
    ID 1001，牛奶的元素 ID 是 1，而鸡蛋的元素 ID 是 2。因此，我们可以将其作为第一个合格的配对添加到表 4.16 的第一行中。对于序列 ID
    1002 也是如此。在表 4.15 的第 4 行中，我们有序列 ID 1002。牛奶的元素 ID 是 1，而第 2 行中鸡蛋的元素 ID 是 3。再次，牛奶的元素
    ID 小于鸡蛋的元素 ID，因此它成为第二个条目，过程继续。关键是比较牛奶和鸡蛋的相应元素 ID 时要有相同的序列 ID。
- en: Table 4.16 Sequence for Milk and Eggs
  id: totrans-417
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.16 牛奶和鸡蛋的序列
- en: '| Milk and Eggs |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶和鸡蛋 |'
- en: '| --- |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID（牛奶） | 元素 ID（鸡蛋） |'
- en: '| --- | --- | --- |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1001  | 1  | 2  |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 2  |'
- en: '| 1002  | 1  | 3  |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 1  | 3  |'
- en: '| 1003  | 2  | 5  |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 2  | 5  |'
- en: '| 1004  | 2  | 4  |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 2  | 4  |'
- en: By using the same logic, we can create the table for Eggs -> Milk, which is
    shown in table 4.17\. Again, the key point is to have the same sequence ID while
    comparing the respective element IDs of Milk and Eggs.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用相同的逻辑，我们可以创建鸡蛋 -> 牛奶的表格，如表 4.17 所示。同样，关键是比较牛奶和鸡蛋的相应元素 ID 时要有相同的序列 ID。
- en: Table 4.17 Sequence for Eggs and Milk
  id: totrans-427
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.17 鸡蛋和牛奶的序列
- en: '| Eggs and Milk |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 鸡蛋和牛奶 |'
- en: '| --- |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Sequence ID | Element ID (Eggs) | Element ID (Milk) |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 序列 ID | 元素 ID（鸡蛋） | 元素 ID（牛奶） |'
- en: '| --- | --- | --- |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1001  | 2  | 3  |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 2  | 3  |'
- en: '| 1002  | 3  | 4  |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 3  | 4  |'
- en: This can be done for each of the possible combinations. We now move to creating
    three-item sequences, and we will create Milk, Eggs -> Milk. For this purpose,
    we have to join the two tables. See table 4.18.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以应用于所有可能的组合。我们现在转向创建三项序列，我们将创建牛奶、鸡蛋 -> 牛奶。为此，我们必须合并两个表。参见表4.18。
- en: Table 4.18 Combining the sequence Milk -> Eggs and Eggs -> Milk to join the
    tables
  id: totrans-435
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.18 将牛奶 -> 鸡蛋和鸡蛋 -> 牛奶的序列组合以合并表
- en: '| Milk and Eggs |  | Eggs and Milk |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶和鸡蛋 |  | 鸡蛋和牛奶 |'
- en: '| --- | --- | --- |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Sequence ID | Element ID (Milk) | Element ID(Eggs) |  | Sequence ID | Element
    ID (Eggs) | Element ID (Milk) |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 元素ID（牛奶） | 元素ID（鸡蛋） |  | 序列ID | 元素ID（鸡蛋） | 元素ID（牛奶） |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1001  | 1  | 2  |  | 1001  | 2  | 3  |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 2  |  | 1001  | 2  | 3  |'
- en: '| 1002  | 1  | 3  |  | 1002  | 3  | 4  |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 1  | 3 |  | 1002  | 3 | 4 |'
- en: '| 1003  | 2  | 5  |  |  |  |  |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 2  | 5 |  |  |  |  |'
- en: '| 1004  | 2  | 4  |  |  |  |  |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 2  | 4  |  |  |  |  |'
- en: The logic of joining is matching the sequence ID and the element ID. We have
    highlighted the matching ones in red and green, respectively, although this will
    not show up in the printed book. For sequence ID 1001, the element ID of Eggs
    in the left table matches the element ID of Eggs in the right table, and that
    becomes the first entry of table 4.19, which shows the results. Similarly, for
    sequence ID 1002, element ID 3 matches.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 连接的逻辑是匹配序列ID和元素ID。我们分别用红色和绿色突出显示匹配项，尽管这不会在打印的书中显示出来。对于序列ID 1001，左表中的鸡蛋元素ID与右表中的鸡蛋元素ID相匹配，这成为表4.19的第一条记录，显示了结果。同样，对于序列ID
    1002，元素ID 3相匹配。
- en: Table 4.19 Final table after we have analyzed all the combinations for the items
  id: totrans-445
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.19 分析所有商品组合后的最终表
- en: '| Milk, Eggs -> Milk |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 牛奶，鸡蛋 -> 牛奶 |'
- en: '| --- |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) | Element ID (Milk) |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 序列ID | 元素ID（牛奶） | 元素ID（鸡蛋） | 元素ID（牛奶） |'
- en: '| --- | --- | --- | --- |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1001  | 1  | 2  | 3  |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 1  | 2 | 3 |'
- en: '| 1002  | 1  | 3  | 4  |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 1 | 3 | 4 |'
- en: This process continues. The algorithm stops when no frequent sequences can be
    found.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程会继续进行。算法在找不到频繁序列时停止。
- en: 'We will now implement SPADE on a dataset using Python. We use the `pyspade`
    library, and thus we have to load the dataset and call the function. It generates
    the result for us. The support is kept as 0.6 here, and then we print the results
    (see figure 4.23):'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用Python在数据集上实现SPADE。我们使用`pyspade`库，因此我们必须加载数据集并调用函数。它为我们生成结果。支持度保持为0.6，然后我们打印结果（见图4.23）：
- en: '[PRE18]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![figure](../Images/CH04_F24_Verdhan.png)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F24_Verdhan.png)'
- en: Figure 4.23 SPADE implemented on the `pyspade` library using Python
  id: totrans-456
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.23 使用Python在`pyspade`库上实现的SPADE
- en: 4.8 Case study for association rules
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8 关联规则案例研究
- en: Association rule mining is quite a helpful and powerful solution. Next, we are
    going to solve an actual case study using association rules. Recall that, at the
    start of the chapter, we suggested you study the pattern of a grocery store. What
    is the logic of such arrangements in the store?
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘是一种非常有帮助且强大的解决方案。接下来，我们将使用关联规则解决一个实际的案例研究。回想一下，在本章开头，我们建议你研究杂货店的模式。商店中这种安排的逻辑是什么？
- en: 'Consider this: you are working for a grocery retailer like Walmart, Tesco,
    Spar, Marks & Spencer’s, etc., and you are planning the visual layout of a new
    store. Obviously, it is imperative that retail stores utilize the space in the
    store wisely and to the maximum capacity. At the same time, it is vital that the
    movement of the customers is not hindered. Customers should have access to all
    the items on display and be able to navigate easily. You might have experienced
    some stores where you feel choked and bombarded with displays while others are
    neatly stacked.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这种情况：你正在为像沃尔玛、特易购、Spar、玛莎百货等杂货零售商工作，并正在规划一家新店的视觉布局。显然，零售店必须明智地利用店内空间并达到最大容量。同时，确保顾客的流动不受阻碍也是至关重要的。顾客应该能够访问所有展示的商品，并且能够轻松地导航。你可能经历过一些商店，你感觉被展示品堵塞和轰炸，而另一些则堆叠得井井有条。
- en: How do we solve this problem? There can be multiple solutions. Some retailers
    might wish to group the items based on their categories. For example, they might
    want to keep all the baking products on one shelf or use some other condition.
    We are studying the machine learning example here.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解决这个问题？可能有多个解决方案。一些零售商可能希望根据商品类别对商品进行分组。例如，他们可能希望将所有烘焙产品放在一个货架上，或者使用其他条件。我们在这里研究机器学习示例。
- en: Using market basket analysis, we can generate the rules that indicate the respective
    relationships between various items. We can predict which items are frequently
    bought together, and they can be kept together in the store. For example, if we
    know that milk and bread are bought together, then bread can be kept near the
    milk counter. The customer purchasing milk can locate bread easily and continue
    with their purchase.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 使用市场篮子分析，我们可以生成指示各种商品之间相应关系的规则。我们可以预测哪些商品经常一起购买，并将它们一起放在商店里。例如，如果我们知道牛奶和面包经常一起购买，那么面包就可以放在牛奶柜台附近。购买牛奶的顾客可以轻松找到面包并继续购物。
- en: 'But it is not as easy as it sounds. Let us solve this case step by step:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不像听起来那么简单。让我们一步一步解决这个问题：
- en: '*Business problem definition*—The very first step is defining the business
    problem, which is clear to us. We wish to discover the relationships between various
    items so that the arrangement in the store can be made better. Here, *planograms*
    come into the picture. Planograms help the retailer plan the utilization of the
    space in the store in a wise manner so that the customer can also navigate and
    access the products easily. It can be considered a visual layout of the store.
    An example is shown in figure 4.24.'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*业务问题定义*—第一步是定义业务问题，这对我们来说很清楚。我们希望发现各种商品之间的关系，以便改善商店的布局。在这里，*商品陈列图*就出现了。商品陈列图帮助零售商明智地规划商店空间的利用，以便顾客也能轻松地导航和获取产品。它可以被视为商店的视觉布局。一个例子在图
    4.24 中展示。'
- en: '![figure](../Images/CH04_F25_Verdhan.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F25_Verdhan.png)'
- en: Figure 4.24 An example of a planogram. Planograms are very useful for visual
    merchandising.
  id: totrans-465
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.24 商品陈列图示例。商品陈列图对视觉营销非常有用。
- en: In the figure, we can see that there are specific areas for each item category.
    Association rules are quite insightful to help generate directions for planograms.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们可以看到每个商品类别都有特定的区域。关联规则非常有洞察力，有助于为商品陈列图提供方向。
- en: 2\. *Data discovery*—The next step is data discovery, wherein the historical
    transactions are scouted and loaded into a database. Typically, a transaction
    can look like table 4.20\. Note it is quite a challenge to convert this data format
    into one that can be consumed by the association rule algorithms.
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. *数据发现*—下一步是数据发现，其中历史交易被搜索并加载到数据库中。通常，一笔交易可以看起来像表 4.20。请注意，将这种数据格式转换为关联规则算法可以消费的格式是一项相当大的挑战。
- en: Table 4.20 Example of invoices generated in a real-world retail store
  id: totrans-468
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.20 实际零售店生成的发票示例
- en: '| Invoice number | Date | Items | Amount |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| 发票号码 | 日期 | 商品 | 金额 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1001  | 01-Jun-21  | Milk, Eggs, Cheese, Bread  | $10  |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 1001  | 01-Jun-21  | 牛奶、鸡蛋、奶酪、面包  | $10  |'
- en: '| 1002  | 01-Jun-21  | Bread, Bananas, Apples, Butter  | $15  |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 1002  | 01-Jun-21  | 面包、香蕉、苹果、黄油  | $15  |'
- en: '| 1003  | 01-Jun-21  | Butter, Carrots, Cheese, Eggs, Bread, Milk, Bananas  |
    $19  |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| 1003  | 01-Jun-21  | 黄油、胡萝卜、奶酪、鸡蛋、面包、牛奶、香蕉  | $19  |'
- en: '| 1004  | 01-Jun-21  | Milk  | $1  |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| 1004  | 01-Jun-21  | 牛奶  | $1  |'
- en: '| 1005  | 01-Jun-21  | Bread  | $0.80  |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| 1005  | 01-Jun-21  | 面包  | $0.80  |'
- en: 3\. *Data preparation*—This step perhaps is the most difficult step. As we have
    seen, association rules model creation is a very simple task. We have libraries
    that can do the heavy lifting for us. But the dataset expected by them is in a
    particular format. This is a tedious task; it is quite time-consuming and requires
    a lot of data preprocessing skills.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3. *数据准备*—这一步可能是最困难的步骤。正如我们所见，关联规则模型的创建是一个非常简单的任务。我们有库可以为我们完成繁重的工作。但它们期望的数据集具有特定的格式。这是一项繁琐的任务；它相当耗时，需要大量的数据预处理技能。
- en: 'There are a few considerations you should keep in mind while preparing the
    dataset:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备数据集时，你应该注意以下几点：
- en: Sometimes we get NULL or blank values during the data preparation phase. Missing
    values in the datasets can lead to problems while computing. In other machine
    learning solutions, we would advise to treat the missing values. In the case of
    association rules, we suggest ignoring the respective transactions and not considering
    them in the final dataset.
  id: totrans-478
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时在数据准备阶段我们会得到NULL或空白值。数据集中的缺失值在计算时可能会导致问题。在其他机器学习解决方案中，我们建议处理缺失值。在关联规则的情况下，我们建议忽略相应的交易，并在最终数据集中不考虑它们。
- en: Many times, we get junk values in the data. Special characters like !@%^&*()_
    are found in the datasets. This can be attributed to incorrect entries in the
    system. Hence, data cleaning is required. We cover the data preprocessing step
    in detail in chapter 11, wherein we deal with NULL values and junk values.
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多时候，我们在数据中会得到垃圾值。数据集中发现了像!@%^&*()_这样的特殊字符。这可以归因于系统中的错误输入。因此，需要数据清洗。我们在第11章详细介绍了数据预处理步骤，其中我们处理NULL值和垃圾值。
- en: Converting a table into a format that can be understood and consumed by the
    association rule learning algorithms is an imperative but arduous step. Go through
    the concept of SQL pivoting to understand the concept better.
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将表格转换为可以被关联规则学习算法理解和消费的格式是一个必要但艰巨的步骤。通过了解SQL透视的概念来更好地理解这一概念。
- en: 4\. *Model preparation*—Perhaps the easiest of the steps is modeling. We have
    already solved Python solutions for different algorithms, so you should be quite
    comfortable with it.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. *模型准备*—也许这是所有步骤中最简单的。我们已经为不同的算法解决了Python解决方案，所以你应该对此相当熟悉。
- en: '5\. *Model interpretation*—Creating the model might be easy, but interpretation
    of the rules is not. Sometimes, you have rules like #NA -> (Milk, Cheese). Such
    a rule is obviously not usable and does not make any sense. It indicates that
    the data preparation was not correct and some junk values are still present in
    the dataset. Another example is (Some items) -> (Packaging material); this is
    perhaps the most obvious rule but, again, not usable. This rule indicates that
    whenever shopping is done, packaging material is also purchased. That’s obvious,
    right? A final example is (Potatoes, Tomatoes) -> (Onions). This kind of rule
    might look correct, but it is a common-sense fact that the retailer would already
    know. Obviously, most of the customers who are buying vegetables will buy potatoes,
    tomatoes, and onions together. Such rules might not add much value to the business.'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5. *模型解释*—创建模型可能很简单，但规则的解释并不容易。有时，你会遇到像#NA -> (Milk, Cheese)这样的规则。这样的规则显然是不可用的，也没有任何意义。它表明数据准备不正确，数据集中仍然存在一些垃圾值。另一个例子是(Some
    items) -> (Packaging material)；这可能是最明显的规则，但同样不可用。这个规则表明，每次购物时，包装材料也会被购买。这不是很明显吗？最后一个例子是(Potatoes,
    Tomatoes) -> (Onions)。这种规则看起来可能是正确的，但常识告诉我们，零售商已经知道这一点。显然，大多数购买蔬菜的顾客都会一起购买土豆、番茄和洋葱。这样的规则可能不会给业务带来太多价值。
- en: The threshold for support, confidence, lift, and conviction allows us to filter
    out the most important rules. We can sort the rules in the descending order of
    the lift and then remove the most obvious ones.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度、置信度、提升和确信度的阈值使我们能够过滤出最重要的规则。我们可以按提升的降序对规则进行排序，然后移除最明显的规则。
- en: It is of vital importance that business stakeholders and subject matter experts
    are involved at every step. In this case study, the operations team, visual merchandising
    team, product teams, and marketing teams are the key players, which should be
    closely aligned at each step.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个步骤中都让业务利益相关者和领域专家参与至关重要。在本案例研究中，运营团队、视觉营销团队、产品团队和营销团队是关键参与者，每个步骤都应紧密协调。
- en: 6\. *Improving the planogram*—Once the rules are generated and accepted, then
    we can use them to improve the planogram for the retail space. The retailer can
    use them to improve the marketing strategy and improve product promotions. For
    example, if a rule like (A, B) -> (C) is accepted, the retailer might wish to
    create a bundle of the products and sell them as a single entity. It will increase
    the average number of items purchased in the same transaction for the business.
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6. *改进商品陈列图*—一旦生成了并接受了规则，我们就可以使用它们来改进零售空间的商品陈列图。零售商可以使用这些规则来改善营销策略和提升产品促销。例如，如果接受了一个像(A,
    B) -> (C)这样的规则，零售商可能希望创建一个产品组合并将其作为一个单一实体出售。这将增加同一交易中购买的平均商品数量。
- en: This case study can be extended to any other domain or business function. For
    example, the same steps can be used if we wish to examine user’s movement across
    web pages. Web developers can analyze the historical clicks and usages of the
    customers on their websites. By identifying the patterns, they can find out what
    users tend to click and which features will maximize their engagement. Medical
    practitioners can use association rules to better diagnose patients. The doctors
    can compare the probability of the symptoms in relationship with other symptoms
    and provide a more accurate diagnosis.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例研究可以扩展到任何其他领域或业务功能。例如，如果我们希望检查用户在网页间的移动，可以使用相同的步骤。网站开发者可以分析客户在其网站上的历史点击和使用情况。通过识别模式，他们可以找出用户倾向于点击哪些内容，以及哪些功能将最大化他们的参与度。医疗从业者可以使用关联规则来更好地诊断患者。医生可以比较症状与其他症状之间的概率，并提供更准确的诊断。
- en: 4.9 Concluding thoughts
  id: totrans-487
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.9 结论性思考
- en: 'There are some assumptions and limitations in the association rules and sequence
    rules we have studied:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的关联规则和序列规则中存在一些假设和限制：
- en: The respective significance of an item is ignored while we generate the rules.
    For example, if a customer purchased five cans of milk and 1 kg of apples in a
    transaction, it is treated similarly to an invoice in which one can of milk and
    5 kg of apples are purchased. Hence, we should bear in mind that the respective
    *weight* of an item is not being considered.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成规则时，我们忽略了项目的相对重要性。例如，如果客户在一次交易中购买了五罐牛奶和1公斤的苹果，这被处理得与购买一罐牛奶和5公斤苹果的发票类似。因此，我们应该记住，项目的相对*权重*没有被考虑。
- en: The cost of an item indicates the perceived value of a product. Some products
    that are costly are more important, and hence, if they are purchased by the customer,
    more revenue can be generated. While analyzing the invoices, we ignore the cost
    associated with an item.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目的成本表明了产品的感知价值。一些昂贵的商品更重要，因此，如果客户购买这些商品，可以产生更多的收入。在分析发票时，我们忽略了与项目相关的成本。
- en: While analyzing the sequence, we have not considered the respective time periods
    between the two transactions. For example, if between T1 and T2 there were 10
    days while between T2 and T3 there were 40 days, both are considered as the same.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分析序列时，我们没有考虑两次交易之间的相应时间段。例如，如果在T1和T2之间有10天，而在T2和T3之间有40天，这两者都被视为相同。
- en: In all the analyses, we have considered different categories as the same. Perishable
    items and nonperishable items are treated in a similar fashion. For example, fresh
    milk with a shelf life of two to three days is treated similarly to washing powder,
    which has a much longer shelf life.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有分析中，我们都将不同的类别视为相同。易腐物品和非易腐物品被以类似的方式处理。例如，保质期为两到三天的鲜奶与保质期较长的洗衣粉被同样对待。
- en: Many times, we receive noninteresting rules after analysis. These results are
    from common sense (Potatoes, Tomatoes) -> (Onion). Such rules are not of much
    use. We face such a problem a lot of the time.
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多时候，我们在分析后收到不有趣的规则。这些结果来自常识（土豆，番茄）->（洋葱）。这样的规则用处不大。我们经常面临这样的问题。
- en: While noninteresting rules are a challenge, a huge number of discovered rules
    are again one of the problems. We get hundreds of rules, and it becomes difficult
    to understand and analyze each one of them. Here the thresholding becomes handy.
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然不有趣的规则是一个挑战，但发现的大量规则又是问题之一。我们得到数百条规则，理解和分析每一条都变得困难。在这里，阈值变得很有用。
- en: The time and memory requirements for computations are huge. The algorithms require
    scanning the datasets many times, and hence it is quite a time-consuming exercise.
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算的时间和内存需求巨大。算法需要多次扫描数据集，因此这是一项相当费时的练习。
- en: The rules generated are dependent on the dataset that has been used for analysis.
    For example, if we analyze the dataset generated during summers only, we cannot
    use the rules for winters as consumers’ preferences change between different weather
    conditions. Moreover, we should refresh the algorithms over time since with the
    passage of time, the macro- and micro-economic factors change and hence the algorithms
    should be refreshed too.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的规则依赖于用于分析的数据库。例如，如果我们只分析夏季生成的数据库，我们无法使用冬季的规则，因为消费者在不同天气条件下的偏好会发生变化。此外，我们应该随着时间的推移刷新算法，因为随着时间的推移，宏观经济和微观经济因素会发生变化，因此算法也应该刷新。
- en: There are some other algorithms that are also of interest. For association rules,
    we can have multirelation association rules, k-optimal pattern discovery, approximate
    frequent datasets, generalized association rules, high-order pattern discovery,
    etc. For sequence mining, we have Generalized Sequence Pattern, FreeSpan, PrefixSpan,
    mining associated patterns, etc. These algorithms are quite interesting and can
    be studied for knowledge enhancement.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他算法也非常有趣。对于关联规则，我们可以有多关系关联规则、k-最优模式发现、近似频繁数据集、广义关联规则、高阶模式发现等。对于序列挖掘，我们有广义序列模式、FreeSpan、PrefixSpan、挖掘关联模式等。这些算法非常有趣，可以用于知识增强。
- en: Association rules and sequence mining are quite interesting topics. Various
    business domains and functions are increasingly using association rules to understand
    the pattern of events. These insights allow the teams to make sound and scientific
    decisions to improve the customer experience and overall engagement. In this chapter,
    we have explored association rules and sequence mining. These were studied using
    Apriori, F-P, and ECLAT algorithms, and for sequence mining we used SPADE.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则和序列挖掘是非常有趣的话题。各个商业领域和功能越来越多地使用关联规则来理解事件模式。这些洞察力使团队能够做出明智和科学的决策，以改善客户体验和整体参与度。在本章中，我们探讨了关联规则和序列挖掘。这些研究使用了Apriori、F-P和ECLAT算法，而对于序列挖掘，我们使用了SPADE。
- en: 4.10 Practical next steps and suggested readings
  id: totrans-499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.10 实际下一步行动和建议阅读
- en: 'The following provides suggestions for what to do next and offers some helpful
    reading:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 以下提供了一些下一步行动的建议和一些有用的阅读材料：
- en: 'Go through these research papers for the association rules algorithm:'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读以下关于关联规则算法的研究论文：
- en: 'Fast Discovery of Association Rules: [https://mng.bz/eyqv](https://mng.bz/eyqv)'
  id: totrans-502
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速发现关联规则：[https://mng.bz/eyqv](https://mng.bz/eyqv)
- en: 'Fast Algorithms for Mining Association Rules: [https://mng.bz/64GZ](https://mng.bz/64GZ)'
  id: totrans-503
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速挖掘关联规则的算法：[https://mng.bz/64GZ](https://mng.bz/64GZ)
- en: 'Efficient Analysis of Pattern and Association Rule Mining Approaches: [https://arxiv.org/pdf/1402.2892.pdf](https://arxiv.org/pdf/1402.2892.pdf)'
  id: totrans-504
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式和关联规则挖掘方法的效率分析：[https://arxiv.org/pdf/1402.2892.pdf](https://arxiv.org/pdf/1402.2892.pdf)
- en: 'A Review of Association Rule Mining Techniques with Respect to their Privacy-Preserving
    Capabilities: [https://mng.bz/0Q0N](https://mng.bz/0Q0N)'
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于关联规则挖掘技术的隐私保护能力的综述：[https://mng.bz/0Q0N](https://mng.bz/0Q0N)
- en: 'For sequence mining, go through these research papers:'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于序列挖掘，阅读以下研究论文：
- en: 'SPADE: An Efficient Algorithm for Mining Frequent Sequences: [https://mng.bz/9YG7](https://mng.bz/9YG7)'
  id: totrans-507
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: SPADE：挖掘频繁序列的高效算法：[https://mng.bz/9YG7](https://mng.bz/9YG7)
- en: 'Sequential Mining: Patterns and Algorithm Analysis: [https://arxiv.org/pdf/1311.0350.pdf](https://arxiv.org/pdf/1311.0350.pdf)'
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列挖掘：模式和算法分析：[https://arxiv.org/pdf/1311.0350.pdf](https://arxiv.org/pdf/1311.0350.pdf)
- en: 'Sequential Pattern Mining Algorithm Based on Interestingness: [https://ieeexplore.ieee.org/document/8567170](https://ieeexplore.ieee.org/document/8567170)'
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于兴趣度的序列挖掘算法：[https://ieeexplore.ieee.org/document/8567170](https://ieeexplore.ieee.org/document/8567170)
- en: 'A New Approach for Problem of Sequential Pattern Mining: [https://mng.bz/jpxr](https://mng.bz/jpxr)'
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决序列模式挖掘问题的新方法：[https://mng.bz/jpxr](https://mng.bz/jpxr)
- en: Summary
  id: totrans-511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Association rule learning identifies relationships between variables in datasets,
    like the beer and diaper example.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则学习识别数据集中变量之间的关系，例如啤酒和尿布的例子。
- en: Through data analysis, such associations can inform marketing strategies, product
    placement, and pricing in supermarkets.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据分析，这些关联可以告知营销策略、超市中的产品摆放和定价。
- en: Market basket analysis in retail uses association rules to find buying patterns
    and is applicable in other industries like bioinformatics.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零售业中的购物篮分析使用关联规则来发现购买模式，并适用于其他行业，如生物信息学。
- en: Association rules consist of antecedents leading to consequents, denoted as
    P -> Q, with no common elements between them.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则由导致后果的前件组成，表示为P -> Q，它们之间没有共同元素。
- en: Rule significance depends on support (frequency), confidence (accuracy), lift
    (dependence measurement), and conviction.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规则的重要性取决于支持度（频率）、置信度（准确性）、提升度（依赖度测量）和确信度。
- en: High support, confidence, lift, and conviction indicate stronger, more useful
    rules.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高支持度、置信度、提升度和确信度表明规则更强、更有用。
- en: The Apriori algorithm generates item sets for association rules using a “bottom-up”
    approach but faces challenges with large datasets.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apriori算法使用“自下而上”的方法生成关联规则的项集，但在处理大数据集时面临挑战。
- en: The ECLAT algorithm uses a depth-first search for faster, memory-efficient computation
    of frequent item sets.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ECLAT算法使用深度优先搜索以实现频繁项集的快速、内存高效的计算。
- en: The F-P growth algorithm improves on Apriori by using a frequent pattern tree
    to eliminate candidate generation.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F-P增长算法通过使用频繁模式树来消除候选生成，在Apriori算法的基础上进行了改进。
- en: Sequence rule mining helps explain user behavior over time, distinct from time-series
    analysis.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列规则挖掘有助于解释用户随时间的行为，与时间序列分析不同。
- en: The SPADE algorithm analyzes sequences of events and dependencies over time
    for sequence rule mining.
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SPADE算法分析事件序列和随时间变化的依赖关系，以进行序列规则挖掘。
- en: Python implementations of the Apriori, ECLAT, F-P growth, and SPADE algorithms
    are achievable with appropriate libraries.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用适当的库可以实现Apriori、ECLAT、F-P增长和SPADE算法的Python实现。
- en: Evaluation metrics and threshold settings for support, confidence, and lift
    are crucial for efficient rule generation.
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于支持度、置信度和提升度的评估指标和阈值设置对于高效规则生成至关重要。
- en: Sequence rule mining has applications in marketing, bioinformatics, and user
    interaction analysis, allowing for actionable insights.
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列规则挖掘在市场营销、生物信息学和用户交互分析中具有应用，允许获得可操作的见解。
