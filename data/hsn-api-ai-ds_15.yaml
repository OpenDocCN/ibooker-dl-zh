- en: Chapter 12\. Using APIs with Artificial Intelligence
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。使用API与人工智能
- en: More AI means more APIs.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 更多的人工智能意味着更多的API。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Frank Kilcommins, SmartBear
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Frank Kilcommins，SmartBear
- en: In technology circles, AI and APIs are sometimes treated as separate specialties.
    But they are closely related, and getting closer all the time. In this chapter,
    you will learn about the ways that AI and APIs overlap, some of the skills you
    should develop, and how to build APIs that are compatible with AI. Then, you will
    set up your Part III portfolio project, which you will use in the remaining chapters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术圈中，人工智能和API有时被视为不同的专业领域。但它们密切相关，并且正在不断接近。在本章中，你将了解人工智能和API的重叠方式，你应该培养的一些技能，以及如何构建与人工智能兼容的API。然后，你将设置你的第三部分项目组合，你将在剩余的章节中使用它。
- en: The Overlap of AI and APIs
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能和API的重叠
- en: To begin with, APIs are important data sources—along with databases and files—for
    training AI models. Once a model is trained, a REST API is a common method to
    make it available for users. You will train a machine learning model in [Chapter 13](ch13.html#chapter_13),
    and deploy it with a REST API.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，API是训练AI模型的重要数据源，与数据库和文件一样。一旦模型训练完成，REST API是使其对用户可用的常见方法。你将在[第13章](ch13.html#chapter_13)中训练一个机器学习模型，并使用REST
    API部署它。
- en: In the same way, cloud-based AI tools are advanced machine learning models that
    are deployed using APIs. AI tools such as generative AI, natural language processing,
    and others are often cloud hosted and made available as APIs. You will call an
    Anthropic large language model (LLM) through a REST API in [Chapter 14](ch14.html#chapter_14).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，基于云的人工智能工具是部署时使用API的高级机器学习模型。生成式人工智能、自然语言处理等AI工具通常托管在云端，并以API的形式提供。你将在[第14章](ch14.html#chapter_14)中通过REST
    API调用Anthropic大型语言模型（LLM）。
- en: An emerging area of overlap between AI and APIs is calling APIs directly from
    *generative AI* applications, which are built using LLMs and interact with users
    via natural language. One type of these applications is called retrieval augmented
    generation (RAG). In a RAG application, the program calls APIs and other data
    sources and then feeds the retrieved information to the LLM along with the user
    prompt. This helps overcome the knowledge gap, in which an LLM only has information
    that it was trained upon.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能和API之间一个新兴的交叉领域是直接从*生成式人工智能*应用中调用API，这些应用是使用LLM构建的，并通过自然语言与用户交互。这类应用中的一种被称为检索增强生成（RAG）。在RAG应用中，程序调用API和其他数据源，然后将检索到的信息连同用户提示一起喂给LLM。这有助于克服LLM仅拥有训练信息的知识差距。
- en: Another type of generative AI application uses LLMs to determine what API endpoints
    to use, which we will call *agentic* applications in this book. The LLMs make
    this decision by interpreting definitions from OAS files, Python code, or API
    documentation. You will create agentic AI applications that call APIs in [Chapter 14](ch14.html#chapter_14)
    with LangChain and in [Chapter 15](ch15.html#chapter_15) with ChatGPT.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种生成式人工智能应用使用LLM来确定使用哪些API端点，在这本书中我们将这类应用称为*代理*应用。LLM通过解释OAS文件、Python代码或API文档中的定义来做出这个决定。你将在[第14章](ch14.html#chapter_14)中使用LangChain，在[第15章](ch15.html#chapter_15)中使用ChatGPT创建调用API的代理人工智能应用。
- en: Designing APIs to Use with Generative AI and LLMs
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计与生成式人工智能和LLM一起使用的API
- en: So, how should you design an API so that a generative AI application can use
    it, as Doerrfield recommends? This field is changing rapidly, but here are some
    initial tips that apply to LangChain ([Chapter 14](ch14.html#chapter_14)) and
    ChatGPT ([Chapter 15](ch15.html#chapter_15)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你应该如何设计一个API，以便生成式人工智能应用可以使用它，正如Doerrfield所建议的？这个领域正在迅速变化，但以下是一些适用于LangChain（[第14章](ch14.html#chapter_14)）和ChatGPT（[第15章](ch15.html#chapter_15)）的初步建议。
- en: First, you need to consider whether an API or endpoint is appropriate to use
    with an agentic generative AI application without additional safeguards in place.
    The providers of LLMs provide warnings such as that LLMs should not be used “on
    their own in high-risk situations” (Anthropic Claude 3) and that they “may sometimes
    provide inaccurate information” (Google NotebookLM). ChatGPT’s documentation simply
    admonishes the user to “check important info.”
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要考虑在没有额外安全措施的情况下，是否可以使用API或端点与代理生成式人工智能应用一起使用。LLM的提供者提供了警告，例如LLM不应在“高风险情况下单独使用”（Anthropic
    Claude 3）以及它们“有时可能提供不准确的信息”（Google NotebookLM）。ChatGPT的文档只是告诫用户“检查重要信息”。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Researchers and machine learning engineers are exploring additional methods
    to address risks of using LLMs for API calls and performing other business tasks.
    Some potential safeguards include requiring a human to approve tasks recommended
    by LLMs before executing, combining multiple AI agents to review tasks before
    executing, reviewing and filtering inputs and outputs to the models, and reviewing
    logs of the functioning of the system. In addition, foundational practices of
    API management and security are required when LLMs use APIs—just as they are when
    conventional software uses APIs. A key security practice is to restrict the permissions
    provided to systems that include LLMs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员和机器学习工程师正在探索额外的方法来应对使用LLM进行API调用和其他业务任务的风险。一些潜在的安全措施包括在执行前要求人工批准LLM推荐的任务，在执行前结合多个AI代理审查任务，审查和过滤模型输入输出，以及审查系统运行日志。此外，当LLM使用API时，需要遵循API管理和安全的基础实践——就像传统软件使用API时一样。一项关键的安全实践是限制包括LLM在内的系统所提供的权限。
- en: 'For APIs that are appropriate, here are some design tips based on my own experience
    and on Blobr’s [“Is Your API AI-ready? Our Guidelines and Best Practices”](https://oreil.ly/jxllA):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于合适的API，以下是一些基于我的经验和Blobr的[“您的API是否为AI准备好了？我们的指南和最佳实践”](https://oreil.ly/jxllA)的建议：
- en: Limit the size of the data results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 限制数据结果的大小。
- en: 'This is important for cost and accuracy. From a cost perspective, model providers
    charge for processing *tokens*, which are chunks of text. The size of these tokens
    differs, but the bottom line is the same: the more data a model processes, the
    greater the cost. In addition to the cost, developers using ChatGPT have found
    that it struggles to perform calculations from very large datasets returned by
    APIs. If you are using a model to perform calculations, limiting the size of the
    data results improves its accuracy.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这对成本和准确性都很重要。从成本角度来看，模型提供商按处理*令牌*收费，这些令牌是文本块。这些令牌的大小不同，但底线是相同的：模型处理的数据越多，成本就越高。除了成本之外，使用ChatGPT的开发者发现，它难以从API返回的非常大的数据集中进行计算。如果您使用模型进行计算，限制数据结果的大小可以提高其准确性。
- en: There are a few ways to accomplish this. Rather than returning all fields related
    to an entity, return only the critical fields. If an API returns child records
    in a collection (e.g., `product.orders`), exclude these from the results and make
    them available in a separate endpoint. Add parameters, filters, and pagination
    to narrow down the specific records in the API call.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点有几种方法。与其返回与实体相关的所有字段，不如只返回关键字段。如果一个API在集合中返回子记录（例如，`product.orders`），则从结果中排除这些记录，并在单独的端点中提供它们。添加参数、过滤器以及分页来缩小API调用中特定记录的范围。
- en: Make data structures consistent throughout the API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个API中保持数据结构的一致性。
- en: The more predictable the API is, the more accurately an AI can use it. By re-using
    schemas inside your APIs and defining them in your OAS file, you will help the
    LLM know what to expect in the results. You used Pydantic in the API you created
    in [Part I](part01.html#part_1), which enforced standard schemas and published
    them in your OAS file.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: API越可预测，AI就能越准确地使用它。通过在您的API中重用模式并在OAS文件中定义它们，您将帮助LLM了解结果中可以期待什么。您在[第一部分](part01.html#part_1)中创建的API使用了Pydantic，它强制执行标准模式并在您的OAS文件中发布。
- en: Provide a software development kit (SDK).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 提供软件开发工具包（SDK）。
- en: Providing an SDK is a way to provide a subset of endpoints and customized API
    calls that are appropriate for an AI application. The SDK can also include detailed
    explanations of the API calls and parameters that assist an LLM in understanding
    its usage. In [Chapter 14](ch14.html#chapter_14), you’ll use the swcpy SDK with
    LangChain and LangGraph.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 提供SDK是一种提供适合AI应用程序的端点子集和定制API调用的方法。SDK还可以包括API调用和参数的详细说明，帮助LLM理解其用法。在[第14章](ch14.html#chapter_14)中，您将使用swcpy
    SDK与LangChain和LangGraph一起使用。
- en: Customize your OpenAPI Specification (OAS).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 定制您的OpenAPI规范（OAS）。
- en: Some methods of using generative AI support reading the OAS file to infer API
    endpoints to call. You can create a customized OAS file with AI-appropriate endpoints
    and detailed descriptions of each endpoint and parameter that assist the LLM in
    inferring their meaning. Endpoints in the OAS file should have unique and clear
    operation IDs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一些使用生成式AI的方法支持读取OAS文件以推断API端点进行调用。您可以使用AI合适的端点和每个端点及参数的详细描述来创建定制的OAS文件，这些描述有助于LLM推断其含义。OAS文件中的端点应具有独特且清晰的操作ID。
- en: Provide a separate endpoint for summary statistics.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个用于摘要统计的单独端点。
- en: If users ask the AI questions about summary information and counts, the LLM’s
    behavior can be erratic. It may try to perform a scan of every record in the API,
    it may just look at the record identifiers and infer this is the count, or it
    may try something completely different. Providing dedicated endpoints takes some
    of the guesswork out.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户询问人工智能关于摘要信息和计数的问题，LLM的行为可能会不稳定。它可能会尝试扫描API中的每条记录，它可能会只查看记录标识符并推断这是计数，或者它可能会尝试完全不同的事情。提供专用端点可以减少一些猜测。
- en: Provide a search endpoint that doesn’t rely on a record identifier.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个不依赖于记录标识符的搜索端点。
- en: LLMs are more comfortable using language than numbers. They like to search based
    on the information that users are likely to ask them.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: LLM更擅长使用语言而不是数字。它们喜欢根据用户可能提出的信息进行搜索。
- en: Defining Artificial Intelligence
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义人工智能
- en: Artificial Intelligence is technology that enables computers and machines to
    simulate human learning, comprehension, problem solving, decision making, creativity
    and autonomy.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能是一种使计算机和机器能够模拟人类学习、理解、问题解决、决策、创造力和自主性的技术。
- en: ''
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “What Is Artificial Intelligence (AI)?”, Cole Stryker and Eda Kavlakoglu, IBM
    Corporation, 2024
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “什么是人工智能（AI）？”，Cole Stryker 和 Eda Kavlakoglu，IBM公司，2024
- en: Aside from that formal definition of AI, an informal definition today is that
    AI is a computer program that can have humanlike conversations and complete humanlike
    tasks. AI includes *expert systems*, which have been around for decades. These
    are complicated rules-based systems that can perform humanlike tasks. Modern AI
    focuses on *machine learning*, in which researchers direct the training of models
    but don’t explicitly program them. Generative AI using LLMs is one major application
    of machine learning.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了人工智能的正式定义之外，今天的非正式定义是：人工智能是一种能够进行类似人类对话和完成类似人类任务的计算机程序。人工智能包括*专家系统*，这些系统已经存在了几十年。这些是复杂的基于规则的系统，可以执行类似人类任务。现代人工智能专注于*机器学习*，其中研究人员指导模型的训练，但并不明确编程它们。使用大型语言模型（LLM）的生成式人工智能是机器学习的一个重要应用。
- en: '[Figure 12-1](#general_ID_diagram_ch12) demonstrates how these terms relate
    to one another.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-1](#general_ID_diagram_ch12) 展示了这些术语是如何相互关联的。'
- en: '![Diagram of AI terminology](assets/haad_1201.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能术语图](assets/haad_1201.png)'
- en: Figure 12-1\. Diagram of AI terminology
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1\. 人工智能术语图
- en: Generative AI and Large Language Models (LLMs)
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能和大型语言模型（LLM）
- en: Although machine learning is used in many different applications, most of the
    attention from the general public in recent years has been given to generative
    AI. The ability of these applications to generate text, music, and videos based
    on text prompts has led to rapid adoption in applications such as OpenAI’s ChatGPT,
    Microsoft’s Copilot, Google’s Gemini, and many additions to other software applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习在许多不同的应用中使用，但近年来公众的关注主要集中在生成式人工智能上。这些应用能够根据文本提示生成文本、音乐和视频的能力，导致了在OpenAI的ChatGPT、微软的Copilot、谷歌的Gemini以及其他许多软件应用中的快速采用。
- en: Despite the impressive capabilities of these applications, generative AI also
    has many risks and limitations associated with it. Providers of some popular models
    include warnings about bias, hallucinations, mistakes, and harmful content. These
    are major risks that should be taken seriously by developers who use them. Chapters
    [14](ch14.html#chapter_14) and [15](ch15.html#chapter_15) have more details on
    the risks and limitations of the models demonstrated in those chapters.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些应用的能力令人印象深刻，但生成式人工智能也伴随着许多风险和限制。一些流行模型的提供者包括关于偏见、幻觉、错误和有害内容的警告。这些是使用它们的开发者应该认真对待的主要风险。第
    [14](ch14.html#chapter_14) 章和 [15](ch15.html#chapter_15) 章有关于这些章节中展示的模型的风险和限制的更多细节。
- en: Creating Agentic AI Applications
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建具有代理性的人工智能应用
- en: As Doerrfield mentions, AI agents are at the forefront of AI research and development.
    An *agent* is software that controls application flow using an LLM. The more autonomously
    the LLM controls the system, the more *agentic* the system is.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如Doerrfield所提到的，人工智能代理处于人工智能研究和开发的前沿。*代理*是一种使用LLM控制应用程序流程的软件。LLM越能自主地控制系统，系统就越具有*代理性*。
- en: Creating AI agents using LLMs is a new field, and a variety of different tools
    have been released to create agents or orchestrate multiple agents to perform
    tasks. [Table 12-1](#frameworks_table_ch12) lists several open source frameworks
    for developing agents and LLM-based applications.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型 (LLM) 创建 AI 代理是一个新兴领域，已经发布了各种不同的工具来创建代理或编排多个代理以执行任务。[表 12-1](#frameworks_table_ch12)
    列出了几个用于开发代理和基于 LLM 的应用程序的开源框架。
- en: Table 12-1\. AI agent frameworks
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-1\. AI 代理框架
- en: '| Software | Programming languages supported |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 软件 | 支持的编程语言 |'
- en: '| --- | --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Autogen | Python, dotnet |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Autogen | Python, dotnet |'
- en: '| CrewAI | Python |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| CrewAI | Python |'
- en: '| LangChain/LangGraph | Python |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| LangChain/LangGraph | Python |'
- en: '| LlamaIndex | Python, Typescript |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| LlamaIndex | Python, Typescript |'
- en: '| PydanticAI | Python |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| PydanticAI | Python |'
- en: '| Vercel AI SDK | Typescript |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Vercel AI SDK | Typescript |'
- en: You will use LangChain and LangGraph in [Chapter 14](ch14.html#chapter_14) to
    call APIs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在 [第 14 章](ch14.html#chapter_14) 中使用 LangChain 和 LangGraph 来调用 API。
- en: Introducing Your Part III Portfolio Project
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍您的第三部分投资组合项目
- en: 'You will create a portfolio project that demonstrates your ability to work
    with API and AI. Here is an overview of the work ahead of you:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您将创建一个投资组合项目，以展示您使用 API 和 AI 的能力。以下是您接下来工作的概述：
- en: '[Chapter 13](ch13.html#chapter_13): Deploying a machine learning API'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 13 章](ch13.html#chapter_13)：部署机器学习 API'
- en: '[Chapter 14](ch14.html#chapter_14): Using APIs with LangChain'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 14 章](ch14.html#chapter_14)：使用 LangChain 与 API 交互'
- en: '[Chapter 15](ch15.html#chapter_15): Using ChatGPT to call your API'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 15 章](ch15.html#chapter_15)：使用 ChatGPT 调用您的 API'
- en: Each of these tasks will enable you to showcase your API and AI skills in a
    unique way.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务中的每一个都将使您以独特的方式展示您的 API 和 AI 技能。
- en: Getting Started with Your GitHub Codespace
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用您的 GitHub Codespace
- en: You will continue to use GitHub Codespaces for all the code you develop in Part
    III. If you didn’t create a GitHub account yet, do that now.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您将继续使用 GitHub Codespaces 来开发第三部分的所有代码。如果您还没有创建 GitHub 账户，请现在创建一个。
- en: Cloning the Part III Repository
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克隆第三部分仓库
- en: All of the [Part III](part03.html#part_3) code examples are contained in [this
    book’s GitHub repository](https://github.com/handsonapibook/api-book-part-three).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 [第三部分](part03.html#part_3) 的代码示例都包含在这本书的 GitHub 仓库中 [this book’s GitHub repository](https://github.com/handsonapibook/api-book-part-three)。
- en: 'To clone the repository, log in to GitHub and go the [GitHub Import Repository
    page](https://github.com/new/import). Enter the following information in the fields
    on this page:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要克隆仓库，请登录到 GitHub 并转到 [GitHub 导入仓库页面](https://github.com/new/import)。在此页面的字段中输入以下信息：
- en: 'The URL for your source repository: **`https://github.com/handsonapibook/api-book-part-three`**'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您源代码仓库的 URL：**`https://github.com/handsonapibook/api-book-part-three`**
- en: 'Your username for your source code repository: Leave blank.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您源代码仓库的用户名：留空。
- en: 'Your access token or password for your source code repository: Leave blank.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您源代码仓库的访问令牌或密码：留空。
- en: 'Repository name: **`ai-project`**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仓库名称：**`ai-project`**
- en: 'Public: Select this so that you can share the results of the work you are doing.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公开：选择此选项，以便您可以分享您正在进行的工作的结果。
- en: Click Begin Import. The import process will begin, and the message “Preparing
    your new repository” will be displayed. After several minutes, you will receive
    an email notifying you that your import has finished. Follow the link to your
    new cloned repository.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“开始导入”。导入过程将开始，并显示“准备您的新的仓库”消息。几分钟后，您将收到一封电子邮件通知您导入已完成。点击链接访问您新克隆的仓库。
- en: Launching Your GitHub Codespace
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动您的 GitHub Codespace
- en: In your new repository, click the Code button and select the Codespaces tab.
    Click “Create codespace on main.” You should see a page with the status “Setting
    up your codespace”. Your Codespace window will be opened as the setup continues.
    When the setup completes, your display will look similar to [Figure 12-2](#codespace_setup_complete_ch12).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的新仓库中，点击“代码”按钮并选择“Codespaces”标签。点击“在主分支上创建 codespace”。您应该会看到一个状态为“设置您的 codespace”的页面。在设置过程中，您的
    Codespace 窗口将被打开。当设置完成时，您的显示将类似于 [图 12-2](#codespace_setup_complete_ch12)。
- en: '![GitHub Codespace for Part 3](assets/haad_1202.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![第三部分的 GitHub Codespace](assets/haad_1202.png)'
- en: Figure 12-2\. GitHub Codespace for Part III
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 第三部分的 GitHub Codespace
- en: Your Codespace is now created with the cloned repository. This is the environment
    you will be using for Part III of this book. Open the [GitHub Codespaces page](https://oreil.ly/nLbqH)
    and scroll down the page to find this new Codespace, click the ellipsis to the
    right of the name, and select Rename. Enter the name **`Part 3 Portfolio project
    codespace`** and click Save. You should see the message “Your codespace *Part
    3 Portfolio project codespace* has been updated.” Click the ellipsis again and
    then click the ribbon next to “Auto-delete codespace” to turn off auto-deletion.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 Codespace 现在已通过克隆的仓库创建。这将是你使用本书第三部分的环境。打开 [GitHub Codespaces 页面](https://oreil.ly/nLbqH)，滚动到页面底部找到这个新的
    Codespace，点击名称右侧的省略号，选择重命名。输入名称 **`Part 3 Portfolio project codespace`** 并点击保存。您应该会看到消息“您的
    codespace *Part 3 Portfolio project codespace* 已更新。”再次点击省略号，然后点击“自动删除 codespace”旁边的彩带以关闭自动删除功能。
- en: Note
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'To save space on the page, I have trimmed the directory listing in the terminal
    prompt of my Codespace. You can do this in your Codespace by editing the */home/codespace/.bashrc*
    file in VS Code. Find the `export PROMPT_DIRTRIM` statement and set it to `export
    PROMPT_DIRTRIM=1`. To load the values the first time, execute this terminal command:
    `source ~/.bashrc`.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在页面上节省空间，我已经在我的 Codespace 的终端提示符中修剪了目录列表。您可以在您的 Codespace 中通过编辑 VS Code 中的
    */home/codespace/.bashrc* 文件来实现这一点。找到 `export PROMPT_DIRTRIM` 语句并将其设置为 `export
    PROMPT_DIRTRIM=1`。要首次加载这些值，请执行以下终端命令：`source ~/.bashrc`。
- en: Additional Resources
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: To view a 100-point scorecard for AI compatibility of APIs, read Blobr’s [“Is
    Your API AI-ready? Our Guidelines and Best Practices”](https://oreil.ly/JLaK1).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 API 人工智能兼容性的 100 分评分卡，请阅读 Blobr 的文章“Is Your API AI-ready? Our Guidelines
    and Best Practices” [链接](https://oreil.ly/JLaK1)。
- en: 'To see an example of working around the limitations of a GPT, read [“Syntax
    Sunday: Custom API Wrapper for GPTs” by Kade Halabuza](https://oreil.ly/khh0J).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '要了解如何绕过 GPT 的限制的示例，请阅读 Kade Halabuza 的文章“Syntax Sunday: Custom API Wrapper
    for GPTs” [链接](https://oreil.ly/khh0J)。'
- en: To learn more about possible futures of AI and APIs, read [“AI + APIs — What
    12 Experts Think The Future Holds” by Peter Schroeder](https://oreil.ly/t2lxH).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 AI 和 API 可能的未来，请阅读 Peter Schroeder 的文章“AI + APIs — What 12 Experts Think
    The Future Holds” [链接](https://oreil.ly/t2lxH)。
- en: Summary
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced the basics of AI and explained how it relates to APIs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了人工智能的基础知识，并解释了它与 API 的关系。
- en: In [Chapter 13](ch13.html#chapter_13), you will create a machine learning model
    and deploy it using FastAPI.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 13 章](ch13.html#chapter_13) 中，您将创建一个机器学习模型并使用 FastAPI 进行部署。
