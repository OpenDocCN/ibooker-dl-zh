- en: Chapter 10\. Interpretation of Deep Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第十章。深度模型的解释
- en: At this point we have seen lots of examples of training deep models to solve
    problems. In each case we collect some data, build a model, and train it until
    it produces the correct outputs on our training and test data. Then we pat ourselves
    on the back, declare the problem to be solved, and go on to the next problem.
    After all, we have a model that produces correct predictions for input data. What
    more could we possibly want?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了许多训练深度模型解决问题的例子。在每种情况下，我们收集一些数据，构建一个模型，并训练它，直到它在我们的训练和测试数据上产生正确的输出。然后我们为自己鼓掌，宣布问题已经解决，然后继续下一个问题。毕竟，我们有一个为输入数据产生正确预测的模型。我们还能想要什么？
- en: But often that is only the beginning! Once you finish training the model there
    are lots of important questions you might ask. How does the model work? What aspects
    of an input sample led to a particular prediction? Can you trust the model’s predictions?
    How accurate are they? Are there situations where it is likely to fail? What exactly
    has it “learned”? And can it lead to new insights about the data it was trained
    on?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但通常这只是一个开始！一旦您完成训练模型，您可能会有很多重要的问题要问。模型是如何工作的？输入样本的哪些方面导致了特定的预测？您可以信任模型的预测吗？它们有多准确？有哪些情况可能会导致失败？它到底“学到”了什么？它是否能带来关于训练数据的新见解？
- en: All of these questions fall under the topic of *interpretability*. It covers
    everything you might want from a model beyond mechanically using it to make predictions.
    It is a very broad subject, and the techniques it encompasses are as diverse as
    the questions they try to answer. We cannot hope to cover all of them in just
    one chapter, but we will try to at least get a taste of some of the more important
    approaches.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题都属于*可解释性*的范畴。它涵盖了您可能希望从模型中获得的一切，而不仅仅是机械地使用它进行预测。这是一个非常广泛的主题，它所包含的技术与它们试图回答的问题一样多样。我们无法希望在仅有一章中涵盖所有内容，但我们将尝试至少尝试一些更重要的方法。
- en: To do this, we will revisit examples from earlier chapters. When we saw them
    before, we just trained models to make predictions, verified their accuracy, and
    then considered our work complete. Now we will take a deeper look and see what
    else we can learn.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将重新审视之前章节中的例子。当我们之前看到它们时，我们只是训练模型进行预测，验证其准确性，然后认为我们的工作完成了。现在我们将深入研究，看看我们还能学到什么。
- en: Explaining Predictions
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释预测
- en: Suppose you have trained a model to recognize photographs of different kinds
    of vehicles. You run it on your test set and find it accurately distinguishes
    between cars, boats, trains, and airplanes. Does that make it ready to put into
    production? Can you trust it to keep producing accurate results in the future?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经训练了一个模型来识别不同种类车辆的照片。您在测试集上运行它，并发现它准确区分了汽车、船只、火车和飞机。这是否意味着它已经准备投入生产？您可以信任它在未来继续产生准确的结果吗？
- en: Maybe, but if wrong results lead to serious consequences you might find yourself
    wishing for some further validation. It would help if you knew *why* the model
    produced its particular predictions. Does it really look at the vehicle, or is
    it actually relying on unrelated aspects of the image? Photos of cars usually
    also include roads. Airplanes tend to be silhouetted against the sky. Pictures
    of trains usually include tracks, and ones of boats include lots of water. If
    the model is really identifying the background rather than the vehicle, it may
    do well on the test set but fail badly in unexpected cases. A boat silhouetted
    against the sky might be classified as an airplane, and a car driving past water
    might be identified as a boat.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 也许，但如果错误的结果导致严重后果，您可能会希望进行进一步的验证。如果您知道模型为什么产生特定的预测，那将会有所帮助。它是否真的看到了车辆，还是实际上依赖于图像的无关方面？汽车的照片通常也包括道路。飞机往往是在天空的背景下剪影。火车的图片通常包括轨道，船只的图片包括大量的水。如果模型真的是在识别背景而不是车辆，它可能在测试集上表现良好，但在意外情况下会严重失败。一艘船在天空的背景下可能被分类为飞机，一辆汽车驶过水域可能被识别为船只。
- en: Another possible problem is that the model is fixating on overly specific details.
    Perhaps it does not really identify pictures of *cars*, just pictures that include
    *license plates*. Or perhaps it is very good at identifying life preservers, and
    has learned to associate them with pictures of boats. This will usually work,
    but will fail when shown a car driving past a swimming pool with a life preserver
    visible in the background.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能的问题是模型过于专注于细节。也许它并不真正识别*汽车*的图片，只是识别包括*车牌*的图片。或者它可能非常擅长识别救生圈，并且已经学会将它们与船只的图片联系起来。这通常会起作用，但当展示一辆汽车驶过一个游泳池，背景中有救生圈可见时，它将失败。
- en: Being able to explain why the model made a prediction is an important part of
    interpretability. When the model identifies a photograph of a car, you want to
    know that it made the identification based on the actual car, not based on the
    road, and not based on only one small part of the car. In short, you want to know
    that it gave the right answer *for the right reasons*. That gives you confidence
    that it will also work on future inputs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 能够解释模型为何做出预测是解释性的重要组成部分。当模型识别出一张汽车的照片时，您希望知道它是基于实际汽车做出识别，而不是基于道路，也不是基于汽车的一个小部分。简而言之，您希望知道它给出了正确答案*出于正确的原因*。这会让您相信它也会在未来的输入上起作用。
- en: As a concrete example, let’s return to the diabetic retinopathy model from [Chapter 8](ch08.xhtml#deep_learning_for_medicine).
    Recall that this model takes an image of a retina as input, and predicts the presence
    and severity of diabetic retinopathy in the patient. Between the input and output
    are dozens of `Layer` objects and more than eight million trained parameters.
    We want to understand why a particular input led to a particular output, but we
    cannot hope to learn that just by looking at the model. Its complexity is far
    beyond human comprehension.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个具体的例子，让我们回到[第8章](ch08.xhtml#deep_learning_for_medicine)中的糖尿病视网膜病变模型。回想一下，这个模型以视网膜图像作为输入，并预测患者患有糖尿病视网膜病变的存在和严重程度。在输入和输出之间有数十个`Layer`对象和超过800万个训练参数。我们想要理解为什么特定的输入导致特定的输出，但我们不能希望仅通过查看模型来学习。它的复杂性远远超出人类理解。
- en: Many techniques have been developed for trying to answer this question. We will
    apply one of the simplest ones, called *saliency mapping*.^([1](ch10.xhtml#idm45806164613576))
    The essence of this technique is to ask which pixels of the input image are most
    important (or “salient”) for determining the output. In some sense, of course,
    *every* pixel is important. The output is a hugely complex nonlinear function
    of all the inputs. In the right image, any pixel might contain signs of disease.
    But in a particular image only a fraction of them do, and we want to know which
    ones they are.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多技术已经被开发出来尝试回答这个问题。我们将应用其中一个最简单的技术，称为*显著性映射*。这种技术的本质是询问输入图像的哪些像素对于确定输出最重要（或“显著”）。在某种意义上，当然，*每个*像素都很重要。输出是所有输入的一个极其复杂的非线性函数。在正确的图像中，任何像素都可能包含疾病的迹象。但在特定图像中，只有其中的一小部分包含，我们想知道它们是哪些。
- en: 'Saliency mapping uses a simple approximation to answer this question: just
    take the derivative of the outputs with respect to all the inputs. If a region
    of the image contains no sign of disease, small changes to any individual pixel
    in that region should have little effect on the output. The derivative should
    therefore be small. A positive diagnosis involves correlations between many pixels.
    When those correlations are absent, they cannot be created just by changing one
    pixel. But when they are present, a change to any one of the participating pixels
    can potentially strengthen or weaken the result. The derivative should be largest
    in the “important” regions the model is paying attention to.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 显著性映射使用一个简单的近似来回答这个问题：只需对所有输入取导数。如果图像的某个区域不包含疾病迹象，那么对该区域中的任何单个像素进行小的更改应该对输出产生很小的影响。导数应该很小。积极的诊断涉及许多像素之间的相关性。当这些相关性不存在时，它们不能仅通过更改一个像素来创建。但当它们存在时，对参与的任何一个像素进行更改可能会加强或削弱结果。导数应该在模型关注的“重要”区域最大。
- en: 'Let’s look at the code. First we need to build the model and reload the trained
    parameter values:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码。首先，我们需要构建模型并重新加载训练参数值：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now we can use the model to make predictions about samples. For example, let’s
    check the predictions for the first 10 test samples:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用模型对样本进行预测。例如，让我们检查前10个测试样本的预测：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the output:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It gets 9 of the first 10 samples right, which is not bad. But what is it looking
    at when it makes its predictions? Saliency mapping can give us an answer. DeepChem
    makes this easy:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 它对前10个样本中的9个做出了正确的预测，这还不错。但是在做出预测时它在看什么呢？显著性映射可以给我们一个答案。DeepChem使这变得容易：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`compute_saliency()` takes the input array for a particular sample and returns
    the derivative of every output with respect to every input. We can get a better
    sense of what this means by looking at the shape of the result:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute_saliency()`接受特定样本的输入数组，并返回每个输出相对于每个输入的导数。我们可以通过查看结果的形状来更好地理解这意味着什么：'
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This reports it is an array of shape `(5, 512, 512, 3)`. `X[0]` is the 0th input
    image, which is an array of shape `(512, 512, 3)`, the last dimension being the
    three color components. In addition, the model has five outputs, the probabilities
    of the sample belonging to each of the five classes. `saliency` contains the derivative
    of each of the five outputs with respect to each of the 512×512×3 inputs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这报告它是一个形状为`(5, 512, 512, 3)`的数组。`X[0]`是第0个输入图像，它是一个形状为`(512, 512, 3)`的数组，最后一个维度是三个颜色分量。此外，模型有五个输出，即样本属于五个类别中的每一个的概率。`saliency`包含每个五个输出相对于每个512×512×3个输入的导数。
- en: 'This needs a little processing to be made more useful. First, we want to take
    the absolute value of every element. We don’t care whether a pixel should be made
    darker or lighter to increase the output, just that it has an effect. Then we
    want to condense it down to just one number per pixel. That could be done in various
    ways, but for now we will simply sum over the first and last dimensions. If any
    color component affects any of the output predictions, that makes the pixel important.
    Finally, we will normalize the values to be between 0 and 1:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要一些处理才能更有用。首先，我们想要取每个元素的绝对值。我们不关心一个像素是否应该变暗或变亮以增加输出，只关心它是否有影响。然后我们想要将其压缩为每个像素仅一个数字。这可以通过各种方式完成，但现在我们将简单地对第一个和最后一个维度求和。如果任何颜色分量影响任何输出预测，那么这个像素就很重要。最后，我们将归一化值为0到1之间：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Let’s see what it looks like. [Figure 10-1](#saliency_map_for_an_image_with_severe_diabetic_retinopathy)
    shows a sample that the model correctly identifies as having severe diabetic retinopathy.
    The input image is on the left, and the right side highlights the most salient
    regions in white.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是什么样子。[图10-1](#saliency_map_for_an_image_with_severe_diabetic_retinopathy)展示了一个模型正确识别为严重糖尿病视网膜病变的样本。左侧是输入图像，右侧突出显示了最显著的区域为白色。
- en: '![A saliency map](Images/dlls_1001.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![一个显著性映射](Images/dlls_1001.png)'
- en: Figure 10-1\. Saliency map for an image with severe diabetic retinopathy.
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1. 严重糖尿病视网膜病变图像的显著性映射。
- en: The first thing we notice is that the saliency is widely spread over the whole
    retina, not just in a few spots. It is not uniform, however. Saliency is concentrated
    along the blood vessels, and especially at points where blood vessels branch.
    Indeed, some of the indications a doctor looks for to diagnose diabetic retinopathy
    include abnormal blood vessels, bleeding, and the growth of new blood vessels.
    The model appears to be focusing its attention on the correct parts of the image,
    the same ones a doctor would look at most closely.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到的第一件事是显著性广泛分布在整个视网膜上，而不仅仅是在几个点上。然而，它并不是均匀的。显著性集中在血管沿线，特别是在血管分叉点。事实上，医生用来诊断糖尿病性视网膜病变的一些指标包括异常的血管、出血和新血管的生长。模型似乎将注意力集中在图像的正确部分，这些部分与医生最密切关注的部分相同。
- en: Optimizing Inputs
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化输入
- en: Saliency mapping and similar techniques tell you what information the model
    was focusing on when it made a prediction. But how exactly did it interpret that
    information? The diabetic retinopathy model focuses on blood vessels, but what
    does it look for to distinguish healthy from diseased blood vessels? Similarly,
    when a model identifies a photograph of a boat, it’s good to know it made the
    identification based on the pixels that make up the boat, not the ones that make
    up the background. But what about those pixels led it to conclude it was seeing
    a boat? Was it based on color? On shape? Combinations of small details? Could
    there be unrelated pictures the model would equally confidently (but incorrectly)
    identify as a boat? What exactly does the model “think” a boat looks like?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 显著性映射和类似技术告诉您模型在进行预测时关注的信息。但它究竟是如何解释这些信息的呢？糖尿病性视网膜病变模型关注血管，但是它是通过什么来区分健康和患病的血管的呢？同样，当模型识别一张船的照片时，了解它是基于构成船的像素，而不是构成背景的像素进行识别是很重要的。但是是什么像素导致它得出看到一艘船的结论呢？是基于颜色吗？形状？小细节的组合？模型是否会同样自信地（但错误地）识别出无关的图片为一艘船？模型究竟认为一艘船是什么样子呢？
- en: A common approach to answering these questions is to search for inputs that
    maximize the prediction probability. Out of all possible inputs you could put
    into the model, which ones lead to the strongest predictions? By examining those
    inputs, you can see what the model is really “looking for.” Sometimes it turns
    out to be very different from what you expect! [Figure 10-2](#fooling) shows images
    that have been optimized to produce strong predictions when fed into a high-quality
    image recognition model. The model identifies each image as the listed category
    with very high confidence, yet to a human they have almost no resemblance!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 回答这些问题的一种常见方法是搜索最大化预测概率的输入。在您可以输入模型的所有可能输入中，哪些会导致最强的预测？通过检查这些输入，您可以看到模型真正“寻找”的是什么。有时结果可能与您的预期非常不同！[图10-2](#fooling)显示了经过优化以在输入到高质量图像识别模型时产生强烈预测的图像。该模型以非常高的置信度将每个图像识别为列出的类别，但对于人类来说，它们几乎没有相似之处！
- en: '![Images that fool a model](Images/dlls_1002.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![欺骗模型的图像](Images/dlls_1002.png)'
- en: 'Figure 10-2\. Images that fool a high-quality image recognition model. (Source:
    [Arxiv.org](https://arxiv.org/abs/1412.1897).)'
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-2。欺骗高质量图像识别模型的图像。（来源：[Arxiv.org](https://arxiv.org/abs/1412.1897)。）
- en: As an example, consider the transcription factor binding model from [Chapter 6](ch06.xhtml#deep_learning_for_genomics).
    Recall that this model takes a DNA sequence as input, and predicts whether the
    sequence contains a binding site for the transcription factor JUND. What does
    it think a binding site looks like? We want to consider all possible DNA sequences
    and find the ones for which the model most confidently predicts that a binding
    site is present.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑来自[第6章](ch06.xhtml#deep_learning_for_genomics)的转录因子结合模型。回想一下，该模型将DNA序列作为输入，并预测该序列是否包含转录因子JUND的结合位点。它认为结合位点是什么样子？我们想要考虑所有可能的DNA序列，并找到模型最有信心地预测存在结合位点的序列。
- en: Unfortunately, we can’t really consider all possible inputs. There are 4^(101)
    possible DNA sequences of length 101\. If you needed only one nanosecond to examine
    each one, it would take many times longer than the age of the universe to get
    through all of them. Instead, we need a strategy to sample a smaller number of
    inputs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法考虑所有可能的输入。长度为101的DNA序列有4^(101)种可能。如果您需要一纳秒来检查每一个，那么要处理完所有这些可能性将需要比宇宙的年龄长得多的时间。相反，我们需要一种策略来采样更少的输入。
- en: One possibility is just to look at the sequences in the training set. In this
    case, that is actually a reasonable strategy. The training set covers tens of
    millions of bases from a real chromosome, so it likely is a good representation
    of the inputs that will be used with this model in practice. [Figure 10-3](#JUND-saliency)
    shows the 10 sequences from the training set for which the model produces the
    highest output. Each of them is predicted to have a binding site with greater
    than 97% probability. Nine of them do in fact have binding sites, while one is
    a false positive. For each one, we have used saliency mapping to identify what
    the model is focusing on and colored the bases by their saliency.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能性是只查看训练集中的序列。在这种情况下，这实际上是一个合理的策略。训练集包含来自真实染色体的数千万个碱基，因此它很可能是该模型在实践中将使用的输入的良好代表。[图10-3](#JUND-saliency)显示了模型产生最高输出的训练集中的10个序列。每个序列被预测具有大于97%概率的结合位点。其中有九个确实有结合位点，而一个是误报。对于每个序列，我们使用显著性映射来确定模型关注的内容，并根据其显著性对碱基进行着色。
- en: '![JUND saliency](Images/dlls_1003.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![JUND显著性](Images/dlls_1003.png)'
- en: Figure 10-3\. The 10 training examples with the highest predicted outputs. Checkmarks
    indicate the samples that contain actual binding sites.
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3。具有最高预测输出的10个训练示例。复选标记表示包含实际结合位点的样本。
- en: 'Looking at these inputs, we can immediately see the core pattern it is recognizing:
    TGA ... TCA, where ... consists of one or two bases that are usually C or G. The
    saliency indicates it also pays some attention to another one or two bases on
    either side. The previous base can be an A, C, or G, and the following base is
    always either a C or T. This agrees with the known binding motif for JUND, which
    is shown in [Figure 10-4](#JUND-binding-motif) as a position weight matrix.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这些输入，我们可以立即看到它所识别的核心模式：TGA ... TCA，其中...由一个或两个通常是C或G的碱基组成。显著性指示它还关注另外一个或两个在两侧的碱基。前一个碱基可以是A、C或G，后一个碱基总是C或T中的一个。这与JUND的已知结合基序一致，该基序在[图10-4](#JUND-binding-motif)中显示为一个位置权重矩阵。
- en: '![JUND binding motif](Images/dlls_1004.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![JUND结合基序](Images/dlls_1004.png)'
- en: Figure 10-4\. The known binding motif for JUND, represented as a position weight
    matrix. The height of each letter indicates the probability of that base appearing
    at the corresponding position.
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-4。JUND的已知结合基序，表示为一个位置权重矩阵。每个字母的高度表示该碱基出现在相应位置的概率。
- en: The one sequence that was incorrectly predicted to have a binding site does
    not contain this pattern. Instead, it has several repetitions of the pattern TGAC,
    all close together. This looks like the beginning of a true binding motif, but
    it is never followed by TCA. Apparently our model has learned to identify the
    true binding motif, but it also can be misled when several incomplete versions
    occur in close proximity.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一一个被错误预测为具有结合位点的序列并不包含这个模式。相反，它有几个重复的TGAC模式，都很接近。这看起来像一个真正的结合基序的开始，但后面从来没有跟着TCA。显然我们的模型已经学会了识别真正的结合基序，但当几个不完整的版本在附近连续出现时，它也会被误导。
- en: The training samples will not always be a good representation of the full range
    of possible inputs. If your training set consists entirely of photographs of vehicles,
    it tells you nothing about how the model responds to other inputs. Perhaps if
    shown a photograph of a snowflake, it would confidently label it as a boat. Perhaps
    there even are inputs that look nothing like photographs—maybe just simple geometric
    patterns or even random noise—that the model would identify as boats. To test
    for this possibility, we can’t rely on the inputs we already have. Instead, we
    need to let the model tell us what it is looking for. We start with a completely
    random input, then use an optimization algorithm to modify it in ways that increase
    the model’s output.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练样本并不总是能很好地代表可能输入的全部范围。如果你的训练集完全由车辆的照片组成，那么它对于模型如何响应其他输入毫无意义。也许如果展示一张雪花的照片，它会自信地将其标记为一艘船。也许甚至有一些看起来完全不像照片的输入——也许只是简单的几何图案或者随机噪音——模型会将其识别为船。为了测试这种可能性，我们不能依赖于我们已经有的输入。相反，我们需要让模型告诉我们它在寻找什么。我们从一个完全随机的输入开始，然后使用优化算法以增加模型输出的方式修改它。
- en: 'Let’s try doing this for the TF binding model. We begin by generating a completely
    random sequence and computing the model’s prediction for it:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试为TF结合模型做同样的事情。我们首先生成一个完全随机的序列，并计算模型对其的预测：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now to optimize it. We randomly select a position within the sequence and a
    new base to set it to. If this change causes the output to increase, we keep it.
    Otherwise, we discard the change and try something else:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来优化它。我们随机选择序列内的一个位置和一个新的碱基来设置它。如果这个改变导致输出增加，我们就保留它。否则，我们放弃这个改变并尝试其他方法：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This rapidly leads to sequences that maximize the predicted probability. Within
    1,000 steps, we usually find the output has saturated and equals 1.0.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这很快导致了最大化预测概率的序列。在1,000步内，我们通常发现输出已经饱和并等于1.0。
- en: '[Figure 10-5](#JUND-optimized-sequences) shows 10 sequences generated by this
    process. All instances of the three most common binding patterns (TGACTCA, TGAGTCA,
    and TGACGTCA) are highlighted. Every sequence contains at least one occurrence
    of one of these patterns, and usually three or four. Sequences that maximize the
    model’s output have exactly the properties we expect them to, which gives us confidence
    that the model is working well.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-5](#JUND-optimized-sequences)显示了通过这个过程生成的10个序列。所有三种最常见的结合模式（TGACTCA、TGAGTCA和TGACGTCA）的所有实例都被突出显示。每个序列至少包含其中一种模式的一个出现，通常是三个或四个。最大化模型输出的序列恰好具有我们期望的属性，这让我们对模型的工作效果感到满意。'
- en: '![example sequences to maximize model output](Images/dlls_1005.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![用于最大化模型输出的示例序列](Images/dlls_1005.png)'
- en: Figure 10-5\. Example sequences that have been optimized to maximize the model’s
    output.
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-5。已经优化以最大化模型输出的示例序列。
- en: Predicting Uncertainty
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测不确定性
- en: 'Even when you have convinced yourself that a model produces accurate predictions,
    that still leaves an important question: exactly *how* accurate are they? In science,
    we are rarely satisfied with just a number; we want an uncertainty for every number.
    If the model outputs 1.352, should we interpret that as meaning the true value
    is between 1.351 and 1.353? Or between 0 and 3?'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你已经确信一个模型能够产生准确的预测，这仍然留下一个重要的问题：它们究竟有多准确？在科学中，我们很少满足于仅仅一个数字；我们希望每个数字都有一个不确定性。如果模型输出1.352，我们应该将其解释为真实值在1.351和1.353之间吗？还是在0和3之间？
- en: As a concrete example, we will use the solubility model from [Chapter 4](ch04.xhtml#machine_learning_for_molecules).
    Recall that this model takes a molecule as input, represented as a molecular graph,
    and outputs a number indicating how easily it dissolves in water. We built and
    trained the model with the following code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个具体的例子，我们将使用[第4章](ch04.xhtml#machine_learning_for_molecules)中的溶解度模型。回想一下，这个模型以分子图表示的分子作为输入，并输出一个数字，指示它在水中溶解的容易程度。我们用以下代码构建和训练了这个模型。
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When we first examined this model, we evaluated its accuracy on the test set
    and declared ourselves satisfied. Now let’s try to do a better job of quantifying
    its accuracy.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首次检查这个模型时，我们评估了它在测试集上的准确性，并表示满意。现在让我们试着更好地量化它的准确性。
- en: 'A very simple thing we might try doing is just to compute the root-mean-squared
    (RMS) error of the model’s predictions on the test set:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试的一个非常简单的事情就是计算模型在测试集上预测的均方根（RMS）误差：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This reports an RMS error of 0.396\. Should we therefore use that as the expected
    uncertainty in all predictions made by the model? *If* the test set is representative
    of all inputs the model will be used on, and *if* all errors follow a single distribution,
    that might be a reasonable thing to do. Unfortunately, neither of those is a safe
    assumption! Some predictions may have much larger errors than others, and depending
    on the particular molecules that happen to be in the test set, their average error
    might be either higher or lower than what you will encounter in practice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这报告了一个RMS误差为0.396。因此，我们是否应该将其用作模型进行的所有预测的预期不确定性？*如果*测试集代表模型将用于的所有输入，并且*如果*所有错误都遊一个分布，那可能是一个合理的做法。不幸的是，这两者都不是安全的假设！一些预测可能比其他预测具有更大的误差，并且根据恰好在测试集中的特定分子，它们的平均误差可能比您在实践中遇到的要高或低。
- en: We really want to associate a different uncertainty with every output. We want
    to know in advance which predictions are more accurate and which are less accurate.
    To do that, we need to consider more carefully the multiple factors that contribute
    to errors in a model’s predictions.^([2](ch10.xhtml#idm45806163802088)) As we
    will see, there are two fundamentally different types of uncertainty that must
    be included.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们真的希望将不同的不确定性与每个输出关联起来。我们想提前知道哪些预测更准确，哪些不太准确。为了做到这一点，我们需要更仔细地考虑导致模型预测中错误的多个因素。正如我们将看到的，必须包括两种根本不同类型的不确定性。
- en: '[Figure 10-6](#true_versus_predicted_solubilities) shows the true versus predicted
    solubilities of the molecules in the training set. The model is doing a very good
    job of reproducing the training set, but not a perfect job. The points are distributed
    in a band with finite width around the diagonal. Even though it was trained on
    those samples, the model still has some error when predicting them. Given that,
    we have to expect it to have *at least* as much error on other data it was not
    trained on.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-6](#真实与预测的溶解度)显示了训练集中分子的真实与预测的溶解度。该模型在复制训练集方面做得非常好，但并非完美。点分布在对角线周围具有有限宽度的带状区域内。即使它是在这些样本上训练的，模型在预测它们时仍然存在一些误差。鉴于此，我们必须期望它在其他未经训练的数据上至少有同样多的误差。'
- en: '![True versus predicted solubilities](Images/dlls_1006.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![真实与预测的溶解度](Images/dlls_1006.png)'
- en: Figure 10-6\. True versus predicted solubilities for the molecules in the training
    set.
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-6。训练集中分子的真实与预测的溶解度。
- en: 'Notice that we are only looking at the training set. This uncertainty can be
    determined entirely from information that is available at training time. That
    means we can train a model to predict it! We can add another set of outputs to
    the model: for every value it predicts, it will also output an estimate of the
    uncertainty in that prediction.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们只看训练集。这种不确定性可以完全根据训练时可用的信息确定。这意味着我们可以训练一个模型来预测它！我们可以向模型添加另一组输出：对于它预测的每个值，它还将输出一个对该预测的不确定性的估计。
- en: Now consider [Figure 10-7](#solubility-variation). We have repeated the training
    process 10 times, giving us 10 different models. We have used each of them to
    predict the solubility of 10 molecules from the test set. All of the models were
    trained on the same data, and they have similar errors on the training set, yet
    they produce different predictions for the test set molecules! For each molecule,
    we get a range of different solubilities depending on which model we use.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑[图10-7](#溶解度变化)。我们已经重复了训练过程10次，得到了10个不同的模型。我们已经使用每个模型来预测测试集中10个分子的溶解度。所有模型都是在相同的数据上训练的，并且它们在训练集上有类似的误差，但是它们对测试集分子的预测却不同！对于每个分子，根据我们使用的模型不同，我们得到了一系列不同的溶解度。
- en: '![Solubilities of ten molecules](Images/dlls_1007.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![十个分子的溶解度](Images/dlls_1007.png)'
- en: Figure 10-7\. Solubilities of 10 molecules from the test set, as predicted by
    a set of models all trained on the same data.
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-7。由所有在相同数据上训练的模型预测的测试集中10个分子的溶解度。
- en: This is a fundamentally different type of uncertainty, known as *epistemic uncertainty*.
    It comes from the fact that many different models fit the training data equally
    well, and we don’t know which one is “best.”
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种根本不同的不确定性类型，称为*认知不确定性*。这是因为许多不同的模型都能很好地拟合训练数据，而我们不知道哪一个是“最佳”的。
- en: A straightforward way to measure epistemic uncertainty is to train many models
    and compare their results, as we have done in [Figure 10-7](#solubility-variation).
    Often this is prohibitively expensive, however. If you have a large, complicated
    model that takes weeks to train, you don’t want to repeat the process many times.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量认知不确定性的一种直接方法是训练许多模型并比较它们的结果，就像我们在[图10-7](#溶解度变化)中所做的那样。然而，通常这是代价高昂的。如果您有一个需要数周才能训练的庞大复杂模型，您不希望多次重复该过程。
- en: A much faster alternative is to train a single model using dropout, then predict
    each output many times with different dropout masks. Usually dropout is only performed
    at training time. If 50% of the outputs from a layer are randomly set to 0 in
    each training step, at test time you would instead multiply *every* output by
    0.5\. But let’s not do that. Let’s randomly set half the outputs to 0, then repeat
    the process with many different random masks to get a collection of different
    predictions. The variation between the predicted values gives a pretty good estimate
    of the epistemic uncertainty.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更快的替代方法是使用dropout训练单个模型，然后使用不同的dropout掩码多次预测每个输出。通常，dropout只在训练时执行。如果在每个训练步骤中有50%的输出被随机设置为0，那么在测试时，您将改为将*每个*输出乘以0.5。但我们不这样做。我们随机将一半的输出设置为0，然后使用许多不同的随机掩码重复该过程，以获得一系列不同的预测。预测值之间的变化给出了对认知不确定性的相当好的估计。
- en: Notice how your modeling choices involve trade offs between these two kinds
    of uncertainty. If you use a large model with lots of parameters, you can get
    it to fit the training data very closely. That model will probably be underdetermined,
    however, so lots of combinations of parameter values will fit the training data
    equally well. If instead you use a small model with few parameters, there is more
    likely to be a unique set of optimal parameter values, but it probably also won’t
    fit the training set as well. In either case, both types of uncertainty must be
    included when estimating the accuracy of the model’s predictions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您的建模选择涉及这两种不确定性之间的权衡。如果使用具有许多参数的大型模型，您可以使其非常紧密地拟合训练数据。然而，该模型可能是欠定的，因此许多参数值的组合将同样适合训练数据。如果相反，您使用具有少量参数的小型模型，则更有可能存在一组唯一的最佳参数值，但它可能也不会像大型模型那样很好地拟合训练集。在任何情况下，在估计模型预测的准确性时，必须包括这两种类型的不确定性。
- en: 'This sounds complicated. How do we do it in practice? Fortunately, DeepChem
    makes it very easy. Just include one extra argument to the model’s constructor:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很复杂。我们如何在实践中做到这一点？幸运的是，DeepChem使这变得非常容易。只需在模型的构造函数中包含一个额外的参数：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'By including the option `uncertainty=True`, we tell the model to add the extra
    outputs for uncertainty and make necessary changes to the loss function. Now we
    can make predictions like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过包括选项`uncertainty=True`，我们告诉模型添加额外的不确定性输出，并对损失函数进行必要的更改。现在我们可以进行预测，如下所示：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This computes the model’s output many times with different dropout masks, then
    returns the average value for each output element, along with an estimate of the
    standard deviation of each one.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这将多次使用不同的dropout掩码计算模型的输出，然后返回每个输出元素的平均值，以及每个输出元素的标准偏差的估计。
- en: '[Figure 10-8](#solubility-uncertainty) shows how it works on the test set.
    For each sample, we plot the actual error in the prediction versus the model’s
    uncertainty estimate. The data shows a clear trend: samples with large predicted
    uncertainty tend to have larger errors than those with small predicted uncertainty.
    The dotted line corresponds to <math><mrow><mi>y</mi><mo>=</mo><mn>2</mn><mi>x</mi></mrow></math>.
    Points below this line have predicted solubilities that are within two (predicted)
    standard deviations of the true value. Roughly 90% of the samples are within this
    region.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-8](#solubility-uncertainty)展示了在测试集上的工作原理。对于每个样本，我们绘制了预测中的实际误差与模型的不确定性估计。数据显示了一个明显的趋势：具有较大预测不确定性的样本往往比具有较小预测不确定性的样本具有更大的误差。虚线对应于<math><mrow><mi>y</mi><mo>=</mo><mn>2</mn><mi>x</mi></mrow></math>。在这条线下的点具有预测的溶解度在真实值的两个（预测的）标准偏差内。大约90%的样本位于这个区域内。'
- en: '![Error in model predictions](Images/dlls_1008.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![模型预测中的误差](Images/dlls_1008.png)'
- en: Figure 10-8\. True error in the model’s predictions, versus its estimates of
    the uncertainty in each value.
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-8。模型预测中的真实误差，与其对每个值的不确定性估计相比。
- en: Interpretability, Explainability, and Real-World Consequences
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性、可解释性和现实世界后果
- en: The greater the consequences of a wrong prediction, the more important it is
    to understand how the model works. For some models, individual predictions are
    unimportant. A chemist working in the early stages of drug development might use
    a model to screen millions of potential compounds and select the most promising
    ones to synthesize. The accuracy of the model’s predictions may be low, but that
    is acceptable. As long as the passing compounds are, on average, better than the
    rejected ones, it is serving a useful purpose.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 错误预测的后果越严重，了解模型如何工作就越重要。对于一些模型，个别预测并不重要。在药物开发的早期阶段工作的化学家可能会使用模型来筛选数百万个潜在化合物，并选择最有前途的化合物进行合成。模型的预测准确性可能较低，但这是可以接受的。只要通过的化合物平均上比被拒绝的化合物更好，它就是有用的。
- en: In other cases, every prediction matters. When a model is used to diagnose a
    disease or recommend a treatment, the accuracy of each result can literally determine
    whether a patient lives or dies. The question “Should I trust this result?” becomes
    vitally important.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，每个预测都很重要。当模型用于诊断疾病或推荐治疗时，每个结果的准确性实际上可能决定患者是否生存。问题“我应该相信这个结果吗？”变得至关重要。
- en: Ideally the model should produce not just a diagnosis, but also a summary of
    the evidence supporting that diagnosis. The patient’s doctor could examine the
    evidence and make an informed decision about whether the model has functioned
    correctly in that particular case. A model that has this property is said to be
    *explainable*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，模型不仅应该产生一个诊断，还应该产生支持该诊断的证据摘要。患者的医生可以检查证据并就模型在该特定情况下是否正确运行做出知情决定。具有这种属性的模型被称为*可解释的*。
- en: Unfortunately, far too many deep learning models are not explainable. In that
    case, the doctor is faced with a difficult choice. Do they trust the model, even
    if they have no idea what evidence a result is based on? Or do they ignore the
    model and rely on their own judgment? Neither choice is satisfactory.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，有太多深度学习模型是无法解释的。在这种情况下，医生面临着一个困难的选择。他们是否相信模型，即使他们不知道结果是基于什么证据？还是忽略模型，依靠自己的判断？这两种选择都不令人满意。
- en: 'Remember this principle: *every model ultimately interacts with humans*. To
    evaluate the quality of a model, you must include those interactions in your analysis.
    Often they depend as much on psychology or economics as on machine learning. It
    is not enough to compute a correlation coefficient or ROC AUC on the model’s predictions.
    You must also consider who will see those predictions, how they will be interpreted,
    and what real-world effects they will ultimately have.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这个原则：*每个模型最终都与人类互动*。要评估模型的质量，您必须在分析中包括这些互动。它们往往与心理学或经济学一样重要，而不仅仅是机器学习。仅仅计算模型预测的相关系数或ROC
    AUC是不够的。您还必须考虑谁将看到这些预测，它们将如何被解释，以及它们最终将产生什么实际影响。
- en: Making a model more interpretable or explainable may not affect the accuracy
    of its predictions, but it can still have a huge impact on the real-world consequences
    of those predictions. It is an essential part of model design.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使模型更具解释性或可解释性可能不会影响其预测的准确性，但仍然可能对这些预测的现实世界后果产生巨大影响。这是模型设计的一个重要部分。
- en: Conclusion
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Deep models have a reputation of being hard to interpret, but many useful techniques
    have been developed that can help. By using these techniques you can begin to
    understand what your model is doing and how it is working. That helps you decide
    whether to trust it, and lets you identify situations where it is likely to fail.
    It also may give new insights into the data. For example, by analyzing the TF
    binding model we discovered the binding motif for a particular transcription factor.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 深度模型被认为很难解释，但已经开发出许多有用的技术可以帮助。通过使用这些技术，您可以开始理解模型的工作原理。这有助于您决定是否信任它，并让您识别可能失败的情况。它还可能为数据提供新的见解。例如，通过分析TF结合模型，我们发现了特定转录因子的结合基序。
- en: '^([1](ch10.xhtml#idm45806164613576-marker)) Simonyan, K., A. Vedaldi, and A.
    Zisserman. “Deep Inside Convolutional Networks: Visualising Image Classification
    Models and Saliency Maps.” [Arxiv.org](https://arxiv.org/abs/1312.6034). 2014.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](ch10.xhtml#idm45806164613576-marker)) Simonyan, K., A. Vedaldi, and A.
    Zisserman. “Deep Inside Convolutional Networks: Visualising Image Classification
    Models and Saliency Maps.” [Arxiv.org](https://arxiv.org/abs/1312.6034). 2014.'
- en: ^([2](ch10.xhtml#idm45806163802088-marker)) Kendall, A., and Y. Gal, “What Uncertainties
    Do We Need in Bayesian Deep Learning for Computer Vision?” [*https://arxiv.org/abs/1703.04977*](https://arxiv.org/abs/1703.04977).
    2017.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.xhtml#idm45806163802088-marker)) Kendall, A., and Y. Gal, “What Uncertainties
    Do We Need in Bayesian Deep Learning for Computer Vision?” [*https://arxiv.org/abs/1703.04977*](https://arxiv.org/abs/1703.04977).
    2017.
