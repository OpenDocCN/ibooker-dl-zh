- en: Chapter 1\. Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 介绍
- en: The goal of this book is to show how any developer with basic experience using
    a command-line terminal and code editor can get started building their own projects
    running machine learning (ML) on embedded devices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是展示任何具有基本命令行终端和代码编辑器使用经验的开发人员如何开始构建自己的项目，运行嵌入式设备上的机器学习（ML）。
- en: When I first joined Google in 2014, I discovered a lot of internal projects
    that I had no idea existed, but the most exciting was the work that the OK Google
    team were doing. They were running neural networks that were just 14 kilobytes
    (KB) in size! They needed to be so small because they were running on the digital
    signal processors (DSPs) present in most Android phones, continuously listening
    for the “OK Google” wake words, and these DSPs had only tens of kilobytes of RAM
    and flash memory. The team had to use the DSPs for this job because the main CPU
    was powered off to conserve battery, and these specialized chips use only a few
    milliwatts (mW) of power.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我2014年首次加入谷歌时，我发现了许多我之前不知道存在的内部项目，但最令人兴奋的是OK Google团队正在进行的工作。他们运行的神经网络只有14千字节（KB）！它们需要如此小是因为它们在大多数Android手机中的数字信号处理器（DSP）上运行，持续监听“OK
    Google”唤醒词，而这些DSP只有几十KB的RAM和闪存。团队必须使用DSP来完成这项工作，因为主CPU已关闭以节省电池，而这些专用芯片只使用几毫瓦（mW）的功率。
- en: Coming from the image side of deep learning, I’d never seen networks so small,
    and the idea that you could use such low-power chips to run neural models stuck
    with me. As I worked on getting TensorFlow and later TensorFlow Lite running on
    Android and iOS devices, I remained fascinated by the possibilities of working
    with even simple chips. I learned that there were other pioneering projects in
    the audio world (like Pixel’s Music IQ) for predictive maintenance (like PsiKick)
    and even in the vision world (Qualcomm’s Glance camera module).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从深度学习的图像方面来看，我从未见过如此小的网络，以及使用低功耗芯片来运行神经模型的想法一直留在我心中。当我努力让TensorFlow和后来的TensorFlow
    Lite在Android和iOS设备上运行时，我仍然被与简单芯片合作的可能性所吸引。我了解到在音频领域还有其他开创性的项目（如Pixel的Music IQ）用于预测性维护（如PsiKick），甚至在视觉领域（高通的Glance相机模块）也有类似的项目。
- en: It became clear to me that there was a whole new class of products emerging,
    with the key characteristics that they used ML to make sense of noisy sensor data,
    could run using a battery or energy harvesting for years, and cost only a dollar
    or two. One term I heard repeatedly was “peel-and-stick sensors,” for devices
    that required no battery changes and could be applied anywhere in an environment
    and forgotten. Making these products real required ways to turn raw sensor data
    into actionable information locally, on the device itself, since the energy costs
    of transmitting streams anywhere have proved to be inherently too high to be practical.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，很明显有一类全新的产品正在涌现，其关键特征是它们利用机器学习来理解嘈杂的传感器数据，可以使用电池或能量收集器运行多年，成本仅为一两美元。我反复听到的一个术语是“剥离和粘贴传感器”，用于不需要更换电池的设备，可以应用于环境中的任何地方并被遗忘。要使这些产品变为现实，需要将原始传感器数据转化为可操作信息的方式，本地在设备上进行处理，因为传输数据流的能量成本被证明太高，以至于不切实际。
- en: This is where the idea of TinyML comes in. Long conversations with colleagues
    across industry and academia have led to the rough consensus that if you can run
    a neural network model at an energy cost of below 1 mW, it makes a lot of entirely
    new applications possible. This might seem like a somewhat arbitrary number, but
    if you translate it into concrete terms, it means a device running on a coin battery
    has a lifetime of a year. That results in a product that’s small enough to fit
    into any environment and able to run for a useful amount of time without any human
    intervention.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是TinyML的概念所在。与行业和学术界同事长时间的交谈导致了一个粗略的共识，即如果你能以低于1毫瓦的能量成本运行神经网络模型，那么将会有许多全新的应用变得可能。这个数字可能看起来有点随意，但如果你将其转化为具体的术语，那就意味着一个运行在硬币电池上的设备可以使用一年。这将导致一个产品足够小，可以适应任何环境，并能够在没有任何人为干预的情况下运行一段有用的时间。
- en: Note
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: I’m going to be jumping straight into using some technical terms to talk about
    what this book will be covering, but don’t worry if some of them are unfamiliar
    to you; we define their meaning the first time we use them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我将直接使用一些技术术语来讨论本书将涵盖的内容，但如果其中一些对您不熟悉，不要担心；我们在第一次使用它们时会定义它们的含义。
- en: At this point, you might be wondering about platforms like the Raspberry Pi,
    or NVIDIA’s Jetson boards. These are fantastic devices, and I use them myself
    frequently, but even the smallest Pi is similar to a mobile phone’s main CPU and
    so draws hundreds of milliwatts. Keeping one running even for a few days requires
    a battery similar to a smartphone’s, making it difficult to build truly untethered
    experiences. NVIDIA’s Jetson is based on a powerful GPU, and we’ve seen it use
    up to 12 watts of power when running at full speed, so it’s even more difficult
    to use without a large external power supply. This is usually not a problem in
    automotive or robotics applications, since the mechanical parts demand a large
    power source themselves, but it does make it tough to use these platforms for
    the kinds of products I’m most interested in, which need to operate without a
    wired power supply. Happily, when using them the lack of resource constraints
    means that frameworks like TensorFlow, TensorFlow Lite, and NVIDIA’s TensorRT
    are available, since they’re usually based on Linux-capable Arm Cortex-A CPUs,
    which have hundreds of megabytes of memory. This book will not be focused on describing
    how to run on those platforms for the reason just mentioned, but if you’re interested,
    there are a lot of resources and documentation available; for example, see [TensorFlow
    Lite’s mobile documentation](https://www.tensorflow.org/lite).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可能会想到像树莓派或NVIDIA的Jetson开发板这样的平台。这些设备非常棒，我自己经常使用，但即使是最小的树莓派也类似于手机的主CPU，因此需要数百毫瓦的电力。即使只是让它运行几天，也需要类似于智能手机的电池，这使得构建真正无线的体验变得困难。NVIDIA的Jetson基于强大的GPU，当以全速运行时，我们看到它使用了高达12瓦的功率，因此即使没有大型外部电源供应，也更难以使用。这通常在汽车或机器人应用中不是问题，因为机械部件本身需要大功率源，但这确实使得在我最感兴趣的那些需要在没有有线电源的情况下运行的产品上使用这些平台变得困难。幸运的是，使用它们时，由于缺乏资源限制，通常可以使用像TensorFlow、TensorFlow
    Lite和NVIDIA的TensorRT这样的框架，因为它们通常基于Linux兼容的Arm Cortex-A CPU，具有数百兆字节的内存。本书不会专注于描述如何在这些平台上运行，原因就是刚才提到的，但如果你感兴趣，有很多资源和文档可用；例如，请参阅[TensorFlow
    Lite的移动文档](https://www.tensorflow.org/lite)。
- en: Another characteristic I care about is cost. The cheapest Raspberry Pi Zero
    is $5 for makers, but it is extremely difficult to buy that class of chip in large
    numbers at that price. Purchases of the Zero are usually restricted by quantity,
    and while the prices for industrial purchases aren’t transparent, it’s clear that
    $5 is definitely unusual. By contrast, the cheapest 32-bit microcontrollers cost
    much less than a dollar each. This low price has made it possible for manufacturers
    to replace traditional analog or electromechanical control circuits with software-defined
    alternatives for everything from toys to washing machines. I’m hoping we can use
    the ubiquity of microcontrollers in these devices to introduce artificial intelligence
    as a software update, without requiring a lot of changes to existing designs.
    It should also make it possible to get large numbers of smart sensors deployed
    across environments like buildings or wildlife reserves without the costs outweighing
    the benefits or funds available.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我关心的另一个特征是成本。最便宜的树莓派Zero面向制造商的价格是5美元，但很难以那个价格大量购买这类芯片。Zero的购买通常受到数量限制，而工业购买的价格并不透明，但很明显5美元绝对是不寻常的。相比之下，最便宜的32位微控制器每个成本远低于一美元。这种低价使得制造商能够用软件定义的替代方案替换传统的模拟或电机控制电路，从玩具到洗衣机的一切。我希望我们可以利用这些设备中微控制器的普及性，通过软件更新引入人工智能，而无需对现有设计进行大量更改。这也应该使得能够在建筑物或野生动物保护区等环境中部署大量智能传感器，而不会使成本超过收益或可用资金。
- en: Embedded Devices
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入式设备
- en: The definition of TinyML as having an energy cost below 1 mW does mean that
    we need to look to the world of embedded devices for our hardware platforms. Until
    a few years ago, I wasn’t familiar with them myself—they were shrouded in mystery
    for me. Traditionally they had been 8-bit devices and used obscure and proprietary
    toolchains, so it seemed very intimidating to get started with any of them. A
    big step forward came when Arduino introduced a user-friendly integrated development
    environment (IDE) along with standardized hardware. Since then, 32-bit CPUs have
    become the standard, largely thanks to Arm’s Cortex-M series of chips. When I
    started to prototype some ML experiments a couple of years ago, I was pleasantly
    surprised by how relatively straightforward the development process had become.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: TinyML的定义是指能耗低于1毫瓦，这意味着我们需要寻找嵌入式设备作为硬件平台。直到几年前，我自己对它们并不熟悉——它们对我来说充满了神秘感。传统上它们是8位设备，使用晦涩和专有的工具链，因此开始使用任何一个都显得非常令人生畏。一个重要的进步是当Arduino推出了用户友好的集成开发环境（IDE）以及标准化的硬件。从那时起，32位CPU已经成为标准，这在很大程度上要归功于Arm的Cortex-M系列芯片。几年前我开始原型设计一些机器学习实验时，我惊讶地发现开发过程变得相对简单。
- en: Embedded devices still come with some tough resource constraints, though. They
    often have only a few hundred kilobytes of RAM, or sometimes much less than that,
    and have similar amounts of flash memory for persistent program and data storage.
    A clock speed of just tens of megahertz is not unusual. They will definitely not
    have full Linux (since that requires a memory controller and at least one megabyte
    of RAM), and if there is an operating system, it may well not provide all or any
    of the POSIX or standard C library functions you expect. Many embedded systems
    avoid using dynamic memory allocation functions like `new` or `malloc()` because
    they’re designed to be reliable and long-running, and it’s extremely difficult
    to ensure that if you have a heap that can be fragmented. You might also find
    it tricky to use a debugger or other familiar tools from desktop development,
    since the interfaces you’ll be using to access the chip are very specialized.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入式设备仍然受到一些严格的资源限制。它们通常只有几百千字节的RAM，有时甚至更少，并且具有类似数量的闪存用于持久性程序和数据存储。时钟速度只有几十兆赫是很常见的。它们肯定不会有完整的Linux（因为那需要内存控制器和至少一兆字节的RAM），如果有操作系统，很可能不会提供您期望的所有或任何POSIX或标准C库函数。许多嵌入式系统避免使用像`new`或`malloc()`这样的动态内存分配函数，因为它们被设计为可靠且长时间运行，如果有一个可以被碎片化的堆，要确保这一点是极其困难的。您可能还会发现使用调试器或其他来自桌面开发的熟悉工具会有些棘手，因为您将使用的接口非常专业化。
- en: There were some nice surprises as I learned embedded development, though. Having
    a system with no other processes to interrupt your program can make building a
    mental model of what’s happening very simple, and the straightforward nature of
    a processor without branch prediction or instruction pipelining makes manual assembly
    optimization a lot easier than on more complex CPUs. I also find a simple joy
    in seeing LEDs light up on a miniature computer that I can balance on a fingertip,
    knowing that it’s running millions of instructions a second to understand the
    world around it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我学习嵌入式开发时，也有一些令人惊喜的地方。拥有没有其他进程来中断您的程序的系统可以使构建对发生的事情的心理模型变得非常简单，而没有分支预测或指令流水线的处理器的直接性质使手动汇编优化比在更复杂的CPU上更容易。我也发现，在一个可以平衡在指尖上的微型计算机上看到LED灯亮起，知道它每秒运行数百万条指令来理解周围世界，这带来了一种简单的喜悦。
- en: Changing Landscape
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变化的景观
- en: It’s only recently that we’ve been able to run ML on microcontrollers at all,
    and the field is very young, which means hardware, software, and research are
    all changing extremely quickly. This book is a based on a snapshot of the world
    as it existed in 2019, which in this area means some parts were out of date before
    we’d even finished writing the last chapter. We’ve tried to make sure we’re relying
    on hardware platforms that will be available over the long term, but it’s likely
    that devices will continue to improve and evolve. The TensorFlow Lite software
    framework that we use has a stable API, and we’ll continue to support the examples
    we give in the text over time, but we also provide web links to the very latest
    versions of all our sample code and documentation. You can expect to see reference
    applications covering more use cases than we have in this book being added to
    the TensorFlow repository, for example. We also aim to focus on skills like debugging,
    model creation, and developing an understanding of how deep learning works, which
    will remain useful even as the infrastructure you’re using changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，我们才能在微控制器上运行机器学习，这个领域非常年轻，这意味着硬件、软件和研究都在非常快速地变化。这本书基于2019年的世界快照，这一领域意味着一些部分在我们完成最后一章的写作之前就已经过时了。我们努力确保我们依赖的硬件平台将长期可用，但设备很可能会继续改进和演变。我们使用的TensorFlow
    Lite软件框架具有稳定的API，我们将继续支持文本中提供的示例，但我们还提供了所有示例代码和文档的最新版本的网页链接。例如，您可以期望看到覆盖更多用例的参考应用程序被添加到TensorFlow存储库中。我们还致力于专注于调试、模型创建和开发对深度学习工作原理的理解等技能，即使您使用的基础设施发生变化，这些技能也将保持有用。
- en: We want this book to give you the foundation you need to develop embedded ML
    products to solve problems you care about. Hopefully we’ll be able to start you
    along the road of building some of the exciting new applications I’m certain will
    be emerging over the next few years in this domain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望这本书能为您提供开发嵌入式机器学习产品所需的基础，以解决您关心的问题。希望我们能够帮助您开始建立一些令人兴奋的新应用程序，我相信在未来几年内这个领域将涌现出一些新的应用程序。
- en: Pete Warden
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 皮特·沃登
