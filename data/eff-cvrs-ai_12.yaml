- en: 10 Reducing complexity with generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 使用生成式AI减少复杂性
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Designing and improving process flows with generative AI
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI设计和改进流程
- en: Replacing disambiguation dialogue flows with LLM judgments
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用LLM判断替换歧义对话流程
- en: Testing static dialogue flows with generative AI as the “user”
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI作为“用户”测试静态对话流程
- en: It’s difficult to design a process-oriented bot that meets all the needs and
    desires of all stakeholders. Competing priorities may lead to a “design by committee”
    that introduces complexity. And well-meaning people can design edge cases that
    hamper the main dialogue flow. These complexities burden your users and make them
    more likely to quit or fail when using the bot. Generative AI can help you detect
    and improve these scenarios, helping you remove complexity and increase the successfulness
    of your bot.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个满足所有利益相关者需求和愿望的面向流程的机器人很困难。相互竞争的优先级可能导致“委员会设计”，从而引入复杂性。而且，好心的人可能会设计出阻碍主要对话流程的边缘情况。这些复杂性会给您的用户带来负担，并使他们更有可能在使用机器人时放弃或失败。生成式AI可以帮助您检测和改进这些场景，帮助您去除复杂性并提高机器人的成功率。
- en: 'Process flow builders often ask for too much information from the user. (More
    information is better, right? Not if it causes the chatbot to fail!) There are
    several ways to improve process flows with generative AI:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 流程构建者通常要求用户提供过多的信息。（信息越多越好，对吧？不是如果它导致聊天机器人失败的话！）有几种方法可以使用生成式AI改进流程：
- en: Use generative AI to make suggestions about how to build a process flow.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI提出关于如何构建流程的建议。
- en: If your process flow is built, use generative AI to suggest improvements. It
    can also test the flow by acting as the user.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的流程已经构建，请使用生成式AI提出改进建议。它还可以通过充当用户来测试流程。
- en: Replace some static process flows with a large language mode (LLM)–driven process.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用大型语言模型（LLM）驱动的流程替换一些静态流程。
- en: We’ll start by exploring a claim status process flow for a medical insurance
    provider. Then we’ll see how generative AI can help us design and improve this
    process flow and others.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探讨医疗保险提供商的索赔状态流程。然后我们将看到生成式AI如何帮助我们设计和改进这个流程以及其他流程。
- en: 10.1 AI-assisted process flows at build time
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 构建时AI辅助流程
- en: Figure 10.1 shows the simplest possible view of a process flow.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1展示了流程的最简单视图。
- en: '![figure](../Images/CH10_F01_Freed2.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F01_Freed2.png)'
- en: Figure 10.1 A high-level view of a process flow. It is initiated by the recognition
    of a specific intent, it includes one or more sequential steps, and it ends with
    completion of the process flow (satisfying the intent).
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.1 流程的高级视图。它由识别特定意图启动，包括一个或多个顺序步骤，并以流程完成（满足意图）结束。
- en: 'Our example process flow involves medical insurance customers who call into
    a chatbot to find the status of a claim. At first, this process sounds like a
    simple lookup, but it has several criteria to meet:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例流程涉及医疗保险客户通过聊天机器人查询索赔状态。起初，这个过程听起来像是一个简单的查找，但它有几个标准需要满足：
- en: '*Intent detection*—Figure out that the user’s intent is “claim status.” This
    initiates a process flow with multiple steps.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意图检测**——确定用户的意图是“索赔状态”。这启动了一个包含多个步骤的流程。'
- en: '*Beginning of process flow*—Gather the information required to complete the
    claim status process: in this case, the information needed to search for a claim.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程开始**——收集完成索赔状态流程所需的信息：在这种情况下，需要搜索索赔的信息。'
- en: '*Middle of process flow*—Use the gathered information to perform some action.
    In this example, that is searching for the user’s claim.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程中间**——使用收集到的信息执行某些操作。在这个例子中，就是搜索用户的索赔。'
- en: '*End of process flow*—Complete the flow by providing the claim status to the
    user.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程结束**——通过向用户提供索赔状态来完成流程。'
- en: The overall claims process flow is shown in figure 10.2.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 整个索赔流程在图10.2中展示。
- en: In chapter 5, we showed how you could improve a chatbot’s intent classifier
    to *detect* and *understand* the user’s intent. In this chapter, we’ll focus on
    improving the rest of the process flow to successfully *fulfill* the user’s intent.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5章中，我们展示了如何改进聊天机器人的意图分类器以**检测**和**理解**用户的意图。在本章中，我们将专注于改进其余的流程，以成功**实现**用户的意图。
- en: '![figure](../Images/CH10_F02_Freed2.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F02_Freed2.png)'
- en: Figure 10.2 Visualizing a claim status process flow
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.2 可视化索赔状态流程
- en: 10.1.1 Generating dialogue flows with generative AI
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 使用生成式AI生成对话流程
- en: Conversational AI process flows are often based on an existing workflow. That
    flow could be copied from another channel, from a web application, or from a call
    center script. For our claim status example, let’s assume there was no existing
    process to work from. We can use an LLM to help us design the target workflow.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式人工智能流程通常基于现有的工作流程。这个流程可以从另一个渠道、网络应用程序或呼叫中心脚本中复制。对于我们的索赔状态示例，让我们假设没有现有的流程可供工作。我们可以使用
    LLM 来帮助我们设计目标工作流程。
- en: The following listing shows an example LLM prompt.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了一个 LLM 提示的示例。
- en: Listing 10.1 Prompt to design a medical insurance claims status flow
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.1 设计医疗保险索赔状态流程的提示
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Scenario and background'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 场景和背景'
- en: '#2 Detailed instructions'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 详细指令'
- en: '#3 Output cue'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 输出提示'
- en: 'We had to give the LLM several pieces of information for the task:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须为任务提供 LLM 几条信息：
- en: '*Scenario/background*—The LLM should know the scenario behind the task (“you
    are a conversational designer”). The LLM should also be given background assumptions,
    such as what information is available on medical claims.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*场景/背景*——LLM 应该了解任务背后的场景（“你是一位对话设计师”）。LLM 还应提供背景假设，例如关于医疗索赔可用的信息。'
- en: '*Instructions*—The LLM must design a dialogue flow that achieves a user goal
    (finding the claim) while being as brief and easy as possible. Further, the LLM
    should describe its “reasoning,” which will help us evaluate the output.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指令*——LLM 必须设计一个对话流程，以尽可能简短和容易的方式实现用户目标（找到索赔），同时描述其“推理”，这将帮助我们评估输出。'
- en: '*Cue*—The cue “Output” lets the LLM know the instruction is finished.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示*——提示“输出”让 LLM 知道指令已完成。'
- en: Small changes may cause big differences
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小的变化可能造成大的差异
- en: LLMs may give significantly different answers to very similar prompts. Even
    formatting changes, like adding a space or including or omitting newline characters,
    can cause major output changes. The exact prompts used in this book are included
    on the book’s GitHub site at [https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 可能会对非常相似的提示给出显著不同的答案。即使是格式更改，如添加空格或包括或省略换行符，也可能导致主要输出变化。本书中使用的确切提示包含在本书的
    GitHub 网站上，网址为 [https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI)。
- en: The next listing shows the output when the prompt uses three lines in the instruction
    (the lines starting with “Instruction,” “Design,” and “Describe”).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了当提示在指令中使用三行时（以“指令”、“设计”和“描述”开头的行）的输出。
- en: Listing 10.2 Output from mixtral-8x7b-instruct-01 for claim status flow (less
    newlines)
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.2 mixtral-8x7b-instruct-01 为索赔状态流程生成的输出（较少换行）
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 Sample conversation, including the chatbot and user messages'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 样本对话，包括聊天机器人和用户的消息'
- en: '#2 Explanation of the design process'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 设计过程说明'
- en: 'The LLM designed a two-sided sample conversation demonstrating what both the
    bot and the user would say. This is nice—it is helpful to visualize what a complete
    conversation looks like. We should be aware that this is only a sample—users may
    respond in many ways to these questions. Let’s recap what happened in the exchange
    with the LLM:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 设计了一个双向样本对话，展示了机器人和用户可能会说的话。这很好——这有助于可视化一个完整的对话看起来是什么样子。我们应该意识到这只是一个样本——用户可能会以多种方式对这些问题做出回应。让我们回顾一下与
    LLM 的交流中发生了什么：
- en: We told the LLM that claims had a member ID, date, amount, and status. It inferred
    that the status was an output and the other three data points were inputs.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们告诉 LLM 索赔有一个成员 ID、日期、金额和状态。它推断出状态是输出，其他三个数据点是输入。
- en: The LLM designed a process flow that collects all three data points in sequential
    order.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 设计了一个流程，按顺序收集所有三个数据点。
- en: The generated dialogue is polite and useful. The bot acknowledges user input
    with “thank you.” It also gives clear instructions to the user about what is expected
    in each step of the flow.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的对话礼貌且有用。机器人用“谢谢”来认可用户的输入。它还向用户提供了关于每个步骤中期望的内容的明确指令。
- en: Interestingly, we get very different output depending on how we use newline
    characters in the prompt. The following listing shows the output from a prompt
    using six lines (a new line after every period in the instruction).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，根据我们在提示中使用换行符的方式，我们会得到非常不同的输出。以下列表显示了使用六行（在指令中的每个句号后都有一行新内容）的提示的输出。
- en: Listing 10.3 Output from mixtral-8x7b-instruct-01 for claim status flow (more
    newlines)
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.3 mixtral-8x7b-instruct-01 为索赔状态流程生成的输出（更多换行）
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output in listing 10.3 is quite different. First, the sample conversation
    and rationale are interleaved. Every step of the conversation has a description,
    an example chatbot message, and a detailed rationale. Second, the sample conversation
    includes only the bot messages. We don’t see user responses. Third, this process
    flow implies confirmation statements after each piece of data is received from
    the user. Finally, the sample dialogue contains minor errors. Instruction 3 says
    it will ask for the claim amount, but the dialogue shows it confirming a claim
    amount without collecting it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3的输出相当不同。首先，样本对话和理由是交织在一起的。对话的每一步都有一个描述、一个示例聊天机器人消息和详细的理由。其次，样本对话只包括机器人消息。我们没有看到用户响应。第三，这个过程流程暗示在收到用户每条数据后都有确认语句。最后，样本对话中包含一些小错误。指令3表示它将询问索赔金额，但对话显示它确认了索赔金额而没有收集。
- en: Together, the two prompts give us plenty of ideas for constructing a dialogue
    flow to implement a claim status process. Since listing 10.2 is more fully formed,
    we will use that as our baseline. Though it is pretty good, the process generated
    seems a little lengthy. Can we improve the process flow? Of course we can! Let’s
    ask the LLM for improvements.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 两个提示一起为我们提供了构建对话流程以实现索赔状态流程的许多想法。由于列表10.2更加完整，我们将使用它作为基准。尽管它相当不错，但生成的流程似乎有点冗长。我们能改进流程吗？当然可以！让我们询问LLM如何改进。
- en: 10.1.2 Improving dialogue flow with generative AI
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 使用生成式AI改进对话流程
- en: We can ask an LLM to improve process flows whether they were generated by LLMs
    or humans. Let’s improve the process flow in listing 10.2, which we generated
    via LLM to help users learn their claim status.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以要求LLM改进流程，无论它们是由LLM还是人类生成的。让我们改进列表10.2中的流程，这是我们通过LLM生成的，以帮助用户了解他们的索赔状态。
- en: 'The process flow, as currently constructed, requires three pieces of information:
    a member ID, a date, and a claim amount. This meets some basic requirements, like
    authenticating the caller (by member ID) and providing search criteria (member
    ID plus date and amount). However, this could be burdensome to the user. By intuition,
    it seems that the member ID plus one more piece of information could uniquely
    identify the claim. Let’s ask the LLM how to simplify the process flow.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当前构建的流程需要三个信息点：会员ID、日期和索赔金额。这满足了一些基本要求，例如通过会员ID验证呼叫者并提供搜索条件（会员ID、日期和金额）。然而，这可能会给用户带来不便。根据直觉，似乎会员ID加上更多信息可以唯一标识索赔。让我们询问LLM如何简化流程。
- en: Listing 10.4 Asking the LLM to improve the dialogue flow from listing 10.2
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.4 要求LLM改进列表10.2中的对话流程
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 The full content of listing 10.1 is in the prompt but omitted here for brevity.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 列表10.1的完整内容包含在提示中，但为了简洁起见，此处省略。'
- en: '#2 The full content of listing 10.2 is in the prompt but omitted here for brevity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 列表10.2的完整内容包含在提示中，但为了简洁起见，此处省略。'
- en: '#3 A lightweight instruction to the LLM'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 对LLM的轻量级指令'
- en: '#4 Output cue'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 输出提示'
- en: 'The “improvement” prompt is simple in nature. We simulate a conversation with
    the LLM by including the full history of our past conversation: the original prompt
    and its response. We then provide a basic instruction (“simplify the dialogue
    flow above”) with a definition of simplification (“only require the user to provide
    two pieces of information”). The output from this prompt is shown in the following
    listing.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: “改进”提示的本质很简单。我们通过包含我们过去对话的完整历史（原始提示及其响应）来模拟与LLM的对话。然后，我们提供一个基本指令（“简化上述对话流程”）以及简化的定义（“只要求用户提供两份信息”）。此提示的输出如下所示。
- en: Listing 10.5 Simplified dialogue flow and justification provided by LLM
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.5 LLM提供的简化对话流程和理由
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Step 2 now collects all information in a single turn.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 第2步现在在一次操作中收集所有信息。'
- en: '#2 Step 5 converts the claim amount from an input to an output parameter.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 第5步将索赔金额从输入参数转换为输出参数。'
- en: 'We see two suggestions from the LLM: first, to not ask the claim amount, and
    second, to combine two questions into one. Let’s review them in detail:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到LLM提出了两个建议：首先，不要询问索赔金额；其次，将两个问题合并为一个。让我们详细审查它们：
- en: '*Removing the claim amount*—Member ID and claim date are the two most “unique”
    data elements and the ones the user is most likely to have in hand. They are also
    the easiest to enter in web or phone bots, with most chat platforms having libraries
    to accept IDs and dates. The chatbot also informs the caller of the claim amount
    during the readout.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*移除索赔金额*——会员ID和索赔日期是两个最“独特”的数据元素，也是用户最有可能拥有的。它们也是最容易在网页或电话机器人中输入的，大多数聊天平台都有接受ID和日期的库。聊天机器人还会在读取时通知呼叫者索赔金额。'
- en: '*Asking two questions at once*—The new flow combines member ID and claim date
    into a single question (step 2). This is excellent for power users who want as
    few steps as possible. This may be more challenging for users who only have one
    piece of information available and need help finding the second. It is good for
    the chatbot to accept both pieces of information in one turn, but it may not be
    optimal to require it.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一次性提出两个问题*——新的流程将会员ID和索赔日期合并为一个问题（步骤2）。这对于希望尽可能减少步骤的资深用户来说非常出色。对于只有一条信息可用且需要帮助找到第二条信息的用户来说，这可能更具挑战性。对于聊天机器人来说，在一次对话中接受这两条信息是好的，但可能不是强制要求的最佳选择。'
- en: Subject matter experts or LLMs?
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 主题专家或LLM？
- en: We advise using subject matter expert (SME) advice before taking any solution
    to production. LLMs are great for generating ideas and testing ideas quickly.
    Use LLMs to explore the art of the possible and quickly draft potential solutions.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议在生产任何解决方案之前使用主题专家（SME）的建议。LLM非常适合生成想法和快速测试想法。使用LLM探索可能的艺术，并快速起草潜在解决方案。
- en: In one simple prompt, we generated two suggestions for how to improve the dialogue
    flow. Can you think of other ways to improve the dialogue flow? What instructions
    would you give the LLM?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个简单的提示中，我们生成了两种改进对话流程的建议。你能想到其他改进对话流程的方法吗？你会给LLM什么样的指令？
- en: Exercises
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Take listing 10.4 and try some alternative instructions:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用列表10.4中的替代指令：
- en: Only ask the user for one piece of information at a time.
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次只向用户询问一条信息。
- en: Guide a user who says “I don’t have it” for one of the questions.
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引导一个说“我没有”的用户回答其中一个问题。
- en: Introduce additional parameters, such as a claim ID, and see how the bot generates
    additional process flow variations.
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入额外的参数，例如索赔ID，并查看机器人如何生成额外的流程变体。
- en: 'Use an LLM to generate a process flow for a different scenario, such as these:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用LLM为不同的场景生成流程，例如这些：
- en: Booking a flight
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预订航班
- en: Buying a movie ticket
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 购买电影票
- en: Recommending a vacation destination
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐度假目的地
- en: Or use a scenario from a chatbot you are building!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用你正在构建的聊天机器人中的一个场景！
- en: 10.2 AI-assisted process flows at run time
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 运行时AI辅助流程
- en: It’s been great using generative AI to build process flow designs. So far, these
    have been somewhat static flows, usable in traditional conversational AI solutions.
    Claims status is an example of a “slot-filling” search, where we use a conversational
    process to collect information required to complete a task. This often takes the
    form of collecting required parameters for an API call. It requires careful mapping
    of questions and answer responses to an API. Then the answers are slotted into
    API parameters until the API can be executed. Slot-filling is one of the most
    popular conversational process flow patterns.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成式AI构建流程设计一直是个不错的选择。到目前为止，这些流程都是相对静态的，适用于传统的对话式AI解决方案。索赔状态是一个“槽填充”搜索的例子，我们通过对话过程收集完成任务所需的信息。这通常表现为收集API调用所需的参数。这需要对问题和答案响应进行仔细的映射到API上。然后，答案被填充到API参数中，直到API可以执行。槽填充是最受欢迎的对话式流程模式之一。
- en: What about deferring more control to the LLM in these flows?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些流程中，是否应该将更多控制权交给LLM？
- en: 10.2.1 Executing dialogue flows with generative AI
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 使用生成式AI执行对话流程
- en: Our previous process flow was designed statically. Let’s try something different.
    We will just describe the process and let the LLM decide what questions to ask
    during the live conversation. Figure 10.3 shows how we’ll incorporate an LLM into
    the process of gathering information for the claim search API.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的过程流程是静态设计的。让我们尝试一些不同的方法。我们只描述流程，让LLM在实时对话中决定要问什么问题。图10.3显示了我们将如何将LLM纳入收集索赔搜索API信息的过程。
- en: '![figure](../Images/CH10_F03_Freed2.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F03_Freed2.png)'
- en: Figure 10.3 How a conversational AI can use an LLM to decide what question to
    ask next
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.3 对话式AI如何使用LLM决定下一个要问的问题
- en: 'We are assuming some logic in the chatbot:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在聊天机器人中假设了一些逻辑：
- en: When it detects a claim status intent, it lets the LLM decide what question
    to ask next.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它检测到状态意图声明时，它让LLM决定下一个要问的问题。
- en: When it detects the LLM responding with a list of variables, it takes back control
    and executes a claim search.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它检测到LLM以变量列表的形式响应时，它重新获得控制权并执行声明搜索。
- en: It uses guardrails like a preclassifier to ensure data sent to the LLM is not
    malicious, like “ignore all previous instructions and <do something nasty>.”
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用像预分类器这样的护栏来确保发送给LLM的数据不是恶意的，比如“忽略所有之前的指令并<做些坏事>。”
- en: The following listing demonstrates an LLM generating the conversation one step
    at a time.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表演示了LLM逐步生成对话。
- en: Listing 10.6 Letting the LLM decide what questions to ask for claim status
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.6 让LLM决定询问声明状态的问题
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Similar instruction to the previous prompts'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 与之前的提示相似的指令'
- en: '#2 Description of new task'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 新任务的描述'
- en: '#3 Assuming a static greeting to the bot, we feed the bot’s initial greeting
    and user’s first utterance.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 假设对机器人的静态问候，我们输入机器人的初始问候和用户的第一次发言。'
- en: '#4 Output cue'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 输出提示'
- en: This simple prompt is enough to get the bot generating some dialogue for us.
    (We wrote this prompt in just a few minutes.) The next few listings show the output
    from each consecutive iteration of the prompt. The following listing shows the
    first turn, using the output from listing 10.6.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的提示就足以让机器人为我们生成一些对话。（我们只用了几分钟就写了这个提示。）接下来的几个列表显示了提示的连续迭代输出。下面的列表显示了第一个轮次，使用了列表10.6的输出。
- en: Listing 10.7 Conversational turn 2 output (LLM generating next question to ask)
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.7 第2轮对话轮次输出（LLM生成下一个问题）
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Previous listing is included here'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 此处包含之前的列表'
- en: '#2 Output from first prompt'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 来自第一个提示的输出'
- en: The bot has done a nice job so far. It decided to ask for the member ID first.
    Let’s see what it does when the user responds.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，机器人做得很好。它决定首先询问成员ID。让我们看看当用户响应时它会做什么。
- en: Listing 10.8 Conversational turn 2 output (LLM generating next question to ask)
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.8 第2轮对话轮次输出（LLM生成下一个问题）
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Previous listing is included here'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 此处包含之前的列表'
- en: '#2 User’s response is passed from chatbot to LLM'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将用户的响应从聊天机器人传递给LLM'
- en: '#3 LLM response'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 LLM的响应'
- en: This is another reasonable response. The LLM is responding well without any
    guidance besides the initial prompt. The responses are a bit repetitive—both questions
    took the form of “What is your <X>.” Let’s see the rest of the conversation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个合理的回应。LLM在没有除了初始提示之外的任何指导的情况下表现良好。回应有点重复——两个问题都采用了“你的<X>是什么”的形式。让我们看看对话的其余部分。
- en: Listing 10.9 Conversational output showing turns 3 and 4
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.9 显示第3和第4轮对话的会话输出
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Previous listing is included here'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 此处包含之前的列表'
- en: '#2 User’s response is passed from chatbot to LLM'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将用户的响应从聊天机器人传递给LLM'
- en: '#3 LLM asks the final question'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 LLM提出最后一个问题'
- en: '#4 User’s final response is passed from chatbot to LLM'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将用户的最终响应从聊天机器人传递给LLM'
- en: '#5 LLM generates a payload that the chatbot can use for search'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 LLM生成聊天机器人可以用于搜索的有效负载'
- en: At the end of the dialogue flow, the LLM has done everything we needed. It asked
    questions without using hardcoded dialogue, and it generated a parameter set we
    could pass to the claim search API. (It did not generate valid JSON, but it could
    probably learn to do that from a better prompt.)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话流程结束时，LLM已经完成了我们所需要的一切。它提出了问题，而没有使用硬编码的对话，并且它生成了一组我们可以传递给声明搜索API的参数集。（它没有生成有效的JSON，但它可能从更好的提示中学会这样做。）
- en: It could be tempting to give full control to the LLM at this point. Before we
    do, let’s see how the LLM reacts in a different scenario. This time, the user
    won’t know everything the system needs. How will the LLM react? The next listing
    demonstrates this scenario.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个点上完全将控制权交给LLM可能会很有诱惑力。在我们这样做之前，让我们看看LLM在不同场景下的反应。这次，用户不知道系统需要的一切。LLM会如何反应？下一个列表演示了这个场景。
- en: Listing 10.10 LLM generated responses for when user doesn’t have all the information
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.10 当用户没有所有信息时的LLM生成响应
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Same instruction as in previous examples'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 与之前示例中相同的指令'
- en: '#2 Same initial conversation as in previous examples'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 与之前示例中相同的初始对话'
- en: '#3 User does not know some information'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 用户不知道一些信息'
- en: '#4 The LLM gets stuck!'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 LLM卡住了！'
- en: Uh-oh! The LLM has no sense of error handling in this prompt. It looks like
    the LLM will perpetually ask questions until the user ends the chat in frustration.
    The user probably can’t opt out of this chat either. Clearly this approach has
    some limitations.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！在这个提示中，LLM没有错误处理的概念。看起来LLM会不断地提问，直到用户因沮丧而结束聊天。用户可能也无法退出这个聊天。显然，这种方法有一些局限性。
- en: Asking multiple questions to fulfill a search process was hit and miss. Let’s
    try something else. What if we let the LLM do the search?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 提出多个问题以完成搜索过程并不总是成功的。让我们尝试其他方法。如果我们让LLM进行搜索会怎样？
- en: 10.2.2 Using LLM for a search process
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 使用LLM进行搜索过程
- en: In scenarios like medical insurance, a careful search is critical. A healthcare
    provider may have hundreds of open claims (or more) across their patient population.
    Strict search criteria are critical to successful searches, not to mention being
    required by law. Let’s imagine a different scenario where there are far fewer
    options to search for.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在医疗保险等场景中，仔细搜索至关重要。医疗服务提供者可能在其患者群体中有数百（或更多）未结索赔。严格的搜索标准对于成功的搜索至关重要，更不用说法律要求了。让我们想象一个搜索选项更少的不同场景。
- en: Isn’t this retrieval-augmented generation (RAG)?
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 这不是检索增强生成（RAG）吗？
- en: Sort of. We are creating textual “passages” based on the output of structured
    APIs and letting the LLM reason over them. Purists may not call it RAG, but it
    has similarities. And most importantly, it is a useful tool in your toolbox, whatever
    you call it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 有点像。我们正在根据结构化API的输出创建文本“段落”，并让LLM对它们进行推理。纯粹主义者可能不会称之为RAG，但它有相似之处。最重要的是，无论你叫它什么，它都是你工具箱中的一个有用工具。
- en: Our scenario for this example is consumers checking their bank account balances.
    A consumer generally has between one and four accounts at one bank. The chatbot
    will need to know which account the user is asking about. Only a few pieces of
    metadata are relevant to the accounts, including type (checking or savings), owner
    (solo or joint), and ID (though owners may not remember it).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例场景是消费者检查他们的银行账户余额。消费者通常在一家银行有1到4个账户。聊天机器人需要知道用户询问的是哪个账户。只有少数几项元数据与账户相关，包括类型（支票或储蓄）、所有者（单独或共同）和ID（尽管所有者可能不记得它）。
- en: Let’s assume the user is logged in to our chatbot (we know who they are from
    their logged-in user ID or their verified phone number). They ask for an account
    balance, and the chatbot asks the LLM for help. The flow diagram is shown in figure
    10.4.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 假设用户已经登录到我们的聊天机器人（我们可以通过他们的登录用户ID或验证过的电话号码知道他们是谁）。他们询问账户余额，聊天机器人向LLM寻求帮助。流程图如图10.4所示。
- en: '![figure](../Images/CH10_F04_Freed2.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F04_Freed2.png)'
- en: Figure 10.4 Using an LLM to handle user responses
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.4 使用LLM处理用户响应
- en: 'We can imagine the user asking the following questions of the assistant:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以想象用户向助手提出以下问题：
- en: How much money is in my account?
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的账户里有多少钱？
- en: How much money is in my savings account?
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我在储蓄账户里有多少钱？
- en: How much money is our joint savings account?
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们共同储蓄账户里有多少钱？
- en: How much money is in my son’s account?
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我儿子的账户里有多少钱？
- en: How much money is in the account I just opened?
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我刚开设的账户里有多少钱？
- en: The prompt and example output are shown in the following listing. This prompt
    is executed with stopping criteria of any whitespace character (space or newline).
    Otherwise, the LLM continues the output with a justification of its choice.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和示例输出如下所示。此提示以任何空白字符（空格或换行符）为停止条件执行。否则，LLM将继续输出，并对其选择进行说明。
- en: Listing 10.11 Using an LLM to perform a search
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.11 使用LLM进行搜索
- en: '[PRE10]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Basic instruction provided as a prompt'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 作为提示提供的基本指令'
- en: '#2 User’s input is passed directly to the LLM'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将用户的输入直接传递给LLM'
- en: '#3 LLM receives the context of the logged-in user and the metadata for all
    accounts'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 LLM接收已登录用户的上下文和所有账户的元数据'
- en: '#4 Output cue and output'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 输出提示和输出'
- en: Awesome! The LLM can answer all five questions. Table 10.1 shows the LLM responses.
    Recall that we are only asking the LLM to pick the account ID. The chatbot will
    still invoke the final “check balance” API call and formulate the final response.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！LLM可以回答所有五个问题。表10.1显示了LLM的响应。回想一下，我们只要求LLM选择账户ID。聊天机器人仍然将调用最终的“检查余额”API调用并制定最终的响应。
- en: Table 10.1 Responses from listing 10.11 for several different input questions
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表10.1 列表10.11的几个不同输入问题的响应
- en: '| Question | Response (Account ID) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 响应（账户ID） |'
- en: '| --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| How much money is in my account?  | 12345  |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 我的账户里有多少钱？ | 12345 |'
- en: '| How much money is in my savings account?  | 23456  |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 我储蓄账户里有多少钱？  | 23456  |'
- en: '| How much money is in our joint savings account?  | 23456  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 我们共同储蓄账户里有多少钱？  | 23456  |'
- en: '| How much money is in my son’s account?  | 34567  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 我儿子的账户里有多少钱？  | 34567  |'
- en: '| How much money is in the account I just opened?  | 34567  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 我刚刚开设的账户里有多少钱？  | 34567  |'
- en: 'We can make several observations :'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做出几个观察：
- en: '*Variability*—We handled several different search criteria, including dates,
    types, and owners, without asking any disambiguation questions.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可变性*——我们处理了包括日期、类型和所有者在内的几个不同的搜索标准，而没有提出任何澄清问题。'
- en: '*Flexibility*—Criteria like “my son” or “the account I just opened” were handled
    without a strict API parameter.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*灵活性*——像“我的儿子”或“我刚刚开设的账户”这样的标准无需严格的API参数即可处理。'
- en: '*Default choice*—For the two ambiguous questions (“my account”) and (“our joint
    savings account”), the bot chose the first matching choice. This implies that
    sort order is important.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*默认选择*——对于两个模糊的问题（“我的账户”）和（“我们的共同储蓄账户”），机器人选择了第一个匹配的选择。这表明排序顺序很重要。'
- en: The LLM offers incredible flexibility! If the stakes are low enough, letting
    the LLM search is an excellent strategy. Assuming that our output message is something
    like “Your <type> account with ID <id> has <balance>,” it may be okay that the
    LLM did not ask a clarifying question. The bot is always responding with accurate
    information and supporting evidence. The user may still ask follow-up questions
    like “No, I meant my savings account balance” if they need different information.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: LLM提供了不可思议的灵活性！如果风险足够低，让LLM搜索是一个绝佳的策略。假设我们的输出信息类似于“您的<类型>账户，ID为<id>，余额为<balance>”，那么LLM没有提出澄清问题可能也是可以接受的。机器人总是以准确的信息和证据进行回应。如果用户需要不同的信息，他们仍然可能会问后续问题，比如“不，我是指我的储蓄账户余额”。
- en: Is letting an LLM pick an account ID safe? What about hallucinations?
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 让LLM选择账户ID安全吗？关于幻想又如何？
- en: 'In the example of consumers checking their bank account balances, we introduce
    safety by separating out the API call from the LLM judgment. A typical “get balance”
    API will have two parameters: a user ID and an account ID. In this scenario, we
    only let the LLM pick the account ID. Thus, we are protected from the LLM hallucinating
    a user ID and account ID combination that leaks someone else’s account information.
    If the LLM hallucinates an account ID, the API will fail the call; if the LLM
    picks the wrong account for this user, at least they will hear about one of their
    own accounts. Be sure to test your design and implementation thoroughly before
    assuming it is safe.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费者检查银行账户余额的例子中，我们通过将API调用与LLM判断分离来引入安全性。一个典型的“获取余额”API将有两个参数：用户ID和账户ID。在这种情况下，我们只让LLM选择账户ID。因此，我们防止了LLM幻想出一个用户ID和账户ID组合，从而泄露他人的账户信息。如果LLM幻想出一个账户ID，API调用将失败；如果LLM为该用户选择了错误的账户，至少他们会听到自己账户中的一个。在假设设计实现是安全之前，务必彻底测试你的设计和实现。
- en: This kind of safety-driven design should be used when letting LLMs execute API
    calls.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当让LLM执行API调用时，应使用这种以安全性为导向的设计。
- en: Generative AI with LLMs offers us interesting possibilities in augmenting our
    chatbots. We need to carefully balance the trade-offs between implementation speed
    and control. But LLMs support things that would otherwise be difficult or impossible
    in traditional chatbots.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 带有LLM的生成式AI为我们提供了增强聊天机器人的有趣可能性。我们需要仔细平衡实现速度和控制之间的权衡。但是，LLM支持在传统聊天机器人中难以或不可能实现的事情。
- en: Exercises
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Update the prompt in listing 10.6 to give more varied responses (not just “what
    is your <X>”).
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新列表10.6中的提示，以提供更多样化的响应（不仅仅是“你的<X>”）。
- en: Update the prompt in listing 10.11 so that the LLM gives a sentinel value like
    “n/a” if the user’s question is ambiguous. You can give additional instructions
    in the prompt or add few-shot examples for the LLM to learn from.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新列表10.11中的提示，以便当用户的提问模糊时，LLM给出类似“n/a”的哨兵值。你可以在提示中给出额外的指令或添加几个示例供LLM学习。
- en: 10.3 AI-assisted flows at test time
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 测试时的AI辅助流程
- en: In the previous sections, we used generative AI to design or implement the chat
    solution by having the LLM act as the chatbot. In this section, we will turn that
    paradigm on its head. We will use the LLM to generate typical or “creative” responses
    and see how the chatbot handles them in our insurance claims scenario. This conceptualized
    flow is shown in figure 10.5.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们使用了生成式AI，通过让LLM充当聊天机器人来设计或实现聊天解决方案。在本节中，我们将颠覆这种范式。我们将使用LLM生成典型或“创意”的回复，并观察聊天机器人在我们的保险索赔场景中如何处理这些回复。这种概念化的流程如图10.5所示。
- en: '![figure](../Images/CH10_F05_Freed2.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F05_Freed2.png)'
- en: Figure 10.5 Flow diagram of how the test script invokes an LLM as a "user" of
    the chatbot
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.5 测试脚本如何调用LLM作为聊天机器人“用户”的流程图
- en: 'We need three things to put this test script together: a generalized prompt
    for the LLM to act as a user, a test script to invoke both the chatbot and the
    LLM, and a methodology for reviewing the results.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要三样东西来组合这个测试脚本：一个通用的提示，让LLM（大型语言模型）充当用户，一个测试脚本以调用聊天机器人和LLM，以及一个用于审查结果的方法。
- en: Let’s get started.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 10.3.1 Setting up generative AI to be the user
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 设置生成式AI作为用户
- en: 'The LLM will need three pieces of information to be an effective user: general
    instructions for the task, a description of the scenario we need to test, and
    the conversation so far.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: LLM需要三块信息才能成为一个有效的用户：任务的通用说明、我们需要测试的场景描述以及到目前为止的对话。
- en: 'First, let’s provide some simple background telling the LLM we want it to mimic
    a user in an ongoing conversation. The instruction can start quite simply:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们提供一些简单的背景信息，告诉LLM我们希望它在持续的对话中模仿一个用户。指令可以非常简单：
- en: '[PRE11]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This instruction describes the basics of what we want the LLM to do. We are
    telling the LLM to respond as the user, not the system. We give no further guidance
    to the LLM.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令描述了我们希望LLM做的基本内容。我们告诉LLM以用户身份回应，而不是系统。我们不向LLM提供进一步的指导。
- en: 'Second, we want the LLM to be able to handle different scenarios. We need an
    adaptable prompt. Here are a few scenarios we’d like to test:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们希望LLM能够处理不同的场景。我们需要一个可适应的提示。以下是我们想要测试的几个场景：
- en: The user has all the information they need (member ID, claim date, claim amount).
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户拥有他们需要的所有信息（会员ID、索赔日期、索赔金额）。
- en: The user is missing some necessary information.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户缺少一些必要的信息。
- en: The user is missing some necessary information but has alternatives (a claim
    ID).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户缺少一些必要的信息，但有替代方案（一个索赔ID）。
- en: For each scenario, we would give slightly different guidance to the prompt.
    Table 10.2 maps some scenarios to the detailed guidance we could give the LLM.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个场景，我们将对提示提供略微不同的指导。表10.2将一些场景映射到我们可以提供给LLM的详细指导。
- en: Table 10.2 Scenario descriptions and prompt-able guidance
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表10.2 场景描述和可提示的指导
- en: '| Description | Guidance |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 描述 | 指导 |'
- en: '| --- | --- |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| User has all the information they need  | You are trying to find out if one
    of your medical claims was paid. You know your member ID is 123456, the claim
    date is May 4, 2024, and the claim amount of $1000\.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '| 用户拥有他们需要的所有信息 | 你正在试图找出你是否支付了你的医疗索赔之一。你知道你的会员ID是123456，索赔日期是2024年5月4日，索赔金额为1000美元。'
- en: '|'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| User is missing some necessary information  | You are trying to find out
    if your most recent medical claim was paid. You know your member ID is 123456
    but don’t know anything else.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '| 用户缺少一些必要的信息 | 你正在试图找出你是否支付了你最近的医疗索赔。你知道你的会员ID是123456，但不知道其他任何信息。'
- en: '|'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| User is missing some necessary information but has alternatives  | You are
    trying to find out if your most recent medical claim was paid. You know your member
    ID is 123456 and that the claim ID is 987654321987654\.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '| 用户缺少一些必要的信息但有替代方案 | 你正在试图找出你是否支付了你最近的医疗索赔。你知道你的会员ID是123456，索赔ID是987654321987654。'
- en: '|'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'The guidance in table 10.2 has the following information the LLM can use in
    the conversation:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2中的指导包含以下LLM可以在对话中使用的信息：
- en: '*Scenario*—What the LLM should try to do, such as find out if a claim was paid.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*场景*——LLM应该尝试做的事情，例如找出是否支付了索赔。'
- en: '*Test data*—We know the chatbot can call APIs, so we need the LLM to provide
    data that exists in our system. We explicitly give the LLM the information we
    want it to use.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*测试数据*——我们知道聊天机器人可以调用API，因此我们需要LLM提供存在于我们系统中的数据。我们明确地给出LLM我们希望它使用的信息。'
- en: '*Boundaries*—We tell the LLM what it does not know. This should prevent the
    LLM from “inventing” (hallucinating) information that will cause our later API
    calls to fail.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边界*——我们告诉LLM它不知道的内容。这应该防止LLM“发明”（产生幻觉）信息，这些信息将导致我们后续的API调用失败。'
- en: We don’t provide the LLM any other guidance. We want to see how it tries to
    achieve these outcomes in the chatbot.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有提供LLM任何其他指导。我们想看看它如何在聊天机器人中尝试实现这些结果。
- en: Finally, we need to provide the conversational transcript to the LLM to inform
    how it responds next (and what it has already responded with). The test script
    will be able to keep track of the transcript because it is invoking both the chatbot
    and LLM. (There are many ways to gather the chat transcript, and chapter 12 will
    demonstrate a few more.)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要向LLM提供对话记录，以告知它如何响应下一个（以及它已经响应了什么）。测试脚本将能够跟踪记录，因为它正在调用聊天机器人和LLM。（有许多方法可以收集聊天记录，第12章将演示更多方法。）
- en: 'We can now build a Python function to generate a prompt for a given scenario.
    The function takes two arguments: the guidance for the scenario (as seen in table
    10.2) and the conversational transcript. The next listing shows the function.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以构建一个Python函数来为给定场景生成提示。该函数接受两个参数：场景的指导（如表10.2所示）和对话记录。下一个列表展示了该函数。
- en: Listing 10.12 Python function to build a prompt for a test scenario
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.12 构建测试场景提示的Python函数
- en: '[PRE12]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Generic description of the task'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 任务的通用描述'
- en: '#2 Scenario-specific guidance and test details'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 特定场景的指导和测试细节'
- en: '#3 Injects the conversational transcript'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 注入对话记录'
- en: '#4 Cue for LLM response'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 LLM响应的提示'
- en: This code’s function dynamically builds a prompt for a given scenario and conversation
    transcript.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的功能动态地为给定场景和对话记录构建提示。
- en: Listing 10.13 demonstrates how we can call the `get_prompt()` function. It assumes
    a `call_llm()` function whose implementation will vary based on the LLM platform
    (assume it is initiated with an API key, it lets you pick a model and configuration
    settings, and it then provides a function that receives a prompt and returns output).
    Be sure to use sampling decoding in your `call_llm()` function so that you get
    variety in your responses.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.13展示了如何调用`get_prompt()`函数。它假设有一个`call_llm()`函数，其实现将根据LLM平台而异（假设它通过API密钥启动，允许你选择模型和配置设置，然后提供一个接收提示并返回输出的函数）。确保在你的`call_llm()`函数中使用采样解码，以便在响应中获得多样性。
- en: Listing 10.13 Python code to use a dynamic prompt
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.13 使用动态提示的Python代码
- en: '[PRE13]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Full text of the test scenario to guide the LLM'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 指导测试场景的全文'
- en: '#2 Full conversational transcript to date'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 到目前为止的完整对话记录'
- en: '#3 Builds the prompt dynamically'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 动态构建提示'
- en: '#4 Gets LLM response (e.g., “Sure, my member ID is 123456”)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 获取LLM响应（例如，“当然，我的会员ID是123456”）'
- en: '#5 Updates the conversational transcript'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 更新对话记录'
- en: We now have the first half of our test script. Let’s set up the other half.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了测试脚本的第一个部分。让我们设置另一半。
- en: 10.3.2 Setting up the conversational test
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.2 设置对话测试
- en: Next, the test script must call the chatbot. The script will take the LLM-generated
    “user” input and pass it to the bot. Then the script will take the bot’s response,
    append it to the transcript, and call the LLM again. We will again depend on a
    function not implemented here (the implementation will vary by platform)—in this
    case, that function is `call_chatbot()`. This function is expected to configure
    a connection to a chatbot, authenticate with an API key, and manage a user conversation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，测试脚本必须调用聊天机器人。脚本将获取LLM生成的“用户”输入并将其传递给机器人。然后脚本将获取机器人的响应，将其附加到记录中，并再次调用LLM。我们将再次依赖于这里未实现的功能（实现将根据平台而异）——在这种情况下，该功能是`call_chatbot()`。这个函数预期将配置与聊天机器人的连接，使用API密钥进行身份验证，并管理用户对话。
- en: The following listing shows this part of our test script.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了测试脚本的这个部分。
- en: Listing 10.14 Python code to call the chatbot
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.14 调用聊天机器人的Python代码
- en: '[PRE14]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Sends a message to the chatbot'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 向聊天机器人发送消息'
- en: '#2 Stores the chatbot response in the transcript'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将聊天机器人响应存储在记录中'
- en: We can now put all the pieces together. In the next listing, we combine all
    the elements into a single test script.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将所有这些部分组合在一起。在下一个列表中，我们将所有元素组合成一个单独的测试脚本。
- en: Listing 10.15 Python code combining LLM-as-user and chatbot calls
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.15 结合LLM用户和聊天机器人调用的Python代码
- en: '[PRE15]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 A conversation is often initiated with “blank” input.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 对话通常以“空白”输入开始。'
- en: '#2 Tests a few turns of the conversation'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 测试对话的几个回合'
- en: '#3 Sends the LLM response to the chatbot'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将LLM的响应发送到聊天机器人'
- en: '#4 Stores the chatbot response in the transcript'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将聊天机器人的响应存储在记录中'
- en: '#5 Prints the transcript at the end of the test'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 在测试结束时打印记录'
- en: The script initiates a connection to the chatbot and runs through a fixed number
    of turns (four). Depending on our test needs, we could increase or decrease that
    number or put in additional logic to detect when the conversation has ended (or
    failed).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本启动与聊天机器人的连接，并运行固定数量的回合（四个）。根据我们的测试需求，我们可以增加或减少这个数字，或者添加额外的逻辑来检测对话何时结束（或失败）。
- en: The next listing shows some example output from running this script on one of
    our test scenarios.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了在测试场景之一上运行此脚本的一些示例输出。
- en: Listing 10.16 Test script example output
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.16 测试脚本示例输出
- en: '[PRE16]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This script sets up the basic mechanics of having an LLM act as a user of your
    chatbot.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本设置了LLM作为你的聊天机器人用户的基本机制。
- en: This kind of test is an excellent supplement to your other testing efforts.
    LLMs may generate user inputs that you never thought to handle in your chatbot,
    and it is good to find out how your chatbot responds to them. Remember that the
    LLM is only simulating a human—real humans may never act or “speak” the way an
    LLM does. But then again, they might.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这种测试是其他测试努力的优秀补充。LLM可能会生成你从未考虑过处理的聊天机器人用户输入，了解你的聊天机器人如何响应它们是很好的。记住，LLM只是在模拟人类——真实的人类可能永远不会像LLM那样行动或“说话”。但另一方面，他们可能会的。
- en: Exercises
  id: totrans-240
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Play the role of the bot. Implement the function `call_chatbot(user_ response)`
    with the following code:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扮演机器人的角色。使用以下代码实现`call_chatbot(user_response)`函数：
- en: '[PRE17]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This lets you test how the LLM responds (as a user) to the messages you (as
    a chatbot) send. This saves you from having to implement a chatbot just to see
    how this test script works.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这样可以让你测试LLM（作为用户）对你（作为聊天机器人）发送的消息的反应。这可以让你不必仅为了测试脚本如何工作就实现一个聊天机器人。
- en: 2\. Connect the `call_chatbot(user_response)` function to an actual chatbot
    you are building. Connect the `call_llm(prompt)` function to your AI platform
    of choice. Update the `get_prompt` function to be more appropriate for your scenario.
    Does the LLM stretch the capabilities of your chatbot?
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2. 将`call_chatbot(user_response)`函数连接到你正在构建的实际聊天机器人。将`call_llm(prompt)`函数连接到你的首选AI平台。更新`get_prompt`函数以更适合你的场景。LLM是否扩展了你的聊天机器人的功能？
- en: Summary
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs can design a process flow for you from scratch. With a little prompting,
    they can generate example conversational flows and justify their design choices.
    This process flow can then be implemented in traditional conversational AI.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM可以从头开始为你设计流程。只需一点提示，它们就可以生成示例对话流程并证明它们的设计选择。然后，这个流程可以在传统的对话式AI中实现。
- en: LLMs can also take an existing process flow and improve it. A typical improvement
    is simplifying the process flow.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM也可以改进现有的流程。一个典型的改进是简化流程。
- en: You can use generative AI to execute an entire conversation. There is a trade-off
    between implementation speed and control. This is especially noticeable on error
    paths.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用生成式AI执行整个对话。在实现速度和控制之间有一个权衡。这在错误路径上尤为明显。
- en: You can replace some slot-filling process flows with an LLM-driven process.
    This can be much more flexible than strictly matching to API parameters.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以用LLM驱动的流程替换一些槽填充过程流程。这比严格匹配API参数要灵活得多。
- en: Consider the cost of being wrong when letting LLMs make judgments. Look for
    cases where “mistakes” are not critical. Be careful about which APIs the LLM is
    allowed to influence.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在让大型语言模型（LLM）做出判断时，要考虑错误带来的成本。寻找那些“错误”并不关键的情况。小心选择LLM可以影响的API。
- en: LLMs can simulate users of your conversational AI. Use them to generate test
    conversations that show how your system may behave in certain scenarios.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM可以模拟你的对话式人工智能的用户。使用它们来生成测试对话，展示你的系统在特定场景下可能的表现。
