- en: Chapter 2\. Pre-Training Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章\. 预训练数据
- en: In [Chapter 1](ch01.html#chapter_llm-introduction), we introduced language models,
    noted their strengths and limitations, explored current and potential use cases,
    and presented the scaling laws that seemingly govern progress in this field. To
    set the stage for the rest of this book, in the next three chapters we will discuss
    in detail the recipe for pre-training LLMs and the ingredients that go into them.
    But wait, this book is about utilizing pre-trained LLMs to design and build user
    applications. Why do we need to discuss the nuances of pre-training these gargantuan
    models from scratch, something most machine learning practitioners are never going
    to do in their lives?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.html#chapter_llm-introduction)中，我们介绍了语言模型，指出了它们的优点和局限性，探讨了当前和潜在的应用场景，并提出了似乎支配该领域进展的扩展定律。为了为本书的其余部分奠定基础，在接下来的三章中，我们将详细讨论预训练LLM的配方以及它们所包含的成分。但是等等，这本书是关于利用预训练LLM来设计和构建用户应用的。为什么我们需要讨论从头开始预训练这些巨型模型的细微差别，这对于大多数机器学习从业者来说在他们的一生中可能永远不会做呢？
- en: Actually, this information is very important because many of the decisions made
    during the pre-training process heavily impact downstream performance. As we will
    notice in subsequent chapters, failure modes are more easily understandable when
    you comprehend the training process. Just like we appreciate having ingredients
    listed on packages at our grocery stores, we would like to know the ingredients
    that go into making a language model before we use it in serious applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这个信息非常重要，因为在预训练过程中做出的许多决策会严重影响下游性能。正如我们在后续章节中将会注意到的，当你理解了训练过程时，失败模式就更容易理解。就像我们喜欢在杂货店的包装上看到成分列表一样，在我们将语言模型用于严重应用之前，我们希望了解制作该模型的成分。
- en: Note
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Not much information is available in the public realm about some of the proprietary
    LLMs that are accessible only through an API. This book will provide as much information
    as has been made public. While the lack of information doesn’t mean that we should
    avoid using these models, model transparency is something that you might need
    to consider while making a final decision regarding what model to use.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 关于一些只能通过API访问的专有LLM，在公共领域可用的信息不多。本书将提供尽可能多的公开信息。虽然信息不足并不意味着我们应该避免使用这些模型，但在做出最终决定选择使用哪个模型时，模型透明度可能是你需要考虑的因素。
- en: Ingredients of an LLM
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM的成分
- en: Let’s start with the ingredients that go into making an LLM.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从制作LLM的成分开始。
- en: 'Broadly speaking, we have:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从广义上讲，我们有：
- en: 'Pre-training data: What’s it trained on?'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练数据：它是在什么上训练的？
- en: The old computer science adage “garbage in, garbage out” is still accurate when
    it comes to language modeling. In this chapter we will explore popular pre-training
    datasets and dig into the various preprocessing steps taken to ensure *high-quality*
    data is fed to the model. We will also showcase some tools that allow us to probe
    these datasets and understand how pre-training data composition impacts downstream
    tasks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 旧计算机科学的格言“垃圾输入，垃圾输出”在语言建模方面仍然适用。在本章中，我们将探讨流行的预训练数据集，并深入了解为确保向模型提供高质量数据而采取的各种预处理步骤。我们还将展示一些工具，这些工具允许我们探测这些数据集，并了解预训练数据组成如何影响下游任务。
- en: 'Vocabulary and tokenizer: What’s it trained over?'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇和分词器：它是在什么上训练的？
- en: To build a model over a language, we first have to determine the vocabulary
    of the language we are modeling and rules to break down a stream of text into
    the right vocabulary units, referred to as tokenization. (We will dedicate [Chapter 3](ch03.html#chapter-LLM-tokenization)
    to discussing these concepts.) Linguistically, humans process language in terms
    of meaning-bearing words and sentences. Language models process language in terms
    of tokens. We will explore the downstream impact when there is a mismatch between
    the two.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要在一种语言上构建模型，我们首先必须确定我们正在建模的语言的词汇以及将文本流分解成正确的词汇单元（称为分词）的规则。（我们将把[第3章](ch03.html#chapter-LLM-tokenization)专门用于讨论这些概念。）从语言学的角度来看，人类从意义承载的单词和句子处理语言。语言模型从标记处理语言。我们将探讨当两者之间存在不匹配时的下游影响。
- en: 'Learning objective: What is it being trained to do?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 学习目标：它被训练去做什么？
- en: By pre-training a language model, we aim to imbue the language model with general
    skills in syntax, semantics, reasoning, and so on, that hopefully will enable
    it to reliably solve any task you throw at it, even if it was not specifically
    trained on the task. Therefore the training objectives should be sufficiently
    general to capture all these skills. In [Chapter 4](ch04.html#chapter_transformer-architecture),
    we will discuss the various tasks (learning objectives) that pre-trained models
    are trained on. You might wonder if LLMs are better suited to solving downstream
    tasks that are similar to the tasks the pre-trained model has been trained to
    solve. We will test this assumption and discuss the impact various learning objectives
    have on task performance.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过预训练语言模型，我们的目标是赋予语言模型在语法、语义、推理等方面的通用技能，希望它能可靠地解决你抛给它的任何任务，即使它没有专门针对该任务进行训练。因此，训练目标应该足够通用，以捕捉所有这些技能。在[第
    4 章](ch04.html#chapter_transformer-architecture)中，我们将讨论预训练模型所训练的各种任务（学习目标）。你可能想知道
    LLM 是否更适合解决与预训练模型训练任务相似的下游任务。我们将测试这个假设，并讨论各种学习目标对任务性能的影响。
- en: 'Architecture: What’s its internal structure?'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 架构：它的内部结构是什么？
- en: The architecture of a model refers to the components of a model, how they connect
    and interact with each other, and how they process input. Each architecture has
    its own inductive bias, a set of assumptions made about the data and tasks it
    will be used for, biasing the model toward certain types of solutions. In [Chapter 4](ch04.html#chapter_transformer-architecture),
    we will conduct a deep dive into the Transformer architecture, which, as discussed
    in [Chapter 1](ch01.html#chapter_llm-introduction), is the predominantly used
    architecture currently.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的架构指的是模型的组件，它们如何连接和相互作用，以及它们如何处理输入。每种架构都有自己的归纳偏差，即关于它将用于的数据和任务的假设集合，使模型偏向于某些类型的解决方案。在[第
    4 章](ch04.html#chapter_transformer-architecture)中，我们将深入探讨 Transformer 架构，正如在[第
    1 章](ch01.html#chapter_llm-introduction)中讨论的那样，这是目前主要使用的架构。
- en: Let’s look at how these ingredients fit together in [Figure 2-1](#ingredients-of-llm).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些成分如何在[图 2-1](#ingredients-of-llm)中组合在一起。
- en: '![LLM Ingredients](assets/dllm_0201.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![LLM 成分](assets/dllm_0201.png)'
- en: Figure 2-1\. How all the ingredients come together to make an LLM
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 所有成分如何结合在一起形成一个 LLM
- en: 'The language models trained using the process described in this chapter and
    the next are called *base models*. Lately, model providers have been augmenting
    the base model by fine-tuning it on much smaller datasets to steer them toward
    being more aligned with human needs and preferences. Some popular tuning modes
    are:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本章和下一章中描述的过程训练的语言模型被称为*基础模型*。最近，模型提供商通过在更小的数据集上微调基础模型来增强它，以便使其更符合人类的需求和偏好。一些流行的微调模式包括：
- en: Supervised instruction fine-tuning (SFT), so that the model is better at following
    human instructions
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督指令微调（SFT），使模型更好地遵循人类指令
- en: Reinforcement learning by human feedback (RLHF), so that the model is better
    aligned with human preferences
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过人类反馈的强化学习（RLHF），使模型更好地与人类偏好对齐
- en: Domain-adaptive or task-adaptive continued pre-training, so that the model is
    better attuned to specific domains and tasks
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域自适应或任务自适应的持续预训练，使模型更好地适应特定领域和任务
- en: Based on the specific augmentation carried out, the resulting models are called
    *instruct models*, *chat models*, and so on.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据具体的增强方式，生成的模型被称为*指令模型*、*聊天模型*等。
- en: We will cover instruct and chat models in [Chapter 6](ch06.html#llm-fine-tuning),
    and domain-adaptive and task-adaptive pre-training in [Chapter 7](ch07.html#ch07).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第 6 章](ch06.html#llm-fine-tuning)中介绍指令和聊天模型，并在[第 7 章](ch07.html#ch07)中介绍领域自适应和任务自适应的预训练。
- en: '![Derivative Models](assets/dllm_0202.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![衍生物模型](assets/dllm_0202.png)'
- en: Figure 2-2\. The relationship between base models and their derivatives
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 基础模型及其衍生物之间的关系
- en: Pre-Training Data Requirements
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练数据需求
- en: Although it has been shown that higher-capacity models are relatively more [sample
    efficient](https://oreil.ly/PbN6F), in general today’s language models are very
    sample inefficient, meaning they need tons of examples to learn a task. It is
    infeasible to create such a large supervised dataset with human annotations, hence
    the predominant means to pre-train language models is using *self-supervised*
    learning, where the target labels exist within your training inputs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已经证明，高容量模型相对更[样本高效](https://oreil.ly/PbN6F)，但总的来说，今天的语言模型非常样本低效，这意味着它们需要大量的例子来学习一个任务。用人工标注创建如此大的监督数据集是不切实际的，因此，预训练语言模型的主要手段是使用*自监督*学习，其中目标标签存在于你的训练输入中。
- en: Using this setup, virtually any type of text is fair game to be included in
    a pre-training dataset, and theoretically any nontextual signal with some structure
    can be encoded in text and included as part of a pre-training dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种设置，几乎任何类型的文本都可以被包括在预训练数据集中，理论上任何具有结构的非文本信号都可以编码成文本，并作为预训练数据集的一部分。
- en: From our scaling laws discussion in [Chapter 1](ch01.html#chapter_llm-introduction),
    we know that model performance increases by just training them longer and on more
    data. Also, as discussed in [Chapter 1](ch01.html#chapter_llm-introduction), the
    *consolidation effect* at play in the field raises expectations on what a single
    language model is expected to do end-to-end. Today a single model is expected
    to answer factual questions about the world, employ arithmetic and logical reasoning,
    write code, and come up with creative ideas.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们在[第1章](ch01.html#chapter_llm-introduction)中的扩展定律讨论中，我们知道模型性能仅通过更长时间和更多数据的训练就能提高。此外，正如[第1章](ch01.html#chapter_llm-introduction)中讨论的，该领域的*巩固效应*提高了对单个语言模型端到端期望的预期。今天，一个模型被期望回答关于世界的事实性问题，运用算术和逻辑推理，编写代码，并提出创新的想法。
- en: All this means that the data needs for language model pre-training are enormous.
    Now, the key question is whether textual data available in the world actually
    contains sufficient and relevant signals needed to learn all the skills we want
    LLMs to learn.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都意味着语言模型预训练所需的数据量是巨大的。现在，关键问题是世界上可用的文本数据是否真的包含了学习我们希望LLM学习到的所有技能所需的足够和相关的信号。
- en: Note that language models that are trained solely on text only have access to
    the linguistic form, i.e., the sequence of characters making up a sentence like,
    “Walter White tossed the pizza onto the roof.” To understand its meaning, the
    linguistic form has to be mapped to the communicative intent of the writer/speaker.
    While a [section](https://oreil.ly/3iYA2) of the research community argues that
    one cannot learn meaning from form alone, recent language models are increasingly
    proving otherwise.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，仅用文本训练的语言模型只能访问语言形式，即构成句子如“Walter White把披萨扔到屋顶上。”的字符序列。要理解其含义，语言形式必须映射到作者/说话者的沟通意图。虽然研究社区的一部分认为不能仅从形式中学习意义，但最近的语言模型越来越多地证明并非如此。
- en: 'To have access to the full picture, the linguistic form needs to be grounded
    to the real world. In the cognitive sciences, grounding is defined as:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得完整的情况，语言形式需要与现实世界联系起来。在认知科学中，这种联系被定义为：
- en: The process of establishing what mutual information is required for successful
    communication between two interlocutors
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 建立两个对话者之间成功沟通所需的互信息量的过程
- en: ''
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chandu et al., [“Grounding ‘grounding’ in NLP”](https://oreil.ly/kPyXu)
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Chandu等人，[“在NLP中‘grounding’的‘grounding’”](https://oreil.ly/kPyXu)
- en: Human text is generally very underspecified, with a lot of communicative intent
    existing outside the textual context, depending on the reader/listener to use
    their common sense, world knowledge, and ability to detect and understand emotional
    subtext to interpret it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 人类文本通常非常不具体，很多沟通意图存在于文本之外，依赖于读者/听者使用他们的常识、世界知识和检测、理解情感隐含意义的能力来解释它。
- en: Note
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It is estimated that only around [12% of information](https://oreil.ly/jg4tW)
    we understand from text is explicitly mentioned in text. There are several theories
    explaining why we communicate thus, including [Zipf’s principle of least effort](https://oreil.ly/UX7Nd),
    which states it is “human nature to want the greatest outcome at the least amount
    of work.”
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 据估计，我们从文本中理解的信息中只有大约[12%](https://oreil.ly/jg4tW)是明确提到的。有几个理论解释了为什么我们这样沟通，包括[Zipf的最小努力原则](https://oreil.ly/UX7Nd)，它表明“人类本性是希望以最少的努力获得最大的成果。”
- en: The field of NLP has seen [a lot of work](https://oreil.ly/PbIhT) in grounding
    language models to the real world. [Multimodal models](https://oreil.ly/ysAeM)
    that combine different modalities like image, video, speech, and text are a promising
    avenue of research, and they are likely to see more widespread usage in the coming
    years. Imagine a model seeing “pizza” in the training text, but also getting signals
    on how it looks, how it sounds, and how it tastes!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理领域已经看到了[大量工作](https://oreil.ly/PbIhT)将语言模型与现实世界联系起来。结合不同模态（如图像、视频、语音和文本）的多模态模型是一个有希望的研究方向，并且它们在未来几年可能会得到更广泛的应用。想象一下，一个模型在训练文本中看到了“披萨”，同时也获得了关于它的外观、声音和味道的信号！
- en: But do multimodal models really help with the grounding problem? Can we instead
    achieve the effect of grounding by just feeding the model with massive amounts
    of diverse text? These are unsolved questions, and there are good arguments in
    both directions as shown by this [debate](https://oreil.ly/oacht).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，多模态模型真的有助于解决基础问题吗？我们能否仅仅通过向模型提供大量多样化的文本来实现基础的效果？这些问题尚未解决，正如这个[辩论](https://oreil.ly/oacht)所示，双方都有很好的论据。
- en: Whether training on massive amounts of text alone can enable language models
    to learn skills like logical reasoning is another open question. Note that text
    on the internet contains a lot of text describing reasoning steps, like theorem
    proofs, explanations of jokes, step-by-step answers to puzzles, and so on. However,
    there is simply not enough of derivational text going around, which leads us to
    cover the shortfall by using prompting methods like CoT (described further in
    [Chapter 5](ch05.html#chapter_utilizing_llms)). There is [recent evidence](https://oreil.ly/Qlntp)
    that process supervision, where feedback is provided for each step of the problem-solving
    process, as opposed to outcome supervision, where feedback is provided only on
    the final solution, helps improve arithmetic reasoning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 单独在大量文本上进行训练是否能够使语言模型学习到诸如逻辑推理等技能，这也是一个悬而未决的问题。请注意，互联网上的文本包含大量描述推理步骤的内容，如定理证明、笑话的解释、拼图的逐步答案等等。然而，衍生的文本实在不够多，这导致我们通过使用如CoT（在第5章中进一步描述）等提示方法来弥补这一不足。有[最新证据](https://oreil.ly/Qlntp)表明，过程监督（为问题解决的每一步提供反馈）与结果监督（仅在最终解决方案上提供反馈）相比，有助于提高算术推理能力。
- en: A crucial skill that language models have to learn is dealing with the inherently
    ambiguous nature of language. Following up on the aforementioned Zipf’s principle
    of least effort, ambiguity enables speakers to manage the efficiency-clarity tradeoff
    in communication. We can leave a lot unsaid because we have established sufficient
    common ground with the people we are communicating with and trust that they are
    able to fill in the gaps.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型必须学习的一项关键技能是处理语言固有的模糊性。在上述的齐夫最小努力原则之后，模糊性使得说话者能够在沟通中的效率-清晰度权衡中做出管理。我们可以留下很多没有说出的内容，因为我们已经与沟通的对象建立了足够的共同基础，并相信他们能够填补这些空白。
- en: 'Earlier language models struggled a lot with modeling ambiguity. I long used
    this sentence as a canonical example in my NLP talks to highlight ambiguity in
    language: “WWE’s John Cena surprises Make-A-Wish 7-year-old with cancer.”'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的语言模型在建模模糊性方面遇到了很多困难。我长期以来一直将这句话作为我的NLP演讲中的典范例子，以突出语言的模糊性：“WWE的约翰·塞纳出人意料地让患有癌症的7岁Make-A-Wish儿童感到惊喜。”
- en: While state-of-the-art models are able to correctly interpret this particular
    sentence and not mistakenly identify John Cena as an evil disease-spreading wizard,
    [recent work](https://oreil.ly/BrSwb) shows that even the best models of today
    still struggle to deal with ambiguity in general. Whether just scaling up models
    and data is enough for LLMs to model ambiguity is an open question.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最先进的模型能够正确地解释这个特定的句子，并且不会错误地将约翰·塞纳识别为邪恶的疾病传播巫师，但[最近的研究](https://oreil.ly/BrSwb)表明，即使是今天最好的模型仍然在处理一般性模糊性方面存在困难。仅仅通过扩大模型和数据规模是否足以让大型语言模型建模模糊性，这是一个悬而未决的问题。
- en: If our only option to resolve all these shortcomings is to scale up dataset
    sizes, the next question is if we actually have enough data available in the world
    that is sufficient for LLMs to learn these skills. Are we at risk of running out
    of training data anytime soon? There is a misconception in certain quarters of
    our field that we already have. However, lack of raw data is not yet a bottleneck
    in training models. For instance, there are billions of publicly available documents
    accessible by scraping or via a free API that haven’t yet made it into most pre-training
    data sets, such as parliamentary proceedings, court judgments, and most SEC filings.
    [“How much LLM training data is there, in the limit?”](https://oreil.ly/XnmHL)
    by Educating Silicon estimates the amount of text present in the world. On the
    other hand, it is true that at a sufficiently large scale, there is simply not
    enough naturally occurring data to feed our models.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们解决所有这些缺陷的唯一选择是扩大数据集的大小，那么下一个问题是，我们实际上是否拥有足够的数据来让LLM学习这些技能。我们是否很快就会面临训练数据不足的风险？在我们领域的某些领域存在一种误解，即我们已经做到了。然而，缺乏原始数据还不是训练模型的瓶颈。例如，有数十亿可以通过抓取或免费API访问的公开文档尚未纳入大多数预训练数据集，例如议会程序、法院判决和大多数SEC文件。[“Educating
    Silicon”的“极限下LLM训练数据有多少？”](https://oreil.ly/XnmHL)估计了世界上存在的文本量。另一方面，确实，在足够大的规模上，自然发生的数据根本不足以喂养我们的模型。
- en: Thus, there are efforts to use text generated by language models, termed *synthetic
    data*, to train models, albeit with the [risk](https://oreil.ly/RdzX0) that training
    on LLM-generated data can potentially be detrimental, as the model deviates from
    the true distribution of the data. Later in this chapter, we will learn the process
    behind creating synthetic data for pre-training.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有人尝试使用由语言模型生成的文本，称为*合成数据*，来训练模型，尽管存在[风险](https://oreil.ly/RdzX0)，即基于LLM生成的数据进行训练可能会对模型产生不利影响，因为模型会偏离数据的真实分布。在本章后面，我们将了解创建用于预训练的合成数据背后的过程。
- en: Of course, not all data is created equal. We can achieve more sample efficiency
    with high-quality data, thus needing smaller dataset sizes. We can preprocess
    data in order to filter out low-quality data or make them higher quality. What
    exactly makes data high quality is a nuanced question, which we will explore later
    in the chapter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并非所有数据都是平等的。我们可以通过高质量的数据实现更高的样本效率，从而需要更小的数据集大小。我们可以预处理数据，以便过滤掉低质量数据或提高其质量。究竟是什么使得数据成为高质量数据是一个复杂的问题，我们将在本章后面探讨。
- en: Popular Pre-Training Datasets
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行预训练数据集
- en: A lot of text is not freely available in public. This includes data exposed
    behind paywalled APIs and login screens, and paywalled books and documents, many
    of which may not even be digitized. Larger companies like Google and OpenAI can
    afford to purchase this data; for example, OpenAI has [struck deals](https://oreil.ly/ygIO2)
    worth hundreds of millions of dollars with the *Wall Street Journal*, *Financial
    Times*, and other news organizations for access to their data. Domain-specific
    text is often proprietary and available only to large incumbents (for example,
    Bloomberg trained [BloombergGPT](https://oreil.ly/87r4j) partly on its proprietary
    financial data). However, even for models trained by the largest companies, a
    significant proportion of training data comes from publicly available data sources.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 许多文本在公共领域并不免费可用。这包括隐藏在付费API和登录屏幕背后的数据，以及付费书籍和文档，其中许多甚至尚未数字化。像谷歌和OpenAI这样的大公司可以负担得起购买这些数据；例如，OpenAI与*华尔街日报*、《金融时报》和其他新闻机构达成了价值数亿美元的交易，以获取其数据。特定领域的文本通常是专有的，并且仅对大型企业开放（例如，彭博社在训练[BloombergGPT](https://oreil.ly/87r4j)时部分使用了其专有的金融数据）。然而，即使是最大公司训练的模型，其训练数据中也有很大一部分来自公开的数据源。
- en: Next, we will cover some of the most popular general-purpose pre-training datasets
    that are being used to train LLMs. While this is not a comprehensive list, most
    LLMs, including closed-source ones, have at least a large subset of their training
    data drawn from these sources. We will defer discussion of domain-specific (catered
    to a particular field like social media, finance, biomedical, etc.) datasets to
    [Chapter 7](ch07.html#ch07).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些最流行的通用预训练数据集，这些数据集被用来训练LLM。虽然这不是一个详尽无遗的列表，但大多数LLM，包括闭源LLM，其训练数据中至少有一大部分来自这些来源。我们将把特定领域（针对特定领域，如社交媒体、金融、生物医学等）数据集的讨论推迟到[第7章](ch07.html#ch07)。
- en: Tip
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Most general-purpose LLMs are trained to be a jack-of-all-trades—to be able
    to solve tasks from a variety of domains. If the data domain for your use case
    is included in the pre-training dataset, models trained on those datasets may
    show relative performance improvements on downstream tasks compared to models
    that aren’t, even if the pre-training data is unlabeled. This means that if you
    intend to use LLMs for specific, well-defined use cases in a particular domain,
    domain-specific models could prove promising. You can also perform *continued
    domain-adaptive* or *task-adaptive pre-training* on your domain data to leverage
    this phenomenon. This will be discussed in detail in [Chapter 7](ch07.html#ch07).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数通用LLM被训练成多面手——能够解决来自各种领域的任务。如果你的用例数据域包含在预训练数据集中，与未包含这些数据集的模型相比，在这些数据集上训练的模型在下游任务上可能显示出相对的性能提升，即使预训练数据是无标签的。这意味着，如果你打算在特定领域使用LLM进行特定、明确的用例，领域特定模型可能会证明是有希望的。你还可以在你的领域数据上执行
    *持续的领域自适应* 或 *任务自适应预训练* 来利用这一现象。这将在第7章（ch07.html#ch07）中详细讨论。
- en: 'Here are some examples of commonly used data sources for general-purpose language
    models:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些通用语言模型常用的数据源示例：
- en: Common Crawl/C4
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Common Crawl/C4
- en: The web is the largest source of openly available textual data, and hence forms
    a significant proportion of pre-training datasets. [Common Crawl](https://oreil.ly/dhBvu)
    is a nonprofit that creates and publishes snapshots of all web crawl data, updated
    every month. However, as one could imagine, this is an extremely coarse dataset
    and needs to be significantly cleaned before it is ready to use. Google prepared
    C4 (Colossal Clean Crawled Corpus), a 750GB English-language dataset, after applying
    a set of preprocessing and filtering steps to a Common Crawl snapshot from 2019
    and released the code for it. [Dodge et al.](https://oreil.ly/bxmVR) used this
    script to reproduce C4 and have made it publicly available. C4 has been used for
    training several well-known LLMs including all models from the T5 family.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是公开可获取的文本数据最大的来源，因此构成了预训练数据集的一个重要比例。[Common Crawl](https://oreil.ly/dhBvu)
    是一个非营利组织，它创建并发布所有网络爬取数据的快照，每月更新一次。然而，正如人们可以想象的那样，这是一个极其粗略的数据集，在准备使用之前需要显著清理。Google
    在对2019年的Common Crawl快照应用了一系列预处理和过滤步骤后，准备了 C4（Colossal Clean Crawled Corpus），这是一个750GB的英语语言数据集，并发布了相应的代码。[Dodge等人](https://oreil.ly/bxmVR)
    使用此脚本重现了C4，并将其公开。C4 已被用于训练包括T5系列中所有模型在内的几个知名LLM。
- en: The Pile
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: The Pile
- en: '[The Pile](https://oreil.ly/7UAcY) is a 825GB dataset from Eleuther AI, which
    focused on publishing a dataset drawn from more diverse sources. Diversity of
    data is important since in-domain unlabeled data in pre-training is helpful for
    downstream performance on that domain, and diverse data sets also enable generalization
    to previously unseen tasks and domains. To this end, the data from The Pile comes
    not only from Common Crawl but also PubMed Central, arXiv, GitHub, the FreeLaw
    Project, Stack Exchange, the US Patent and Trademark Office, Ubuntu IRC, HackerNews,
    YouTube, PhilPapers, NIH ExPorter, Project Gutenberg, and Wikipedia, among others.
    The Pile and its subsets have been preferred as a data source for training several
    LLMs, including [Llama](https://oreil.ly/_8eOD).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[The Pile](https://oreil.ly/7UAcY) 是来自Eleuther AI的825GB数据集，它专注于从更多样化的来源发布数据集。数据多样性很重要，因为预训练中的领域内未标记数据有助于该领域的下游性能，多样化的数据集也使得模型能够泛化到之前未见过的任务和领域。为此，The
    Pile 的数据不仅来自 Common Crawl，还包括 PubMed Central、arXiv、GitHub、FreeLaw项目、Stack Exchange、美国专利和商标局、Ubuntu
    IRC、HackerNews、YouTube、PhilPapers、NIH ExPorter、Project Gutenberg 和 Wikipedia 等。The
    Pile 及其子集已被选为训练几个LLM的数据源，包括 [Llama](https://oreil.ly/_8eOD)。'
- en: WebText/OpenWebText/OpenWebText2
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: WebText/OpenWebText/OpenWebText2
- en: These refer to a subset of web text and are limited to web pages representing
    outbound links on Reddit that have at least three *karma*, the absolute difference
    between user upvotes and downvotes. The assumption is that the wisdom of the crowd
    will enable only high-quality links to surface, which contain information people
    actually find interesting. Models that have been trained on this data include
    GPT-2 and GPT-3.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指的是网络文本的一个子集，并且仅限于在Reddit上代表出站链接的网页，这些链接至少有三个 *karma*，即用户点赞和踩的绝对差值。假设群众的智慧将只允许高质量链接浮现，这些链接包含人们真正感兴趣的信息。在此数据上训练过的模型包括
    GPT-2 和 GPT-3。
- en: Wikipedia
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Wikipedia
- en: Wikipedia assumes a major role in the training of just about every general-purpose
    LLM. A full dump of Wikipedia contains valuable encyclopedic text that provides
    factual knowledge to the model. Wikipedia’s editorial system ensures that the
    text follows a highly structured format. However, it is not diverse stylistically,
    as the text is written in a formal manner. Therefore, Wikipedia alone is not sufficient
    to train a rudimentary language model and needs to be combined with data sources
    comprising diverse writing styles.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科在几乎所有通用大型语言模型的训练中都扮演着重要角色。维基百科的完整存档包含了有价值的百科全书文本，为模型提供了事实知识。维基百科的编辑系统确保文本遵循高度结构化的格式。然而，在风格上并不多样，因为文本是以正式的方式编写的。因此，仅靠维基百科不足以训练一个基本的语言模型，需要结合包含多样写作风格的数据源。
- en: BooksCorpus/BooksCorpus2
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: BooksCorpus/BooksCorpus2
- en: Probably the most historically influential of all pre-training datasets, this
    dataset was part of the training corpus for well-known models like BERT, RoBERTa,
    GPT-2/3, etc. The BooksCorpus contains over 7,000 free, mostly fiction books written
    by unpublished authors. Twenty-six percent of books in the original dataset belonged
    to the Romance genre. A replication of the BooksCorpus is present in The Pile
    as BooksCorpus2.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是所有前训练数据集中历史影响力最大的一个，这个数据集是知名模型如 BERT、RoBERTa、GPT-2/3 等的训练语料库的一部分。BooksCorpus
    包含超过 7,000 本由未发表作者撰写的免费、主要是虚构书籍。原始数据集中 26% 的书籍属于浪漫类型。BooksCorpus 的副本存在于 The Pile
    中，称为 BooksCorpus2。
- en: FineWeb
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: FineWeb
- en: As of the book’s writing, [FineWeb](https://oreil.ly/1GyZd) is the world’s largest
    publicly available pre-training dataset. Published by Hugging Face, FineWeb has
    15 trillion tokens and is drawn from 96 snapshots of Common Crawl, after a rigorous
    cleaning and filtering process. Hugging Face also released [FineWeb-Edu](https://oreil.ly/8XHH-),
    a subset of FineWeb composed of educational data, which is crucial in enabling
    LLMs to pass standardized tests and popular benchmarks.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书撰写时，[FineWeb](https://oreil.ly/1GyZd) 是世界上最大的公开可用的前训练数据集。由 Hugging Face 发布，FineWeb
    拥有 1500 万亿个 token，并从 96 个 Common Crawl 快照中提取，经过严格的清洗和过滤过程。Hugging Face 还发布了 [FineWeb-Edu](https://oreil.ly/8XHH-)，这是
    FineWeb 的一个子集，由教育数据组成，这对于使大型语言模型通过标准化测试和流行基准至关重要。
- en: '[Table 2-1](#popular-pretraining-datasets) provides a list of some of the most
    commonly used datasets, their size, year of release, and the means to access them.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2-1](#popular-pretraining-datasets) 提供了一些最常用数据集的列表，包括它们的大小、发布年份以及访问它们的方式。'
- en: Table 2-1\. Popular pretraining datasets
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. 流行的前训练数据集
- en: '| Name | Data source(s) | Size | Year released | Public? | Models using this
    dataset |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 数据来源 | 大小 | 发布年份 | 公开？ | 使用此数据集的模型 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| C4 | Common Crawl | 750GB | 2019 | Yes (reproduced version) | T5, FLAN-T5,
    UL2, Llama, etc. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| C4 | Common Crawl | 750GB | 2019 | 是（复制品） | T5, FLAN-T5, UL2, Llama, 等 |'
- en: '| The Pile | Common Crawl, PubMed Central, Wikipedia, arXiv, Project Gutenberg,
    Stack Exchange, USPTO, GitHub, etc. | 825GB | 2020 | Yes | GPT-NeoX, GPT-J, Cerebras-GPT,
    StableLM, Pythia, etc. |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| The Pile | Common Crawl, PubMed Central, Wikipedia, arXiv, Project Gutenberg,
    Stack Exchange, USPTO, GitHub, 等 | 825GB | 2020 | 是 | GPT-NeoX, GPT-J, Cerebras-GPT,
    StableLM, Pythia, 等 |'
- en: '| RedPajama | Common Crawl, GitHub, Wikipedia, arXiv, Stack Exchange, etc.
    | 1.2T tokens | 2023 | Yes | Red Pajama-INCITE, MPT |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| RedPajama | Common Crawl, GitHub, Wikipedia, arXiv, Stack Exchange, 等 | 1.2T
    tokens | 2023 | 是 | Red Pajama-INCITE, MPT |'
- en: '| BooksCorpus | Sampled from smashwords.com | 74M sentences | 2015 | Original
    not available anymore | Most models including BERT, GPT, etc. |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| BooksCorpus | 从 smashwords.com 抽样 | 7400 万句子 | 2015 | 原始数据不再可用 | 包括 BERT、GPT
    等在内的多数模型 |'
- en: '| OpenWebText2 | Outbound Reddit links | 65GB | 2020 | Yes | GPT-2, GPT-3 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| OpenWebText2 | Reddit 外链 | 65GB | 2020 | 是 | GPT-2, GPT-3 |'
- en: '| ROOTS | Big Science Catalogue, Common Crawl, GitHub | 1.6T tokens | 2022
    | No (but available on request) | BLOOM |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| ROOTS | 大科学目录，Common Crawl，GitHub | 1.6T tokens | 2022 | 否（但可请求提供） | BLOOM
    |'
- en: '| RefinedWeb | Common Crawl | 5T tokens | 2023 | Yes (600B subset only) | Falcon
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| RefinedWeb | Common Crawl | 5T tokens | 2023 | 是（仅 600B 子集） | Falcon |'
- en: '| SlimPajama | Cleaned from RedPajama | 627B tokens | 2023 | Yes | N/A |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| SlimPajama | 从 RedPajama 清洗而来 | 627B tokens | 2023 | 是 | N/A |'
- en: The table highlights the fact that most models are trained on similar data sources.
    In this chapter, we are limiting our coverage to pre-training datasets for base
    models. We will cover datasets used to augment base models like instruction tuning
    datasets, RLHF datasets, etc. in [Chapter 6](ch06.html#llm-fine-tuning).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表格突出了这样一个事实：大多数模型都是在类似的数据源上训练的。在本章中，我们将限制我们的覆盖范围到基础模型的预训练数据集。我们将在 [第 6 章](ch06.html#llm-fine-tuning)
    中介绍用于增强基础模型的数据集，如指令微调数据集、RLHF 数据集等。
- en: 'Let’s explore the content of these pre-training datasets. Using a Google Colab
    notebook or a code editor of your choice, load the `realnewslike` subset of the
    C4 dataset, which consumes around 15 GB:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索这些预训练数据集的内容。使用 Google Colab 笔记本或你选择的代码编辑器，加载 C4 数据集的 `realnewslike` 子集，该子集大约消耗
    15 GB：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using this code, we can observe all the instances in which Iceland appears in
    this C4 subset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码，我们可以观察到在 C4 子集中出现冰岛的所有实例。
- en: Synthetic Pre-Training Data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成预训练数据
- en: An emerging trend is the use of LLMs to generate synthetic data that can be
    used for pre-training LLMs. One of the first success stories in training LLMs
    on datasets with a significant proportion of synthetic data is Microsoft’s [phi
    series of models](https://oreil.ly/eFphR). For the phi-1.5 model, Microsoft created
    20 billion tokens of synthetic data, using 20,000 seed topics and samples from
    real-world web datasets in their prompts.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新兴趋势是使用 LLM 生成可用于预训练 LLM 的合成数据。在训练包含大量合成数据的 LLM 数据集方面，第一个成功案例之一是微软的 [phi 系列模型](https://oreil.ly/eFphR)。对于
    phi-1.5 模型，微软创建了 200 亿个合成数据标记，使用 20,000 个种子主题和来自现实世界网络数据集的样本作为提示。
- en: Hugging Face released [Cosmopedia](https://oreil.ly/Pdwnw), an open source synthetic
    dataset used to train the SmolLM series of models. Its seed data included curated
    sources like Stanford courses, Khan Academy, and WikiHow, as well as general web
    data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 发布了 [Cosmopedia](https://oreil.ly/Pdwnw)，这是一个开源的合成数据集，用于训练 SmolLM
    系列模型。其种子数据包括经过精心挑选的资源，如斯坦福课程、可汗学院和 WikiHow，以及一般网络数据。
- en: For curated sources, synthetic data was generated by extracting outlines of
    courses from Khan Academy and other sources and prompting the Mistral LLM to generate
    lengthy, detailed textbooks for individual sections. To generate diverse data
    at scale, Hugging Face issues several variants of the same prompt for each topic,
    like “create a textbook on this topic for young children” and “create a textbook
    on this topic for professionals.”
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于精心挑选的资源，通过从可汗学院和其他来源提取课程大纲并提示 Mistral LLM 为各个部分生成详细的长篇教科书来生成合成数据。为了大规模生成多样化的数据，Hugging
    Face 为每个主题发布了几个变体的提示，例如“为幼儿创建这个主题的教科书”和“为专业人士创建这个主题的教科书”。
- en: For general web data, Hugging Face clustered a subset of the RefinedWeb dataset
    into over a hundred topics. The LLM was then prompted with web page snippets and
    asked to generate an extensive blog post within the context of the topic the web
    page fell under. The cluster visualization can be explored in [Nomic Atlas](https://oreil.ly/t8R-6).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一般网络数据，Hugging Face 将 RefinedWeb 数据集的一个子集聚类到一百多个主题中。然后，LLM 被提示使用网页片段，并要求在网页所属的主题背景下生成一篇广泛的博客文章。聚类可视化可以在
    [Nomic Atlas](https://oreil.ly/t8R-6) 中探索。
- en: Training Data Preprocessing
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据预处理
- en: Once we have collected or procured data, we need to filter and clean the data
    by running it through a preprocessing pipeline. Data preprocessing is the most
    unglamorous and underappreciated part of the LLM training pipeline, yet perhaps
    the most important. Based on my experience, spending more effort and resources
    during this phase can lead to significant downstream performance gains. As we
    walk through the data processing pipeline, I hope you come to appreciate the complexity
    of language text and the difficulty in processing it. Note that since these datasets
    are enormous, any preprocessing step should also be very efficient (ideally linear
    time).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们收集或获取了数据，我们需要通过运行预处理管道来过滤和清理数据。数据预处理是 LLM 训练管道中最不引人注目且最不被重视的部分，但也许是最重要的。根据我的经验，在这个阶段投入更多努力和资源可以带来显著的下游性能提升。在我们遍历数据处理管道时，我希望你能体会到语言文本的复杂性和处理它的难度。请注意，由于这些数据集非常大，任何预处理步骤都应该非常高效（理想情况下为线性时间）。
- en: '[Figure 2-3](#data-collection) shows the typical preprocessing steps used to
    generate a pre-training dataset. The ordering of steps is not fixed, but there
    are dependencies between some of the steps.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-3](#data-collection) 展示了用于生成预训练数据集的典型预处理步骤。步骤的顺序不是固定的，但某些步骤之间存在依赖关系。'
- en: '![Data preprocessing pipeline](assets/dllm_0203.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![数据预处理流程](assets/dllm_0203.png)'
- en: Figure 2-3\. Data collection and preprocessing pipeline
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. 数据收集和预处理流程
- en: Let’s go through these steps in detail.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细地走一遍这些步骤。
- en: Data Filtering and Cleaning
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据过滤和清洗
- en: 'A majority of text extracted from HTML files is gibberish, like menu text from
    websites, boilerplate text, and random web page artifacts. There is a significant
    amount of pornography and toxic/hateful language on the web as well. For example,
    here is a text sample from an uncleaned version of the C4 dataset:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从 HTML 文件中提取的大多数文本都是乱码，例如来自网站的菜单文本、模板文本和随机的网页碎片。互联网上也有大量的色情和有害/仇恨性语言。例如，以下是
    C4 数据集未清洗版本的一个文本样本：
- en: Skip to Main Content Skip to Footer Skip to Email Signup Skip to Feedback Form
    MY REWARDS SIGN OUT SIGN IN & EARN REWARDS 0 Keyboard Controls Welcome to the
    main navigation. This menu has three levels of product categories. Use and keys
    to navigate between each category in the current level. Use the key to navigate
    down a level. Use the key to navigate up a level. Hit the key to be taken to the
    selected category page. Men What’s Hot New Arrivals Brand That Unites Performance
    Shop Online Exclusives Express Essentials Vacation Getaway Wedding Tuxedos Military
    Trend 9 Pieces / 33 Looks The Edit x Express NBA Collection Express + NBA Fashion
    NBA Game Changers Suiting & Blazers Find
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 跳转到主要内容 跳转到页脚 跳转到电子邮件注册 跳转到反馈表单 MY REWARDS 登出 登录并赚取奖励 0 键盘控制 欢迎来到主要导航。此菜单有三个产品类别的层级。使用和键在当前层级的每个类别之间导航。使用键向下导航一个层级。使用键向上导航一个层级。按键可转到所选类别页面。菜单
    热门新品 新品上市 品牌联合性能在线独家快闪必备度假婚礼礼服军装趋势 9 件/33 款造型 The Edit x Express NBA Collection
    Express + NBA 时尚 NBA 改变游戏规则西装与夹克衫在线购物独家系列
- en: How useful do you think this text is for language and task learning?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为这段文本对语言和任务学习有多大的帮助？
- en: Data from Common Crawl is made available via both raw HTML and web-extracted
    text (WET) format. While many dataset creators directly use the WET files, the
    open source organization Eleuther AI [noticed](https://oreil.ly/hciZS) that the
    quality of the WET files left much to be desired, with HTML boilerplate still
    prominent as seen above. To create The Pile, Eleuther AI thus used the [jusText
    library](https://oreil.ly/YRFzZ) to more reliably remove boilerplate text from
    HTML documents.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Common Crawl 的数据以原始 HTML 和网页提取文本（WET）格式提供。虽然许多数据集创建者直接使用 WET 文件，但开源组织 Eleuther
    AI [注意到](https://oreil.ly/hciZS)，WET 文件的质量还有很多需要改进的地方，如上所示，HTML 模板文本仍然突出。因此，为了创建
    The Pile，Eleuther AI 使用了 [jusText 库](https://oreil.ly/YRFzZ) 来更可靠地从 HTML 文档中去除模板文本。
- en: 'Let’s explore the effect of using jusText with an example. In your Google Colab
    or Jupyter notebook, try this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来探索使用 jusText 的影响。在你的 Google Colab 或 Jupyter 笔记本中，尝试以下操作：
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output displays all the boilerplate that is filtered out from a standard
    Wikipedia article:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了从标准维基百科文章中过滤出的所有模板文本：
- en: '[PRE2]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: jusText just so happens to be more aggressive in removing content, but this
    is generally OK for cleaning pre-trained datasets since there is an abundance
    of text available. Some alternative libraries used for this task include [Dragnet](https://oreil.ly/URvsq),
    [html2text](https://oreil.ly/xk7Hc), [inscriptis](https://oreil.ly/6-2z1), [Newspaper](https://oreil.ly/LPXe1),
    and [Trafilatura](https://oreil.ly/zdZxj). According to the creators of [The Pile](https://oreil.ly/DZG7w),
    dividing the extraction pipeline across multiple libraries can reduce the risk
    of the resulting dataset being affected by any bias introduced by one of these
    libraries.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: jusText 正好更积极地去除内容，但对于清理预训练数据集来说通常是可行的，因为可用的文本量很大。用于此任务的某些替代库包括 [Dragnet](https://oreil.ly/URvsq)、[html2text](https://oreil.ly/xk7Hc)、[inscriptis](https://oreil.ly/6-2z1)、[Newspaper](https://oreil.ly/LPXe1)
    和 [Trafilatura](https://oreil.ly/zdZxj)。根据 [The Pile](https://oreil.ly/DZG7w)
    的创建者，将提取流程分散到多个库中可以降低结果数据集受到任何库引入的偏差的影响。
- en: Boilerplate removal in web pages is a challenging task. Web pages may also contain
    code blocks, tables, and math formulas, which need careful processing. [Meta](https://oreil.ly/bXELJ)
    noted that it built a custom HTML parser for preparing the dataset to train Llama
    3\. It also mentioned that Meta retains the *alt* attribute in images, which it
    found contains useful information like math content.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在网页中去除模板文本是一个具有挑战性的任务。网页还可能包含代码块、表格和数学公式，这些都需要仔细处理。[Meta](https://oreil.ly/bXELJ)
    指出，为了准备训练 Llama 3 的数据集，它构建了一个定制的 HTML 解析器。它还提到，Meta 保留了图像中的 *alt* 属性，它发现其中包含有用的信息，如数学内容。
- en: LLMs can also be utilized for accurate content extraction from web pages. However,
    as of this book’s writing, it is prohibitively expensive to do so, given the scale
    of the dataset.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs也可以用来从网页中准确提取内容。然而，截至本书编写时，考虑到数据集的规模，这样做成本过高。
- en: 'Once text is extracted, the documents are passed through a series of data filtering
    steps. First, rudimentary filtering steps based on heuristics are applied. While
    the details differ across datasets, here are some of the steps typically performed:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提取文本，文档就会通过一系列数据过滤步骤。首先，应用基于启发式的基本过滤步骤。虽然不同数据集的细节不同，但以下是一些通常执行的步骤：
- en: Boilerplate removal
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 模板文本移除
- en: Only lines that end with punctuation, like the period, exclamation point, and
    question mark are retained. This ensures that menu text from websites is removed.
    Only lines with greater than a particular threshold of words and documents with
    greater than a particular threshold of sentences are retained. The latter helps
    in modeling long sequences, which is an important capability for language models
    to have. Documents containing “lorem ipsum…” and other boilerplate text are filtered
    out.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 只有以标点符号结束的行，如句号、感叹号和问号，才会被保留。这确保了来自网站的菜单文本被移除。只有包含超过特定阈值的单词的行和包含超过特定阈值的句子的文档会被保留。后者有助于建模长序列，这对于语言模型来说是一个重要的能力。包含“lorem
    ipsum…”和其他模板文本的文档会被过滤掉。
- en: Non-English text removal
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 非英语文本移除
- en: Libraries like langdetect, langid, fasttext, and pycld2 are used to detect the
    language of the text. For example, C4 retains text that has > 0.99 probability
    of English as judged by langdetect. Note that these libraries can also be used
    to remove boilerplate and web page artifacts since they give a lower probability
    of English to those texts.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于langdetect、langid、fasttext和pycld2这样的库被用来检测文本的语言。例如，C4保留langdetect判断英语概率大于0.99的文本。请注意，这些库也可以用来移除模板文本和网页碎片，因为它们给这些文本的英语概率较低。
- en: Search engine optimization (SEO) text/spam removal
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎优化（SEO）文本/垃圾邮件移除
- en: Documents with a lot of repeated character sequences are removed. Documents
    with a low proportion of closed class words are removed. Closed class words in
    English are function words like “of,” “at,” “the,” and “is.” If a page is engaged
    in keyword stuffing and other SEO tricks, then they would have a lower closed
    class words ratio.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 移除包含大量重复字符序列的文档。移除低比例封闭类词汇的文档。英语中的封闭类词汇是功能词，如“of”，“at”，“the”和“is”。如果一个页面正在进行关键词堆砌和其他SEO技巧，那么它们的封闭类词汇比例会较低。
- en: Pornographic/abusive text removal
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 恶俗/侮辱性文本移除
- en: Documents containing any words from keyword lists like the [“List of Dirty,
    Naughty, Obscene or Otherwise Bad Words”](https://oreil.ly/w3u_r) are removed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 移除包含来自像[“脏话、下流、淫秽或其他不良词汇列表”](https://oreil.ly/w3u_r)等关键词列表中任何单词的文档。
- en: Tools like langdetect and langid are helpful for speedy determination of the
    language in which the text is written at scale, but how do they deal with code-switched
    text (text in multiple languages, where English is often interspersed with a local
    language)?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于langdetect和langid这样的工具对于大规模快速确定文本所使用的语言很有帮助，但它们如何处理代码切换文本（包含多种语言，其中英语通常与本地语言交织）呢？
- en: 'You can try it! Here is an example for Taglish (Tagalog + English, which is
    a common mode of communication in the Philippines). In your notebook, run the
    following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以试试！以下是一个关于Taglish（菲律宾常见的交流模式，即他加禄语+英语）的例子。在你的笔记本中运行以下代码：
- en: '[PRE3]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Output:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE4]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Output:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The second paragraph would get included in the C4 dataset, as per its filtering
    criteria (probability of English should be greater than .99). Therefore, even
    datasets that claim to be English-only routinely contain text in other languages,
    leading to surprising multilingual behavior during inference. Ever wondered why
    some monolingual models seem to perform well at machine translation? This is a
    major reason.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 根据其过滤标准（英语的概率应大于.99），第二段将被包含在C4数据集中。因此，即使声称是纯英语的数据集也经常包含其他语言的文本，导致推理过程中出现令人惊讶的多语言行为。你是否曾想过为什么一些单语模型在机器翻译方面似乎表现良好？这是一个主要原因。
- en: 'The way langdetect is implemented makes it poor at identifying language when
    short sequences are provided. For example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: langdetect的实现方式使其在提供短序列时识别语言的能力较差。例如：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: returns
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 返回
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: sk refers to Slovak here.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: sk在这里指的是斯洛伐克语。
- en: Selecting Quality Documents
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择优质文档
- en: Not all data is created equal. Text from a high school physics textbook is considered
    higher quality compared to promotional text about a footwear brand. There are
    several ways we can operationalize the notion of quality and separate high-quality
    from low-quality data. In this section we will highlight a few such ways.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有数据都是平等的。与关于鞋类品牌的促销性文本相比，高中物理教科书的文本被认为是更高品质的。我们有几种方法可以将质量概念具体化，并将高质量数据与低质量数据区分开来。在本节中，我们将突出介绍几种这样的方法。
- en: Token-distribution K-L divergence
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标记分布K-L散度
- en: In this method, documents with a token distribution that deviates too much from
    a reference token distribution are removed. In effect, this removes documents
    that have a lot of outlier tokens. This is calculated by using the [Kullback-Liebler
    (K-L) divergence](https://oreil.ly/gd5GH).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，那些与参考标记分布差异过大的文档会被移除。实际上，这移除了包含大量异常标记的文档。这是通过使用[库尔巴克-利布勒（K-L）散度](https://oreil.ly/gd5GH)来计算的。
- en: Classifier-based approaches
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于分类器的方法
- en: We can also build a classifier for identifying high-quality data. A simple way
    to build a quality-based classifier is to have examples for the positive class
    come from high-quality data sources like Wikipedia, and examples for the negative
    class to be drawn from random documents in the Common Crawl data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以构建一个用于识别高质量数据的分类器。构建基于质量分类器的一个简单方法是将正类的示例来自像维基百科这样的高质量数据源，而负类的示例则来自Common
    Crawl数据中的随机文档。
- en: Meta employed a variety of classifier models for high-quality data extraction
    for its [Llama 3 model](https://oreil.ly/O-CKF). One of them was a [fasttext classification
    model](https://oreil.ly/EWic6) trained to identify if a text is likely to be referenced
    by Wikipedia. Meta also trained a classifier whose training data was generated
    by Llama 2 by providing it with cleaned web documents and quality requirements
    and asking it to determine if the quality requirements are met. To extract code
    and text containing reasoning steps, Meta built classifiers that can identify
    them.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Meta为其[Llama 3模型](https://oreil.ly/O-CKF)的高质量数据提取使用了多种分类器模型。其中之一是一个[fasttext分类模型](https://oreil.ly/EWic6)，用于识别文本是否可能被维基百科引用。Meta还训练了一个分类器，其训练数据由Llama
    2生成，通过向其提供清洗过的网络文档和质量要求，并要求其判断是否满足质量要求。为了提取包含推理步骤的代码和文本，Meta构建了能够识别它们的分类器。
- en: '[Figure 2-4](#classifier-filtering) shows how a classifier can be built to
    discriminate between high-quality and low-quality data.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2-4](#classifier-filtering)展示了如何构建一个分类器来区分高质量和低质量数据。'
- en: '![classifier-filtering](assets/dllm_0204.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![分类器过滤](assets/dllm_0204.png)'
- en: Figure 2-4\. Classifier-based quality filtering
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 基于分类器的质量过滤
- en: Perplexity for quality selection
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 质量选择的困惑度
- en: '[Perplexity](https://oreil.ly/OfycZ), an intrinsic evaluation measure for language
    models, has been used for document filtering in the context of preparing pre-training
    datasets, notably by the creators of [CCNet](https://oreil.ly/VF98y). Perplexity
    measures how well a model can predict a given text; the lower the perplexity,
    the better the model.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[困惑度](https://oreil.ly/OfycZ)，作为语言模型的一个内在评估指标，在准备预训练数据集的上下文中用于文档过滤，特别是由[CCNet](https://oreil.ly/VF98y)的创建者所使用。困惑度衡量模型预测给定文本的能力；困惑度越低，模型越好。'
- en: Just like the classifier approach, we select documents from data sources that
    we deem high quality (like Wikipedia) as the positive class. We then train a 5-gram
    language model using [KenLM](https://oreil.ly/EU5r3) (a library facilitating training
    of n-gram language models) over it. Next, we take the dataset we want to filter
    and calculate the perplexity of each paragraph in it over the trained language
    model. The lower the perplexity, the more similar it is to the positive class.
    We can then discard documents with high perplexity.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 就像分类器方法一样，我们从我们认为高质量的数据源（如维基百科）中选择文档作为正类。然后，我们使用[KenLM](https://oreil.ly/EU5r3)（一个便于训练n-gram语言模型的库）在所选数据上训练一个5-gram语言模型。接下来，我们取我们想要过滤的数据集，并计算其中每个段落相对于训练语言模型的困惑度。困惑度越低，它与正类越相似。然后我们可以丢弃困惑度高的文档。
- en: Low perplexity may not always be a good thing, however. Short, repetitive text
    can have low perplexity. Note that writing style gets factored into perplexity.
    If the reference language model is trained over Wikipedia, then documents written
    in an informal style may receive higher perplexity scores. Therefore, it would
    be beneficial to have a more involved filtering strategy.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 低困惑度不一定总是好事。简短、重复的文本可能具有低困惑度。请注意，写作风格被纳入困惑度计算。如果参考语言模型是在维基百科上训练的，那么非正式风格的文档可能会获得更高的困惑度分数。因此，拥有更复杂的过滤策略将是有益的。
- en: To resolve this, the creators of [BERTIN](https://oreil.ly/uI9eV) introduced
    the concept of perplexity sampling. In perplexity sampling, instead of just filtering
    out low-perplexity text, it uses a sampling strategy that oversamples from the
    middle part of the perplexity probability distribution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，[BERTIN](https://oreil.ly/uI9eV)的创造者引入了困惑度采样的概念。在困惑度采样中，它不仅过滤掉低困惑度文本，还使用一种采样策略，从困惑度概率分布的中间部分进行过采样。
- en: '[Figure 2-5](#perplexity-sampling) shows how perplexity sampling is achieved
    in practice.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2-5](#perplexity-sampling) 展示了在实际中如何实现困惑度采样。'
- en: '![perplexity-sampling](assets/dllm_0205.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![困惑度采样](assets/dllm_0205.png)'
- en: Figure 2-5\. Perplexity sampling
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5。困惑度采样
- en: 'Let’s explore the perplexity scores assigned by a model trained on Wikipedia
    text. Download this [file](https://oreil.ly/xwYjY). After placing the file in
    your home directory, run this code in a new file:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索由维基百科文本训练的模型分配的困惑度分数。下载此[文件](https://oreil.ly/xwYjY)。将文件放置在您的家目录中后，在新的文件中运行此代码：
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: According to an [analysis of C4](https://oreil.ly/Nzla7), the internet domain
    that contributed the largest proportion of text in the dataset was patents.google.com.
    Over 10% of the text from this domain is in fact machine translated, with patents
    from countries like Japan being translated from Japanese to English. So a significant
    amount of pre-training data is already not generated by humans!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[C4](https://oreil.ly/Nzla7)的分析，向数据集贡献最大比例文本的互联网域名是patents.google.com。实际上，来自这个域的超过10%的文本是机器翻译的，例如，来自日本的专利是从日语翻译成英语的。因此，大量的预训练数据实际上并非由人类生成！
- en: Propelled by LLMs, the internet is slated to see widespread prevalence of AI-generated
    text. Recognizing whether text was written by a human or an LLM is a nontrivial
    task and certainly not feasible at scale. How this will affect future LLM performance
    is an open research question.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动于大型语言模型（LLM），互联网预计将广泛普及由AI生成的文本。识别文本是由人类还是LLM编写的是一个非平凡的任务，并且在大规模上肯定不可行。这将如何影响未来LLM的性能是一个开放的研究问题。
- en: Despite all the data cleaning steps, the resulting dataset is still not going
    to be perfect at this level of scale. For example, Eleuther AI [reported](https://oreil.ly/WEBne)
    that the boilerplate sentence “select the forum that you want to visit from the
    selection below” occurs 180K times in The Pile.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管进行了所有数据清洗步骤，但在这个规模级别上，生成的数据集仍然不会完美。例如，Eleuther AI [报告](https://oreil.ly/WEBne)称，在The
    Pile中，模板句“从下面的选择中选择您想要访问的论坛”出现了18万次。
- en: Deduplication
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 去重
- en: 'So far we have discussed data extraction and cleaning, language identification,
    and quality filtering. Let’s now explore the most contentious step in the pipeline:
    deduplication.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了数据提取和清洗、语言识别和质量过滤。现在让我们探索管道中最具争议的步骤：去重。
- en: We know that web-crawled text is ridden with a lot of duplicates. Duplicates
    form a nontrivial portion of the training dataset, so any decision made about
    them will have a noticeable impact on the ensuing model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道网络爬取的文本中充斥着大量重复内容。重复内容构成了训练数据集的非小部分，因此对它们的任何决策都将对后续模型产生显著影响。
- en: 'How do we define a duplicate? We will make a distinction between three kinds:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何定义重复内容？我们将区分三种类型：
- en: Exact matches
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 完全匹配
- en: Two sequences with the same text are exact-match duplicates. They are the easiest
    to handle.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 两个具有相同文本的序列是精确匹配的重复内容。它们是最容易处理的。
- en: Approximate matches
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 近似匹配
- en: In many cases, there are near-duplicates, where sequences of text are identical
    except for a few characters. Sometimes these sequences are slightly different
    only due to HTML text extraction artifacts and other filtering processes.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，存在近似重复内容，其中文本序列除了少数字符外完全相同。有时这些序列之所以略有不同，仅是因为HTML文本提取伪影和其他过滤过程。
- en: Semantic duplicates
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 语义重复
- en: Duplicates that semantically convey the same content but using different wordings.
    This is usually treated as out of scope.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 语义上传达相同内容但使用不同措辞的重复项。这通常被视为超出范围。
- en: 'Duplicates can also be categorized based on the granularity at which they occur:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 根据它们发生的粒度，重复项也可以进行分类：
- en: Document-level duplicates
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 文档级别的重复
- en: Duplicate documents are removed during the preparation of most pre-training
    datasets. However, in some datasets like The Pile, certain subsets (like Wikipedia)
    are deliberately duplicated, so that they are seen more often by the model.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备大多数预训练数据集的过程中，会移除重复文档。然而，在某些数据集（如 The Pile）中，某些子集（如维基百科）被故意重复，以便模型更频繁地看到它们。
- en: Sequence-level duplicates
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 序列级别的重复
- en: These are lines or sentences in documents that are repeated across multiple
    documents. In some cases they can be massively duplicated, like terms of service
    text, copyright notices, website prefaces, etc.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在多个文档中重复出现的行或句子。在某些情况下，它们可以被大量复制，如服务条款文本、版权声明、网站前言等。
- en: Note
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Dededuplication is a very complex process, typically performed using the MinHash
    algorithm. This writeup by [Cheng Hao](https://oreil.ly/2RO9f) details the deduplication
    process followed in the Big Science and Big Code open source LLM projects.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 去重是一个非常复杂的过程，通常使用 MinHash 算法来执行。[程浩](https://oreil.ly/2RO9f) 的这篇文档详细介绍了在 Big
    Science 和 Big Code 开源 LLM 项目中遵循的去重过程。
- en: 'Deduplicating data has several benefits:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 去重数据有几个好处：
- en: A small subset of the pre-training dataset is usually set aside for validation/test.
    Deduplication can ensure the removal/reduction of overlap between the train and
    test sets, which is essential for an unbiased evaluation. Without sequence-level
    deduplication, there is a high likelihood of overlap of common text sequences
    in the train and test sets.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常会将预训练数据集的一个小部分留出用于验证/测试。去重可以确保训练集和测试集之间重叠的去除/减少，这对于无偏评估至关重要。如果没有序列级别的去重，训练集和测试集中常见文本序列的重叠可能性很高。
- en: Removing duplicate sequences reduces the overall size of the training dataset.
    However, [Lee et al.](https://oreil.ly/k5OwJ) show that the perplexity of a model
    trained on the smaller dataset isn’t affected. Thus, the model can be trained
    for a shorter period yet with the same benefit.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除重复序列可以减少训练数据集的整体大小。然而，[李等人](https://oreil.ly/k5OwJ) 表明，在较小的数据集上训练的模型的困惑度并未受到影响。因此，模型可以在较短的时间内以相同的效益进行训练。
- en: Deduplication can also reduce the tendency of the model to memorize its training
    data. Memorization is closely linked to model overfitting and thwarts the model’s
    ability to generalize. While there are many ways to quantify memorization, we
    will focus on *memorization by generation*, where a model is said to have memorized
    a sequence if it is capable of generating it verbatim. [Lee et al.](https://oreil.ly/xpoz7)
    have shown that models trained on datasets that have been deduplicated at the
    sequence level generate ten times less verbatim training data.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去重还可以减少模型记住其训练数据的倾向。记忆与模型过拟合密切相关，并阻碍了模型泛化的能力。虽然有很多方法可以量化记忆，但我们将关注 *通过生成进行记忆*，即如果一个模型能够逐字逐句地生成一个序列，那么它就被认为已经记住了这个序列。[李等人](https://oreil.ly/xpoz7)
    的研究表明，在去重后的序列级别数据集上训练的模型生成的逐字逐句的训练数据量减少了十倍。
- en: Tip
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: One advantage of using models trained on publicly available datasets is that
    you can search through the datasets to see if the text generated by the model
    exists verbatim in the dataset.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在公共数据集上训练的模型的一个优点是，你可以搜索数据集以查看模型生成的文本是否逐字逐句地存在于数据集中。
- en: '[Figure 2-6](#privacy-attacks-against-llms) demonstrates the flow of a rudimentary
    training-data extraction attack.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-6](#privacy-attacks-against-llms) 展示了基本的训练数据提取攻击流程。'
- en: '![Privacy attacks](assets/dllm_0206.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![隐私攻击](assets/dllm_0206.png)'
- en: Figure 2-6\. Privacy attacks against LLMs
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 对 LLM 的隐私攻击
- en: Removing Personally Identifiable Information
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移除个人可识别信息
- en: While deduplication can reduce the likelihood of the model memorizing training
    data, it is by no means a panacea for the memorization problem. Even information
    that appears only once in the training set could potentially be memorized (and
    leaked). While a lot of content in the training data is innocuous (terms of service
    text) and perhaps even desirable to memorize (factual information, like the capital
    of Canada), memorization of personally identifiable information (PII) is a major
    concern.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然去重可以减少模型记住训练数据的可能性，但它绝不是记忆问题的万能药。即使在训练集中只出现一次的信息也可能被记住（并泄露）。虽然训练数据中的许多内容是无害的（服务条款文本）甚至可能希望记住（如加拿大首都的事实信息），但个人可识别信息（PII）的记忆是一个主要问题。
- en: 'Let us see what PII entails. The formal definition from [Cornell Law](https://oreil.ly/kN3J8)
    is as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看个人身份信息（PII）包含哪些内容。来自[康奈尔法律](https://oreil.ly/kN3J8)的正式定义如下：
- en: Information that can be used to distinguish or trace an individual’s identity,
    either alone or when combined with other personal or identifying information that
    is linked or linkable to a specific individual.
  id: totrans-182
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 可以用来区分或追踪个人身份的信息，无论是单独使用还是与其他个人或识别信息结合使用，这些信息是相关联的或可关联到特定个人的。
- en: Based on this definition, non-PII can become PII when another piece of information
    becomes public, which when combined with the non-PII can be used to uniquely identify
    an individual.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个定义，当另一条信息变得公开时，非个人身份信息（PII）可以变成个人身份信息（PII），当它与非个人身份信息（PII）结合使用时，可以用来唯一识别个人。
- en: 'The legal definition of PII varies by jurisdiction. For example, the [General
    Data Protection Regulation (GDPR)](https://oreil.ly/F2dGL) in Europe says:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 个人身份信息（PII）的法律定义因司法管辖区而异。例如，欧洲的[通用数据保护条例（GDPR）](https://oreil.ly/F2dGL)规定：
- en: Protection should be extended to anything used to directly or indirectly identify
    a person (or data subject). This may be extended to include characteristics that
    describe “physical, physiological, genetic, mental, commercial, cultural, or social
    identity of a person.”
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 应将保护扩展到任何用于直接或间接识别个人（或数据主体）的东西。这可能包括描述“个人的身体、生理、遗传、心理、商业、文化或社会身份”的特征。
- en: 'Most open source models are trained on publicly available datasets. These datasets
    might contain PII, but one might be tempted to say, “Well it is already out in
    the open, so there is no need for privacy protection.” This argument overlooks
    the importance of consent and discoverability controls. For instance, I might
    have shared my PII on my blog, which resides in an obscure corner of the internet
    and is not easily discoverable through search engines, but if it ends up being
    added to a pre-training dataset, it suddenly brings this data into the spotlight,
    without my consent. This concept is called *contextual integrity*: data should
    only be shared in the original context in which it was shared.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数开源模型都是在公开可用的数据集上训练的。这些数据集可能包含个人身份信息（PII），但有人可能会想，“嗯，它已经公开了，所以没有必要保护隐私。”这种论点忽略了同意和可发现性控制的重要性。例如，我可能在博客上分享了个人身份信息，我的博客位于互联网的一个隐蔽角落，不容易通过搜索引擎发现，但如果它最终被添加到预训练数据集中，它突然将数据置于聚光灯下，而没有我的同意。这个概念被称为*情境完整性*：数据只应在共享的原始情境中共享。
- en: So ideally, we would like to *detect* PII in the dataset, and then *remediate*
    it in some fashion, so that the PII is no longer present in the training data
    or at least not memorizable. The presence of *public-figure PII* adds a layer
    of complexity to this problem. We would like our model to be able to accurately
    answer factual questions about public figures, such as providing their birth date.
    The privacy expectations for public figures are lower, showcasing how the values
    of transparency and openness clash with privacy. Determining who is a public figure
    and what level of privacy they are entitled to is a complex socio-technical challenge.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，理想情况下，我们希望能够在数据集中*检测*到个人身份信息（PII），并以某种方式对其进行*修复*，使得个人身份信息（PII）不再存在于训练数据中，或者至少不是可记忆的。*公众人物的个人身份信息*的存在给这个问题增加了复杂性。我们希望我们的模型能够准确回答有关公众人物的客观问题，例如提供他们的出生日期。公众人物的隐私期望较低，展示了透明度和开放性价值观与隐私之间的冲突。确定谁是公众人物以及他们有权获得何种程度的隐私是一个复杂的社会技术挑战。
- en: Data considered private includes names, addresses, credit card data, government
    IDs, medical history and diagnosis data, email IDs, phone numbers, identity and
    affinity groups the person belongs to (religion, race, union membership), geolocation
    data, and so on.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 被认为是私密的包括姓名、地址、信用卡数据、政府身份证明、医疗历史和诊断数据、电子邮件地址、电话号码、个人所属的认同和亲和群体（宗教、种族、工会会员）、地理位置数据等等。
- en: Attacks can be either targeted or untargeted. In an untargeted attack, the attacker
    just generates a large body of text using the model and then runs a membership
    inference attack to determine text within it that is most likely to be memorized.
    In a targeted attack, the attacker attempts to recover personal information about
    a particular individual or a group of individuals. Targeted attacks are more difficult
    to execute, because while language models are good at memorization, they are bad
    at *association*, for instance, identifying that an email ID belongs to a specific
    person.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击可以是针对性的也可以是非针对性的。在非针对性攻击中，攻击者只是使用模型生成大量文本，然后运行成员推理攻击，以确定其中最有可能被记住的文本。在针对性攻击中，攻击者试图恢复特定个人或一组个人的个人信息。针对性攻击更难执行，因为虽然语言模型擅长记忆，但它们在
    *关联* 方面表现不佳，例如，识别一个电子邮件 ID 属于特定个人。
- en: Most pre-training datasets have undergone little to no PII remediation. The
    Privacy working group (of which I was the co-lead) of the Big Science project
    that trained the BLOOM model developed a pipeline for PII detection and remediation,
    which we will discuss next.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数预训练数据集都经历了很少或没有 PII 补救。训练 BLOOM 模型的 Big Science 项目（我是联合负责人）的隐私工作组开发了一个用于
    PII 检测和补救的流程，我们将在下一节中讨论。
- en: Note
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Language models are also susceptible to training data poisoning attacks. Since
    a large portion of training data is sourced from web-crawled text, bad actors
    have an opportunity to influence the content of the training set. [Tramer er al.](https://oreil.ly/g_A-d)
    have shown that one can poison less than 0.1% of the training set with data whose
    effect is to make it easier for other data in the training set to leak more easily.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型也容易受到训练数据中毒攻击。由于大部分训练数据来源于网络爬取的文本，恶意行为者有机会影响训练集的内容。[Tramer 等人](https://oreil.ly/g_A-d)
    已经表明，可以通过数据中毒的方式影响不到 0.1% 的训练集，这些数据的效果是使得训练集中的其他数据更容易泄露。
- en: As LLMs increasingly get used as search engines, the demand for LLM SEO is cropping
    up. For example, a company could write content on their web sites in a manner
    that makes it more likely to be chosen in a pre-training dataset creation process
    that uses perplexity filtering.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型越来越多地被用作搜索引擎，对 LLM SEO 的需求正在出现。例如，一家公司可以在其网站上以某种方式撰写内容，使其更有可能在采用困惑度过滤的预训练数据集创建过程中被选中。
- en: '[Figure 2-7](#PII-processing-pipeline) shows a typical PII processing pipeline.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-7](#PII-processing-pipeline) 展示了一个典型的 PII 处理流程。'
- en: '![PII Processing Pipeline](assets/dllm_0207.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![PII 处理流程](assets/dllm_0207.png)'
- en: Figure 2-7\. PII processing pipeline
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. PII 处理流程
- en: PII detection
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PII 检测
- en: The task of PII detection is similar to the NLP task of NER, introduced in [Chapter 1](ch01.html#chapter_llm-introduction).
    However, not all named entities constitute PII. For our task we determined the
    PII tags to be PERSON, AGE, NORP (nationality, race, religion, political party
    affiliation, socio-economic class, and union membership), STREET_ADDRESS, CREDIT_CARD,
    GOVT_ID, EMAIL_ADDRESS, USER_ID, and PUBLIC_FIGURE.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: PII 检测的任务类似于第 1 章中介绍的 NLP 任务 NER（命名实体识别）。然而，并非所有命名实体都构成 PII。对于我们的任务，我们确定的 PII
    标签包括：PERSON（人物）、AGE（年龄）、NORP（国籍、种族、宗教、政党隶属、社会经济阶层和工会会员）、STREET_ADDRESS（街道地址）、CREDIT_CARD（信用卡）、GOVT_ID（政府身份证明）、EMAIL_ADDRESS（电子邮件地址）、USER_ID（用户ID）和PUBLIC_FIGURE（公众人物）。
- en: We used the PUBLIC_FIGURE tag to identify information about public figures,
    since we didn’t want to filter them out. We also assigned fictional characters
    this tag.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 PUBLIC_FIGURE 标签来识别关于公众人物的信息，因为我们不想过滤掉这些信息。我们还把虚构人物分配了这个标签。
- en: Some of the structured tags in this list like emails and government IDs can
    be identified using regular expressions. For other tags, we annotated datasets
    that could then be used to train Transformer-based NER-like models. Interestingly,
    we observed a very high degree of inter-annotator disagreement (same example being
    annotated differently by different people) that underscored the cultural nuances
    of the definition of privacy and what constitutes personal information.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中的一些结构化标签，如电子邮件和政府身份证，可以使用正则表达式进行识别。对于其他标签，我们标注了数据集，然后可以使用这些数据集来训练基于Transformer的NER-like模型。有趣的是，我们观察到高度不一致的标注者间差异（不同的人对相同示例的标注不同），这突显了隐私定义的文化细微差别以及构成个人信息的内容。
- en: 'Here is the [regular expression](https://oreil.ly/8YwG9) to detect SSN (US
    Social Security numbers):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是检测SSN（美国社会安全号码）的正则表达式：
- en: '[PRE10]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Note that detection is not the same as validation. Not all nine-digit numbers
    of the form XXX-XX-XXXX are SSNs! Validation is the process of checking if a sequence
    of characters maps to a valid identifier. For example, the Canadian equivalent
    of SSN, the social insurance number (SIN) contains a checksum digit that can be
    used to validate it:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，检测与验证不同。并非所有九位数的XXX-XX-XXXX形式的数字都是SSN！验证是检查字符序列是否映射到有效标识符的过程。例如，SSN的加拿大对应物，社会保险号（SIN）包含一个校验位，可以用来验证它：
- en: '[PRE11]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `is_valid()` function uses the [Luhn checksum algorithm](https://oreil.ly/i34BW)
    to validate if the sequence of digits maps to a valid SIN. The same algorithm
    is also used to validate credit cards. Here is the [regex](https://oreil.ly/6uTq-)
    for detecting credit card numbers:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`is_valid()`函数使用[Luhn校验算法](https://oreil.ly/i34BW)来验证数字序列是否映射到有效的SIN。相同的算法也用于验证信用卡。以下是检测信用卡号码的正则表达式：'
- en: '[PRE12]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The regular expression for detecting email address is as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检测电子邮件地址的正则表达式如下：
- en: '[PRE13]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Removing structured PII data while keeping the number of false positives low
    is hard enough, but detecting and remediating unstructured data is even harder.
    Due to the complexity of this task and the uncertainty about its impact on the
    resulting model performance, we decided to not run the Transformer model–based
    PII pipeline over the ROOTS dataset for training the BLOOM model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在保持假阳性数量低的同时移除结构化PII数据已经足够困难，但检测和修复非结构化数据则更加困难。由于这项任务的复杂性和其对模型性能影响的不可确定性，我们决定不将基于Transformer的PII管道应用于ROOTS数据集以训练BLOOM模型。
- en: PII remediation
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PII修复
- en: Once PII has been detected, it can be remediated. [Figure 2-8](#PII-remediation-options)
    depicts one of the remediation schemes.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦检测到PII，就可以进行修复。[图2-8](#PII-remediation-options)展示了其中一种修复方案。
- en: '![PII Remediation Options](assets/dllm_0208.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![PII修复选项](assets/dllm_0208.png)'
- en: Figure 2-8\. PII remediation options
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-8. PII修复选项
- en: 'Here is a nonexhaustive list of remediation options:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个非详尽的修复选项列表：
- en: Replace with a special token
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 用特殊标记替换
- en: For example, a valid phone number can be replaced by the string `<phone` `number>`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个有效的电话号码可以被替换为字符串`<phone number>`。
- en: Replace with a random token of the same entity type
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 用相同实体类型的随机标记替换
- en: For example, replace the name “Clarietta Richards” with “Natasha Bridges,” or
    any other name.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将名字“Clarietta Richards”替换为“Natasha Bridges”，或任何其他名字。
- en: Replace with a shuffled token
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 用打乱顺序的标记替换
- en: Entities detected across the dataset can be shuffled.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个数据集中检测到的实体可以进行打乱。
- en: Remove entire document/data source
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 删除整个文档/数据源
- en: If the amount of PII detected in a single document or data source is higher
    than a specific threshold, it is probably best to remove it. For example, *pastebin.com*
    is said to contain a lot of inadvertently placed PII and is recommended to be
    not included in training datasets.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单个文档或数据源中检测到的PII数量高于特定阈值，最好将其删除。例如，据说*pastebin.com*包含大量意外放置的PII，并建议不要将其包含在训练数据集中。
- en: Each of these techniques can have a varied effect on the model’s downstream
    performance. How does replacing tokens affect training perplexity? Are downstream
    tasks like NER negatively affected when tuned on the resulting model? How does
    replacement by special tokens compare to replacement with random tokens? This
    is a relatively underexplored topic, and all these questions are still open.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术对模型下游性能的影响可能各不相同。替换标记如何影响训练困惑度？当在生成的模型上调整时，下游任务如NER是否会受到负面影响？特殊标记的替换与随机标记的替换相比如何？这是一个相对未被充分探索的主题，所有这些问题仍然悬而未决。
- en: '[Faker](https://oreil.ly/K4QI_) is an excellent library for facilitating random
    token replacement. It supports random token generation for a variety of PII types
    including names, addresses, credit card numbers, and phone numbers. One danger
    in using random tokens is that the replacement process can alter the demographic
    distribution of the dataset, for example, if the replacement names were all or
    mostly Anglo-Saxon names. Faker has localization support to enable replacement
    with fake data from the same geography/culture. Let’s explore the library in more
    detail:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[Faker](https://oreil.ly/K4QI_)是一个用于促进随机令牌替换的优秀库。它支持为各种PII类型生成随机令牌，包括姓名、地址、信用卡号码和电话号码。使用随机令牌的一个危险是，替换过程可能会改变数据集的人口分布，例如，如果替换的名称都是或主要是盎格鲁-撒克逊名称。Faker支持本地化，可以使用同一地理/文化区域的虚假数据替换。让我们更详细地探索这个库：'
- en: '[PRE14]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This code generates 12-digit fake Aadhaar IDs, which are the Indian equivalent
    of Social Security numbers. Note that the generated IDs are all invalid but still
    follow the same format. Similarly:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码生成12位假的Aadhaar ID，这是印度社会保障号码的等价物。请注意，生成的ID都是无效的，但仍然遵循相同的格式。同样：
- en: '[PRE15]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: generates fake but representative addresses for the selected locale.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 为选定的区域生成代表性的虚假地址。
- en: Note
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Removing PII from training datasets is only one of several solutions to prevent
    data leakage from models. One promising technique is [differential privacy](https://oreil.ly/TRbsf),
    which introduces randomness in the inputs or outputs to provide theoretical guarantees
    for privacy preservation. In neural networks, differential privacy is implemented
    using the [DP-SGD](https://oreil.ly/DVQkl) algorithm, which involves gradient
    clipping and noise addition at the end of each update. However, differential privacy
    significantly slows training, negatively affects model performance, and disproportionately
    impacts minority groups in the dataset in terms of model utility degradation.
    Apart from differential privacy, other methods include adversarial training, [model
    unlearning](https://oreil.ly/_AV3V), [retroactive censoring, and “memfree” decoding](https://oreil.ly/5p0z3).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练数据集中移除PII（个人身份信息）是防止模型数据泄露的几种解决方案之一。一种有前途的技术是[差分隐私](https://oreil.ly/TRbsf)，它在输入或输出中引入随机性，以提供隐私保护的理论保证。在神经网络中，差分隐私通过[DP-SGD](https://oreil.ly/DVQkl)算法实现，该算法涉及在每个更新结束时进行梯度裁剪和噪声添加。然而，差分隐私会显著减慢训练速度，对模型性能产生负面影响，并使数据集中少数群体的模型效用退化不成比例。除了差分隐私之外，其他方法还包括对抗训练、[模型反学习](https://oreil.ly/_AV3V)、[事后审查和“memfree”解码](https://oreil.ly/5p0z3)。
- en: Training Set Decontamination
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练集去污
- en: Training set decontamination is a crucial data preprocessing step that helps
    improve LLM evaluations. A pre-training dataset is said to be contaminated if
    it contains data from the benchmark test sets used to evaluate its performance.
    Contamination can happen if the test datasets were constructed from web text,
    or if the dataset was uploaded on the web after creation. There are two types
    of contamination:^([1](ch02.html#id625))
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集去污是数据预处理的关键步骤，有助于提高LLM评估。如果一个预训练数据集包含用于评估其性能的基准测试集的数据，则称其为受污染。污染可能发生在测试数据集由网络文本构建，或者数据集在创建后上传到网络的情况下。有两种类型的污染：^([1](ch02.html#id625))
- en: Input and label contamination
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 输入和标签污染
- en: In this setting, both the questions (inputs) and answers (target labels) exist
    in the pre-training dataset.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置中，问题和答案（目标标签）都存在于预训练数据集中。
- en: Input contamination
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 输入污染
- en: In this setting, only the inputs are present in the pre-training dataset but
    not the target labels. We will describe the effects of input contamination and
    how we can leverage it for positive use in [Chapter 7](ch07.html#ch07).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置中，只有输入存在于预训练数据集中，但没有目标标签。我们将描述输入污染的影响以及我们如何在[第7章](ch07.html#ch07)中利用它进行积极的应用。
- en: '[OpenAI](https://oreil.ly/d7pHK) addressed training set contamination in GPT-3
    by finding 13-gram overlaps between text in the test/validation set and the train
    set, and removing 200 characters before and after the matched texts. The n-gram
    matching approach is the most commonly used method for decontamination.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenAI](https://oreil.ly/d7pHK)通过在测试/验证集文本和训练集之间找到13-gram重叠，并在匹配文本前后删除200个字符来解决GPT-3中的训练集污染问题。n-gram匹配方法是去污中最常用的方法。'
- en: However, [Yang et al.](https://oreil.ly/JjtHS) note that contamination can also
    happen if a rephrased or translation of the benchmark data is present in the training
    dataset. This makes data contamination very challenging to detect and remove.
    Most benchmark results continue to be overstated due to this problem.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，[Yang 等人](https://oreil.ly/JjtHS) 指出，如果基准数据的改写或翻译出现在训练数据集中，也可能发生污染。这使得数据污染的检测和去除变得非常困难。由于这个问题，大多数基准结果仍然被高估。
- en: Data Mixtures
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据混合
- en: Pre-training datasets contain data from a wide variety of domains. The final
    dataset is prepared such that these domains are represented in optimal proportions.
    For example, Wikipedia, academic texts, and smaller subsets were [upsampled](https://oreil.ly/hpHdw)
    by up to three times in The Pile dataset. More involved techniques like [DoReMi](https://oreil.ly/5z9u1)
    and [RegMix](https://oreil.ly/VWyzt) are also used to calculate the right data
    mixture. Meta noted that for [Llama 3](https://oreil.ly/fMOrb), it empirically
    arrived at a data mixture where 50% of the tokens are about general knowledge,
    25% are about math and reasoning, 17% represent code, and the remaining are non-English
    tokens.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练数据集包含来自广泛领域的数据。最终数据集的制备确保这些领域以最佳比例表示。例如，在 The Pile 数据集中，维基百科、学术文本和较小的子集被
    [upsampled](https://oreil.ly/hpHdw) 至最多三倍。还使用了 [DoReMi](https://oreil.ly/5z9u1)
    和 [RegMix](https://oreil.ly/VWyzt) 等更复杂的技巧来计算正确的数据混合。Meta 指出，对于 [Llama 3](https://oreil.ly/fMOrb)，它经验性地得出了一种数据混合，其中
    50% 的标记关于一般知识，25% 关于数学和推理，17% 代表代码，其余的是非英语标记。
- en: Note
  id: totrans-242
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Many pre-training datasets these days include code, even if the model is not
    intended for generating code. [Aryabumi et al.](https://oreil.ly/Vm0lH) have shown
    that including code in pre-training data significantly improves performance on
    downstream tasks that do not involve generating code.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 许多预训练数据集现在都包含代码，即使模型并非旨在生成代码。[Aryabumi 等人](https://oreil.ly/Vm0lH) 已经表明，在预训练数据中包含代码可以显著提高不涉及生成代码的下游任务的表现。
- en: Now that we have discussed all the important data collection and preprocessing
    steps for preparing a pre-training dataset, let’s see how individual datasets
    differ in terms of the preprocessing steps they have undergone.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了准备预训练数据集所需的所有重要数据收集和预处理步骤，让我们看看各个数据集在预处理步骤上的差异。
- en: Tip
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: '[DataTrove](https://oreil.ly/lDFm2) by Hugging Face is a full-fledged pre-training
    dataset preprocessing pipeline code repository. You can go through the repo to
    understand how the concepts introduced in the chapter are implemented at scale.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 的 [DataTrove](https://oreil.ly/lDFm2) 是一个完整的预训练数据集预处理流程代码仓库。您可以查看该仓库以了解本章中介绍的概念是如何大规模实现的。
- en: '[Table 2-2](#table2-pretraining-datasets) provides a list of the popular pre-training
    datasets and the kind of preprocessing they went through.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2-2](#table2-pretraining-datasets) 提供了流行预训练数据集及其所经历的预处理类型列表。'
- en: Table 2-2\. Pretraining datasets and their preprocessing pipeline
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-2\. 预训练数据集及其预处理流程
- en: '| Name | Extraction and cleaning | Quality filtering | Deduplication | Language
    identification | Models trained with this dataset |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 提取和清洗 | 质量过滤 | 去重 | 语言识别 | 使用此数据集训练的模型 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| C4 | Remove pages containing word in blocklist, remove code, remove short
    lines and pages | - | Deduplication of 3-sentence spans | langdetect | T5, FLAN-T5,
    UL2, Llama |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| C4 | 移除包含黑名单中单词的页面，移除代码，移除短行和页面 | - | 3 句跨度去重 | langdetect | T5, FLAN-T5,
    UL2, Llama |'
- en: '| The Pile | justext library for text extraction | fasttext classifier | Document
    level, with MinHashLSH | pycld2 | GPT-NeoX, GPT-J, Cerebras-GPT, StableLM, Pythia
    |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| The Pile | justext 库用于文本提取 | fasttext 分类器 | 文档级，使用 MinHashLSH | pycld2 |
    GPT-NeoX, GPT-J, Cerebras-GPT, StableLM, Pythia |'
- en: '| CCNet | - | Perplexity filtering | Paragraph-level deduplication | fasttext
    |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| CCNet | - | 混淆度过滤 | 段落级去重 | fasttext |  |'
- en: '| RedPajama | CCNet pipeline | Classifier distinguishing between Wikipedia
    text and random C4 text | Paragraph-level deduplication (for Common Crawl) | fasttext
    | Red Pajama-INCITE, MPT |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| RedPajama | CCNet 流程 | 区分维基百科文本和随机 C4 文本的分类器 | 段落级去重（针对 Common Crawl） | fasttext
    | Red Pajama-INCITE, MPT |'
- en: '| CleanPajama | Low-length filter, NFC normalization | - | MinHashLSH | - |
    - |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| CleanPajama | 低长度过滤器，NFC 规范化 | - | MinHashLSH | - | - |'
- en: '| RefinedWeb | URL filtering by blocklists, trafilatura library for text extraction,
    repetitive content removal | - | Fuzzy document-level deduplication with MinHash,
    exact sequence-level deduplication | fasttext | Falcon |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 精炼网络 | 通过黑名单进行 URL 过滤，使用 trafilatura 库进行文本提取，重复内容移除 | - | 使用 MinHash 进行模糊文档级去重，使用精确序列级去重
    | fasttext | Falcon |'
- en: '| ROOTS | Removal of documents with low ratio of closed class words, high ratio
    of blocklist words, high ratio of character/word repetition | Perplexity filtering
    | SimHash, Suffix Array | fasttext | BLOOM |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 根 | 移除具有低封闭类词比例、高黑名单词比例、高字符/词重复比例的文档 | 混淆度过滤 | SimHash, 后缀数组 | fasttext |
    BLOOM |'
- en: Effect of Pre-Training Data on Downstream Tasks
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练数据对下游任务的影响
- en: Given a pre-training dataset for an LLM, what assumptions can we make from it
    about downstream performance? It turns out that there is a correlation between
    the model’s performance on a given task or input and the pre-training dataset
    frequency of the task or the salient words in the input, respectively. First observed
    by [Razeghi et al.](https://oreil.ly/cPYej), this phenomenon has been studied
    in detail in McCoy et al.’s [“Embers of Autoregression” paper](https://oreil.ly/_O2NK).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个 LLM 的预训练数据集，我们可以从它那里得出哪些关于下游性能的假设？事实证明，模型在特定任务或输入上的性能与该任务或输入中的显著词在预训练数据集中的频率之间存在相关性。这一现象首先由
    [Razeghi 等人](https://oreil.ly/cPYej)观察到，并在 McCoy 等人的论文“自回归的余烬”（“Embers of Autoregression”）中进行了详细研究。
- en: McCoy et al. show that language models perform better at tasks that are more
    frequently represented in the training dataset than ones that are less frequently
    represented. For example, language models are better at base 10 addition than
    base 9 addition. They are also better at sorting by alphabetical order than they
    are at sorting by reverse alphabetical order.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: McCoy 等人表明，语言模型在训练数据集中出现频率更高的任务上的表现优于出现频率较低的任务。例如，语言模型在十进制加法上的表现优于九进制加法。它们在按字母顺序排序上的表现也优于按逆字母顺序排序。
- en: Similarly, McCoy et al. also show that for a given task, models perform relatively
    better when the output is text with high frequency in the pre-training dataset
    as opposed to when the text is lower frequency. This phenomenon is also observed
    for inputs; models do relatively better with higher-frequency inputs compared
    to lower-frequency inputs.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，McCoy 等人也表明，对于给定的任务，当输出是预训练数据集中高频文本时，模型的表现相对较好，而不是当文本是低频时。这种现象也适用于输入；与低频输入相比，模型在高频输入上的表现相对较好。
- en: 'As an example, consider the sentence: “record a be that miles, yes, hour, per
    fifty clocked he.” We ask the LLM to reverse the words in the sentence, which
    would lead to “He clocked fifty per hour, yes, miles, that be a record,” a rather
    low-probability sequence, due to its odd linguistic construction.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下句子：“record a be that miles, yes, hour, per fifty clocked he。”我们要求 LLM
    反转句子中的单词，这将导致“他每小时五十英里，是的，英里，那是一个记录，”这是一个相当低概率的序列，因为它有奇怪的语构。
- en: 'As of the book’s writing, GPT-4o returns the wrong answer: “He clocked fifty
    miles per hour that be a record,” but you can notice that it performs relatively
    better when the output sequence is higher probability.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书撰写时，GPT-4o 返回了错误的答案：“他以每小时五十英里的速度行驶，这是一个记录，”但你可能会注意到，当输出序列的概率更高时，它的表现相对较好。
- en: Bias and Fairness Issues in Pre-Training Datasets
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预训练数据集中的偏差和公平性问题
- en: A multitude of ethical questions arise during the productization of large language
    models. The existence of significant bias and fairness issues in these models
    often leads to a no-ship condition for a large number of use cases. In this section
    we will go through some bias and fairness issues specifically related to the collection
    and filtering of pre-training data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型语言模型的产品化过程中，会出现许多伦理问题。这些模型中存在的重大偏差和公平性问题通常会导致大量用例无法发货。在本节中，我们将探讨一些与预训练数据的收集和过滤特别相关的偏差和公平性问题。
- en: The scale of data that LLMs are fed with means that they are not just constructing
    models of language but also of the world we inhabit. This gives rise to the question
    of whether we want to model the world the way it is or the way we would like it
    to be. The internet is filled with hate, violence, and abusive language and is
    often used as an outlet for humanity’s worst impulses. The text in it implicitly
    encodes long-existing biases against groups of people. For example, in The Pile,
    an [analysis](https://oreil.ly/hu3-b) of word co-occurrence statistics shows the
    word “radical” co-occurs with the word “Muslim” substantially more than it does
    for other religions.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs所接受的数据规模意味着它们不仅仅是构建语言模型，也在构建我们所处的世界模型。这引发了一个问题：我们是否想要按照世界的本来面目来建模，还是按照我们希望它成为的样子来建模。互联网充满了仇恨、暴力和侮辱性语言，经常被用作人类最恶劣冲动的一种出口。其中的文本隐含地编码了对某些人群长期存在的偏见。例如，在《Pile》中，对词共现统计的分析[显示](https://oreil.ly/hu3-b)，“radical”一词与“穆斯林”一词的共现频率显著高于与其他宗教的共现频率。
- en: 'The phenomenon of *bias amplification* makes these problems all the more critical.
    It has been shown that large language models [amplify the biases](https://oreil.ly/x-ba9)
    that are encoded in their pre-training data: they make biased predictions against
    groups of people at higher rates than what the training data statistics would
    suggest.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*偏差放大*的现象使这些问题变得更加关键。研究表明，大型语言模型[放大了](https://oreil.ly/x-ba9)其预训练数据中编码的偏差：它们以比训练数据统计所暗示的更高的比率对某些人群做出有偏见的预测。'
- en: So, can we “fix” our training data such that we can model a world that encodes
    our values and principles that downstream applications will inherit? There is
    substantial debate in the research community about this. Opponents argue it is
    hard to identify and fix all societal biases encoded in the data since there are
    so many dimensions of bias that intersect in complex ways. Values are not universal,
    and model providers would like to be value-neutral to cater to all sections of
    society.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们能否“修复”我们的训练数据，以便我们可以构建一个编码了我们的价值观和原则的世界模型，下游应用将继承这些价值观和原则？在研究界对此有大量的争议。反对者认为，由于存在许多相互交织的复杂偏见维度，很难识别和修复数据中编码的所有社会偏见。价值观并非普遍适用，模型提供者希望保持价值中立，以迎合社会的各个部分。
- en: However, as Anna Rogers describes in her [paper](https://oreil.ly/hxU_-), this
    question is already moot. Data curation is already happening, whether we like
    it or not, and the values and interests of model providers are already being encoded
    into the models. For example, only a small proportion of available data is selected
    to be part of the pre-training set. This selection process is not value-neutral,
    even if one might not explicitly think in terms of it.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如安娜·罗杰斯在她的[论文](https://oreil.ly/hxU_-)中所描述的，这个问题已经变得无关紧要。数据整理已经在进行中，无论我们是否喜欢，模型提供者的价值观和利益已经被编码到模型中。例如，只有一小部分可用数据被选中成为预训练集的一部分。这个选择过程并非价值中立，即使一个人可能没有明确地从这个角度去思考。
- en: Wikipedia is one of the more popular datasets used in training LLMs. While it
    might be a no-brainer to include Wikipedia in a pre-training dataset, let’s explore
    the implications. Wikipedia is edited by volunteers, a very large proportion of
    them being men. Since the determination of whether a topic is reputable enough
    to deserve a Wikipedia page rests with the editors who are largely made up of
    men, we see disparities like obscure male football players from lower-level leagues
    getting their own pages while a disproportionate number of biography articles
    about women are slated for deletion.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科是用于训练LLMs的更受欢迎的数据集之一。虽然将维基百科包含在预训练数据集中可能是不言而喻的，但让我们探讨其影响。维基百科由志愿者编辑，其中很大一部分是男性。由于是否一个主题足够有信誉值得拥有维基百科页面取决于主要由男性组成的编辑，我们看到一些来自低级别联赛的男性足球运动员有自己的页面，而大量关于女性的传记文章则被计划删除。
- en: Similarly, the highly influential WebText dataset is sourced from Reddit outbound
    links. Reddit is a predominantly male site, with [74% of users](https://oreil.ly/i2RkB)
    being men. Naturally, links posted on Reddit are more likely to be catered to
    male interests.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，高度影响力的WebText数据集来源于Reddit的外链。Reddit是一个以男性为主的网站，[74%的用户](https://oreil.ly/i2RkB)是男性。自然地，Reddit上发布的链接更有可能迎合男性的兴趣。
- en: Bias can also be introduced during the data filtering stages. Earlier, we noted
    that keyword lists are often used to filter out pornographic material and abusive
    text. However, using a naive keyword list is a lazy approach that not only has
    problems with effectiveness (false negatives) but also inadvertently [results
    in](https://oreil.ly/XWBjV) filtering out positive text written by or about minority
    communities, as well as text written in dialects like African American English
    and Hispanic-aligned English. The fact that words in English have multiple senses
    has resulted in certain documents about breastfeeding being filtered out of the
    C4 dataset.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据过滤阶段也可能引入偏差。之前我们提到，关键词列表常用于过滤掉色情材料和侮辱性文本。然而，使用简单的关键词列表是一种懒惰的方法，不仅存在有效性问题（假阴性），而且无意中[导致](https://oreil.ly/XWBjV)过滤掉由少数族裔社区撰写或关于少数族裔社区的积极文本，以及使用像非裔美国英语和西班牙语系英语这样的方言撰写的文本。英语单词具有多种含义的事实导致某些关于母乳喂养的文档被从C4数据集中过滤掉。
- en: Overall, whether a word is hateful, abusive, or toxic depends on the social
    context, the intentions of the reader, and the intended audience. Keyword-based
    methods simply do not capture this nuance. The question of whether it is more
    effective to handle these issues at the pre-training stage or further downstream
    is an open area of research. We will explore techniques that can be employed downstream
    in [Chapter 10](ch10.html#ch10).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，一个词是否仇恨、侮辱或有毒，取决于社会环境、读者的意图以及目标受众。基于关键词的方法根本无法捕捉这种细微差别。关于是否在预训练阶段或更下游处理这些问题更有效，这是一个开放的研究领域。我们将在第10章中探讨可以用于下游的技术。
- en: Note
  id: totrans-274
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The authors of the [Pythia model](https://oreil.ly/r4oAT) experimented by replacing
    masculine pronouns with feminine ones for the last 7% of training tokens and noticed
    a de-biasing impact on downstream tasks.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pythia模型](https://oreil.ly/r4oAT)的作者通过将最后7%的训练标记中的男性代词替换为女性代词进行了实验，并注意到对下游任务的去偏影响。'
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we outlined the key ingredients of a language model: the pre-training
    data, the vocabulary and tokenizer, the language objective, and the model architecture.
    We walked through the steps involved in creating a pre-training dataset in detail,
    including language identification, text extraction and cleaning, quality filtering,
    deduplication, PII removal, and test set decontamination. We also provided a list
    of commonly used pre-training datasets and the steps taken for preprocessing each
    of them. In the next chapter, we will explore the vocabulary and tokenizer of
    the language model: the language we intend the model to learn.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了语言模型的关键组成部分：预训练数据、词汇和分词器、语言目标以及模型架构。我们详细介绍了创建预训练数据集的步骤，包括语言识别、文本提取和清理、质量过滤、去重、PII移除和测试集净化。我们还提供了一份常用预训练数据集列表以及预处理每个数据集的步骤。在下一章中，我们将探讨语言模型的词汇和分词器：我们希望模型学习到的语言。
- en: ^([1](ch02.html#id625-marker)) From Dodge et al., [“A Case Study on the Colossal
    Clean Crawled Corpus”](https://oreil.ly/PwtVp), EMNLP 2021.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.html#id625-marker)) 来自Dodge等人，《“大规模清洁爬取语料库案例研究”》，EMNLP 2021。
