- en: Chapter 15\. Music and Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章。音乐和深度学习
- en: The other chapters in this book are all about processing of images or texts.
    Those chapters represent the balance of media in deep learning research, but that
    is not to say that sound processing isn’t interesting and that we haven’t seen
    some great developments in this area in the last few years. Speech recognition
    and speech synthesis are what made home assistants like Amazon Alexa and Google
    Home a possibility. The old sitcom joke where the phone dials the wrong number
    hasn’t really been current since Siri came out.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书中的其他章节都是关于图像或文本的处理。这些章节代表了深度学习研究中媒体的平衡，但这并不意味着声音处理不是有趣的，我们在过去几年中也看到了一些重大进展。语音识别和语音合成使得像亚马逊Alexa和谷歌Home这样的家庭助手成为可能。自从Siri推出以来，那个老的情景喜剧笑话中电话拨错号码的情节并不是很现实。
- en: It is easy to start experimenting with these systems; there are APIs out there
    that let you get a simple voice app up and running in a few hours. The voice processing,
    however, is done in Amazon, Google, or Apple’s data center, so we can’t really
    count these as deep learning experiments. Building state-of-the-art voice recognition
    systems is hard, although Mozilla’s Deep Speech is making some impressive progress.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 开始尝试这些系统很容易；有一些API可以让你在几个小时内建立一个简单的语音应用程序。然而，语音处理是在亚马逊、谷歌或苹果的数据中心进行的，所以我们不能真的将这些视为深度学习实验。构建最先进的语音识别系统很困难，尽管Mozilla的Deep
    Speech正在取得一些令人印象深刻的进展。
- en: This chapter focuses on music. We’ll start out with training a music classification
    model that can tell us what music we’re listening to. We’ll then use the results
    of this model to index local MP3s, making it possible to find songs similar in
    style. After that we’ll use the Spotify API to create a corpus of public playlists
    that we’ll use to train a music recommender.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章重点是音乐。我们将首先训练一个音乐分类模型，可以告诉我们正在听什么音乐。然后我们将使用这个模型的结果来索引本地MP3，使得可以找到风格相似的歌曲。之后我们将使用Spotify
    API创建一个公共播放列表的语料库，用来训练音乐推荐系统。
- en: 'The notebooks for this chapter are:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的笔记本有：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 15.1 Creating a Training Set for Music Classification
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.1 为音乐分类创建训练集
- en: Problem
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you get and prepare a set of music for classification?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如何获取和准备一组音乐用于分类？
- en: Solution
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Create spectrograms from the test set provided by the University of Victoria
    in Canada.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从加拿大维多利亚大学提供的测试集中创建频谱图。
- en: 'You could try to do this by plugging in that dusty external drive with your
    MP3 collection on it and relying on the tags on those songs. But a lot of those
    tags may be somewhat random or missing, so it’s best to get started with a training
    set from a scientific institution that is nicely labeled:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试通过连接那个带有MP3收藏的尘封外部驱动器，并依赖那些歌曲的标签来做这件事。但很多标签可能有些随机或缺失，所以最好从一个科学机构获得一个有标签的训练集开始：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This should get us a directory, *genres*, with subdirectories containing music
    of different genres:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们创建一个包含不同流派音乐的子目录*genres*：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Those directories contain sound files (*.au*), 100 clips per genre, each 29
    seconds long. We could try to feed the raw sound frames directly into the network
    and maybe an LSTM would pick up something, but there are better ways of preprocessing
    sounds. Sound is really sound waves, but we don’t hear waves. Instead, we hear
    tones of a certain frequency.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些目录包含声音文件（*.au*），每种流派100个片段，每个片段长29秒。我们可以尝试直接将原始声音帧馈送到网络中，也许LSTM会捕捉到一些东西，但有更好的声音预处理方法。声音实际上是声波，但我们听不到波。相反，我们听到一定频率的音调。
- en: 'So a good way to make our network behave more like our hearing works is to
    convert sound into blocks of spectrograms; each sample will be represented by
    a series of audio freqencies and their respective intensities. The `librosa` library
    for Python has some standard functions for this and also provides what’s called
    a *melspectrogram*, a type of spectrogram that is meant to closely emulate how
    human hearing works. So let’s load up the music and convert the fragments to melspectrograms:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们的网络更像我们的听觉工作的一个好方法是将声音转换为频谱图块；每个样本将由一系列音频频率及其相应的强度表示。Python的`librosa`库有一些标准函数可以做到这一点，并且还提供了所谓的*melspectrogram*，一种旨在紧密模拟人类听觉工作方式的频谱图。所以让我们加载音乐并将片段转换为melspectrograms：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s also have a quick look at some of the genres as spectrograms. Since those
    spectrograms are now just matrices, we can treat them as bitmaps. They are really
    quite sparse, so we are going to overexpose them to see more details:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也快速看一下一些流派的频谱图。由于这些频谱图现在只是矩阵，我们可以将它们视为位图。它们实际上非常稀疏，所以我们将过度曝光它们以查看更多细节：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Classical Spectrogram](assets/dlcb_15in01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![古典音乐频谱图](assets/dlcb_15in01.png)'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Metal Spectrogram](assets/dlcb_15in02.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![金属音乐频谱图](assets/dlcb_15in02.png)'
- en: Even though it is hard to say what exactly the pictures mean, there is some
    suggestion that metal has more of a rigid structure than classical music, which
    is maybe not completely unexpected.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管很难说图片到底代表什么意思，但有一些迹象表明金属音乐可能比古典音乐更具有刚性结构，这也许并不完全出乎意料。
- en: Discussion
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: As we’ve seen throughout this book, preprocessing data before letting networks
    do their thing increases our chances of success significantly. When it comes to
    sound processing, `librosa` has functions for almost anything you could wish for,
    from loading sound files and playing them inside notebooks to visualizing them
    and doing any kind of preprocessing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在整本书中看到的那样，在让网络处理数据之前对数据进行预处理会显著增加我们成功的机会。在声音处理方面，`librosa`有几乎任何你想要的功能，从加载声音文件并在笔记本中播放它们到可视化它们和进行任何类型的预处理。
- en: Visually inspecting spectrograms doesn’t tell us much, but it does give us a
    hint that they are different for different genres of music. We’ll see in the next
    recipe whether a network can learn to distinguish between them too.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过视觉检查频谱图并不能告诉我们太多，但它确实给了我们一个暗示，即不同音乐流派的频谱图是不同的。在下一个步骤中，我们将看到网络是否也能学会区分它们。
- en: 15.2 Training a Music Genre Detector
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.2 训练音乐流派检测器
- en: Problem
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you set up and train a deep network to detect music genres?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如何设置和训练一个深度网络来检测音乐流派？
- en: Solution
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use a one-dimensional convolutional network.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一维卷积网络。
- en: We’ve used convolutional networks in this book for image detection (see [Chapter 9](ch09.html#transfer_learning))
    and for text (see [Chapter 7](ch07.html#suggest_emojis)). It might seem that treating
    our spectrograms as images would be the more logical way to proceed, but we are
    actually going to go with a one-dimensional convolutional network. Each frame
    in our spectrogram represents a frame of music. Using a convolutional net to convert
    stretches of time into a more abstract representation makes sense when we try
    to classify genres; reducing the “height” of the frames is less intuitively sensible.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们已经使用卷积网络进行图像检测（参见[第9章](ch09.html#transfer_learning)）和文本（参见[第7章](ch07.html#suggest_emojis)）。处理我们的频谱图像为图像可能是更合乎逻辑的方法，但实际上我们将使用一维卷积网络。我们的频谱图中的每个帧代表音乐的一个帧。当我们尝试对流派进行分类时，使用卷积网络将时间段转换为更抽象的表示是有意义的；减少帧的“高度”在直觉上不太合理。
- en: 'We’ll start by stacking some layers on top of each other. This will reduce
    the size of our input from 128 dimensions wide to 25\. The `GlobalMaxPooling`
    layer will then make this into a 128-float vector:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从顶部堆叠一些层。这将把我们的输入从128维减少到25。`GlobalMaxPooling`层将把这个转换成一个128浮点向量：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This is followed by a few fully connected layers to get to the labels:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 接着是一些全连接层，以获得标签：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Before we feed our data into the model, we’ll split each song into 10 fragments
    of 3 seconds each. We do this to increase the amount of data, since 1,000 songs
    isn’t really that much:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据输入模型之前，我们将每首歌曲分成10个每个3秒的片段。我们这样做是为了增加数据量，因为1000首歌曲并不算太多：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Training this model gives us accuracy of around 60% after 100 epochs, which
    is not bad, but certainly not superhuman. We can improve upon this result by taking
    advantage of the fact that we split each song into 10 fragments and use the information
    across the chunks to get to a result. Majority voting would be one strategy, but
    it turns out that going with whatever chunk the model is most sure of works even
    better. We can do this by splitting the data back into 100 chunks and applying
    `argmax` on each of them. This will get us for each one the index in the entire
    chunk. By applying modulo 10 we get the index into our label set:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在100个epochs后，训练这个模型可以达到大约60%的准确率，这并不差，但肯定不是超人的水平。我们可以通过利用将每首歌曲分成10个片段并使用跨片段的信息来改进结果。多数投票可能是一种策略，但事实证明，选择模型最确定的片段效果更好。我们可以通过将数据重新分成100个片段，并在每个片段上应用`argmax`来实现这一点。这将为每个片段得到整个片段中的索引。通过应用模10，我们可以得到我们标签集中的索引：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This gets us up to 75% accuracy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们达到了75%的准确率。
- en: Discussion
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: With 100 songs for each of our 10 genres, we don’t have a lot of training data.
    Splitting our songs up into 10 chunks of 3 seconds each gets us to somewhere half
    decent, although our model still ends up overfitting a bit.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的10种流派，每种有100首歌曲，我们没有太多的训练数据。将我们的歌曲分成10个每个3秒的块，可以让我们达到一定程度的准确性，尽管我们的模型仍然有点过拟合。
- en: One thing to explore would be to apply some data augmentation techniques. We
    could try adding noise to the music, speeding it up a bit, or slowing it down
    though the spectrogram itself might not really change that much. It would be better
    to get our hands on a larger set of music.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 探索的一个方向是应用一些数据增强技术。我们可以尝试给音乐添加噪音，稍微加快或减慢速度，尽管频谱图本身可能并不会有太大变化。最好是能获取更大量的音乐数据。
- en: 15.3 Visualizing Confusion
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.3 可视化混淆
- en: Problem
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you show the mistakes that the network makes in a clear way?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如何清晰地展示网络所犯的错误？
- en: Solution
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Graphically display a confusion matrix.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以图形方式显示混淆矩阵。
- en: 'A confusion matrix has columns for each of the genres representing the truth
    and rows for the genres the model predicted. The cells contain the counts for
    each (truth, prediction) pair. `sklearn` comes with a handy method to calculate
    it:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的列代表真实的流派，行代表模型预测的流派。单元格包含每个（真实，预测）对的计数。`sklearn`带有一个方便的方法来计算它：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can visualize this a bit more clearly by shading the matrix. Transposing
    the matrix so we can see the confusion per row also makes things a bit easier
    to process:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过给矩阵着色来更清晰地可视化。将矩阵转置，这样我们可以看到每行的混淆，也让处理变得更容易：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Confusion Matrix](assets/dlcb_15in03.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![混淆矩阵](assets/dlcb_15in03.png)'
- en: Discussion
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Confusion matrices are a neat way to display the performance of a network, but
    they also give you an idea of where it goes wrong, which might hint at how to
    improve things. In the example in this recipe we can see that the network does
    very well at distinguishing classical music and metal from other types of music,
    but it does less well at distinguishing rock from country. None of this is unexpected,
    of course.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是展示网络性能的一种巧妙方式，但它也让你了解它出错的地方，这可能暗示着如何改进事情。在这个示例中，我们可以看到网络在区分古典音乐和金属音乐与其他类型音乐时表现得非常好，但在区分摇滚和乡村音乐时表现得不太好。当然，这一切都是意料之中的。
- en: 15.4 Indexing Existing Music
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.4 索引现有音乐
- en: Problem
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to build an index over pieces of music that captures their style.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您想建立一个能捕捉音乐风格的音乐片段索引。
- en: Solution
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Treat the last fully connected layer of the model as an embedding layer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型的最后一个全连接层视为嵌入层。
- en: 'In [Chapter 10](ch10.html#image_search) we built a reverse search engine for
    images by interpreting the last fully connected layer of an image recognition
    network as image embeddings. We can do something similar with music. Let’s start
    by collecting some MP3s—you probably have a collection of them lying around somewhere:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](ch10.html#image_search)中，我们通过将图像识别网络的最后一个全连接层解释为图像嵌入，构建了一个图像的反向搜索引擎。我们可以用音乐做类似的事情。让我们开始收集一些MP3文件——你可能有一些散落在某处的收藏：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then we’ll index them. As before, we extract a melspectrogram. We also fetch
    the MP3 tags:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将对它们进行索引。与以前一样，我们提取一个梅尔频谱图。我们还获取MP3标签：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We want to index every spectrogram of all MP3s—we can do that in one batch
    if we concatenate all of them together:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要索引所有MP3的每个频谱图像-如果我们将它们全部连接在一起，我们可以一次完成：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To get to the vector representation, we’ll construct a model that returns the
    fourth-to-last layer from our previous model and run it over the collected spectra:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得向量表示，我们将构建一个模型，该模型从我们先前模型的倒数第四层返回，并在收集的频谱上运行：
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A simple nearest neighbor model lets us now find similar songs. Given a song,
    we’ll look up for each of its vectors what the other nearest vectors are. The
    very first result we can skip, since it is the vector itself:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的最近邻模型让我们现在可以找到相似的歌曲。给定一首歌曲，我们将查找它的每个向量的其他最近向量是什么。我们可以跳过第一个结果，因为它是向量本身：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Trying this out on a random song seems to work:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在随机歌曲上尝试这个似乎有效：
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Indexing songs using the last fully connected layer of our model works reasonably
    well. In this example it not only finds the original song, but also a slightly
    different version of that song that happens to be in the MP3 collection. Whether
    the other two songs returned are really similar in style is a judgment call, but
    they are not completely different.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们模型的最后一个全连接层对歌曲进行索引工作得相当不错。在这个例子中，它不仅找到了原始歌曲，还找到了一个略有不同版本的歌曲，恰好在MP3收藏中。其他两首返回的歌曲是否在风格上真的相似是一个判断问题，但它们并不完全不同。
- en: The code here could be used as a basis to build something like Shazam; record
    a bit of music, run that through our vectorizer, and see which indexed song it
    matches most closely. Shazam’s algorithm is different and predates the popularity
    of deep learning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的代码可以用作构建类似Shazam的基础；录制一小段音乐，通过我们的向量化器运行，看看它与哪首索引歌曲最接近。Shazam的算法是不同的，并且早于深度学习的流行。
- en: By taking a short bit of music and finding other music that sounds similar,
    we have the basics for a music recommender system. The fact that it only works
    for music we already have access to does limit its usefulness a bit, though. In
    the rest of this chapter we’ll look at another approach to building a music recommender
    system.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过找到听起来相似的其他音乐来获取音乐推荐系统的基础。然而，它只适用于我们已经可以访问的音乐，这在一定程度上限制了其实用性。在本章的其余部分，我们将看看另一种构建音乐推荐系统的方法。
- en: 15.5 Setting Up Spotify API Access
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.5 设置Spotify API访问权限
- en: Problem
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How can you get access to a large set of music data?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如何获得大量音乐数据的访问权限？
- en: Solution
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use the Spotify API.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Spotify API。
- en: The system we created in the previous recipe is a sort of music recommender,
    but it only recommends songs it has already seen. By harvesting playlists and
    songs from the Spotify API we can build up a much larger training set. Let’s start
    by registering a new app at Spotify. Head over to [*https://beta.developer.spotify.com/dashboard/applications*](https://beta.developer.spotify.com/dashboard/applications),
    and create a new application.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一个配方中创建的系统是一种音乐推荐器，但它只推荐它已经看过的歌曲。通过从Spotify API中收集播放列表和歌曲，我们可以建立一个更大的训练集。让我们从Spotify注册一个新应用程序开始。转到[*https://beta.developer.spotify.com/dashboard/applications*](https://beta.developer.spotify.com/dashboard/applications)，创建一个新应用程序。
- en: Note
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The URL mentioned here starts with beta. By the time you are reading this, the
    new application interface on Spotify might have come out of beta and the URL might
    have changed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提到的URL以beta开头。当您阅读此内容时，Spotify上的新应用程序界面可能已经退出beta测试，URL可能已更改。
- en: You’ll need to log in first and possibly register before that. Once you’ve created
    an app, go to the app page and note the Client ID and the Client Secret. Since
    the secret is, well, secret, you’ll need to press the button to show it.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要先登录，可能需要注册。创建应用程序后，转到应用程序页面并记下客户端ID和客户端密钥。由于密钥是秘密的，您需要按下按钮显示它。
- en: 'Enter your various details in three constants:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在三个常量中输入您的各种细节：
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can now access the Spotify API:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以访问Spotify API：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The first time you run this code, the API will ask you to enter a URL into a
    browser. This works somewhat awkwardly when run from a notebook; the URL to redirect
    to will be printed in the window where your notebook server runs. However, if
    you press the Stop button in the browser, it will show you the URL to redirect
    to. Click on that URL. It will redirect to something starting with *http://127.0.0.1*
    that won’t resolve, but that doesn’t matter. Enter that URL back into the box
    that now shows up in the notebook page and press Enter. This should authorize
    you.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次运行此代码时，API将要求您在浏览器中输入一个URL。当从笔记本运行时，这种方式有些笨拙；要重定向的URL将打印在笔记本服务器运行的窗口中。但是，如果您在浏览器中按下停止按钮，它将向您显示要重定向的URL。单击该URL。它将重定向到以*http://127.0.0.1*开头的内容，这不会解析，但这并不重要。将该URL输入回现在在笔记本页面上显示的框中，然后按Enter。这应该授权您。
- en: You only need to do this once; the token gets stored locally in a file named
    *.cache-<username>*. If something goes wrong, delete this file and try again.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需要执行一次此操作；令牌将存储在名为*.cache-<username>*的文件中。如果出现问题，请删除此文件并重试。
- en: Discussion
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: The Spotify API is a remarkably great source for musical data. The API is accessible
    through a nicely designed REST API with well-defined endpoints that return self-describing
    JSON documents.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Spotify API是一个非常好的音乐数据来源。该API通过一个设计精良的REST API可访问，具有定义良好的端点，返回自描述的JSON文档。
- en: The [API documentation](https://developer.spotify.com/web-api/) has information
    on how to access songs, artists, and playlists, including rich metainformation
    like album covers.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[API文档](https://developer.spotify.com/web-api/)提供了有关如何访问歌曲、艺术家和播放列表的信息，包括丰富的元信息，如专辑封面。'
- en: 15.6 Collecting Playlists and Songs from Spotify
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.6 从Spotify收集播放列表和歌曲
- en: Problem
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You need to create a training set for your music recommender.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要为您的音乐推荐器创建一个训练集。
- en: Solution
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Search for common words to find playlists and fetch the songs that belong to
    them.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索常见词以找到播放列表，并获取属于它们的歌曲。
- en: 'As rich as the Spotify API is, there is no easy way to get a set of public
    playlists. You can search for them by word, though. In this recipe we’ll use that
    as a way to get access to a nice body of playlists. Let’s start by implementing
    a function to fetch all playlists matching a search term. The only complication
    in the code is due to the fact that we need to recover from timeouts and other
    errors:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Spotify API非常丰富，但没有简单的方法可以获取一组公共播放列表。但您可以通过单词搜索它们。在这个配方中，我们将使用这种方法来获取一组不错的播放列表。让我们首先实现一个函数来获取与搜索词匹配的所有播放列表。代码中唯一的复杂之处在于我们需要从超时和其他错误中恢复：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We’ll start with one word, “a,” and fetch 5,000 playlists that contain that
    word. We’ll keep track of all those playlists, but also count the words that occur
    in the titles of those playlists. That way when we’re done with the word “a,”
    we can do the same with the word that occurs most. We can keep doing this until
    we have enough playlists:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个单词“a”开始，获取包含该单词的5,000个播放列表。我们将跟踪所有这些播放列表，同时计算出现在这些播放列表标题中的单词。这样，当我们完成单词“a”后，我们可以使用出现最多的单词做同样的操作。我们可以一直这样做，直到我们有足够的播放列表：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The playlists we fetched don’t actually contain the songs; for this we need
    to do a separate call. To get all the tracks of a playlist, use:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取的播放列表实际上并不包含歌曲；为此，我们需要进行单独的调用。要获取播放列表的所有曲目，请使用：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Getting a large set of songs and playlists can take a significant amount of
    time. To get some decent results, we need at least 100,000 playlists, but something
    closer to a million would be better. Getting 100,000 playlists and their songs
    takes about 15 hours on a decent connection—it’s doable, but not something you’d
    want to do over and over again, so we’d better save the results.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 获取大量歌曲和播放列表可能需要相当长的时间。为了获得一些体面的结果，我们至少需要100,000个播放列表，但更接近一百万会更好。获取100,000个播放列表及其歌曲大约需要15个小时，这是可行的，但不是您想一遍又一遍地做的事情，所以最好保存结果。
- en: 'We are going to store three datasets. The first contains the playlist information
    itself—we don’t actually need this for the next recipe, but it is useful to check
    things. Secondly, we’ll store the IDs of the songs in the playlists in a big text
    file. And finally, we’ll store the per-song information. We’ll want to be able
    to look up these details in a dynamic fashion, so we’re going to use a SQLite
    database for this. We’ll write out the results as we collect song information
    to keep memory usage under control:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将存储三个数据集。第一个包含播放列表信息本身——实际上我们不需要这个信息用于下一个配方，但检查事物时会很有用。其次，我们将把播放列表中歌曲的ID存储在一个大文本文件中。最后，我们将存储每首歌曲的信息。我们希望能够以动态方式查找这些详细信息，因此我们将使用SQLite数据库。我们将在收集歌曲信息时将结果写出，以控制内存使用：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Discussion
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In this recipe we looked at building up a database of playlists and their songs.
    Since there is no clear way to get a balanced sample of public playlists from
    Spotify, we took the approach of using the search interface and trying popular
    keywords. While this works, the set we’ve acquired is hardly unbiased.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们研究了建立播放列表及其歌曲数据库。由于没有明确的方法可以从Spotify获取公共播放列表的平衡样本，我们采取了使用搜索界面并尝试流行关键词的方法。虽然这样做有效，但我们获取的数据集并不完全公正。
- en: For one thing, we get the popular keywords from the playlists that we fetched.
    This does give us words that are relevant for music, but can easily increase the
    skewing we already have. If we end up with playlists that are disproportionately
    about country music then our word lists will also start to fill up with country-related
    words, which in turn will have us fetch more country music.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从获取的播放列表中获取流行关键词。这确实为我们提供了与音乐相关的单词，但也很容易增加我们已经存在的偏差。如果最终我们的播放列表过多地涉及乡村音乐，那么我们的单词列表也将开始充斥着与乡村相关的单词，这反过来将使我们获取更多的乡村音乐。
- en: The other bias risk is that fetching playlists that contain popular words will
    get us popular songs. Terms like “greatest” and “hits” will occur often and cause
    us to get a lot of greatest hits; niche albums have less of a chance to be picked
    up.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个偏见风险是获取包含流行词的播放列表将使我们得到流行歌曲。像“最伟大”和“热门”这样的术语经常出现，会导致我们获得很多最伟大的热门歌曲；小众专辑被选中的机会较小。
- en: 15.7 Training a Music Recommender
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.7 训练音乐推荐系统
- en: Problem
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’ve fetched a large set of playlists, but how do you use them to train your
    music recommender system?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经获取了大量的播放列表，但如何使用它们来训练您的音乐推荐系统呢？
- en: Solution
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use an off-the-shelf Word2vec model and treat song IDs as words.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用现成的Word2vec模型，将歌曲ID视为单词。
- en: In [Chapter 3](ch03.html#word_embeddings) we explored how a Word2vec model projects
    words into a semantic space with nice properties; similar words end up in the
    same neighborhood and relations between words are somewhat consistent. In [Chapter 4](ch04.html#movie_recommender)
    we used an embedding technique to build a movie recommender. In this recipe we
    combine both approaches. Rather than training our own model, we’ll use an off-the-shelf
    model for Word2vec, but we’ll use the results to build a recommender for music.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html#word_embeddings)中，我们探讨了Word2vec模型如何将单词投影到具有良好属性的语义空间中；相似的单词最终位于同一邻域，单词之间的关系也相对一致。在[第4章](ch04.html#movie_recommender)中，我们使用了嵌入技术构建了一个电影推荐系统。在这个配方中，我们结合了这两种方法。我们不会训练自己的模型，而是使用现成的Word2vec模型，但我们将使用结果来构建一个音乐推荐系统。
- en: 'The `gensim` module we used in [Chapter 3](ch03.html#word_embeddings) also
    comes with the possibility to train a model. All it needs is an iterator that
    produces series of tokens. This isn’t too hard since we have our playlists stored
    as lines in a file, with each line containing the IDs of the songs separated by
    spaces:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第3章](ch03.html#word_embeddings)中使用的`gensim`模块还具有训练模型的可能性。它所需要的只是一个生成一系列标记的迭代器。这并不太难，因为我们将我们的播放列表存储为文件中的行，每行包含由空格分隔的歌曲ID：
- en: '[PRE26]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'After that training the model is a single-line operation:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，训练模型只需一行操作：
- en: '[PRE27]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Depending on how many songs/playlists the previous recipe resulted in, this
    could take a while. Let’s save the model for future use:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前一个配方产生的歌曲/播放列表数量，这可能需要一段时间。让我们保存模型以备将来使用：
- en: '[PRE28]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 15.8 Recommending Songs Using a Word2vec Model
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 15.8 使用Word2vec模型推荐歌曲
- en: Problem
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you use your model to predict songs based on an example?
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用您的模型根据示例预测歌曲？
- en: Solution
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use the Word2vec distances and your SQLite3 database of songs.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Word2vec距离和您的SQLite3歌曲数据库。
- en: 'The first step is to get a set of `song_id`s given a song name or part of it.
    The `LIKE` operator will get us a selection of songs that match the searched-for
    pattern. Song names, though, are hardly unique these days. Even for the same artists
    there are different versions around. So we need some way of scoring them. Luckily,
    we can use the `vocab` property of our model—the records in it have a *count*
    property. The more often a song appears in our playlists, the more likely it is
    that it is the song we are after (or at least the song we know most about):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是根据歌曲名称或部分名称获取一组`song_id`。`LIKE`运算符将为我们提供与搜索模式匹配的歌曲选择。但是，如今歌曲名称很少是唯一的。即使是同一位艺术家也有不同版本。因此，我们需要一种评分方式。幸运的是，我们可以使用模型的`vocab`属性——其中的记录具有*count*属性。歌曲在我们的播放列表中出现的次数越多，它就越有可能是我们要找的歌曲（或者至少是我们最了解的歌曲）：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now we can pick the song we really are after, in this case possibly the one
    by Survivor. Now on to suggesting songs. We let our model do the heavy lifting:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以选择我们真正想要的歌曲，这种情况下可能是Survivor的那首歌。现在开始建议歌曲。让我们的模型来做繁重的工作：
- en: '[PRE31]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we have a lookup table from song ID to score, which we can easily expand
    to a list of actual songs:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了从歌曲ID到分数的查找表，我们可以很容易地扩展为实际歌曲的列表：
- en: '[PRE32]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output for “The Eye of the Tiger” is:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: “The Eye of the Tiger”的输出是：
- en: '[PRE33]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This looks like a decent mix of upbeat ’80s-ish music.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来是一种不错的充满活力的80年代风格音乐的混合。
- en: Discussion
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Using Word2vec is an effective way to create a song recommender. Rather than
    training our own model as we did in [Chapter 4](ch04.html#movie_recommender),
    we used an off-the-shelf model here from `gensim`. There is less tuning, but it
    works well since the words in a sentence and songs in a playlist are fairly comparable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Word2vec是创建歌曲推荐系统的有效方法。与我们在第4章中所做的训练自己的模型不同，我们在这里使用了来自`gensim`的现成模型。虽然调整较少，但由于句子中的单词和播放列表中的歌曲是相当可比的，因此它效果很好。
- en: Word2vec works by trying to predict a word from its context. This prediction
    leads to an embedding that causes words that are similar to each other to appear
    near each other. Running the same process over songs in a playlist means trying
    to predict a song based on the context of the song in the playlist. Similar songs
    end up near each other in the song space.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Word2vec通过尝试从上下文预测单词来工作。这种预测导致嵌入，使得相似的单词彼此靠近。在播放列表中对歌曲运行相同的过程意味着尝试根据播放列表中歌曲的上下文来预测歌曲。相似的歌曲最终在歌曲空间中靠近彼此。
- en: With Word2vec it turns out that relations between words also have meaning. The
    vector separating the words “queen” and “princess” is similar to the vector separating
    “king” and “prince.” It would be interesting to see if something similar can be
    done with songs—what is the Beatles version of “Paint It Black” by the Rolling
    Stones? This would, however, require us to somehow project artists into the same
    space.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Word2vec，事实证明单词之间的关系也具有意义。分隔“queen”和“princess”之间的向量类似于分隔“king”和“prince”之间的向量。有趣的是，看看是否可以用类似的方式处理歌曲——披头士版本的滚石乐队的“Paint
    It Black”是什么？然而，这将要求我们以某种方式将艺术家投影到相同的空间中。
