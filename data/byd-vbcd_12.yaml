- en: Chapter 9\. The Ethical Implications of Vibe Coding
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章\. 感应编码的伦理影响
- en: 'As AI-assisted development becomes increasingly commonplace, it’s critical
    to address the ethical and societal implications of this new paradigm. This chapter
    steps back from the technical details to examine vibe coding through an ethical
    lens: these new development methods can be effective, but they also need to be
    implemented responsibly and to benefit individuals and society at large.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能辅助开发变得越来越普遍，解决这一新范式在伦理和社会方面的含义至关重要。本章从技术细节中抽身，通过伦理视角来审视感应编码：这些新的开发方法可能有效，但它们也需要负责任地实施，并使个人和整个社会受益。
- en: 'I begin with questions of intellectual property (IP). Who owns the code that
    AI generates, and is it permissible to use AI outputs that may be derived from
    open source code without attribution? From there, I consider bias and fairness.
    Transparency is another focus: should developers disclose which parts of a codebase
    were AI-generated, and how can teams ensure accountability for code quality and
    bugs?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我从知识产权（IP）的问题开始。谁拥有人工智能生成的代码，并且在不注明出处的情况下使用可能源自开源代码的人工智能输出是否允许？从那里，我考虑偏见和公平性。透明度也是另一个焦点：开发者是否应该披露代码库中哪些部分是由人工智能生成的，团队如何确保代码质量和错误的责任？
- en: I outline responsible development practices in AI usage, from establishing transparency
    and accountability to avoiding sensitive data in prompts to ensuring accessibility
    and inclusivity. The chapter finishes with a set of guidelines for using AI tools
    responsibly.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我概述了人工智能使用中的负责任开发实践，从建立透明度和问责制到避免在提示中使用敏感数据，再到确保可访问性和包容性。本章以一组使用人工智能工具的负责任指南结束。
- en: Legal Disclaimer
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 法律免责声明
- en: The following section touches on complex legal topics, particularly concerning
    copyright and intellectual property law, from a primarily US perspective. Legal
    systems and interpretations are evolving worldwide, especially concerning artificial
    intelligence. This information is for educational purposes only and does not constitute
    legal advice. You should consult with a qualified intellectual property lawyer
    before making any decisions based on this information, especially if you have
    concerns about the ownership or licensing of code you or an AI tool generates.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 下文将涉及复杂法律主题，尤其是从美国视角出发的版权和知识产权法。全球法律体系和解释正在演变，尤其是在人工智能方面。此信息仅用于教育目的，并不构成法律建议。在基于此信息做出任何决定之前，您应咨询合格的知识产权律师，尤其是如果您对代码的所有权或许可有疑问，或者代码是由人工智能工具生成的。
- en: Intellectual Property Considerations
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识产权考虑事项
- en: Who owns AI-generated code? And does using it respect the licenses and copyrights
    of the source material on which the AI was trained? AI models like GPT have been
    trained on huge swaths of code from the internet, including open source repositories
    with various licenses (MIT, GPL, Apache, etc.). If the AI generates a snippet
    that is [very similar](https://oreil.ly/I3HxT) (or identical) to something from
    a GPL-licensed project, using that snippet in a proprietary codebase could inadvertently
    violate the GPL, which generally requires [sharing derivative code](https://oreil.ly/8inJc).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 谁拥有人工智能生成的代码？使用它是否尊重了人工智能训练所依据的源材料的许可证和版权？像GPT这样的AI模型已经在互联网上大量代码上进行训练，包括具有各种许可证的开源存储库（MIT、GPL、Apache等）。如果人工智能生成了一段与GPL许可项目非常相似（或相同）的片段，那么在专有代码库中使用该片段可能会无意中违反GPL，通常要求[共享衍生代码](https://oreil.ly/8inJc)。
- en: According to open source norms and general copyright principles, small snippets
    of a few lines *might not* be copyrightable if they lack sufficient originality
    to be considered an independent creative work, or their use *could potentially*
    be considered de minimis (too trivial to warrant legal concern). However, anything
    substantial or expressing a unique creative choice is more likely to be protected
    by copyright. It’s crucial to understand that “open source” does not mean “public
    domain.” By default, creative work, including code, is under exclusive copyright
    by its author. Open source licenses explicitly grant permissions that would otherwise
    be restricted by copyright law.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 根据开源规范和一般版权原则，如果几行代码片段缺乏足够的独创性，不能被视为独立创意作品，或者其使用*可能*被视为微不足道（过于微不足道，不值得法律关注），那么它们可能*不*受版权保护。然而，任何实质性的或表达独特创意选择的内容更有可能受到版权保护。重要的是要理解，“开源”并不意味着“公共领域”。默认情况下，包括代码在内的创意作品由其作者享有独家版权。开源许可证明确授予了版权法通常限制的权限。
- en: 'If you want to know more about open source norms, good places to start include
    the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于开源规范的信息，以下是一些好的起点：
- en: The Open Source Initiative
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 开源倡议
- en: The [OSI](https://oreil.ly/hmJVN) defines and promotes open source software,
    maintains the Open Source Definition, and approves licenses that meet its criteria.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[OSI](https://oreil.ly/hmJVN)定义和推广开源软件，维护开源定义，并批准符合其标准的许可证。'
- en: The Free Software Foundation (FSF)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自由软件基金会（FSF）
- en: The [FSF](https://fsf.org) advocates for “free software” (which has a strong
    overlap with open source principles) and is the steward of licenses like the GNU
    General Public License (GPL).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[FSF](https://fsf.org)倡导“免费软件”（与开源原则有强烈重叠）并管理着像GNU通用公共许可证（GPL）这样的许可证。'
- en: Project-specific documentation
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 项目特定文档
- en: Individual open source projects typically include *LICENSE* files, *README*
    files, and *CONTRIBUTING* guidelines that detail the terms of use and contribution
    for that specific project.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 个体开源项目通常包括*LICENSE*文件、*README*文件和*CONTRIBUTING*指南，详细说明了该特定项目的使用条款和贡献。
- en: Community and legal resources
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 社区和法律资源
- en: Websites like GitHub offer extensive documentation and discussions on open source
    practices. Organizations like the Linux Foundation and legal information sites
    also provide valuable resources on open source compliance and legal aspects.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于GitHub的网站提供了关于开源实践的广泛文档和讨论。像Linux基金会和法律信息网站这样的组织也提供了关于开源合规性和法律方面的宝贵资源。
- en: 'The question of whether using small code snippets overlaps with the [fair use
    doctrine](https://oreil.ly/d0ZK8) (in the US; “fair dealing” in many other jurisdictions)
    is complex and highly fact-dependent. [Fair use](https://oreil.ly/EwrJ2) permits
    limited use of copyrighted material without permission for purposes such as criticism,
    comment, news reporting, teaching, scholarship, or research. US courts typically
    consider four factors to determine fair use:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用小代码片段是否与[合理使用原则](https://oreil.ly/d0ZK8)（在美国；许多其他司法管辖区称为“公平使用”）重叠的问题复杂且高度依赖事实。合理使用[允许](https://oreil.ly/EwrJ2)在未经许可的情况下有限使用受版权保护的材料，用于批评、评论、新闻报道、教学、学术研究或研究等目的。美国法院通常考虑以下四个因素来确定合理使用：
- en: The [purpose](https://oreil.ly/1TE5B) and character of the use (commercial versus
    nonprofit, transformative versus duplicative)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用目的和性质（商业与非营利，变革性对复制性）
- en: The nature of the copyrighted work (highly creative versus factual)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 受版权保护作品的性质（高度创意与事实性）
- en: The amount and substantiality of the portion used in relation to the copyrighted
    work as a whole
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所用部分的数量和实质与整个受版权保护作品的关系
- en: The effect of the use upon the potential market for or value of the copyrighted
    work
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用对受版权保护作品潜在市场或价值的影响
- en: While some might argue that copying very small, functional code snippets for
    interoperability or to access uncopyrightable ideas could fall under fair use,
    especially if the use is transformative, this is not a clearly settled area of
    law for code, and there’s no universally agreed-upon number of lines that is definitively
    “fair use” or de minimis. The safest course is often to get permission or to understand
    the underlying idea and rewrite the code in your own way. The U.S. Supreme Court
    case *Google LLC v. Oracle America, Inc.* addressed fair use in the context of
    software APIs, finding Google’s reimplementation of Java API declaring code to
    be fair use, but this was a specific and complex ruling focused on API declarations,
    not all code. It’s generally understood that copyright protects the specific expression
    of an idea, not the idea, procedure, or method of operation itself.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有些人可能会认为，为了互操作性或访问不受版权保护的想法而复制非常小的、功能性的代码片段可能属于合理使用，尤其是如果使用具有变革性，但这并不是代码法律中一个明确确定的领域，也没有一个普遍认同的行数数量可以明确地界定为“合理使用”或最小损害。最安全的做法通常是获得许可或理解底层想法，并以自己的方式重写代码。美国最高法院案件
    *Google LLC v. Oracle America, Inc.* 在软件API的背景下讨论了合理使用，认为谷歌对Java API声明代码的重实现属于合理使用，但这是一个针对API声明特定且复杂的裁决，并不适用于所有代码。通常认为，版权保护的是想法的具体表达，而不是想法、程序或操作方法本身。
- en: Typically, the developer *using* the AI is considered the “author” in the sense
    that the AI is a tool, similar to a compiler or a word processor. Thus, if code
    is generated in a work context, the developer’s company would likely own the code
    produced by the developer using the tool, subject to the AI tool’s terms of service
    and underlying IP issues. However, the terms of service (ToS) of AI tools are
    critical. Most ToS grant the user rights to the output they generate. OpenAI’s
    ToS, for instance, states, “You own the outputs you create with GPT-4, including
    code.”
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，使用AI的开发者被视为“作者”，因为AI是一个工具，类似于编译器或文字处理器。因此，如果在工作环境中生成代码，那么使用该工具的开发者所在的公司可能会拥有由开发者生成的代码，但需遵守AI工具的服务条款和底层知识产权问题。然而，AI工具的服务条款（ToS）至关重要。大多数ToS授予用户对其生成的输出拥有权利。例如，OpenAI的ToS规定：“您拥有使用GPT-4创建的输出，包括代码。”
- en: This “ownership,” however, needs careful consideration. It generally means that
    the AI provider isn’t claiming ownership of what *you* create *with their tool*.
    But this assumes you have the rights to the *inputs* you provide, and it doesn’t
    automatically mean the output is itself eligible for copyright protection or that
    it’s free from third-party intellectual property claims. If you input your own
    original code to the tool for modification or extension, the output is most likely
    yours (or your employer’s), again, subject to how the AI processes it and what
    it incorporates from its training data. But if you input someone else’s copyrighted
    code to fix or transform, the output *might* be considered a [derivative work
    of that third-party code](https://oreil.ly/mBPyq).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种“所有权”需要仔细考虑。这通常意味着AI提供商并不声称拥有你使用他们的工具所创建的内容的所有权。但这假设你拥有你提供的输入的权利，并且这并不意味着输出本身有资格获得版权保护，或者它不受第三方知识产权主张的影响。如果你将你自己的原创代码输入到工具中进行修改或扩展，输出很可能是你的（或你雇主的），再次强调，这取决于AI如何处理它以及它从训练数据中吸收了什么。但如果你输入他人的版权代码进行修复或转换，输出*可能*被视为[该第三方代码的衍生作品](https://oreil.ly/mBPyq)。
- en: In the US and many other jurisdictions, whether AI-generated output that is
    substantially similar to training data, or output based on copyrighted input,
    constitutes a derivative work is a subject of ongoing legal debate and lacks full
    clarity. Don’t feed large chunks of copyrighted code that isn’t yours (or licensed
    appropriately) into an AI tool, because the output could be deemed a [derivative
    work](https://oreil.ly/O4ktq) and thus fall under the license of that original
    copyrighted code.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国和许多其他司法管辖区，AI生成的输出与训练数据实质上相似，或者基于受版权保护输入的输出是否构成衍生作品，是一个持续的法律辩论主题，且缺乏完全的清晰度。不要将不属于你（或适当许可的）版权代码的大量片段输入到AI工具中，因为输出可能被视为[衍生作品](https://oreil.ly/O4ktq)，从而落入原始版权代码的许可之下。
- en: Given these uncertainties, to be safe, treat AI-generated code as if it’s under
    an ambiguous license, and only use it if you are comfortable that it doesn’t infringe
    on existing copyrights and that you can comply with any potential open source
    license obligations. Regarding the copyright status of the AI output itself, the
    [US Copyright Office has stated](https://oreil.ly/Y0PYG) that works generated
    solely by AI without sufficient human authorship are not copyrightable. If a human
    significantly modifies or arranges AI-generated material in a creative way, that
    human contribution might be [copyrightable](https://oreil.ly/NV3Gl) but not the
    AI-generated elements standing alone. Thus, it’s often wise to assume that purely
    AI-generated outputs might not be copyrightable by anyone or that copyright would
    extend only to the human’s creative contributions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些不确定性面前，为了安全起见，将AI生成的代码视为处于模糊许可之下，并且只有在你确信它不会侵犯现有版权并且你能够遵守任何潜在的开源许可义务时才使用它。关于AI输出本身的版权状态，[美国版权局已声明](https://oreil.ly/Y0PYG)
    ，仅由AI生成且缺乏足够人类作者的作品不可获得版权。如果人类以创造性的方式显著修改或编排AI生成的材料，那么人类的贡献可能具有版权性，但AI生成的元素本身则不一定。因此，通常明智的做法是假设纯粹由AI生成的输出可能无人拥有版权，或者版权仅限于人类的创造性贡献。
- en: 'This is not a hypothetical worry. In fact, there’s ongoing legal debate. A
    [prominent class-action lawsuit, *Doe v. GitHub, Inc.*](https://githubcopilotlitigation.com),
    was filed against GitHub, Microsoft, and OpenAI, claiming that GitHub Copilot
    produces code that is too similar to licensed open source code without proper
    attribution or adherence to license terms.  While some claims in this case have
    been dismissed or are under appeal (as of mid-2025, the case involves ongoing
    proceedings, including an appeal to the Ninth Circuit regarding DMCA claims and
    remaining breach of contract claims), it highlights a genuine concern: AI can
    and sometimes does regurgitate or closely paraphrase copyrighted code from its
    training data.^([1](ch09.html#id1032))'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一种假设的担忧。事实上，存在持续的司法辩论。一项[著名的集体诉讼案，*Doe v. GitHub, Inc.*](https://githubcopilotlitigation.com)
    已对GitHub、微软和OpenAI提起，声称GitHub Copilot生成的代码与受许可的开源代码过于相似，而没有适当的归属或遵守许可条款。虽然此案中的一些主张已被驳回或正在上诉（截至2025年中，该案件涉及持续的诉讼，包括对第九巡回法院关于DMCA主张和剩余违约诉讼的上诉），但它凸显了一个真正的担忧：AI可以，有时确实会从其训练数据中重复或紧密释义受版权保护的代码。（^([1](ch09.html#id1032)）
- en: An older (but still relevant and later substantiated) [study by GitHub itself](https://oreil.ly/fFUUd)
    noted that, in some cases, Copilot’s output included suggestions that matched
    training data, including rare instances of longer verbatim snippets. While most
    AI tools are designed to avoid direct, extensive copying of identifiable code
    unless specifically prompted or dealing with very standard algorithms, the risk
    exists. Furthermore, it’s not just open source code that’s a concern; numerous
    lawsuits have been filed by authors, artists, and media companies alleging that
    their fully copyrighted, privately owned intellectual property was used without
    permission or compensation to train large language models and other generative
    AI systems. The challenge with proprietary code is that, unlike open source, it’s
    often not publicly visible, making it harder for an end user to confirm if an
    AI’s output is inadvertently similar to such private code.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub本身的一项（虽然较旧但仍然相关且后来得到证实）[研究](https://oreil.ly/fFUUd) 指出，在某些情况下，Copilot的输出包括与训练数据匹配的建议，包括罕见的长句直接引用。尽管大多数AI工具设计用来避免直接、广泛的复制可识别的代码，除非被明确提示或处理非常标准的算法，但风险是存在的。此外，问题不仅限于开源代码；作者、艺术家和媒体公司已提起众多诉讼，声称他们的完全版权、私有知识产权未经许可或未获补偿就被用于训练大型语言模型和其他生成性AI系统。与专有代码相比，挑战在于，与开源不同，它通常不是公开可见的，这使得最终用户更难确认AI的输出是否无意中与这样的私有代码相似。
- en: Nevertheless, the ethical and prudent practice is to *act as if any code you
    accept from an AI tool is your responsibility*. Thoroughly review, test, and understand
    any AI-generated code before incorporating it into your projects, and ensure its
    use complies with all applicable licenses and copyright laws.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，道德和谨慎的做法是*假定你从AI工具接受的任何代码都是你的责任*。在将任何AI生成的代码纳入你的项目之前，彻底审查、测试和理解它，并确保其使用符合所有适用的许可和版权法律。
- en: What to Do If You Get Suspicious Output
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果你得到可疑的输出，应该怎么做
- en: If an AI output seems like a verbatim or near-verbatim copy of known code (especially
    if it includes distinctive comments or author names), treat it carefully. Consider
    running a similarity check using a plagiarism detector tool, or do a web search
    for unique strings to see if you find any matches that could indicate copying.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI的输出看起来是已知代码的逐字或近似逐字复制（特别是如果它包括独特的注释或作者姓名），请谨慎处理。考虑使用抄袭检测工具进行相似性检查，或者进行网络搜索以查看是否有任何匹配项可以表明复制。
- en: Another principle to follow is *When in doubt, leave it out*. Either avoid using
    the output or make sure it’s under a compatible license and give attribution if
    required. For example, if Copilot spits out a well-known algorithm implementation
    that you recognize from Stack Overflow or an open source project, cite the source
    or rewrite it in your own way, using the AI’s answer as a guide but not quoting
    it verbatim.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要遵循的原则是*如有疑问，则弃之不用*。要么避免使用输出，要么确保它符合兼容的许可协议，并在需要时提供归属。例如，如果Copilot输出一个你从Stack
    Overflow或开源项目中识别出的知名算法实现，请引用来源或以你自己的方式重写它，将AI的答案作为指导，但不要直接引用。
- en: 'If you suspect the output matches an existing library solution, consider including
    the library itself instead (with proper license). You can also prompt the AI:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你怀疑输出与现有的库解决方案相匹配，考虑包含库本身（带有适当的许可证）。你也可以提示AI：
- en: Please provide an original implementation rather than one copied from a library.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请提供原始实现，而不是从库中复制的实现。
- en: It might then synthesize a more unique solution. (There’s no guarantee it won’t
    be influenced by its training code, but at least it will try to not copy outright).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能会合成一个更独特的解决方案。（无法保证它不会被训练代码所影响，但至少它会尝试不直接复制）。
- en: 'The ethics here also touch on not using AI to willfully strip attribution.
    For example, it would be unethical to copy code from Stack Overflow via AI without
    attribution to circumvent a policy that you should credit the answer. That erodes
    trust in the open knowledge ecosystem. It’s better to incorporate the material
    with proper credit. Depending on the circumstances, that might mean the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的伦理问题还涉及到不使用AI故意去除归属。例如，通过AI复制Stack Overflow上的代码而不提供归属以规避你应该归功于答案的政策是不道德的。这会破坏开放知识生态系统的信任。更好的做法是以适当的信用融入材料。根据情况，这可能意味着以下内容：
- en: If an AI writes a code comment from some source that has an author’s name (like
    copying a snippet with “John Doe 2018” in a comment), you should keep that or
    move it to a proper attribution section with a full citation rather than deleting
    it. That respects the original author’s credit.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AI从某个有作者姓名的来源（如注释中包含“John Doe 2018”的片段）编写了代码注释，你应该保留它或将它移至适当的归属部分，并附上完整的引用，而不是删除它。这尊重了原始作者的信用。
- en: If an AI provided a solution that you know comes from a known algorithm or code
    snippet, cite that source as you normally would if you had looked it up yourself.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AI提供了一个你已知来自已知算法或代码片段的解决方案，你应该像自己查找那样引用该来源。
- en: If an AI tool creates something arguably creative (like a unique approach or
    text for documentation), acknowledge its contribution. Though it doesn’t have
    rights, it’s about transparency (and maybe a nod to the tech).
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AI工具创造了一些具有争议的创意内容（如独特的文档方法或文本），请承认其贡献。尽管它没有权利，但这关乎透明度（也许是对技术的认可）。
- en: Some open source licenses (like MIT) are permissive enough that including copied
    code with attribution would satisfy the license. Others, like GPL or AGPL, would
    “infect” your whole codebase if you include that code, which is undesirable for
    closed projects.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开源许可证（如MIT）足够宽容，包含带有归属的复制的代码就能满足许可证的要求。其他一些，如GPL或AGPL，如果你包含这些代码，就会“感染”你的整个代码库，这对封闭项目来说是不理想的。
- en: 'In short: if you suspect the AI has given you something that might cause IP
    issues, either avoid using it or transform it sufficiently to ensure you’re complying
    with any possible license.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之：如果你怀疑AI给你提供了可能引起知识产权问题的东西，要么避免使用它，要么充分转换它以确保你遵守任何可能的许可证。
- en: Gray Areas
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模糊区域
- en: 'Even as I write this, AI tools continue to raise new questions about IP, copyright,
    and ethics. For instance:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在我撰写这篇文章的时候，AI工具仍在提出关于知识产权、版权和伦理的新问题。例如：
- en: If your vibe coding includes using AI to generate noncode assets like documentation
    text, config files, or images, similar IP questions arise. For instance, if you
    generate an icon image via an AI tool that was trained on copyrighted images,
    who owns that new image?
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的编码风格包括使用AI生成非代码资产，如文档文本、配置文件或图像，类似的知识产权问题也会出现。例如，如果你通过一个在受版权保护的图像上训练的AI工具生成图标图像，那么新的图像归谁所有？
- en: If an AI writes a significant part of a software product, should the original
    authors of the code on which the AI was trained get credit?
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果AI编写了软件产品的很大一部分，那么AI训练代码的原始作者应该得到认可吗？
- en: Could someone claim that your AI-generated code infringes on their copyright
    because it looks similar to theirs? If sections of nontrivial lengths are possibly
    identical, this is where similarity checking comes in.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有人声称你的AI生成的代码侵犯了他们的版权，因为它看起来与他们的一样？如果非重要部分的长度可能相同，这就是相似性检查介入的地方。
- en: There’s an emerging notion that AI companies might need to implement license-respecting
    filters or allow teams to opt out of their code being included in AI training
    data. It’s evolving, but developers on the ground should act conservatively to
    not violate rights.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正在出现一种观点，即AI公司可能需要实施尊重许可的过滤器或允许团队选择不将其代码包含在AI训练数据中。这正在演变，但地面上的开发者应该谨慎行事，以免侵犯权利。
- en: It will take time for courts to settle all of the legal issues, but in the meantime,
    intellectual honesty and respect should guide us. If AI uses a known algorithm
    from a published paper, cite the paper in a comment. If it uses a common open
    source helper code, credit the project. It’s about respect for authorship. If
    you recognize where something came from, err on the side of giving credit. It’s
    a good practice that fosters transparency.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 法院需要时间来解决所有法律问题，但在此期间，我们应该以诚信和尊重为指导。如果AI使用了一个已知的、来自已发表论文的算法，请在注释中引用该论文。如果它使用了常见的开源辅助代码，请为该项目提供信用。这是关于尊重作者的问题。如果你认识到某物来自何处，就倾向于给予信用。这是一种促进透明度的良好做法。
- en: Remember that under the hood, the AI’s knowledge comes from thousands of developers
    who shared their code publicly. Ethically, the software industry owes that community
    the respect of upholding open source licenses and norms. Give credit where it’s
    due and don’t abuse others’ work under the guise of “the AI wrote it, not me.”
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在底层，AI的知识来自成千上万的公开分享代码的开发者。从道德上讲，软件行业应该尊重开源许可和规范，尊重这个社区。给予应得的信用，不要以“AI写了它，不是我”为借口滥用他人的工作。
- en: Transparency and Attribution
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 透明度和归属
- en: '*Transparency* refers to being open about the use of AI in your development
    process and outputs, and *attribution* refers to giving proper credit when AI-derived
    code comes from identifiable sources.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**透明度**指的是在开发过程和输出中公开使用AI，**归属**指的是当AI生成的代码来自可识别的来源时给予适当的信用。'
- en: 'Transparency is important for the sake of accountability. For example, if AI-generated
    code introduces a bug or security flaw, being transparent that “this code was
    AI-suggested” might help you analyze the root cause—perhaps an ambiguous prompt
    should be rewritten. In code comments or a project’s README or documentation,
    you might mention generally that “this project was built with assistance from
    AI tools like ChatGPT.” Or get more specific: “Added a function to parse CSV (generated
    with ChatGPT’s help, then modified).” It’s a bit like acknowledging your use of
    frameworks or libraries.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度对于问责制也很重要。例如，如果AI生成的代码引入了错误或安全漏洞，明确指出“这段代码是AI建议的”可能有助于你分析根本原因——可能需要重写模糊的提示。在代码注释或项目的README或文档中，你可能会提到“该项目是在ChatGPT等AI工具的帮助下构建的。”或者更具体：“添加了一个解析CSV的功能（在ChatGPT的帮助下生成，然后进行了修改）。”这有点像承认你使用了框架或库。
- en: 'Transparency is also key to trust: stakeholders (your team, clients, end users,
    or industry regulators) might want to know how your software was developed and
    validated. If an AI was involved in code generation, some stakeholders might wrongly
    trust it too much or too little. Transparency allows a conversation about reliability:
    “Yes, we used AI, but we tested it thoroughly” or “This part was tricky—we had
    AI generate the initial code, but we’ve since verified it.”'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度也是建立信任的关键：利益相关者（你的团队、客户、最终用户或行业监管机构）可能想知道你的软件是如何开发和验证的。如果AI参与了代码生成，一些利益相关者可能会错误地过分或不足地信任它。透明度允许就可靠性进行对话：“是的，我们使用了AI，但我们已经彻底测试了它”或“这部分很棘手——我们让AI生成了初始代码，但我们后来已经验证了它。”
- en: Attributions are also expected or required in many academic venues. Some open
    source projects restrict or even forbid AI contributions due to IP concerns, so
    check the contributor guidelines before using AI. Being transparent with maintainers
    if a patch was AI-generated helps them evaluate it, especially if licensing is
    a worry.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多学术场合，也需要或期望提供归属信息。一些开源项目由于知识产权的担忧，限制或甚至禁止AI贡献，因此在使用AI之前请检查贡献指南。如果补丁是由AI生成的，向维护者保持透明可以帮助他们评估它，尤其是如果版权是一个担忧的话。
- en: In fact, some highly regulated industries require software vendors to disclose
    any AI use for auditing purposes. [The EU’s AI Act](https://oreil.ly/wDNKs) mandates
    transparency for automated decision making that affects individuals (such as credit-scoring
    algorithms). If vibe coding leads to such systems, it becomes a legal/ethical
    necessity to inform users that “recommendations are generated automatically and
    may reflect patterns in data.”
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，一些高度监管的行业要求软件供应商披露任何AI使用情况，以供审计目的。[欧盟的AI法案](https://oreil.ly/wDNKs)要求对影响个人的自动化决策（如信用评分算法）进行透明度管理。如果vibe编码导致这样的系统，通知用户“推荐是自动生成的，可能反映了数据中的模式”成为一种法律/道德上的必要性。
- en: Similarly, if your product feeds user data or proprietary data like user-provided
    code examples into an AI model to fine-tune it and help program its analysis,
    you might need to say in the privacy policy that user data may be used with permission
    to improve AI models (as always, do consult a lawyer for legal matters). Transparency
    intersects with privacy here.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果你的产品将用户数据或用户提供的代码示例等专有数据输入到AI模型中，以微调它并帮助编程其分析，你可能需要在隐私政策中说明用户数据可能会在许可的情况下用于改进AI模型（当然，在法律事务上，始终要咨询律师）。透明度在这里与隐私相交。
- en: It’s also just generally ethical to acknowledge the tools and sources you use.
    If 30% of your code was generated by Copilot, it’s fair to mention that in your
    documentation or internal communication—not to diminish your own role but to be
    honest about the process.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，承认你使用的工具和来源也是道德上的要求。如果你的30%代码是由Copilot生成的，那么在文档或内部沟通中提及这一点是公平的——不是为了贬低自己的角色，而是为了对过程保持诚实。
- en: Some developers might fear admitting that AI helped, worried that it could undermine
    their perceived contribution or skill or be seen as “cheating.” As vibe coding
    becomes more normalized, this stigma should decrease; eventually, you might be
    seen as behind the times if you’re *not* using the AI available to you. We need
    to normalize AI as a tool—it’s no more “cheating” than using Stack Overflow or
    an IDE.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开发者可能害怕承认AI的帮助，担心这可能会削弱他们感知到的贡献或技能，或者被视为“作弊”。随着vibe编码变得更加普遍，这种耻辱感应该会减少；最终，如果你不使用可用的AI，你可能会被视为落后于时代。我们需要将AI作为一种工具来正常化——它并不比使用Stack
    Overflow或IDE更“作弊”。
- en: 'On the flip side, providing too many disclaimers could cause undue worry. If
    you tell a client, “We used AI to code this product,” they might question its
    safety (even if that’s due to misconceptions). It’s important how you phrase it.
    Emphasize quality measures in the same breath: “We utilized advanced coding assistants
    to speed up development, and all AI-generated code was rigorously reviewed and
    tested to meet our quality standards.”'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从另一方面来看，提供过多的免责声明可能会引起不必要的担忧。如果你告诉客户，“我们使用了AI来编码这个产品”，他们可能会质疑其安全性（即使这是由于误解）。你如何措辞很重要。强调质量措施：
    “我们利用高级编码助手加快了开发速度，所有AI生成的代码都经过严格审查和测试，以满足我们的质量标准。”
- en: In sum, transparency and attribution foster trust and community values. They
    ensure that credit flows to human creators and that we remain honest about how
    our software is built. It’s akin to an artist listing their tools or inspirations;
    it doesn’t diminish the art; it contextualizes it. If, like me, you want vibe
    coding to be accepted widely, being open about using AI and how you mitigate its
    risks is important.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，透明度和归属感可以培养信任和社区价值观。它们确保信用流向人类创作者，并且我们保持对软件构建过程的诚实。这就像艺术家列出他们的工具或灵感一样；它并不减少艺术的价值；它为艺术提供了背景。如果你像我一样，希望vibe编码被广泛接受，那么公开使用AI以及如何减轻其风险是很重要的。
- en: Bias and Fairness
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏见与公平
- en: As you know well by this point in the book, AI models’ output reflects the data
    they’re trained on. If that data contains biases or exclusionary patterns, the
    models can produce outputs that are biased or unfair.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，到这本书的这一部分，AI模型的输出反映了它们训练的数据。如果这些数据包含偏见或排他性模式，模型可以产生有偏见或不公平的输出。
- en: 'You might ask: “How can code be biased? It’s not like an LLM is making hiring
    decisions or something.” But bias can creep into your coding in subtle ways:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问：“代码怎么会有偏见？LLM又不是在做招聘决定或类似的事情。”但偏见可能会以微妙的方式渗透到你的编码中：
- en: Code often reflects assumptions on its creators’ part. User-facing text or content
    the AI generates might reflect cultural biases or insensitive language present
    in its training data. For instance, [Microsoft’s Tay](https://oreil.ly/d8wxO),
    an early chatbot in 2016, infamously learned to parrot racist and misogynistic
    slurs from Twitter interactions within hours of launch.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码通常反映了其创作者的假设。AI生成的面向用户的文本或内容可能会反映其训练数据中的文化偏见或无礼语言。例如，2016年早期聊天机器人[微软的Tay](https://oreil.ly/d8wxO)臭名昭著地学会了在启动后几小时内从Twitter互动中模仿种族主义和性别歧视的侮辱性语言。
- en: Assumptions can also be geared toward specific cultural norms, like a middle-class
    North American lifestyle (such as assuming car ownership or universal access to
    certain technologies). A notable example of unexamined assumptions leading to
    exclusionary products was the initial [2014 release of Apple’s Health app](https://oreil.ly/67sZG),
    which lacked a period tracker—a significant oversight likely stemming from a lack
    of diversity and perspective on the design team. Even in example code, comments,
    or synthetic data, the model might always use *he/him* pronouns, reinforcing gender
    bias.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设也可能针对特定的文化规范，例如中产阶级北美生活方式（例如假设拥有汽车或对某些技术的普遍访问）。一个未经验证的假设导致排他性产品的显著例子是苹果公司在2014年的[首次发布Health应用](https://oreil.ly/67sZG)，该应用缺少经期追踪器——这是一个重大的疏忽，很可能是由于设计团队缺乏多样性和视角。即使在示例代码、注释或合成数据中，模型也可能始终使用*他/他*代词，从而强化性别偏见。
- en: It is well known that code repositories and the broader software development
    landscape predominantly reflect Western perspectives and English speakers. As
    a result, an AI trained on these repositories might overlook crucial internationalization
    aspects, such as proper support for Unicode and multibyte characters (essential
    for languages like Chinese, Japanese, Korean, Arabic, Hindi, and many others using
    non-Latin or syllabary scripts), or it might default to English-centric examples
    for things like type names. Developers must bring awareness and design and code
    for internationalization, even if the AI doesn’t spontaneously do so.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 众所周知，代码库和更广泛的软件开发领域主要反映了西方观点和英语使用者的视角。因此，在这些代码库上训练的AI可能会忽视关键的国际化方面，例如对Unicode和多字节字符的适当支持（对于中文、日语、韩语、阿拉伯语、印地语以及许多使用非拉丁或音节文字的语言至关重要），或者它可能会默认使用以英语为中心的示例，例如类型名称。开发者必须提高意识，并设计和编码以实现国际化，即使AI没有自发这样做。
- en: If writing algorithms, be wary of certain variables like race, gender, age,
    etc. The AI might not spontaneously include them unless asked, but if it hallucinates
    some criteria or if you’re using an AI like Code Assistant on a dataset, apply
    fairness constraints; the AI won’t inherently know the moral or legal context.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果编写算法，要警惕某些变量，如种族、性别、年龄等。AI可能不会自发地包括它们，除非被要求，但如果它产生了某些标准或如果你在一个数据集上使用像Code
    Assistant这样的AI，应用公平约束；AI本身不会天生知道道德或法律背景。
- en: 'Beyond just coding, models can mirror *data bias* in their content domain:
    the historical biases present in their training data. For example, consider an
    AI tasked with writing code for a credit-scoring algorithm for loan approvals.
    In the United States, credit scoring systems have a documented history of reflecting
    and perpetuating racial biases. These biases stem from historical practices like
    redlining and other forms of systemic discrimination that have had lasting financial
    repercussions, particularly for Black communities and other marginalized groups.
    (See Richard Rothstein’s *The Color of Law* [Economic Policy Institute, 2017]
    for a comprehensive history of how government policies segregated America.)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是编码，模型还可以在其内容领域反映*数据偏差*：它们训练数据中存在的历史偏差。例如，考虑一个被赋予为贷款审批算法编写代码的AI。在美国，信用评分系统有记录的历史表明，它们反映了并持续着种族偏见。这些偏见源于历史上的做法，如红线划分和其他形式的系统性歧视，这些做法对黑人社区和其他边缘化群体产生了持久的经济影响。（参见理查德·罗思斯坦的*《法律的颜色》*
    [经济政策研究所，2017]，了解政府政策如何将美国隔离的历史。）
- en: If the training data reflects these historical biases, the AI might incorporate
    discriminatory variables, such as using zip codes (which can be a proxy for racial
    demographics due to segregated housing patterns) or other seemingly neutral data
    points that correlate with protected characteristics. If not properly guided,
    the AI might produce code that leads banks to make unfair lending decisions, thus
    perpetuating historical inequalities and affecting real people’s lives. Similar
    issues arise in areas like predictive policing algorithms, where historical arrest
    data (itself potentially biased) can lead to AI systems that [disproportionately
    target certain communities](https://oreil.ly/H4rmr).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果训练数据反映了这些历史偏见，AI可能会包含歧视性变量，例如使用邮政编码（由于住房隔离模式，它可以作为种族人口统计的代理）或其他看似中性的数据点，这些数据点与受保护的特征相关。如果没有得到适当的指导，AI可能会生成导致银行做出不公平贷款决定的代码，从而延续历史不平等并影响真实人们的生活。类似的问题也出现在预测警务算法等领域，其中历史逮捕数据（本身可能存在偏见）可能导致AI系统[不成比例地针对某些社区](https://oreil.ly/H4rmr)。
- en: Similarly, if you’re using specialized models (like an AI code assistant fine-tuned
    for, say, medical software), ensure the model isn’t locked into biases from that
    domain’s data. For example, historically, some medical guidelines were biased
    by research studies that predominantly used male subjects, leading to misdiagnoses
    or less effective treatments for other genders. If AI is recommending code or
    solutions for medical diagnostics, you need to double-check that it doesn’t inadvertently
    encode those biases.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果您正在使用专用模型（例如针对医疗软件进行微调的AI代码助手），请确保该模型没有陷入该领域数据的偏见。例如，历史上，一些医疗指南由于主要使用男性受试者的研究而存在偏见，导致对其他性别误诊或治疗效果不佳。如果AI正在推荐用于医疗诊断的代码或解决方案，您需要确保它没有无意中编码这些偏见。
- en: There are tools emerging to detect bias in AI outputs, though these are more
    common in GPT models used to generate content, and AI providers themselves attempt
    to filter overtly biased or toxic outputs. Code-oriented AIs rarely produce hate
    speech spontaneously, but it’s good that they have content filters for it. Building
    in ethical constraints means, in many AI tools, that if a user tries to get the
    AI to create malware or discriminatory algorithms, it will refuse. Don’t try to
    break those filters to get unethical outputs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有工具可以检测AI输出的偏见，但这些工具在用于生成内容的GPT模型中更为常见，AI提供商本身也试图过滤明显有偏见或有毒的输出。以代码为导向的AI很少会自发产生仇恨言论，但它们有内容过滤器是好事。在许多AI工具中，内置道德约束意味着，如果用户试图让AI创建恶意软件或歧视性算法，它将拒绝。不要试图绕过这些过滤器来获取不道德的输出。
- en: 'There are lots of other ways to recognize and mitigate bias at different stages
    of the development process, though. These include:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，在开发过程的各个阶段，还有许多其他方法可以识别和减轻偏见。这些包括：
- en: Testing with diverse examples
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多样化的示例进行测试
- en: If your AI generates user-facing components or logic that deals with human-related
    data, test it with diverse inputs. For example, if an AI-generated form validation
    expects “First Name” and “Last Name,” does it allow single names, which are common
    in some cultures? If not, that’s a bias in assumption. If it generates sample
    usernames, are they all like “JohnDoe”? If so, consider incorporating more diversity
    in the examples.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的AI生成面向用户的组件或处理与人类相关数据的逻辑，请使用多样化的输入进行测试。例如，如果AI生成的表单验证期望“名字”和“姓氏”，它是否允许单名，这在某些文化中很常见？如果不允许，那就是假设上的偏见。如果它生成示例用户名，它们是否都是像“JohnDoe”这样的？如果是这样，考虑在示例中增加多样性。
- en: Prompting for inclusivity
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 提示包容性
- en: 'You can explicitly instruct the AI to be neutral or inclusive: “Generate examples
    using a variety of names from different cultures.” If it always refers to the
    user as “he,” you might prompt:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以明确指示AI保持中立或包容：“生成使用来自不同文化的各种名字的示例。”如果它总是用“他”来称呼用户，您可能会提示：
- en: Avoid gendered language in this code comment; use neutral phrasing or they/them
    pronouns.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在此代码注释中避免使用性别语言；使用中性措辞或他们/他们代词。
- en: Also, be cautious about jokes or examples the AI might produce that could be
    culturally insensitive; you can prompt it to use a professional tone to avoid
    that. The AI will usually comply. It doesn’t have an agenda; it just outputs what
    seems normal to it, unless told otherwise. We shape that “normal.”
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对AI可能产生的可能文化不敏感的笑话或示例要谨慎；您可以提示它使用专业语气以避免这种情况。AI通常会遵守。它没有议程；它只是输出它认为正常的内容，除非被告知否则。我们塑造那个“正常”。
- en: Hiring diverse teams
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 聘请多元化的团队
- en: Having a diverse team review outputs can catch issues. For example, someone
    might say, “Hey, our AI always picks variable names like foo/bar, which is fine,
    but in documentation, all of its personas are male-typed.” Then you can correct
    that systematically. If all developers are from similar backgrounds, they might
    not catch a subtle bias. If possible, involve people from underrepresented groups—or
    at least consider their perspectives—when reviewing AI usage guidelines.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让一个多元化的团队审查输出可以捕捉到问题。例如，有人可能会说，“嘿，我们的 AI 总是选择像 foo/bar 这样的变量名，这没问题，但在文档中，它的所有角色都是男性化的。”然后你可以系统地纠正这一点。如果所有开发者都来自相似背景，他们可能不会捕捉到微妙的偏见。如果可能的话，在审查
    AI 使用指南时，涉及来自代表性不足的群体的人——或者至少考虑他们的观点。
- en: In summary, bias and fairness are about using vibe-coding tools to produce code
    that is fair to users of all backgrounds and that doesn’t reflect—or, worse, perpetuate—historical
    discrimination. The way we use these tools in teams should also be fair to developers
    and other colleagues of varying levels and backgrounds. See [Chapter 4](ch04.html#ch04_beyond_the_70_maximizing_human_contribution_1752630043401362)
    for a discussion of the ethical implications of how AI tools are changing workplaces,
    especially for junior developers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，偏见和公平性是关于使用 vibe-coding 工具来生成对所有背景用户都公平的代码，并且不会反映——或者更糟，延续——历史歧视。我们在团队中使用这些工具的方式也应该对各种水平和背景的开发者和其他同事公平。参见[第4章](ch04.html#ch04_beyond_the_70_maximizing_human_contribution_1752630043401362)，讨论了
    AI 工具如何改变工作场所的道德影响，特别是对初级开发者的影响。
- en: Golden Rules for Responsible AI Use
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负责任使用 AI 的黄金法则
- en: 'Bringing together a lot of what we’ve covered, it’s worth articulating a set
    of responsible practices for vibe coding:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们讨论的许多内容综合起来，值得阐述一套 vibe coding 的负责任实践：
- en: '*Always keep a human in the loop.*'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*始终将人类纳入循环。*'
- en: 'Again: never let the AI work unsupervised. Responsible AI-assisted dev means
    you, the developer, are reviewing every line and making decisions, not deploying
    raw AI output without human validation.'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次强调：绝不要让 AI 无监督地工作。负责任的 AI 辅助开发意味着你，作为开发者，正在审查每一行并做出决定，而不是在没有人类验证的情况下部署原始 AI
    输出。
- en: '*Take responsibility for your code.*'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*对你的代码负责。*'
- en: If something goes wrong, it’s not the AI’s fault—it’s the development team’s
    responsibility. Keeping that mindset avoids complacency. Be prepared to justify
    your code, whether you wrote it from scratch or accepted AI code. If someone asks
    you, “Why does the code do this?” don’t say, “I don’t know; Copilot did that.”
    That’s why one of [Chapter 3](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933)’s
    golden rules is “Never commit code you don’t fully understand.” That’s responsible
    engineering.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果出现问题，这不是 AI 的错——这是开发团队的责任。保持这种心态可以避免自满。无论你是从头开始编写代码还是接受 AI 代码，都要准备好为自己的代码辩护。如果有人问你，“为什么代码会这样做？”不要说，“我不知道；Copilot
    做了那件事。”这就是为什么[第3章](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933)的黄金法则之一是“永远不要提交你不完全理解的代码。”这是负责任工程。
- en: '*Protect users’ privacy and ask for their consent.*'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*保护用户的隐私并征求他们的同意。*'
- en: Ethically, you owe it to users and your company to keep their secret data secret.
    When using AI tools, especially cloud-based ones, be careful not to expose sensitive
    data in your prompts or conversations. For instance, if you’re debugging an issue
    with a user database, don’t feed actual user records to ChatGPT. Use sanitized
    or synthetic data instead.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在道德上，你有责任保护用户的秘密数据。在使用 AI 工具时，尤其是基于云的工具时，要小心不要在提示或对话中暴露敏感数据。例如，如果你正在调试用户数据库的问题，不要将实际的用户记录输入到
    ChatGPT 中。使用清洗过的或合成的数据代替。
- en: Many tools now allow users (or at least business users) to opt out of having
    their input data used for training. If you’re an enterprise user, use those settings
    or use on-prem solutions for sensitive code. If you do feed any user data to a
    model, or if any AI functionality directly touches users (like a chatbot in your
    app that uses an LLM), get users’ consent and allow them to opt out if appropriate.
    A warning like “This feature uses an AI service; your input will be sent to it
    for processing” is transparent and lets privacy-conscious users decide for themselves.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 许多工具现在允许用户（至少是商业用户）选择不使用他们的输入数据用于训练。如果你是企业用户，使用那些设置或使用本地解决方案来处理敏感代码。如果你向模型提供了任何用户数据，或者如果任何
    AI 功能直接接触用户（例如，你的应用程序中使用的 LLM 的聊天机器人），获取用户的同意，并在适当的情况下允许他们选择退出。像“此功能使用 AI 服务；您的输入将被发送到它进行处理”这样的警告是透明的，并让对隐私敏感的用户自己做出决定。
- en: '*Comply with laws and regulations.*'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*遵守法律和法规。*'
- en: Keep an eye on legal requirements around AI, which are constantly evolving.
    For instance, data protection laws like the EU’s General Data Protection Regulation
    (GDPR) and AI Act consider some AI outputs as personal data if they include any
    personal data. Training a model on users’ data might require those users’ consent.
    Regulatory bodies may classify code generation as “general AI” and impose transparency
    or risk management obligations. Stay informed and work closely with your legal
    and compliance professionals to avoid breaking any regulations.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关注AI相关的法律要求，这些要求不断演变。例如，像欧盟的通用数据保护条例（GDPR）和AI法案这样的数据保护法律，如果AI输出包含任何个人数据，则将其视为个人数据。在用户数据上训练模型可能需要这些用户的同意。监管机构可能会将代码生成归类为“通用AI”，并强制执行透明度或风险管理义务。保持信息畅通，并与您的法律和合规专业人员密切合作，以避免违反任何规定。
- en: While this should go without saying, do not use AI to generate malware, exploit
    code without ethical justification, or automate unethical or illegal practices.^([2](ch09.html#id1062))
    While an AI could probably write a very effective phishing email or code injection
    attack, using it for that purpose violates ethics, the laws of most countries,
    and likely the AI’s terms of service. Focus on constructive use.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然这应该是不言而喻的，但不要使用AI生成恶意软件、未经道德正当性证明的代码，或自动化不道德或非法的行为。[2](ch09.html#id1062) 虽然AI可能能够编写非常有效的钓鱼邮件或代码注入攻击，但将其用于此目的违反了伦理、大多数国家的法律，以及可能违反AI的服务条款。专注于建设性的使用。
- en: '*Foster a responsible AI culture in your organization.*'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在您的组织中培养负责任的AI文化。*'
- en: If your team adopts vibe coding, encourage discussions about ethics and provide
    relevant ethics training. Consider having developers and code reviewers use a
    brief checklist like the one in [Figure 9-1](#ch09_figure_1_1752630044839745).
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您的团队采用情绪编码，鼓励关于伦理的讨论，并提供相关的伦理培训。考虑让开发人员和代码审查人员使用[图9-1](#ch09_figure_1_1752630044839745)中的简短清单。
- en: '![](assets/bevc_0901.png)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](assets/bevc_0901.png)'
- en: 'Figure 9-1\. Responsible AI development checklist: essential validation steps
    including intellectual property review, bias assessment, and security audits before
    integrating AI-generated code into production systems.'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-1\. 负责任的AI开发清单：在将AI生成的代码集成到生产系统之前，包括知识产权审查、偏见评估和安全审计等基本验证步骤。
- en: 'Everyone should feel responsible for ethical AI use; it’s a collective effort,
    not just the burden of the individual using the tool at any given moment. To formalize
    this, consider designating an “ethics champion” or a small ethics committee within
    your team or organization. This individual or group wouldn’t be the sole owner
    of ethics (as that responsibility remains shared), but they would take the lead
    on:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个人都应对AI的道德使用负责；这是一个集体努力，而不仅仅是任何时刻使用该工具的个人的负担。为了正式化这一点，考虑在您的团队或组织中指定一个“伦理倡导者”或一个小型的伦理委员会。这个个人或团体不会是伦理的唯一所有者（因为这种责任仍然是共享的），但他们会在以下方面带头：
- en: Staying abreast of the latest developments in AI ethics, emerging best practices,
    and new regulatory landscapes
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注AI伦理的最新发展、新兴的最佳实践和新的监管环境
- en: Facilitating discussions about ethical considerations in specific projects
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进关于特定项目中伦理考虑的讨论
- en: Championing the integration of ethical principles into the development lifecycle
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推动将伦理原则融入开发生命周期
- en: Helping to curate and disseminate relevant resources and training materials
    to the broader team
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助整理和传播相关的资源和培训材料给更广泛的团队
- en: Acting as a point of contact for team members who have ethical questions or
    concerns
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为有伦理问题或担忧的团队成员的联系人
- en: Since this field is moving incredibly fast, it’s crucial to work as a team to
    stay updated on new versions of AI tools and their capabilities, limitations,
    and evolving best practices for responsible use.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于这个领域发展极其迅速，与团队一起工作以保持对AI工具的新版本及其功能、限制和负责任使用的发展最佳实践的更新至关重要。
- en: 'Since this field is moving fast, work as a team to stay updated on new versions
    of AI tools and best practices. One important concept to integrate into your workflows
    is the use of model cards. *Model cards* are essentially standardized documents
    that provide transparency about a machine learning model. Think of them as nutrition
    labels for AI models. They typically include details about:'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于这个领域发展迅速，作为团队工作以保持对AI工具的新版本和最佳实践的更新至关重要。要整合到您的工作流程中的一个重要概念是使用模型卡。*模型卡*基本上是提供关于机器学习模型透明度的标准化文档。把它们想象成AI模型的营养标签。它们通常包括以下详细信息：
- en: What the model is, its version, and when it was developed
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的定义、版本以及开发时间
- en: The specific use cases the model was designed and tested for
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型设计和测试的具体用例
- en: Scenarios where the model should not be used, due to limitations or potential
    for harm
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于限制或潜在危害，模型不应使用的场景
- en: How well the model performs on various benchmarks, including evaluations for
    fairness and bias across different demographic groups
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在各种基准测试中的表现如何，包括对不同人口群体公平性和偏差的评估
- en: Information about the datasets used to train the model, including any known
    limitations or biases in the data
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练模型的数据库信息，包括数据中任何已知的局限性或偏差
- en: Potential risks and societal implications and any mitigation strategies employed
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在风险和社会影响以及采取的任何缓解策略
- en: Whenever you are using a pretrained model or evaluating a model for use, look
    for its model card. If you are fine-tuning or developing models, creating your
    own model cards is a best practice.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无论何时您在使用预训练模型或评估模型用于使用时，都要寻找其模型卡片。如果您正在微调或开发模型，创建自己的模型卡片是最佳实践。
- en: '*Create guardrails and safety nets.*'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*创建护栏和安全网。*'
- en: Practicing responsible design means that your AI-generated systems should have
    safety nets. For example, if AI suggests an out-of-bounds index fix that might
    mask an underlying issue, it’s better for the system to fail safely than to cause
    silent errors. If an AI-generated recommendation system might be wrong, providing
    ways for users to correct or override it shows respect for their human agency.
    Strive to build systems that degrade gracefully if AI components misbehave.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实践负责任的设计意味着您的AI生成系统应该有安全网。例如，如果AI建议一个超出范围的索引修复，可能会掩盖潜在问题，那么系统安全失败比造成静默错误更好。如果一个AI生成的推荐系统可能是错误的，提供用户纠正或覆盖它的方法表明对他们的自主权的尊重。努力构建在AI组件行为不当时能够优雅降级的系统。
- en: '*Document AI usage decisions within your team.*'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在您的团队中记录文档化的AI使用决策。*'
- en: 'Keep an internal log of why you used certain AI suggestions (or didn’t): “We
    tried AI for module X, but it tended to produce too much duplicate code, so we
    wrote that part manually.” This can help you refine your processes, provide context
    to new team members about AI’s role in the codebase’s history, and augment your
    team’s collective memory. It can also be useful during audits.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记录您使用某些AI建议（或未使用）的原因：“我们尝试使用AI进行模块X，但它倾向于产生过多的重复代码，所以我们手动编写了那部分。”这可以帮助您完善流程，向新团队成员提供关于AI在代码库历史中的作用的背景信息，并增强团队的集体记忆。在审计期间也可能很有用。
- en: '*Proactively work to avoid bias, discrimination, and unfairness.*'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*积极努力避免偏见、歧视和不公平。*'
- en: Be vigilant for signs that your AI usage could lead to discrimination, and work
    to avoid such situations before they happen. For example, if your app is global,
    is your AI multilingual or does it favor those who speak English? Do all of your
    team members have equal access to AI tools and training?
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保持警惕，注意您的AI使用可能导致歧视的迹象，并在这些情况发生之前努力避免。例如，如果您的应用是全球性的，您的AI是否是多语言的，或者它是否偏袒讲英语的人？您的团队成员是否都能平等地访问AI工具和培训？
- en: As the AI landscape continues changing and growing, the software industry is
    likely to introduce AI standards or certifications. It’s early, but your company
    could even help shape those guidelines by engaging in standardization efforts,
    like IEEE or ISO working groups on AI software engineering. Ethically, it’s better
    for the dev community to help set the rules than to leave it solely to regulators
    or the courts.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI领域的持续变化和增长，软件行业可能会引入AI标准或认证。虽然还处于早期阶段，但您的公司可以通过参与标准化工作，如IEEE或ISO的AI软件工程工作组，甚至可以帮助塑造这些指南。从伦理的角度来看，开发社区帮助制定规则比完全由监管机构或法院制定更好。
- en: Summary and Next Steps
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要和下一步行动
- en: 'Responsible vibe coding means integrating AI into the software development
    lifecycle in a way that respects all stakeholders: original creators (by respecting
    their IP), colleagues (through transparency and fairness), users (through privacy,
    security, and fairness in outcomes), and society (by not letting misuse cause
    harm). It’s about leveraging AI’s strengths while diligently guarding against
    its weaknesses.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任的设计意味着将AI集成到软件开发生命周期中，以尊重所有利益相关者：原始创作者（通过尊重其知识产权）、同事（通过透明度和公平性）、用户（通过隐私、安全和公平的结果）、以及社会（通过不让滥用造成伤害）。这是关于利用AI的优势，同时勤奋地防范其弱点。
- en: I’ve often said that vibe coding is not an excuse for low-quality work. It’s
    not an excuse for ethical shortcuts either. As the humans in charge, developers
    must ensure that speed doesn’t compromise values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我经常说，氛围编码不是低质量工作的借口。它也不是道德捷径的借口。作为负责的人类，开发者必须确保速度不会损害价值观。
- en: 'Next, [Chapter 10](ch10.html#ch10_autonomous_background_coding_agents_1752630045087844)
    looks at a new technology that’s changing the way we work with AI models: autonomous
    coding agents.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，[第10章](ch10.html#ch10_autonomous_background_coding_agents_1752630045087844)探讨了正在改变我们与AI模型合作方式的新技术：自主编码代理。
- en: ^([1](ch09.html#id1032-marker)) Case information can often be found on [court
    dockets](https://oreil.ly/BdDiV), like those for the US District Court for the
    Northern District of California and the Ninth Circuit Court of Appeals, or through
    [legal news outlets and case trackers](https://oreil.ly/AZrc-).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09.html#id1032-marker)) 案件信息通常可以在[法庭案卷](https://oreil.ly/BdDiV)中找到，例如美国加利福尼亚北部地区地方法院和第九巡回上诉法院的案卷，或者通过[法律新闻机构和案例追踪器](https://oreil.ly/AZrc-)。
- en: ^([2](ch09.html#id1062-marker)) There are some ethically justified exceptions.
    Penetration testers and security researchers can ethically use AI to find vulnerabilities
    that should be fixed, as long as they work under responsible disclosure protocols.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch09.html#id1062-marker)) 存在一些在道德上可以接受的例外情况。渗透测试员和安全研究人员可以在负责任的披露协议下，道德地使用AI来发现应该修复的漏洞。
