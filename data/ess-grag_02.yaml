- en: 3 Advanced vector retrieval strategies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 高级向量检索策略
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Query rewriting techniques
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询重写技术
- en: Advanced text-embedding strategies
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级文本嵌入策略
- en: Implementing parent document retrieval
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现父文档检索
- en: In chapter 2 of this book, you learned about the basics of text embeddings and
    vector similarity search. By converting text into numerical vectors, you have
    seen how machines can understand the semantic meaning of content. Combining text-embedding
    and vector similarity search techniques allows for optimized and accurate retrieval
    of relevant unstructured text from vast amounts of documents, enabling more accurate
    and up-to-date answers in RAG applications. Suppose you have implemented and deployed
    a RAG application as described in chapter 2\. After some testing, you and the
    users of the RAG application noticed that the accuracy of the generated answers
    is lacking due to incomplete or irrelevant information in the retrieved documents.
    Consequently, you have been assigned the task of enhancing the retrieval system
    to improve the accuracy of the generated answers.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第二章中，你学习了文本嵌入和向量相似度搜索的基础知识。通过将文本转换为数值向量，你看到了机器如何理解内容的语义意义。结合文本嵌入和向量相似度搜索技术，可以从大量文档中优化并准确地检索相关非结构化文本，从而在RAG应用中提供更准确和更新的答案。假设你已经按照第二章的描述实现了并部署了一个RAG应用。经过一些测试后，你和RAG应用的用户注意到，由于检索到的文档中存在不完整或不相关信息，生成的答案的准确性不足。因此，你被分配了增强检索系统以提高生成答案准确性的任务。
- en: As with any technology, the basic implementations of text embeddings and vector
    similarity search can produce insufficient retrieval accuracy and recall. The
    embeddings generated from a user’s query might not always align closely with those
    of documents containing the crucial information needed due to differences in terminology
    or context. This discrepancy can lead to situations where documents highly relevant
    to the query’s intent are overlooked, as the embedding representation of the query
    does not capture the essence of the information sought.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何技术一样，文本嵌入和向量相似度搜索的基本实现可能无法产生足够的检索准确性和召回率。由于术语或上下文的不同，从用户查询生成的嵌入可能并不总是与包含所需关键信息的文档的嵌入紧密对齐。这种差异可能导致与查询意图高度相关的文档被忽视，因为查询的嵌入表示未能捕捉到所寻求信息的本质。
- en: One strategy to improve the retrieval accuracy and recall is to rewrite the
    query used to find relevant documents. The query-rewriting approach aims to bridge
    the gap between the user’s query and the information-rich documents by reformulating
    the query in a way that better aligns with the language and context of the target
    documents. This query refinement improves the chances of finding documents containing
    relevant information, thereby enhancing the accuracy of responses to the original
    query. Examples of query-rewriting strategies are hypothetical document retriever
    (Gao et al., 2022) or step-back prompting (Zheng et al., 2023). The step-back
    prompting strategy is visualized in figure 3.1\.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提高检索准确性和召回率的一种策略是重写用于查找相关文档的查询。查询重写方法旨在通过以更好地符合目标文档的语言和上下文的方式重构查询，来弥合用户查询和信息丰富的文档之间的差距。这种查询细化提高了找到包含相关信息的文档的机会，从而提高了对原始查询的响应的准确性。查询重写策略的例子有假设性文档检索器（Gao
    et al., 2022）或回退提示（Zheng et al., 2023）。回退提示策略在图3.1中进行了可视化。
- en: '![figure](../Images/3-1.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-1.png)'
- en: Figure 3.1 Query rewriting by using the step-back technique to increase the
    vector retrieval accuracy
  id: totrans-9
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.1 使用回退技术进行查询重写以提高向量检索准确度
- en: Figure 3.1 outlines a process where a user’s query is transformed to improve
    document retrieval outcomes, a technique known as *step-back prompting*. In the
    scenario presented, the user poses a detailed question regarding Estella Leopold’s
    educational history during a specific timeframe. This initial question is then
    processed by a language model such as GPT-4 with query-rewriting capabilities,
    which rephrases it into a more general inquiry about Estella Leopold’s educational
    background. The purpose of this step is to cast a wider net during the search
    process, as the rewritten query is more likely to align with a range of documents
    that may contain the required information.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1概述了一个过程，其中用户的查询被转换以改善文档检索结果，这种技术被称为*回退提示*。在所提出的场景中，用户就埃斯特拉·利奥波德在特定时间段内的教育历史提出了一个详细的问题。然后，这个初始问题被一个具有查询重写能力的语言模型（如GPT-4）处理，将其改写为一个更一般的问题，关于埃斯特拉·利奥波德的教育背景。这一步骤的目的是在搜索过程中撒更宽的网，因为重写的查询更有可能与可能包含所需信息的各种文档相匹配。
- en: Another way to improve retrieval accuracy is by changing the document embedding
    strategy. In the previous chapter, you embedded a section of text, retrieved that
    same text, and used it as input to an LLM to generate an answer. However, vector
    retrieval systems are flexible, as you’re not limited to embedding the exact text
    you plan to retrieve. Instead, you can embed content that better represents the
    document’s meaning, such as more contextually relevant sections, synthetic questions,
    or paraphrased versions. These alternatives can better capture key ideas and themes,
    resulting in more accurate and relevant retrieval. Two examples of advanced embedding
    strategies are shown in figure 3.2\.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 提高检索准确性的另一种方法是改变文档嵌入策略。在上一章中，你嵌入了一段文本，检索了相同的文本，并将其作为输入到LLM（大型语言模型）中生成答案。然而，向量检索系统是灵活的，因为你不仅限于嵌入你计划检索的确切文本。相反，你可以嵌入更好地代表文档意义的文本，例如更具情境相关性的部分、合成问题或改写版本。这些替代方案可以更好地捕捉关键思想和主题，从而实现更准确和相关的检索。图3.2展示了两个高级嵌入策略的示例。
- en: '![figure](../Images/3-2.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-2.png)'
- en: Figure 3.2 Hypothetical question and parent document retriever strategies
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.2 假设性问题与父文档检索策略
- en: The left side of figure 3.2 demonstrates the hypothetical question strategy.
    With the hypothetical question–embedding strategy, you must determine the questions
    the information in the document can answer. For example, you could use an LLM
    to generate hypothetical questions, or you could use the conversation history
    of your chatbot to come up with the questions a document can answer. The idea
    is that instead of embedding the original document itself, you embed the questions
    the document can answer. For instance, the question “What did Leopold study at
    the University of California?” is encoded by the vector `[1,2,3,0,5]` in figure
    3.2\. When a user poses a question, the system computes the query’s embedding
    and searches for the nearest neighbors among the precomputed question embeddings.
    The goal is to locate questions that closely match and are semantically similar
    to the user question. The system then retrieves the documents that contain the
    information that can answer these similar questions. In essence, the hypothetical
    question–embedding strategy involves embedding potential questions a document
    can answer and using these embeddings to match and retrieve relevant documents
    in response to user queries.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2的左侧展示了假设性问题策略。在假设性问题-嵌入策略中，你必须确定文档中的信息可以回答的问题。例如，你可以使用LLM生成假设性问题，或者你可以使用你的聊天机器人的对话历史来提出文档可以回答的问题。其想法是，而不是嵌入原始文档本身，你嵌入文档可以回答的问题。例如，图3.2中用向量
    `[1,2,3,0,5]` 编码的问题“利奥波德在加州大学学习了什么？”当用户提出问题时，系统计算查询的嵌入并搜索预计算的查询嵌入中的最近邻。目标是定位与用户问题密切匹配且语义相似的问题。然后，系统检索包含可以回答这些相似问题的信息的文档。本质上，假设性问题-嵌入策略涉及嵌入文档可以回答的潜在问题，并使用这些嵌入来匹配和检索用户查询的相关文档。
- en: The right side of figure 3.2 illustrates the parent document–embedding strategy.
    In this approach, the original document—referred to as the parent—is split into
    smaller units called *child chunks*, typically based on a fixed token count. Instead
    of embedding the entire parent document as a single unit, you compute a separate
    embedding for each child chunk. For example, the chunk “Leopold attained her master’s
    in botany” might be embedded as the vector `[1,` `0,` `3,` `0,` `1]`. When a user
    submits a query, the system compares it against these child embeddings to find
    the most relevant matches. However, rather than returning only the matched chunk,
    the system retrieves the entire original parent document associated with it. This
    allows the language model to operate with the full context of the information,
    increasing the chances of generating accurate and complete answers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2的右侧说明了父文档-嵌入策略。在这种方法中，原始文档—被称为父文档—被拆分成更小的单元，称为*子块*，通常基于固定的标记计数。不是将整个父文档作为一个单一单元嵌入，而是为每个子块计算一个单独的嵌入。例如，块“Leopold获得了她的植物学硕士学位”可能被嵌入为向量
    `[1,` `0,` `3,` `0,` `1]`。当用户提交查询时，系统将其与这些子嵌入进行比较，以找到最相关的匹配。然而，系统不仅返回匹配的块，还检索与它关联的整个原始父文档。这允许语言模型在完整的信息上下文中操作，增加了生成准确和完整答案的机会。
- en: 'This strategy addresses a common limitation of embedding long documents: when
    you embed the full parent document, the resulting vector can blur distinct ideas
    through averaging, making it harder to match specific queries effectively. By
    contrast, splitting the document into smaller chunks allows for more precise matching
    while still enabling the system to return the full context when needed.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略解决了嵌入长文档的常见限制：当你嵌入完整的父文档时，结果向量可能会通过平均模糊不同的观点，使得有效地匹配特定查询变得困难。相比之下，将文档拆分成更小的块可以允许更精确的匹配，同时仍然在需要时使系统能够返回完整的上下文。
- en: Other strategies to improve retrieval accuracy
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 其他提高检索准确性的策略
- en: 'Beyond changing the document-embedding strategy, several other techniques can
    enhance retrieval accuracy:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除了改变文档嵌入策略之外，还有其他几种技术可以增强检索准确性：
- en: '*Finetuning the text-embedding model*—By adjusting the embedding model on domain-specific
    data, you can improve its ability to capture the context of user queries, leading
    to a closer semantic match with relevant documents. Note that finetuning typically
    requires more compute and infrastructure. In addition, once the model is updated,
    all existing document embeddings must be recomputed to reflect the changes—this
    can be resource intensive for large document repositories.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*微调文本嵌入模型*—通过在特定领域的数据上调整嵌入模型，你可以提高其捕捉用户查询上下文的能力，从而与相关文档实现更接近的语义匹配。请注意，微调通常需要更多的计算和基础设施。此外，一旦模型更新，所有现有的文档嵌入都必须重新计算以反映这些变化—对于大型文档库来说，这可能非常耗费资源。'
- en: '*Reranking strategies*—After an initial set of documents is retrieved, reranking
    algorithms can reorder them based on relevance to the user’s intent. This second
    pass often uses more complex models or scoring heuristics to refine the results.
    Reranking helps surface the most relevant content even if the initial match was
    suboptimal.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重排序策略*—在检索到一组初始文档后，重排序算法可以根据用户意图的相关性对它们进行重新排序。这一轮处理通常使用更复杂的模型或评分启发式方法来细化结果。重排序有助于揭示最相关的内容，即使初始匹配不是最优的。'
- en: '*Metadata-based contextual filtering*—Many documents contain structured metadata
    such as authorship, publication date, topic tags, or source type. Applying filters
    based on this metadata—either manually or as part of the retrieval pipeline—can
    significantly narrow the candidate documents before semantic'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于元数据的上下文过滤*—许多文档包含结构化元数据，如作者、发布日期、主题标签或来源类型。根据这些元数据应用过滤器—无论是手动还是作为检索流程的一部分—可以在语义分析之前显著缩小候选文档的范围。'
- en: matching, increasing precision. For example, a query about recent policy updates
    can be restricted to documents published within the last year.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配，提高精确度。例如，关于最近政策更新的查询可以限制在去年发布的文档中。
- en: '*Hybrid retrieval (keyword + dense vector search)*—Combining sparse retrieval
    (e.g., keyword-based search) with dense vector retrieval (semantic search) offers
    the best of both worlds. Keyword search excels at precise matches and rare terms,
    while dense retrieval captures the broader meaning. Hybrid systems can merge and
    rerank results from both methods to maximize both recall and precision.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*混合检索（关键词+密集向量搜索）*—结合稀疏检索（例如，基于关键词的搜索）和密集向量检索（语义搜索）可以兼得两者之长。关键词搜索擅长精确匹配和罕见术语，而密集检索则捕捉更广泛的意义。混合系统可以合并和重新排序两种方法的结果，以最大化召回率和精确率。'
- en: While all these strategies can improve retrieval quality, detailed implementation
    guidance is beyond the scope of this book, except for hybrid retrieval, which
    was introduced in chapter 2.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然所有这些策略都可以提高检索质量，但详细的实现指南超出了本书的范围，除了混合检索，这在第2章中已介绍。
- en: 'In the remainder of this chapter, we’ll move from concepts to code and walk
    through the implementation step by step. To follow along, you’ll need access to
    a running, blank Neo4j instance. This can be a local installation or a cloud-hosted
    instance; just make sure it’s empty. You can follow the implementation directly
    in the accompanying Jupyter notebook available here: [https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch03.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch03.ipynb).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将从概念转向代码，逐步介绍实现过程。为了跟上，你需要访问一个运行中的空白Neo4j实例。这可以是一个本地安装或云托管实例；只需确保它是空的。你可以直接在附带的Jupyter笔记本中跟随实现，笔记本地址为：[https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch03.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch03.ipynb)。
- en: Imagine you’ve implemented the basic RAG system from chapter 2, but the retrieval
    accuracy wasn’t quite good enough. The responses lacked relevance or missed important
    context, and you suspect the system isn’t retrieving the most useful documents
    to support high-quality answers. To address this, you’ve decided to enhance the
    existing RAG pipeline by adding a step-back prompting step to improve the quality
    of the query itself. Additionally, you’ll switch from the basic retriever to a
    parent document retriever strategy. This approach enables more granular and accurate
    information retrieval by matching on smaller chunks while still providing the
    full parent document as context.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你已经实现了第2章中的基本RAG系统，但检索准确性还不够高。响应缺乏相关性或遗漏了重要背景，你怀疑系统没有检索到最有用的文档来支持高质量的答案。为了解决这个问题，你决定通过添加回溯提示步骤来提高查询本身的质量，以增强现有的RAG管道。此外，你将切换到父文档检索策略。这种方法通过匹配更小的块来提供更精细和准确的检索，同时仍然提供完整的父文档作为背景。
- en: These improvements aim to boost both the relevance of retrieved content and
    the overall accuracy of the generated answers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这些改进旨在提高检索内容的关联性和生成答案的整体准确性。
- en: 3.1 Step-back prompting
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 回溯提示
- en: 'As mentioned, step-back prompting is a query-rewriting technique that aims
    to improve the accuracy of vector retrieval. An example from the original paper
    (Zheng et al., 2023) demonstrates this process: the specific query “Which team
    did Thierry Audel play for from 2007 to 2008?” is broadened to “Which teams did
    Thierry Audel play for in his career?” to improve vector search precision and
    consequently the accuracy of the generated answers. By transforming a detailed
    question into a broader, high-level query, step-back prompting reduces the complexity
    of the vector search process. The idea is that broader queries typically encompass
    a more comprehensive range of information, making it easier for the model to identify
    relevant facts without getting bogged down by the specifics.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，回溯提示是一种查询重写技术，旨在提高向量检索的准确性。原始论文（Zheng等人，2023年）中的一个例子展示了这一过程：具体查询“Thierry
    Audel在2007年至2008年间为哪支球队效力？”被扩展为“Thierry Audel在其职业生涯中为哪些球队效力？”以提高向量搜索的精确性，从而提高生成答案的准确性。通过将详细问题转化为更广泛、更高层次查询，回溯提示简化了向量搜索过程。其理念是，更广泛的查询通常包含更全面的信息范围，这使得模型更容易识别相关事实，而不会因具体细节而陷入困境。
- en: The authors used an LLM for the query rewriting task, as shown in figure 3.3.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用了LLM进行查询重写任务，如图3.3所示。
- en: '![figure](../Images/3-3.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-3.png)'
- en: Figure 3.3 Rewriting queries using the step-back approach with an LLM
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.3 使用LLM的回溯方法重写查询
- en: LLMs are an excellent fit for query-rewriting tasks as they excel at natural
    language comprehension and generation. You don’t have to train or finetune a new
    model for each task. Instead, you can provide task instructions in the input prompt.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 对于查询重写任务非常适用，因为它们在自然语言理解和生成方面表现出色。你不需要为每个任务训练或微调新的模型。相反，你可以在输入提示中提供任务指令。
- en: The authors of the step-back prompting paper used the system prompt in the following
    listing to instruct the LLM on how to rewrite the input query.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 回退提示论文的作者使用了以下列表中的系统提示来指导 LLM 如何重写输入查询。
- en: Listing 3.1 System prompt of an LLM for generating step-back questions
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.1 LLM 生成回退问题的系统提示
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Query rewriting instructions'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 查询重写指令'
- en: '#2 Few-shot examples'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 少样本示例'
- en: The system prompt in listing 3.1 begins by giving the LLM a simple instruction
    to rewrite a user’s question into a more generic, step-back version. On its own,
    this kind of instruction is known as *zero-shot prompting*, which relies solely
    on the LLM’s general capabilities and understanding of the task, without providing
    any examples. However, to guide the model more effectively and ensure consistent
    results, the authors chose to expand the prompt with several examples of the desired
    paraphrasing behavior. This technique is called *few-shot prompting*, where a
    small number of examples (typically two to five) are included in the prompt to
    illustrate the task. Few-shot prompting helps the LLM better understand the expected
    transformation by anchoring it in concrete instances, improving the quality and
    reliability of the output.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.1 中的系统提示首先给 LLM 一个简单指令，将用户的提问重写为一个更通用的、回退版本。这种指令本身被称为 *零样本提示*，它完全依赖于 LLM
    的一般能力和对任务的了解，而不提供任何示例。然而，为了更有效地引导模型并确保结果的一致性，作者选择通过几个期望释义行为的示例来扩展提示。这种技术被称为 *少样本提示*，其中在提示中包含少量示例（通常是两到五个）来展示任务。少样本提示通过将任务锚定在具体实例中，有助于
    LLM 更好地理解预期的转换，从而提高输出质量和可靠性。
- en: To achieve the query rewriting, all you need to do is send the system prompt
    found in listing 3.1 along with the user’s question to an LLM. The specific function
    for this task is outlined in the next listing.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现查询重写，你只需要将列表 3.1 中的系统提示与用户的提问一起发送给 LLM。这个任务的特定功能将在下一个列表中概述。
- en: Listing 3.2 Function to generate a step-back question
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.2 生成回退问题的函数
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can now test the step-back prompt generation by executing the code shown
    next.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以通过执行下面的代码来测试回退提示生成。
- en: Listing 3.3 Executing the step-back prompt function
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.3 执行回退提示函数
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The results in listing 3.3 demonstrate a successful execution of the step-back
    prompt generation function. By transforming the specific query about Thierry Audel’s
    team from 2007 to 2008 into a broader question regarding his entire career history,
    the function effectively broadens the context and should increase the retrieval
    accuracy and recall.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.3 中的结果展示了回退提示生成函数的成功执行。通过将关于 Thierry Audel 2007 年至 2008 年团队的特定查询转换为关于他整个职业生涯的更广泛问题，该函数有效地扩展了上下文，并应提高检索准确性和召回率。
- en: Exercise 3.1
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 3.1
- en: To explore the step-back prompt generation’s effectiveness, try applying it
    to various questions and observe how it broadens the context. You can also change
    the system prompt to observe how it affects the output.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索回退提示生成的有效性，尝试将其应用于各种问题，并观察它如何扩展上下文。你还可以更改系统提示，观察它如何影响输出。
- en: 3.2 Parent document retriever
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 父文档检索器
- en: The parent document retriever strategy involves dividing a large document into
    smaller sections, calculating embeddings for each section rather than the whole
    document, and using these embeddings to match user queries more accurately, ultimately
    retrieving the entire document for context-rich responses. However, as you cannot
    feed the whole PDF directly to the LLM, you first need to split the PDF into parent
    documents and then further divide those parent documents into child documents
    for embedding and retrieval. The graph representation of the parent and child
    documents is shown in figure 3.4\.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 父文档检索策略涉及将大文档分成更小的部分，计算每个部分的嵌入而不是整个文档，并使用这些嵌入来更准确地匹配用户查询，最终检索整个文档以提供丰富的上下文响应。然而，由于你不能直接将整个
    PDF 输入到 LLM 中，你首先需要将 PDF 分成父文档，然后将这些父文档进一步分成子文档进行嵌入和检索。父文档和子文档的图表示如图 3.4 所示。
- en: '![figure](../Images/3-4.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-4.png)'
- en: Figure 3.4 Parent document graph representation
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.4 父文档图表示
- en: Figure 3.4 illustrates a graph-based approach to storing and organizing documents
    for the parent document retrieval strategy. At the top, a PDF node represents
    the entire document, labeled with a title and an identifier. This node is connected
    to several parent document nodes. You will use a 2,000-character limit to split
    the PDF into parent documents in this example. These parent document nodes are,
    in turn, linked to child document nodes, with each child node containing a 500-character
    chunk of the corresponding parent node text. The child nodes have an embedding
    vector representing the child chunk of the text for retrieval purposes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 展示了一种基于图的方法来存储和组织文档，以实现父文档检索策略。在顶部，一个 PDF 节点代表整个文档，带有标题和标识符。此节点连接到多个父文档节点。在这个例子中，你将使用
    2,000 个字符的限制来分割 PDF 成父文档。这些父文档节点反过来又连接到子文档节点，每个子节点包含对应父节点文本的 500 个字符块。子节点有一个表示文本子块的嵌入向量，用于检索目的。
- en: We will be using the same text as in chapter 2, which is a paper titled “Einstein’s
    Patents and Inventions” by Asis Kumar Chaudhuri ([https://arxiv.org/abs/1709.00666](https://arxiv.org/abs/1709.00666)).
    Additionally, when segmenting a document into smaller parts for processing, it
    is best to start by splitting the text based on structural elements like paragraphs
    or sections. This approach maintains the coherence and context of the content,
    as paragraphs or sections typically encapsulate complete ideas or topics. Therefore,
    we will start by splitting the PDF text into sections.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与第 2 章相同的文本，这是一篇由 Asis Kumar Chaudhuri 撰写的论文，标题为“爱因斯坦的专利和发明”（[https://arxiv.org/abs/1709.00666](https://arxiv.org/abs/1709.00666)）。此外，在将文档分割成更小的部分进行处理时，最好首先根据结构元素如段落或章节来分割文本。这种方法保持了内容的连贯性和上下文，因为段落或章节通常封装了完整的思想或主题。因此，我们将首先将
    PDF 文本分割成章节。
- en: Listing 3.4 Splitting the text into sections with a regular expression
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.4 使用正则表达式将文本分割成章节
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `split_text_by_titles` function in listing 3.4 uses a regular expression
    to split the text by sections. The regular expression is based on the fact that
    sections in the text are organized as a numbered list, where each new section
    starts with a number and an optional character, followed by a dot and the section
    title. The output of the `split_ text_by_titles` function is nine sections. If
    you check the PDF, you will notice only four main sections. However, there are
    also four subsections (3A–3D) describing some of the patents, and if you count
    the introduction abstract as its own section, you get a total of nine sections.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 3.4 中的 `split_text_by_titles` 函数使用正则表达式按章节分割文本。该正则表达式基于这样一个事实，即文本中的章节组织为一个编号列表，其中每个新的章节以一个数字和一个可选字符开始，后跟一个点和章节标题。`split_text_by_titles`
    函数的输出是九个章节。如果你检查 PDF，你会注意到只有四个主要章节。然而，还有四个子章节（3A–3D）描述了一些专利，如果你将引言摘要视为一个单独的章节，那么总共是九个章节。
- en: Before continuing with the parent document retriever, you will count the number
    of tokens per section to better understand their length. You will use the `tiktoken`,
    a package developed by OpenAI, to count the number of tokens in a given text.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续使用父文档检索器之前，你需要计算每个章节的标记数，以便更好地理解它们的长度。你将使用由 OpenAI 开发的 `tiktoken` 包来计算给定文本中的标记数。
- en: Listing 3.5 Counting the number of tokens in sections
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.5 计算章节中的标记数
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Most sections have a relatively small size of up to 600 tokens, which fits most
    LLM context prompts. However, the third section has over 4,000 tokens, which could
    lead to token limit errors during LLM generation. Therefore, you must split the
    sections into parent documents, where each document has at most 2,000 characters.
    You will use the `chunk_text` from the previous chapter to achieve this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数章节的大小相对较小，最多 600 个标记，这适合大多数 LLM 上下文提示。然而，第三章节有超过 4,000 个标记，这可能导致在 LLM 生成过程中的标记限制错误。因此，你必须将章节分割成父文档，其中每个文档最多有
    2,000 个字符。你将使用上一章的 `chunk_text` 来实现这一点。
- en: Listing 3.6 Splitting sections into parent documents of max size of 2,000 characters
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.6 将章节分割成最大长度为 2,000 个字符的父文档
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Exercise 3.2
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 3.2
- en: Use the `num_tokens_from_string` function to determine the token count of each
    parent document. The token count can help you decide about additional steps in
    the preprocessing. For instance, longer sections that exceed a reasonable token
    count should be split further. On the other hand, if some segments are exceptionally
    brief, consisting of 20 tokens or fewer, you should consider eliminating them
    entirely as they might not add any information value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`num_tokens_from_string`函数确定每个父文档的标记数。标记数可以帮助您决定预处理中的额外步骤。例如，超过合理标记数的较长的部分应进一步拆分。另一方面，如果某些部分异常简短，包含20个标记或更少，您应考虑完全删除它们，因为它们可能不会增加任何信息价值。
- en: Instead of splitting the child chunks and importing them in a subsequent step,
    you will perform the splitting and the import in a single step. Performing the
    two operations in a single step allows you to skip slightly more complex data
    structures storing intermediate results. Before importing the graph, you need
    to define the import Cypher statement. The Cypher statement to import the parent
    document structure is relatively straightforward.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是在后续步骤中拆分子块并导入它们，您将一次性执行拆分和导入操作。在单个步骤中执行这两个操作允许您跳过稍微复杂一些的存储中间结果的中间数据结构。在导入图之前，您需要定义导入Cypher语句。导入父文档结构的Cypher语句相对简单。
- en: Listing 3.7 Cypher query used to import the parent document strategy graph
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.7 用于导入父文档策略图的Cypher查询
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Merges PDF node based on the id property'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 根据id属性合并PDF节点'
- en: '#2 Merges Parent node and set its text property'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 合并父节点并设置其文本属性'
- en: '#3 Merges multiple Child nodes for each Parent node'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 合并每个父节点的多个子节点'
- en: The Cypher statement in listing 3.7 starts by merging a `PDF` node. Next, it
    merges the `Parent` node using a unique ID. The `Parent` node is then linked to
    the `PDF` node through a `HAS_PARENT` relationship and has the `text` property
    set. Lastly, it iterates over a list of child documents. It creates a `Child`
    node for each element in the list, sets the text and embedding properties, and
    links it to its `Parent` node with a `HAS_CHILD` relationship.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.7中的Cypher语句首先合并一个`PDF`节点。接下来，它使用唯一ID合并`Parent`节点。然后，`Parent`节点通过`HAS_PARENT`关系链接到`PDF`节点，并设置`text`属性。最后，它遍历子文档列表。为列表中的每个元素创建一个`Child`节点，设置文本和嵌入属性，并通过`HAS_CHILD`关系将其链接到其`Parent`节点。
- en: Now that everything is prepared, you can import the parent document structure
    into the graph database.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切准备就绪，您可以将父文档结构导入到图数据库中。
- en: Listing 3.8 Importing the parent document data into the graph database
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.8 将父文档数据导入到图数据库中
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Splits the parent documents into child chunks'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将父文档拆分为子块'
- en: '#2 Calculates text embeddings for child chunks'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 计算子块的文本嵌入'
- en: '#3 Imports into Neo4j'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 导入到Neo4j'
- en: The code in listing 3.8 starts by iterating over the parent document chunks.
    Each parent document chunk is divided into multiple child chunks using the `chunk_text`
    function. The code then calculates text embeddings for these child chunks with
    the `embed` function. Following the embedding generation, the `execute_query`
    method imports the data into a Neo4j graph database.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.8中的代码首先遍历父文档块。每个父文档块使用`chunk_text`函数拆分为多个子块。然后，代码使用`embed`函数计算这些子块的文本嵌入。在嵌入生成之后，`execute_query`方法将数据导入到Neo4j图数据库中。
- en: You can examine the generated graph structure by running the Cypher statement
    shown in the following listing in Neo4j Browser.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在Neo4j浏览器中运行以下列表中的Cypher语句来检查生成的图结构。
- en: Listing 3.9 Create a vector index on child nodes
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.9 在子节点上创建向量索引
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The Cypher statement in listing 3.9 produces the graph shown in figure 3.5\.
    This graph visualization depicts a central PDF node connected to several parent
    nodes, illustrating the hierarchical relationship between the document and its
    sections. Each parent node is further linked to multiple child nodes, indicating
    the breakdown of sections into smaller chunks within the document structure.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.9中的Cypher语句生成了图3.5所示的图。此图可视化显示了一个中心PDF节点连接到多个父节点，说明了文档与其部分之间的层次关系。每个父节点进一步连接到多个子节点，表明文档结构中将部分拆分为更小的块。
- en: To ensure efficient comparison of document embeddings, you will add a vector
    index.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保文档嵌入的有效比较，您将添加一个向量索引。
- en: Listing 3.10 Creating a vector index on child nodes
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.10 在子节点上创建向量索引
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The code to generate the vector index in listing 3.10 is identical to the one
    used in chapter 2\. Here, you created a vector index on the `embedding` property
    of the `Child`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.10中生成向量索引的代码与第2章中使用的代码相同。在这里，你在`Child`的`embedding`属性上创建了一个向量索引。
- en: '![figure](../Images/3-5.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-5.png)'
- en: Figure 3.5 Graph visualization of part of the imported data in Neo4j Browser
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.5 Neo4j浏览器中导入数据的一部分的图可视化
- en: 3.2.1 Retrieving parent document strategy data
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 检索父文档策略数据
- en: After importing the data and defining the vector index, you can focus on implementing
    the retrieval part. To retrieve relevant documents from the graph, you must define
    the retrieval Cypher statement described in the following listing.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入数据和定义向量索引后，你可以专注于实现检索部分。要从图中检索相关文档，你必须定义以下列表中描述的检索Cypher语句。
- en: Listing 3.11 Parent document retrieval Cypher statement
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.11 父文档检索Cypher语句
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Vector index search'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 向量索引搜索'
- en: '#2 Traverses to parent documents'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 遍历到父文档'
- en: '#3 Deduplicates parent documents'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 去重父文档'
- en: '#4 Ensures final limit'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 确保最终限制'
- en: The Cypher statement in listing 3.11 starts by executing a vector-based search
    within a graph database to identify child nodes closely aligned with a specified
    question embedding. You can see that we retrieve `k` `*` `4` documents in the
    initial vector search. The reason for using the `k` `*` `4` value in the initial
    vector search is that you anticipate a scenario where multiple similar child nodes
    from the vector search may actually belong to the same parent document. Therefore,
    it becomes crucial to deduplicate the parent documents. Without deduplication,
    the result set could include multiple entries for the same parent document, each
    corresponding to a different child node of that parent. However, to guarantee
    a final count of `k` unique parent documents, you start with a larger pool of
    `k` `*` `4` child nodes, effectively creating a safety buffer. In the end of the
    Cypher statement, you enforce the final `k` limit.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.11中的Cypher语句首先在图数据库中执行基于向量的搜索，以识别与指定问题嵌入紧密相关的子节点。你可以看到，在初始向量搜索中我们检索了`k`
    `*` `4`个文档。在初始向量搜索中使用`k` `*` `4`值的原因是，你预计会有多个来自向量搜索的相似子节点实际上属于同一个父文档。因此，去重父文档变得至关重要。如果没有去重，结果集可能会包含多个针对同一父文档的条目，每个条目对应于该父文档的不同子节点。然而，为了保证最终有`k`个唯一的父文档，你从一个更大的`k`
    `*` `4`个子节点池开始，从而创建了一个安全缓冲区。在Cypher语句的末尾，你强制执行最终的`k`限制。
- en: The function that utilizes the Cypher statement in listing 3.11 to retrieve
    parent documents from the database is shown in the following listing.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 利用列表3.11中的Cypher语句从数据库中检索父文档的函数如下所示。
- en: Listing 3.12 Parent document retrieval function
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.12 父文档检索函数
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `parent_retrieval` function in listing 3.12 first generates a text embedding
    for a given question and then uses the previously mentioned Cypher statement to
    retrieve a list of the most relevant documents from the database.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.12中的`parent_retrieval`函数首先为给定的问题生成一个文本嵌入，然后使用之前提到的Cypher语句从数据库中检索最相关的文档列表。
- en: 3.3 Complete RAG pipeline
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 完整的RAG管道
- en: The last piece of the pipeline is the answer-generating function.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的最后一部分是生成答案的函数。
- en: Listing 3.13 Generating answers with an LLM
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.13 使用LLM生成答案
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The code in listing 3.13 is identical to that in chapter 2\. You pass the question
    along with the relevant documents to an LLM and prompt it to generate an answer.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.13中的代码与第2章中的代码相同。你将问题以及相关文档传递给LLM，并提示它生成答案。
- en: After implementing the step-back prompting and parent document retrieval, you
    are ready to bring it all together in a single function.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现了回溯提示和父文档检索之后，你就可以将所有这些内容整合到一个单独的函数中。
- en: '**Listing 3.14 Complete parent document retriever with step-back prompting
    RAG pipeline**'
  id: totrans-109
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**列表3.14 完整的带有回溯提示的父文档检索RAG管道**'
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `rag_pipeline` function in listing 3.14 takes a question as input and creates
    a step-back prompt. It then retrieves related documents based on the step-back
    prompt and passes them along with the original question to an LLM to generate
    the final answer.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 列表3.14中的`rag_pipeline`函数接收一个问题作为输入并创建一个回溯提示。然后，它根据回溯提示检索相关文档，并将这些文档与原始问题一起传递给LLM以生成最终答案。
- en: You can now test the `rag_pipeline` implementation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以测试`rag_pipeline`的实现。
- en: '**Listing 3.15 Complete parent document retriever with step-back prompting
    RAG pipeline**'
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**列表 3.15 带有回溯提示的完整父文档检索器 RAG 流程**'
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Exercise 3.3
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 3.3
- en: Evaluate how well the `rag_pipeline` implementation performs by asking other
    questions about Einstein’s life mentioned in the PDF. Additionally, you can remove
    the step-back prompting step to compare if it improves the results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过询问关于爱因斯坦生平的其他问题来评估 `rag_pipeline` 实现的效果。此外，您还可以移除回溯提示步骤，以比较它是否改善了结果。
- en: Congratulations! You have successfully implemented an advanced vector search
    retrieval strategy by combining query rewriting and parent document retrieval.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功通过结合查询重写和父文档检索实现了高级向量搜索检索策略。
- en: Summary
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Query rewriting can enhance the accuracy of document retrieval by aligning user
    queries more closely with the language and context of target documents.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将用户查询与目标文档的语言和上下文更紧密地对齐，查询重写可以提高文档检索的准确性。
- en: Techniques like hypothetical document retriever and step-back prompting effectively
    bridge the gap between the user’s intent and the document’s content, reducing
    the chances of missing relevant information.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像假设文档检索器和回溯提示这样的技术有效地弥合了用户意图与文档内容之间的差距，减少了遗漏相关信息的机会。
- en: The effectiveness of a retrieval system can be improved by embedding not just
    the exact text but also contextually relevant summaries or paraphrases, capturing
    the essence of documents.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过嵌入不仅精确文本，还包括上下文相关的摘要或释义，可以捕捉文档的精髓，从而提高检索系统的有效性。
- en: Implementing strategies like hypothetical question embedding and parent document
    retrieval can lead to more precise matching between queries and documents, enhancing
    the relevance and accuracy of retrieved information.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过实施假设问题嵌入和父文档检索等策略，可以实现查询与文档之间更精确的匹配，增强检索信息的关联性和准确性。
- en: Splitting documents into smaller, more manageable chunks for embedding purposes
    allows for a more granular approach to information retrieval, ensuring that specific
    queries find the most relevant document sections.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文档拆分为更小、更易于管理的块以进行嵌入，允许采用更细粒度的信息检索方法，确保特定查询找到最相关的文档部分。
