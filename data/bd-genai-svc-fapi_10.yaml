- en: Capitolo 7\. Integrare i database nei servizi di intelligenza artificiale
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章\. 在人工智能服务中集成数据库
- en: 'Questo lavoro è stato tradotto utilizzando l''AI. Siamo lieti di ricevere il
    tuo feedback e i tuoi commenti: [translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作使用AI进行了翻译。我们很高兴收到您的反馈和评论：[translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)
- en: In questo capitolo, integrerai un database al tuo attuale servizio API per memorizzare
    e recuperare le interazioni degli utenti.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将把数据库集成到您当前的服务API中，以存储和检索用户交互。
- en: Questo capitolo presuppone un'esperienza di base nell'utilizzo dei database
    e del linguaggio SQL (Structured Query Language), quindi non tratterà tutti gli
    aspetti della programmazione SQL e dei flussi di lavoro dei database, ma ti illustrerà
    i concetti di database di livello superiore, i flussi di lavoro per lo sviluppo
    e le migliori pratiche per l'integrazione dei database nelle tue applicazioni
    FastAPI che interagiscono con modelli GenAI come gli LLM.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这章假设您对数据库和SQL（结构化查询语言）的使用有基本的经验，因此不会涵盖SQL编程和数据库工作流程的所有方面，而是会向您介绍高级数据库概念、开发工作流程以及将数据库集成到您的FastAPI应用程序中的最佳实践，这些应用程序与像LLM（大型语言模型）这样的GenAI模型交互。
- en: Imparerai il ruolo dei database relazionali (SQL) rispetto a quelli non relazionali
    (noSQL) nello sviluppo di un'applicazione e sarai in grado di scegliere con sicurezza
    il database giusto per il tuo caso d'uso. Poi capirai meglio le caratteristiche
    dei database relazionali e gli strumenti associati, come i mappatori relazionali
    a oggetti (ORM) e gli strumenti di migrazione dei database. Infine, come esercizio
    pratico, integrerai un database nella tua applicazione esistente utilizzando SQL
    e Alembic, per memorizzare e recuperare le conversazioni degli utenti con un LLM.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 您将学习关系型数据库（SQL）与非关系型数据库（noSQL）在应用程序开发中的作用，并能够安全地选择适合您用例的正确数据库。然后，您将更好地了解关系型数据库的特点和相关工具，如对象关系映射器（ORM）和数据库迁移工具。最后，作为实际操作练习，您将使用SQL和Alembic将数据库集成到现有应用程序中，以存储和检索与LLM的对话。
- en: Alla fine di questo capitolo, ti sentirai più sicuro nel selezionare, configurare
    e risolvere i problemi legati al database nelle tue applicazioni GenAI.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将更有信心选择、配置和解决您在GenAI应用程序中遇到的数据库相关问题和挑战。
- en: Il ruolo di un database
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库的角色
- en: Quando costruisci servizi di backend, spesso hai bisogno di un database per
    mantenere lo stato dell'applicazione e memorizzare i dati degli utenti. In altri
    casi, la tua applicazione non avrà bisogno di un database e non dovresti cercare
    di aggiungerne uno, poiché qualsiasi integrazione con il database può aumentare
    significativamente la complessità dei tuoi servizi.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建后端服务时，您通常需要一个数据库来维护应用程序状态和存储用户数据。在其他情况下，您的应用程序可能不需要数据库，您也不应该尝试添加数据库，因为任何与数据库的集成都可能显著增加您服务的复杂性。
- en: 'Qui ci sono diversi casi in cui puoi rinunciare all''uso di un database:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，有几种情况您可以放弃使用数据库：
- en: La tua applicazione può partire da uno stato nuovo all'avvio per ogni nuova
    sessione utente.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序可以在每个新的用户会话启动时从新状态开始。
- en: Il ricalcolo dei dati dell'applicazione è semplice ed efficiente dal punto di
    vista delle risorse.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从资源角度来看，应用程序数据的重新计算既简单又高效。
- en: I dati dell'applicazione sono abbastanza piccoli da poter essere memorizzati.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序数据足够小，可以存储。
- en: La tua applicazione è tollerante alle perdite di dati dovute a vari motivi,
    come errori del server, riavvii o altri eventi inaspettati.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序对由于服务器错误、重启或其他意外事件等原因导致的数据丢失具有容错性。
- en: Sessioni utente o istanze applicative diverse non avranno bisogno di condividere
    i dati.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的用户会话或应用程序实例不需要共享数据。
- en: I dati di cui hai bisogno possono essere prelevati direttamente da sistemi esterni,
    modelli GenAI e altre API applicative, e non dal tuo database.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您需要的数据可以直接从外部系统、GenAI模型和其他应用程序API中提取，而不是从您的数据库中提取。
- en: L'utente è felice di aspettare che i dati vengano ricalcolati per ogni nuova
    sessione o azione.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户愿意等待为每个新的会话或操作重新计算数据。
- en: I requisiti del tuo servizio consentono di conservare i dati in file su disco,
    nello storage del browser o in un cloud esterno invece che in un database. Con
    queste alternative, i tuoi servizi possono tollerare che l'archiviazione e il
    recupero dei dati non siano affidabili ed efficienti come un database.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的服务要求允许你在磁盘上的文件、浏览器存储或外部云中保存数据，而不是在数据库中。使用这些替代方案，你的服务可以容忍数据存档和恢复不如数据库可靠和高效。
- en: Stai realizzando un proof-of-concept e devi evitare a tutti i costi ritardi
    o complessità del progetto.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在实现一个概念验证，必须尽量避免项目中的延迟或复杂性。
- en: Un esempio di applicazione che corrisponde ai criteri precedenti è un *generatore
    di immagini GenAI* utilizzato solo a scopo dimostrativo.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 符合上述标准的一个应用示例是仅用于演示目的的GenAI图像生成器。
- en: In questo esempio, non dovrai memorizzare alcuna immagine generata e potrai
    sempre riavviare o utilizzare l'applicazione in qualsiasi momento partendo da
    uno stato nuovo. Inoltre, l'applicazione non ha bisogno di sapere chi è l'utente
    e non c'è bisogno di condividere i dati tra le sessioni. Inoltre, se si verifica
    un errore del server, l'impatto della perdita di dati è minimo perché puoi rigenerare
    una nuova immagine al volo.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你不需要记住任何生成的图像，并且你总是可以从一个新状态重新启动或使用应用程序。此外，应用程序不需要知道用户身份，也不需要在会话之间共享数据。此外，如果发生服务器错误，数据丢失的影响最小，因为你可以即时重新生成一个新的图像。
- en: Come puoi vedere, ci sono almeno una manciata di casi in cui non hai bisogno
    di un database per costruire i tuoi servizi GenAI. Tuttavia, potresti chiederti
    quando hai davvero bisogno di un database.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，至少有一些情况下，你不需要数据库来构建你的GenAI服务。然而，你可能想知道何时真正需要数据库。
- en: Per capire quando un database è necessario, devi comprendere il ruolo dei database.
    In breve, puoi usarli per archiviare, organizzare e gestire i dati in un formato
    efficiente che consenta di recuperarli, manipolarli e analizzarli facilmente.
    Inoltre, i database sono dotati di funzioni fondamentali come il ripristino/backup,
    la gestione dell'accesso concorrente, l'indicizzazione, il caching e il controllo
    dell'accesso basato sui ruoli, oltre a molte altre, che li rendono una componente
    insostituibile di qualsiasi servizio che visualizza, produce e consuma dati.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解何时需要数据库，你必须了解数据库的作用。简而言之，你可以使用它们以高效的方式存档、组织和处理数据，从而便于恢复、操作和分析。此外，数据库还具备诸如恢复/备份、并发访问管理、索引、缓存和基于角色的访问控制等基本功能，这使得它们成为任何显示、生成和消费数据的服务的不可或缺组成部分。
- en: Nella prossima sezione esamineremo nel dettaglio il funzionamento interno dei
    database, con particolare attenzione ai database relazionali su cui si concentreranno
    gli esempi pratici di questo capitolo. Grazie alla comprensione dettagliata degli
    interni dei database, potrai progettare API GenAI completamente ottimizzate e
    pronte per la produzione. In questo modo potrai delegare i carichi di lavoro più
    pesanti al motore del database, che è stato progettato specificamente per i compiti
    più pesanti.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将详细探讨数据库的内部工作原理，特别是本章将集中讨论的关系型数据库。通过对数据库内部结构的深入了解，你可以设计出完全优化且适用于生产的GenAI
    API。这样，你可以将最重的负载委托给专门为处理重任务而设计的数据库引擎。
- en: Sistemi di database
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库系统
- en: Ora che hai capito quando utilizzare un database, scopriamo di più sui diversi
    database che puoi utilizzare e sul loro funzionamento.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了何时使用数据库，让我们更深入地了解你可以使用的不同数据库及其工作原理。
- en: 'È possibile costruire un modello mentale dei database suddividendoli in due
    categorie principali: database*relazionali* (SQL) e *non relazionali* (NoSQL).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过将数据库分为两大类来构建一个关于数据库的思维模型：关系型数据库（SQL）和非关系型数据库（NoSQL）。
- en: La categorizzazione *SQL* contro *NoSQL* si basa sul fatto che i database relazionali
    utilizzano vari dialetti di SQL come linguaggio di query principale, mentre i
    database non relazionali sono spesso dotati di un proprio linguaggio di query
    specializzato.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SQL与NoSQL的分类基于这样一个事实：关系型数据库使用SQL的各种方言作为主要的查询语言，而非关系型数据库通常配备有专用的查询语言。
- en: 'Per entrambe le categorie di sistemi di database, è possibile adottare un modello
    mentale di come sono strutturati tali sistemi. Sia i sistemi di database SQL che
    quelli NoSQL sono spesso costituiti dai seguenti elementi:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据库系统的这两类，可以采用一个心理模型来了解这些系统的结构。无论是SQL数据库还是NoSQL数据库，通常都由以下元素组成：
- en: Un *server* di livello superiore, che ospita l'intera infrastruttura del database
    e consuma risorse di sistema (CPU, RAM e storage).
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个高级别的*服务器*，它托管整个数据库基础设施并消耗系统资源（CPU、RAM和存储）。
- en: Uno o più *database* all'interno del server, che agiscono come *contenitori
    logici* che contengono dati correlati.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器内的一个或多个*数据库*，作为包含相关数据的逻辑容器。
- en: Uno o più *schemi* all'interno di un database (a seconda del software del database),
    che servono a definire *la* struttura completa dei dati e i vari oggetti strutturali
    come indici, vincoli logici, trigger e così via.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据库内部（根据数据库软件），一个或多个*schemata*，用于定义数据的完整结构和各种结构化对象，如索引、逻辑约束、触发器等。
- en: Zero o più *tabelle* (SQL) o *collezioni* (NoSQL) create all'interno del database
    (come parte di uno schema), che raggruppano dati correlati.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据库内部（作为模式的一部分）创建的零个或多个*表*（SQL）或*集合*（NoSQL），将相关数据分组。
- en: Zero o più *elementi* all'interno di ogni raccolta (come documenti) o tabella
    (come righe), che rappresentano record o entità specifiche.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个集合（如文档）或表（如行）内的零个或多个*元素*，代表特定的记录或实体。
- en: '[La Figura 7-1](#database_server_breakdown) visualizza la suddetta ripartizione.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-1](#database_server_breakdown)展示了上述划分。'
- en: '![bgai 0701](assets/bgai_0701.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0701](assets/bgai_0701.png)'
- en: Figura 7-1\. Suddivisione del sistema di database
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1. 数据库系统划分
- en: L'adozione di un modello mentale come quello illustrato nella [Figura 7-1](#database_server_breakdown)
    ti aiuterà a orientarti nella crescente varietà di sistemi di database, in quanto
    puoi aspettarti la presenza di meccanismi di base simili. Questa familiarità,
    si spera, ridurrà la tua curva di apprendimento nell'adozione di diversi sistemi
    di database.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 采用如图7-1所示的心理模型可以帮助你在不断增长的数据库系统种类中找到方向，因为你可以期待存在类似的基本机制。希望这种熟悉感能减少你在采用不同数据库系统时的学习曲线。
- en: Passiamo quindi in rassegna brevemente i sistemi di database SQL e NoSQL, in
    modo da comprendere meglio i loro casi d'uso, le loro caratteristiche e i loro
    limiti nella creazione di API e servizi.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们简要回顾一下SQL和NoSQL数据库系统，以便更好地理解它们的用例、特性和在创建API和服务中的局限性。
- en: Per aiutarti a creare un modello mentale dei database relazionali e non relazionali,
    dai un'occhiata alla [Figura 7-2](#db_types).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你建立关系型数据库和非关系型数据库的心理模型，请参阅[图7-2](#db_types)。
- en: '![bgai 0702](assets/bgai_0702.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0702](assets/bgai_0702.png)'
- en: Figura 7-2\. Tipi di database
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2. 数据库类型
- en: Puoi anche usare il riepilogo della [Tabella 7-1](#db_comparison) come riferimento
    dei tipi di database che verranno trattati in questo capitolo.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用[表7-1](#db_comparison)的总结作为本章将要讨论的数据库类型的参考。
- en: Tabella 7-1\. Confronto tra i database
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-1. 数据库对比
- en: '| Tipo | Modello di dati | Esempi | Casi d''uso |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 数据模型 | 示例 | 用例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Negozi chiave-valore | Coppie chiave-valore | Redis, DynamoDB, Memcached
    | Caching, gestione delle sessioni |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 键值商店 | 键值对 | Redis, DynamoDB, Memcached | 缓存、会话管理 |'
- en: '| Negozi di grafici | Nodi e bordi | Neo4j, Amazon Neptune, ArangoDB | Social
    network, motori di raccomandazione, rilevamento delle frodi |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 图形商店 | 节点和边 | Neo4j, Amazon Neptune, ArangoDB | 社交网络、推荐引擎、欺诈检测 |'
- en: '| Archivi di documenti | Documenti | MongoDB, CouchDB, Amazon DocumentDB |
    Gestione dei contenuti, e-commerce, analisi in tempo reale |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 文档存储 | 文档 | MongoDB, CouchDB, Amazon DocumentDB | 内容管理、电子商务、实时分析 |'
- en: '| Negozi vettoriali | Vettori ad alta dimensione | Pigna, Weaviate | Sistemi
    di raccomandazione, ricerca di immagini/testi, archiviazione di modelli ML |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 向量商店 | 高维向量 | Pigna, Weaviate | 推荐系统、图像/文本搜索、ML模型存储 |'
- en: '| Negozi di famiglia a colonna larga | Tabelle con righe e colonne | Apache
    Cassandra, HBase, ScyllaDB | Dati di serie temporali, analisi in tempo reale,
    registrazione |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 宽列家族商店 | 行和列的表 | Apache Cassandra, HBase, ScyllaDB | 时间序列数据、实时分析、日志记录 |'
- en: Ora che hai un'ampia panoramica di tutti i più comuni database relazionali e
    non relazionali, puoi visualizzare un servizio GenAI del mondo reale che utilizza
    questi database insieme.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对所有的常见关系型和非关系型数据库有了全面的了解，你可以查看一个使用这些数据库的实时GenAI服务。
- en: Immagina di costruire un servizio LLM abilitato a RAG in grado di dialogare
    con una base di conoscenza. I documenti di questa base di conoscenza sono correlati
    tra loro, quindi decidi di implementare un grafo RAG per catturare un contesto
    più ricco. Per implementare un grafo RAG, integra il tuo servizio con un database
    a grafi.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下构建一个能够与知识库进行对话的LLM服务。这个知识库中的文档是相互关联的，因此你决定实现一个RAG图来捕获更丰富的上下文。为了实现RAG图，你需要将你的服务与一个图数据库集成。
- en: Ora, per recuperare i pezzi di documenti rilevanti, devi anche inserirli in
    un database vettoriale e, come parte di questo, hai bisogno anche di un database
    relazionale per monitorare l'utilizzo e memorizzare i dati degli utenti e la cronologia
    delle conversazioni.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了检索相关的文档片段，你也必须将它们插入到一个向量数据库中，作为这一部分，你还需要一个关系型数据库来监控使用情况并存储用户数据和对话历史。
- en: Poiché gli utenti possono porre domande comuni, decidi anche di memorizzare
    nella cache le risposte di LLM generando diversi output in anticipo. Pertanto,
    integri anche un archivio di valori-chiave al tuo servizio.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于用户可能会提出常见问题，你也决定提前生成不同的LLM输出并将其存储在缓存中。因此，你还将把一个键值存储库集成到你的服务中。
- en: Infine, vuoi dare agli amministratori il controllo sui prompt del sistema con
    la possibilità di controllarne la versione. Per questo motivo, aggiungi alla tua
    soluzione un sistema di gestione dei contenuti come gestore dei prompt. Tuttavia,
    poiché i modelli di prompt possono cambiare spesso, decidi di integrare anche
    un database di documenti.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你希望管理员能够控制系统的提示，并能够控制其版本。因此，你将内容管理系统添加到你的解决方案中作为提示的管理器。然而，由于提示模型可能会经常变化，你决定也集成一个文档数据库。
- en: 'Come puoi vedere, ogni tipo di database risolve un problema particolare nella
    tua complessa applicazione abilitata a RAG: uno memorizza i dati del backend e
    degli utenti, un altro cattura le relazioni tra i documenti, uno memorizza gli
    embeddings dei documenti, un altro ancora aiuta a memorizzare gli schemi flessibili
    dei prompt e l''ultimo ti aiuta a restituire gli output in cache.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，每种类型的数据库都在你的复杂RAG应用中解决特定的问题：一个存储后端和用户数据，另一个捕获文档之间的关系，一个存储文档的嵌入，另一个帮助存储灵活的提示模式，最后一个帮助你缓存返回的输出。
- en: Puoi vedere una visualizzazione dell'architettura dell'applicazione nella [Figura
    7-3](#rag_graph_architecture) per capire come questi database possono lavorare
    insieme per realizzare una soluzione.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图7-3](#rag_graph_architecture)中看到应用程序架构的展示，以了解这些数据库如何一起工作以实现解决方案。
- en: '![bgai 0703](assets/bgai_0703.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0703](assets/bgai_0703.png)'
- en: Figura 7-3\. Utilizzo congiunto di vari tipi di database
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. 各种类型数据库的联合使用
- en: Ora che hai capito come i tuoi servizi GenAI possono integrarsi con diversi
    database, nella prossima sezione ci concentreremo sull'aggiunta di un database
    relazionale al tuo servizio.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了你的GenAI服务如何与不同的数据库集成，在下一节中，我们将专注于将关系型数据库添加到你的服务中。
- en: 'Progetto: Memorizzare le conversazioni degli utenti con un LLM in un database
    relazionale'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目：将用户与LLM的对话存储在关系型数据库中
- en: Nella sezione precedente abbiamo trattato i concetti fondamentali dei database
    per aggiungere la persistenza dei dati alle tue applicazioni.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了数据库的基本概念，以将数据持久性添加到你的应用程序中。
- en: In questa sezione, integrerai un database relazionale al tuo servizio GenAI
    in modo da poter memorizzare le cronologie delle conversazioni degli utenti con
    un LLM nel database. Come parte di questo lavoro, imparerai anche le migliori
    pratiche, gli strumenti e il flusso di sviluppo per gestire le modifiche allo
    schema e le migrazioni dei dati nel tuo database.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将把一个关系型数据库集成到你的GenAI服务中，以便能够将用户与LLM的对话历史存储在数据库中。作为这项工作的一个部分，你还将学习到管理数据库模式更改和数据迁移的最佳实践、工具和开发流程。
- en: Per questo progetto, installeremo un database relazionale Postgres, che è open
    source, gratuito e collaudato ed è utilizzato da molte aziende. Per iniziare,
    scarichiamo ed eseguiamo il container Postgres utilizzando `docker run`, come
    mostrato nell'[Esempio 7-1](#postgres).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此项目，我们将安装一个开源、免费且经过验证的关系型数据库 Postgres，许多公司都在使用它。为了开始，我们使用 `docker run` 命令下载并执行
    Postgres 容器，如[Esempio 7-1](#postgres)所示。
- en: Esempio 7-1\. Scarica ed esegui il contenitore del database Postgres
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-1\. 下载并执行 Postgres 数据库容器
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO1-1)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO1-1)'
- en: Scarica ed esegui l'ultima immagine del database relazionale `postgres` dal
    registro di Docker.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Docker 注册表中下载并执行最新的关系型数据库 `postgres` 镜像。
- en: '[![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO1-2)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO1-2)'
- en: Esegui l'immagine `postgres` e poi esponi e mappa la porta del container `5432`
    sulle stesse porte del computer host.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 `postgres` 镜像，然后暴露并映射容器的 `5432` 端口到主机上的相同端口。
- en: '[![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO1-3)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO1-3)'
- en: Esegui il contenitore con diverse variabili ambientali che specificano il nome
    utente e la password predefiniti dell'amministratore del database, il nome del
    database e la posizione dei dati del DBMS all'interno del contenitore.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的环境变量执行容器，这些变量指定了数据库管理员的默认用户名和密码、数据库名以及 DBMS 数据在容器内的位置。
- en: '[![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO1-4)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO1-4)'
- en: Monta il database Postgres sul filesystem della macchina host in una cartella
    `dbstorage` nella directory di lavoro attuale.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在主机文件系统中，将 Postgres 数据库挂载到当前工作目录下的 `dbstorage` 文件夹中。
- en: 'Installiamo quindi i pacchetti `sqlalchemy`, `alembic` e `psycopg3`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们安装 `sqlalchemy`、`alembic` 和 `psycopg3` 包：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2] # entities.py  from datetime import UTC, datetime from sqlalchemy import
    ForeignKey from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column,
    relationship  class Base(DeclarativeBase): ![1](assets/1.png)     pass  class
    Conversation(Base): ![2](assets/2.png)     __tablename__ = "conversations"      id:
    Mapped[int] = mapped_column(primary_key=True)     title: Mapped[str] = mapped_column()
    ![3](assets/3.png)     model_type: Mapped[str] = mapped_column(index=True) ![4](assets/4.png)     created_at:
    Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at: Mapped[datetime]
    = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC)
    ![5](assets/5.png)     )      messages: Mapped[list["Message"]] = relationship(         "Message",
    back_populates="conversation", cascade="all, delete-orphan" ![6](assets/6.png)     )   class
    Message(Base): ![7](assets/7.png)     __tablename__ = "messages"      id: Mapped[int]
    = mapped_column(primary_key=True)     conversation_id: Mapped[int] = mapped_column(         ForeignKey("conversations.id",
    ondelete="CASCADE"), index=True ![6](assets/6.png)     )     prompt_content: Mapped[str]
    = mapped_column()     response_content: Mapped[str] = mapped_column()     prompt_tokens:
    Mapped[int | None] = mapped_column()     response_tokens: Mapped[int | None] =
    mapped_column()     total_tokens: Mapped[int | None] = mapped_column()     is_success:
    Mapped[bool | None] = mapped_column()     status_code: Mapped[int | None] = mapped_column()
    ![8](assets/8.png) ![9](assets/9.png)     created_at: Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at:
    Mapped[datetime] = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC)     )      conversation:
    Mapped["Conversation"] = relationship(         "Conversation", back_populates="messages"     )
    [PRE3] # database.py  from sqlalchemy.ext.asyncio import create_async_engine from
    entities import Base  database_url = ( ![1](assets/1.png)     "postgresql+psycopg://fastapi:mysecretpassword@localhost:5432/backend_db"
    ) engine = create_async_engine(database_url, echo=True) ![2](assets/2.png)  async
    def init_db() -> None:     async with engine.begin() as conn:         await conn.run_sync(Base.metadata.drop_all)         await
    conn.run_sync(Base.metadata.create_all) ![3](assets/3.png)  # main.py  from contextlib
    import asynccontextmanager from fastapi import FastAPI from database import engine,
    init_db  @asynccontextmanager async def lifespan(_: FastAPI):     await init_db()     #
    other startup operations within the lifespan     ...     yield     await engine.dispose()
    ![4](assets/4.png)  app = FastAPI(lifespan=lifespan) [PRE4] # database.py  from
    typing import Annotated from fastapi import Depends from sqlalchemy.ext.asyncio
    import AsyncSession, async_sessionmaker from database import engine  async_session
    = async_sessionmaker(     bind=engine, class_=AsyncSession, autocommit=False,
    autoflush=False ![1](assets/1.png) ) async def get_db_session(): ![2](assets/2.png)     try:         async
    with async_session() as session: ![3](assets/3.png)             yield session
    ![4](assets/4.png)     except:         await session.rollback() ![5](assets/5.png)         raise     finally:         await
    session.close() ![6](assets/6.png)  DBSessionDep = Annotated[AsyncSession, Depends(get_db_session)]
    ![7](assets/7.png) [PRE5] # schemas.py  from datetime import datetime from pydantic
    import BaseModel, ConfigDict  class ConversationBase(BaseModel):     model_config
    = ConfigDict(from_attributes=True) ![1](assets/1.png)      title: str     model_type:
    str  class ConversationCreate(ConversationBase): ![2](assets/2.png)     pass  class
    ConversationUpdate(ConversationBase): ![2](assets/2.png)     pass  class ConversationOut(ConversationBase):
    ![2](assets/2.png)     id: int     created_at: datetime     updated_at: datetime
    [PRE6] # main.py  from typing import Annotated from database import DBSessionDep
    from entities import Conversation from fastapi import Depends, FastAPI, HTTPException,
    status from schemas import ConversationCreate, ConversationOut, ConversationUpdate
    from sqlalchemy import select  ...  async def get_conversation(     conversation_id:
    int, session: DBSessionDep ![1](assets/1.png) ) -> Conversation:     async with
    session.begin(): ![2](assets/2.png)         result = await session.execute(             select(Conversation).where(Conversation.id
    == conversation_id)         )         conversation = result.scalars().first()     if
    not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation
    not found",         )     return conversation  GetConversationDep = Annotated[Conversation,
    Depends(get_conversation)]  @app.get("/conversations") async def list_conversations_controller(     session:
    DBSessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     async
    with session.begin():         result = await session.execute(             select(Conversation).offset(skip).limit(take)
    ![3](assets/3.png)         )     return [         ConversationOut.model_validate(conversation)         for
    conversation in result.scalars().all()     ]  @app.get("/conversations/{id}")
    async def get_conversation_controller(     conversation: GetConversationDep, )
    -> ConversationOut:     return ConversationOut.model_validate(conversation) ![4](assets/4.png)  @app.post("/conversations",
    status_code=status.HTTP_201_CREATED) async def create_conversation_controller(     conversation:
    ConversationCreate, session: DBSessionDep ) -> ConversationOut:     new_conversation
    = Conversation(**conversation.model_dump())     async with session.begin():         session.add(new_conversation)         await
    session.commit() ![5](assets/5.png)         await session.refresh(new_conversation)     return
    ConversationOut.model_validate(new_conversation)  @app.put("/conversations/{id}",
    status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     updated_conversation:
    ConversationUpdate,     conversation: GetConversationDep,     session: DBSessionDep,
    ) -> ConversationOut:     for key, value in updated_conversation.model_dump().items():         setattr(conversation,
    key, value)     async with session.begin():         await session.commit() ![5](assets/5.png)         await
    session.refresh(conversation)     return ConversationOut.model_validate(conversation)  @app.delete("/conversations/{id}",
    status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation:
    GetConversationDep, session: DBSessionDep ) -> None:     async with session.begin():         await
    session.delete(conversation)         await session.commit() ![5](assets/5.png)
    [PRE7] # repositories/interfaces.py  from abc import ABC, abstractmethod from
    typing import Any  class Repository(ABC): ![1](assets/1.png)     @abstractmethod     async
    def list(self) -> list[Any]:         pass      @abstractmethod     async def get(self,
    uid: int) -> Any:         pass      @abstractmethod     async def create(self,
    record: Any) -> Any:         pass      @abstractmethod     async def update(self,
    uid: int, record: Any) -> Any:         pass      @abstractmethod     async def
    delete(self, uid: int) -> None:         pass [PRE8] # repositories/conversations.py  from
    entities import Conversation from repositories.interfaces import Repository from
    schemas import ConversationCreate, ConversationUpdate from sqlalchemy import select
    from sqlalchemy.ext.asyncio import AsyncSession  class ConversationRepository(Repository):
    ![1](assets/1.png)     def __init__(self, session: AsyncSession) -> None:         self.session
    = session      async def list(self, skip: int, take: int) -> list[Conversation]:         async
    with self.session.begin():             result = await self.session.execute(                 select(Conversation).offset(skip).limit(take)             )         return
    [r for r in result.scalars().all()]      async def get(self, conversation_id:
    int) -> Conversation | None:         async with self.session.begin():             result
    = await self.session.execute(                 select(Conversation).where(Conversation.id
    == conversation_id)             )         return result.scalars().first()      async
    def create(self, conversation: ConversationCreate) -> Conversation:         new_conversation
    = Conversation(**conversation.model_dump())         async with self.session.begin():             self.session.add(new_conversation)             await
    self.session.commit()             await self.session.refresh(new_conversation)         return
    new_conversation      async def update(         self, conversation_id: int, updated_conversation:
    ConversationUpdate     ) -> Conversation | None:         conversation = await
    self.get(conversation_id)         if not conversation:             return None         for
    key, value in updated_conversation.model_dump().items():             setattr(conversation,
    key, value)         async with self.session.begin():             await self.session.commit()             await
    self.session.refresh(conversation)         return conversation      async def
    delete(self, conversation_id: int) -> None:         conversation = await self.get(conversation_id)         if
    not conversation:             return         async with self.session.begin():             await
    self.session.delete(conversation)             await self.session.commit() [PRE9]
    # routers/conversations.py  from typing import Annotated from fastapi import APIRouter,
    Depends, FastAPI, HTTPException, status ...  # Other imports from repositories
    import ConversationRepository  ...  # Other controllers and dependency implementations  router
    = APIRouter(prefix="/conversations") ![1](assets/1.png)  async def get_conversation(     conversation_id:
    int, session: SessionDep ) -> Conversation:     conversation = await ConversationRepository(session).get(conversation_id)
    ![2](assets/2.png)     if not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation
    not found",         )     return conversation  GetConversationDep = Annotated[Conversation,
    Depends(get_conversation)]  @router.get("") async def list_conversations_controller(     session:
    SessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     conversations
    = await ConversationRepository(session).list(skip, take)     return [ConversationOut.model_validate(c)
    for c in conversations]   @router.get("/{id}") async def get_conversation_controller(     conversation:
    GetConversationDep, ) -> ConversationOut:     return ConversationOut.model_validate(conversation)
    ![2](assets/2.png)   @router.post("", status_code=status.HTTP_201_CREATED) async
    def create_conversation_controller(     conversation: ConversationCreate, session:
    SessionDep ) -> ConversationOut:     new_conversation = await ConversationRepository(session).create(         conversation     )
    ![2](assets/2.png)     return ConversationOut.model_validate(new_conversation)   @router.put("/{id}",
    status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     conversation:
    GetConversationDep,     updated_conversation: ConversationUpdate,     session:
    SessionDep, ) -> ConversationOut:     updated_conversation = await ConversationRepository(session).update(
    ![2](assets/2.png)         conversation.id, updated_conversation     )     return
    ConversationOut.model_validate(updated_conversation)   @router.delete("/{id}",
    status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation:
    GetConversationDep, session: SessionDep ) -> None:     await ConversationRepository(session).delete(conversation.id)   #
    main.py  from routers.conversations import router as conversations_router  app.include_router(conversations_router)
    ![1](assets/1.png) [PRE10] # services/conversations.py  from entities import Message
    from repositories.conversations import ConversationRepository from sqlalchemy
    import select  class ConversationService(ConversationRepository):     async def
    list_messages(self, conversation_id: int) -> list[Message]:         result = await
    self.session.execute(             select(Message).where(Message.conversation_id
    == conversation_id)         )         return [m for m in result.scalars().all()]  #
    routers/conversations.py  from database import DBSessionDep from entities import
    Message from fastapi import APIRouter from schemas import MessageOut from services.conversations
    import ConversationService  router = APIRouter(prefix="/conversations")  @router.get("/{conversation_id}/messages")
    ![1](assets/1.png) async def list_conversation_messages_controller(     conversation:
    GetConversationDep,     session: DBSessionDep, ) -> list[Message]:     messages
    = await ConversationService(session).list_messages(conversation.id)     return
    [MessageOut.model_validate(m) for m in messages] [PRE11]`  [PRE12]*# Gestione
    delle modifiche agli schemi di database    Avrai notato che nell''[Esempio 7-3](#sqlalchemy_engine)
    stai cancellando e ricreando le tabelle del database ogni volta che avvii il server
    FastAPI. Questo è accettabile per i flussi di lavoro di sviluppo durante la fase
    di prototipazione, ma non lo è affatto quando devi distribuire i tuoi servizi
    in produzione con utenti attivi. Non puoi resettare il database da zero ogni volta
    che aggiorni lo schema del database.    Inoltre, probabilmente avrai bisogno di
    un modo per ripristinare le modifiche se qualcosa si rompe o se decidi di fare
    un rollback di alcune funzionalità. Per ottenere questo risultato, puoi utilizzare
    uno strumento di migrazione del database come Alembic, progettato per funzionare
    perfettamente con l''ORM SQLAlchemy.    Alembic ti permette di controllare la
    versione degli schemi del tuo database nello stesso modo in cui strumenti come
    Git ti aiutano a controllare la versione del tuo codice. Sono estremamente utili
    quando lavori in un team con più ambienti applicativi e hai bisogno di tenere
    traccia delle modifiche o di ripristinare gli aggiornamenti se necessario.    Per
    iniziare, devi prima installare `alembic` tramite `pip` e poi inizializzarlo eseguendo
    l''[Esempio 7-11](#alembic_init) nella root del tuo progetto FastAPI.    #####
    Esempio 7-11\. Inizializzazione di un ambiente Alembic    [PRE13]py    Alembic
    creerà il suo ambiente all''interno della cartella `alembic` con diversi file
    e una cartella `versions`, come mostrato nell''[Esempio 7-12](#alembic_dir).    #####
    Esempio 7-12\. Ambiente Alembic nella directory principale del progetto    [PRE14]py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO11-1)      Un
    file di ambiente per specificare lo schema di destinazione e le connessioni al
    database      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO11-2)      Una
    directory per contenere i file *di migrazione*, che specificano le istruzioni
    su come aggiornare o ripristinare lo schema del database.      Una volta generato
    l''ambiente Alembic, apri e modifica il file *env.py* che si trova nella directory
    `alembic`, come mostrato nell''[Esempio 7-13](#alembic_env), in modo da ottenere
    l''accesso all''oggetto metadati SQLAlchemy che contiene le informazioni sullo
    schema di destinazione.    ##### Esempio 7-13\. Collegare l''ambiente Alembic
    con i modelli SQLAlchemy    [PRE15]py    Con Alembic collegato ai tuoi modelli
    SQLAlchemy, Alembic può ora generare automaticamente i file di migrazione confrontando
    lo schema attuale del tuo database con i tuoi modelli SQLAlchemy:    [PRE16]py   [PRE17]`
    [PRE18] # main.py  from itertools import tee from database import DBSessionDep
    from entities import Message from fastapi import BackgroundTasks, Depends from
    fastapi.responses import StreamingResponse from repositories.conversations import
    Conversation from repositories.messages import MessageRepository from sqlalchemy.ext.asyncio
    import AsyncSession  async def store_message( ![1](assets/1.png)     prompt_content:
    str,     response_content: str,     conversation_id: int,     session: AsyncSession,
    ) -> None:     message = Message(         conversation_id=conversation_id,         prompt_content=prompt_content,         response_content=response_content,     )     await
    MessageRepository(session).create(message)  @app.get("/text/generate/stream")
    async def stream_llm_controller(     prompt: str,     background_task: BackgroundTasks,     session:
    DBSessionDep,     conversation: Conversation = Depends(get_conversation), ![2](assets/2.png)
    ) -> StreamingResponse:     # Invoke LLM and obtain the response stream     ...     stream_1,
    stream_2 = tee(response_stream) ![3](assets/3.png)     background_task.add_task(         store_message,
    prompt, "".join(stream_1), conversation.id, session     ) ![4](assets/4.png)     return
    StreamingResponse(stream_2) [PRE19] from entities import Conversation from openai
    import AsyncClient from repositories.conversations import ConversationRepository
    from sqlalchemy.ext.asyncio import AsyncSession  async_client = AsyncClient(...)  async
    def create_conversation(     initial_prompt: str, session: AsyncSession ) -> Conversation:     completion
    = await async_client.chat.completions.create(         messages=[             {                 "role":
    "system",                 "content": "Suggest a title for the conversation "                            "based
    on the user prompt",             },             {                 "role": "user",                 "content":
    initial_prompt,             },         ],         model="gpt-3.5-turbo",     )     title
    = completion.choices[0].message.content     conversation = Conversation(         title=title,         #
    add other conversation properties         ...     )     return await ConversationRepository(session).create(conversation)
    [PRE20]` [PRE21]```'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE2] # entities.py  from datetime import UTC, datetime from sqlalchemy import
    ForeignKey from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column,
    relationship  class Base(DeclarativeBase): ![1](assets/1.png)     pass  class
    Conversation(Base): ![2](assets/2.png)     __tablename__ = "conversations"      id:
    Mapped[int] = mapped_column(primary_key=True)     title: Mapped[str] = mapped_column()
    ![3](assets/3.png)     model_type: Mapped[str] = mapped_column(index=True) ![4](assets/4.png)     created_at:
    Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at: Mapped[datetime]
    = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC)
    ![5](assets/5.png)     )      messages: Mapped[list["Message"]] = relationship(         "Message",
    back_populates="conversation", cascade="all, delete-orphan" ![6](assets/6.png)     )   class
    Message(Base): ![7](assets/7.png)     __tablename__ = "messages"      id: Mapped[int]
    = mapped_column(primary_key=True)     conversation_id: Mapped[int] = mapped_column(         ForeignKey("conversations.id",
    ondelete="CASCADE"), index=True ![6](assets/6.png)     )     prompt_content: Mapped[str]
    = mapped_column()     response_content: Mapped[str] = mapped_column()     prompt_tokens:
    Mapped[int | None] = mapped_column()     response_tokens: Mapped[int | None] =
    mapped_column()     total_tokens: Mapped[int | None] = mapped_column()     is_success:
    Mapped[bool | None] = mapped_column()     status_code: Mapped[int | None] = mapped_column()
    ![8](assets/8.png) ![9](assets/9.png)     created_at: Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at:
    Mapped[datetime] = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC)     )      conversation:
    Mapped["Conversation"] = relationship(         "Conversation", back_populates="messages"     )
    [PRE3] # database.py  from sqlalchemy.ext.asyncio import create_async_engine from
    entities import Base  database_url = ( ![1](assets/1.png)     "postgresql+psycopg://fastapi:mysecretpassword@localhost:5432/backend_db"
    ) engine = create_async_engine(database_url, echo=True) ![2](assets/2.png)  async
    def init_db() -> None:     async with engine.begin() as conn:         await conn.run_sync(Base.metadata.drop_all)         await
    conn.run_sync(Base.metadata.create_all) ![3](assets/3.png)  # main.py  from contextlib
    import asynccontextmanager from fastapi import FastAPI from database import engine,
    init_db  @asynccontextmanager async def lifespan(_: FastAPI):     await init_db()     #
    other startup operations within the lifespan     ...     yield     await engine.dispose()
    ![4](assets/4.png)  app = FastAPI(lifespan=lifespan) [PRE4] # database.py  from
    typing import Annotated from fastapi import Depends from sqlalchemy.ext.asyncio
    import AsyncSession, async_sessionmaker from database import engine  async_session
    = async_sessionmaker(     bind=engine, class_=AsyncSession, autocommit=False,
    autoflush=False ![1](assets/1.png) ) async def get_db_session(): ![2](assets/2.png)     try:         async
    with async_session() as session: ![3](assets/3.png)             yield session
    ![4](assets/4.png)     except:         await session.rollback() ![5](assets/5.png)         raise     finally:         await
    session.close() ![6](assets/6.png)  DBSessionDep = Annotated[AsyncSession, Depends(get_db_session)]
    ![7](assets/7.png) [PRE5] # schemas.py  from datetime import datetime from pydantic
    import BaseModel, ConfigDict  class ConversationBase(BaseModel):     model_config
    = ConfigDict(from_attributes=True) ![1](assets/1.png)      title: str     model_type:
    str  class ConversationCreate(ConversationBase): ![2](assets/2.png)     pass  class
    ConversationUpdate(ConversationBase): ![2](assets/2.png)     pass  class ConversationOut(ConversationBase):
    ![2](assets/2.png)     id: int     created_at: datetime     updated_at: datetime
    [PRE6] # main.py  from typing import Annotated from database import DBSessionDep
    from entities import Conversation from fastapi import Depends, FastAPI, HTTPException,
    status from schemas import ConversationCreate, ConversationOut, ConversationUpdate
    from sqlalchemy import select  ...  async def get_conversation(     conversation_id:
    int, session: DBSessionDep ![1](assets/1.png) ) -> Conversation:     async with
    session.begin(): ![2](assets/2.png)         result = await session.execute(             select(Conversation).where(Conversation.id
    == conversation_id)         )         conversation = result.scalars().first()     if
    not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation
    not found",         )     return conversation  GetConversationDep = Annotated[Conversation,
    Depends(get_conversation)]  @app.get("/conversations") async def list_conversations_controller(     session:
    DBSessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     async
    with session.begin():         result = await session.execute(             select(Conversation).offset(skip).limit(take)
    ![3](assets/3.png)         )     return [         ConversationOut.model_validate(conversation)         for
    conversation in result.scalars().all()     ]  @app.get("/conversations/{id}")
    async def get_conversation_controller(     conversation: GetConversationDep, )
    -> ConversationOut:     return ConversationOut.model_validate(conversation) ![4](assets/4.png)  @app.post("/conversations",
    status_code=status.HTTP_201_CREATED) async def create_conversation_controller(     conversation:
    ConversationCreate, session: DBSessionDep ) -> ConversationOut:     new_conversation
    = Conversation(**conversation.model_dump())     async with session.begin():         session.add(new_conversation)         await
    session.commit() ![5](assets/5.png)         await session.refresh(new_conversation)     return
    ConversationOut.model_validate(new_conversation)  @app.put("/conversations/{id}",
    status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     updated_conversation:
    ConversationUpdate,     conversation: GetConversationDep,     session: DBSessionDep,
    ) -> ConversationOut:     for key, value in updated_conversation.model_dump().items():         setattr(conversation,
    key, value)     async with session.begin():         await session.commit() ![5](assets/5.png)         await
    session.refresh(conversation)     return ConversationOut.model_validate(conversation)  @app.delete("/conversations/{id}",
    status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation:
    GetConversationDep, session: DBSessionDep ) -> None:     async with session.begin():         await
    session.delete(conversation)         await session.commit() ![5](assets/5.png)
    [PRE7] # repositories/interfaces.py  from abc import ABC, abstractmethod from
    typing import Any  class Repository(ABC): ![1](assets/1.png)     @abstractmethod     async
    def list(self) -> list[Any]:         pass      @abstractmethod     async def get(self,
    uid: int) -> Any:         pass      @abstractmethod     async def create(self,
    record: Any) -> Any:         pass      @abstractmethod     async def update(self,
    uid: int, record: Any) -> Any:         pass      @abstractmethod     async def
    delete(self, uid: int) -> None:         pass [PRE8] # repositories/conversations.py  from
    entities import Conversation from repositories.interfaces import Repository from
    schemas import ConversationCreate, ConversationUpdate from sqlalchemy import select
    from sqlalchemy.ext.asyncio import AsyncSession  class ConversationRepository(Repository):
    ![1](assets/1.png)     def __init__(self, session: AsyncSession) -> None:         self.session
    = session      async def list(self, skip: int, take: int) -> list[Conversation]:         async
    with self.session.begin():             result = await self.session.execute(                 select(Conversation).offset(skip).limit(take)             )         return
    [r for r in result.scalars().all()]      async def get(self, conversation_id:
    int) -> Conversation | None:         async with self.session.begin():             result
    = await self.session.execute(                 select(Conversation).where(Conversation.id
    == conversation_id)             )         return result.scalars().first()      async
    def create(self, conversation: ConversationCreate) -> Conversation:         new_conversation
    = Conversation(**conversation.model_dump())         async with self.session.begin():             self.session.add(new_conversation)             await
    self.session.commit()             await self.session.refresh(new_conversation)         return
    new_conversation      async def update(         self, conversation_id: int, updated_conversation:
    ConversationUpdate     ) -> Conversation | None:         conversation = await
    self.get(conversation_id)         if not conversation:             return None         for
    key, value in updated_conversation.model_dump().items():             setattr(conversation,
    key, value)         async with self.session.begin():             await self.session.commit()             await
    self.session.refresh(conversation)         return conversation      async def
    delete(self, conversation_id: int) -> None:         conversation = await self.get(conversation_id)         if
    not conversation:             return         async with self.session.begin():             await
    self.session.delete(conversation)             await self.session.commit() [PRE9]
    # routers/conversations.py  from typing import Annotated from fastapi import APIRouter,
    Depends, FastAPI, HTTPException, status ...  # Other imports from repositories
    import ConversationRepository  ...  # Other controllers and dependency implementations  router
    = APIRouter(prefix="/conversations") ![1](assets/1.png)  async def get_conversation(     conversation_id:
    int, session: SessionDep ) -> Conversation:     conversation = await ConversationRepository(session).get(conversation_id)
    ![2](assets/2.png)     if not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation
    not found",         )     return conversation  GetConversationDep = Annotated[Conversation,
    Depends(get_conversation)]  @router.get("") async def list_conversations_controller(     session:
    SessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     conversations
    = await ConversationRepository(session).list(skip, take)     return [ConversationOut.model_validate(c)
    for c in conversations]   @router.get("/{id}") async def get_conversation_controller(     conversation:
    GetConversationDep, ) -> ConversationOut:     return ConversationOut.model_validate(conversation)
    ![2](assets/2.png)   @router.post("", status_code=status.HTTP_201_CREATED) async
    def create_conversation_controller(     conversation: ConversationCreate, session:
    SessionDep ) -> ConversationOut:     new_conversation = await ConversationRepository(session).create(         conversation     )
    ![2](assets/2.png)     return ConversationOut.model_validate(new_conversation)   @router.put("/{id}",
    status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     conversation:
    GetConversationDep,     updated_conversation: ConversationUpdate,     session:
    SessionDep, ) -> ConversationOut:     updated_conversation = await ConversationRepository(session).update(
    ![2](assets/2.png)         conversation.id, updated_conversation     )     return
    ConversationOut.model_validate(updated_conversation)   @router.delete("/{id}",
    status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation:
    GetConversationDep, session: SessionDep ) -> None:     await ConversationRepository(session).delete(conversation.id)   #
    main.py  from routers.conversations import router as conversations_router  app.include_router(conversations_router)
    ![1](assets/1.png) [PRE10] # services/conversations.py  from entities import Message
    from repositories.conversations import ConversationRepository from sqlalchemy
    import select  class ConversationService(ConversationRepository):     async def
    list_messages(self, conversation_id: int) -> list[Message]:         result = await
    self.session.execute(             select(Message).where(Message.conversation_id
    == conversation_id)         )         return [m for m in result.scalars().all()]  #
    routers/conversations.py  from database import DBSessionDep from entities import
    Message from fastapi import APIRouter from schemas import MessageOut from services.conversations
    import ConversationService  router = APIRouter(prefix="/conversations")  @router.get("/{conversation_id}/messages")
    ![1](assets/1.png) async def list_conversation_messages_controller(     conversation:
    GetConversationDep,     session: DBSessionDep, ) -> list[Message]:     messages
    = await ConversationService(session).list_messages(conversation.id)     return
    [MessageOut.model_validate(m) for m in messages] [PRE11]`  [PRE12]*# Gestione
    delle modifiche agli schemi di database    Avrai notato che nell''[Esempio 7-3](#sqlalchemy_engine)
    stai cancellando e ricreando le tabelle del database ogni volta che avvii il server
    FastAPI. Questo è accettabile per i flussi di lavoro di sviluppo durante la fase
    di prototipazione, ma non lo è affatto quando devi distribuire i tuoi servizi
    in produzione con utenti attivi. Non puoi resettare il database da zero ogni volta
    che aggiorni lo schema del database.    Inoltre, probabilmente avrai bisogno di
    un modo per ripristinare le modifiche se qualcosa si rompe o se decidi di fare
    un rollback di alcune funzionalità. Per ottenere questo risultato, puoi utilizzare
    uno strumento di migrazione del database come Alembic, progettato per funzionare
    perfettamente con l''ORM SQLAlchemy.    Alembic ti permette di controllare la
    versione degli schemi del tuo database nello stesso modo in cui strumenti come
    Git ti aiutano a controllare la versione del tuo codice. Sono estremamente utili
    quando lavori in un team con più ambienti applicativi e hai bisogno di tenere
    traccia delle modifiche o di ripristinare gli aggiornamenti se necessario.    Per
    iniziare, devi prima installare `alembic` tramite `pip` e poi inizializzarlo eseguendo
    l''[Esempio 7-11](#alembic_init) nella root del tuo progetto FastAPI.    #####
    Esempio 7-11\. Inizializzazione di un ambiente Alembic    [PRE13]py    Alembic
    creerà il suo ambiente all''interno della cartella `alembic` con diversi file
    e una cartella `versions`, come mostrato nell''[Esempio 7-12](#alembic_dir).    #####
    Esempio 7-12\. Ambiente Alembic nella directory principale del progetto    [PRE14]py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO11-1)      Un
    file di ambiente per specificare lo schema di destinazione e le connessioni al
    database      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO11-2)      Una
    directory per contenere i file *di migrazione*, che specificano le istruzioni
    su come aggiornare o ripristinare lo schema del database.      Una volta generato
    l''ambiente Alembic, apri e modifica il file *env.py* che si trova nella directory
    `alembic`, come mostrato nell''[Esempio 7-13](#alembic_env), in modo da ottenere
    l''accesso all''oggetto metadati SQLAlchemy che contiene le informazioni sullo
    schema di destinazione.    ##### Esempio 7-13\. Collegare l''ambiente Alembic
    con i modelli SQLAlchemy    [PRE15]py    Con Alembic collegato ai tuoi modelli
    SQLAlchemy, Alembic può ora generare automaticamente i file di migrazione confrontando
    lo schema attuale del tuo database con i tuoi modelli SQLAlchemy:    [PRE16]py   [PRE17]`
    [PRE18] # main.py  from itertools import tee from database import DBSessionDep
    from entities import Message from fastapi import BackgroundTasks, Depends from
    fastapi.responses import StreamingResponse from repositories.conversations import
    Conversation from repositories.messages import MessageRepository from sqlalchemy.ext.asyncio
    import AsyncSession  async def store_message( ![1](assets/1.png)     prompt_content:
    str,     response_content: str,     conversation_id: int,     session: AsyncSession,
    ) -> None:     message = Message(         conversation_id=conversation_id,         prompt_content=prompt_content,         response_content=response_content,     )     await
    MessageRepository(session).create(message)  @app.get("/text/generate/stream")
    async def stream_llm_controller(     prompt: str,     background_task: BackgroundTasks,     session:
    DBSessionDep,     conversation: Conversation = Depends(get_conversation), ![2](assets/2.png)
    ) -> StreamingResponse:     # Invoke LLM and obtain the response stream     ...     stream_1,
    stream_2 = tee(response_stream) ![3](assets/3.png)     background_task.add_task(         store_message,
    prompt, "".join(stream_1), conversation.id, session     ) ![4](assets/4.png)     return
    StreamingResponse(stream_2) [PRE19] from entities import Conversation from openai
    import AsyncClient from repositories.conversations import ConversationRepository
    from sqlalchemy.ext.asyncio import AsyncSession  async_client = AsyncClient(...)  async
    def create_conversation(     initial_prompt: str, session: AsyncSession ) -> Conversation:     completion
    = await async_client.chat.completions.create(         messages=[             {                 "role":
    "system",                 "content": "Suggest a title for the conversation "                            "based
    on the user prompt",             },             {                 "role": "user",                 "content":
    initial_prompt,             },         ],         model="gpt-'
