- en: Chapter 6\. Normalizing Flow Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。正规化流模型
- en: 'So far, we have discussed three families of generative models: variational
    autoencoders, generative adversarial networks, and autoregressive models. Each
    presents a different way to address the challenge of modeling the distribution
    <math alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math> , either by introducing a latent variable
    that can be easily sampled (and transformed using the decoder in VAEs or generator
    in GANs), or by tractably modeling the distribution as a function of the values
    of preceding elements (autoregressive models).'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了三类生成模型家族：变分自动编码器、生成对抗网络和自回归模型。每种模型都提出了不同的方法来解决建模分布p(x)的挑战，要么通过引入一个可以轻松采样的潜变量（并在VAE中使用解码器或在GAN中使用生成器进行转换），要么通过可处理地将分布建模为前面元素值的函数（自回归模型）。
- en: In this chapter, we will cover a new family of generative models—normalizing
    flow models. As we shall see, normalizing flows share similarities with both autoregressive
    models and variational autoencoders. Like autoregressive models, normalizing flows
    are able to explicitly and tractably model the data-generating distribution <math
    alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> . Like VAEs, normalizing flows attempt to map the data
    into a simpler distribution, such as a Gaussian distribution. The key difference
    is that normalizing flows place a constraint on the form of the mapping function,
    so that it is invertible and can therefore be used to generate new data points.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一种新的生成模型家族——正规化流模型。正如我们将看到的，正规化流与自回归模型和变分自动编码器都有相似之处。像自回归模型一样，正规化流能够明确且可处理地建模数据生成分布p(x)。像变分自动编码器一样，正规化流试图将数据映射到一个更简单的分布，比如高斯分布。关键区别在于，正规化流对映射函数的形式施加了约束，使其可逆，因此可以用来生成新的数据点。
- en: We will dig into this definition in detail in the first section of this chapter
    before implementing a normalizing flow model called RealNVP using Keras. We will
    also see how normalizing flows can be extended to create more powerful models,
    such as GLOW and FFJORD.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一节中，我们将详细探讨这个定义，然后使用Keras实现一个名为RealNVP的正规化流模型。我们还将看到如何扩展正规化流以创建更强大的模型，如GLOW和FFJORD。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: We will begin with a short story to illustrate the key concepts behind normalizing
    flows.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个简短的故事开始，以阐明正规化流背后的关键概念。
- en: The story of Jacob and the F.L.O.W. machine is a depiction of a normalizing
    flow model. Let’s now explore the theory of normalizing flows in more detail,
    before we implement a practical example using Keras.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 雅各布和F.L.O.W.机器的故事是对正规化流模型的描述。现在让我们更详细地探讨正规化流的理论，然后在使用Keras实现一个实际示例之前。
- en: Normalizing Flows
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正规化流
- en: The motivation of normalizing flow models is similar to that of variational
    autoencoders, which we explored in [Chapter 3](ch03.xhtml#chapter_vae). To recap,
    in a variational autoencoder, we learn an *encoder* mapping function between a
    complex distribution and a much simpler distribution that we can sample from.
    We then also learn a *decoder* mapping function from the simpler distribution
    to the complex distribution, so that we can generate a new data point by sampling
    a point <math alttext="z"><mi>z</mi></math> from the simpler distribution and
    applying the learned transformation. Probabilistically speaking, the decoder models
    <math alttext="p left-parenthesis x vertical-bar z right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>z</mi> <mo>)</mo></mrow></math> but the encoder
    is only an approximation <math alttext="q left-parenthesis z vertical-bar x right-parenthesis"><mrow><mi>q</mi>
    <mo>(</mo> <mi>z</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></math> of the true
    <math alttext="p left-parenthesis z vertical-bar x right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>z</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></math> —the encoder
    and decoder are two completely distinct neural networks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正规化流模型的动机与我们在第3章中探讨的变分自动编码器的动机类似。简而言之，在变分自动编码器中，我们学习一个*编码器*映射函数，将一个复杂分布映射到一个我们可以从中采样的简单分布。然后我们还学习一个*解码器*映射函数，从简单分布到复杂分布，这样我们可以通过从简单分布中采样一个点z并应用学习到的转换来生成一个新的数据点。从概率上讲，解码器建模p(x|z)，但编码器只是真实p(z|x)的近似—编码器和解码器是两个完全不同的神经网络。
- en: In a normalizing flow model, the decoding function is designed to be the exact
    inverse of the encoding function and quick to calculate, giving normalizing flows
    the property of tractability. However, neural networks are not by default invertible
    functions. This raises the question of how we can create an invertible process
    that converts between a complex distribution (such as the data generation distribution
    of a set of watercolor paintings) and a much simpler distribution (such as a bell-shaped
    Gaussian distribution) while still making use of the flexibility and power of
    deep learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在正规化流模型中，解码函数被设计为编码函数的精确逆函数且计算迅速，使得正规化流具有可处理性质。然而，神经网络默认情况下不是可逆函数。这引发了一个问题，即我们如何创建一个可逆过程，将一个复杂分布（如一组水彩画的数据生成分布）转换为一个更简单的分布（如钟形高斯分布），同时仍然利用深度学习的灵活性和强大性。
- en: To answer this question, we first need to understand a technique known as *change
    of variables*. For this section, we will work with a simple example in just two
    dimensions, so that you can see exactly how normalizing flows work in fine detail.
    More complex examples are just extensions of the basic techniques presented here.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们首先需要了解一种称为*变量变换*的技术。在本节中，我们将使用一个简单的二维示例，这样你可以看到归一化流是如何详细工作的。更复杂的例子只是基本技术的扩展。
- en: Change of Variables
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量变换
- en: Suppose we have a probability distribution <math alttext="p Subscript upper
    X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> defined over a rectangle
    <math alttext="upper X"><mi>X</mi></math> in two dimensions ( <math alttext="x
    equals left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mi>x</mi> <mo>=</mo>
    <mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> ), as shown in [Figure 6-2](#simple_prob).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个在二维矩形<math alttext="upper X"><mi>X</mi></math>上定义的概率分布<math alttext="p
    Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>（<math
    alttext="x equals left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mi>x</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>），如[图6-2](#simple_prob)所示。
- en: '![https://www.math3d.org/VlDIWw2AK](Images/gdl2_0602.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![https://www.math3d.org/VlDIWw2AK](Images/gdl2_0602.png)'
- en: Figure 6-2\. A probability distribution <math alttext="p Subscript upper X Baseline
    left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> defined over two dimensions,
    shown in 2D (left) and 3D (right)
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2。在二维空间中定义的概率分布<math alttext="p Subscript upper X Baseline left-parenthesis
    x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>，在2D（左）和3D（右）中显示
- en: 'This function integrates to 1 over the domain of the distribution (i.e., <math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> in the range [1, 4] and
    <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> in the range [0,
    2]), so it represents a well-defined probability distribution. We can write this
    as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数在分布的定义域上积分为1（即<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>在范围[1,
    4]，<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>在范围[0, 2]），因此它代表了一个明确定义的概率分布。我们可以写成如下形式：
- en: <math alttext="integral Subscript 0 Superscript 2 Baseline integral Subscript
    1 Superscript 4 Baseline p Subscript upper X Baseline left-parenthesis x right-parenthesis
    d x 1 d x 2 equals 1" display="block"><mrow><msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow>
    <mn>2</mn></msubsup> <msubsup><mo>∫</mo> <mrow><mn>1</mn></mrow> <mn>4</mn></msubsup>
    <msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mi>d</mi> <msub><mi>x</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="integral Subscript 0 Superscript 2 Baseline integral Subscript
    1 Superscript 4 Baseline p Subscript upper X Baseline left-parenthesis x right-parenthesis
    d x 1 d x 2 equals 1" display="block"><mrow><msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow>
    <mn>2</mn></msubsup> <msubsup><mo>∫</mo> <mrow><mn>1</mn></mrow> <mn>4</mn></msubsup>
    <msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mi>d</mi> <msub><mi>x</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>1</mn></mrow></math>
- en: 'Let’s say that we want to shift and scale this distribution so that it is instead
    defined over a unit square <math alttext="upper Z"><mi>Z</mi></math> . We can
    achieve this by defining a new variable <math alttext="z equals left-parenthesis
    z 1 comma z 2 right-parenthesis"><mrow><mi>z</mi> <mo>=</mo> <mo>(</mo> <msub><mi>z</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    and a function <math alttext="f"><mi>f</mi></math> that maps each point in <math
    alttext="upper X"><mi>X</mi></math> to exactly one point in <math alttext="upper
    Z"><mi>Z</mi></math> as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '假设我们想要移动和缩放这个分布，使其在一个单位正方形<math alttext="upper Z"><mi>Z</mi></math>上定义。我们可以通过定义一个新变量<math
    alttext="z equals left-parenthesis z 1 comma z 2 right-parenthesis"><mrow><mi>z</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>z</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>和一个将<math alttext="upper X"><mi>X</mi></math>中的每个点映射到<math
    alttext="upper Z"><mi>Z</mi></math>中的一个点的函数<math alttext="f"><mi>f</mi></math>来实现这一点： '
- en: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    f left-parenthesis x right-parenthesis 2nd Row 1st Column z 1 2nd Column equals
    3rd Column StartFraction x 1 minus 1 Over 3 EndFraction 3rd Row 1st Column z 2
    2nd Column equals 3rd Column StartFraction x 2 Over 2 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mn>1</mn></mrow>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>z</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><msub><mi>x</mi>
    <mn>2</mn></msub> <mn>2</mn></mfrac></mtd></mtr></mtable></math>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    f left-parenthesis x right-parenthesis 2nd Row 1st Column z 1 2nd Column equals
    3rd Column StartFraction x 1 minus 1 Over 3 EndFraction 3rd Row 1st Column z 2
    2nd Column equals 3rd Column StartFraction x 2 Over 2 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mn>1</mn></mrow>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>z</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><msub><mi>x</mi>
    <mn>2</mn></msub> <mn>2</mn></mfrac></mtd></mtr></mtable></math>
- en: Note that this function is *invertible*. That is, there is a function <math
    alttext="g"><mi>g</mi></math> that maps every <math alttext="z"><mi>z</mi></math>
    back to its corresponding <math alttext="x"><mi>x</mi></math> . This is essential
    for a change of variables, as otherwise we cannot consistently map backward and
    forward between the two spaces. We can find <math alttext="g"><mi>g</mi></math>
    simply by rearranging the equations that define <math alttext="f"><mi>f</mi></math>
    , as shown in [Figure 6-3](#change_of_variables).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个函数是*可逆的*。也就是说，有一个函数<math alttext="g"><mi>g</mi></math>，它将每个<math alttext="z"><mi>z</mi></math>映射回其对应的<math
    alttext="x"><mi>x</mi></math>。这对于变量变换是必不可少的，否则我们无法在两个空间之间一致地进行前向和后向映射。我们可以通过简单地重新排列定义<math
    alttext="f"><mi>f</mi></math>的方程来找到<math alttext="g"><mi>g</mi></math>，如[图6-3](#change_of_variables)所示。
- en: '![](Images/gdl2_0603.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0603.png)'
- en: Figure 6-3\. Changing variables between <math alttext="upper X"><mi>X</mi></math>
    and <math alttext="upper Z"><mi>Z</mi></math>
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3。在<math alttext="upper X"><mi>X</mi></math>和<math alttext="upper Z"><mi>Z</mi></math>之间改变变量
- en: 'We now need to see how the change of variables from <math alttext="upper X"><mi>X</mi></math>
    to <math alttext="upper Z"><mi>Z</mi></math> affects the probability distribution
    <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    . We can do this by plugging the equations that define <math alttext="g"><mi>g</mi></math>
    into <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    to transform it into a function <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> that is defined in terms of <math alttext="z"><mi>z</mi></math>
    :'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要看看从<math alttext="upper X"><mi>X</mi></math>到<math alttext="upper Z"><mi>Z</mi></math>的变量变换如何影响概率分布<math
    alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>。我们可以通过将定义<math
    alttext="g"><mi>g</mi></math>的方程代入<math alttext="p Subscript upper X Baseline
    left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>来将其转换为一个以<math alttext="z"><mi>z</mi></math>为变量的函数<math
    alttext="p Subscript upper Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Z</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>：
- en: <math alttext="StartLayout 1st Row 1st Column p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis 2nd Column equals 3rd Column StartFraction left-parenthesis
    left-parenthesis 3 z 1 plus 1 right-parenthesis minus 1 right-parenthesis left-parenthesis
    2 z 2 right-parenthesis Over 9 EndFraction 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column StartFraction 2 z 1 z 2 Over 3 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mo>(</mo><mn>3</mn><msub><mi>z</mi>
    <mn>1</mn></msub> <mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mrow><mo>(</mo><mn>2</mn><msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></mrow> <mn>9</mn></mfrac></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub>
    <msub><mi>z</mi> <mn>2</mn></msub></mrow> <mn>3</mn></mfrac></mtd></mtr></mtable></math>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis 2nd Column equals 3rd Column StartFraction left-parenthesis
    left-parenthesis 3 z 1 plus 1 right-parenthesis minus 1 right-parenthesis left-parenthesis
    2 z 2 right-parenthesis Over 9 EndFraction 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column StartFraction 2 z 1 z 2 Over 3 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mo>(</mo><mn>3</mn><msub><mi>z</mi>
    <mn>1</mn></msub> <mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mrow><mo>(</mo><mn>2</mn><msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></mrow> <mn>9</mn></mfrac></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub>
    <msub><mi>z</mi> <mn>2</mn></msub></mrow> <mn>3</mn></mfrac></mtd></mtr></mtable></math>
- en: However, if we now integrate <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> over the unit square, we can see that
    we have a problem!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们现在在单位正方形上对p_Z(z)进行积分，我们会发现有问题！
- en: <math alttext="integral Subscript 0 Superscript 1 Baseline integral Subscript
    0 Superscript 1 Baseline StartFraction 2 z 1 z 2 Over 3 EndFraction d z 1 d z
    2 equals one-sixth" display="block"><mrow><msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow>
    <mn>1</mn></msubsup> <msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow> <mn>1</mn></msubsup>
    <mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub> <msub><mi>z</mi> <mn>2</mn></msub></mrow>
    <mn>3</mn></mfrac> <mi>d</mi> <msub><mi>z</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="integral Subscript 0 Superscript 1 Baseline integral Subscript
    0 Superscript 1 Baseline StartFraction 2 z 1 z 2 Over 3 EndFraction d z 1 d z
    2 equals one-sixth" display="block"><mrow><msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow>
    <mn>1</mn></msubsup> <msubsup><mo>∫</mo> <mrow><mn>0</mn></mrow> <mn>1</mn></msubsup>
    <mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub> <msub><mi>z</mi> <mn>2</mn></msub></mrow>
    <mn>3</mn></mfrac> <mi>d</mi> <msub><mi>z</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math>
- en: The transformed function <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> is now no longer a valid probability
    distribution, because it only integrates to 1/6\. If we want to transform our
    complex probability distribution over the data into a simpler distribution that
    we can sample from, we must ensure that it integrates to 1.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，转换后的函数p_Z(z)不再是一个有效的概率分布，因为它只积分到1/6。如果我们想要将数据上的复杂概率分布转换为一个简单的我们可以从中抽样的分布，我们必须确保它积分到1。
- en: The missing factor of 6 is due to the fact that the domain of our transformed
    probability distribution is six times smaller than the original domain—the original
    rectangle <math alttext="upper X"><mi>X</mi></math> had area 6, and this has been
    compressed into a unit square <math alttext="upper Z"><mi>Z</mi></math> that only
    has area 1\. Therefore, we need to multiply the new probability distribution by
    a normalization factor that is equal to the relative change in area (or volume
    in higher dimensions).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 缺少的因子6是因为我们转换后的概率分布的定义域比原始定义域小了六倍——原始矩形X的面积为6，而这被压缩成了只有面积为1的单位正方形Z。因此，我们需要将新的概率分布乘以一个归一化因子，该因子等于面积（或在更高维度中的体积）的相对变化。
- en: Luckily, there is a way to calculate this volume change for a given transformation—it
    is the absolute value of the Jacobian determinant of the transformation. Let’s
    unpack that!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一种方法可以计算给定变换的体积变化——即变换的雅可比行列式的绝对值。让我们来解释一下！
- en: The Jacobian Determinant
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 雅可比行列式
- en: 'The *Jacobian* of a function <math alttext="z equals f left-parenthesis x right-parenthesis"><mrow><mi>z</mi>
    <mo>=</mo> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> is the matrix
    of its first-order partial derivatives, as shown here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 函数z=f(x)的雅可比矩阵是其一阶偏导数的矩阵，如下所示：
- en: <math alttext="normal upper J equals StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction equals Start 3 By 3 Matrix 1st
    Row 1st Column StartFraction normal partial-differential z 1 Over normal partial-differential
    x 1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z 1 Over normal partial-differential x Subscript n Baseline EndFraction 2nd Row
    1st Column  ellipsis 2nd Column  ellipsis 3rd Row 1st Column StartFraction normal
    partial-differential z Subscript m Baseline Over normal partial-differential x
    1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z Subscript m Baseline Over normal partial-differential x Subscript n Baseline
    EndFraction EndMatrix" display="block"><mrow><mi mathvariant="normal">J</mi> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mstyle> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>⋯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr>
    <mtr><mtd><mo>⋱</mo></mtd> <mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><mstyle scriptlevel="0"
    displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi> <mi>m</mi></msub></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>⋯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mi>m</mi></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper J equals StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction equals Start 3 By 3 Matrix 1st
    Row 1st Column StartFraction normal partial-differential z 1 Over normal partial-differential
    x 1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z 1 Over normal partial-differential x Subscript n Baseline EndFraction 2nd Row
    1st Column  ellipsis 2nd Column  ellipsis 3rd Row 1st Column StartFraction normal
    partial-differential z Subscript m Baseline Over normal partial-differential x
    1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z Subscript m Baseline Over normal partial-differential x Subscript n Baseline
    EndFraction EndMatrix" display="block"><mrow><mi mathvariant="normal">J</mi> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mstyle> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>⋯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr>
    <mtr><mtd><mo>⋱</mo></mtd> <mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><mstyle scriptlevel="0"
    displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi> <mi>m</mi></msub></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>⋯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mi>m</mi></msub></mrow> <mrow><mi>∂</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr></mtable></mfenced></mrow></math>
- en: The best way to explain this is with our example. If we take the partial derivative
    of <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math> with respect
    to <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> , we obtain <math
    alttext="one-third"><mfrac><mn>1</mn> <mn>3</mn></mfrac></math> . If we take the
    partial derivative of <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math>
    with respect to <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , we obtain 0\. Similarly, if we take the partial derivative of <math alttext="z
    2"><msub><mi>z</mi> <mn>2</mn></msub></math> with respect to <math alttext="x
    1"><msub><mi>x</mi> <mn>1</mn></msub></math> , we obtain 0\. Lastly, if we take
    the partial derivative of <math alttext="z 2"><msub><mi>z</mi> <mn>2</mn></msub></math>
    with respect to <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , we obtain <math alttext="one-half"><mfrac><mn>1</mn> <mn>2</mn></mfrac></math>
    .
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的方法是用我们的例子来解释。如果我们对z1关于x1进行偏导数，我们得到1/3。如果我们对z1关于x2进行偏导数，我们得到0。同样，如果我们对z2关于x1进行偏导数，我们得到0。最后，如果我们对z2关于x2进行偏导数，我们得到1/2。
- en: 'Therefore, the Jacobian matrix for our function <math alttext="f left-parenthesis
    x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    is as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们函数的雅可比矩阵如下：
- en: <math alttext="upper J equals Start 2 By 2 Matrix 1st Row 1st Column one-third
    2nd Column 0 2nd Row 1st Column 0 2nd Column one-half EndMatrix" display="block"><mrow><mi>J</mi>
    <mo>=</mo> <mfenced open="(" close=")"><mtable><mtr><mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>2</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper J equals Start 2 By 2 Matrix 1st Row 1st Column one-third
    2nd Column 0 2nd Row 1st Column 0 2nd Column one-half EndMatrix" display="block"><mrow><mi>J</mi>
    <mo>=</mo> <mfenced open="(" close=")"><mtable><mtr><mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>2</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
- en: The *determinant* is only defined for square matrices and is equal to the signed
    volume of the parallelepiped created by applying the transformation represented
    by the matrix to the unit (hyper)cube. In two dimensions, this is therefore just
    the signed area of the parallelogram created by applying the transformation represented
    by the matrix to the unit square.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 行列式仅对方阵有定义，并且等于通过将矩阵表示的变换应用于单位（超）立方体而创建的平行六面体的有符号体积。在二维中，这只是通过将矩阵表示的变换应用于单位正方形而创建的平行四边形的有符号面积。
- en: 'There is a [general formula](https://oreil.ly/FuDCf) for calculating the determinant
    of a matrix with *n* dimensions, which runs in <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>𝒪</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math> time. For our example, we only need the formula for two
    dimensions, which is simply as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个用于计算具有n维的矩阵行列式的[通用公式](https://oreil.ly/FuDCf)，其运行时间为𝒪(n^3)。对于我们的例子，我们只需要二维的公式，如下所示：
- en: <math alttext="normal d normal e normal t Start 2 By 2 Matrix 1st Row 1st Column
    a 2nd Column b 2nd Row 1st Column c 2nd Column d EndMatrix equals a d minus b
    c" display="block"><mrow><mi>det</mi> <mfenced open="(" close=")"><mtable><mtr><mtd><mi>a</mi></mtd>
    <mtd><mi>b</mi></mtd></mtr> <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mi>a</mi> <mi>d</mi> <mo>-</mo> <mi>b</mi> <mi>c</mi></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal d normal e normal t Start 2 By 2 Matrix 1st Row 1st Column
    a 2nd Column b 2nd Row 1st Column c 2nd Column d EndMatrix equals a d minus b
    c" display="block"><mrow><mi>det</mi> <mfenced open="(" close=")"><mtable><mtr><mtd><mi>a</mi></mtd>
    <mtd><mi>b</mi></mtd></mtr> <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mi>a</mi> <mi>d</mi> <mo>-</mo> <mi>b</mi> <mi>c</mi></mrow></math>
- en: Therefore, for our example, the determinant of the Jacobian is <math alttext="one-third
    times one-half minus 0 times 0 equals one-sixth"><mrow><mfrac><mn>1</mn> <mn>3</mn></mfrac>
    <mo>×</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <mo>-</mo> <mn>0</mn> <mo>×</mo>
    <mn>0</mn> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math> . This
    is the scaling factor of 1/6 that we need to ensure that the probability distribution
    after transformation still integrates to 1!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于我们的示例，雅可比行列式的行列式是 <math alttext="one-third times one-half minus 0 times
    0 equals one-sixth"><mrow><mfrac><mn>1</mn> <mn>3</mn></mfrac> <mo>×</mo> <mfrac><mn>1</mn>
    <mn>2</mn></mfrac> <mo>-</mo> <mn>0</mn> <mo>×</mo> <mn>0</mn> <mo>=</mo> <mfrac><mn>1</mn>
    <mn>6</mn></mfrac></mrow></math>。这是我们需要确保变换后的概率分布仍然积分为1的缩放因子为1/6！
- en: Tip
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: By definition, the determinant is signed—that is, it can be negative. Therefore
    we need to take the absolute value of the Jacobian determinant in order to obtain
    the relative change of volume.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，行列式是有符号的——也就是说，它可以是负数。因此，我们需要取雅可比行列式的绝对值，以获得体积的相对变化。
- en: The Change of Variables Equation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量转换方程
- en: We can now write down a single equation that describes the process for changing
    variables between <math alttext="upper X"><mi>X</mi></math> and <math alttext="upper
    Z"><mi>Z</mi></math> . This is known as the *change of variables equation* ([Equation
    6-1](#cov_equation)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以写下一个单一方程，描述在 <math alttext="upper X"><mi>X</mi></math> 和 <math alttext="upper
    Z"><mi>Z</mi></math> 之间变量转换的过程。这被称为*变量转换方程*（[方程6-1](#cov_equation)）。
- en: Equation 6-1\. The change of variables equation
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程6-1. 变量转换方程
- en: <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals p Subscript upper Z Baseline left-parenthesis z right-parenthesis StartAbsoluteValue
    normal d normal e normal t left-parenthesis StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction right-parenthesis EndAbsoluteValue"
    display="block"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mfenced separators="" open="|" close="|"><mi>det</mi>
    <mfenced separators="" open="(" close=")"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals p Subscript upper Z Baseline left-parenthesis z right-parenthesis StartAbsoluteValue
    normal d normal e normal t left-parenthesis StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction right-parenthesis EndAbsoluteValue"
    display="block"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mfenced separators="" open="|" close="|"><mi>det</mi>
    <mfenced separators="" open="(" close=")"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
- en: How does this help us build a generative model? The key is understanding that
    if <math alttext="p Subscript upper Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Z</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>
    is a simple distribution from which we can easily sample (e.g., a Gaussian), then
    in theory, all we need to do is find an appropriate invertible function <math
    alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> that can map from the data <math alttext="upper X"><mi>X</mi></math>
    into <math alttext="upper Z"><mi>Z</mi></math> and the corresponding inverse function
    <math alttext="g left-parenthesis z right-parenthesis"><mrow><mi>g</mi> <mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></math> that can be used to map a sampled <math alttext="z"><mi>z</mi></math>
    back to a point <math alttext="x"><mi>x</mi></math> in the original domain. We
    can use the preceding equation involving the Jacobian determinant to find an exact,
    tractable formula for the data distribution <math alttext="p left-parenthesis
    x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    .
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这如何帮助我们构建一个生成模型？关键在于理解，如果 <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> 是一个简单的分布，我们可以轻松地从中抽样（例如，高斯分布），那么理论上，我们所需要做的就是找到一个适当的可逆函数
    <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math>，可以将数据 <math alttext="upper X"><mi>X</mi></math>
    映射到 <math alttext="upper Z"><mi>Z</mi></math>，以及相应的逆函数 <math alttext="g left-parenthesis
    z right-parenthesis"><mrow><mi>g</mi> <mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></math>，可以用来将抽样的
    <math alttext="z"><mi>z</mi></math> 映射回原始域中的点 <math alttext="x"><mi>x</mi></math>。我们可以使用涉及雅可比行列式的前述方程找到数据分布
    <math alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math> 的一个精确、可处理的公式。
- en: However, there are two major issues when applying this in practice that we first
    need to address!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实践中应用时存在两个主要问题，我们首先需要解决！
- en: Firstly, calculating the determinant of a high-dimensional matrix is computationally
    extremely expensive—specifically, it is <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>𝒪</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math> . This is completely impractical to implement in practice,
    as even small 32 × 32–pixel grayscale images have 1,024 dimensions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，计算高维矩阵的行列式在计算上是极其昂贵的——具体来说，是 <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>𝒪</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math>。这在实践中是完全不切实际的，因为即使是小的32×32像素灰度图像也有1024个维度。
- en: Secondly, it is not immediately obvious how we should go about calculating the
    invertible function <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> . We could use a neural network
    to find some function <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> but we cannot necessarily invert
    this network—neural networks only work in one direction!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们不清楚如何计算可逆函数 <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>。我们可以使用神经网络找到一些函数 <math alttext="f
    left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>，但我们不能保证可以反转这个网络——神经网络只能单向工作！
- en: To solve these two problems, we need to use a special neural network architecture
    that ensures that the change of variables function <math alttext="f"><mi>f</mi></math>
    is invertible and has a determinant that is easy to calculate.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这两个问题，我们需要使用一种特殊的神经网络架构，确保变量转换函数 <math alttext="f"><mi>f</mi></math> 是可逆的，并且其行列式易于计算。
- en: We shall see how to do this in the following section using a technique called
    *real-valued non-volume preserving (RealNVP) transformations*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分中看到如何使用一种称为*实值非体积保持（RealNVP）变换*的技术来解决这个问题。
- en: RealNVP
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RealNVP
- en: RealNVP was first introduced by Dinh et al. in 2017.^([1](ch06.xhtml#idm45387014186656))
    In this paper the authors show how to construct a neural network that can transform
    a complex data distribution into a simple Gaussian, while also possessing the
    desired properties of being invertible and having a Jacobian that can be easily
    calculated.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVP首次由Dinh等人在2017年提出。在这篇论文中，作者展示了如何构建一个神经网络，可以将复杂的数据分布转换为简单的高斯分布，同时具有可逆性和易于计算雅可比行列式的期望特性。
- en: Running the Code for This Example
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行此示例的代码
- en: The code for this example can be found in the Jupyter notebook located at *notebooks/06_normflow/01_realnvp/realnvp.ipynb*
    in the book repository.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的代码可以在位于书籍存储库中的*notebooks/06_normflow/01_realnvp/realnvp.ipynb*的Jupyter笔记本中找到。
- en: The code has been adapted from the excellent [RealNVP tutorial](https://oreil.ly/ZjjwP)
    created by Mandolini Giorgio Maria et al. available on the Keras website.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码改编自由Mandolini Giorgio Maria等人创建的优秀[RealNVP教程](https://oreil.ly/ZjjwP)，可在Keras网站上找到。
- en: The Two Moons Dataset
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 两个moons数据集
- en: The dataset we will use for this example is created by the `make_moons` function
    from the Python library `sklearn`. This creates a noisy dataset of points in 2D
    that resemble two crescents, as shown in [Figure 6-4](#moons_image).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在此示例中使用的数据集是由Python库`sklearn`中的`make_moons`函数创建的。这将创建一个嘈杂的2D点数据集，类似于两个新月形状，如[图6-4](#moons_image)所示。
- en: '![gdl2 0604](Images/gdl2_0604.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![gdl2 0604](Images/gdl2_0604.png)'
- en: Figure 6-4\. The two moons dataset in two dimensions
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4。二维中的两个moons数据集
- en: The code for creating this dataset is given in [Example 6-1](#moons-dataset).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 创建此数据集的代码在[示例6-1](#moons-dataset)中给出。
- en: Example 6-1\. Creating a *moons* dataset
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-1。创建一个*moons*数据集
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO1-1)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO1-1)'
- en: Make a noisy, unnormalized moons dataset of 3,000 points.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个包含3,000个点的嘈杂、非标准化的moons数据集。
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO1-2)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO1-2)'
- en: Normalize the dataset to have mean 0 and standard deviation 1.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集归一化为均值为0，标准差为1。
- en: We will build a RealNVP model that can generate points in 2D that follow a similar
    distribution to the two moons dataset. Whilst this is a very simple example, it
    will help us understand how a normalizing flow model works in practice, in fine
    detail.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个RealNVP模型，可以生成遵循与两个moons数据集类似分布的2D点。虽然这是一个非常简单的例子，但它将帮助我们详细了解正规化流模型在实践中的工作方式。
- en: First, however, we need to introduce a new type of layer, called a coupling
    layer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，首先，我们需要介绍一种新类型的层，称为耦合层。
- en: Coupling Layers
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 耦合层
- en: A *coupling layer* produces a scale and translation factor for each element
    of its input. In other words, it produces two tensors that are exactly the same
    size as the input, one for the scale factor and one for the translation factor,
    as shown in [Figure 6-5](#coupling_layer).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*耦合层*为其输入的每个元素产生一个比例和平移因子。换句话说，它产生两个与输入完全相同大小的张量，一个用于比例因子，一个用于平移因子，如[图6-5](#coupling_layer)所示。'
- en: '![](Images/gdl2_0605.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0605.png)'
- en: 'Figure 6-5\. A coupling layer outputs two tensors that are the same shape as
    the input: a scaling factor (s) and a translation factor (t)'
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-5。耦合层输出两个与输入相同形状的张量：一个缩放因子（s）和一个平移因子（t）
- en: To build a custom `Coupling` layer for our simple example, we can stack `Dense`
    layers to create the scale output and a different set of `Dense` layers to create
    the translation output, as shown in [Example 6-2](#coupling-layer-code).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为我们的简单示例构建自定义的`Coupling`层，我们可以堆叠`Dense`层以创建比例输出，并堆叠不同的`Dense`层以创建平移输出，如[示例6-2](#coupling-layer-code)所示。
- en: Tip
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: For images, `Coupling` layer blocks use `Conv2D` layers instead of `Dense` layers.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像，`Coupling`层块使用`Conv2D`层而不是`Dense`层。
- en: Example 6-2\. A `Coupling` layer in Keras
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-2。Keras中的`Coupling`层
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO2-1)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO2-1)'
- en: The input to the `Coupling` layer block in our example has two dimensions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例中`Coupling`层块的输入有两个维度。
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO2-2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO2-2)'
- en: The *scaling* stream is a stack of `Dense` layers of size 256.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*缩放*流是一个大小为256的`Dense`层堆叠。'
- en: '[![3](Images/3.png)](#co_normalizing_flow_models_CO2-3)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_normalizing_flow_models_CO2-3)'
- en: The final scaling layer is of size 2 and has `tanh` activation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的缩放层大小为2，并具有`tanh`激活。
- en: '[![4](Images/4.png)](#co_normalizing_flow_models_CO2-4)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_normalizing_flow_models_CO2-4)'
- en: The *translation* stream is a stack of `Dense` layers of size 256.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*平移*流是一个大小为256的`Dense`层堆叠。'
- en: '[![5](Images/5.png)](#co_normalizing_flow_models_CO2-5)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_normalizing_flow_models_CO2-5)'
- en: The final translation layer is of size 2 and has `linear` activation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的翻译层大小为2，并具有`linear`激活。
- en: '[![6](Images/6.png)](#co_normalizing_flow_models_CO2-6)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_normalizing_flow_models_CO2-6)'
- en: The `Coupling` layer is constructed as a Keras `Model` with two outputs (the
    scaling and translation factors).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`Coupling`层被构建为一个Keras `Model`，具有两个输出（缩放和平移因子）。'
- en: Notice how the number of channels is temporarily increased to allow for a more
    complex representation to be learned, before being collapsed back down to the
    same number of channels as the input. In the original paper, the authors also
    use regularizers on each layer to penalize large weights.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，临时增加通道数以允许学习更复杂的表示，然后将其折叠回与输入相同数量的通道。在原始论文中，作者还在每一层上使用正则化器来惩罚大的权重。
- en: Passing data through a coupling layer
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过耦合层传递数据
- en: The architecture of a coupling layer is not particularly interesting—what makes
    it unique is the way the input data is masked and transformed as it is fed through
    the layer, as shown in [Figure 6-6](#forward_update_equations).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 耦合层的架构并不特别有趣——它的独特之处在于输入数据在通过层时如何被掩盖和转换，如[图6-6](#forward_update_equations)所示。
- en: '![](Images/gdl2_0606.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0606.png)'
- en: Figure 6-6\. The process of transforming the input <math alttext="x"><mi>x</mi></math>
    through a coupling layer
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-6。通过耦合层转换输入<math alttext="x"><mi>x</mi></math>的过程
- en: Notice how only the first <math alttext="d"><mi>d</mi></math> dimensions of
    the data are fed through to the first coupling layer—the remaining <math alttext="upper
    D minus d"><mrow><mi>D</mi> <mo>-</mo> <mi>d</mi></mrow></math> dimensions are
    completely masked (i.e., set to zero). In our simple example with <math alttext="upper
    D equals 2"><mrow><mi>D</mi> <mo>=</mo> <mn>2</mn></mrow></math> , choosing <math
    alttext="d equals 1"><mrow><mi>d</mi> <mo>=</mo> <mn>1</mn></mrow></math> means
    that instead of the coupling layer seeing two values, <math alttext="left-parenthesis
    x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math> , the layer
    sees <math alttext="left-parenthesis x 1 comma 0 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math>
    .
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意数据的前<math alttext="d"><mi>d</mi></math>维度被直接传递到第一个耦合层，剩下的<math alttext="upper
    D minus d"><mrow><mi>D</mi> <mo>-</mo> <mi>d</mi></mrow></math>维度完全被遮蔽（即设为零）。在我们的简单示例中，选择<math
    alttext="d equals 1"><mrow><mi>d</mi> <mo>=</mo> <mn>1</mn></mrow></math>意味着耦合层看到的不是两个值<math
    alttext="left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>，而是看到<math
    alttext="left-parenthesis x 1 comma 0 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math>。
- en: 'The outputs from the layer are the scale and translation factors. These are
    again masked, but this time with the *inverse* mask to previously, so that only
    the second halves are let through—i.e., in our example, we obtain <math alttext="left-parenthesis
    0 comma s 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> and <math alttext="left-parenthesis
    0 comma t 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>t</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> . These are then applied element-wise
    to the second half of the input <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    and the first half of the input <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    is simply passed straight through, without being updated at all. In summary, for
    a vector with dimension <math alttext="upper D"><mi>D</mi></math> where <math
    alttext="d less-than upper D"><mrow><mi>d</mi> <mo><</mo> <mi>D</mi></mrow></math>
    , the update equations are as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 层的输出是比例和平移因子。这些再次被遮蔽，但这次是与之前的*反向*遮罩，只有后半部分被放行——即在我们的示例中，我们得到<math alttext="left-parenthesis
    0 comma s 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>和<math alttext="left-parenthesis 0 comma
    t 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>t</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>。然后这些被逐元素应用到输入的后半部分<math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math>，而输入的前半部分<math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math>则直接传递，完全不被更新。总之，对于维度为<math alttext="upper D"><mi>D</mi></math>的向量，其中<math
    alttext="d less-than upper D"><mrow><mi>d</mi> <mo><</mo> <mi>D</mi></mrow></math>，更新方程如下：
- en: <math alttext="StartLayout 1st Row 1st Column z Subscript 1 colon d 2nd Column
    equals 3rd Column x Subscript 1 colon d 2nd Row 1st Column z Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column x Subscript d plus 1 colon upper
    D Baseline circled-dot normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis plus t left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub>
    <mo>⊙</mo> <mi>exp</mi> <mfenced separators="" open="(" close=")"><mi>s</mi> <mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mfenced>
    <mo>+</mo> <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z Subscript 1 colon d 2nd Column
    equals 3rd Column x Subscript 1 colon d 2nd Row 1st Column z Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column x Subscript d plus 1 colon upper
    D Baseline circled-dot normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis plus t left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub>
    <mo>⊙</mo> <mi>exp</mi> <mfenced separators="" open="(" close=")"><mi>s</mi> <mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mfenced>
    <mo>+</mo> <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: 'You may be wondering why we go to the trouble of building a layer that masks
    so much information. The answer is clear if we investigate the structure of the
    Jacobian matrix of this function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道为什么我们要费力构建一个遮蔽了这么多信息的层。答案很明显，如果我们调查这个函数的雅可比矩阵的结构：
- en: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x EndFraction equals Start 2 By 2 Matrix 1st Row 1st Column bold upper I 2nd Column
    0 2nd Row 1st Column StartFraction normal partial-differential z Subscript d plus
    1 colon upper D Baseline Over normal partial-differential x Subscript 1 colon
    d Baseline EndFraction 2nd Column normal d normal i normal a normal g left-parenthesis
    normal e normal x normal p left-bracket s left-parenthesis x Subscript 1 colon
    d Baseline right-parenthesis right-bracket right-parenthesis EndMatrix" display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>𝐈</mi></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></mfrac></mtd>
    <mtd><mrow><mi>diag</mi> <mo>(</mo> <mi>exp</mi> <mrow><mo>[</mo> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow>
    <mo>]</mo></mrow> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x EndFraction equals Start 2 By 2 Matrix 1st Row 1st Column bold upper I 2nd Column
    0 2nd Row 1st Column StartFraction normal partial-differential z Subscript d plus
    1 colon upper D Baseline Over normal partial-differential x Subscript 1 colon
    d Baseline EndFraction 2nd Column normal d normal i normal a normal g left-parenthesis
    normal e normal x normal p left-bracket s left-parenthesis x Subscript 1 colon
    d Baseline right-parenthesis right-bracket right-parenthesis EndMatrix" display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>𝐈</mi></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mfrac><mrow><mi>∂</mi><msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></mfrac></mtd>
    <mtd><mrow><mi>diag</mi> <mo>(</mo> <mi>exp</mi> <mrow><mo>[</mo> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow>
    <mo>]</mo></mrow> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: The top-left <math alttext="d times d"><mrow><mi>d</mi> <mo>×</mo> <mi>d</mi></mrow></math>
    submatrix is simply the identity matrix, because <math alttext="z Subscript 1
    colon d Baseline equals x Subscript 1 colon d"><mrow><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>=</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></math>
    . These elements are passed straight through without being updated. The top-right
    submatrix is therefore 0, because <math alttext="z Subscript 1 colon d"><msub><mi>z</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></math> is not dependent on
    <math alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    .
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 左上角的<math alttext="d times d"><mrow><mi>d</mi> <mo>×</mo> <mi>d</mi></mrow></math>子矩阵只是单位矩阵，因为<math
    alttext="z Subscript 1 colon d Baseline equals x Subscript 1 colon d"><mrow><msub><mi>z</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>=</mo> <msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></math>。这些元素直接传递而不被更新。因此，右上角的子矩阵为0，因为<math
    alttext="z Subscript 1 colon d"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></math>不依赖于<math
    alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>。
- en: The bottom-left submatrix is complex, and we do not seek to simplify this. The
    bottom-right submatrix is simply a diagonal matrix, filled with the elements of
    <math alttext="normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis"><mrow><mi>exp</mi>
    <mo>(</mo> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow></math> , because <math alttext="z Subscript
    d plus 1 colon upper D"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    is linearly dependent on <math alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    and the gradient is dependent only on the scaling factor (not on the translation
    factor). [Figure 6-7](#jacobian_upper_triangular) shows a diagram of this matrix
    form, where only the nonzero elements are filled in with color.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 左下角的子矩阵是复杂的，我们不寻求简化这个。右下角的子矩阵只是一个对角矩阵，填充有<math alttext="normal e normal x normal
    p left-parenthesis s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis
    right-parenthesis"><mrow><mi>exp</mi> <mo>(</mo> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
    ，因为<math alttext="z Subscript d plus 1 colon upper D"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>是线性相关于<math
    alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>，梯度仅依赖于缩放因子（而不依赖于平移因子）。[图6-7](#jacobian_upper_triangular)显示了这个矩阵形式的图表，只有非零元素被填充为彩色。
- en: Notice how there are no nonzero elements above the diagonal—for this reason,
    this matrix form is called *lower triangular*. Now we see the benefit of structuring
    the matrix in this way—the determinant of a lower-triangular matrix is just equal
    to the product of the diagonal elements. In other words, the determinant is not
    dependent on any of the complex derivatives in the bottom-left submatrix!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意对角线上方没有非零元素—因此，这种矩阵形式被称为*下三角形*。现在我们看到了以这种方式构造矩阵的好处—下三角矩阵的行列式就等于对角线元素的乘积。换句话说，行列式不依赖于左下子矩阵中的任何复杂导数！
- en: '![](Images/gdl2_0607.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0607.png)'
- en: Figure 6-7\. The Jacobian matrix of the transformation—a lower triangular matrix,
    with determinant equal to the product of the elements along the diagonal
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-7。变换的雅可比矩阵——一个下三角矩阵，行列式等于对角线上元素的乘积
- en: 'Therefore, we can write the determinant of this matrix as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以将这个矩阵的行列式写成如下形式：
- en: <math alttext="normal d normal e normal t left-parenthesis normal upper J right-parenthesis
    equals normal e normal x normal p left-bracket sigma-summation Underscript j Endscripts
    s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis Subscript
    j Baseline right-bracket" display="block"><mrow><mi>det</mi> <mrow><mo>(</mo>
    <mi mathvariant="normal">J</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>exp</mi> <mfenced
    separators="" open="[" close="]"><munder><mo>∑</mo> <mi>j</mi></munder> <mi>s</mi>
    <msub><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mi>j</mi></msub></mfenced></mrow></math>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal d normal e normal t left-parenthesis normal upper J right-parenthesis
    equals normal e normal x normal p left-bracket sigma-summation Underscript j Endscripts
    s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis Subscript
    j Baseline right-bracket" display="block"><mrow><mi>det</mi> <mrow><mo>(</mo>
    <mi mathvariant="normal">J</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>exp</mi> <mfenced
    separators="" open="[" close="]"><munder><mo>∑</mo> <mi>j</mi></munder> <mi>s</mi>
    <msub><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mi>j</mi></msub></mfenced></mrow></math>
- en: This is easily computable, which was one of the two original goals of building
    a normalizing flow model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是很容易计算的，这是构建归一化流模型的两个最初目标之一。
- en: 'The other goal was that the function must be easily invertible. We can see
    that this is true as we can write down the invertible function just by rearranging
    the forward equations, as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个目标是函数必须易于反转。我们可以看到这是正确的，因为我们可以通过重新排列正向方程来写出可逆函数，如下所示：
- en: <math alttext="StartLayout 1st Row 1st Column x Subscript 1 colon d 2nd Column
    equals 3rd Column z Subscript 1 colon d 2nd Row 1st Column x Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column left-parenthesis z Subscript d plus
    1 colon upper D Baseline minus t left-parenthesis x Subscript 1 colon d Baseline
    right-parenthesis right-parenthesis circled-dot normal e normal x normal p left-parenthesis
    minus s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mrow><mo>(</mo> <msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub> <mo>-</mo>
    <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>⊙</mo> <mi>exp</mi> <mfenced separators=""
    open="(" close=")"><mo>-</mo> <mi>s</mi> <mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mfenced></mrow></mtd></mtr></mtable></math>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x Subscript 1 colon d 2nd Column
    equals 3rd Column z Subscript 1 colon d 2nd Row 1st Column x Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column left-parenthesis z Subscript d plus
    1 colon upper D Baseline minus t left-parenthesis x Subscript 1 colon d Baseline
    right-parenthesis right-parenthesis circled-dot normal e normal x normal p left-parenthesis
    minus s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mrow><mo>(</mo> <msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub> <mo>-</mo>
    <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>⊙</mo> <mi>exp</mi> <mfenced separators=""
    open="(" close=")"><mo>-</mo> <mi>s</mi> <mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mfenced></mrow></mtd></mtr></mtable></math>
- en: The equivalent diagram is shown in [Figure 6-8](#backward_update_equations).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 等效图表显示在[图6-8](#backward_update_equations)中。
- en: '![](Images/gdl2_0608.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0608.png)'
- en: Figure 6-8\. The inverse function x = g(z)
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-8。逆函数x = g(z)
- en: We now have almost everything we need to build our RealNVP model. However, there
    is one issue that still remains—how should we update the first <math alttext="d"><mi>d</mi></math>
    elements of the input? Currently they are left completely unchanged by the model!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们几乎拥有构建RealNVP模型所需的一切。然而，仍然存在一个问题—我们应该如何更新输入的前<d>个元素？目前，它们被模型完全保持不变！
- en: Stacking coupling layers
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 堆叠耦合层
- en: To resolve this problem, we can use a really simple trick. If we stack coupling
    layers on top of each other but alternate the masking pattern, the layers that
    are left unchanged by one layer will be updated in the next. This architecture
    has the added benefit of being able to learn more complex representations of the
    data, as it is a deeper neural network.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以使用一个非常简单的技巧。如果我们将耦合层堆叠在一起，但交替掩码模式，那么被一个层保持不变的层将在下一个层中更新。这种架构的额外好处是能够学习数据的更复杂表示，因为它是一个更深的神经网络。
- en: 'The Jacobian of this composition of coupling layers will still be simple to
    compute, because linear algebra tells us that the determinant of a matrix product
    is the product of the determinants. Similarly, the inverse of the composition
    of two functions is just the composition of the inverses, as shown in the following
    equations:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些耦合层的雅可比矩阵仍然很容易计算，因为线性代数告诉我们，矩阵乘积的行列式是对角线上元素的乘积。同样，两个函数的复合的逆函数就是逆函数的复合，如下方程所示：
- en: <math alttext="StartLayout 1st Row 1st Column normal d normal e normal t left-parenthesis
    normal upper A dot normal upper B right-parenthesis 2nd Column equals 3rd Column
    normal d normal e normal t left-parenthesis normal upper A right-parenthesis normal
    d normal e normal t left-parenthesis normal upper B right-parenthesis 2nd Row
    1st Column left-parenthesis f Subscript b Baseline ring f Subscript a Baseline
    right-parenthesis Superscript negative 1 2nd Column equals 3rd Column f Subscript
    a Superscript negative 1 Baseline ring f Subscript b Superscript negative 1 EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>·</mo> <mi mathvariant="normal">B</mi>
    <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>)</mo> <mi>det</mi> <mo>(</mo>
    <mi mathvariant="normal">B</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msup><mrow><mo>(</mo><msub><mi>f</mi>
    <mi>b</mi></msub> <mo>∘</mo><msub><mi>f</mi> <mi>a</mi></msub> <mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msubsup><mi>f</mi>
    <mi>a</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup> <mo>∘</mo> <msubsup><mi>f</mi>
    <mi>b</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mtd></mtr></mtable></math>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column normal d normal e normal t left-parenthesis
    normal upper A dot normal upper B right-parenthesis 2nd Column equals 3rd Column
    normal d normal e normal t left-parenthesis normal upper A right-parenthesis normal
    d normal e normal t left-parenthesis normal upper B right-parenthesis 2nd Row
    1st Column left-parenthesis f Subscript b Baseline ring f Subscript a Baseline
    right-parenthesis Superscript negative 1 2nd Column equals 3rd Column f Subscript
    a Superscript negative 1 Baseline ring f Subscript b Superscript negative 1 EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>·</mo> <mi mathvariant="normal">B</mi>
    <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>)</mo> <mi>det</mi> <mo>(</mo>
    <mi mathvariant="normal">B</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msup><mrow><mo>(</mo><msub><mi>f</mi>
    <mi>b</mi></msub> <mo>∘</mo><msub><mi>f</mi> <mi>a</mi></msub> <mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msubsup><mi>f</mi>
    <mi>a</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup> <mo>∘</mo> <msubsup><mi>f</mi>
    <mi>b</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mtd></mtr></mtable></math>
- en: Therefore, if we stack coupling layers, flipping the masking each time, we can
    build a neural network that is able to transform the whole input tensor, while
    retaining the essential properties of having a simple Jacobian determinant and
    being invertible. [Figure 6-9](#stacking_coupling) shows the overall structure.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们堆叠耦合层，每次翻转掩码，我们可以构建一个神经网络，能够转换整个输入张量，同时保留具有简单雅可比行列式和可逆性的基本属性。[图6-9](#stacking_coupling)显示了整体结构。
- en: '![](Images/gdl2_0609.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0609.png)'
- en: Figure 6-9\. Stacking coupling layers, alternating the masking with each layer
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-9。堆叠耦合层，每层交替掩码
- en: Training the RealNVP Model
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练RealNVP模型
- en: 'Now that we have built the RealNVP model, we can train it to learn the complex
    distribution of the two moons dataset. Remember, we want to minimize the negative
    log-likelihood of the data under the model <math alttext="minus log p Subscript
    upper X Baseline left-parenthesis x right-parenthesis"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></mrow></math>
    . Using [Equation 6-1](#cov_equation), we can write this as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了RealNVP模型，我们可以训练它来学习两个月亮数据集的复杂分布。记住，我们希望最小化模型下数据的负对数似然 <math alttext="minus
    log p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><mo>-</mo>
    <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></mrow></math> 。使用[方程6-1](#cov_equation)，我们可以写成如下形式：
- en: <math alttext="minus log p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals minus log p Subscript upper Z Baseline left-parenthesis z right-parenthesis
    minus log StartAbsoluteValue normal d normal e normal t left-parenthesis StartFraction
    normal partial-differential z Over normal partial-differential x EndFraction right-parenthesis
    EndAbsoluteValue" display="block"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow>
    <mo>=</mo> <mo>-</mo> <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow> <mo>-</mo> <mo form="prefix">log</mo>
    <mfenced separators="" open="|" close="|"><mi>det</mi> <mfenced separators=""
    open="(" close=")"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="minus log p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals minus log p Subscript upper Z Baseline left-parenthesis z right-parenthesis
    minus log StartAbsoluteValue normal d normal e normal t left-parenthesis StartFraction
    normal partial-differential z Over normal partial-differential x EndFraction right-parenthesis
    EndAbsoluteValue" display="block"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow>
    <mo>=</mo> <mo>-</mo> <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow> <mo>-</mo> <mo form="prefix">log</mo>
    <mfenced separators="" open="|" close="|"><mi>det</mi> <mfenced separators=""
    open="(" close=")"><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
- en: We choose the target output distribution <math alttext="p Subscript upper Z
    Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math> of the forward process
    <math alttext="f"><mi>f</mi></math> to be a standard Gaussian, because we can
    easily sample from this distribution. We can then transform a point sampled from
    the Gaussian back into the original image domain by applying the inverse process
    <math alttext="g"><mi>g</mi></math> , as shown in [Figure 6-10](#realnvp_to_gaussian).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择正向过程<f>的目标输出分布 <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> 为标准高斯分布，因为我们可以轻松从这个分布中采样。然后，我们可以通过应用逆过程<g>将从高斯分布中采样的点转换回原始图像域，如[图6-10](#realnvp_to_gaussian)所示。
- en: '![](Images/gdl2_0610.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0610.png)'
- en: Figure 6-10\. Transforming between the complex distribution <math alttext="p
    Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    and a simple Gaussian <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> in 1D (middle row) and 2D (bottom row)
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-10。在1D（中间行）和2D（底部行）中，将复杂分布<math alttext="p Subscript upper X Baseline left-parenthesis
    x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>和简单高斯<math alttext="p Subscript upper
    Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>之间的转换
- en: '[Example 6-3](#realnvp_model) shows how to build a RealNVP network, as a custom
    Keras `Model`.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例6-3](#realnvp_model)展示了如何构建一个RealNVP网络，作为自定义的Keras `Model`。'
- en: Example 6-3\. Building the RealNVP model in Keras
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-3。在Keras中构建RealNVP模型
- en: '[PRE2]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO3-1)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO3-1)'
- en: The target distribution is a standard 2D Gaussian.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 目标分布是标准的2D高斯分布。
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO3-2)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO3-2)'
- en: Here, we create the alternating mask pattern.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建交替的掩码模式。
- en: '[![3](Images/3.png)](#co_normalizing_flow_models_CO3-3)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_normalizing_flow_models_CO3-3)'
- en: A list of `Coupling` layers that define the RealNVP network.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 定义RealNVP网络的`Coupling`层列表。
- en: '[![4](Images/4.png)](#co_normalizing_flow_models_CO3-4)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_normalizing_flow_models_CO3-4)'
- en: In the main `call` function of the network, we loop over the `Coupling` layers.
    If `training=True`, then we move forward through the layers (i.e., from data to
    latent space). If `training=False`, then we move backward through the layers (i.e.,
    from latent space to data).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络的主`call`函数中，我们遍历`Coupling`层。如果`training=True`，那么我们通过层向前移动（即从数据到潜在空间）。如果`training=False`，那么我们通过层向后移动（即从潜在空间到数据）。
- en: '[![5](Images/5.png)](#co_normalizing_flow_models_CO3-5)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_normalizing_flow_models_CO3-5)'
- en: This line describes both the forward and backward equations dependent on the
    `direction` (try plugging in `direction = -1` and `direction = 1` to prove this
    to yourself!).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这行描述了正向和反向方程，取决于`direction`（尝试将`direction = -1`和`direction = 1`代入以证明这一点！）。
- en: '[![6](Images/6.png)](#co_normalizing_flow_models_CO3-6)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_normalizing_flow_models_CO3-6)'
- en: The log determinant of the Jacobian, which we need to calculate the loss function,
    is simply the sum of the scaling factors.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 雅可比行列式的对数，我们需要计算损失函数，简单地是缩放因子的总和。
- en: '[![7](Images/7.png)](#co_normalizing_flow_models_CO3-7)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_normalizing_flow_models_CO3-7)'
- en: The loss function is the negative sum of the log probability of the transformed
    data, under our target Gaussian distribution and the log determinant of the Jacobian.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数是转换数据的对数概率的负和，根据我们的目标高斯分布和雅可比行列式的对数确定。
- en: Analysis of the RealNVP Model
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealNVP模型的分析
- en: Once the model is trained, we can use it to transform the training set into
    the latent space (using the forward direction, <math alttext="f"><mi>f</mi></math>
    ) and, more importantly, to transform a sampled point in the latent space into
    a point that looks like it could have been sampled from the original data distribution
    (using the backward direction, <math alttext="g"><mi>g</mi></math> ).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，我们可以使用它将训练集转换为潜在空间（使用正向方向<math alttext="f"><mi>f</mi></math>），更重要的是，将潜在空间中的采样点转换为看起来可能是从原始数据分布中采样的点（使用反向方向<math
    alttext="g"><mi>g</mi></math>）。
- en: '[Figure 6-11](#realnvp_before_training) shows the output from the network before
    any learning has taken place—the forward and backward directions just pass information
    straight through with hardly any transformation.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-11](#realnvp_before_training)显示了在任何学习之前网络的输出 - 正向和反向方向只是直接传递信息，几乎没有任何转换。'
- en: '![](Images/gdl2_0611.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0611.png)'
- en: Figure 6-11\. The RealNVP model inputs (left) and outputs (right) before training,
    for the forward process (top) and the reverse process (bottom)
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-11。RealNVP模型在训练前的输入（左）和输出（右），用于正向过程（顶部）和反向过程（底部）
- en: After training ([Figure 6-12](#realnvp_after_training)), the forward process
    is able to convert the points from the training set into a distribution that resembles
    a Gaussian. Likewise, the backward process can take points sampled from a Gaussian
    distribution and map them back to a distribution that resembles the original data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后（[图6-12](#realnvp_after_training)），正向过程能够将训练集中的点转换为类似高斯分布的分布。同样，反向过程可以将从高斯分布中采样的点映射回类似原始数据的分布。
- en: '![](Images/gdl2_0612.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0612.png)'
- en: Figure 6-12\. The RealNVP model inputs (left) and outputs (right) after training,
    for the forward process (top) and the reverse process (bottom)
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-12。RealNVP模型在训练后的输入（左）和输出（右），用于正向过程（顶部）和反向过程（底部）
- en: The loss curve for the training process is shown in [Figure 6-13](#realnvp_loss_curve).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程的损失曲线显示在[图6-13](#realnvp_loss_curve)中。
- en: '![](Images/gdl2_0613.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0613.png)'
- en: Figure 6-13\. The loss curve for the RealNVP training process
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-13。RealNVP训练过程的损失曲线
- en: This completes our discussion of RealNVP, a specific case of a normalizing flow
    generative model. In the next section, we’ll cover some modern normalizing flow
    models that extend the ideas introduced in the RealNVP paper.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们对RealNVP的讨论，这是正则化流生成模型的一个特定案例。在下一节中，我们将介绍一些现代正则化流模型，这些模型扩展了RealNVP论文中介绍的思想。
- en: Other Normalizing Flow Models
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他正则化流模型
- en: Two other successful and important normalizing flow models are *GLOW* and *FFJORD*.
    The following sections describe the key advancements they made.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个成功且重要的正则化流模型是*GLOW*和*FFJORD*。以下部分描述了它们所取得的关键进展。
- en: GLOW
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GLOW
- en: Presented at NeurIPS 2018, GLOW was one of the first models to demonstrate the
    ability of normalizing flows to generate high-quality samples and produce a meaningful
    latent space that can be traversed to manipulate samples. The key step was to
    replace the reverse masking setup with invertible 1 × 1 convolutional layers.
    For example, with RealNVP applied to images, the ordering of the channels is flipped
    after each step, to ensure that the network gets the chance to transform all of
    the input. In GLOW a 1 × 1 convolution is applied instead, which effectively acts
    as a general method to produce any permutation of the channels that the model
    desires. The authors show that even with this addition, the distribution as a
    whole remains tractable, with determinants and inverses that are easy to compute
    at scale.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在NeurIPS 2018上展示的GLOW是第一个证明归一化流能够生成高质量样本并产生可遍历以操作样本的有意义潜在空间的模型之一。关键步骤是用可逆的1×1卷积层替换反向掩码设置。例如，在应用于图像的RealNVP中，通道的顺序在每一步之后都会翻转，以确保网络有机会转换所有的输入。而在GLOW中，应用了1×1卷积，这有效地作为一种通用方法来产生模型所需的任何通道排列。作者表明，即使加入了这一步骤，整体分布仍然是可处理的，具有易于大规模计算的行列式和逆。
- en: '![](Images/gdl2_0614.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0614.png)'
- en: 'Figure 6-14\. Random samples from the GLOW model (source: [Kingma and Dhariwal,
    2018](https://arxiv.org/abs/1807.03039))^([2](ch06.xhtml#idm45387012901552))'
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-14。GLOW模型的随机样本（来源：[Kingma和Dhariwal，2018](https://arxiv.org/abs/1807.03039)）^([2](ch06.xhtml#idm45387012901552))
- en: FFJORD
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FFJORD
- en: 'RealNVP and GLOW are discrete time normalizing flows—that is, they transform
    the input through a discrete set of coupling layers. FFJORD (Free-Form Continuous
    Dynamics for Scalable Reversible Generative Models), presented at ICLR 2019, shows
    how it is possible to model the transformation as a continuous time process (i.e.,
    by taking the limit as the number of steps in the flow tends to infinity and the
    step size tends to zero). In this case, the dynamics are modeled using an ordinary
    differential equation (ODE) whose parameters are produced by a neural network
    ( <math alttext="f Subscript theta"><msub><mi>f</mi> <mi>θ</mi></msub></math>
    ). A black-box solver is used to solve the ODE at time <math alttext="t 1"><msub><mi>t</mi>
    <mn>1</mn></msub></math> —i.e., to find <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math>
    given some initial point <math alttext="z 0"><msub><mi>z</mi> <mn>0</mn></msub></math>
    sampled from a Gaussian at <math alttext="t 0"><msub><mi>t</mi> <mn>0</mn></msub></math>
    , as described by the following equations:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVP和GLOW是离散时间归一化流模型，即它们通过一组离散的耦合层来转换输入。FFJORD（用于可扩展可逆生成模型的自由形式连续动力学），在ICLR
    2019上展示了如何将转换建模为连续时间过程（即，通过将流中步数趋近于无穷大且步长趋近于零的极限来实现）。在这种情况下，动力学是使用由神经网络产生的普通微分方程（ODE）来建模的。使用黑盒求解器来解决在时间t1处的ODE，即找到在时间t0处从高斯分布中采样的一些初始点z0的z1，如下面的方程所描述的那样：
- en: <math alttext="StartLayout 1st Row 1st Column z 0 2nd Column tilde 3rd Column
    p left-parenthesis z 0 right-parenthesis 2nd Row 1st Column StartFraction normal
    partial-differential z left-parenthesis t right-parenthesis Over normal partial-differential
    t EndFraction 2nd Column equals 3rd Column f Subscript theta Baseline left-parenthesis
    x left-parenthesis t right-parenthesis comma t right-parenthesis 3rd Row 1st Column
    x 2nd Column equals 3rd Column z 1 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>z</mi> <mn>0</mn></msub></mtd> <mtd><mo>∼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>p</mi> <mo>(</mo> <msub><mi>z</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mfrac><mrow><mi>∂</mi><mi>z</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>t</mi></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>f</mi>
    <mi>θ</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>t</mi> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>x</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>z</mi> <mn>1</mn></msub></mtd></mtr></mtable></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z 0 2nd Column tilde 3rd Column
    p left-parenthesis z 0 right-parenthesis 2nd Row 1st Column StartFraction normal
    partial-differential z left-parenthesis t right-parenthesis Over normal partial-differential
    t EndFraction 2nd Column equals 3rd Column f Subscript theta Baseline left-parenthesis
    x left-parenthesis t right-parenthesis comma t right-parenthesis 3rd Row 1st Column
    x 2nd Column equals 3rd Column z 1 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>z</mi> <mn>0</mn></msub></mtd> <mtd><mo>∼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>p</mi> <mo>(</mo> <msub><mi>z</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mfrac><mrow><mi>∂</mi><mi>z</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><mi>t</mi></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>f</mi>
    <mi>θ</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>t</mi> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>x</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>z</mi> <mn>1</mn></msub></mtd></mtr></mtable></math>
- en: A diagram of the transformation process is shown in [Figure 6-15](#ffjord_model).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 转换过程的图示在[图6-15](#ffjord_model)中展示。
- en: '![](Images/gdl2_0615.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0615.png)'
- en: 'Figure 6-15\. FFJORD models the transformation between the data distribution
    and a standard Gaussian via an ordinary differential equation, parameterized by
    a neural network (source: [Will Grathwohl et al., 2018](https://arxiv.org/abs/1810.01367))^([3](ch06.xhtml#idm45387012548496))'
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-15。FFJORD通过由神经网络参数化的普通微分方程模拟数据分布与标准高斯之间的转换（来源：[Will Grathwohl等人，2018](https://arxiv.org/abs/1810.01367)）^([3](ch06.xhtml#idm45387012548496))
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter we explored normalizing flow models such as RealNVP, GLOW, and
    FFJORD.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了诸如RealNVP、GLOW和FFJORD等归一化流模型。
- en: A normalizing flow model is an invertible function defined by a neural network
    that allows us to directly model the data density via a change of variables. In
    the general case, the change of variables equation requires us to calculate a
    highly complex Jacobian determinant, which is impractical for all but the simplest
    of examples.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化流模型是由神经网络定义的可逆函数，允许我们通过变量的改变直接建模数据密度。在一般情况下，变量改变方程要求我们计算一个高度复杂的雅可比行列式，这对于除了最简单的例子之外都是不切实际的。
- en: 'To sidestep this issue, the RealNVP model restricts the form of the neural
    network, such that it adheres to the two essential criteria: it is invertible
    and has a Jacobian determinant that is easy to compute.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规避这个问题，RealNVP模型限制了神经网络的形式，使其符合两个基本标准：可逆且雅可比行列式易于计算。
- en: It does this through stacking coupling layers, which produce scale and translation
    factors at each step. Importantly, the coupling layer masks the data as it flows
    through the network, in a way that ensures that the Jacobian is lower triangular
    and therefore has a simple-to-compute determinant. Full visibility of the input
    data is achieved through flipping the masks at each layer.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过堆叠耦合层来实现，这些层在每一步产生尺度和平移因子。重要的是，耦合层在数据流经网络时会掩盖数据，以确保雅可比是下三角形的，因此具有易于计算的行列式。通过在每一层翻转掩码，实现了对输入数据的完全可见性。
- en: By design, the scale and translation operations can be easily inverted, so that
    once the model is trained it is possible to run data through the network in reverse.
    This means that we can target the forward transformation process toward a standard
    Gaussian, which we can easily sample from. We can then run the sampled points
    backward through the network to generate new observations.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 按设计，尺度和平移操作可以轻松地被反转，因此一旦模型训练完成，就可以通过网络反向运行数据。这意味着我们可以将正向转换过程定向到标准高斯分布，从中轻松采样。然后，我们可以通过网络反向运行采样点以生成新的观测数据。
- en: The RealNVP paper also shows how it is possible to apply this technique to images,
    by using convolutions inside the coupling layers, rather than densely connected
    layers. The GLOW paper extended this idea to remove the necessity for any hardcoded
    permutation of the masks. The FFJORD model introduced the concept of continuous
    time normalizing flows, by modeling the transformation process as an ODE defined
    by a neural network.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVP论文还展示了如何将这种技术应用于图像，通过在耦合层内部使用卷积，而不是密集连接层。GLOW论文将这一思想扩展到消除任何硬编码排列掩模的必要性。FFJORD模型引入了连续时间归一化流的概念，通过将转换过程建模为由神经网络定义的ODE。
- en: Overall, we have seen how normalizing flows are a powerful generative modeling
    family that can produce high-quality samples, while maintaining the ability to
    tractably describe the data density function.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们已经看到了归一化流是一个强大的生成建模家族，可以生成高质量的样本，同时保持能够可靠地描述数据密度函数的能力。
- en: ^([1](ch06.xhtml#idm45387014186656-marker)) Laurent Dinh et al., “Density Estimation
    Using Real NVP,” May 27, 2016, [*https://arxiv.org/abs/1605.08803v3*](https://arxiv.org/abs/1605.08803v3).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.xhtml#idm45387014186656-marker)) Laurent Dinh等人，“使用Real NVP进行密度估计”，2016年5月27日，[*https://arxiv.org/abs/1605.08803v3*](https://arxiv.org/abs/1605.08803v3)。
- en: '^([2](ch06.xhtml#idm45387012901552-marker)) Diedrick P. Kingma and Prafulla
    Dhariwal, “Glow: Generative Flow with Invertible 1x1 Convolutions,” July 10, 2018,
    *[*https://arxiv.org/abs/1807.03039*](https://arxiv.org/abs/1807.03039)*.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '^([2](ch06.xhtml#idm45387012901552-marker)) Diedrick P. Kingma和Prafulla Dhariwal，“Glow:
    具有可逆1x1卷积的生成流”，2018年7月10日，[*https://arxiv.org/abs/1807.03039*](https://arxiv.org/abs/1807.03039)。'
- en: '^([3](ch06.xhtml#idm45387012548496-marker)) Will Grathwohl et al., “FFJORD:
    Free-Form Continuous Dynamics for Scalable Reversible Generative Models,” October
    22, 2018, *[*https://arxiv.org/abs/1810.01367*](https://arxiv.org/abs/1810.01367)*.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '^([3](ch06.xhtml#idm45387012548496-marker)) Will Grathwohl等人，“FFJORD: 用于可扩展可逆生成模型的自由形式连续动力学”，2018年10月22日，[*https://arxiv.org/abs/1810.01367*](https://arxiv.org/abs/1810.01367)。'
