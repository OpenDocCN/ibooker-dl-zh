- en: 5 Improving weak understanding for traditional AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 提升对传统人工智能的薄弱理解
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Identifying the types of errors a classifier can make
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别分类器可能犯的错误类型
- en: Establishing a baseline of current classifier performance
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立当前分类器性能的基线
- en: Using data science methodologies to identify and prioritize improvements
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据科学方法来识别和优先处理改进
- en: Infusing your traditional AI with generated content to enhance understanding
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将生成内容融入你的传统人工智能以增强理解
- en: In this chapter, we will demonstrate a methodical, iterative approach to improving
    the understanding of a classification-based conversational solution. This chapter
    builds on the concepts introduced in the previous chapter and uses the output
    produced by the final exercise in section 4.4 (where you created a test set with
    the golden intent assigned to each utterance in a format that can be used by your
    testing tool). Later in this chapter, we’ll explore how large language models
    can supplement intent-driven output responses to deliver a more robust experience.
    (If you’re looking for generative AI improvement techniques, feel free to skip
    ahead to the next chapter.)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展示一种系统性的、迭代的方法来提高基于分类的对话解决方案的理解。本章建立在上一章中介绍的概念之上，并使用第4.4节中产生的最终输出（你在其中创建了一个测试集，每个话语都分配了黄金意图，并且格式可以用于你的测试工具）。在本章的后面部分，我们将探讨大型语言模型如何补充意图驱动的输出响应，以提供更稳健的体验。（如果你在寻找生成式人工智能改进技术，可以自由地跳到下一章。）
- en: We will start by building an improvement plan and identifying the types of errors
    your classifier may be committing. Next, we’ll iterate through seven improvement
    cycles to solve the various problems you might see in your own text classifier.
    Although data science techniques are used, you do not need to be a data scientist
    to extract meaningful insights about your data using the methodologies presented
    in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先制定一个改进计划，并确定你的分类器可能犯的错误类型。接下来，我们将通过七个改进周期来解决你可能在自己的文本分类器中看到的各种问题。尽管使用了数据科学技术，但你不需要是数据科学家，就可以使用本章中介绍的方法从你的数据中提取有意义的见解。
- en: 5.1 Building your improvement plan
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 制定你的改进计划
- en: If you built a blind test set using a sample from your production logs, you
    should have a reliable “representative distribution” test set. This means that
    the topics that are most frequently asked by your users are represented with corresponding
    volume in your testing data. This will be a key factor in prioritizing any problems
    that are surfaced by your test results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用生产日志中的样本构建了一个盲测试集，你应该有一个可靠的“代表性分布”测试集。这意味着用户最常询问的主题在你的测试数据中都有相应的数量表示。这将是在优先处理测试结果中暴露出来的任何问题的一个关键因素。
- en: If you are working with the results of a *k*-fold test (discussed in chapter
    4), you won’t know for certain which topics are the most important, so the most
    egregious accuracy scores are a logical starting point.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理第4章中讨论的*k*-折测试的结果，你将无法确定哪些主题是最重要的，因此最严重的准确度得分是一个合理的起点。
- en: In either case, it’s now time to dig into those test results. An improvement
    plan starts with identifying the biggest problem spots in the bot’s training.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，现在是时候深入挖掘那些测试结果了。改进计划从识别机器人训练中的最大问题区域开始。
- en: 5.1.1 Identify problematic patterns in misunderstood utterances
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 识别误解话语中的问题模式
- en: The first score that will grab your attention is the overall accuracy of your
    test results. This is a lot like getting back a spelling or math test and looking
    at the red ink at the top of the page. If your test had 100 questions and you
    got 79 of them correct, your accuracy score would be 79%. For classifiers, this
    number is good for an “at a glance” view of the model, but it doesn’t give a complete
    picture of what is going on or where to start making improvements. For that, we
    need to understand the possible outcomes and types of errors our classifier may
    be committing. This is revealed in the measurements of recall, precision, and
    F1 score.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个会吸引你注意的分数是测试结果的整体准确率。这就像拿到一份拼写或数学测试，看到页面顶部的红墨水。如果你的测试有100个问题，你答对了79个，你的准确率就是79%。对于分类器来说，这个数字可以提供一个“一目了然”的模型视图，但它并不提供关于正在发生的事情或从哪里开始改进的完整画面。为了做到这一点，我们需要了解我们分类器可能犯的错误和可能的结果类型。这体现在回收率、精确率和F1分数的测量中。
- en: A brief explanation of recall, precision, and F1 scores
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回收率、精确率和F1分数的简要说明
- en: 'In chapter 4, we described *recall* as the classifier’s ability to predict
    a correct intent and *precision* as the ability to refrain from predicting a wrong
    intent. You can think of this in terms of positive and negative predictions. For
    every utterance that we test against the model, there are four possible outcomes,
    and they are not mutually exclusive, meaning that every prediction is going to
    have two or three of these outcomes happening simultaneously. Figure 5.1 shows
    a confusion matrix that visualizes these possible outcomes:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4章中，我们将*召回率*描述为分类器预测正确意图的能力，将*精确率*描述为避免预测错误意图的能力。你可以从正面和负面预测的角度来考虑这一点。对于我们要测试的每个话语，都有四种可能的结果，它们不是互斥的，这意味着每个预测都会同时发生两个或三个这些结果。图5.1显示了可视化这些可能结果的混淆矩阵：
- en: '![figure](../Images/CH05_F01_Freed2.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F01_Freed2.png)'
- en: Figure 5.1 In a 2 × 2 confusion matrix, the possible outcomes are derived by
    comparing the predicted intent to the actual intent.
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 在一个2×2的混淆矩阵中，可能的结果是通过比较预测意图和实际意图得出的。
- en: '*True positive*—A prediction that matches the correct intent'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*真阳性*—与正确意图匹配的预测'
- en: '*True negative*—A prediction that does not match an incorrect intent'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*真阴性*—不匹配错误意图的预测'
- en: '*False positive*—A prediction that matches an incorrect intent'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*假阳性*—匹配错误意图的预测'
- en: '*False negative*—A prediction that does not match the correct intent'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*假阴性*—不匹配正确意图的预测'
- en: 'The first metric that might interest us is the recall of our intents. For this,
    we need to know the true positives and the false negatives. An intent that is
    returning false negatives is committing an error of under-selection. When measured
    per intent, this looks like an accuracy score. If our test had five questions
    for the `#Request_Agent` intent, and the classifier got those questions correct
    four times, the intent’s recall would be 80%:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能感兴趣的第一个指标是意图的召回率。为此，我们需要知道真阳性和假阴性。返回假阴性的意图正在犯选择不足的错误。按意图衡量，这看起来像是一个准确率分数。如果我们的测试有五个关于`#Request_Agent`意图的问题，分类器正确回答了四个，那么该意图的召回率将是80%：
- en: '*Recall = True positives / (True positives + False negatives)*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率 = 真阳性 / (真阳性 + 假阴性)*'
- en: 'The next metric that helps us understand our classifier is precision. This
    measures how good our classifier is at refraining from giving a false positive.
    An intent that is returning false positives is committing an error of over-selection.
    An example of over-selection can be seen in the last two rows of table 5.1:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助我们理解分类器的下一个指标是精确率。这衡量我们的分类器在避免给出假阳性方面的好坏。返回假阳性的意图正在犯选择过多的错误。表5.1的最后两行提供了一个选择过多的例子：
- en: '*Precision = True positives / (True positives + False positives)*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确率 = 真阳性 / (真阳性 + 假阳性)*'
- en: 'Table 5.1 Test results show seven utterances, five of which are labeled with
    the correct `#Request_Agent` intent. The first four predictions were true positives.
    The last two rows show where `#Request_Agent` was predicted twice for utterances
    where it shouldn’t have been (“What can I ask you” and “Somebody hit my car”).
    These false positives contribute to our precision calculation: 4 / (4 + 2) = 0.66.'
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.1 测试结果显示有七个话语，其中五个被标记为正确的`#Request_Agent`意图。前四个预测是真阳性。最后两行显示了在不应预测`#Request_Agent`意图的话语中预测了两次（“我可以问您什么？”和“有人撞了我的车”）。这些假阳性贡献于我们的精确率计算：4
    / (4 + 2) = 0.66。
- en: '| Utterance | Correct intent | Predicted intent | Correct |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 正确意图 | 预测意图 | 正确 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Customer service  | `Request_Agent`  | `Request_Agent`  | 1  |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 客户服务 | `Request_Agent` | `Request_Agent` | 1 |'
- en: '| Speak with an agent  | `Request_Agent`  | `Request_Agent`  | 1  |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 与代理交谈 | `Request_Agent` | `Request_Agent` | 1 |'
- en: '| Can I please speak with somebody?  | `Request_Agent`  | `Request_Agent`  |
    1  |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 我可以和某人说话吗？ | `Request_Agent` | `Request_Agent` | 1 |'
- en: '| Talk with a human  | `Request_Agent`  | `Request_Agent`  | 1  |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 与真人交谈 | `Request_Agent` | `Request_Agent` | 1 |'
- en: '| When will I get a live person?  | `Request_Agent`  | `Office_Hours`  | 0  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 我什么时候能接到真人？ | `Request_Agent` | `Office_Hours` | 0 |'
- en: '| What can I ask you?  | `VA_Capabilities`  | `Request_Agent`  | 0  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 我可以问您什么？ | `VA_Capabilities` | `Request_Agent` | 0 |'
- en: '| Somebody hit my car  | `Report_Accident`  | `Request_Agent`  | 0  |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 有人撞了我的车 | `Report_Accident` | `Request_Agent` | 0 |'
- en: A full analysis of all possible outcomes for `#Request_Agent` is shown in figure
    5.2\. It also shows the true negatives (which are not used in our calculations
    but have been included to demonstrate the range of other outcomes).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`#Request_Agent` 的所有可能结果的全面分析显示在图 5.2 中。它还显示了真阴性值（这些值在我们的计算中未使用，但已包括以展示其他结果的范围）。'
- en: '![figure](../Images/CH05_F02_Freed2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图表](../Images/CH05_F02_Freed2.png)'
- en: Figure 5.2 The highlighted columns are used for calculating precision and recall
    for `#Request_Agent`.
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.2 用于计算 `#Request_Agent` 的精确度和召回率的突出列。
- en: 'Now that we know the recall and precision, we can also calculate the F1 score,
    which is the harmonic mean of recall and precision. This calculation is made as
    follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了召回率和精确度，我们还可以计算 F1 分数，它是召回率和精确率的调和平均值。这个计算如下：
- en: '*F1 score = (2 *×* Precision *×* Recall) / (Precision + Recall)*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*F1 分数 = (2 × 精确度 × 回忆) / (精确度 + 回忆)*'
- en: For our `#Request_Agent` intent, this would be calculated as (2 × 0.66 × 0.8)
    / (0.66 + 0.8) = 0.72\. Table 5.2 shows all three scores.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 `#Request_Agent` 目标，这将计算为 (2 × 0.66 × 0.8) / (0.66 + 0.8) = 0.72。表 5.2
    显示了所有三个分数。
- en: Table 5.2 Recall, precision, and F1 score for `#Request_Agent`
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.2 `#Request_Agent` 的召回率、精确度和 F1 分数
- en: '| Intent | Recall | Precision | F1 score |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 目标 | 回忆 | 精确度 | F1 分数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `Request_Agent`  | 0.80  | 0.66  | 0.72  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Agent` | 0.80 | 0.66 | 0.72 |'
- en: What about the true negatives?
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真阴性值如何？
- en: Earlier in this section, we mentioned true negatives—a prediction that does
    not match an incorrect intent. True negatives occur whenever we have more than
    one trained intent. However, they are not a useful measurement in our methods.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节前面，我们提到了真阴性值——一个不匹配错误意图的预测。只要我们有一个以上的训练目标，就会发生真阴性值。然而，它们并不是我们方法中的有用度量。
- en: Why not? Well, for every prediction the model makes, there is only one way for
    it to be right, but there are two ways for it to be wrong. This seems a little
    unfair, and it’s hard to see why if you’re just looking at two intents. But imagine
    we have a model that was trained with 20 intents. Whenever we make a single prediction
    that returns a true positive, we will also get 19 true negatives. And for every
    false positive prediction,
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不呢？好吧，对于模型做出的每一个预测，它只有一种正确的方式，但有两种错误的方式。这似乎有点不公平，如果你只是看两个目标，就很难理解这一点。但想象一下，我们有一个用20个目标训练的模型。每次我们做出一个返回真阳性的单个预测时，我们也会得到19个真阴性值。而对于每一个假阳性预测，
- en: we have 1 false negative and 18 true negatives. So all those true negatives
    add up to a very large number that, for our purposes, doesn’t give us much insight.
    Therefore, we don’t factor true negatives into our calculations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有1个假阴性值和18个真阴性值。所以所有这些真阴性值加起来是一个非常大的数字，对于我们来说，这并不提供太多洞察。因此，我们不将真阴性值纳入我们的计算中。
- en: Deciding which metric is important
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 决定哪个指标很重要
- en: 'Recall, precision, F1 score: Which number should we care about? That’s a great
    question! The answer is that it depends on what your organization values most
    in terms of what the solution needs to deliver. Here are some considerations to
    guide you to an answer:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率、精确度、F1 分数：我们应该关注哪个数字？这是一个很好的问题！答案是，这取决于你的组织在解决方案需要交付的内容中最重视什么。以下是一些指导你找到答案的考虑因素：
- en: Recall is useful when there is a high cost associated with false negatives.
    Imagine the effect if a fraud detection tool missed 25% of the fraudulent transactions
    it evaluated. (For a chatbot, this would look like a correct intent that is not
    predicted 25% of the time.)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当与假阴性相关的高成本时，召回率是有用的。想象一下，如果欺诈检测工具错过了它评估的25%的欺诈交易，会有什么影响。（对于聊天机器人来说，这看起来像是一个正确的意图，但25%的时间没有被预测到。）
- en: Precision is useful when there is a high cost associated with false positives.
    Think of the gameshow Jeopardy!, which penalizes a contestant for attempting to
    answer and getting it wrong (or a chatbot that over-selects the `#Request_ Agent`
    intent, resulting in unnecessary escalations).
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当与假阳性相关的高成本时，精确度是有用的。想想《危险边缘》这个游戏节目，它会惩罚试图回答并答错题目的参赛者（或者一个过度选择 `#Request_Agent`
    目标的聊天机器人，导致不必要的升级）。
- en: The F1 score is useful when there is a high cost associated with both false
    positives and false negatives. We like to use this for most implementations because
    it reflects a good balance of the recall and precision scores.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当与假阳性和假阴性都相关的高成本时，F1 分数是有用的。我们喜欢使用这个指标，因为它反映了召回率和精确率分数的良好平衡。
- en: Visualizing your data with a confusion matrix
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用混淆矩阵可视化你的数据
- en: Earlier in this section, we showed a 2 × 2 confusion matrix to demonstrate the
    potential outcomes. A confusion matrix can help you assess the performance of
    a classification model by visualizing a summary of the predictions made by your
    model. Some testing tools produce this with their results output.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节前面，我们展示了2×2混淆矩阵以展示潜在的结果。混淆矩阵可以帮助你通过可视化模型做出的预测摘要来评估分类模型的性能。一些测试工具会在其结果输出中生成此信息。
- en: Figure 5.3 shows a fictional scenario where a classifier model made ten perfect
    predictions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3显示了一个虚构场景，其中分类器模型做出了十个完美的预测。
- en: '![figure](../Images/CH05_F03_Freed2.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F03_Freed2.png)'
- en: Figure 5.3 A solid diagonal line shows that each predicted intent (represented
    by a single letter) matched to the actual intent.
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 一条实线对角线表明每个预测意图（用一个字母表示）都与实际意图相匹配。
- en: Shaded boxes that stray from the diagonal provide useful insights about where
    your model is confused, as shown in figure 5.4.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从对角线偏离的阴影框提供了关于模型在哪里混淆的有用见解，如图5.4所示。
- en: '![figure](../Images/CH05_F04_Freed2.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F04_Freed2.png)'
- en: Figure 5.4 This model had nine correct predictions, but wrongly predicted intent
    G when the actual intent was E.
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.4显示，该模型有九个正确的预测，但在实际意图是E时错误地预测了意图G。
- en: 5.1.2 Incremental improvements
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 逐步改进
- en: An incremental improvement approach will affect measurable change in a manageable
    way. Every change you make to a classifier has the potential to affect multiple
    intents. Sometimes this effect is positive, but sometimes it’s not. You might
    get away with updating several intents all at once, but if the testing shows a
    performance decline, it can be difficult to track down the culprit. You will have
    to balance the need for efficiency with your tolerance for rework.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步改进的方法将以可管理的方式影响可衡量的变化。你对分类器所做的每一次更改都可能影响多个意图。有时这种影响是积极的，但有时则不然。你可能会同时更新多个意图而不会出现问题，但如果测试显示性能下降，追踪问题根源可能会很困难。你将不得不在效率需求与对返工的容忍度之间取得平衡。
- en: '5.1.3 Where to start: Identifying the biggest problems'
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 从哪里开始：识别最大的问题
- en: Generally, the best place to start is with the highest volume intents that have
    the lowest F1 scores. The business may also weigh in on priorities. If a lower
    volume intent fails to recognize the type of request it was designed to handle,
    but this failure incurs costly human intervention, it might take priority.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，最好的起点是具有最低F1分数的最高量意图。企业也可能对优先级提出意见。如果一个低量意图未能识别其设计用来处理的那种请求，但这种失败导致了昂贵的人工干预，它可能会被优先考虑。
- en: 'For the rest of this chapter, we will explore a fictional use case: a chatbot
    that serves a population that interacts with a state’s Bureau of Motor Vehicles
    (a type of US government agency that regulates and manages the issuance of state
    identification cards, driver’s licenses, certain permits, and vehicle registrations).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将探讨一个虚构的用例：一个服务于与州机动车管理局（一种美国政府机构，负责监管和管理州身份证、驾驶执照、某些许可证和车辆注册的发放）互动的人群的聊天机器人。
- en: To begin, let’s follow the advice given in chapter 4 and take a quick, high-level
    look at our current training data, as laid out in table 5.3.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们遵循第4章中给出的建议，快速、高层次地查看我们的当前训练数据，如表5.3所示。
- en: Table 5.3 Intents with example counts in a baseline training set
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.3 基线训练集中具有示例计数的意图
- en: '| Intent name | Number of examples |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 意图名称 | 示例数量 |'
- en: '| --- | --- |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Accident_Report`  | 2  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| `Accident_Report`  | 2  |'
- en: '| `Appointment`  | 6  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `Appointment`  | 6  |'
- en: '| `Change_Contact_Records`  | 3  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `Change_Contact_Records`  | 3  |'
- en: '| `Chitchat_Goodbye`  | 3  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Goodbye`  | 3  |'
- en: '| `Chitchat_Hello`  | 4  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Hello`  | 4  |'
- en: '| `Chitchat_Thanks`  | 2  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Thanks`  | 2  |'
- en: '| `Chitchat_VA_About`  | 8  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`  | 8  |'
- en: '| `Fee_Info`  | 5  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `Fee_Info`  | 5  |'
- en: '| `General_Negative_Feedback`  | 6  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `General_Negative_Feedback`  | 6  |'
- en: '| `General_Request_Agent`  | 5  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `General_Request_Agent`  | 5  |'
- en: '| `Get_ID_Number`  | 4  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `Get_ID_Number`  | 4  |'
- en: '| `Item_Not_Received`  | 8  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`  | 8  |'
- en: '| `License_or_ID`  | 5  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID`  | 5  |'
- en: '| `License_Reinstatement`  | 4  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement`  | 4  |'
- en: '| `Login_Issue`  | 4  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`  | 4  |'
- en: '| `Name_Change`  | 6  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `Name_Change`  | 6  |'
- en: '| `Office_Information`  | 6  |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `Office_Information`  | 6  |'
- en: '| `Payment_Methods`  | 3  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `Payment_Methods`  | 3  |'
- en: '| `Refund_Overcharge`  | 4  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `Refund_Overcharge`  | 4  |'
- en: '| `Report_Sold_Vehicle`  | 6  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Sold_Vehicle`  | 6  |'
- en: '| `Report_Stolen_License_Permit_ID`  | 5  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 5  |'
- en: '| `Report_Stolen_Plates_Registration`  | 3  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration`  | 3  |'
- en: '| `Report_Stolen_Vehicle`  | 2  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 2  |'
- en: '| `Request_Receipt`  | 4  |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Receipt` | 4 |'
- en: '| `Vehicle_Permit`  | 5  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Permit` | 5 |'
- en: '| `Vehicle_Title`  | 6  |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Title` | 6 |'
- en: '| `Walk_In`  | 6  |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In` | 6 |'
- en: '| **Grand Total**  | **125**  |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| **总计** | **125** |'
- en: We can make some quantitative statements about this training set. It has 27
    intents with a grand total of 125 training examples. The examples are distributed
    fairly evenly. As a qualitative assessment, we might say that many of the intents
    appear to be unique, but a few of them might have some overlap. Some terms definitely
    overlap across intent names. A peek at the full set of training utterances (not
    shown) revealed that many terms appear in multiple intents, such as “ID,” “title,”
    “permit,” “vehicle,” “stolen.” However, as shown in table 5.4, the contexts in
    which these words appeared were judged to be appropriately labeled.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这个训练集做出一些定量陈述。它有27个意图，总共有125个训练示例。示例分布相对均匀。作为定性评估，我们可能会说许多意图看起来是独特的，但其中一些可能存在一些重叠。一些术语肯定在意图名称中重叠。查看完整的训练语句集（未显示）揭示了许多术语出现在多个意图中，例如“ID”、“title”、“permit”、“vehicle”、“stolen”。然而，如表5.4所示，这些词出现的上下文被认为是适当标注的。
- en: Table 5.4 Utterances extracted from the baseline training set show a variety
    of terms overlapping across multiple intents.
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.4 基线训练集中提取的语句显示了多个意图之间重叠的各种术语。
- en: '| Utterance | Labeled intent |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 语句 | 标注意图 |'
- en: '| --- | --- |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| How much is an ID?  | `Fee_Info`  |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 身份证多少钱？ | `Fee_Info` |'
- en: '| I need to find out my ID number  | `Get_ID_Number`  |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 我需要找出我的身份证号码 | `Get_ID_Number` |'
- en: '| I didn’t receive my ID  | `Item_Not_Received`  |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 我没有收到我的身份证 | `Item_Not_Received` |'
- en: '| Title never came  | `Item_Not_Received`  |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 标题从未到来 | `Item_Not_Received` |'
- en: '| Add a person to the title  | `Vehicle_Title`  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 将人添加到标题中 | `Vehicle_Title` |'
- en: '| How do I get a driving permit?  | `License_or_ID`  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 我如何获得驾驶执照？ | `License_or_ID` |'
- en: '| Replace my program parking permit  | `Vehicle_Permit`  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 替换我的程序停车许可证 | `Vehicle_Permit` |'
- en: '| I sold a vehicle  | `Report_Sold_Vehicle`  |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 我卖掉了一辆车 | `Report_Sold_Vehicle` |'
- en: '| I need to report a stolen car  | `Report_Stolen_Vehicle`  |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 我需要报告一辆被盗的汽车 | `Report_Stolen_Vehicle` |'
- en: '| My ID was stolen  | `Report_Stolen_License_Permit_ID`  |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 我的身份证被盗了 | `Report_Stolen_License_Permit_ID` |'
- en: Overall, it seems that the range of topics is reasonable for the chatbot’s purpose,
    which in this case is to answer questions a user might have when dealing with
    a state’s Bureau of Motor Vehicles.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，对于聊天机器人的目的而言，主题范围似乎是合理的，在这种情况下，其目的是回答用户在处理州机动车辆局时可能遇到的问题。
- en: Establishing a baseline
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 建立基线
- en: Now that we have made an initial assessment of our training data, we need to
    understand how it is currently performing. We’ll start by running a *k*-fold cross
    validation test to establish a baseline. The results, our first version (V1) shown
    in table 5.5, are not that bad, considering the low volume of data present in
    the training set.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对训练数据进行了初步评估，我们需要了解它当前的性能。我们将从运行一个 *k*-折交叉验证测试来建立基线开始。考虑到训练集中数据量较低，表5.5中显示的初步版本（V1）的结果并不算太差。
- en: Table 5.5 Baseline (V1) *k*-fold results
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.5 基线（V1）*k*-折结果
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确率 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Accident_Report`  | 2  | 2  | 1  | 1  | 1  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `Accident_Report` | 2 | 2 | 1 | 1 | 1 |'
- en: '| `Appointment`  | 6  | 8  | 1  | 0.75  | 0.8571  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `Appointment` | 6 | 8 | 1 | 0.75 | 0.8571 |'
- en: '| `Change_Contact_Records`  | 3  | 0  | 0  | 0  | 0  |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `Change_Contact_Records` | 3 | 0 | 0 | 0 | 0 |'
- en: '| `Chitchat_Goodbye`  | 3  | 0  | 0  | 0  | 0  |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Goodbye` | 3 | 0 | 0 | 0 | 0 |'
- en: '| `Chitchat_Hello`  | 4  | 6  | 1  | 0.6667  | 0.80  |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Hello` | 4 | 6 | 1 | 0.6667 | 0.80 |'
- en: '| `Chitchat_Thanks`  | 2  | 2  | 1  | 1  | 1  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Thanks` | 2 | 2 | 1 | 1 | 1 |'
- en: '| `Chitchat_VA_About`  | 8  | 8  | 1  | 1  | 1  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About` | 8 | 8 | 1 | 1 | 1 |'
- en: '| `Fee_Info`  | 5  | 2  | 0.40  | 1  | 0.5714  |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `Fee_Info` | 5 | 2 | 0.40 | 1 | 0.5714 |'
- en: '| `General_Negative_Feedback`  | 6  | 7  | 1  | 0.8571  | 0.9231  |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `General_Negative_Feedback` | 6 | 7 | 1 | 0.8571 | 0.9231 |'
- en: '| `General_Request_Agent`  | 5  | 4  | 0.80  | 1  | 0.8889  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `General_Request_Agent` | 5 | 4 | 0.80 | 1 | 0.8889 |'
- en: '| `Get_ID_Number`  | 4  | 6  | 1  | 0.6667  | 0.80  |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `Get_ID_Number` | 4 | 6 | 1 | 0.6667 | 0.80 |'
- en: '| `Item_Not_Received`  | 8  | 6  | 0.6250  | 0.8333  | 0.7143  |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received` | 8 | 6 | 0.6250 | 0.8333 | 0.7143 |'
- en: '| `License_Reinstatement`  | 4  | 4  | 1  | 1  | 1  |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement` | 4 | 4 | 1 | 1 | 1 |'
- en: '| `License_or_ID`  | 5  | 5  | 0.60  | 0.60  | 0.60  |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID` | 5 | 5 | 0.60 | 0.60 | 0.60 |'
- en: '| `Login_Issue`  | 4  | 4  | 1  | 1  | 1  |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue` | 4 | 4 | 1 | 1 | 1 |'
- en: '| `Name_Change`  | 6  | 8  | 1  | 0.75  | 0.8571  |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `Name_Change`  | 6  | 8  | 1  | 0.75  | 0.8571  |'
- en: '| `Office_Information`  | 6  | 6  | 1  | 1  | 1  |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `Office_Information`  | 6  | 6  | 1  | 1  | 1  |'
- en: '| `Payment_Methods`  | 3  | 3  | 1  | 1  | 1  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `Payment_Methods`  | 3  | 3  | 1  | 1  | 1  |'
- en: '| `Refund_Overcharge`  | 4  | 4  | 1  | 1  | 1  |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `Refund_Overcharge`  | 4  | 4  | 1  | 1  | 1  |'
- en: '| `Report_Sold_Vehicle`  | 6  | 5  | 0.8333  | 1  | 0.9091  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Sold_Vehicle`  | 6  | 5  | 0.8333  | 1  | 0.9091  |'
- en: '|'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE0]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '| 5  | 6  | 1  | 0.8333  | 0.9091  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 5  | 6  | 1  | 0.8333  | 0.9091  |'
- en: '|'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE1]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '| 3  | 3  | 0.3333  | 0.3333  | 0.3333  |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 3  | 3  | 0.3333  | 0.3333  | 0.3333  |'
- en: '| `Report_Stolen_Vehicle`  | 2  | 3  | 1  | 0.6667  | 0.80  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 2  | 3  | 1  | 0.6667  | 0.80  |'
- en: '| `Request_Receipt`  | 4  | 4  | 1  | 1  | 1.0000  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Receipt`  | 4  | 4  | 1  | 1  | 1.0000  |'
- en: '| `Vehicle_Permit`  | 5  | 6  | 1  | 0.8333  | 0.9091  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Permit`  | 5  | 6  | 1  | 0.8333  | 0.9091  |'
- en: '| `Vehicle_Title`  | 6  | 9  | 1  | 0.6667  | 0.80  |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Title`  | 6  | 9  | 1  | 0.6667  | 0.80  |'
- en: '| `Walk_In`  | 6  | 4  | 0.6667  | 1  | 0.80  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In`  | 6  | 4  | 0.6667  | 1  | 0.80  |'
- en: Our *k*-fold test had a total of 125 questions (the grand total of our training
    set), and it got 105 of them correct, for an overall accuracy of 84%. Several
    intents had perfect recall and perfect precision (which is often a hallmark of
    a manufactured data set). There were two intents that had a recall of 0; they
    each had only three training examples. This reveals one of the flaws of *k*-fold
    testing—there simply weren’t enough examples to distribute across the auto-generated
    train and test sets. More than likely, those intents will perform better than
    0 in production. However, the intents with perfect recall will probably not perform
    quite as well. If you are launching a pilot and have no other training data available,
    these results are generally good enough to go live, with a strong caution to the
    stakeholders that they should expect lower actual performance until representative
    data is available for use in training updates.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*k*-fold测试共有125个问题（我们训练集的总数），其中正确回答了105个，总体准确率为84%。有几个意图具有完美的召回率和精确度（这通常是人工数据集的一个标志）。有两个意图的召回率为0；它们各自只有三个训练示例。这揭示了*k*-fold测试的一个缺陷——简单地没有足够的示例可以分配到自动生成的训练和测试集中。很可能，这些意图在生产中的表现将优于0。然而，具有完美召回率的意图可能不会表现得那么好。如果您正在推出试点项目并且没有其他训练数据可用，这些结果通常足够上线，但应向利益相关者发出强烈警告，他们应预期实际性能在可用代表数据用于训练更新之前会较低。
- en: Once the solution is live, a new baseline should be taken using the blind test
    set you created from the logs. We have an example of this in table 5.6, and it
    really emphasizes the gap in performance predicted by our *k*-fold test compared
    to real user inputs.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦解决方案上线，应使用从日志中创建的盲测试集来获取一个新的基线。表5.6中有一个这样的例子，它确实强调了我们的*k*-fold测试与实际用户输入相比预测的性能差距。
- en: Table 5.6 Baseline (V1) blind results
  id: totrans-153
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.6基线（V1）盲测试结果
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确度 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Accident_Report`  | 2  | 2  | 1  | 1  | 1  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `Accident_Report`  | 2  | 2  | 1  | 1  | 1  |'
- en: '| `Appointment`  | 7  | 5  | 0.7143  | 1  | 0.8333  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| `Appointment`  | 7  | 5  | 0.7143  | 1  | 0.8333  |'
- en: '| `Change_Contact_Records`  | 4  | 4  | 1  | 1  | 1  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| `Change_Contact_Records`  | 4  | 4  | 1  | 1  | 1  |'
- en: '| `Chitchat_Goodbye`  | 1  | 1  | 1  | 1  | 1  |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Goodbye`  | 1  | 1  | 1  | 1  | 1  |'
- en: '| `Chitchat_Hello`  | 1  | 1  | 1  | 1  | 1  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Hello`  | 1  | 1  | 1  | 1  | 1  |'
- en: '| `Chitchat_Thanks`  | 1  | 1  | 1  | 1  | 1  |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Thanks`  | 1  | 1  | 1  | 1  | 1  |'
- en: '| `Chitchat_VA_About`  | 1  | 2  | 1  | 0.50  | 0.6667  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`  | 1  | 2  | 1  | 0.50  | 0.6667  |'
- en: '| `Fee_Info`  | 11  | 9  | 0.8182  | 1  | 0.90  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| `Fee_Info`  | 11  | 9  | 0.8182  | 1  | 0.90  |'
- en: '| `General_Negative_Feedback`  | 2  | 3  | 1  | 0.6667  | 0.80  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `General_Negative_Feedback`  | 2  | 3  | 1  | 0.6667  | 0.80  |'
- en: '| `General_Request_Agent`  | 3  | 2  | 0.6667  | 1  | 0.80  |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| `General_Request_Agent`  | 3  | 2  | 0.6667  | 1  | 0.80  |'
- en: '| `Get_ID_Number`  | 3  | 5  | 1  | 0.60  | 0.75  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `Get_ID_Number`  | 3  | 5  | 1  | 0.60  | 0.75  |'
- en: '| `Item_Not_Received`  | 16  | 9  | 0.4375  | 0.7778  | 0.56  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`  | 16  | 9  | 0.4375  | 0.7778  | 0.56  |'
- en: '| `License_Reinstatement`  | 5  | 5  | 0.60  | 0.60  | 0.60  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement`  | 5  | 5  | 0.60  | 0.60  | 0.60  |'
- en: '| `License_or_ID`  | 7  | 5  | 0.5714  | 0.80  | 0.6667  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID`  | 7  | 5  | 0.5714  | 0.80  | 0.6667  |'
- en: '| `Login_Issue`  | 9  | 5  | 0.4444  | 1  | 0.6153  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`  | 9  | 5  | 0.4444  | 1  | 0.6153  |'
- en: '| `Name_Change`  | 9  | 9  | 1  | 1  | 1  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| `Name_Change`  | 9  | 9  | 1  | 1  | 1  |'
- en: '| `Office_Information`  | 9  | 11  | 1  | 0.8182  | 0.90  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| `Office_Information`  | 9  | 11  | 1  | 0.8182  | 0.90  |'
- en: '| `Payment_Methods`  | 2  | 2  | 1  | 1  | 1  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| `Payment_Methods`  | 2  | 2  | 1  | 1  | 1  |'
- en: '| `Refund_Overcharge`  | 3  | 4  | 1  | 0.7500  | 0.8571  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| `Refund_Overcharge`  | 3  | 4  | 1  | 0.7500  | 0.8571  |'
- en: '| `Report_Sold_Vehicle`  | 6  | 7  | 1  | 0.8571  | 0.9231  |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Sold_Vehicle`  | 6  | 7  | 1  | 0.8571  | 0.9231  |'
- en: '|'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE2]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '| 7  | 8  | 0.8571  | 0.75  | 0.80  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 7  | 8  | 0.8571  | 0.75  | 0.80  |'
- en: '|'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE3]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '| 5  | 4  | 0.80  | 1  | 0.8889  |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 5  | 4  | 0.80  | 1  | 0.8889  |'
- en: '| `Report_Stolen_Vehicle`  | 2  | 2  | 0.50  | 0.50  | 0.50  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 2  | 2  | 0.50  | 0.50  | 0.50  |'
- en: '| `Request_Receipt`  | 4  | 4  | 1  | 1  | 1  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Receipt`  | 4  | 4  | 1  | 1  | 1  |'
- en: '| `Vehicle_Permit`  | 4  | 5  | 1  | 0.80  | 0.8889  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Permit`  | 4  | 5  | 1  | 0.80  | 0.8889  |'
- en: '| `Vehicle_Title`  | 2  | 8  | 1  | 0.25  | 0.40  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Title`  | 2  | 8  | 1  | 0.25  | 0.40  |'
- en: '| `Walk_In`  | 8  | 5  | 0.3750  | 0.60  | 0.4615  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In`  | 8  | 5  | 0.3750  | 0.60  | 0.4615  |'
- en: On the first run of our blind test, 102 questions were correct out of 134, for
    an overall accuracy of 76%—8 points lower than the 84% predicted by our *k*-fold
    test.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们盲测试的第一轮中，134个问题中有102个是正确的，总体准确率为76%——比我们预测的84%低8个百分点。
- en: Validating your initial training strategy
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 验证您的初始训练策略
- en: Once you have obtained annotated logs and taken some baseline performance measurements,
    you can validate the decisions that informed your initial training strategy.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您获得了标注日志并进行了某些基线性能测量，您就可以验证那些指导您初始训练策略的决定。
- en: Scarcity of representative training data is a very common problem for conversational
    AI projects. Just like many other newly launched chatbots, our initial training
    set was developed by subject matter experts (SMEs) who manufactured training examples
    for the topics they believed would occur most frequently. In figure 5.5, we can
    compare the number of examples trained for each intent to the number of examples
    that were present in the randomly selected logs used for testing.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 代表性训练数据的稀缺是对话式人工智能项目非常常见的问题。就像许多其他新推出的聊天机器人一样，我们的初始训练集是由主题专家（SMEs）开发的，他们为他们认为最可能发生的话题制造了训练示例。在图5.5中，我们可以比较为每个意图训练的示例数量与用于测试的随机选择的日志中存在的示例数量。
- en: '![figure](../Images/CH05_F05_Freed2.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F05_Freed2.png)'
- en: Figure 5.5 A comparison of training examples to the utterances in our representative
    blind test set shows that there is some disparity in volume for many of the most
    popular intents (the representative blind utterances) on the left side of the
    graph. We also see disparity across several of the least popular intents (those
    on the right).
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 将训练示例与我们的代表性盲测试集中的话语进行比较，显示在图表左侧的许多最流行意图（代表性的盲话语）在音量上存在一些差异。我们还在几个不太受欢迎的意图（右侧的意图）中看到了差异。
- en: A side-by-side volume comparison of training data to representative blind utterances
    per intent can help us understand if our solution’s topic coverage is in alignment
    with the real-world interactions. One of the first observations we noted was that
    `#Item_Not_Received` was the most popular real-world intent. This validated the
    initial build strategy of supplying that intent with a higher number of training
    examples (relative to most other intents). We also noted that `#Chitchat_VA_About`
    had a high number of training examples compared to how infrequently this topic
    came up in the logs. This intent may be over-trained. It certainly doesn’t seem
    to be as popular as we thought it might be. Yet, until we look at the performance
    metrics for these intents, we cannot draw any solid conclusions. Rather, these
    observations might inform our improvement recommendations.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 每个意图的训练数据与代表性盲话语的并排音量比较可以帮助我们了解我们的解决方案的主题覆盖范围是否与实际世界的交互一致。我们首先注意到的是`#Item_Not_Received`是最受欢迎的实际意图。这验证了为该意图提供更多训练示例（相对于大多数其他意图）的初始构建策略。我们还注意到，与日志中该主题出现的频率相比，`#Chitchat_VA_About`有大量的训练示例。这个意图可能过度训练了。它显然不像我们想象的那么受欢迎。然而，在我们查看这些意图的性能指标之前，我们无法得出任何明确的结论。相反，这些观察结果可能会为我们的改进建议提供信息。
- en: Exercises
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Run a representative blind test using your own data, and identify which intents,
    if any, exhibit poor performance.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您自己的数据运行代表性盲测试，并确定哪些意图（如果有的话）表现出较差的性能。
- en: Does your training volume align with the intent volume seen in your logs?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的训练音量与日志中看到的意图音量一致吗？
- en: How would you prioritize improvements for the poorest-performing intents?
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您会如何优先考虑对表现最差的意图进行改进？
- en: 5.2 Solving “wrong intent matched”
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 解决“意图匹配错误”
- en: 'When your chatbot returns the wrong intent, it has committed two categories
    of errors: false positives (predicting the wrong intent), and false negatives
    (failing to predict the right intent). Let’s walk through an improvement cycle
    to demonstrate how we would approach this problem.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的聊天机器人返回错误的意图时，它犯了两种类型的错误：假阳性（预测错误的意图）和假阴性（未能预测正确的意图）。让我们通过一个改进周期来演示我们将如何处理这个问题。
- en: 5.2.1 Improve recall for one intent
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1提高一个意图的召回率
- en: We will start with `#Login_Issue`, which was the fifth most popular topic but
    had a considerably low recall of 0.44\. There were nine test utterances in our
    blind set; it got four questions correct (true positives) and five incorrect (false
    negatives). This intent had a perfect precision score, which means it never showed
    up as a wrong prediction for other intents. Table 5.7 shows the summary metrics.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从`#Login_Issue`开始，这是第五个最受欢迎的主题，但召回率相当低，为0.44。在我们的盲测集中有九个测试话语；它正确回答了四个问题（真阳性）和五个错误（假阴性）。这个意图有一个完美的精确度分数，这意味着它从未作为其他意图的错误预测出现。表5.7显示了总结指标。
- en: Table 5.7 Summary metrics for `#Login_Issue`; a blind test set run against our
    baseline classifier shows low recall but perfect precision.
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.7 `#Login_Issue`的总结指标；对基线分类器进行的盲测集运行显示召回率低但精确度完美。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确度 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Login_Issue`  | 9  | 5  | 0.4444  | 1  | 0.6153  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue` | 9 | 5 | 0.4444 | 1 | 0.6153 |'
- en: In table 5.8, we can drill down to the result details of the blind test. Our
    classifier failed to predict a correct intent five times. Three of those were
    predictions of a wrong intent. Two were instances where confidence was so low
    that the classifier did not return a prediction.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在表5.8中，我们可以深入到盲测的结果细节。我们的分类器五次未能预测正确的意图。其中三次是错误意图的预测。两次是置信度如此之低，以至于分类器没有返回预测。
- en: Table 5.8 Baseline blind result details for `#Login_Issue` show that we had
    a recall score of 44%. Out of nine utterances, the correct (aka *golden*) intent
    was predicted five times.
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.8基线盲测结果细节显示，我们有一个召回率为44%的分数。在九个话语中，正确的（即*金色*）意图被预测了五次。
- en: '| Utterance | Golden intent | Predicted intent | Confidence |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 金色意图 | 预测意图 | 置信度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| BMV portal password reset  | `Login_Issue`  | <none>  | n/a  |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| BMV门户密码重置 | `Login_Issue` | <none> | n/a |'
- en: '| I can’t get on my profile  | `Login_Issue`  | `Item_Not_Received`  | 0.8131  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 我无法进入我的个人资料 | `Login_Issue` | `Item_Not_Received` | 0.8131 |'
- en: '| I need help logging into my BMV profile  | `Login_Issue`  | <none>  | n/a  |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 我需要帮助登录我的BMV个人资料 | `Login_Issue` | <none> | n/a |'
- en: '| I never got my security verification code  | `Login_Issue`  | `Item_Not_Received`  |
    0.2358  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 我从未收到我的安全验证码 | `Login_Issue` | `Item_Not_Received` | 0.2358 |'
- en: '| I tried logging in and it didn’t work  | `Login_Issue`  | `Login_Issue`  |
    0.8033  |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 我尝试登录但失败了 | `Login_Issue` | `Login_Issue` | 0.8033 |'
- en: '| I’m not able to get into the portal  | `Login_Issue`  | `Login_Issue`  |
    0.6680  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 我无法进入门户 | `Login_Issue` | `Login_Issue` | 0.6680 |'
- en: '| Password locked out  | `Login_Issue`  | `Login_Issue`  | 0.5520  |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 密码被锁定 | `Login_Issue` | `Login_Issue` | 0.5520 |'
- en: '| Password reset  | `Login_Issue`  | `Login_Issue`  | 0.4875  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 密码重置 | `Login_Issue` | `Login_Issue` | 0.4875 |'
- en: '| You never sent a security code  | `Login_Issue`  | `Item_Not_Received`  |
    0.2091  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 你从未发送安全码 | `Login_Issue` | `Item_Not_Received` | 0.2091 |'
- en: 'If we look at our current trained examples, it’s easy to see why so many questions
    were missed. There were only four examples:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看看我们当前的训练示例，很容易看出为什么错过了这么多问题。只有四个示例：
- en: I’m unable to log in on the website
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我无法在网站上登录
- en: Online account problem
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线账户问题
- en: Online problems
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线问题
- en: Problem signing onto my account
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 登录我的账户有问题
- en: 'Our training examples lack the variety of meaningful words and phrases seen
    in interactions with real users. Users might refer to their account as their “profile.”
    They list explicit problems such as being “locked out,” needing a “password reset,”
    and failing to receive a “security code.” We should expect to see an improvement
    if we add a few representative examples (obtained from our logs):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练示例缺乏在与真实用户互动中看到的丰富词汇和短语。用户可能会将他们的账户称为他们的“个人资料”。他们列出明确的问题，例如“被锁定”、“需要密码重置”和“未能收到安全码”。如果我们添加一些代表性的示例（从我们的日志中获取），我们应该会看到改进：
- en: Help signing in to online portal
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助登录在线门户
- en: I need to reset my password
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我需要重置我的密码
- en: I need a security code to log on
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我需要安全码来登录
- en: With these additions, we updated our classifier to V2 and reran the blind test
    set. Let’s look at how this affected the recall for `#Login_Issue` in table 5.9.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些新增功能，我们将我们的分类器更新到V2版本，并重新运行了盲测试集。让我们看看这对表5.9中`#Login_Issue`的召回率有何影响。
- en: Table 5.9 Blind test result details show improved recall for our newest classifier
    version (V2). Out of nine utterances, the correct (aka *golden*) intent was predicted
    eight times.
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.9盲测试结果细节显示，我们最新分类器版本（V2）的召回率有所提高。在九个表述中，正确的（即*金色*）意图被预测了八次。
- en: '| Utterance | Golden intent | Predicted intent | Confidence |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 表述 | 金色意图 | 预测意图 | 置信度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| BMV portal password reset  | `Login_Issue`  | `Login_Issue`  | 0.8253  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| BMV门户密码重置  | `Login_Issue`  | `Login_Issue`  | 0.8253  |'
- en: '| I can’t get on my profile  | `Login_Issue`  | `Item_Not_Received`  | 0.8131  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 我无法登录我的资料库  | `Login_Issue`  | `Item_Not_Received`  | 0.8131  |'
- en: '| I need help logging into my BMV profile  | `Login_Issue`  | `Login_Issue`  |
    0.6846  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 我需要帮助登录我的BMV资料库  | `Login_Issue`  | `Login_Issue`  | 0.6846  |'
- en: '| I never got my security verification code  | `Login_Issue`  | `Login_Issue`  |
    0.7179  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 我从未收到我的安全验证码  | `Login_Issue`  | `Login_Issue`  | 0.7179  |'
- en: '| I tried logging in and it didn’t work  | `Login_Issue`  | `Login_Issue`  |
    0.8899  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 我尝试登录但没成功  | `Login_Issue`  | `Login_Issue`  | 0.8899  |'
- en: '| I’m not able to get into the portal  | `Login_Issue`  | `Login_Issue`  |
    0.7840  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 我无法进入门户  | `Login_Issue`  | `Login_Issue`  | 0.7840  |'
- en: '| Password locked out  | `Login_Issue`  | `Login_Issue`  | 0.9083  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 密码锁定  | `Login_Issue`  | `Login_Issue`  | 0.9083  |'
- en: '| Password reset  | `Login_Issue`  | `Login_Issue`  | 0.9204  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 密码重置  | `Login_Issue`  | `Login_Issue`  | 0.9204  |'
- en: '| You never sent a security code  | `Login_Issue`  | `Login_Issue`  | 0.2551  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 你从未发送过安全码  | `Login_Issue`  | `Login_Issue`  | 0.2551  |'
- en: Our overall accuracy improved from 76% to 79% (106 out of 134 correct), and
    table 5.10 shows a dramatic improvement in the recall and F1 score. The precision
    score also remained steady.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的整体准确率从76%提高到79%（106个正确中的134个），表5.10显示了召回率和F1分数的显著提高。精确度分数也保持稳定。
- en: Table 5.10 A comparison of summary metrics; our V2 classifier shows an overall
    improvement compared to the baseline (V1) for `#Login_Issue`.
  id: totrans-242
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '| 表5.10 比较总结指标；我们的V2分类器与基线（V1）相比，在`#Login_Issue`上显示出整体改进。'
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确度 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Login_Issue`—Baseline (V1)  | 9  | 5  | 0.4444  | 1  | 0.6153  |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`—基线（V1）  | 9  | 5  | 0.4444  | 1  | 0.6153  |'
- en: '| `Login_Issue`—V2  | 9  | 8  | 0.8889  | 1  | 0.9412  |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`—V2  | 9  | 8  | 0.8889  | 1  | 0.9412  |'
- en: 5.2.2 Improve precision for one intent
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 提高一个意图的精确度
- en: Next, let’s experiment with improving the precision for an intent. The `#Chitchat_VA_About`
    intent remained unchanged between the baseline test results and the V2 test results.
    (It is important to look at the newest results after each change.) Table 5.11
    shows that the recall was perfect, but the precision was only 50%. This means
    our classifier is placing a bit more importance on this topic, and it is showing
    up as a false positive (over-selecting) in another intent.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们尝试提高一个意图的精确度。`#Chitchat_VA_About`意图在基线测试结果和V2测试结果之间保持不变。（在每次更改后查看最新结果是很重要的。）表5.11显示，召回率完美，但精确度仅为50%。这意味着我们的分类器对这个主题的重要性略有增加，并在另一个意图中显示为假阳性（过度选择）。
- en: Table 5.11 Metrics after the V2 update show that `#Chitchat_VA_About` has perfect
    recall but poor precision.
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.11 V2更新后的指标显示，`#Chitchat_VA_About`的召回率完美，但精确度较差。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确度 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Chitchat_VA_About`  | 1  | 2  | 1  | 0.50  | 0.6667  |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`  | 1  | 2  | 1  | 0.50  | 0.6667  |'
- en: In table 5.12, we see that there was only one test question in our blind set
    for this intent, but our classifier predicted the intent twice.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在表5.12中，我们看到我们盲测试集中这个意图只有一个测试问题，但我们的分类器预测了这个意图两次。
- en: Table 5.12 V2 blind result details show an over-selection for `#Chitchat_VA_About`.
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.12 V2盲测试结果细节显示对`#Chitchat_VA_About`的过度选择。
- en: '| Utterance | Golden intent | Predicted intent | Confidence |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 表述 | 金色意图 | 预测意图 | 置信度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Do you have a name?  | `Chitchat_VA_About`  | `Chitchat_VA_About`  | 0.8042  |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 你叫什么名字？  | `Chitchat_VA_About`  | `Chitchat_VA_About`  | 0.8042  |'
- en: '| Where are my tags?  | `Item_Not_Received`  | `Chitchat_VA_About`  | 0.3015  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 我的标签在哪里？  | `Item_Not_Received`  | `Chitchat_VA_About`  | 0.3015  |'
- en: Our training has eight examples. We knew that these examples were manufactured
    (in fact, they were provided by a template), but our logs show that this is not
    a very common topic. Our blind test set only contained one utterance for this
    intent.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练有八个示例。我们知道这些示例是人为制造的（实际上，它们是由模板提供的），但我们的日志显示这并不是一个非常常见的话题。我们的盲测集只包含一个关于这个意图的表述。
- en: 'One strategy for improving precision is to prune the training examples. This
    tells our classifier that the intent isn’t quite as dominant as the other intents
    within our solution. We’ll discard three examples because they are either overly
    redundant or, in the case of “Where are you from,” there was no evidence in the
    logs that this was a relevant question:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 提高精度的策略之一是修剪训练示例。这告诉我们的分类器，意图并不像我们解决方案中的其他意图那样占主导地位。我们将丢弃三个示例，因为它们要么过于冗余，或者在“你来自哪里”的情况下，日志中没有证据表明这是一个相关的问题：
- en: Are you a robot?
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是机器人吗？
- en: What can I ask you?
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以问你什么？
- en: What can you do?
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能做什么？
- en: What can you help me with? (REMOVE FROM TRAINING)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以帮你做什么？（从训练中移除）
- en: What’s your name?
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你叫什么名字？
- en: Where are you from? (REMOVE FROM TRAINING)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你来自哪里？（从训练中移除）
- en: Who am I talking to? (REMOVE FROM TRAINING)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我在跟谁说话？（从训练中移除）
- en: Who are you?
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是谁？
- en: Once the training was updated (now V3), we ran the blind test again and reviewed
    the results. We saw an improvement to the precision for the `#Chitchat_VA_About`
    intent from V2 to V3—it was a perfect score across all metrics. Oddly enough,
    our overall accuracy dropped to 78% (from 79%), and one of the questions we lost
    was from our `#Login_Issue` intent. Table 5.13 shows the changes in metrics from
    V2 to V3 for both intents.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练更新（现在是V3），我们再次进行了盲测并审查了结果。我们发现`#Chitchat_VA_About`意图从V2到V3的精度有所提高——所有指标都是满分。奇怪的是，我们的整体准确率下降到78%（从79%），我们失去的一个问题是来自我们的`#Login_Issue`意图。表5.13显示了两个意图从V2到V3的指标变化。
- en: Table 5.13 Metrics before and after V3 update for `#Chitchat_VA_About` and `#Login_Issue`
    show that changing one intent can have an effect on another intent.
  id: totrans-270
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.13 V3更新前后`#Chitchat_VA_About`和`#Login_Issue`的指标显示，改变一个意图可能会影响另一个意图。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确率 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Chitchat_VA_About`—V2  | 1  | 2  | 1  | 0.50  | 0.6667  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`—V2  | 1  | 2  | 1  | 0.50  | 0.6667  |'
- en: '| `Chitchat_VA_About`—V3  | 1  | 1  | 1  | 1  | 1  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`—V3  | 1  | 1  | 1  | 1  | 1  |'
- en: '| `Login_Issue`—V2  | 9  | 8  | 0.8889  | 1  | 0.9412  |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`—V2  | 9  | 8  | 0.8889  | 1  | 0.9412  |'
- en: '| `Login_Issue`—V3  | 9  | 7  | 0.7777  | 1  | 0.875  |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`—V3  | 9  | 7  | 0.7777  | 1  | 0.875  |'
- en: Although `#Login_Issue` had a slight decline, the current F1 score of 0.875
    is still far better than the baseline F1 score of 0.6153\. Keep in mind that smaller
    datasets are more sensitive to small changes, and a change to any intent can potentially
    affect every intent. Those changes may have negative or positive results. Instead
    of focusing on this, however, we will make a few more changes elsewhere and check
    back to see if the intent improves.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`#Login_Issue`略有下降，但当前的F1分数为0.875，仍然远优于基线F1分数0.6153。记住，较小的数据集对微小变化更敏感，任何意图的变化都可能影响每个意图。这些变化可能会有负面影响或正面结果。然而，我们不会专注于这一点，而是在其他地方进行一些更改，并检查意图是否有所改善。
- en: 5.2.3 Improve the F1 score for one intent
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 提高一个意图的F1分数
- en: Let’s move forward with improving the F1 score for `#Item_Not_Received`. Table
    5.14 shows that it had an F1 score of 56% after our V3 update.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续提高`#Item_Not_Received`的F1分数。表5.14显示，在我们的V3更新后，它的F1分数为56%。
- en: Table 5.14 After V3 update, the F1 score remained unchanged at 0.56 for `#Item_Not_Received`.
  id: totrans-280
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.14 在V3更新后，`#Item_Not_Received`的F1分数保持不变，为0.56。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确率 | F1分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Item_Not_Received`—V2  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`—V2  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
- en: '| `Item_Not_Received`—V3  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`—V3  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
- en: The intent had eight training examples, but our logs showed that this is a very
    popular topic, so we need it to perform much better. We’ll add 10 more examples
    from our logs to that intent (now V4) and run another experiment.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 该意图有八个训练示例，但我们的日志显示这是一个非常热门的话题，因此我们需要它表现得更好。我们将从我们的日志中添加 10 个更多示例到该意图（现在是 V4）并运行另一个实验。
- en: Table 5.15 shows that our recall for this intent has now more than doubled,
    and though the precision fell slightly, the F1 score is greatly improved. The
    classifier’s overall accuracy also increased from 78% to 81%.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.15 显示，我们对于这个意图的召回率现在已经超过了两倍，尽管精确度略有下降，但 F1 分数得到了显著提高。分类器的整体准确率也从 78% 提高到了
    81%。
- en: Table 5.15 Before and after metrics for `#Item_Not_Received` show an improved
    F1 score.
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.15 `#Item_Not_Received` 在更新前后的指标显示 F1 分数有所提高。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确度 | F1 分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `Item_Not_Received`—V3  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`—V3  | 16  | 9  | 0.4375  | 0.7777  | 0.56  |'
- en: '| `Item_Not_Received`—V4  | 16  | 19  | 0.875  | 0.7368  | 0.8  |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`—V4  | 16  | 19  | 0.875  | 0.7368  | 0.8  |'
- en: 5.2.4 Improve precision and recall for multiple intents
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 提高多个意图的精确度和召回率
- en: Sometimes there is confusion due to a heavy overlap of terms across intents
    that have similar goals. Figure 5.6 shows the confusion matrix that our testing
    tool provided.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于具有相似目标的意图之间术语的重叠度很高，会导致混淆。图 5.6 显示了我们的测试工具提供的混淆矩阵。
- en: In our model, we see a fair amount of confusion across the intents that relate
    to stolen items. One solution to this problem is to merge intents. This must be
    considered carefully. The intents were probably created separately by design,
    as they all have different answers. However, entity detection can be used to route
    the flow to the appropriate answer.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模型中，我们观察到与被盗物品相关的意图之间存在相当多的混淆。解决这个问题的方法之一是合并意图。这必须仔细考虑。意图可能是由设计分别创建的，因为它们都有不同的答案。然而，可以使用实体检测来将流量路由到适当的答案。
- en: '![figure](../Images/CH05_F06_Freed2.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F06_Freed2.png)'
- en: Figure 5.6 Confusion matrix after the V4 update. The density in shading represents
    the volume of questions predicted for a given intent. If a classifier test had
    a perfect accuracy score, you would see a solid black diagonal line running from
    the upper left corner to the lower right corner. The shaded squares that stray
    away from this diagonal line mark the areas of confusion within your model.
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.6 V4 更新后的混淆矩阵。阴影密度表示针对特定意图预测的问题量。如果一个分类器测试具有完美的准确度分数，你将看到一个从左上角到右下角的实心黑色对角线。偏离这条对角线的阴影方块表示模型中的混淆区域。
- en: We’ll merge all of these into a single intent called `#Report_Stolen`. These
    examples are listed in table 5.16\. Don’t forget that the blind test set will
    need to reflect this change, as well as the related dialogue flows.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有这些合并成一个名为 `#Report_Stolen` 的单一意图。这些示例列在表 5.16 中。别忘了盲测试集也需要反映这一变化，以及相关的对话流程。
- en: Table 5.16 Examples from three intents to be merged into a new `#Report_Stolen`
    intent
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.16 将合并到新的 `#Report_Stolen` 意图中的三个意图的示例
- en: '| Intent name | Training example |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 意图名称 | 训练示例 |'
- en: '| --- | --- |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Report_Stolen_Vehicle`  | Report a stolen car  |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 报告一辆被盗的汽车 |'
- en: '| `Report_Stolen_Vehicle`  | I need to report a stolen car  |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 我需要报告一辆被盗的汽车 |'
- en: '| `Report_Stolen_Plates_Registration`  | My plates were stolen  |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration`  | 我的车牌被盗 |'
- en: '| `Report_Stolen_Plates_Registration`  | My registration was stolen  |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration`  | 我的注册证被盗 |'
- en: '| `Report_Stolen_Plates_Registration`  | License plate stolen off vehicle  |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration`  | 车辆上的车牌被盗 |'
- en: '| `Report_Stolen_License_Permit_ID`  | Stolen real ID  |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 被盗的真实身份证 |'
- en: '| `Report_Stolen_License_Permit_ID`  | Wallet was stolen  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 钱包被盗 |'
- en: '| `Report_Stolen_License_Permit_ID`  | My drivers license was stolen  |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 我的驾照被盗 |'
- en: '| `Report_Stolen_License_Permit_ID`  | My ID was stolen  |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 我的身份证被盗 |'
- en: '| `Report_Stolen_License_Permit_ID`  | My permit was stolen  |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 我的许可证被盗 |'
- en: The conversational flow will be updated so that when a defined entity value
    or synonym is detected in an utterance, the corresponding original answer is provided.
    You may also need a default condition to disambiguate or provide a generic answer
    in case an utterance triggers the new intent but no entity is detected. Table
    5.17 is an example of what that might look like.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 对话流程将被更新，以便在话语中检测到定义的实体值或同义词时，提供相应的原始答案。你可能还需要一个默认条件来消除歧义或提供通用答案，以防话语触发了新意图但没有检测到实体。表
    5.17 是这种情况可能看起来像的例子。
- en: Table 5.17 Dialogue updates using entity detection for the new `#Report_Stolen`
    intent
  id: totrans-312
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.17 使用实体检测更新新 `#Report_Stolen` 意图的对话
- en: '| Entity/synonym detected | Treatment |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 实体/同义词检测 | 处理 |'
- en: '| --- | --- |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| vehicle, car, truck, motorcycle  | Routes to original answer for `#Report
    Stolen Vehicle`  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 车辆、汽车、卡车、摩托车  | 到 `#Report Stolen Vehicle` 的原始答案路由  |'
- en: '| plates, registration, tags  | Routes to original answer for `#Report_Stolen_Plates_Registration`  |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 车牌，注册，标签  | 到 `#Report_Stolen_Plates_Registration` 的原始答案路由  |'
- en: '| ID, license, permit  | Routes to original answer for `#Report_Stolen_License_Permit_ID`  |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| ID、执照、许可证  | 到 `#Report_Stolen_License_Permit_ID` 的原始答案路由  |'
- en: '| (none detected)  | Disambiguate (“It sounds like something was stolen; can
    you tell me what it was?”)  |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| (未检测到)  | 分歧消除（“听起来像有什么东西被盗了；你能告诉我是什么吗？”）  |'
- en: With these changes, our classifier is now on V5\. Table 5.18 shows the metrics
    for the three old intents under V4 and the metrics for our new intent in V5.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些更改，我们的分类器现在处于 V5 版本。表 5.18 显示了 V4 下三个旧意图的指标以及 V5 中我们新意图的指标。
- en: Table 5.18 Metrics before and after V5 update show that merging three intents
    into the single `#Report_Stolen` intent results in perfect scores across the board
    for this topic.
  id: totrans-320
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.18 V5 更新前后的指标显示，将三个意图合并为单个 `#Report_Stolen` 意图，在这个主题上实现了完美的分数。
- en: '| Intent | Number of samples | Number of predictions | Recall | Precision |
    F1 score |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 样本数量 | 预测数量 | 召回率 | 精确率 | F1 分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE4]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: —V4
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: —V4
- en: '| 7  | 5  | 0.5714  | 0.8  | 0.6666  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 7  | 5  | 0.5714  | 0.8  | 0.6666  |'
- en: '|'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE5]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: —V4
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: —V4
- en: '| 5  | 4  | 0.8  | 1  | 0.8888  |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 5  | 4  | 0.8  | 1  | 0.8888  |'
- en: '| `Report_Stolen_Vehicle`—V4  | 2  | 2  | 0.5  | 0.5  | 0.5  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`—V4  | 2  | 2  | 0.5  | 0.5  | 0.5  |'
- en: '| `Report_Stolen`—new intent in V5  | 14  | 14  | 1  | 1  | 1  |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen`—V5 中的新意图 | 14  | 14  | 1  | 1  | 1  |'
- en: Our latest change dramatically improved the performance of this topic, and it
    bumped the overall accuracy to 85%, which is now higher than our baseline *k*-fold
    (which was 84%).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最新的更改显著提高了这个主题的性能，并将整体准确率提升至 85%，这现在高于我们的基线 *k*-fold（为 84%）。
- en: With that update complete, we can move on to other intents that need improvement.
    Following the iterative processes, we updated the remaining intents that showed
    the poorest performance by adding a few more examples from the logs. This became
    V6 of our classifier. Table 5.19 is an overview of the intents that were updated.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 更新完成之后，我们可以继续处理其他需要改进的意图。按照迭代过程，我们通过添加日志中的更多示例来更新表现最差的剩余意图。这成为了我们分类器的 V6 版本。表
    5.19 是更新意图的概述。
- en: Table 5.19 Training example counts increase from V5 to V6 and more closely align
    with the volume present in the representative blind test set.
  id: totrans-335
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 5.19 从 V5 到 V6 训练示例数量的增加以及与代表性盲测试集中存在的体积更接近。
- en: '| Intent | V5 training example count | V6 training example count | Test utterances
    in representative blind |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | V5 训练示例数量 | V6 训练示例数量 | 代表性盲测试中的测试话语 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| `License_or_ID`  | 5  | 6  | 7  |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID`  | 5  | 6  | 7  |'
- en: '| `License_Reinstatement`  | 4  | 6  | 5  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement`  | 4  | 6  | 5  |'
- en: '| `Login_Issue`  | 7  | 8  | 9  |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`  | 7  | 8  | 9  |'
- en: '| `Walk_In`  | 6  | 8  | 8  |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In`  | 6  | 8  | 8  |'
- en: This update resulted in an overall accuracy of 92% for the latest classifier
    (now on V6). In the world of natural language classification, this is a very good
    score for a representative blind test set. You will never achieve 100%; even human-to-human
    communications don’t come close to that.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这次更新使得最新分类器的整体准确率达到 92%（现在处于 V6 版本）。在自然语言分类的世界里，这对于代表性盲测试集来说是一个非常不错的分数。你永远无法达到
    100%；即使是人与人之间的交流也无法接近那个水平。
- en: Every data set is different, and we could spend several more cycles tweaking
    our training if there is plenty of data available. However, there are diminishing
    returns associated with pursuing results that approach 100%. There is also a risk
    of over-fitting your model to the current blind test set. Once additional logs
    become available and a new test set is created, you may discover additional gaps
    (or your overfitting will be exposed).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据集都是不同的，如果数据量充足，我们可以花费更多几个周期微调我们的训练。然而，追求接近100%的结果会有递减的回报。还有可能过度拟合你的模型到当前的盲测集。一旦有额外的日志可用并创建了一个新的测试集，你可能会发现更多的差距（或者你的过度拟合将被暴露）。
- en: Table 5.20 shows a comparison of the blind test F1 scores of the baseline classifier
    against our latest updates. Twelve of the intents did not change (and they were
    already performing very well). One intent decreased from 90% to 80%, and the remaining
    14 intents showed improvement. We felt that this was a good and reasonable tradeoff,
    improving more than half of our intents at the cost of one intent showing a slight
    decline.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.20显示了基准分类器与最新更新之间的盲测F1分数的比较。十二个意图没有变化（并且它们已经表现得很出色）。一个意图从90%下降到80%，其余的14个意图有所改进。我们认为这是一个良好且合理的权衡，在牺牲一个意图略有下降的情况下，使超过一半的意图得到改进。
- en: Table 5.20 Comparison of baseline F1 scores and V6 F1 scores
  id: totrans-345
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.20基准F1分数与V6 F1分数比较
- en: '| Intent | Baseline (V1) F1 score | V6 F1 score | Change |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 基准（V1）F1分数 | V6 F1分数 | 变化 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `Accident_Report`  | 1  | 1  | (no change)  |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| `Accident_Report`  | 1  | 1  | (no change)  |'
- en: '| `Appointment`  | 0.8333  | 0.833  | (no change)  |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| `Appointment`  | 0.8333  | 0.833  | (no change)  |'
- en: '| `Change_Contact_Records`  | 1  | 1  | (no change)  |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| `Change_Contact_Records`  | 1  | 1  | (no change)  |'
- en: '| `Chitchat_Goodbye`  | 1  | 1  | (no change)  |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Goodbye`  | 1  | 1  | (no change)  |'
- en: '| `Chitchat_Hello`  | 1  | 1  | (no change)  |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Hello`  | 1  | 1  | (no change)  |'
- en: '| `Chitchat_Thanks`  | 1  | 1  | (no change)  |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Thanks`  | 1  | 1  | (no change)  |'
- en: '| `Chitchat_VA_About`  | 0.6667  | 0.9524  | + 0.2857  |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About`  | 0.6667  | 0.9524  | + 0.2857  |'
- en: '| `Fee_Info`  | 0.90  | 0.80  | - 0.1  |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| `Fee_Info`  | 0.90  | 0.80  | - 0.1  |'
- en: '| `General_Negative_Feedback`  | 0.80  | 0.80  | (no change)  |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| `General_Negative_Feedback`  | 0.80  | 0.80  | (no change)  |'
- en: '| `General_Request_Agent`  | 0.80  | 0.80  | (no change)  |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| `General_Request_Agent`  | 0.80  | 0.80  | (no change)  |'
- en: '| `Get_ID_Number`  | 0.75  | 0.8571  | + 0.1071  |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| `Get_ID_Number`  | 0.75  | 0.8571  | + 0.1071  |'
- en: '| `Item_Not_Received`  | 0.56  | 0.8750  | + 0.315  |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received`  | 0.56  | 0.8750  | + 0.315  |'
- en: '| `License_Reinstatement`  | 0.60  | 0.75  | + 0.15  |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement`  | 0.60  | 0.75  | + 0.15  |'
- en: '| `License_or_ID`  | 0.6667  | 1  | + 0.3333  |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID`  | 0.6667  | 1  | + 0.3333  |'
- en: '| `Login_Issue`  | 0.6153  | 0.9412  | + 0.3259  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue`  | 0.6153  | 0.9412  | + 0.3259  |'
- en: '| `Name_Change`  | 1  | 1  | (no change)  |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| `Name_Change`  | 1  | 1  | (no change)  |'
- en: '| `Office_Information`  | 0.90  | 1  | + 0.1  |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| `Office_Information`  | 0.90  | 1  | + 0.1  |'
- en: '| `Payment_Methods`  | 1  | 1  | (no change)  |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| `Payment_Methods`  | 1  | 1  | (no change)  |'
- en: '| `Refund_Overcharge`  | 0.8571  | 0.8571  | (no change)  |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| `Refund_Overcharge`  | 0.8571  | 0.8571  | (no change)  |'
- en: '| `Report_Sold_Vehicle`  | 0.9231  | 1  | + 0.0769  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Sold_Vehicle`  | 0.9231  | 1  | + 0.0769  |'
- en: '| `Report_Stolen_License_Permit_ID`  | 0.80  | (n/a - merged)  | + 0.2  |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID`  | 0.80  | (n/a - merged)  | + 0.2  |'
- en: '| `Report_Stolen_Plates_Registration`  | 0.8889  | (n/a - merged)  | + 0.1111  |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration`  | 0.8889  | (n/a - merged)  | + 0.1111  |'
- en: '| `Report_Stolen_Vehicle`  | 0.50  | (n/a - merged)  | + 0.5  |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle`  | 0.50  | (n/a - merged)  | + 0.5  |'
- en: '| `Report_Stolen`  | n/a  | 1  | (n/a – merged)  |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen`  | n/a  | 1  | (n/a – merged)  |'
- en: '| `Request_Receipt`  | 1  | 1  | (no change)  |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Receipt`  | 1  | 1  | (no change)  |'
- en: '| `Vehicle_Permit`  | 0.8889  | 1  | + 0.1111  |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Permit`  | 0.8889  | 1  | + 0.1111  |'
- en: '| `Vehicle_Title`  | 0.40  | 0.8  | + 0.4  |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Title`  | 0.40  | 0.8  | + 0.4  |'
- en: '| `Walk_In`  | 0.4615  | 0.75  | + 0.2885  |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In`  | 0.4615  | 0.75  | + 0.2885  |'
- en: Exercises
  id: totrans-376
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Using the output from the previous exercise (a prioritized list of your poorest-performing
    intents), identify the category of error each intent is committing: recall, precision,
    or both.'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前一个练习的输出（你最差表现意图的优先级列表），确定每个意图所犯错误的类别：召回、精确度或两者都有。
- en: Make iterative training adjustments to improve each intent.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过迭代训练调整来改进每个意图。
- en: Measure each change to verify that
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量每次变化以验证
- en: The intended effect is achieved
  id: totrans-380
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期的效果已经实现
- en: No other intents were negatively affected
  id: totrans-381
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有其他意图受到负面影响
- en: 5.3 Solving “no intent matched”
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 解决“没有匹配意图”问题
- en: Now that we have our classifier in good shape for the current scope, we can
    focus on expanding the domain, if needed. During an initial review of your production
    logs, you will almost surely encounter topics that were not included in the initial
    training set. Some of these topics will be obvious, but perhaps there wasn’t enough
    data to train an intent at the time of the initial launch. Maybe the business
    wasn’t ready to write answers for some topics. Sometimes a seasonal topic is not
    included because it was not in the forefront of anyone’s mind (e.g., tax season,
    hurricane season, fiscal year end, etc.). Other topics may be completely unexpected
    (e.g., a data breach).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将分类器调整得适合当前范围，如果需要的话，我们可以专注于扩展领域。在初步审查您的生产日志时，您几乎肯定会遇到一些未包含在初始训练集中的主题。其中一些主题可能是显而易见的，但也许在初始发布时没有足够的数据来训练意图。也许业务当时还没有准备好为某些主题编写答案。有时，由于这些主题没有成为任何人的首要任务（例如，税务季节、飓风季节、财政年度结束等），季节性主题可能没有被包括在内。其他主题可能是完全出乎意料的（例如，数据泄露）。
- en: Although you don’t have any intents defined to match these utterances, the classifier
    will always attempt to make a prediction; it doesn’t know what it doesn’t know,
    so it does its best to match an utterance to what it does know. In an ideal world,
    the classifier would return very low confidence, and this would trigger an “anything_else”
    or “no action matches” type of response. In reality, such user utterances often
    contain words that appear somewhere in your training, so it is possible that the
    classifier will predict an intent that has training examples with similar words.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您没有定义任何意图来匹配这些语句，但分类器总是会尝试做出预测；它不知道自己不知道什么，所以它会尽力将语句与已知的内容相匹配。在一个理想的世界里，分类器会返回非常低的置信度，这将触发“其他”或“没有匹配的动作”类型的响应。在现实中，这样的用户语句通常包含出现在您的训练中的某些单词，因此分类器可能会预测一个具有类似单词的训练示例的意图。
- en: 5.3.1 Clustering utterances for new intents
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 为新意图聚类语句
- en: In the guidelines described in chapter 4, we recommended setting aside utterances
    that were related to the domain but not included in the original scope. It’s time
    to address these.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4章中描述的指南中，我们建议将那些与领域相关但未包含在原始范围内的语句留出。现在是时候解决这些问题了。
- en: One of the topics our logs revealed was related to users wanting to cancel their
    license or registration. We know from our logs how the classifier predicted each
    utterance at the time the utterance was asked. Now we can test them against our
    latest classifier (V6) to get new model predictions.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我们日志中揭示的一个主题与用户想要取消他们的执照或注册有关。我们知道从我们的日志中，在语句被提出时，分类器是如何预测每个语句的。现在我们可以用我们最新的分类器（V6）来测试它们，以获得新的模型预测。
- en: In table 5.21, we see that our classifier exhibited low confidence and/or was
    incorrect whenever an utterance contained a form of the word “cancel.”
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在表5.21中，我们看到我们的分类器在语句包含“取消”这个词的任何形式时，表现出了低置信度或错误。
- en: Table 5.21 Unmatched utterances from logs with predictions from the V6 classifier
  id: totrans-389
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.21：来自日志的未匹配语句与V6分类器的预测
- en: '| Utterance | Predicted intent | Confidence |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 语句 | 预测意图 | 置信度 |'
- en: '| --- | --- | --- |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Cancel a registration  | `Appointment`  | 0.2681  |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 取消注册 | `Appointment` | 0.2681 |'
- en: '| Cancel my car registration  | `License_or_ID`  | 0.3651  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 取消我的汽车注册 | `License_or_ID` | 0.3651 |'
- en: '| Cancel a drivers license  | `License_Reinstatement`  | 0.3042  |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 取消驾驶执照 | `License_Reinstatement` | 0.3042 |'
- en: '| Canceling a registration  | `Appointment`  | 0.2417  |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 取消注册 | `Appointment` | 0.2417 |'
- en: '| Cancellation of registration  | `Fee_Info`  | 0.2786  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 注册取消 | `Fee_Info` | 0.2786 |'
- en: '| Cancelling my registration  | `Item_Not_Received`  | 0.3004  |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 取消我的注册 | `Item_Not_Received` | 0.3004 |'
- en: '| Cancel a replacement license  | `Vehicle_Permit`  | 0.3264  |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 取消更换执照 | `Vehicle_Permit` | 0.3264 |'
- en: '| Cancel the license  | `License_Reinstatement`  | 0.3237  |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 取消执照 | `License_Reinstatement` | 0.3237 |'
- en: '| Cancel a title or registration  | `Vehicle_Title`  | 0.5913  |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 取消车牌或注册 | `Vehicle_Title` | 0.5913 |'
- en: '| Cancel vehicle registrations  | `Item_Not_Received`  | 0.2914  |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 取消车辆注册 | `Item_Not_Received` | 0.2914 |'
- en: '| Commercial drivers license cancel  | `License_Reinstatement`  | 0.2995  |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 商业驾驶员执照取消 | `License_Reinstatement` | 0.2995 |'
- en: '| Driver’s license cancellation  | `Get_ID_Number`  | 0.3387  |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 驾驶执照取消 | `Get_ID_Number` | 0.3387 |'
- en: '| How do I cancel my vehicle registration?  | `License_or_ID`  | 0.4324  |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 我如何取消我的车辆注册？ | `License_or_ID` | 0.4324 |'
- en: '| I need to cancel a vehicle registration  | `License_or_ID`  | 0.3481  |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 我需要取消车辆注册 | `License_or_ID` | 0.3481 |'
- en: '| I need to cancel my ID  | `Get_ID_Number`  | 0.3205  |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 我需要取消我的身份证 | `Get_ID_Number` | 0.3205 |'
- en: '| I would like to cancel the registration on my car  | `Change_Contact_Records`  |
    0.3147  |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 我想取消我的车辆注册 | `Change_Contact_Records` | 0.3147 |'
- en: '| I would like to cancel my car registration  | `License_or_ID`  | 0.3447  |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 我想取消我的汽车注册 | `License_or_ID` | 0.3447 |'
- en: '| I would like to cancel my state identification card  | `Change_Contact_Records`  |
    0.2982  |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 我想取消我的州身份证 | `Change_Contact_Records` | 0.2982 |'
- en: '| I wanted to cancel a registration  | `Item_Not_Received`  | 0.3155  |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 我想取消注册 | `Item_Not_Received` | 0.3155 |'
- en: '| I want to confirm cancellation of my registration  | `Item_Not_Received`  |
    0.4092  |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 我想确认取消我的注册 | `Item_Not_Received` | 0.4092 |'
- en: '| Questions about cancelling registration for a vehicle  | `Fee_Info`  | 0.2795  |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 关于取消车辆注册的问题 | `Fee_Info` | 0.2795 |'
- en: '| I want to cancel my registration on my pickup  | `Item_Not_Received`  | 0.4761  |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 我想取消我的皮卡注册 | `Item_Not_Received` | 0.4761 |'
- en: We’ll randomly divide these into a training set of nine utterances under a new
    `#Cancel_Registration_or_License` intent and add the remaining thirteen to our
    blind test set.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些随机分成包含九个表述的新`#Cancel_Registration_or_License`意图的训练集，并将剩余的十三个添加到我们的盲测试集中。
- en: When we run the updated blind test set against our updated classifier (now V7),
    we get an overall accuracy of 92%, which is usually a very good, if not ideal,
    outcome. This will not always be the case, so if your overall performance drastically
    drops, you will need to iterate through the applicable improvement steps (depending
    on whether the problem was recall, precision, or both) for the intents that were
    affected.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将更新的盲测试集与更新的分类器（现在是V7）运行时，我们得到整体准确率为92%，这通常是一个非常好的，如果不是理想的结果。这并不总是如此，所以如果你的整体性能急剧下降，你需要迭代适用于受影响意图的适用改进步骤（取决于问题是召回、精确度还是两者），以解决这些问题。
- en: Let’s walk through one more example of adding a new intent. The logs contained
    several utterances referring to a data breach. This is an example of how a chatbot
    can exhibit declining performance due to new information in the world. In this
    case, the organization had never experienced a data breach before. But when it
    did, and this news became public, users suddenly had a lot of questions about
    it. This manifested as unmatched and incorrect predictions, as seen in table 5.22.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再通过一个添加新意图的例子来了解一下。日志中包含了几条关于数据泄露的表述。这是一个例子，说明了聊天机器人如何因为世界上的新信息而表现出下降的性能。在这种情况下，该组织之前从未经历过数据泄露。但是当它发生时，并且这个消息公开后，用户突然对它提出了很多问题。这表现为不匹配和不正确的预测，如表5.22所示。
- en: Table 5.22 Unmatched utterances on the topic of “data breach” from logs, with
    predictions from the V7 classifier. The classifier didn’t have enough confidence
    to match most of the utterances referring to “hack” or “data breach,” which is
    good because we hadn’t yet taught it anything about that topic. But most of the
    utterances that contain the word “stolen” match strongly against our `#Report_Stolen`
    intent. This may not go so well for the user because our solution doesn’t have
    any answers yet concerning data that was stolen.
  id: totrans-417
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.22 从日志中关于“数据泄露”主题的不匹配表述，以及V7分类器的预测。分类器对大多数提到“黑客”或“数据泄露”的表述缺乏足够的信心进行匹配，这是好的，因为我们还没有教它关于这个主题的任何东西。但是，包含“被盗”一词的大多数表述都强烈匹配我们的`#Report_Stolen`意图。这可能不会对用户很好，因为我们的解决方案还没有关于被盗数据的任何答案。
- en: '| Utterance | Predicted intent | Confidence |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 表述 | 预测意图 | 置信度 |'
- en: '| --- | --- | --- |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| I want to know about that hacking on the BMV  | <none>  | n/a  |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 我想了解BMV上的黑客攻击情况 | <none> | n/a |'
- en: '| I want to know about the breach in information at the BMV and if I’m at risk  |
    <none>  | n/a  |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 我想了解BMV信息泄露的情况以及我是否处于风险之中 | <none> | n/a |'
- en: '| My identity has been stolen  | `Report_Stolen`  | 0.9483  |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 我的身份信息被盗 | `Report_Stolen` | 0.9483 |'
- en: '| My license number was stolen  | `Report_Stolen`  | 0.9240  |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 我的许可证号码被盗 | `Report_Stolen` | 0.9240 |'
- en: '| Need questions answered about data breach  | <none>  | n/a  |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| 需要回答关于数据泄露的问题 | <none> | n/a |'
- en: '| No I’m curious about the current breach of stolen IDs  | `Report_Stolen`  |
    0.8604  |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 不，我对当前被盗身份证的泄露情况感到好奇 | `Report_Stolen` | 0.8604 |'
- en: '| Someone hacked my information  | `Report_Stolen`  | 0.4662  |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 有人黑客攻击了我的信息 | `Report_Stolen` | 0.4662 |'
- en: '| Someone is using my drivers license number  | `Get_ID_Number`  | 0.4067  |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 有人在使用我的驾照号码 | `Get_ID_Number` | 0.4067 |'
- en: '| Someone stole my identity  | `Report_Stolen`  | 0.7705  |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 有人偷了我的身份信息 | `Report_Stolen` | 0.7705 |'
- en: '| Someone stole my information  | `Report_Stolen`  | 0.8043  |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 有人偷走了我的信息 | `Report_Stolen` | 0.8043 |'
- en: '| Stolen personal identity  | `Report_Stolen`  | 0.9263  |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 被盗的个人身份 | `Report_Stolen` | 0.9263 |'
- en: '| Stolen personal information  | `Report_Stolen`  | 0.9166  |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 被盗的个人身份信息 | `Report_Stolen` | 0.9166 |'
- en: '| Stolen social security number  | `Report_Stolen`  | 0.7515  |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 被盗的社会保障号码 | `Report_Stolen` | 0.7515 |'
- en: '| Was my account affected by the recent data hack?  | <none>  | n/a  |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 我的账户是否受到了最近数据黑客攻击的影响？ | <none> | n/a |'
- en: '| Was my account hacked?  | `Login_Issue`  | 0.3998  |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 我的账户是否被黑客攻击？ | `Login_Issue` | 0.3998 |'
- en: '| Was there a data breach?  | <none>  | n/a  |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 是否发生了数据泄露？ | <none> | n/a |'
- en: '| Yeah I’d like to know if my driver’s license has been breached  | `Report_Stolen`  |
    0.4092  |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 嗯，我想知道我的驾照是否被泄露 | `Report_Stolen` | 0.4092 |'
- en: '| Yes what do I do about the data breach at the BMV?  | <none>  | n/a  |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 是的，我在BMV的数据泄露事件中该怎么办？ | <none> | n/a |'
- en: '| Was my social security number stolen in the hack?  | `Report_Stolen`  | 0.7806  |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 在黑客攻击中我的社会保障号码是否被盗？ | `Report_Stolen` | 0.7806 |'
- en: '| I want to know if my information was stolen  | `Report_Stolen`  | 0.9198  |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 我想了解我的信息是否被盗 | `Report_Stolen` | 0.9198 |'
- en: To resolve the problem of this unmatched intent, we selected seven representative
    utterances from the logs to create a new intent called `#Data_Breach`. Our selection
    ensured that a variety of important terms, such as “hack,” “breach,” and “stolen,”
    were added to our new training set. The remaining utterances were added to our
    blind test set, and we tested our newest classifier, V8\. The new `#Data_Breach`
    intent returned a perfect score, and the F1 score comparisons in table 5.23 show
    that nearly all others remained steady or improved since our baseline reading.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这种不匹配的意图问题，我们从日志中选择了七个代表性语句来创建一个新的意图，称为`#Data_Breach`。我们的选择确保将各种重要术语，如“黑客”、“泄露”和“被盗”，添加到我们的新训练集中。其余的语句被添加到我们的盲测试集中，我们测试了最新的分类器V8。新的`#Data_Breach`意图得到了满分，表5.23中的F1分数比较显示，几乎所有其他指标自基线以来都保持稳定或有所提高。
- en: Table 5.23 Final score comparison between the baseline (V1) and the final version
    (V8)
  id: totrans-441
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.23 基线版本（V1）和最终版本（V8）的最终分数比较
- en: '| Intent | Baseline (V1) F1 score | V8 F1 score |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 意图 | 基线（V1）F1分数 | V8 F1分数 |'
- en: '| --- | --- | --- |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `Accident_Report`  | 1  | 1  |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| `Accident_Report` | 1 | 1 |'
- en: '| `Appointment`  | 0.8333  | 0.8333  |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| `Appointment` | 0.8333 | 0.8333 |'
- en: '| `Cancel_Registration_or_License`  | n/a (NEW)  | 0.9630  |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| `Cancel_Registration_or_License` | n/a (NEW) | 0.9630 |'
- en: '| `Change_Contact_Records`  | 1  | 0.8889  |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| `Change_Contact_Records` | 1 | 0.8889 |'
- en: '| `Chitchat_Goodbye`  | 1  | 1  |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Goodbye` | 1 | 1 |'
- en: '| `Chitchat_Hello`  | 1  | 1  |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Hello` | 1 | 1 |'
- en: '| `Chitchat_Thanks`  | 1  | 1  |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_Thanks` | 1 | 1 |'
- en: '| `Chitchat_VA_About`  | 0.6667  | 1  |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| `Chitchat_VA_About` | 0.6667 | 1 |'
- en: '| `Data_Breach`  | n/a (NEW)  | 1  |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| `Data_Breach` | n/a (NEW) | 1 |'
- en: '| `Fee_Info`  | 0.90  | 0.9524  |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| `Fee_Info` | 0.90 | 0.9524 |'
- en: '| `General_Negative_Feedback`  | 0.80  | 0.80  |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| `General_Negative_Feedback` | 0.80 | 0.80 |'
- en: '| `General_Request_Agent`  | 0.80  | 0.80  |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| `General_Request_Agent` | 0.80 | 0.80 |'
- en: '| `Get_ID_Number`  | 0.75  | 1  |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| `Get_ID_Number` | 0.75 | 1 |'
- en: '| `Item_Not_Received`  | 0.56  | 0.8750  |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| `Item_Not_Received` | 0.56 | 0.8750 |'
- en: '| `License_Reinstatement`  | 0.60  | 0.75  |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| `License_Reinstatement` | 0.60 | 0.75 |'
- en: '| `License_or_ID`  | 0.6667  | 1  |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| `License_or_ID` | 0.6667 | 1 |'
- en: '| `Login_Issue`  | 0.6153  | 0.9412  |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| `Login_Issue` | 0.6153 | 0.9412 |'
- en: '| `Name_Change`  | 1  | 1  |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| `Name_Change` | 1 | 1 |'
- en: '| `Office_Information`  | 0.90  | 1  |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| `Office_Information` | 0.90 | 1 |'
- en: '| `Payment_Methods`  | 1  | 1  |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| `Payment_Methods` | 1 | 1 |'
- en: '| `Refund_Overcharge`  | 0.8571  | 0.80  |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| `Refund_Overcharge` | 0.8571 | 0.80 |'
- en: '| `Report_Sold_Vehicle`  | 0.9231  | 1  |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Sold_Vehicle` | 0.9231 | 1 |'
- en: '| `Report_Stolen_License_Permit_ID`  | 0.80  | (n/a - merged)  |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_License_Permit_ID` | 0.80 | (n/a - merged) |'
- en: '| `Report_Stolen_Plates_Registration`  | 0.8889  | (n/a - merged)  |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Plates_Registration` | 0.8889 | (n/a - merged) |'
- en: '| `Report_Stolen_Vehicle`  | 0.50  | (n/a - merged)  |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen_Vehicle` | 0.50 | (n/a - merged) |'
- en: '| `Report_Stolen`  | n/a  | 0.9630  |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| `Report_Stolen` | n/a | 0.9630 |'
- en: '| `Request_Receipt`  | 1  | 1  |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| `Request_Receipt` | 1 | 1 |'
- en: '| `Vehicle_Permit`  | 0.8889  | 1  |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Permit` | 0.8889 | 1 |'
- en: '| `Vehicle_Title`  | 0.40  | 0.6667  |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| `Vehicle_Title` | 0.40 | 0.6667 |'
- en: '| `Walk_In`  | 0.4615  | 0.75  |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| `Walk_In` | 0.4615 | 0.75 |'
- en: Our overall accuracy score remained steady at 92%. (Our updated blind test set
    has 160 questions, and 147 were correct.) You might recall that our very first
    blind test had an overall accuracy of 76%, so this is quite an improvement. Our
    V8 confusion matrix, shown in figure 5.7, also looks improved, with a fairly dark
    diagonal line.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的总体准确率保持在92%。（我们的更新后的盲测试集有160个问题，其中147个是正确的。）您可能还记得，我们第一次盲测试的总体准确率是76%，所以这是一个很大的改进。图5.7中显示的V8混淆矩阵看起来也有所改进，有一个相当暗的对角线。
- en: '![figure](../Images/CH05_F07_Freed2.png)'
  id: totrans-475
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F07_Freed2.png)'
- en: Figure 5.7 Comparison of baseline (V1) confusion matrix to the V8 update
  id: totrans-476
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7 基线（V1）混淆矩阵与V8更新的比较
- en: We could iterate further to try to get a little higher, but for this use case,
    the classifier’s accuracy is more than good enough for the time being. Any further
    tweaks with the limited data we have at present are likely to over-fit our model
    to the current blind test set. Remember that a healthy strategy is to plan to
    iterate over the life of the bot, using newer logs and refreshed blind test sets.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步迭代以尝试提高一点，但对于这个用例，分类器的准确性目前已经足够好了。使用我们目前有限的现有数据进行的任何进一步调整都可能使我们的模型过度拟合当前的盲测试集。请记住，一个健康的策略是在机器人的整个生命周期中迭代，使用新的日志和更新的盲测试集。
- en: 5.3.2 When to stop adding intents
  id: totrans-478
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 何时停止添加意图
- en: 'When reviewing your logs, you may have encountered a diverse range of other
    questions that are perfectly reasonable for the domain, but very infrequent. In
    our logs, we saw questions like the following, but no additional utterances with
    similar goals:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查您的日志时，您可能遇到了各种各样的问题，这些问题对于该领域来说是完全合理的，但非常罕见。在我们的日志中，我们看到了以下问题，但没有类似目标的额外表述：
- en: I need a form for a doctor to fill out saying a driver is not safe to drive
    anymore.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我需要一份医生填写的形式，说明一名驾驶员不再安全驾驶。
- en: I have a question about electronic signatures.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我有一个关于电子签名的问题。
- en: What is the process for getting a specialty license plate?
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得特殊牌照的过程是怎样的？
- en: How do we know when to stop adding intents? It’s best to let the data from our
    human-annotated logs guide us. We can total up all of the examples by intent and
    render them as a chart, as in figure 5.8\.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道何时停止添加意图？最好的做法是让我们的手动注释日志数据来引导我们。我们可以按意图汇总所有示例，并将其绘制成图表，如图5.8所示。
- en: '![figure](../Images/CH05_F08_Freed2.png)'
  id: totrans-484
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F08_Freed2.png)'
- en: Figure 5.8 Example of a longtail chart. The terms we use to describe the volume
    distribution of our available training data are “short head” and “long tail.”
    These terms describe the visual representation of rendering our data on a bar
    chart. The heavier-volume intents are on the left (the short head), and as the
    volume decreases for each intent, the data has the appearance of a long tail falling
    off to the right.
  id: totrans-485
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.8 长尾图表的示例。我们用来描述可用训练数据量分布的术语是“短头”和“长尾”。这些术语描述了在柱状图上渲染我们的数据的视觉表示。高量级的意图位于左侧（短头），随着每个意图的量级减少，数据看起来像是从右侧掉落的长尾。
- en: 'In our longtail chart, we picked a point to divide between what should be in
    scope versus out of scope. This point isn’t a static, prescriptive position. It’s
    a decision that should be made with the business by establishing a minimum number
    of training examples required to create a new intent. Everything that falls on
    the left of this line should probably be included in the training, as there is
    evidence that these topics will be asked more frequently. Everything to the right
    will not be trained in the current classifier. Over time, you may find enough
    data in the logs to justify adding a new intent. Until then, your solution will
    have to handle such topics with one of the following strategies: give a response
    saying the bot doesn’t understand, fall back to an agent escalation, add a search
    integration to find answers in a document repository, or implement a retrieval-augmented
    generation (RAG) or large language model (LLM) component to generate answers.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的长尾图表中，我们选择了一个点来区分应该包含在范围内还是范围外。这个点不是一个静态的、规定性的位置。这是一个应该与业务方通过建立创建新意图所需的最小训练示例数量来做出的决定。所有落在这条线左侧的内容可能都应该包含在训练中，因为有证据表明这些主题将被更频繁地询问。所有落在这条线右侧的内容将不会在当前的分类器中进行训练。随着时间的推移，您可能在日志中找到足够的数据来证明添加新意图的合理性。在此之前，您的解决方案将不得不使用以下策略之一来处理这些主题：给出一个响应说机器人不理解，回退到代理升级，添加一个搜索集成以在文档存储库中查找答案，或者实现检索增强生成（RAG）或大型语言模型（LLM）组件来生成答案。
- en: Exercises
  id: totrans-487
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Identify new topics based on your logs, and build new intents from the utterances
    found in the logs.
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据您的日志识别新主题，并从日志中找到的表述构建新的意图。
- en: Add utterances to your blind set, and test your changes.
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将表述添加到您的盲集中，并测试您的更改。
- en: Is your classifier able to recognize the new intent without negatively affecting
    the performance of your existing intents?
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的分类器能否在不会对现有意图的性能产生负面影响的情况下识别新的意图？
- en: 5.4 Supplementing traditional AI with generative content
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 使用生成内容补充传统人工智能
- en: In conversational AI, we typically think of delivering either a static answer
    (as in classic intent-driven implementations) or an answer that is entirely generated
    (as in a RAG pattern). Static answers fill a need where an answer must maintain
    consistency, either in content or in structure. Although personalization is possible,
    it is generally limited to defined entities or other context-driven dialogue conditions.
    This tends to result in colder, less personalized bot responses. Figure 5.9 shows
    how three users with the same general goal, but very different personal situations,
    all receive the same bot response.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话式人工智能中，我们通常认为提供的是静态答案（如在经典意图驱动实现中）或完全生成的答案（如在RAG模式中）。静态答案满足了一个需求，即答案必须在内容或结构上保持一致性。尽管个性化是可能的，但它通常仅限于定义的实体或其他由上下文驱动的对话条件。这往往会导致更冷、更缺乏个性化的机器人响应。图5.9显示了具有相同一般目标但个人情况非常不同的三个用户都收到相同机器人响应的情况。
- en: '![figure](../Images/CH05_F09_Freed2.png)'
  id: totrans-493
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F09_Freed2.png)'
- en: Figure 5.9 In a traditional (classification-based) dialogue pattern, an intent
    is identified, and the dialogue is configured to give a static or minimally personalized
    answer.
  id: totrans-494
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.9 在传统的（基于分类的）对话模式中，识别了一个意图，并且对话被配置为提供静态或最小个性化的答案。
- en: 5.4.1 Combining traditional and generative AI for an intent
  id: totrans-495
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 为意图结合传统和生成人工智能
- en: We can enhance the user experience using a hybrid response pattern, which combines
    personalized generated content with the static predefined answers written for
    our intent. Our goal is to acknowledge the user’s problem while ensuring that
    important information is delivered with consistency. Many large language models
    excel at summarization tasks, so a model can be prompted to craft an empathetic
    message that conveys a personalized level of understanding. Figure 5.10 shows
    what this looks like from the user’s perspective.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用混合响应模式来增强用户体验，该模式结合了个性化的生成内容与我们为意图编写的静态预定义答案。我们的目标是承认用户的问题，同时确保重要信息以一致性传达。许多大型语言模型在总结任务上表现出色，因此可以提示模型编写一个传达个性化理解水平的同情信息。图5.10显示了从用户的角度看这会是什么样子。
- en: '![figure](../Images/CH05_F10_Freed2.png)'
  id: totrans-497
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F10_Freed2.png)'
- en: Figure 5.10 An output response identifies the correct intent using traditional
    AI and then prepends generated text to the static output response configured for
    the intent. The generated greeting and summary convey to the user that the bot
    understands their goal and the particular details of the user’s situation.
  id: totrans-498
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.10 一个输出响应使用传统人工智能识别正确的意图，然后在其为该意图配置的静态输出响应之前添加生成的文本。生成的问候和总结向用户传达机器人理解了他们的目标以及用户特定的情况细节。
- en: This pattern employs an API call to the LLM as a dialogue step. Content is generated
    by the LLM and delivered just before the predefined output response. Figure 5.11
    shows the high-level steps for such a pattern.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式使用API调用LLM作为对话步骤。内容由LLM生成，并在预定义的输出响应之前交付。图5.11显示了这种模式的高级步骤。
- en: '![figure](../Images/CH05_F11_Freed2.png)'
  id: totrans-500
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F11_Freed2.png)'
- en: Figure 5.11 LLMs can be called within traditional dialogue patterns to greet
    a user and summarize their problem before delivering a predefined or static answer.
  id: totrans-501
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.11 LLM可以在传统对话模式中调用，以问候用户并在提供预定义或静态答案之前总结他们的问题。
- en: 5.4.2 Prompting to convey understanding
  id: totrans-502
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 提示以传达理解
- en: In conversational AI, your bot’s role is typically to be a representative of
    your company. They are a “digital” resource, as opposed to a “human” resource.
    Still, their job is to be the face of the company. Human agents are great at conveying
    empathy and understanding. In fact, they will often restate the user’s problem
    to demonstrate that they understand. LLMs can be prompted to simulate this summarization
    behavior.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话式人工智能中，您的机器人的角色通常是作为您公司的代表。他们是“数字”资源，而不是“人类”资源。尽管如此，他们的工作是要成为公司的面孔。人类代理擅长传达同情和理解。事实上，他们经常会重申用户的问题，以表明他们理解。可以提示LLM来模拟这种总结行为。
- en: Since our traditional AI has already classified the user’s intent under this
    pattern, we can craft a prompt that instructs the LLM to perform a specific task.
    In this case, we want the LLM to generate a personalized, empathetic greeting
    that can be paired with additional static content. The next listing shows a prompt
    instruction for summarizing a user’s input.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的传统AI已经根据这种模式对用户的意图进行了分类，我们可以制定一个提示，指导LLM执行特定任务。在这种情况下，我们希望LLM生成一个个性化的、富有同情心的问候语，可以与额外的静态内容搭配。下面的列表显示了总结用户输入的提示指令。
- en: Listing 5.1 Prompting a model to greet and summarize a user problem
  id: totrans-505
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.1 指示模型问候和总结用户问题
- en: '[PRE6]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Exercises
  id: totrans-507
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Collect a set of user utterances to test and tune an LLM prompt that can greet
    a user where appropriate and summarize their problem.
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一组用户话语以测试和调整一个LLM提示，该提示可以在适当的时候问候用户并总结他们的问题。
- en: Experiment with a variety of instruction prompts. The goal is to create an efficient
    prompt instruction that will produce good results for the majority of your utterance
    test set.
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尝试各种指令提示。目标是创建一个高效的提示指令，以便为大多数话语测试集产生良好的结果。
- en: Summary
  id: totrans-510
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A classifier’s performance can be measured in terms of accuracy, recall, precision,
    and F1 score. These measurements reflect the types of errors a classifier may
    be committing.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器的性能可以用准确率、召回率、精确率和F1分数来衡量。这些测量反映了分类器可能犯的错误类型。
- en: The performance metrics produced by your testing will inform your next steps
    toward improving classifier performance. Higher volume intents with low performance
    are a good place to start.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的测试产生的性能指标将指导你下一步提高分类器性能的步骤。具有低性能的高体积意图是一个好的起点。
- en: Iterative test and train cycles will show you the effects of your changes.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代测试和训练周期将显示你更改的效果。
- en: A chatbot can use additional strategies, such as disambiguation, clarifying
    questions, and entity detection to overcome confusion or route answers for merged
    intents.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个聊天机器人可以使用额外的策略，例如消除歧义、澄清问题和实体检测，以克服混淆或为合并的意图路由答案。
- en: A chatbot with a strong classifier can deliver more business value by delivering
    the right answers on the first try and deflecting work that would otherwise be
    handled by a human agent. You should plan to monitor and retrain your solution
    throughout the life of the bot.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有强大分类器的聊天机器人可以通过在第一次尝试就给出正确答案，并转移由人工代理处理的工作，从而提供更多的商业价值。你应该计划在整个聊天机器人生命周期内监控和重新训练你的解决方案。
- en: Generative AI can supplement a traditional AI solution by infusing static chatbot
    responses with personalization and empathy, which enhances the perception of understanding.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI可以通过在静态聊天机器人响应中注入个性化和同情心来补充传统AI解决方案，这增强了理解的感觉。
