- en: Chapter 3\. Architectures and Trust Boundaries
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章. 架构和信任边界
- en: Unlike traditional web applications that rely on predefined algorithms and static
    databases, LLMs utilize massive neural networks to generate dynamic, context-aware
    responses. This seismic shift brings a unique set of security challenges, different
    from those seen in traditional web applications. While researchers have meticulously
    studied web applications and their vulnerabilities, the field of LLM security
    is still relatively nascent.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 与依赖于预定义算法和静态数据库的传统Web应用程序不同，LLMs利用庞大的神经网络生成动态、上下文感知的响应。这种地震般的变化带来了一组独特的安全挑战，与在传统Web应用程序中看到的挑战不同。虽然研究人员已经仔细研究了Web应用程序及其漏洞，但LLM安全领域仍然相对较新。
- en: This chapter aims to bridge this knowledge gap by dissecting the fundamental
    elements that set LLMs apart. We’ll start by exploring the building blocks of
    AI, neural networks, and how they relate to large language models. Then, we dive
    into the groundbreaking architecture that powers most LLMs today—the transformer
    model. Following this, we look into the various LLM-powered applications, such
    as chatbots and copilots.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在通过剖析区分LLMs的基本元素来弥合这一知识差距。我们将从探索人工智能、神经网络及其与大型语言模型的关系的构建块开始。然后，我们将深入了解今天大多数LLMs所采用的革命性架构——转换器模型。在此之后，我们将探讨由LLM驱动的各种应用，例如聊天机器人和共飞行员。
- en: However, in addition to understanding the technology, security professionals
    must be aware of the new kinds of *trust boundaries* unique to LLMs—boundaries
    that demarcate areas of varying trustworthiness within an application. These include
    user prompts, uploaded content, training and test data, databases, plug-ins, and
    other boundary systems that we’ll detail later in the chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，除了理解技术之外，安全专业人士还必须了解LLMs特有的新型*信任边界*——这些边界在应用程序中划定了不同可信度的区域。这包括用户提示、上传的内容、训练和测试数据、数据库、插件以及其他我们将在本章后面详细说明的边界系统。
- en: 'AI, Neural Networks, and Large Language Models: What’s the Difference?'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能、神经网络和大型语言模型：它们有什么区别？
- en: 'Artificial intelligence, neural network, and LLM are terms often used interchangeably,
    but they represent different facets of a broader landscape of machine learning
    and computational intelligence. Let’s break down the differences to understand
    their unique roles in technology and security:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能、神经网络和LLM是经常被互换使用的术语，但它们代表了更广泛机器学习和计算智能领域的不同方面。让我们分析它们的区别，以了解它们在技术和安全中的独特角色：
- en: Artificial intelligence (AI)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）
- en: '*Artificial intelligence*, at its core, is a multidisciplinary field aimed
    at creating systems capable of performing tasks that would ordinarily require
    human intelligence. These tasks include problem-solving, perception, and language
    understanding. AI encompasses a wide range of technologies and methodologies,
    from rule-based systems to machine learning algorithms, serving as an umbrella
    term for multiple approaches to achieving artificial intelligence. It’s worth
    noting that the very definition of AI has been a moving target over the past few
    decades and continues to evolve as technology advances.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能*，从其核心来看，是一个跨学科领域，旨在创建能够执行通常需要人类智能的任务的系统。这些任务包括问题解决、感知和语言理解。人工智能涵盖了广泛的技术和方法，从基于规则的系统到机器学习算法，作为一个总称，涵盖了实现人工智能的多种方法。值得注意的是，人工智能的定义在过去几十年中一直是一个不断变化的目标，并且随着技术的进步而持续发展。'
- en: Neural networks
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: '*Neural networks* are one type of AI technology inspired by the human brain’s
    architecture. They are computational models designed to recognize patterns and
    make decisions based on the data they process. Neural networks can be simple,
    with a minimal number of layers (shallow neural networks), or highly complex,
    with multiple interconnected layers (deep neural networks). They are the backbone
    of many modern AI applications, including image recognition, natural language
    processing, and autonomous vehicles.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*神经网络*是一种受人类大脑架构启发的AI技术。它们是计算模型，旨在识别模式并根据它们处理的数据做出决策。神经网络可以是简单的，具有最少数量的层（浅层神经网络），也可以是高度复杂的，具有多个相互连接的层（深层神经网络）。它们是许多现代AI应用的基础，包括图像识别、自然语言处理和自动驾驶汽车。'
- en: Large language models (LLMs)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）
- en: '*LLMs* represent a specific type of neural network. LLMs usually employ advanced
    forms of neural networks, such as transformer models, to analyze and produce text
    based on the training data their developers feed them. What sets them apart is
    their massive scale and specialization in handling linguistic tasks, which range
    from simple text completion to complex question answering and summarization.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*LLMs*代表一种特定的神经网络。LLMs通常采用高级神经网络形式，如变压器模型，根据其开发者提供的数据分析并生成文本。它们与众不同的地方在于其庞大的规模和专门处理语言任务的能力，这些任务范围从简单的文本补全到复杂的问答和总结。'
- en: Understanding these distinctions is crucial for security professionals. Each
    layer—from broad AI technologies to specialized LLMs—introduces vulnerabilities
    and requires unique security measures. As we analyze the complexities of LLMs,
    recognizing their position in the broader AI landscape will be critical to discussing
    effectively safeguarding them. The rest of this book is centered on that discussion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于安全专业人士来说，理解这些区别至关重要。每一层——从广泛的AI技术到专门的LLMs——都引入了漏洞，并需要独特的安全措施。随着我们分析LLMs的复杂性，认识到它们在更广泛的AI景观中的位置对于有效地讨论保护它们将是关键的。本书的其余部分都围绕着这一讨论展开。
- en: 'The Transformer Revolution: Origins, Impact, and the LLM Connection'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变压器的革命：起源、影响以及与LLM的联系
- en: The transformer architecture is a pivotal milestone in the evolution of artificial
    intelligence, profoundly impacting the AI landscape and, by extension, LLMs. Let’s
    unravel the story of the transformer revolution—where it came from, when it happened,
    and the seismic shifts it brought to AI and LLMs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器架构是人工智能演变中的一个关键里程碑，对AI景观产生了深远的影响，进而影响了LLMs。让我们揭开变压器革命的历程——它的起源、发生的时间以及它给AI和LLMs带来的地震般的变化。
- en: Origins of the Transformer
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变压器的起源
- en: 'The transformer architecture was introduced in the groundbreaking research
    paper [“Attention Is All You Need”](https://oreil.ly/lRNoH) by Ashish Vaswani
    et al., published in 2017\. This paper proposed a novel approach to natural language
    processing (NLP) tasks, departing from the traditional models that relied heavily
    on recurrent neural networks (RNNs) and convolutional neural networks (CNNs).
    The transformer introduced a key innovation: the self-attention mechanism. This
    mechanism allowed the model to weigh the importance of different words in a sentence,
    enabling it to understand context more effectively.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器架构是在2017年发表的具有里程碑意义的学术论文[“Attention Is All You Need”](https://oreil.ly/lRNoH)中由Ashish
    Vaswani等人提出的。这篇论文提出了一种新颖的自然语言处理（NLP）任务方法，与传统依赖于循环神经网络（RNNs）和卷积神经网络（CNNs）的模型不同。变压器引入了一个关键创新：自注意力机制。这种机制使得模型能够权衡句子中不同单词的重要性，从而更有效地理解上下文。
- en: Before the emergence of transformers, the world of neural networks was replete
    with promise but often struggled to deliver on the lofty expectations. Traditional
    architectures like RNNs and CNNs enabled advanced AI capabilities but grappled
    with inherent limitations. These limitations stemmed from their inability to capture
    and utilize context effectively, particularly in natural language understanding.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在变压器出现之前，神经网络的世界充满了希望，但往往难以满足高期望。传统的架构如RNNs和CNNs虽然使先进的AI能力成为可能，但面临着固有的局限性。这些局限性源于它们无法有效地捕捉和利用上下文，尤其是在自然语言理解方面。
- en: RNNs, while suitable for sequential data, faced challenges maintaining context
    over long sequences. They exhibited a form of “short-term memory,” which made
    them less adept at grasping intricate relationships and dependencies within lengthy
    texts or conversations. On the other hand, CNNs, renowned for their prowess in
    image recognition, needed help to extend their effectiveness to sequential data
    like language, where understanding context across words and sentences was paramount.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs虽然适合处理序列数据，但在长序列中保持上下文方面面临挑战。它们表现出一种“短期记忆”形式，这使得它们在理解长文本或对话中的复杂关系和依赖性方面不太擅长。另一方面，CNNs以其在图像识别方面的能力而闻名，但在将它们的有效性扩展到需要理解单词和句子之间上下文的序列数据（如语言）方面需要帮助。
- en: This shortcoming in contextual understanding was the Achilles’ heel of traditional
    neural networks. They could only glimpse small portions of a text at a time, rendering
    them incapable of comprehending the broader narrative or nuances. It was akin
    to trying to understand a novel by reading only a few random sentences from its
    pages. The result was a gap between the promise of AI and its practical application,
    particularly in natural language understanding. It was this gap that the transformer
    architecture would bridge, unleashing a wave of progress and redefining the landscape
    of AI-driven language models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种上下文理解上的不足是传统神经网络的阿喀琉斯之踵。它们一次只能看到文本的一小部分，这使得它们无法理解更广泛的叙事或细微差别。这就像只阅读小说几页中的几个随机句子来理解小说一样。结果是人工智能的承诺与其实际应用之间存在着差距，尤其是在自然语言理解方面。正是这个差距，变换器架构将弥合，引发一波进步并重新定义人工智能驱动的语言模型领域。
- en: Transformer Architecture’s Impact on AI
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变换器架构对人工智能的影响
- en: 'Introducing the transformer architecture wasn’t just a milestone for natural
    language processing; it marked a paradigm shift across multiple domains within
    the AI landscape. While researchers initially used the transformer architecture
    to solve problems related to understanding and generating text, researchers and
    engineers quickly found that its capabilities extended far beyond that. Here are
    some areas where transformer architectures have made a considerable impact:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 引入变换器架构不仅仅是对自然语言处理的一个里程碑；它标志着人工智能领域多个领域内范式的转变。虽然研究人员最初使用变换器架构来解决与理解和生成文本相关的问题，但研究人员和工程师很快发现其能力远远超出了这一点。以下是一些变换器架构产生了重大影响的领域：
- en: Natural language processing (NLP)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）
- en: Of course, the first and most immediate impact was in NLP. Transformer models
    are now the backbone for various language tasks such as translation, summarization,
    question-answering, and sentiment analysis. They have set new performance benchmarks,
    sometimes surpassing human-level capabilities in specific tasks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，最初和最直接的影响是在自然语言处理（NLP）领域。变换器模型现在是各种语言任务的骨干，如翻译、摘要、问答和情感分析。它们设定了新的性能基准，有时在特定任务中甚至超过了人类水平的能力。
- en: Computer vision
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: Interestingly, the transformer architecture also has applications in computer
    vision. While CNNs have been the gold standard for image-related tasks, transformer-based
    models like vision transformer (ViT) demonstrate competitive, if not superior,
    performance in tasks like image classification, object detection, and segmentation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，变换器架构在计算机视觉领域也有应用。虽然卷积神经网络（CNN）一直是图像相关任务的金标准，但基于变换器的模型，如视觉变换器（ViT），在图像分类、目标检测和分割等任务中表现出竞争力，如果不是更优越的性能。
- en: Speech recognition
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 语音识别
- en: The flexibility of transformer architectures has also made them a good fit for
    speech recognition. Combined with specialized models like the conformer, which
    fuses convolutional layers with transformer layers, they have set new standards
    for understanding spoken language.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器架构的灵活性也使它们非常适合语音识别。结合像conformer这样的专用模型，该模型将卷积层与变换器层融合，它们为理解口语语言设定了新的标准。
- en: Autonomous systems and self-driving cars
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自主系统和自动驾驶汽车
- en: One of the most intriguing applications of transformers is autonomous systems,
    including self-driving cars. These vehicles require a high contextual understanding
    to navigate the world safely. Transformer models are at the heart of self-driving
    models from companies like Tesla.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器最引人入胜的应用之一是自主系统，包括自动驾驶汽车。这些车辆需要高度上下文理解才能安全地导航世界。特斯拉等公司自动驾驶模型的核心就是变换器模型。
- en: Health care
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗保健
- en: In health care, transformer models are aiding in tasks ranging from drug discovery
    to the analysis of medical images. Their ability to sift through and interpret
    large amounts of data can speed up research and potentially lead to more accurate
    diagnoses.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在医疗保健领域，变换器模型正在帮助从药物发现到医疗图像分析的各种任务。它们筛选和解释大量数据的能力可以加快研究，并可能导致更准确的诊断。
- en: Therefore, the rise of the transformer architecture has been a tide that lifted
    all boats, revolutionizing not just one but multiple fields within AI. However,
    this versatility also brings unique security challenges across these various applications.
    As we look more deeply into LLM security, we’ll explore how the ubiquitous nature
    of transformer architectures necessitates a multifaceted approach to safeguarding
    AI systems.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Transformer架构的兴起是一场提升所有船只的浪潮，不仅革命了AI领域的一个领域，而且革命了多个领域。然而，这种多功能性也带来了这些各种应用中独特的安全挑战。当我们更深入地研究LLM安全时，我们将探讨Transformer架构无处不在的本质如何需要一种多方面的方法来保护AI系统。
- en: Types of LLM-Based Applications
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLM的应用类型
- en: Two common types of LLM-based applications are chatbots and copilots. Let’s
    briefly look at each to help you understand the breadth of applications in which
    developers use LLMs and give you context for understanding various architectural
    choices as you study further.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的两种常见应用类型是聊天机器人和Copilot。让我们简要地看看每种类型，以帮助您了解开发者使用LLM的应用范围，并在您进一步学习时为您提供理解各种架构选择的背景。
- en: '*Chatbots* are computer programs that can simulate conversations with humans,
    and they often power customer service applications, where they can answer questions
    and support customers. Chatbots also excel at entertainment applications like
    playing games or telling stories. Tay from [Chapter 1](ch01.html#chatbots_breaking_bad)
    is an example of an entertainment chatbot. Here are some more examples of LLM-based
    chatbots:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*聊天机器人*是能够与人类模拟对话的计算机程序，它们通常用于客户服务应用，可以回答问题并支持客户。聊天机器人也擅长娱乐应用，如玩游戏或讲故事。来自[第1章](ch01.html#chatbots_breaking_bad)的Tay是一个娱乐聊天机器人的例子。以下是一些基于LLM的聊天机器人的更多示例：'
- en: Sephora uses a chatbot to help customers find the right products for their skin
    type and needs.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sephora使用聊天机器人帮助客户找到适合他们皮肤类型和需求的产品。
- en: H&M uses a chatbot to help customers find clothes and accessories that match
    their style.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H&M使用聊天机器人帮助客户找到与他们风格相匹配的服装和配饰。
- en: Domino’s Pizza uses a chatbot to allow customers to order pizza via X (Twitter)
    or Facebook Messenger.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domino’s Pizza使用聊天机器人允许客户通过X（Twitter）或Facebook Messenger订购披萨。
- en: Fandango uses a chatbot to help customers find movie times and theaters nearby.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fandango使用聊天机器人帮助客户查找附近的电影时间和影院。
- en: JetBlue Airways uses a chatbot to answer customer questions about flights.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JetBlue Airways使用聊天机器人回答客户关于航班的问题。
- en: Amtrak uses a chatbot to help customers book tickets, check train status, and
    get answers to their questions.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amtrak使用聊天机器人帮助客户预订车票、检查火车状态以及回答他们的问题。
- en: The Golden State Warriors use a chatbot to help fans purchase tickets, learn
    about upcoming games, and get news about the team.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金州勇士队使用聊天机器人帮助球迷购买门票、了解即将到来的比赛以及获取球队新闻。
- en: '*Copilots* are AI systems that can assist humans with writing, coding, and
    research tasks. They can help users to generate ideas, identify errors, and improve
    their work. Copilots are still under development, but they have the potential
    to revolutionize the way we work and learn. Specific examples of LLM-based copilots
    are:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*Copilot*是能够协助人类进行写作、编码和研究任务的AI系统。它们可以帮助用户生成想法、识别错误并改进他们的工作。Copilot仍在开发中，但它们有潜力彻底改变我们的工作和学习方式。基于LLM的Copilot的具体例子包括：'
- en: Grammarly and ProWritingAid help users improve their writing by identifying
    and correcting grammatical errors, suggesting style improvements, and providing
    feedback.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grammarly和ProWritingAid通过识别和纠正语法错误、建议风格改进和提供反馈来帮助用户提高写作水平。
- en: GitHub Copilot, Google Gemini Code Assist, and AWS CodeWhisperer help programmers
    write code faster and more efficiently. They can generate code suggestions, translate
    between programming languages, and help to identify and debug errors.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub Copilot、Google Gemini Code Assist和AWS CodeWhisperer帮助程序员更快、更高效地编写代码。它们可以生成代码建议、在不同编程语言之间进行翻译，并帮助识别和调试错误。
- en: Copilot for Microsoft 365 and Gemini for Google Workspace are AI-powered tools
    integrated into their respective office suites that help users to be more productive
    and creative in their work.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软365的Copilot和谷歌工作空间的Gemini都是集成到各自办公套件中的AI工具，帮助用户在工作中更加高效和富有创造力。
- en: Note
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A chatbot like ChatGPT can read and review a text block and then provide suggestions
    to improve it. However, the experience of using a copilot like Grammarly to do
    that is dramatically different and generally superior for that type of focused
    task.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于ChatGPT的聊天机器人可以阅读和审查文本块，然后提供改进建议。然而，使用Grammarly这样的辅助工具来完成这项任务的经验则大相径庭，并且通常在专注于此类任务时更为优越。
- en: 'Similarities between chatbots and copilots:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人和辅助工具之间的相似之处：
- en: Both chatbots and copilots are LLM-based applications.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人和辅助工具都是基于LLM的应用程序。
- en: Both chatbots and copilots generate text.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人和辅助工具都能生成文本。
- en: Both chatbots and copilots assist humans with tasks.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人和辅助工具都帮助人类完成任务。
- en: 'Differences between chatbots and copilots:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人和辅助工具之间的差异：
- en: Chatbots simulate conversation with humans, while copilots assist humans with
    specific tasks.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人模拟与人类的对话，而辅助工具则帮助人类完成特定任务。
- en: Chatbots often power customer service applications, while copilots assist in
    writing, coding, and research applications.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人通常用于客户服务应用程序，而辅助工具则用于写作、编码和研究应用程序。
- en: Chatbots are typically more interactive than copilots, while copilots focus
    more on completing tasks.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与辅助工具相比，聊天机器人通常更具交互性，而辅助工具则更专注于完成任务。
- en: Keep these concepts in mind as we dig into the details of LLM architectures.
    Both application types share similar components, but you may make different decisions
    on implementing pieces based on the differing security considerations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨LLM架构的细节时，请记住这些概念。这两种应用程序类型具有相似组件，但您可能基于不同的安全考虑在实现组件时做出不同的决策。
- en: LLM Application Architecture
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM应用程序架构
- en: Developers often consider LLMs standalone entities capable of impressive text
    generation and comprehension feats. However, in practice, an LLM is rarely isolated;
    it is a cog in the intricate machinery that constitutes an intelligent application.
    These applications are complex systems comprising multiple interconnected components,
    each playing a vital role in the overall functionality and performance of the
    application. Whether a conversational agent, an automated content generator, or
    a copilot for code, an LLM usually interacts with various elements such as users,
    databases, APIs, web pages, and even other machine learning models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者通常认为大型语言模型（LLM）是独立的实体，能够实现令人印象深刻的文本生成和理解壮举。然而，在实践中，LLM很少是孤立的；它是构成智能应用程序复杂机械的一部分。这些应用程序是由多个相互连接的组件组成的复杂系统，每个组件都在应用程序的整体功能和性能中扮演着至关重要的角色。无论是会话代理、自动内容生成器还是代码辅助工具，LLM通常与各种元素进行交互，如用户、数据库、API、网页，甚至其他机器学习模型。
- en: Understanding the architecture of such composite systems is not just a matter
    of technical proficiency; it is crucial for effective security planning. The way
    these components interact introduces multiple trust and data flow layers, defining
    new security boundaries far removed from traditional web application security
    models. For instance, user inputs may not just be simple text fields but could
    include voice commands, images, or real-time collaborative editing. Similarly,
    an LLM’s outputs could be fed into other systems for further processing, introducing
    vulnerabilities and risks.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 理解此类复合系统的架构不仅是一个技术熟练的问题；对于有效的安全规划至关重要。这些组件的交互引入了多个信任和数据流层，定义了与传统Web应用程序安全模型截然不同的新安全边界。例如，用户输入可能不仅仅是简单的文本字段，还可能包括语音命令、图像或实时协作编辑。同样，LLM的输出可能被输入到其他系统中进行进一步处理，从而引入漏洞和风险。
- en: In essence, the holistic view of an LLM-based application goes beyond securing
    the language model itself. It demands a comprehensive approach that considers
    the security of the entire architecture, from data ingestion and storage to model
    serving and user interaction. Only by understanding these intricacies can one
    formulate an effective strategy to safeguard an application against the myriad
    vulnerabilities such complex systems inherently possess.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，基于LLM的应用程序的整体视角不仅超越了保护语言模型本身。它要求一种全面的方法，考虑整个架构的安全性，从数据摄取和存储到模型服务和用户交互。只有通过理解这些复杂性，才能制定出有效的策略来保护应用程序免受复杂系统固有的各种漏洞的侵害。
- en: As we dig deeper into the subject in this chapter, we’ll dissect the various
    components that typically make up an LLM application, examine their roles, and
    explore the unique security challenges each presents. This understanding will
    be the foundation for a robust, multilayered approach to securing your LLM-based
    applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们在本章中深入探讨主题，我们将剖析通常构成LLM应用的各个组件，检查它们的作用，并探索每个组件带来的独特安全挑战。这种理解将是构建强大、多层次方法以保护基于LLM的应用程序的基础。
- en: '[Figure 3-1](#fig_1_typical_llm_application_dataflow_architecture) shows a
    highly simplified diagram to illustrate the components, relationships, and data
    flows in an application using an LLM. Subsequent chapters will expand on these
    areas.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-1](#fig_1_typical_llm_application_dataflow_architecture)显示了一个高度简化的图，用于说明使用LLM的应用程序中的组件、关系和数据流。后续章节将扩展这些领域。'
- en: '![](assets/dpls_0301.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dpls_0301.png)'
- en: Figure 3-1\. Typical LLM application data-flow architecture
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 典型的LLM应用数据流架构
- en: Trust Boundaries
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信任边界
- en: In application security, a *trust boundary* serves as an invisible, yet crucial,
    demarcation line that separates different components or entities based on their
    level of trustworthiness. These boundaries delineate areas where data or control
    flow changes from one level of trust to another—such as transitioning from user-controlled
    input to internal processing or moving from a secure internal database to a public-facing
    API. These boundaries act as checkpoints where developers should rigorously apply
    security measures like authentication, authorization, and data validation to prevent
    vulnerabilities.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用安全中，*信任边界*作为一个无形但至关重要的分界线，根据其可信度水平将不同的组件或实体分开。这些边界划定了数据或控制流从一个信任级别变化到另一个级别的区域——例如从用户控制的输入过渡到内部处理，或者从安全的内部数据库移动到面向公众的API。这些边界充当检查点，开发者应在此处严格执行安全措施，如身份验证、授权和数据验证，以防止漏洞。
- en: Warning
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Understanding trust boundaries is critical to threat modeling. Properly defining
    and recognizing these boundaries can be the difference between a secure system
    and one vulnerable to threats.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 理解信任边界对于威胁建模至关重要。正确定义和识别这些边界可能是安全系统与易受威胁的系统之间的区别。
- en: '[Figure 3-2](#fig_2_llm_application_architecture_with_trust_boundaries) adds
    the trust boundaries to our architecture diagram.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-2](#fig_2_llm_application_architecture_with_trust_boundaries)将信任边界添加到我们的架构图中。'
- en: '![](assets/dpls_0302.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dpls_0302.png)'
- en: Figure 3-2\. LLM application architecture with trust boundaries
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2\. 带有信任边界的LLM应用架构
- en: 'These boundaries, as depicted in the diagram, serve as gateways through which
    the LLM interfaces with diverse components—public data from the web, structured
    databases, spontaneous user interactions, or internally sourced training sets.
    Each delineated boundary highlights considerations we must make when considering
    data that flows into and out of the LLM. Here’s a quick summary; we’ll dive more
    deeply in the next section:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些边界，如图中所示，作为LLM与各种组件交互的门户——包括来自网络的公共数据、结构化数据库、自发的用户交互或内部来源的训练集。每个划定的边界都突出了我们在考虑流入和流出LLM的数据时必须考虑的因素。以下是一个简要总结；我们将在下一节中深入探讨：
- en: User interactions
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 用户交互
- en: You’ll need to consider safeguarding the model from potential adversarial or
    misleading inputs that users or systems might introduce. You’ll also need to worry
    about toxic, inaccurate, or sensitive data being output from the model and passed
    back to the user.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要考虑保护模型免受潜在对抗性或误导性输入的影响，这些输入可能是用户或系统引入的。您还必须担心模型输出的有毒、不准确或敏感数据被传回给用户。
- en: In-the-wild training data
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 野外训练数据
- en: LLMs are often trained on massive amounts of internet data. You need to consider
    this data untrusted and watch out for potential toxicity, bias, and adversarial
    data poisoning, which we’ll cover in [Chapter 7](ch07.html#trust_no_one).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: LLM通常在大量互联网数据上进行训练。您需要将这些数据视为不可信的，并警惕潜在的毒性、偏见和对抗性数据中毒，这些内容我们将在第7章（ch07.html#trust_no_one）中介绍。
- en: Internal test and training data
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 内部测试和训练数据
- en: You may use internally curated data to fine-tune your model, which can significantly
    increase accuracy. But you must be wary of ingesting and exposing sensitive, confidential,
    or personally identifiable information. We’ll discuss this more in [Chapter 5](ch05.html#can_your_llm_know_too_much).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用内部精选的数据来微调您的模型，这可以显著提高准确性。但您必须警惕摄入和暴露敏感、机密或个人信息。我们将在第5章（ch05.html#can_your_llm_know_too_much）中进一步讨论这个问题。
- en: External services
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 外部服务
- en: You must actively control how the LLM interfaces with connected services, like
    databases or APIs, from unauthorized interactions or data leaks. We’ll cover this
    more in [Chapter 7](ch07.html#trust_no_one).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须积极控制LLM与连接的服务（如数据库或API）的接口，以防止未经授权的交互或数据泄露。我们将在[第7章](ch07.html#trust_no_one)中进一步讨论这一点。
- en: Public data access
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 公共数据访问
- en: Pulling data live from the web can be a powerful way to augment your application’s
    capabilities. However, you’ll need to consider this data untrusted and watch for
    issues like indirect prompt injection, which we’ll cover in [Chapter 4](ch04.html#prompt_injection).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从网络实时获取数据可以是一种增强应用程序功能的有效方式。然而，您需要考虑这些数据是不可信的，并注意像间接提示注入等问题，这些问题我们将在[第4章](ch04.html#prompt_injection)中讨论。
- en: Each point is a potential avenue of vulnerability, susceptible to exploitation
    if overlooked. In the evolving landscape of LLM applications, securing these trust
    boundaries is not just best practice—it’s essential to prevent unauthorized data
    access, mitigate data tampering, and avert system breaches. Recognizing these
    boundaries and their implications is the cornerstone of a resilient LLM security
    architecture. Now, let’s go into more detail on each area to ensure you have enough
    context to dive into the following chapters that detail the risk areas and mitigations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每一点都是一个潜在的漏洞途径，如果被忽视，就容易被利用。在LLM应用程序不断发展的环境中，保护这些信任边界不仅是最佳实践，而且是防止未经授权的数据访问、减轻数据篡改和避免系统漏洞的必要措施。认识到这些边界及其影响是构建弹性LLM安全架构的基础。现在，让我们更详细地探讨每个领域，以确保您有足够的背景知识来深入研究以下章节，这些章节详细介绍了风险区域和缓解措施。
- en: The Model
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: The language model serves as the intellectual core of any LLM application, taking
    in data, generating responses, and driving interactions. Depending on the architecture
    and requirements, you may interact with the language model through a public API
    hosted by a third-party service or run a privately hosted model. For example,
    you can download versions of Meta’s powerful Llama model from GitHub or Hugging
    Face and run it locally.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型是任何LLM应用程序的智力核心，它接收数据、生成响应并驱动交互。根据架构和需求，您可能通过第三方服务提供的公共API与语言模型交互，或者运行私有托管模型。例如，您可以从GitHub或Hugging
    Face下载Meta强大的Llama模型的版本并在本地运行。
- en: 'Public APIs: The convenience and the risks'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 公共API：便利性与风险
- en: Utilizing a public API to access a language model offers convenience and lower
    up-front costs. Third parties manage and update these models, reducing your organization’s
    resource burden. However, the trade-off often comes in the form of higher risk
    of data exposure. When making a request to a third-party model, the data crosses
    a trust boundary, exiting your secure network and entering an external system.
    This process exposes you to risks around data confidentiality and, depending on
    the third party’s security measures, could make you vulnerable to data breaches.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 利用公共API访问语言模型提供了便利和较低的前期成本。第三方负责管理和更新这些模型，减轻了您组织的资源负担。然而，这种权衡往往以更高的数据泄露风险为代价。当向第三方模型发出请求时，数据会跨越信任边界，离开您的安全网络并进入外部系统。这个过程使您面临数据机密性的风险，并且根据第三方的安全措施，可能会使您容易受到数据泄露的攻击。
- en: 'Privately hosted models: More control, different risks'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 私有托管模型：更多控制，不同风险
- en: Opting for a privately hosted model gives you more control over your data, allowing
    you to manage trust boundaries more tightly. It also allows you to customize or
    fine-tune the model according to your needs. However, running a privately hosted
    model brings challenges, such as maintenance, updates, and ensuring that the model
    doesn’t contain vulnerabilities—essentially exposing you to potential supply chain
    risks. If you use an open source model, it becomes crucial to ensure its provenance
    and integrity to avoid embedded vulnerabilities or biases.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 选择私有托管模型可以给您提供更多对数据的控制，让您能够更紧密地管理信任边界。它还允许您根据需要自定义或微调模型。然而，运行私有托管模型会带来挑战，例如维护、更新以及确保模型不包含漏洞——本质上暴露您于潜在的供应链风险。如果您使用开源模型，确保其来源和完整性变得至关重要，以避免嵌入的漏洞或偏见。
- en: Risk considerations
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险考虑
- en: 'Let’s look at some security considerations that depend on your choice of model
    and where it is deployed:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些依赖于您选择的模型及其部署位置的安全考虑因素：
- en: Sensitive data exposure
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据泄露
- en: Public APIs may increase the risk of exposing sensitive information, while privately
    hosted models offer better control but require robust internal security measures.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 公共 API 可能会增加泄露敏感信息的风险，而私有托管模型提供更好的控制，但需要强大的内部安全措施。
- en: Supply chain risk
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 供应链风险
- en: The origins of your model, whether it’s a well-vetted public service or an open
    source download, are crucial. A compromised model can introduce vulnerabilities
    into your application, effectively acting as a back door for attacks. We’ll explore
    this more in [Chapter 9](ch09.html#find_the_weakest_link).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 您的模型起源，无论是经过严格审查的公共服务还是开源下载，都至关重要。一个被破坏的模型可能会将漏洞引入您的应用程序，实际上充当攻击的后门。我们将在[第9章](ch09.html#find_the_weakest_link)中更深入地探讨这一点。
- en: By carefully considering the model’s hosting environment, you can better assess
    the trade-offs and risks associated with sensitive data exposure and supply chain
    vulnerabilities. These considerations will guide you in establishing appropriate
    trust boundaries and security protocols tailored to your chosen model’s architecture.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细考虑模型的托管环境，您可以更好地评估与敏感数据暴露和供应链漏洞相关的权衡和风险。这些考虑将指导您建立适当的信任边界和安全协议，以适应您选择的模型架构。
- en: User Interaction
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户交互
- en: While *user**input* might suggest a one-way flow of information from the user
    into the application, the reality is often more nuanced. In the context of LLM
    applications, *user interaction* encapsulates both receiving input from the user
    and providing output back to the user. This bidirectional interaction is fundamental
    for creating an engaging and practical user experience, but also introduces a
    more complicated security landscape.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 *用户输入* 可能暗示信息从用户流向应用程序的单向流动，但现实情况通常更为复杂。在大型语言模型（LLM）应用程序的背景下，*用户交互* 包含从用户接收输入并向用户提供输出的双向交互。这种双向交互对于创建引人入胜且实用的用户体验至关重要，但也引入了一个更复杂的网络安全环境。
- en: Prompts are a vital element of user interaction. They are not merely requests
    for information but serve as a guide to how the user interacts with the LLM. A
    well-crafted prompt can direct the model to provide valuable and accurate information,
    while an ambiguous or poorly constructed one can lead to unclear or even misleading
    outputs. As a result, the management of prompts becomes a critical aspect of application
    security. For example, a carefully crafted prompt from a malicious user could
    trick the model into divulging information it shouldn’t or cause the model to
    generate harmful content. Returning to [Chapter 1](ch01.html#chatbots_breaking_bad),
    Tay fell victim to this when prompts from her 4chan hackers helped lead her astray.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 提示（Prompts）是用户交互的一个关键元素。它们不仅仅是信息请求，还充当了指导用户如何与大型语言模型（LLM）交互的指南。一个精心设计的提示可以引导模型提供有价值且准确的信息，而一个模糊或构建不当的提示可能会导致输出不明确甚至误导。因此，提示的管理成为应用安全的一个关键方面。例如，一个恶意用户精心设计的提示可能会诱使模型泄露它不应该泄露的信息，或者导致模型生成有害内容。回到[第1章](ch01.html#chatbots_breaking_bad)，Tay
    就是因为她的 4chan 黑客的提示而受到误导。
- en: Given the importance of this bidirectional interaction, securing both inputs
    and outputs is crucial. On the input side, input validation, sanitation, and rate
    limiting measures are vital in mitigating vulnerabilities like injection attacks.
    On the output side, ensuring that the model’s responses are appropriately filtered
    and that your application does not leak sensitive information is equally vital.
    The nature of LLMs makes this even more challenging than it is with traditional
    applications, and we’ll discuss more techniques related to this later in the book.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这种双向交互的重要性，确保输入和输出都得到保护至关重要。在输入方面，输入验证、清理和速率限制措施对于减轻注入攻击等漏洞至关重要。在输出方面，确保模型响应得到适当的过滤，并且您的应用程序不会泄露敏感信息同样至关重要。大型语言模型（LLMs）的性质使得这比传统应用程序更具挑战性，我们将在本书后面讨论更多相关技术。
- en: This interactive layer with the user creates a critical trust boundary in the
    application architecture. Any data crossing this boundary, whether going in or
    out, should be carefully managed to avoid security risks. Additional layers of
    protection include using encryption for sensitive outputs and employing real-time
    monitoring to flag potentially harmful or sensitive data flows. We’ll discuss
    this more thoroughly in [Chapter 7](ch07.html#trust_no_one).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个与用户交互的层在应用架构中创建了一个关键的信任边界。任何跨越这个边界的，无论是进入还是出去的数据，都应该被仔细管理以避免安全风险。额外的保护层包括对敏感输出使用加密和采用实时监控来标记可能有害或敏感的数据流。我们将在[第7章](ch07.html#trust_no_one)中更详细地讨论这个问题。
- en: Training Data
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据
- en: Training data is the bedrock upon which LLMs build their understanding and capabilities.
    Whether used for initial training or subsequent fine-tuning, the nature and source
    of this data have significant implications for both the model’s performance and
    security posture. One crucial distinction is whether the data is internally sourced
    or culled from public or external sources (“in the wild”).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据是LLMs构建其理解和能力的基础。无论是用于初始训练还是后续微调，数据的性质和来源对模型的表现和安全态势都有重大影响。一个重要的区别是数据是内部来源的还是从公共或外部来源（“野外”）收集的。
- en: Data generated or curated within an organization usually undergoes a more rigorous
    vetting than publicly sourced data. It is often aligned with the application’s
    specific requirements or use cases, making it generally more reliable and relevant.
    The controlled environment also allows for better implementation of security measures
    like encryption, access controls, and auditing. However, this data may contain
    sensitive or proprietary information, and the trust boundary here is closely tied
    to internal security protocols. A breach at this level could have serious ramifications,
    including data leakage or the corruption of the training set.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织内部生成或整理的数据通常比公开来源的数据经过更严格的审查。它通常与应用程序的具体要求或用例相一致，使其通常更可靠和更相关。受控环境还允许更好地实施安全措施，如加密、访问控制和审计。然而，这些数据可能包含敏感或专有信息，这里的信任边界与内部安全协议紧密相关。这一级别的泄露可能产生严重的后果，包括数据泄露或训练集的损坏。
- en: 'Data sourced from public repositories or “the wild” introduces different challenges.
    While this data can offer diversity and scale, its reliability and safety are
    often not guaranteed. Such data could include misleading information, biases,
    or malicious inputs to compromise the model. The trust boundary here is more porous
    and extends to the external entities that generate or host this data: rigorous
    filtering, validation, and continuous monitoring become essential to mitigate
    risks and vulnerabilities. As we saw in [Chapter 1](ch01.html#chatbots_breaking_bad),
    Tay was digesting user prompts directly as training data. In this way, remnants
    of toxic prompts became part of her knowledge base, and then she began to spill
    poisonous output. Accepting unfiltered, untrusted user input into your training
    dataset is the simplest example of a failure to manage this critical security
    boundary.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 来自公共存储库或“野外”的数据引入了不同的挑战。虽然这些数据可以提供多样性和规模，但其可靠性和安全性通常无法保证。此类数据可能包括误导性信息、偏见或恶意输入，以损害模型。这里的信任边界更加脆弱，并扩展到生成或托管这些数据的实体：严格的过滤、验证和持续监控成为减轻风险和漏洞的必要条件。正如我们在[第1章](ch01.html#chatbots_breaking_bad)中看到的，Tay直接将用户提示作为训练数据消化。这样，有毒提示的残留部分成为了她的知识库的一部分，然后她开始输出有毒的内容。将未经筛选、不可信的用户输入接受到训练数据集中是未能管理这一关键安全边界的最简单例子。
- en: For either internally sourced or public data, the concept of trust boundaries
    is critical. For internally sourced data, the boundary is often within the organization’s
    controlled environment, making it easier to enforce security measures. On the
    other hand, using external data effectively extends your trust boundary to include
    those external sources, which may not adhere to your security standards. Using
    external data for training necessitates additional layers of validation and security
    checks to ensure that unvetted data doesn’t compromise the integrity or security
    of the LLM application.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内部来源或公共数据，信任边界的概念至关重要。对于内部来源的数据，边界通常在组织的受控环境中，这使得执行安全措施变得更容易。另一方面，有效使用外部数据可以将您的信任边界扩展到包括那些可能不符合您安全标准的外部来源。使用外部数据进行训练需要额外的验证和安全检查层，以确保未经审查的数据不会损害
    LLM 应用程序的完整性和安全性。
- en: Understanding the origins of your training data, the associated trust boundaries,
    and their respective security implications is crucial for safeguarding your LLM
    application. Comprehensive data governance policies must be in place to manage
    the lifecycle of your training data, regardless of its source.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 理解您的训练数据的来源、相关的信任边界及其相应的安全影响对于保护您的 LLM 应用程序至关重要。必须制定全面的数据治理政策来管理您的训练数据的生命周期，无论其来源如何。
- en: Access to Live External Data Sources
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问实时外部数据源
- en: Live external data sources bring an added dimension to the capabilities of LLM
    applications by enabling them to provide real-time information, context, or even
    third-party integrations. While access to live external data enhances the user
    experience and functional range, it introduces a new layer of complexity to the
    application’s security landscape.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 实时外部数据源通过使 LLM 应用程序能够提供实时信息、上下文或甚至第三方集成，为 LLM 应用程序的能力增加了新的维度。虽然访问实时外部数据增强了用户体验和功能范围，但它为应用程序的安全格局引入了新的复杂性。
- en: As an example of this, as of the writing of this chapter, OpenAI’s ChatGPT does
    not have direct access to the live web and is thus limited only to facts in its
    older training data. On the other hand, Google’s Bard (now called Gemini) does
    have access to live internet data for this test. Because of this, while the GPT-4
    model is doubtlessly superior in reasoning capability, it fails at many basic
    tasks where Bard succeeds. [Figure 3-3](#fig_3_chatgpt_with_gtp_4_fails_to_answer_a_simple_questi)
    shows an interaction with ChatGPT. [Figure 3-4](#fig_4_bard_s_direct_access_to_internet_feeds_gives_it_an)
    shows the same interaction with Bard.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，截至撰写本章时，OpenAI 的 ChatGPT 没有直接访问实时网络，因此仅限于其较老训练数据中的事实。另一方面，Google 的 Bard（现在称为
    Gemini）确实有权访问用于此测试的实时互联网数据。正因为如此，尽管 GPT-4 模型在推理能力上无疑更优越，但在 Bard 成功的许多基本任务上却失败了。[图
    3-3](#fig_3_chatgpt_with_gtp_4_fails_to_answer_a_simple_questi) 展示了与 ChatGPT 的交互。[图
    3-4](#fig_4_bard_s_direct_access_to_internet_feeds_gives_it_an) 展示了与 Bard 的相同交互。
- en: '![](assets/dpls_0303.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/dpls_0303.png)'
- en: Figure 3-3\. ChatGPT with GTP-4 fails to answer a simple question due to limited
    access to external data
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 由于对外部数据的访问有限，ChatGPT 无法回答一个简单的问题
- en: '![](assets/dpls_0304.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/dpls_0304.png)'
- en: Figure 3-4\. Bard’s direct access to internet feeds gives it an advantage
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. Bard 直接访问互联网数据流使其具有优势
- en: While accessing outside data sources such as websites, APIs, or third-party
    databases has advantages, it exposes the application to potential risks. The risks
    of ingesting untrusted external data sources can range from consuming false or
    harmful information from compromised websites to becoming a conduit for security
    threats like malware or unauthorized data access. The untrusted nature of these
    data sources makes them inherently less controllable than internal resources,
    thereby adding an additional layer of uncertainty and risk.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然访问外部数据源，如网站、API 或第三方数据库具有优势，但它会使应用程序面临潜在的风险。摄入不受信任的外部数据源的风险范围从消耗受损害网站中的虚假或有害信息到成为恶意软件或未经授权的数据访问等安全威胁的渠道。这些数据源的不受信任性质使它们在本质上不如内部资源可控，从而增加了额外的不确定性和风险。
- en: The concept of trust boundaries becomes especially pertinent when accessing
    public internet data. Unlike internal services, where you can uniformly apply
    security measures, external sources may adhere to security standards different
    from those of your organization. This differential in trust necessitates additional
    layers of validation, security checks, and monitoring to ensure that data crossing
    this boundary doesn’t compromise the system.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当访问公共互联网数据时，信任边界的概念变得尤为重要。与内部服务不同，您可以在其中统一应用安全措施，外部来源可能遵循与您的组织不同的安全标准。这种信任差异需要额外的验证层、安全检查和监控，以确保跨越这一边界的不会损害系统。
- en: Access to Internal Services
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部服务的访问
- en: Internal services like databases and internal APIs often serve as the backend
    support structure for LLM applications. They may house critical data from user
    profiles and logs to configuration settings and even vast data in SQL or vector
    databases. As a component that often interfaces with various other internal and
    external elements of the system, internal services represent a critical point
    in the application’s architecture, both functionally and from a security perspective.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库和内部API等内部服务通常作为LLM应用的底层支持结构。它们可能存储来自用户资料和日志到配置设置，甚至SQL或向量数据库中的大量数据。作为经常与系统内部和外部各种元素接口的组件，内部服务在应用架构中代表了功能性和安全性的关键点。
- en: These services often function within an organization’s controlled environment,
    enabling uniform application of security policies. However, just because these
    services are internal, you mustn’t fall victim to a false sense of security. They
    are still vulnerable to various threats, such as unauthorized access, data leaks,
    and internal threats from within the organization.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务通常在组织的受控环境中运行，使得安全策略的统一应用成为可能。然而，仅仅因为这些服务是内部的，您也不应陷入虚假的安全感。它们仍然容易受到各种威胁，如未经授权的访问、数据泄露和组织内部的内部威胁。
- en: Internal services such as databases, proprietary APIs, and backend systems often
    constitute the operational backbone for LLM applications. These resources typically
    reside within the organization’s secure network, providing trust and control that
    is harder to achieve with external services. However, this internal nature can
    paradoxically elevate the security risks involved, primarily if these services
    house the organization’s “crown jewels” of sensitive or valuable data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 内部服务，如数据库、专有API和后端系统，通常构成了LLM应用的运营骨干。这些资源通常位于组织的安全网络内，提供比外部服务更难以实现的信任和控制。然而，这种内部性质可能反常地提高涉及的安全风险，尤其是如果这些服务存储了组织的“皇冠上的宝石”——敏感或有价值的数据。
- en: Conclusion
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Securing LLM applications is an endeavor fraught with complexities, intricacies,
    and challenges that are significantly different from those of traditional web
    applications. This chapter has aimed to lay down the foundational knowledge required
    to navigate this complex landscape, focusing on three critical areas: distinguishing
    between artificial intelligence, neural networks, and large language models; understanding
    the pivotal role of transformer architectures; and diving deep into LLM application
    architecture, particularly the concept of trust boundaries. Knowing what sets
    LLMs apart helps us tailor our security strategies more effectively, going beyond
    general AI or machine learning frameworks.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 保护LLM应用是一项充满复杂、微妙和挑战的任务，这些挑战与传统Web应用显著不同。本章旨在阐述导航这一复杂领域所需的基础知识，重点关注三个关键领域：区分人工智能、神经网络和大型语言模型；理解变换器架构的关键作用；以及深入探讨LLM应用架构，特别是信任边界的概念。了解LLMs的独特之处有助于我们更有效地定制安全策略，超越一般的AI或机器学习框架。
