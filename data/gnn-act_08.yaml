- en: '6 Dynamic graphs: Spatiotemporal GNNs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 动态图：时空GNN
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing memory into your deep learning models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将记忆引入你的深度学习模型
- en: Understanding the different ways to model temporal relations using graph neural
    networks
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解使用图神经网络建模时序关系的不同方法
- en: Implementing dynamic graph neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现动态图神经网络
- en: Evaluating your temporal graph neural network models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估你的时序图神经网络模型
- en: So far, all of our models and data have been single snapshots in time. In practice,
    the world is dynamic and in constant flux. Objects can move physically, following
    a trajectory in front of our eyes, and we’re able to predict their future positions
    based on these observed trajectories. Traffic flow, weather patterns, and the
    spread of diseases across networks of people are all examples where more information
    can be gained when modeled with spatiotemporal graphs instead of static graphs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所有的模型和数据都只是时间上的单一快照。在实践中，世界是动态的，并且处于不断变化之中。物体可以物理移动，在我们眼前沿着轨迹移动，我们能够根据这些观察到的轨迹预测它们的未来位置。交通流量、天气模式和疾病在人群网络中的传播都是当使用时空图而不是静态图建模时可以获取更多信息的情况。
- en: Models that we build today might quickly lose performance and accuracy as we
    deploy them in the real world. These are problems intrinsic to any deep learning
    (and machine learning) model, known as *out-of-distribution (OOD) generalization,*
    that is, how well models generalize to entirely unseen data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天构建的模型，一旦部署到现实世界中，可能会迅速失去性能和准确性。这些问题是任何深度学习（以及机器学习）模型固有的，被称为*分布外（OOD）泛化*问题，即模型对完全未见过的数据的泛化能力如何。
- en: In this chapter, we consider how to make models that are suitable for dynamic
    events. While this doesn’t mean they can deal with OOD data, our dynamic models
    will be able to make predictions about unseen events in the future using the recent
    past.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们考虑如何构建适合动态事件的模型。虽然这并不意味着它们可以处理OOD数据，但我们的动态模型将能够利用最近过去的数据对未来未见的事件进行预测。
- en: To build our dynamic graph-based learning model, we’ll consider the problem
    of pose estimation. *Pose estimation* relates to those classes of problems that
    predict how bodies (human, animal, or robotic) move over time. In this chapter,
    we’ll consider a body walking and build several models that learn how to predict
    the next step from a series of video frames. To do this, we’ll first explain the
    problem in more detail and how to understand this as a relational problem before
    jumping in to see how graph-based learning approaches this problem. As with the
    rest of our book, further technical details are left to section 6.5 at the end
    of the chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们的基于动态图的 学习模型，我们将考虑姿态估计的问题。*姿态估计*与那些预测身体（人类、动物或机器人）随时间移动的类问题相关。在本章中，我们将考虑一个行走的人体，并构建几个模型来学习如何从一系列视频帧中预测下一步。为此，我们首先将更详细地解释这个问题，以及如何将其理解为一个关系问题，然后再深入探讨基于图的学习方法是如何处理这个问题的。与本书的其他部分一样，更详细的技术细节留到本章末尾的6.5节。
- en: We’ll use much of the material that we’ve already covered in the book. If you’ve
    skipped ahead to this chapter, make sure you have a good understanding of the
    concepts described in the “Building on what you’ve learned” sidebar.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用本书中已经覆盖的大部分材料。如果你已经跳到了这一章，请确保你对“建立在所学知识的基础上”侧边栏中描述的概念有很好的理解。
- en: Note  Code from this chapter can be found in notebook form at the GitHub repository
    ([https://mng.bz/4a8D](https://mng.bz/4a8D)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：本章的代码以笔记本形式可在GitHub仓库（[https://mng.bz/4a8D](https://mng.bz/4a8D)）中找到。
- en: Building on what you’ve learned
  id: totrans-12
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 建立在所学知识的基础上
- en: 'To introduce temporal updates into our GNN, we can build on some of the concepts
    that we’ve learned in previous chapters. As a quick refresher, we’ve summarized
    some of the main important features from each chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要将时序更新引入我们的GNN，我们可以基于之前章节中学到的某些概念。作为一个快速回顾，我们已经总结了每个章节的一些主要重要特性：
- en: '*Message passing*—In chapter 2, you learned that the main method used by GNNs
    to learn from relational data is by combining message passing with artificial
    neural networks. Each layer of a GNN can be understood as one step of message
    passing.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消息传递*——在第2章中，你了解到GNN（图神经网络）从关系数据中学习的主要方法是结合消息传递与人工神经网络。GNN的每一层都可以理解为消息传递的一个步骤。'
- en: '*Graph convolutional networks (GCNs)*—In chapter 3, you saw that message passing
    itself can be understood as the relational form of the convolution operator (as
    in convolutional neural networks [CNNs]), and this is the central idea behind
    GCNs. Messages can also be averaged across neighborhoods by only sampling a subset
    of nearest neighbors. This is used for GraphSAGE and can considerably reduce the
    total compute needed.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图卷积网络（GCNs）**—在第3章中，你看到消息传递本身可以理解为卷积算子的关系形式（如卷积神经网络 [CNNs] 中的那样），这是GCNs背后的核心思想。消息也可以通过仅采样最近邻的子集来在邻域内平均。这用于GraphSAGE，并且可以显著减少所需的总体计算量。'
- en: '*Attention*—In chapter 4, we showed how the aggregation function for message
    passing doesn’t need to be restricted to only summing, averaging, or max operations
    (though the operation must be permutation invariant). Attention allows for a weighting
    to be learned during training to give more flexible message-passing aggregation
    functions. Using a graph attention network (GAT) is the basic form of adding attention
    to message passing.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意**—在第4章中，我们展示了消息传递的聚合函数不需要仅限于求和、平均或最大操作（尽管操作必须是排列不变的）。注意力机制允许在训练过程中学习权重，从而为消息传递聚合函数提供更大的灵活性。使用图注意力网络（GAT）是向消息传递添加注意力的基本形式。'
- en: '*Generative models*—While discriminative models seek to learn separations between
    data classes, generative models attempt to learn the underlying data-generating
    process. The autoencoder is one of the most popular frameworks for designing generative
    models, where data is passed through a neural network bottleneck to create a low-dimensional
    representation of the data, also called the latent space. These are commonly implemented
    as graph autoencoders (GAEs) or variational graph autoencoders (VGAEs) for graphs,
    as we discussed in chapter 5\.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成模型**—虽然判别模型试图学习数据类之间的分离，但生成模型试图学习底层的数据生成过程。自动编码器是设计生成模型中最受欢迎的框架之一，其中数据通过神经网络瓶颈传递以创建数据的低维表示，也称为潜在空间。这些通常作为图自动编码器（GAEs）或变分图自动编码器（VGAEs）在图中实现，正如我们在第5章中讨论的那样。'
- en: '6.1 Temporal models: Relations through time'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 时间模型：通过时间的关系
- en: Almost every data problem will, in some way, also be a dynamic problem. In many
    cases, we can ignore changes in time and build models that are suitable for snapshots
    of the data that we’ve collected. For example, image segmentation methods rarely
    consider video footage to train models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每个数据问题在某种程度上也会是一个动态问题。在许多情况下，我们可以忽略时间的变化，并构建适合我们所收集的数据快照的模型。例如，图像分割方法很少考虑视频素材来训练模型。
- en: In chapter 3, we used a GCN to predict suitable products to recommend to customers
    using data on a customer-purchaser network. We used a toy dataset that had been
    collected over a period of several years. However, in reality, we’ll often have
    constant streams of data and want to make up-to-date predictions that account
    for both customer and cultural habit changes. Similarly, when we applied a GAT
    to a fraud-detection problem, the data we used was a single snapshot of financial
    records that was collected over a period of several years. However, we didn’t
    account for how financial behaviors changed over time in our model. Again, we
    would likely want to use this information to predict where an individual’s spending
    behavior abruptly changes to help us detect fraudulent activity.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，我们使用GCN根据客户购买网络上的数据预测向客户推荐的产品。我们使用了一个跨越数年的玩具数据集。然而，在现实中，我们通常会拥有持续的数据流，并希望做出最新的预测，这些预测要考虑到客户和文化习惯的变化。同样，当我们将GAT应用于欺诈检测问题时，我们所使用的数据是在数年内收集的金融记录的单一快照。然而，我们没有在我们的模型中考虑到金融行为随时间的变化。再次，我们可能会希望使用这些信息来预测个人的消费行为突然改变的位置，以帮助我们检测欺诈活动。
- en: These are just a few of the many different dynamic problems that we’re faced
    with every day (see figure 6.1). GNNs are unique in that they can model both dynamic
    and relational changes. This is very important as many of the networks that operate
    around us are also moving in time. Take, for example, a social network. Our friendships
    change, mature, and sadly (or fortunately!) weaken over time. We might become
    stronger friends with work colleagues or friends of friends and see friends from
    our hometown less frequently. Making predictions for social networks need to account
    for this.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是我们每天面临的大量不同动态问题中的一小部分（见图6.1）。GNN的独特之处在于它们可以模拟动态和关系变化。这一点非常重要，因为围绕我们的许多网络也在随时间移动。以社交网络为例。我们的友谊会变化、成熟，并且不幸地（或者幸运地！）会减弱。我们可能会与工作同事或朋友的朋友变得更亲密，而与家乡的朋友见面的频率会降低。对社交网络进行预测需要考虑到这一点。
- en: As another example, we often make predictions about which way to go and when
    we might arrive based on our knowledge of the roads, traffic patterns, and how
    much of a rush we’re in. A dynamic GNN can also be used to help make use of this
    data, by treating the road network as a graph and making temporal predictions
    on how this network will change. Finally, we can consider predicting how two or
    more objects move together, that is, by estimating their future trajectories.
    While this might seem less useful than making friends or getting to work on time,
    predicting trajectories of interacting bodies, such as molecules, cells, objects,
    or even stars, is vital to many sciences as well as for robotic planning. Again,
    dynamic GNNs can help us both predict these trajectories and infer new equations
    or rules that explain them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，我们经常根据我们对道路、交通模式和我们的紧迫感的了解来预测我们将走向何方以及我们何时可能到达。动态GNN也可以用来帮助利用这些数据，通过将道路网络视为图，并对该网络如何变化进行时间预测。最后，我们可以考虑预测两个或更多物体如何一起移动，即通过估计它们的未来轨迹。虽然这可能不如交朋友或按时到达工作地点有用，但预测相互作用物体的轨迹，如分子、细胞、物体甚至恒星，对于许多科学以及机器人规划都是至关重要的。同样，动态GNN可以帮助我们预测这些轨迹并推断解释它们的新的方程或规则。
- en: '![figure](../Images/6-1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-1.png)'
- en: Figure 6.1 Examples of different dynamic problems
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.1 不同动态问题的示例
- en: 'These examples are just the tip of the iceberg for applications where we need
    to model temporal changes. In fact, we’re sure that you can think of many others.
    Given the importance of knowing how to combine relational learning with temporal
    learning, we’ll cover three different methods for building dynamic models, two
    of which use GNNs: a recurrent neural network (RNN) model, a GAT model, and a
    neural relational inference (NRI) model. We’ll build machine learning models that
    “learn to walk” by estimating how a human pose changes over time. These models
    are often deployed in, for example, medical consultations, remote home security
    services, and filmmaking. The models are also a great toy problem for us to learn
    to walk before we can run. In that spirit, let’s first learn more about the data
    and build our first benchmark model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子只是我们需要对时间变化进行建模的应用的冰山一角。实际上，我们确信你们可以想到很多其他的例子。鉴于了解如何结合关系学习和时间学习的重要性，我们将介绍三种构建动态模型的不同方法，其中两种使用GNN：一个循环神经网络（RNN）模型，一个GAT模型，以及一个神经关系推理（NRI）模型。我们将通过估计人类姿态随时间的变化来构建“学习走路”的机器学习模型。这些模型通常被部署在例如医疗咨询、远程家庭安全服务和电影制作中。这些模型也是我们在能够奔跑之前学习走路的绝佳玩具问题。本着这种精神，让我们首先更多地了解数据并构建我们的第一个基准模型。
- en: '6.2 Problem definition: Pose estimation'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 问题定义：姿态估计
- en: 'In this chapter, we’ll solve a “dynamic relational” problem with one set of
    data: preprocessed segmentation of a body walking. This is a useful dataset to
    explore these techniques, as a moving body is a textbook example of an interacting
    system: our foot moves because our knee moves because a leg moves, and our arms
    and torso will all move too. This means that there is a temporal component to
    our problem.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一组数据解决一个“动态关系”问题：一个行走身体的预处理分割。这是一个探索这些技术的有用数据集，因为移动的身体是相互作用系统的教科书式例子：我们的脚移动是因为膝盖移动，因为腿移动，而我们的手臂和躯干也会移动。这意味着我们的问题有一个时间成分。
- en: In a nutshell, our pose estimation problem is about path prediction. More precisely,
    we want to know where, for example, a foot will move having followed the rest
    of the body for some number of previous timesteps. This type of object tracking
    is something that we do every day, for example, when we play sports, catch something
    that’s falling, or watch a television show. We learn this skill as a child and
    often take it for granted. However, as you’ll see, teaching a machine to perform
    this object tracking was a significant challenge up until the emergence of spatiotemporal
    GNNs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们的姿态估计问题关乎路径预测。更精确地说，我们想要知道，例如，在跟随身体其他部分经过一定数量的前一时间步之后，一只脚会移动到哪个位置。这种类型的对象跟踪是我们每天都会做的事情，例如，当我们运动、接住掉落的东西或观看电视节目时。我们在儿童时期就学会了这项技能，并且常常认为这是理所当然的。然而，正如你将看到的，直到时空图神经网络（spatiotemporal
    GNNs）的出现，教机器执行这种对象跟踪是一个重大的挑战。
- en: The skills that we’ll use for path prediction are important for many other tasks.
    Predicting events in the future is useful when we want to predict the next purchase
    of a customer or understand how weather patterns will change based on geospatial
    data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用于路径预测的技能对于许多其他任务都很重要。当我们想要预测客户的下一次购买或根据地理空间数据了解天气模式如何变化时，预测未来的事件是有用的。
- en: 'We’ll be using the Carnegie Mellon University (CMU) Motion Capture Database
    ([http://mocap.cs.cmu.edu/](http://mocap.cs.cmu.edu/)), which contains many examples
    of different dynamic poses, including walking, running, jumping, and performing
    sports moves, as well as multiple people interacting [1]. Throughout this chapter,
    we’ll use the same dataset of subject #35 walking. At each timestep, the subject
    has 41 sensors that each follow a single joint, ranging from the toes up to the
    neck. An example of the data from this database is shown in figure 6.2\. These
    sensors track the movement of part of the body across snapshots of their motion.
    In this chapter, we won’t follow the entire motion and consider only a small subset
    of the motion. We’ll use the first 49 frames for our training and validation datasets
    and 99 frames for our test set. In total, there are 31 different examples of this
    subject walking. We’ll discuss more about the structure of our data in the next
    section.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用卡内基梅隆大学（CMU）动作捕捉数据库（[http://mocap.cs.cmu.edu/](http://mocap.cs.cmu.edu/)），其中包含许多不同动态姿态的示例，包括行走、跑步、跳跃以及进行体育动作，以及多人互动[1]。在本章中，我们将使用受试者#35行走的相同数据集。在每一个时间步，受试者有41个传感器，每个传感器跟踪一个单一的关节，从脚趾到颈部。这个数据库中的数据示例如图6.2所示。这些传感器跟踪身体部分在运动快照中的移动。在本章中，我们不会跟踪整个运动，而只考虑运动的小部分。我们将使用前49帧作为我们的训练和验证数据集，以及99帧作为我们的测试集。总共有31个不同的人体受试者行走示例。我们将在下一节中讨论我们数据的结构。
- en: '![figure](../Images/6-2.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-2.png)'
- en: Figure 6.2 Snapshots in time (t = time in seconds) of a human subject walking.
    The dots represent sensors placed on key joints on the human’s body. These snapshots
    are across 30 seconds. To represent these figures as a graph, the sensor placements
    (joints) can be represented as nodes, and the body’s connections between the joints
    are the edges.
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.2展示了一个人体受试者行走的时间快照（t = 秒）。这些点代表放置在人体关键关节上的传感器。这些快照跨越了30秒。为了将这些图像表示为图，传感器的放置（关节）可以表示为节点，而身体关节之间的连接是边。
- en: 6.2.1 Setting up the problem
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 设置问题
- en: Our aim is to predict the dynamics for all the individual joints. Clearly, we
    can construct this as a graph because all the joints are connected through edges,
    as shown previously in figure 6.2\. Therefore, it makes sense to use GNNs to solve
    this problem. However, we’ll first compare another approach, which doesn’t account
    for the graph data, to benchmark our GNN models.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是预测所有单个关节的动态。显然，我们可以将其构建为一个图，因为所有关节都通过边连接，如图6.2所示。因此，使用图神经网络（GNNs）来解决这个问题是有意义的。然而，我们首先将比较另一种方法，这种方法没有考虑图数据，以作为我们GNN模型的基准。
- en: Downloading the data
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 下载数据
- en: We’ve included the steps to download and preprocess the data in our code repository.
    The data is contained within a zip file where each of the different trials is
    saved as an advanced systems format (.asf) file. These .asf files are basically
    just text files that contain the label for each sensor and their xyz coordinates
    at each timestep. In the following listing, we show a snippet of the text.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的代码仓库中包含了下载和预处理数据的步骤。数据包含在一个zip文件中，其中每个不同的试验都保存为高级系统格式(.asf)文件。这些.asf文件基本上只是包含每个传感器在每个时间步的标签及其xyz坐标的文本文件。在下面的列表中，我们展示了一段文本的片段。
- en: Listing 6.1 Example of the sensor data text files
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.1 传感器数据文本文件示例
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, the first number is the frame number, and `root` is specific to the sensors
    and can be ignored. `lowerback`, `upperback`, `thorax`, `lowerneck`, and `upperneck`
    denote the positions of the sensors. In total, there are 31 sensors mapping the
    movement of a man walking. To convert this sensor data into trajectories, we need
    to calculate the change in position for each sensor. This becomes quite a complicated
    task, as we need to account for both translational movements and angular rotations
    for the various sensors between each frame. Here, we’ll use the same data files
    as in the NRI paper [2]. We can use these to map out the trajectories of each
    individual sensor in x, y, and z, or look at how the sensors are moving in two
    dimensions to get intuition about how the entire body is moving. Examples of this
    are shown in figure 6.3, where we focus on the movement of a foot sensor in x,
    y, and z, as well as the overall movement of the body over time (with the sensor
    shown as solid black stars).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，第一个数字是帧号，`root`是特定于传感器的，可以忽略。`lowerback`、`upperback`、`thorax`、`lowerneck`和`upperneck`表示传感器的位置。总共有31个传感器映射一个行走的人的运动。为了将这个传感器数据转换为轨迹，我们需要计算每个传感器的位置变化。这变成了一项相当复杂的工作，因为我们需要考虑每个帧之间各种传感器的平移运动和角旋转。在这里，我们将使用与NRI论文[2]中相同的数据文件。我们可以使用这些文件在x、y和z方向上绘制每个单个传感器的轨迹，或者观察传感器在二维空间中的运动，以了解整个身体的运动。图6.3中的例子展示了这一点，我们关注脚传感器的x、y和z方向的运动，以及随着时间的推移身体的整体运动（传感器以实心黑色星号表示）。
- en: '![figure](../Images/6-3.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-3.png)'
- en: Figure 6.3 Preconstructed spatial trajectories of sensors
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.3 传感器的预构建空间轨迹
- en: Along with the spatial data, we can also calculate the velocity data. This data
    is provided as separate files for each of the movie frames. An example of the
    change in velocity data is shown in figure 6.4\. As you can see, the velocity
    data varies around a smaller range. Both spatial and velocity data will be used
    as the features in our machine learning problem. Here, we now have six features
    across 50 frames for each of our 31 sensors and across 33 different trials. We
    can understand this as a multivariate time series problem. We’re trying to predict
    the future evolution of a six-dimensional (three spatial and three velocity) object
    (each sensor). Our first approach will treat these as independent, looking to
    predict future positions and velocity based on past sensor data. We’ll then switch
    to treating this as a graph, where we can couple all sensors together.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了空间数据，我们还可以计算速度数据。这些数据以每个电影帧的单独文件提供。速度数据变化的一个例子如图6.4所示。如图所示，速度数据在一个较小的范围内变化。空间和速度数据都将作为我们机器学习问题中的特征。在这里，我们现在有31个传感器和33个不同试验的每个传感器的50帧，共有六个特征。我们可以将此视为一个多元时间序列问题。我们试图预测一个六维（三个空间和三个速度）对象（每个传感器）的未来演化。我们的第一个方法将它们视为独立的，试图根据过去的传感器数据预测未来的位置和速度。然后我们将转向将其视为一个图，其中我们可以将所有传感器耦合在一起。
- en: '![figure](../Images/6-4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-4.png)'
- en: Figure 6.4 Preconstructed velocity data of sensors
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.4 传感器的预构建速度数据
- en: Currently, this is a relational problem, but we’re only considering the node
    data and not the edge data. Where there is node data and no edge data, we have
    to be careful not to make too many assumptions. For example, if we chose to connect
    nodes based on their distance from one another, then we might end up with a very
    strange-looking skeleton, as shown in figure 6.5\. Luckily, we have the edge data
    as well, which has been built using the CMU dataset and is included in the data
    provided. This serves as a cautionary tale that GNNs are only as powerful as the
    graphs they’re trained on and that we must take care to ensure that the graph
    structure is correct. However, if edge data is entirely lacking, then we can attempt
    to infer the edge data from the node data itself. While we won’t be doing this
    here, note that the NRI model we’ll be using has this capability.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，这是一个关系问题，但我们只考虑节点数据，而不是边数据。当存在节点数据而没有边数据时，我们必须小心不要做出太多的假设。例如，如果我们选择根据节点之间的距离来连接节点，那么我们可能会得到一个非常奇怪的骨架，如图6.5所示。幸运的是，我们还有边数据，这些数据是使用CMU数据集构建的，并包含在提供的数据中。这是一个警示故事，说明GNN的强大程度取决于它们训练的图，我们必须小心确保图结构正确。然而，如果边数据完全缺失，那么我们可以尝试从节点数据本身推断边数据。虽然我们在这里不会这样做，但请注意，我们将使用的NRI模型具有这种能力。
- en: '![figure](../Images/6-5.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-5.png)'
- en: Figure 6.5 Sensor networks showing the error of wrongly inferring graph structures.
    The nodes are human skeletal connections. The left figure shows a network with
    edges inferred from node proximity (closest nodes connected to one another). This
    figure does not reflect a real human skeleton. The true set of edges is shown
    in the right figure.
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.5 显示错误推断图结构的传感器网络。节点是人体骨骼连接。左图显示了一个具有从节点邻近性推断的边（最近的节点相互连接）的网络。此图并不反映真实的人体骨骼。真正的边集在右图中显示。
- en: We now have all of our data loaded. In total, we have three datasets (training,
    validation, testing) that each contain 31 individual sensor positions. Each of
    these sensors contain six features (spatial coordinates) and are connected by
    an adjacency matrix that is constant in time. The sensor graph is undirected,
    and the edges are unweighted. The training and validation sets contain 49 frames,
    and the test sets contain 99 frames.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经加载了所有数据。总共有三个数据集（训练、验证、测试），每个数据集包含31个单个传感器位置。每个传感器包含六个特征（空间坐标），并通过一个随时间恒定的邻接矩阵连接。传感器图是无向的，边是无权的。训练和验证集包含49帧，测试集包含99帧。
- en: 6.2.2 Building models with memory
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 带有记忆的模型构建
- en: 'Now that our problem is defined and our data is loaded, let’s consider how
    we might approach the problem of predicting the joint dynamics. First, we need
    to think about what the underlying aim is. At its core, we’ll be involved in sequence
    prediction, just like autocomplete on a phone or search tool. These types of problems
    are often approached using networks, such as transformers, for which we use an
    attention mechanism as in chapter 4\. However, before attention-based networks,
    many deep learning practitioners instead approached sequence prediction tasks
    by introducing memory into their models [3]. This makes intuitive sense: if we
    want to predict the future, we need to remember the past.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了问题并加载了数据，让我们考虑如何处理预测关节动态的问题。首先，我们需要思考基本目标是什么。本质上，我们将参与序列预测，就像手机上的自动完成或搜索工具一样。这类问题通常使用网络（如transformers）来解决，我们在第4章中使用了注意力机制。然而，在基于注意力的网络之前，许多深度学习从业者通过在模型中引入记忆来处理序列预测任务[3]。这从直觉上是有意义的：如果我们想要预测未来，我们需要记住过去。
- en: Let’s build a simple model that predicts the next location for all the individual
    sensors using past events. Essentially, this means we’ll build a model that predicts
    the position of nodes without edge data. An example of what we’ll be attempting
    is shown in figure 6.6\. Here, we’ll start by preprocessing and preparing our
    data to be passed to a model that can predict how the data evolves over time.
    This allows us to predict the changes in the pose given a few input frames.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个简单的模型，该模型使用过去的事件预测所有单个传感器的下一个位置。本质上，这意味着我们将构建一个模型来预测没有边数据的节点位置。我们将尝试的示例如图6.6所示。在这里，我们将首先进行预处理和准备数据，以便传递给可以预测数据随时间演变的模型。这使我们能够根据几个输入帧预测姿态的变化。
- en: '![figure](../Images/6-6.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-6.png)'
- en: Figure 6.6 Predicting future positions using only sensor data
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.6 仅使用传感器数据预测未来位置
- en: To introduce memory to our neural networks, we’ll start by considering a recurrent
    neural network (RNN). Similar to convolutional and attention neural networks,
    RNNs are a broad class of architectures that are fundamental tools for researchers
    and practitioners alike. For more information about RNNs, see, for example *Machine
    Learning with TensorFlow* (Manning, 2020, [https://mng.bz/VVOW](https://mng.bz/VVOW)).
    RNNs can be considered as multiple individual networks that link together. These
    repeating subnetworks allow for past information to be “remembered” and the effect
    from past data to affect future predictions. After initializing, each subnetwork
    takes in input data as well as the output of the last subnetwork, and these are
    used to make new predictions. In other words, each subnetwork takes input and
    information from the recent past to build inferences about the data. However,
    a vanilla RNN will only ever remember the preceding step. They have *very* short-term
    memory. To improve the effect of the past on the future, we need something stronger.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将记忆引入我们的神经网络，我们首先考虑循环神经网络（RNN）。与卷积和注意力神经网络类似，RNN是一类广泛的架构，是研究人员和实践者共同的基本工具。有关RNN的更多信息，请参阅例如《用TensorFlow进行机器学习》（Manning，2020年，[https://mng.bz/VVOW](https://mng.bz/VVOW)）。RNN可以被视为多个相互连接的独立网络。这些重复的子网络允许“记住”过去的信息，以及过去数据对未来预测的影响。初始化后，每个子网络都会接收输入数据以及最后一个子网络的输出，并使用这些信息进行新的预测。换句话说，每个子网络都会接收来自最近过去的信息和输入，以构建关于数据的推理。然而，普通的RNN只会记住前一步。它们的记忆非常短暂。为了增强过去对未来影响的效果，我们需要更强大的东西。
- en: Long short-term memory (LSTM) networks are another extremely popular neural
    network architecture for modeling and predicting temporal or sequential information.
    These networks are special cases of RNN that similarly link multiple subnetworks
    together. The difference is that LSTMs introduce more complex dependencies in
    the subnetwork structure. LSTMs are particularly useful for sequential data as
    they resolve the problem of vanishing gradients that is observed for RNNs. Put
    simply, *vanishing gradients* refers to where the gradient that we use to train
    our neural network using gradient descent approaches zero. This is especially
    likely to happen when we train an RNN that has many layers. (We won’t go into
    the reasons for this here, but if you’re interested, read *Deep Learning with
    Python* (Manning, 2024, [https://mng.bz/xKag](https://mng.bz/xKag)) for more information.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）网络是另一种用于建模和预测时间或序列信息的极受欢迎的神经网络架构。这些网络是RNN的特殊情况，类似于将多个子网络链接在一起。不同之处在于，LSTMs在子网络结构中引入了更复杂的依赖关系。LSTMs对于序列数据特别有用，因为它们解决了RNN中观察到的梯度消失问题。简单来说，*梯度消失*指的是我们使用梯度下降法训练神经网络时，梯度变为零的情况。当我们训练具有许多层的RNN时，这种情况尤其可能发生。（我们在这里不会深入探讨其原因，但如果您对此感兴趣，请阅读《用Python进行深度学习》（Manning，2024年，[https://mng.bz/xKag](https://mng.bz/xKag)）以获取更多信息。）
- en: Gated recurrent unit networks (GRUs) also resolve the problem of vanishing gradients
    by allowing new information to be added to the memory store about the recent past.
    This is achieved through a gating structure, where gates within the model architecture
    help to control the flow of information. These gates also add a new design element
    to how we can build and adapt our neural networks. We won’t consider LSTM here
    as it’s outside the scope of the book, but again we recommend that you check out
    *Deep Learning with Python* (Manning, 2024, [https://mng.bz/xKag](https://mng.bz/xKag))
    for more information.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 门控循环单元网络（GRUs）通过允许将关于最近过去的新信息添加到记忆存储中，解决了梯度消失的问题。这是通过一个门控结构实现的，模型架构中的门控帮助控制信息的流动。这些门控还为我们构建和调整神经网络添加了一个新的设计元素。在这里我们不会考虑LSTM，因为它超出了本书的范围，但再次建议您查阅《用Python进行深度学习》（Manning，2024年，[https://mng.bz/xKag](https://mng.bz/xKag)）以获取更多信息。
- en: Constructing a recurrent neural network
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建循环神经网络
- en: Let’s now look at how to use an RNN to predict the trajectories of the body
    sensors over time, which will act as one of our baselines for future performance
    gains. We won’t go into the details of RNNs and GRU architectures but additional
    information is provided at the end of the chapter in section 6.5\.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何使用RNN来预测随时间变化的身体传感器的轨迹，这将成为我们未来性能提升的基准之一。我们不会深入探讨RNN和GRU架构的细节，但有关信息可在本章6.5节末尾找到。
- en: The idea for this model is that our RNN will predict the future positions for
    sensors without taking into account relational data. When we start to introduce
    our graph models, we’ll see how this can be improved.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型的想法是我们的RNN将预测传感器的未来位置，而不考虑关系数据。当我们开始介绍我们的图模型时，我们将看到如何改进这一点。
- en: We’ll use the same standard training loop for deep learning, as shown in figure
    6.7\. Once we define our model and define a training and test loop, we use these
    to train and then test the model. As always, we’ll keep the training and testing
    data completely separate and include a validation set of data to make sure our
    model isn’t over-fitting during training.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与图6.7所示相同的深度学习标准训练循环。一旦我们定义了我们的模型并定义了训练和测试循环，我们就使用这些循环来训练和测试模型。一如既往，我们将训练数据和测试数据完全分开，并包括一个验证数据集，以确保我们的模型在训练过程中不会过拟合。
- en: '![figure](../Images/6-7.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-7.png)'
- en: Figure 6.7 Standard process for training a deep learning model that we’ll follow
    throughout this chapter
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.7本章我们将遵循的深度学习模型的标准训练流程
- en: The training loop used here is fairly standard, so we’ll describe it first.
    In the training loop definition shown in listing 6.2, we follow the same convention
    as in previous chapters, looping through model prediction and loss updates over
    a fixed number of epochs. Here, our loss will be contained in our criterion function,
    which we define as a simple mean standard error (MSE) loss. We will use a learning
    rate scheduler, which will reduce the learning rate parameter after our validation
    loss starts to plateau. We initialize the best loss as infinity and lower the
    learning rate after the validation loss is less than our best loss for `N` steps.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的训练循环相当标准，所以我们首先描述它。在列表6.2中显示的训练循环定义中，我们遵循与之前章节相同的惯例，通过固定数量的时代在模型预测和损失更新之间循环。在这里，我们的损失将包含在我们的标准函数中，我们将其定义为简单的均方误差（MSE）损失。我们将使用学习率调度器，该调度器将在验证损失开始平台期后降低学习率参数。我们将最佳损失初始化为无穷大，并在验证损失小于最佳损失`N`步之后降低学习率。
- en: Listing 6.2 Training loop
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.2 训练循环
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 Initializes loss and accuracy variables'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 初始化损失和准确率变量'
- en: '#2 Begins the training loop'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 开始训练循环'
- en: '#3 Zeros the parameter gradients'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将参数梯度置零'
- en: '#4 Forward + backward + optimize'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 前向 + 反向 + 优化'
- en: '#5 Updates training loss, multiplying by the number of samples in the current
    mini-batch'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 更新训练损失，乘以当前小批次的样本数'
- en: '#6 Begins the validation loop'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 开始验证循环'
- en: '#7 Checks for early stopping'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 检查早期停止'
- en: '#8 Steps the scheduler'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 步进调度器'
- en: '#9 Calculates and stores losses'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '#9 计算并存储损失'
- en: Both layers are trained (using our training loop in listing 6.3) for a specific
    task. For both the RNN and the GRU, the format for the data will be the individual
    trials or videos, the frame timestamp, the number of sensors, and the features
    of the sensors. By providing the data broken up into individual snapshots of time,
    the model is able to use the temporal aspects to learn from. Here, we use the
    RNN to predict the future position for each individual sensor, given the 40 previous
    frames. For all of our calculations, we’ll normalize the data based on the node
    features (position and velocity) using min-max scaling.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 两个层都针对特定任务进行训练（使用列表6.3中的训练循环）。对于RNN和GRU，数据的格式将是单独的试验或视频，帧时间戳，传感器数量和传感器的特征。通过提供分割成单独时间快照的数据，模型能够利用时间方面进行学习。在这里，我们使用RNN根据40个之前的帧预测每个单独传感器的未来位置。对于所有的计算，我们将基于节点特征（位置和速度）使用最小-最大缩放来归一化数据。
- en: After we finish our training loop, we test our network. As always, we don’t
    want to update the parameters of our network, so we make sure that there is no
    backpropagated gradient (by selecting `torch.no_grad()`). Note that we choose
    a sequence length of 40 so that our testing loop is able to see the first 40 frames
    and then attempt to infer the final 10 frames.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成训练循环后，我们测试我们的网络。一如既往，我们不希望更新网络的参数，因此我们确保没有反向传播的梯度（通过选择`torch.no_grad()`）。请注意，我们选择40个序列长度，以便我们的测试循环能够看到前40帧，然后尝试推断最后的10帧。
- en: Listing 6.3 Testing loop
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.3 测试循环
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Sets the model to evaluation mode'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将模型设置为评估模式'
- en: '#2 Updates inputs for the next prediction'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 更新下一次预测的输入'
- en: '#3 Computes the loss for this sequence'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算此序列的损失'
- en: '#4 Converts predictions to a NumPy array for easier manipulation'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将预测转换为NumPy数组以便更容易操作'
- en: '#5 Computes the average test loss'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 计算平均测试损失'
- en: Once our models are defined, we can next use the training loop given in listing
    6.3 to train our model. At this point, you might be wondering how we’ll amend
    the training loop to correctly account for the temporal element when backpropagating.
    The good news is that this is handled automatically by PyTorch. We find that the
    RNN model is able to predict the future positions with 70% accuracy for the validation
    data and 60% accuracy for the test data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的模型被定义，我们就可以使用列表6.3中给出的训练循环来训练我们的模型。在这个阶段，你可能想知道我们如何修改训练循环以正确地考虑反向传播时的时序元素。好消息是，PyTorch会自动处理这个问题。我们发现，RNN模型能够以70%的准确率预测验证数据的未来位置，以及60%的准确率预测测试数据的未来位置。
- en: We also tried a GRU model to predict the future steps taken and found this model
    is able to get an accuracy of 75% using the validation data. This is quite low
    but not as low as it might be given the simplicity of the model and the little
    amount of information that we’ve passed it. However, when we test the model performance
    on our test data, we can see that performance falls to 65%. A few example outputs
    from our model are shown in figure 6.8\. Clearly, the model quickly degrades,
    and the estimated pose position starts to vary widely. For better accuracy, we’ll
    need to use some of the relational inductive biases in the pose data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还尝试了一个GRU模型来预测未来的步骤，并发现这个模型使用验证数据能够达到75%的准确率。这相当低，但考虑到模型的简单性和我们传递给它的信息量很小，这并不低。然而，当我们测试模型在测试数据上的性能时，我们可以看到性能下降到65%。我们的模型的一些示例输出显示在图6.8中。显然，模型很快就会退化，估计的姿态位置开始大幅变化。为了获得更高的准确率，我们需要在姿态数据中使用一些关系归纳偏见。
- en: '![figure](../Images/6-8.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-8.png)'
- en: Figure 6.8 Predicting future movements using an RNN. Here, figures on the left
    represent the true data, and those on the right represent the predicted data.
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.8 使用RNN预测未来运动。在这里，左边的图表示真实数据，右边的图表示预测数据。
- en: 6.3 Dynamic graph neural networks
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 动态图神经网络
- en: To predict the future evolution of the graph, we need to restructure our data
    to account for temporal data. Specifically, dynamic GNNs connect different sequential
    snapshots of the graph’s evolution and learn to predict future evolutions [4–6].
    One method for doing so is to combine them into a single graph. This temporal
    graph now contains both per-timestep data and the temporal connections encoded
    as nodes with temporal edges. We’ll first approach the task of pose estimation
    by taking a naive approach to modeling graph evolution. We’ll look at how we can
    combine our temporal data into one large graph and then predict the future evolution
    by masking the nodes of interest. We’ll use the same GAT network that you saw
    in chapter 3\. Then, in section 6.4, we’ll show another method for solving the
    pose estimation problem by instead encoding each snapshot of the graph and predicting
    the evolution using a combination of variational autoencoders (VAEs) and RNNs,
    which is the NRI method [2].
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测图的未来演化，我们需要重新结构我们的数据以考虑时序数据。具体来说，动态GNN连接图演化的不同连续快照，并学习预测未来的演化[4–6]。实现这一目标的一种方法是将它们组合成一个单一的图。这个时序图现在包含了每一步的数据以及作为具有时序边的节点编码的时序连接。我们将首先通过采用对图演化建模的朴素方法来处理姿态估计的任务。我们将探讨如何将我们的时序数据组合成一个大型图，然后通过屏蔽感兴趣的节点来预测未来的演化。我们将使用与第3章中看到相同的GAT网络。然后，在第6.4节中，我们将展示另一种通过编码每个图的快照并使用变分自编码器（VAEs）和RNNs的组合来预测演化的方法，即NRI方法[2]。
- en: 6.3.1 Graph attention network for dynamic graphs
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 动态图上的图注意力网络
- en: We’ll look at how to convert our pose estimation problem into a graph-based
    problem. To do this, we need to construct an adjacency matrix that accounts for
    temporal information. First, we need to load our data in as a PyTorch Geometric
    (PyG) data object. We’ll use the same location and velocity data that we used
    to train our RNN. The difference here is that we’ll construct a single graph that
    contains all the data. The code snippet in listing 6.4 shows how we initialize
    our dataset. We pass the paths for where the location and velocity data are as
    well as where the edge data is located. We also pass whether we need to transform
    our data and the mask and window size that we’ll predict over.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨如何将我们的姿态估计问题转换为基于图的问题。为此，我们需要构建一个考虑时间信息的邻接矩阵。首先，我们需要将我们的数据作为PyTorch Geometric（PyG）数据对象加载进来。我们将使用与训练我们的RNN相同的地点和速度数据。这里的区别在于，我们将构建一个包含所有数据的单个图。列表6.4中的代码片段展示了我们如何初始化我们的数据集。我们传递位置和速度数据以及边缘数据所在的路径。我们还传递是否需要转换我们的数据以及我们将预测的掩码和窗口大小。
- en: Listing 6.4 Loading the data as a graph
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.4 以图形式加载数据
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 Loads the data from .npy files'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从.npy文件加载数据'
- en: '#2 Determines the mask size'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 确定掩码大小'
- en: '#3 Determines the window size'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 确定窗口大小'
- en: For all our dataset objects, we need a `get` method inside the class to describe
    how to retrieve this data, which is shown in listing 6.5\. This method combines
    the location and velocity data into node features. We also provide an option to
    transform the data using a `normalize_array` function.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们所有的数据集对象，我们需要在类中实现一个`get`方法来描述如何检索这些数据，这将在列表6.5中展示。此方法将位置和速度数据组合成节点特征。我们还提供了一个选项，可以使用`normalize_array`函数转换数据。
- en: Listing 6.5 Set up node features using location and velocity data
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.5 使用位置和速度数据设置节点特征
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Concatenates location and velocity data for each node'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将每个节点的位置和速度数据连接起来'
- en: '#2 Determines the mask size'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 确定掩码大小'
- en: '#3 Applies normalization if transform is True'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 如果转换为True，则应用归一化'
- en: '#4 Repeats the edges for the total number of timesteps (past + future)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 对总时间步数（过去+未来）重复边缘'
- en: '#5 Applies the shift to the edge indices'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将平移应用于边缘索引'
- en: '#6 Flattens the edge indices into two dimensions'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 将边缘索引展平到二维'
- en: '#7 Converts everything to PyTorch tensors'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 将所有内容转换为PyTorch张量'
- en: '#8 Calculates the indices of the masked nodes'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 计算掩码节点的索引'
- en: We next want to combine all nodes across the different timesteps into one large
    graph containing all individual frames. This gives an adjacency matrix that covers
    all different timesteps. (For further details on the idea of temporal adjacency
    matrices, see section 6.5 at the end of this chapter.) To do this for our pose
    estimation data, we first construct the adjacency matrix for each timestep, as
    shown in listing 6.6 and included in listing 6.5\.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们希望将不同时间步长的所有节点组合成一个包含所有单独帧的大型图。这给出一个覆盖所有不同时间步长的邻接矩阵。（关于时间邻接矩阵概念的进一步细节，请参阅本章末尾的6.5节。）为了对我们的姿态估计数据进行此操作，我们首先构建每个时间步长的邻接矩阵，如列表6.6所示，并包含在列表6.5中。
- en: As shown in figure 6.9, the process begins by representing the graph data across
    multiple timesteps, where each timestep is treated as a distinct layer (Step 1).
    All nodes have node feature data (not shown in the figure). For our application,
    the node feature data consists of location and velocity information.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如图6.9所示，过程从表示跨越多个时间步长的图数据开始，其中每个时间步长被视为一个独立的层（步骤1）。所有节点都有节点特征数据（图中未显示）。对于我们的应用，节点特征数据由位置和速度信息组成。
- en: Nodes within a timestep are connected to each other using intra-timestep edges,
    that is, connections between nodes on the same timestep layer (Step 2). These
    edges ensure that each graph at a specific timestep is internally consistent.
    The nodes are not yet connected across timesteps.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一时间步长内的节点通过时间步长内边缘相互连接，即同一时间步长层（步骤2）之间的节点连接。这些边缘确保特定时间步长的每个图在内部是一致的。节点尚未在不同时间步长之间连接。
- en: To incorporate temporal relationships, inter-timestep edges (i.e., connections
    between nodes on different timestep layers) are added to connect corresponding
    nodes across adjacent timesteps (Step 3). These edges allow information to flow
    between nodes in different timesteps, enabling temporal modeling of the graph
    data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纳入时间关系，添加了时间步长间边缘（即不同时间步长层之间的节点连接），以连接相邻时间步长中的对应节点（步骤3）。这些边缘允许不同时间步长的节点之间传递信息，从而实现图数据的时序建模。
- en: In preparation for predicting future values, the nodes in the last timestep
    are masked to represent unknown data (Step 4). These masked nodes are treated
    as the target of the prediction task. Their values are unknown, but they can be
    inferred by leveraging the features and relationships of the unmasked nodes in
    earlier timesteps.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测未来的值，最后时间步的节点被掩码以表示未知数据（步骤 4）。这些掩码节点被视为预测任务的靶标。它们的值是未知的，但可以通过利用早期时间步中未掩码节点的特征和关系来推断。
- en: The inference process (Step 5) involves using the known features of unmasked
    nodes from previous timesteps (t = 0 and t = 1) to predict the features of the
    masked nodes in t = 2\. Dotted arrows illustrate how information flows from unmasked
    nodes to masked nodes, showing the dependency of the predictions on earlier graph
    data. This transforms the task into a node prediction problem, where the goal
    is to estimate the features of the masked nodes based on the relationships and
    features of the unmasked nodes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 推理过程（步骤 5）涉及使用来自先前时间步（t = 0 和 t = 1）的未掩码节点的已知特征来预测 t = 2 中掩码节点的特征。虚线箭头说明了信息如何从未掩码节点流向掩码节点，显示了预测对早期图数据的依赖性。这把任务转换成了一个节点预测问题，其目标是根据未掩码节点的关联和特征来估计掩码节点的特征。
- en: '![figure](../Images/6-9.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-9.png)'
- en: Figure 6.9 Illustration of the spatiotemporal graph construction and inference
    process. Step 1 shows the sequence of graphs across timesteps with nodes representing
    entities at each timestep. Step 2 highlights intra-timestep edges (solid lines)
    connecting nodes within the same graph layer. Step 3 introduces inter-timestep
    edges (dotted lines) that encode temporal dependencies by linking corresponding
    nodes across adjacent timesteps. In Step 4, nodes at the final timestep are masked
    (gray) to represent unknown values for prediction. Step 5 demonstrates the inference
    process (dashed arrows), where information from unmasked nodes in earlier timesteps
    is used to estimate the features of masked nodes. The legend clarifies the types
    of nodes and edges used in the graph representation.
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.9 时空图构建和推理过程的示意图。步骤 1 显示了时间步之间的图序列，每个时间步的节点代表实体。步骤 2 突出了同一图层内节点之间的时间步内边（实线）。步骤
    3 引入了时间步间边（虚线），通过连接相邻时间步中相应的节点来编码时间依赖性。在步骤 4 中，最终时间步的节点被掩码（灰色）以表示预测的未知值。步骤 5 展示了推理过程（虚线箭头），其中使用早期时间步中未掩码节点的信息来估计掩码节点的特征。图例说明了在图表示中使用的节点和边的类型。
- en: Listing 6.6 Constructing the adjacency matrix
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.6 构建邻接矩阵
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Repeats the edges for the total number of timesteps (past + future)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 重复边以匹配总时间步数（过去 + 未来）'
- en: '#2 Creates a shift for each timestep'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 为每个时间步创建一个偏移'
- en: '#3 Applies the shift to the edge indices'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将偏移应用于边索引'
- en: '#4 Flattens the edge indices into two dimensions'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将边索引展平到二维'
- en: Now that we have the adjacency matrix, the next step is to build a model that
    can predict future timesteps. Here, we’ll use a GAT model, introduced in chapter
    4 [7]. We choose this GNN because it can be more expressive than other GNNs, and
    we want something that is able to account for the different temporal and spatial
    information. The model architecture is provided in listing 6.7\.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了邻接矩阵，下一步是构建一个可以预测未来时间步的模型。在这里，我们将使用第 4 章中介绍的 GAT 模型 [7]。我们选择这个 GNN 是因为它可以比其他
    GNN 更具表现力，我们想要一个能够考虑不同时间和空间信息的模型。模型架构在列表 6.7 中提供。
- en: Listing 6.7 Defining the GAT model
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.7 定义 GAT 模型
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 First GAT layer'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 第一个 GAT 层'
- en: '#2 BatchNorm layer for the first GAT layer'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 第一个 GAT 层的 BatchNorm 层'
- en: '#3 Intermediate GAT layers'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 中间 GAT 层'
- en: '#4 BatchNorm layers for intermediate GAT layers'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 中间 GAT 层的 BatchNorm 层'
- en: '#5 Last GAT layer'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 最后一个 GAT 层'
- en: '#6 Don’t apply batch normalization and dropout to the output of the last GAT
    layer.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 不要将批归一化和dropout应用于最后一个 GAT 层的输出。'
- en: '#7 Only outputs the last frame'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 仅输出最后一帧'
- en: This model follows the basic structure outlined in chapter 4\. We define the
    number of layers and heads for our model as well as the relevant input size, which
    depends on the number of features that we’re predicting. Each of our GAT layers
    has a hidden size and we include dropout and batch normalization to improve performance.
    We then loop through the number of layers in our model, ensuring that the dimensions
    are correct to match our target output. We also define our forward function, which
    predicts the node features for the masked nodes. By unwrapping each timestep into
    a larger graph, we start to introduce temporal effects as additional network structures
    that our model can learn.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型遵循第4章中概述的基本结构。我们定义了模型的层数和头数，以及相关的输入大小，这取决于我们预测的特征数量。我们每个GAT层都有一个隐藏大小，并包括dropout和批量归一化来提高性能。然后我们遍历模型中的层数，确保维度正确以匹配我们的目标输出。我们还定义了我们的前向函数，该函数预测掩码节点的节点特征。通过将每个时间步展开到更大的图中，我们开始引入时序效应，作为模型可以学习的额外网络结构。
- en: With both model and dataset defined, let’s start training our model and see
    how it performs. Recall that the RNN and GRU achieved 60% and 65% in test accuracy,
    respectively. In listing 6.8, we show the training loop for our GAT model. This
    training loop follows the same structure as that used in previous chapters. We
    use the MSE as our loss functions and set the learning rate to 0.0005\. We calculate
    the node features of the masked nodes using our GAT and then compare these to
    the true data, which is stored in `data`. We first train our model and then compare
    the model predictions using our validation set. Note that because of the multiple
    graph sequences we’re now predicting, this training loop takes more time than
    previous models. On a V100 GPU through Google Colab, this took under an hour to
    train.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了模型和数据集之后，让我们开始训练我们的模型并看看它的表现如何。回想一下，RNN和GRU在测试准确率上分别达到了60%和65%。在列表6.8中，我们展示了GAT模型的训练循环。这个训练循环遵循了之前章节中使用的相同结构。我们使用均方误差（MSE）作为损失函数，并将学习率设置为0.0005。我们使用GAT计算掩码节点的节点特征，并将其与存储在`data`中的真实数据进行比较。我们首先训练我们的模型，然后使用验证集比较模型预测。请注意，由于我们现在预测了多个图序列，这个训练循环比之前的模型花费了更多的时间。在Google
    Colab的V100 GPU上，这需要不到一个小时来训练。
- en: Listing 6.8 GAT training loop
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.8 GAT训练循环
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Initializes loss and optimizer with learning rate'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 初始化损失和优化器，设置学习率'
- en: '#2 Generates the model’s predictions for the input'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 生成模型对输入的预测'
- en: '#3 Computes the loss between the outputs and the targets'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算输出和目标之间的损失'
- en: '#4 Validation loop'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 验证循环'
- en: '#5 Generates the model’s predictions for the input'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 生成模型对输入的预测'
- en: '#6 Computes the loss between the outputs and the targets'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 计算输出和目标之间的损失'
- en: Finally, we test our trained model using the test set and code shown in the
    following listing.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用以下列表中所示的训练集和代码测试我们的训练好的模型。
- en: Listing 6.9 GAT test loop
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.9 GAT测试循环
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Generates the model’s predictions for the input'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 生成模型对输入的预测'
- en: '#2 Computes the loss between the outputs and the targets'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 计算输出和目标之间的损失'
- en: We find that this naive approach is unable to predict the poses. Our overall
    test accuracy is 55%, and the predicted graphs look very different from our expectation
    of the pose’s appearance. This is due to the large amount of data that we’re now
    holding in a single graph. We’re compressing both node features and temporal data
    into one graph, and we’re not emphasizing the temporal property when defining
    our model. There are ways to improve this, such as by using temporal encodings
    to extract the edge data that is unused, as in the temporal GAT (TGAT) model.
    TGAT treats edges as dynamic rather than static, such that each edge also encodes
    a timestamp.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现这种朴素的方法无法预测姿态。我们的整体测试准确率为55%，预测的图表与我们对姿态外观的预期大相径庭。这是由于我们在单个图中存储了大量的数据。我们将节点特征和时序数据压缩到一个图中，并且在定义我们的模型时没有强调时序属性。有方法可以改进这一点，例如使用时序编码来提取未使用的边数据，就像在时序GAT（TGAT）模型中那样。TGAT将边视为动态的而不是静态的，这样每条边也编码了一个时间戳。
- en: However, without this time data, our model has become too expressive such that
    the overall structure of the pose has diverged significantly from the original
    structure, as shown with the predicted poses in figure 6.10\. Next, we’ll investigate
    how to combine the best of both approaches into a GNN that uses RNN-based predictions
    by learning on each graph snapshot.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，没有这些时间数据，我们的模型变得过于表达，以至于姿态的整体结构已经与原始结构显著偏离，如图6.10中的预测姿态所示。接下来，我们将研究如何将两种方法中的优点结合起来，形成一个使用基于RNN预测的GNN，通过在每个图快照上进行学习来实现。
- en: '![figure](../Images/6-10.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-10.png)'
- en: Figure 6.10 Output from the GAT model
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.10 GAT模型的输出
- en: 6.4 Neural relational inference
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 神经关系推理
- en: Our RNN focused entirely on the temporal data but ignored the underlying relational
    data. This resulted in a model that was able to move in the right direction on
    average but didn’t really alter the individual sensor positions very well. On
    the other hand, our GAT model ignored temporal data by encoding all individual
    temporal graphs into a single graph and attempting node prediction on the unknown
    future graphs. The model caused the sensors to move dramatically, and our resulting
    graphs looked very unlike how we would expect a human to move.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究中的RNN模型完全关注于时间数据，但忽略了底层的关系数据。这导致了一个模型，它在平均方向上能够移动，但并没有很好地改变各个传感器的位置。另一方面，我们的GAT模型通过将所有个体时间图编码成一个单一图，并尝试在未知未来图上进行节点预测，从而忽略了时间数据。这个模型导致传感器大幅移动，我们得到的图与我们所期望的人类移动方式非常不同。
- en: Neural relational inference (NRI), as mentioned earlier, is a slightly different
    approach that uses a more complex encoding framework to combine the best of both
    RNN and GNNs [2]. The architecture for this model is shown in figure 6.11\. Specifically,
    NRI uses an autoencoder structure to embed the information at each timestep. Therefore,
    the embedding architecture is applied to the entire graph in a similar way to
    GAE, which we discussed in chapter 5\. This encoded graph data is then updated
    using an RNN. One key point is that NRI evolves the latent representation of the
    embeddings.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，神经关系推理（NRI）是一种稍微不同的方法，它使用更复杂的编码框架来结合RNN和GNNs的最佳之处[2]。该模型的架构如图6.11所示。具体来说，NRI使用自动编码器结构在每个时间步嵌入信息。因此，嵌入架构以类似于我们在第5章中讨论的GAE的方式应用于整个图。然后使用RNN更新编码的图数据。一个关键点是NRI会演化嵌入的潜在表示。
- en: '![figure](../Images/6-11.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-11.png)'
- en: 'Figure 6.11 Schematic for NRI (Source: Kipf et al. [2]). The model consists
    of an encoder and decoder layer and several message-passing steps. However, here
    the messages are passed in the encoder from node to edge, back from edge to node,
    and then back from node to edge again. For the decoder, messages are passed from
    node to edge and then from edge to node. The final step takes the latent representation
    and is used to predict the next step in the temporal evolution of the body.'
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.11 NRI的示意图（来源：Kipf等人[2]）。该模型由一个编码器和解码器层以及几个消息传递步骤组成。然而，在这里，消息是从节点传递到边，然后从边传递回节点，再从节点传递回边。对于解码器，消息是从节点传递到边，然后从边传递回节点。最后一步使用潜在表示来预测身体时间演变的下一步。
- en: Let’s explore how this model applies to our problem of pose estimation so that
    we can best understand the different components in the model. We’ll use the same
    format of masking some data during training and then using the test day to identify
    these masked nodes. Recall that this is equivalent to inferring the future frames
    in our video. However, we now need to change both the model architecture and the
    loss. We need to change the model architecture to account for the new autoencoder
    structure, and we need to adjust the loss to include minimizing the reconstruction
    loss as well as the Kullbeck-Liebler divergence (KL divergence). For more information
    on the NRI model and relevant changes, see section 6.5 at the end of the chapter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索这个模型如何应用于我们的姿态估计问题，以便我们最好地理解模型中的不同组件。我们将在训练期间对一些数据进行掩码，然后在测试日识别这些掩码节点。回想一下，这相当于推断我们的视频中的未来帧。然而，我们现在需要改变模型架构和损失。我们需要改变模型架构以考虑新的自动编码器结构，并且需要调整损失以包括最小化重建损失以及Kullback-Leibler散度（KL散度）。有关NRI模型和相关更改的更多信息，请参阅本章末尾的6.5节。
- en: The code for the base class of an NRI model is provided in listing 6.10\. As
    is clear in the code, we need to define an encoder and decoder when calling this
    class. Along with the encoder and decoder, there are some other model-specific
    details we need to be aware of. First, we need to define the number of variables.
    This relates to the number nodes in our graph rather than the number of features
    for each node. In our case, this will be 31, corresponding to each of the different
    sensors tracking a joint position. We also need to define the different types
    of edges between the nodes. This will be either 1 or 0, representing whether an
    edge exists.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: NRI模型基类的代码在列表6.10中提供。从代码中可以看出，当我们调用这个类时，需要定义一个编码器和一个解码器。除了编码器和解码器之外，还有一些其他特定于模型的具体细节我们需要注意。首先，我们需要定义变量的数量。这关系到我们图中的节点数量，而不是每个节点的特征数量。在我们的情况下，这将对应于31个，对应于跟踪关节位置的每个不同传感器。我们还需要定义节点之间的不同类型边。这将表示为1或0，表示是否存在边。
- en: We’ll assume that the way the nodes, or sensors, connect doesn’t change, that
    is, that the graph structure is static. Note that this model also allows for dynamic
    graphs where the connectivity changes over time, for example, when different players
    move around a basketball court. The total number of players is fixed but the number
    of players that can be passed to changes. In fact, this model was also used to
    predict how different players would pass using footage from the NBA.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将假设节点或传感器的连接方式不会改变，也就是说，图结构是静态的。请注意，此模型还允许动态图，其中连接性随时间变化，例如，当不同的球员在篮球场周围移动时。球员的总数是固定的，但可以传球的球员数量会变化。实际上，此模型也被用来预测NBA球员如何传球。
- en: Finally, this model needs some hyperparameters to be set, including the Gumbel
    temperature and the prior variance. *Gumbel temperature* controls the tradeoff
    between exploration and exploitation when performing discrete sampling. Here,
    we need to use a discrete probability distribution to predict the edge type. We
    discuss this in more detail in section 6.5\. *Prior variance* reflects how uncertain
    we are on the connectivity of the graph before we start. We need to set this because
    the model assumes we *don’t* know the connectivity. In fact, the model learns
    the connectivity that best helps it to improve its predictions. This is exactly
    what we’re setting when we call the `_initialize_log_prior` function. We’re telling
    the model what our best guess is for a likely connectivity pattern. For example,
    if we were to apply this model to a sports team, we might use a Gaussian distribution
    with a high mean for edges between players that frequently pass to each other
    or even to players on the same team.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个模型需要设置一些超参数，包括Gumbel温度和先验方差。*Gumbel温度*控制在进行离散采样时探索和利用之间的权衡。在这里，我们需要使用一个离散概率分布来预测边类型。我们将在第6.5节中更详细地讨论这个问题。*先验方差*反映了我们在开始之前对图连接性的不确定性。我们需要设置这个参数，因为模型假设我们*不知道*连接性。实际上，模型学习的是最能帮助它改进预测的连接性。这正是我们在调用`_initialize_log_prior`函数时所做的设置。我们告诉模型我们对可能连接模式的最佳猜测。例如，如果我们将此模型应用于一个运动队，我们可能会使用高均值的高斯分布来表示经常互相传球或甚至同一队球员之间的边。
- en: To demonstrate our model, we’re instead going to assume a uniform prior, which
    means that all edges are as likely as all others, or in everyday terms “we don’t
    know.” The prior variance sets our uncertainty bound for each of the edges. In
    the following listing, we set it to be 5 × 10^(–5) for numerical stability, but
    given that our prior is uniform, it shouldn’t have much effect.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们的模型，我们将假设一个均匀先验，这意味着所有边与其他边一样可能，或者用日常用语来说，“我们不知道。”先验方差为每个边设置我们的不确定性界限。在下面的列表中，我们将其设置为5
    × 10^(–5)，以保持数值稳定性，但鉴于我们的先验是均匀的，它不应有太大影响。
- en: Listing 6.10 Base class for the NRI model
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.10 NRI模型基类
- en: '[PRE9]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Number of variables in the mode'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 模式中的变量数量'
- en: '#2 Encoder neural network'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 编码器神经网络'
- en: '#3 Decoder neural network'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 解码器神经网络'
- en: '#4 Gumbel temperature for sampling categorical variables'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 用于采样分类变量的Gumbel温度'
- en: '#5 Prior variance'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 先验方差'
- en: '#6 Fills the prior tensor with uniform probabilities'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 用均匀概率填充先验张量'
- en: '#7 Takes the log and adds two singleton dimensions'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 对数并添加两个单例维度'
- en: As we discovered in chapter 5, VAEs have a two-component loss—the reconstruction
    error and the error in representing the distributional properties of the data—captured
    by the KL-divergence. The total loss function is given in listing 6.11.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第 5 章中发现的，VAEs 有两个组成部分的损失——重建误差和表示数据分布特性的误差——由 KL 散度捕捉。总损失函数在列表 6.11 中给出。
- en: Our encoder is passed edge embeddings and then outputs log probabilities of
    an edge type. The Gumbel-Softmax function converts these discrete logits into
    a differentiable continuous distribution. The decoder takes this distribution
    and the edge representations and then converts these back into node data. At this
    point, we’re ready to use the standard loss machinery for VAEs, so we calculate
    the reconstruction loss as MSE and the KL divergence. For further insight into
    VAE losses and how the KL divergence is calculated, revisit chapter 5\.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的编码器接收边缘嵌入，然后输出边缘类型的对数概率。Gumbel-Softmax 函数将这些离散的 logits 转换为可微的连续分布。解码器接收这个分布和边缘表示，然后将这些转换回节点数据。在这个时候，我们就可以使用
    VAE 的标准损失机制了，所以我们计算重建损失为均方误差 (MSE) 和 KL 散度。对于 VAE 损失和 KL 散度如何计算的进一步了解，请回顾第 5 章。
- en: Listing 6.11 Loss for the NRI model
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.11 NRI 模型的损失
- en: '[PRE10]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Calculates Gumbel-Softmax using PyTorch''s functional API, imported as F
    in code'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用 PyTorch 的功能 API 计算 Gumbel-Softmax，在代码中导入为 F'
- en: '#2 Negative log likelihood (NLL) for Gaussian distribution'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 高斯分布的负对数似然 (NLL)'
- en: '#3 Adds a small constant to avoid taking the logarithm of zero'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 添加一个小的常数以避免取零的对数'
- en: '#4 KL divergence with a uniform categorical distribution'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 与均匀分类分布的 KL 散度'
- en: Finally, we need our model to be able to predict the future trajectories of
    the sensors. The code for predicting the future state of the graph is given in
    listing 6.12\. This is a relatively simple function once we have our encoder and
    decoder trained. We pass the encoder the current graph, and this returns a latent
    representation of whether an edge exists. We then convert these probabilities
    into a suitable distribution using Gumbel-Softmax and pass this to our decoder.
    The output from the decoder is our predictions. We can either get the predictions
    directly or get both predictions and whether an edge exists.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要我们的模型能够预测传感器的未来轨迹。预测图未来状态的代码在列表 6.12 中给出。一旦我们的编码器和解码器被训练，这是一个相对简单的函数。我们传递当前图给编码器，这返回一个表示是否存在边缘的潜在表示。然后我们使用
    Gumbel-Softmax 将这些概率转换为合适的分布，并将其传递给解码器。解码器的输出是我们的预测。我们可以直接获取预测，或者获取预测和是否存在边缘。
- en: Listing 6.12 Predicting the future
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.12 预测未来
- en: '[PRE11]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Runs the encoder to get logits for edge types'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 运行编码器以获取边缘类型的 logits'
- en: '#2 Applies Gumbel-Softmax to the edges'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将 Gumbel-Softmax 应用到边缘上'
- en: '#3 Runs the decoder to get the initial predictions and decoder state'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 运行解码器以获取初始预测和解码器状态'
- en: '#4 Uses the last input and decoder state to predict future steps'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用最后一个输入和解码器状态来预测未来步骤'
- en: '#5 Concatenates initial and future predictions if needed'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 如有必要，则连接初始和未来预测'
- en: '#6 Returns predictions and edges if specified'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 如果指定，则返回预测和边缘'
- en: This is the basis of the NRI model. We have an encoder that converts our initial
    node data into edge probabilities. The edge probabilities get passed to our decoder,
    and the decoder predicts future trajectories conditional on the most likely graph
    representation. Our encoder will be a simple multilayer perceptron (MLP) that
    works on graph data. Our decoder needs to be able to make future predictions,
    so we’ll use an RNN to do this, specifically the same GRU model we discussed in
    section 6.2.2\. Let’s next meet our encoder and decoder networks so we can apply
    our model to the data and see how it performs.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 NRI 模型的基础。我们有一个编码器，它将我们的初始节点数据转换为边缘概率。边缘概率传递给我们的解码器，解码器根据最可能的图表示预测条件下的未来轨迹。我们的编码器将是一个简单的多层感知器
    (MLP)，它处理图数据。我们的解码器需要能够做出未来预测，因此我们将使用 RNN 来实现这一点，具体是我们在第 6.2.2 节中讨论的相同的 GRU 模型。接下来，让我们认识一下编码器和解码器网络，这样我们就可以将模型应用于数据并查看其性能。
- en: 6.4.1 Encoding pose data
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.1 编码姿态数据
- en: Now that we know the different parts of our NRI model, let’s define our encoder.
    This encoder will act as the bottleneck to make our problem simpler. After encoding,
    we’ll be left with a low-dimensional representation of the edge data, so we don’t
    need to worry about temporal data at this stage. However, by providing our temporal
    data together, we’re transferring temporal structure into our latent space. Specifically,
    the encoder takes the temporal patterns and relationships from the input data
    and preserves this in the compressed, low-dimensional representations. This makes
    it easier to decode from, making our pose prediction problem easier to solve.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了我们NRI模型的不同部分，让我们定义我们的编码器。这个编码器将作为瓶颈来简化我们的问题。编码后，我们将剩下边数据的低维表示，所以我们在这个阶段不需要担心时间数据。然而，通过一起提供我们的时间数据，我们将时间结构转移到我们的潜在空间中。具体来说，编码器从输入数据中提取时间模式和关系，并在压缩的低维表示中保留这些信息。这使得解码更容易，使我们的姿态预测问题更容易解决。
- en: There are several subsets to implementing the encoder. First, we pass the input
    data, which comprises the different sensors at different frames, across different
    experiments. The encoder then takes this data, *x*, and performs a message-passing
    step to transform edge data into node data and then back into edge data. The edge
    data is then converted to node data again before being encoded in the latent space.
    This is equivalent to three message-passing steps, from edges to nodes, edges
    to edges, and edges to nodes again. The repeated transformations are useful for
    information aggregation through repeated message passing and capturing high-order
    interactions in the graph. By repeatedly transforming between nodes and edges,
    the model becomes aware of both local and global structure information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 实现编码器有几个子集。首先，我们传递输入数据，它由不同帧、不同实验中的不同传感器组成。然后，编码器将此数据，*x*，执行消息传递步骤，将边数据转换为节点数据，然后再转换回边数据。然后，边数据再次转换为节点数据，在潜在空间中进行编码。这相当于三个消息传递步骤，从边到节点，从边到边，然后再从边到节点。重复的转换对于通过重复消息传递进行信息聚合和捕获图中的高阶交互是有用的。通过在节点和边之间重复转换，模型能够意识到局部和全局结构信息。
- en: Throughout this book, we’ve explored how to use message passing to convert node
    or edge features into complex representations of nodes or edges. These are at
    the core of all GNN methods. The NRI model is slightly different from the methods
    that we’ve explored before because messages are passed between nodes and edges,
    rather than node to node or edge to edge. To make explicit what these steps are
    doing, we’ll depart from PyG and code our model in plain PyTorch instead.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们探讨了如何使用消息传递将节点或边特征转换为节点或边的复杂表示。这些是所有GNN方法的核心。NRI模型与我们之前探索的方法略有不同，因为消息是在节点和边之间传递，而不是节点到节点或边到边。为了明确这些步骤的作用，我们将从PyG转向，并用纯PyTorch编写我们的模型。
- en: In listing 6.13, we show the base class for our encoder, which requires several
    key features. First, note that we haven’t described the actual neural network
    that will be used to encode the data. We’ll introduce this shortly. Instead, we
    have two message-passing functions, `edge2node` and `node2edge`, as well as an
    encoding function, `one_hot_recv`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表6.13中，我们展示了我们编码器的基类，它需要几个关键特性。首先，请注意，我们还没有描述将要用于编码数据的实际神经网络。我们将很快介绍这一点。相反，我们有两个消息传递函数，`edge2node`和`node2edge`，以及一个编码函数，`one_hot_recv`。
- en: Listing 6.13 Encoder base class
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.13 编码器基类
- en: '[PRE12]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Creates a matrix representing edges between variables'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建表示变量之间边的矩阵'
- en: '#2 Finds the indices where edges exist'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 查找存在边的索引'
- en: '#3 Creates a one-hot representation for receiving edges'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 创建接收边的one-hot表示'
- en: '#4 Creates a parameter tensor for edge-to-node transformation'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 创建边到节点转换的参数张量'
- en: '#5 Extracts sender and receiver embeddings'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 提取发送者和接收者的嵌入'
- en: '#6 Concatenates sender and receiver embeddings'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 连接发送者和接收者的嵌入'
- en: '#7 Multiplies edge embeddings with edge-to-node matrix'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 将边嵌入与边到节点矩阵相乘'
- en: '#8 Normalizes the incoming embeddings'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 正则化传入的嵌入'
- en: The first step in our encoder class is to build an adjacency matrix. Here, we
    assume that the graph is fully connected, such that all nodes are connected to
    all other nodes but not to themselves. The `node2edge` function takes node embedding
    data and identifies the direction that these messages have been sent. Figure 6.12
    shows an example of how we’re building the adjacency matrix.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编码器类的第一步是构建一个邻接矩阵。在这里，我们假设图是完全连接的，这意味着所有节点都与其他所有节点相连，但与自己不相连。`node2edge`函数接受节点嵌入数据并识别这些消息发送的方向。图6.12展示了我们构建邻接矩阵的一个示例。
- en: '![figure](../Images/6-12.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-12.png)'
- en: Figure 6.12 Example of creating an adjacency matrix for a fully connected graph
    with three nodes. The matrix on the left represents a fully connected graph, the
    matrix in the middle represents the identity matrix, and the matrix on the right
    shows the final adjacency matrix after subtracting the identity matrix. This results
    in a graph where each node is connected to every other node with no self-loops.
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.12展示了为具有三个节点的完全连接图创建邻接矩阵的示例。左边的矩阵代表一个完全连接的图，中间的矩阵代表单位矩阵，右边的矩阵显示了减去单位矩阵后的最终邻接矩阵。这导致一个每个节点都与其他每个节点相连但没有自环的图。
- en: The next function call then determines which nodes are sending or receiving
    data by returning two vectors that contain rows and columns for connected nodes.
    Recall that in an adjacency matrix, the rows represent receiving nodes and the
    columns represent sending nodes. The output is then
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数调用通过返回包含连接节点行和列的两个向量来确定哪些节点正在发送或接收数据。回想一下，在邻接矩阵中，行代表接收节点，列代表发送节点。输出结果是
- en: '[PRE13]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can interpret this as saying that the node at row 0 sends data to nodes at
    columns 1 and 2, and so on. This allows us to extract edges between nodes. Once
    we construct our node embeddings, we then use the sending and receiving data to
    convert our node data to edges. This is the principle of the `node2edge` function.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以理解为，行0的节点向列1和2的节点发送数据，依此类推。这使我们能够提取节点之间的边。一旦我们构建了节点嵌入，我们就使用发送和接收数据将节点数据转换为边。这就是`node2edge`函数的原理。
- en: The next function we need is how to build `edge2node` based on our `edge_ embeddings`.
    We first construct an `edge2node` matrix. Here, we’re using a one-hot encoding
    method that converts our receiving edges into a one-hot encoded representation.
    Specifically, we create a matrix where each row denotes whether that category
    (receiving node) exists. For our simple three-node case, the one-hot encoding
    method for the receiving edges is shown in figure 6.13\.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的下一个函数是如何根据我们的`edge_embeddings`构建`edge2node`。我们首先构建一个`edge2node`矩阵。在这里，我们使用一种one-hot编码方法，将接收到的边转换为one-hot编码表示。具体来说，我们创建一个矩阵，其中每一行表示该类别（接收节点）是否存在。对于我们的简单三个节点案例，接收边的one-hot编码方法如图6.13所示。
- en: We then transpose this to switch rows and columns, so that the dimension will
    be (number of nodes, number of edges), and we convert it into a PyTorch parameter
    so that we can differentiate over it. Once we have our `edge2node` matrix, we
    multiple this by our edge embeddings. Our edge embeddings will be of shape (number
    of edges, embedding size) so that multiplying the `edge2node` matrix by the edge
    embeddings gives us an object of shape (number of nodes, embedding size). These
    are our new node embeddings! Finally, we normalize this matrix by the number of
    possible nodes for numerical stability.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将这个矩阵转置以交换行和列，这样维度将是（节点数，边数），并将其转换为PyTorch参数，以便我们可以对其进行微分。一旦我们有了`edge2node`矩阵，我们就将其与边嵌入相乘。我们的边嵌入将是形状为（边数，嵌入大小）的对象，这样将`edge2node`矩阵与边嵌入相乘就给我们一个形状为（节点数，嵌入大小）的对象。这些就是我们的新节点嵌入！最后，我们通过可能的节点数来归一化这个矩阵，以确保数值稳定性。
- en: This section is key to understanding the message-passing step in the model.
    (For further information on message passing, revisit chapter 2 and 3.) As discussed
    there, once we have a principled way to pass messages between nodes, edges, or
    some combination of both, we then apply neural networks to these embeddings to
    get nonlinear representations. To do so, we need to define our embedding architecture.
    The code for the complete encoder is given in listing 6.14\.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分是理解模型中消息传递步骤的关键。（关于消息传递的更多信息，请回顾第2章和第3章。）正如所讨论的，一旦我们有一种在节点、边或两者的组合之间传递消息的原则性方法，我们就将这些嵌入应用于神经网络以获得非线性表示。为此，我们需要定义我们的嵌入架构。完整的编码器代码在列表6.14中给出。
- en: '![figure](../Images/6-13.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-13.png)'
- en: Figure 6.13 The one-hot encoding matrix representing incoming edges for each
    node in a fully connected graph with three nodes is shown on the left. Each row
    corresponds to an edge, and each column corresponds to a node. A 1 in position
    (i, j) indicates that edge i is directed toward node j. This matrix is used to
    transform edge embeddings to node embeddings in the `edge2node` function of the
    encoder base class, enabling the model to aggregate information from incoming
    edges for each node. In this graph structure, nodes 0, 1, and 2 each send messages
    to the other two nodes, resulting in a total of six directed edges. The diagram
    of the three-node graph is shown on the right.
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.13展示了在具有三个节点的全连接图中，每个节点 incoming edges 的一热编码矩阵，位于左侧。每一行对应一条边，每一列对应一个节点。位置（i,
    j）处的1表示边i指向节点j。这个矩阵用于在编码器基类的`edge2node`函数中将边嵌入转换为节点嵌入，使模型能够为每个节点聚合来自 incoming
    edges 的信息。在这个图结构中，节点0、1和2各自向其他两个节点发送消息，从而产生总共六个有向边。三个节点图的示意图位于右侧。
- en: The `RefMLPEncoder` is shown in listing 6.14\. This encoder uses four MLPs for
    message processing, each featuring exponential linear unit (ELU) activation and
    batch normalization (defined in `RefNRIMLP`, shown in the chapter’s code repository).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`RefMLPEncoder`在列表6.14中展示。这个编码器使用四个MLP进行消息处理，每个MLP都具备指数线性单元（ELU）激活和批归一化（在`RefNRIMLP`中定义，本章代码库中展示）。'
- en: Note  The exponential linear unit (ELU) is an activation function that is useful
    in smoothing outputs across multiple layers and preventing vanishing gradients.
    In contrast to ReLUs, ELUs have a smoother gradient built in for negative inputs
    and allows for negative outputs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：指数线性单元（ELU）是一种有用的激活函数，可用于平滑多层输出并防止梯度消失。与ReLU不同，ELU在负输入时内置了更平滑的梯度，并允许有负输出。
- en: The final part of the network (`self.fc_out`) is a sequence of linear layers
    with ELU activations between them, ending with a linear layer that outputs the
    desired embeddings or predictions. The final layer of this sequence is a fully
    connected layer.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的最后一部分（`self.fc_out`）是一系列带有ELU激活的线性层，以输出所需嵌入或预测的线性层结束。这个序列的最后一层是一个全连接层。
- en: Listing 6.14 NRI MLP encoder
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.14 NRI MLP编码器
- en: '[PRE14]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Defines MLP layers. RefNRIMLP is a 2-layer fully connected ELU net with
    batch norm.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义了MLP层。RefNRIMLP是一个2层全连接ELU网络，带有批归一化。'
- en: '#2 Defines the final fully connected layer'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义了最终的完全连接层'
- en: Here, we define architectural details related to the encoder. As discussed earlier,
    there are 31 sensors that we represent using the `num_vars` variable. The number
    of features is 6, which is the `input_size` for our network. The number of timesteps
    for our training and validation set is still 50, and our encoder network size
    will be 256\. The number of `edge_types` is 2, and we assume no dropout of the
    weights. We then initialize our networks, which are typical MLPs, described in
    our shared repository. The networks include a batch normalization layer and two
    fully connected layers. Once the network is defined, we also pre-initialize the
    weights, as shown in listing 6.15\. Here, we loop through all the different layers
    and then initialize the weights using the Xavier initialization approach. This
    ensures that the gradients in the layers are all approximately of similar scale,
    which reduces the risk of our loss rapidly diverging—known as blow-up. This is
    an important step when combining multiple networks with different architectures
    as we do here. We also set the initial bias to 0.1, which further helps with the
    stability of training.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义与编码器相关的架构细节。如前所述，我们使用`num_vars`变量表示31个传感器。特征数量为6，这是网络的`input_size`。我们的训练和验证集的时间步数为50，编码器网络的大小将为256。`edge_types`的数量为2，我们假设权重没有dropout。然后我们初始化我们的网络，这些是典型的MLP，在共享的代码库中描述。网络包括一个批归一化层和两个全连接层。一旦定义了网络，我们也预先初始化权重，如列表6.15所示。在这里，我们遍历所有不同的层，然后使用Xavier初始化方法初始化权重。这确保了层中的梯度都大致处于相似的比例，从而降低了损失迅速发散的风险——即爆炸。当我们像这里这样组合具有不同架构的多个网络时，这是一个重要的步骤。我们还设置了初始偏置为0.1，这有助于提高训练的稳定性。
- en: Listing 6.15 Weight initialization
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.15权重初始化
- en: '[PRE15]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 Only applies to linear layers'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 仅适用于线性层'
- en: '#2 Initializes weights using Xavier normal initialization'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用Xavier正态初始化权重'
- en: '#3 Sets bias to 0.1'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将偏置设置为0.1'
- en: Finally, we need to define our forward pass method, as shown in listing 6.16\.
    This is where our message-passing step occurs.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要定义我们的前向传递方法，如列表6.16所示。这就是我们的消息传递步骤发生的地方。
- en: Listing 6.16 Encoder forward pass
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.16 编码器前向传递
- en: '[PRE16]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#1 New shape: [num_sims, num_atoms, num_timesteps*num_dims]'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 新形状：[num_sims, num_atoms, num_timesteps*num_dims]'
- en: '#2 Passes through first MLP layer (two-layer ELU network per node)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 通过第一个MLP层（每个节点两个ELU网络层）'
- en: '#3 Converts node embeddings to edge embeddings'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将节点嵌入转换为边嵌入'
- en: '#4 Passes through the second MLP layer'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 通过第二个MLP层'
- en: '#5 Converts edge embeddings back to node embeddings'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将边嵌入转换回节点嵌入'
- en: '#6 Converts node embeddings to edge embeddings again'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 再次将节点嵌入转换为边嵌入'
- en: '#7 Final fully connected layer to get the logits'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 最终的全连接层以获取logits'
- en: Our encoder lets our model transform different sets of frames of our sensor
    graphs into latent representation of edge probabilities. Next, let’s explore how
    to construct a decoder that transforms the latent edge probabilities into trajectory
    using the recent sensor data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的编码器允许我们的模型将我们的传感器图的帧集转换为边概率的潜在表示。接下来，让我们探索如何构建一个解码器，该解码器使用最近的传感器数据将潜在边概率转换为轨迹。
- en: 6.4.2 Decoding pose data using a GRU
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.2 使用GRU解码姿态数据
- en: To transform the latent representations into future frames, we need to account
    for the temporal evolution of the trajectories. To do so, we train a decoder network.
    Here, we’ll follow the original structure of the NRI paper [2] and use a GRU as
    our RNN.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将潜在表示转换为未来帧，我们需要考虑轨迹的时间演化。为此，我们训练一个解码器网络。在这里，我们将遵循NRI论文[2]的原始结构，并使用GRU作为我们的RNN。
- en: We introduced the concept of a GRU in section 6.2.2 earlier. As a quick reminder,
    gated recurrent units (GRUs) are a type of RNN that uses a gated process to allow
    RNNs to capture long-term behaviors in the data. They are composed of two types
    of gates—reset gates and update gates.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在6.2.2节中介绍了GRU的概念。为了快速回顾，门控循环单元（GRU）是一种使用门控过程来允许RNN捕获数据中长期行为的RNN类型。它们由两种类型的门组成——重置门和更新门。
- en: For the NRI model, we’ll apply GRUs to our edges, rather than across the entire
    graph. The update gates will be used to determine how much of the node’s hidden
    state should be updated, given the receiving data, and the reset gate decides
    how much should be erased or “forgotten.” To put it another way, we’ll use a GRU
    to predict what the future state of a node should be based on the edge type probabilities
    from our encoder network.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 对于NRI模型，我们将GRU应用于我们的边，而不是整个图。更新门将用于确定根据接收到的数据，应该更新节点隐藏状态的多少，而重置门决定应该删除或“忘记”多少。换句话说，我们将使用GRU根据编码器网络中的边类型概率预测节点的未来状态。
- en: Let’s look at how we construct this step-by-step. The initialization code for
    our decoder is given in listing 6.17\. First, we note some of the variables passed
    to this network. We again define the number of variables or nodes in our graphs,
    31, and the number of input features, 6\. We assume there is no dropout of the
    weights and the hidden size for each layer is 64\. Again, we need to make clear
    that our decoder should be predicting two different types of edges. We’ll also
    skip the first edge type when making predictions as this denotes that there is
    no edge.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地看看我们是如何构建这个步骤的。我们的解码器初始化代码在列表6.17中给出。首先，我们注意到传递给这个网络的一些变量。我们再次定义我们图中变量或节点的数量，31个，以及输入特征的个数，6个。我们假设权重没有dropout，并且每层的隐藏大小为64。再次明确，我们的解码器应该预测两种不同类型的边。在预测时，我们也会跳过第一种边类型，因为这表示没有边。
- en: Once we have the input parameters defined, we can introduce the network architecture.
    The first layer is a simple linear network that needs to have twice the input
    dimension to account for the mean and variance provided by our encoder, and we
    define this network for each of the edge types. We then define a second layer
    to further increase the expressivity of our network. The output from these two
    linear layers is passed to our RNN, which is a GRU. Here, we have to use a custom
    GRU to account for both node data and edge data. The output from the GRU is passed
    to three more neural network layers to provide the future predictions. Finally,
    we need to define our `edge2node` matrix and sending and receiving nodes, as we
    did with our encoder.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了输入参数，我们就可以引入网络架构。第一层是一个简单的线性网络，需要具有两倍的输入维度，以考虑由编码器提供的均值和方差，并且我们为每种边类型定义了这个网络。然后我们定义第二层以进一步提高我们网络的表达能力。这两个线性层的输出传递给我们的RNN，即GRU。在这里，我们必须使用自定义GRU来考虑节点数据和边数据。GRU的输出传递给三个更多的神经网络层以提供未来预测。最后，我们需要定义我们的`edge2node`矩阵以及发送和接收节点，就像我们处理编码器时那样。
- en: Listing 6.17 RNN decoder
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.17 RNN解码器
- en: '[PRE17]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Edge-related layers'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 与边相关的层'
- en: '#2 GRU layers'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 GRU层'
- en: '#3 Fully connected layers'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 全连接层'
- en: 'In listing 6.18, we provide the architecture for our GRU. The first overall
    architecture for this network is the same structure as a typical GRU. We define
    three hidden layers which represent the reset gates defined by `hidden_r` and
    `input_r`, the update gates defined by `hidden_i` and `input_i`, and the activation
    networks defined by `hidden_h` and `input_h`. The forward network, however, needs
    to account for the aggregated messages from the message-passing output of our
    encoder. This is shown in the forward pass. We’ll pass the edge probabilities
    in `agg_msgs`, along with the input node data, and these combine to return future
    predictions. This can be seen in the `predict_future` code in our base NRI class:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表6.18中，我们提供了我们的GRU架构。这个网络的整体架构与典型的GRU结构相同。我们定义了三个隐藏层，这些层代表了由`hidden_r`和`input_r`定义的重置门，由`hidden_i`和`input_i`定义的更新门，以及由`hidden_h`和`input_h`定义的激活网络。然而，正向网络需要考虑来自编码器消息传递输出的聚合消息。这可以在正向传递中看到。我们将`agg_msgs`中的边概率以及输入节点数据传递，这些数据结合起来返回未来预测。这可以在我们的基础NRI类中的`predict_future`代码中看到：
- en: '[PRE18]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Our decoder gets passed the last time frame of our graphs. The edge data that
    is output from our encoder is also passed to the decoder.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的解码器接收我们图的最后一个时间帧。从编码器输出的边数据也传递给解码器。
- en: Listing 6.18 Custom GRU network
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.18 自定义GRU网络
- en: '[PRE19]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#1 Defines hidden layer transformations for reset, input, and new gates'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义重置、输入和新门的隐藏层变换'
- en: '#2 Defines input layer transformations for reset, input, and new gates'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义重置、输入和新门的输入层变换'
- en: '#3 Computes reset gate activations'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算重置门激活'
- en: '#4 Computes input gate activations'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 计算输入门激活'
- en: '#5 Computes new gate activations'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 计算新门激活'
- en: '#6 Updates hidden state'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 隐藏状态更新'
- en: 'The output from the decoder network is then the future prediction timesteps.
    To better understand this, let’s look at the forward pass method for our decoder,
    given in listing 6.19\. Our forward pass is given the inputs and sampled edges
    to build a prediction. There are also four additional arguments that help control
    the behavior. First, we define a `teacher_forcing` variable. Teaching forcing
    is a typical method used when training sequential models, such as RNNs. If this
    is true, we use the ground truth (the real graph) to predict the next time frame.
    When this is false, we use the output from the model’s previous timestep. This
    makes sure that the model isn’t led astray by incorrect predictions during training.
    Next, we include a `return_state` variable, which allows us to access the hidden
    representations given by the decoder network. We use this when we predict the
    future graph evolution, as shown here:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器网络的输出是未来的预测时间步。为了更好地理解这一点，让我们看看解码器的正向传递方法，如列表6.19所示。我们的正向传递接收输入和采样边来构建预测。还有四个额外的参数有助于控制行为。首先，我们定义一个`teacher_forcing`变量。教学强制是一种在训练序列模型时常用的典型方法，例如RNN。如果这是真的，我们使用真实值（真实图）来预测下一个时间帧。当这是假的时，我们使用模型上一个时间步的输出。这确保了模型在训练期间不会被错误的预测所误导。接下来，我们包括一个`return_state`变量，它允许我们访问解码器网络提供的隐藏表示。当我们预测未来图演化时，我们使用这个变量，如这里所示：
- en: '[PRE20]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Let’s now discuss the prediction process. First, we predict a temporary prediction
    set. Then, we use the hidden representations to predict as many steps in the future
    as is needed. This is particularly useful when we want to predict more than one
    timestep, as we show in the testing phase of this model. This is controlled by
    the `prediction_steps` variable, which tells us how many times to loop through
    our RNN, that is, how many timesteps in the future we want to predict. Finally,
    we have a `state` variable, which is used to control the information being passed
    to our decoder. When it’s left empty, we initialize a tensor of zeros so that
    there is no information being passed. Otherwise, we’ll use information from previous
    timesteps.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论预测过程。首先，我们预测一个临时预测集。然后，我们使用隐藏表示来预测所需的所有未来步骤。当我们想要预测多个时间步时，这特别有用，正如我们在该模型的测试阶段所展示的。这由`prediction_steps`变量控制，它告诉我们RNN要循环多少次，即我们想要预测多少未来的时间步。最后，我们有一个`state`变量，用于控制传递给解码器的信息。当它为空时，我们初始化一个零张量，以便没有信息被传递。否则，我们将使用之前时间步的信息。
- en: Listing 6.19 Decoder forward pass
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.19 解码器正向传递
- en: '[PRE21]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#1 Determines the number of prediction steps'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 确定预测步骤的数量'
- en: '#2 Expands the sampled_edges tensor if needed'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 如有必要扩展sampled_edges张量'
- en: '#3 Initializes the hidden state if not provided'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 如果未提供，初始化隐藏状态'
- en: '#4 Determines the number of steps to apply teacher forcing to'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 确定应用教师强制的步骤数量'
- en: '#5 Decides the input for this step based on teacher forcing'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 根据教师强制决定这一步的输入'
- en: '#6 Performs a single forward step using the ins calculated from inputs or pred_all
    (see the previous comment)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 使用从输入或pred_all计算出的ins执行单个正向步骤（见上一条注释）'
- en: '#7 Returns predictions and the hidden state'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 返回预测和隐藏状态'
- en: To predict timesteps into the future, we make an additional forward pass that
    is based on a single timestep, as defined in listing 6.20\. This is where our
    network performs additional message-passing steps. We take our receiver nodes
    and sending nodes, which are defined from the edge probabilities from our encoder.
    We ignore the first edges, as these are unconnected nodes, and the network then
    loops through the different networks for the different edge types to get all edge-dependent
    messages from the network. This is the critical step that makes our predictions
    dependent on the graph data. Our GRU then takes the messages from the connected
    node to inform its predictions of the trajectories. At this step, we’re learning
    to predict how the body is walking from what we’ve learned about how the body
    is connected. The output is both the predicted trajectories of the sensors on
    the body as well as the network data for why it made these predictions, encoded
    in the hidden weights. This completes the NRI model for estimating poses.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测未来的时间步，我们进行一个基于单个时间步的额外正向传递，如第6.20列所示。这是我们的网络执行额外消息传递步骤的地方。我们取我们的接收节点和发送节点，这些节点是从编码器的边概率中定义的。我们忽略第一个边，因为这些是无连接的节点，然后网络遍历不同类型的边，从网络中获取所有与边相关的消息。这是使我们的预测依赖于图数据的临界步骤。我们的GRU随后从连接节点接收消息，以告知其对轨迹的预测。在这一步，我们正在学习如何根据我们对身体连接的了解来预测身体的行走方式。输出包括身体上传感器的预测轨迹以及为什么做出这些预测的网络数据，这些数据编码在隐藏权重中。这完成了估计姿态的NRI模型。
- en: Listing 6.20 Decoder single step forward
  id: totrans-273
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.20 解码器单步正向
- en: '[PRE22]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Node-to-edge step'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 节点到边步骤'
- en: '#2 Message of size: [batch, num_edges, 2*msg_out]'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 消息大小：[batch, num_edges, 2*msg_out]'
- en: '#3 Runs a separate MLP for every edge type'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 为每种边类型运行一个单独的MLP'
- en: '#4 Sums all the messages per node'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 对每个节点求所有消息的总和'
- en: '#5 GRU-style gated aggregation'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 GRU风格的门控聚合'
- en: '#6 Builds output MLP'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 构建输出多层感知器（MLP）'
- en: 6.4.3 Training the NRI model
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.3 训练NRI模型
- en: 'Now that we’ve defined the different parts of our model, let’s train the model
    and see how it performs. To train our model, we’ll take the following steps:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了模型的各个部分，让我们训练模型并看看它的表现。为了训练我们的模型，我们将采取以下步骤：
- en: Train an encoder that converts sensor data into a representation of edge probabilities,
    indicating whether a sensor is connected to another or not.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个编码器，将传感器数据转换为边概率的表示，指示传感器是否连接到另一个。
- en: Train a decoder to predict future trajectories, conditional on the probability
    of there being an edge connecting the different sensors.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个解码器，根据不同传感器之间存在边的概率来预测未来的轨迹。
- en: Run the decoder to predict the future trajectories using a GRU, which is passed
    the edge probabilities.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行解码器，使用GRU预测未来轨迹，GRU接收到的边缘概率。
- en: 'Reduce the loss based on the reconstructed poses. This loss has two components:
    the reconstruction loss and the KL divergence.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于重建姿态减少损失。这种损失有两个组成部分：重建损失和KL散度。
- en: Repeat steps 1 through 4 until training converges.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1至4，直到训练收敛。
- en: This is also shown in figure 6.14, and the training loop is given in listing
    6.21.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这也在图6.14中显示，训练循环在列表6.21中给出。
- en: '![figure](../Images/6-14.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-14.png)'
- en: Figure 6.14 Pipeline for the NRI model
  id: totrans-290
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.14 NRI模型的流程
- en: Listing 6.21 NRI training loop
  id: totrans-291
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.21 NRI训练循环
- en: '[PRE23]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '#1 Training loop'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 训练循环'
- en: '#2 Update the weights.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 更新权重。'
- en: '#3 Zero gradients for the validation pass'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 验证过程中的梯度为零'
- en: We’ll train for 50 epochs with a learning rate of 0.0005, a learning rate scheduler
    that reduces the learning rate by a factor of 0.5 after 500 forward passes, and
    a batch size of 8\. Most of the training is based on the `calculate_loss` method
    call, which we defined earlier in listing 6.14\. We find that our model loss falls
    along with the validation loss, reaching a validation loss of 1.21 based on the
    negative log likelihood (`nll`). This looks good but let’s see how it performs
    on the test data, where it needs to predict multiple steps into the future. To
    do so, we need to define a new function, given in the following listing.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用学习率为0.0005，学习率调度器在500次正向传递后减少学习率因子为0.5，批大小为8进行50个epoch的训练。大部分训练基于我们之前在列表6.14中定义的`calculate_loss`方法调用。我们发现我们的模型损失随着验证损失下降，基于负对数似然(`nll`)达到验证损失1.21。这看起来不错，但让我们看看它在测试数据上的表现，它需要预测未来的多个步骤。为此，我们需要定义一个新的函数，如下面的列表所示。
- en: Listing 6.22 Evaluating future predictions
  id: totrans-297
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.22评估未来预测
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This function loads our test data and then calculates the MSE for our predictions
    given different time horizons. When we test our model, we find that it’s able
    to predict the next timestep with an MSE of 0.00008\. Even better, it predicts
    40 timesteps into the future with an accuracy of 94%. This is significantly better
    than our LSTM and GAT models, which achieved 65% and 55%, respectively. The reduction
    in accuracy over future timesteps is shown in figure 6.15, and the example output
    is given in figure 6.16.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数加载我们的测试数据，然后根据不同的时间范围计算我们的预测的均方误差(MSE)。当我们测试我们的模型时，我们发现它能够以均方误差0.00008预测下一个时间步。更好的是，它能够以94%的准确度预测40个时间步的未来。这显著优于我们的LSTM和GAT模型，分别达到了65%和55%。未来时间步的准确度降低如图6.15所示，示例输出如图6.16所示。
- en: '![figure](../Images/6-15.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-15.png)'
- en: Figure 6.15 Reduction in accuracy as we predict into the future
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.15预测未来时准确度的降低
- en: '![figure](../Images/6-16.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-16.png)'
- en: Figure 6.16 Example output from the NRI model
  id: totrans-303
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.16 NRI模型的示例输出
- en: We’ve covered all the core components for the NRI model, with the full working
    code provided in the GitHub repository ([https://mng.bz/4a8D](https://mng.bz/4a8D)).
    The accuracy is impressive and highlights the power of combining generative and
    graph-based methods with temporal models. This is shown in figure 6.15, where
    we see good agreement with the predicted pose and the resulting estimated pose.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了NRI模型的所有核心组件，完整的可工作代码已提供在GitHub仓库([https://mng.bz/4a8D](https://mng.bz/4a8D))中。准确度令人印象深刻，突出了结合生成和基于图的方法与时间模型的强大功能。这如图6.15所示，我们看到预测姿态和结果估计姿态之间有很好的吻合。
- en: Furthermore, this method is robust at not just predicting graphs but also learning
    the underlying structure even when all the graph data isn’t available. In this
    problem, we knew what interaction network to expect. However, there are many instances
    where we don’t know the interaction network. One example is particles that are
    moving in a confined space. When they are within some interaction radius, then
    they will influence each other, but not when they are farther away. This is true
    of organisms from cells to sports players. In fact, the majority of the world
    involves interacting agents with secret interaction networks. NRI models provide
    a tool to not only predict the behavior and movement of these agents but also
    learn about their interaction patterns with other agents. Indeed, the original
    NRI paper demonstrated this using video tracking data of basketball games and
    showed that the model can learn typical patterns between ball, ball handler, screener,
    and defensive matchups for the different players. (For more information, refer
    to Kipf et al. [2].)
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这种方法不仅能够预测图，而且在所有图数据不可用的情况下，也能学习底层结构，因此非常稳健。在这个问题中，我们知道预期的交互网络。然而，有许多情况下我们并不知道交互网络。一个例子是处于封闭空间中运动的粒子。当它们在某个交互半径内时，它们会相互影响，但当它们距离更远时则不会。这种情况适用于从细胞到运动员的所有生物体。事实上，世界上大多数情况都涉及具有秘密交互网络的交互代理。NRI模型不仅提供了一种预测这些代理的行为和运动的方法，还能了解它们与其他代理的交互模式。确实，原始的NRI论文通过篮球比赛的视频跟踪数据展示了这一点，并表明该模型可以学习球、球手、挡拆者和不同球员之间的典型模式。（更多信息，请参阅Kipf等人[2]的研究。）
- en: 6.5 Under the hood
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 内部机制
- en: In this chapter, we showed how to tackle temporal or dynamic problems. Here,
    we go into more detail for some of the key model components that we used.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了如何处理时间或动态问题。在这里，我们更详细地讨论了我们使用的一些关键模型组件。
- en: 6.5.1 Recurrent neural networks
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.1 循环神经网络
- en: In figure 6.16, we showed a schematic for RNN models. The main difference for
    RNN models compared to all the other models that we’ve seen is that the model
    can cope with sequential data. This means that each timestep has a hidden layer,
    and output from this hidden layer is combined with new input at subsequent timesteps.
    In figure 6.17, this is shown in two ways. First, on the left side, we show the
    temporal updates as a single self-loop denoted by Whh. To get a better understanding
    of what this self-loop is doing, we’ve “unfolded” the model in time so that we
    can explicitly see how our model updates. Here, we change our input, output, and
    hidden layers (x, y, h) to be temporal variables (xt, yt, ht). At our initial
    step, t, we update our current hidden layer with input data from xt and the weights
    from our previous hidden layer ht–1 and then use this to output yt. The weights
    from ht are then passed to ht+1 along with the new input at xt+1 to infer yt+1\.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在图6.16中，我们展示了RNN模型的示意图。与我们所见过的所有其他模型相比，RNN模型的主要区别在于模型可以处理序列数据。这意味着每个时间步都有一个隐藏层，并且从该隐藏层输出的结果会在后续时间步与新的输入相结合。在图6.17中，这以两种方式展示。首先，在左侧，我们展示时间更新作为一个单独的自我循环，用Whh表示。为了更好地理解这个自我循环的作用，我们已经“展开”了模型在时间上的表现，以便我们可以明确地看到我们的模型是如何更新的。在这里，我们将我们的输入、输出和隐藏层（x,
    y, h）更改为时间变量（xt, yt, ht）。在我们的初始步骤t，我们使用xt的数据和从我们之前的隐藏层ht–1的权重来更新我们的当前隐藏层，然后使用这个来输出yt。然后，ht的权重会传递给ht+1，并伴随着新的输入xt+1来推断yt+1。
- en: One of the key features for this model is that when we backpropagate to update
    our weights, we need to backpropagate through time (BPTT). This is a specific
    feature for all RNNs. However, most modern deep learning packages make this very
    straightforward to do and hide all the difficult computational details for the
    practitioner.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的一个关键特性是，当我们反向传播以更新我们的权重时，我们需要进行时间反向传播（BPTT）。这是所有RNN的一个特定特性。然而，大多数现代深度学习包都使这一过程变得非常简单，并隐藏了所有复杂的计算细节，以便于实践者使用。
- en: '![figure](../Images/6-17.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-17.png)'
- en: Figure 6.17 Structure for an RNN. Temporal updates as a single self-loop denoted
    by Whh (left). An unfolded model in time showing the model updates (right). Here,
    we change our input, output, and hidden layers (x, y, h) to be temporal variables
    (x[t], y[t], h[t]). At our initial step, t, we update our current hidden layer
    with input data from x[t] and the weights from our previous hidden layer h[t–1]
    and then use this to output y[t]. The weights from ht are then passed to h[t+1]
    along with the new input at x[t+1] to infer y[t+1].
  id: totrans-312
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.17 RNN 的结构。时间更新作为一个单环自我循环，由 Whh 表示（左侧）。展开的时间模型显示了模型更新（右侧）。在这里，我们将输入、输出和隐藏层（x、y、h）更改为时间变量（x[t]、y[t]、h[t]）。在初始步骤
    t，我们使用来自 x[t] 的输入数据和来自先前隐藏层 h[t–1] 的权重来更新当前隐藏层，然后使用它来输出 y[t]。然后，ht 的权重与新的输入 x[t+1]
    一起传递到 h[t+1]，以推断 y[t+1]。
- en: Let’s see how to implement an RNN using PyTorch. This is as straightforward
    as defining a neural network class and then introducing specific RNN layers within
    the network. For example, in listing 6.23, we show the code for defining a network
    with a single RNN layer. This is a very basic definition of an RNN, given there
    is only one hidden layer. However, it’s useful to see this example to get some
    solid intuition on how a model can be trained. For each timestep, our input is
    passed both to the hidden layer and the output. When we perform a forward pass,
    the output goes back to output and the hidden layer. Finally, we need to initialize
    our hidden layer with something, so we’re using a fully connected layer.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 PyTorch 实现一个 RNN。这就像定义一个神经网络类，然后在网络中引入特定的 RNN 层一样简单。例如，在列表 6.23 中，我们展示了定义具有单个
    RNN 层的网络的代码。这是一个非常基本的 RNN 定义，因为只有一个隐藏层。然而，看到这个例子对于了解模型如何训练有一些直观的帮助。对于每个时间步，我们的输入都传递到隐藏层和输出。当我们执行前向传递时，输出返回到输出和隐藏层。最后，我们需要用某物初始化我们的隐藏层，所以我们使用全连接层。
- en: Listing 6.23 Defining an RNN
  id: totrans-314
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.23 定义 RNN
- en: '[PRE25]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#1 RNN layer'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 RNN 层'
- en: '#2 Fully connected layer'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 全连接层'
- en: '#3 Sets the initial hidden and cell states'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 设置初始隐藏和细胞状态'
- en: '#4 Forward propagates the RNN'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 前向传播 RNN'
- en: '#5 Passes the output of the last timestep to the fully connected layer'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将最后一个时间步的输出传递到全连接层'
- en: In practice, we often want to use more complicated RNNs. This includes extensions
    to RNNs such as LSTM networks or GRU networks. We can even stack RNNs, LSTMs,
    and GRUs together using our deep learning library of choice. A GRU is similar
    to an RNN in that it’s useful for sequences of data. They were specifically designed
    to resolve one of the key drawbacks of RNNs, the vanishing gradient problem. It
    uses two gates, which determine both how much past information to keep (the update
    gates) and how much to forget or throw away (the reset gates). We show an example
    design for a GRU in figure 6.18\. Here, *z**[t]* denotes the update gates, and
    r*[t]* denotes the reset gates. The *~h**[t]* term is known as the candidate activation
    and reflects a candidate for the new state of the representations, while the *h**[t]*
    term is the actual hidden state.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们经常想要使用更复杂的 RNN。这包括 RNN 的扩展，如 LSTM 网络或 GRU 网络。我们甚至可以使用我们选择的深度学习库将 RNN、LSTMs
    和 GRUs 堆叠起来。GRU 与 RNN 类似，因为它对数据序列很有用。它们被特别设计来解决 RNN 的一个关键缺点，即梯度消失问题。它使用两个门，这些门决定了保留多少过去信息（更新门）以及忘记或丢弃多少（重置门）。我们在图
    6.18 中展示了 GRU 的一个示例设计。在这里，*z**[t]* 表示更新门，r*[t]* 表示重置门。*~h**[t]* 术语被称为候选激活，反映了表示的新状态的候选，而
    *h**[t]* 术语是实际的隐藏状态。
- en: '![figure](../Images/6-18.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/6-18.png)'
- en: Figure 6.18 Design of the GRU layer, where r*[t]* represents the reset gate,
    z*[t]* is the update gate, ~h*[t]* is the candidate function, and h*[t]* is the
    final actual hidden state
  id: totrans-323
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.18 GRU 层的设计，其中 r*[t]* 表示重置门，z*[t]* 是更新门，~h*[t]* 是候选函数，h*[t]* 是最终的实际隐藏状态
- en: In listing 6.24, we show how to build a model with GRU layers. Here, the majority
    of the implementation is handled by PyTorch, where the layer is imported from
    the standard PyTorch library. The rest of the model definition is a typical neural
    network.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 6.24 中，我们展示了如何使用 GRU 层构建模型。在这里，大多数实现由 PyTorch 处理，其中层是从标准 PyTorch 库导入的。模型定义的其余部分是典型的神经网络。
- en: Listing 6.24 GRU
  id: totrans-325
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.24 GRU
- en: '[PRE26]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#1 GRU layer'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 GRU 层'
- en: '#2 Fully connected layer'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 全连接层'
- en: '#3 Sets the initial hidden state'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 设置初始隐藏状态'
- en: '#4 Forward propagates the GRU'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 前向传播 GRU'
- en: '#5 Passes the output of the last timestep to the fully connected layer'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将最后一个时间步的输出传递到全连接层'
- en: 6.5.2 Temporal adjacency matrices
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.2 时间邻接矩阵
- en: When considering temporal graphs, we might start with two nodes connected by
    one edge, then at each subsequent timestep, another few nodes and/or edges are
    added. This results in several distinct graphs, each with a differently sized
    adjacency matrix.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑时间图时，我们可能从一个由一条边连接的两个节点开始，然后在每个后续的时间步长中，再添加一些节点和/或边。这导致出现几个不同的图，每个图都有一个不同大小的邻接矩阵。
- en: This might present a difficulty when designing our GNN. First, we have different
    sized graphs at each timestep. This means we won’t be able to use node embeddings
    because the number of nodes will keep changing across input data. One method is
    to use graph embeddings at each timestep to store the entire graph as a low-dimensional
    representation. This method is at the heart of many temporal approaches, where
    graph embeddings are evolved in time rather than the actual graph. We can even
    use more complex transformations on our graph, such as using an autoencoder model
    as in our NRI model.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这在设计我们的GNN时可能会带来困难。首先，每个时间步长都有不同大小的图。这意味着我们无法使用节点嵌入，因为节点数量将在输入数据中不断变化。一种方法是使用每个时间步长的图嵌入来存储整个图作为一个低维度的表示。这种方法是许多时间方法的核心，在这些方法中，图嵌入随时间演变，而不是实际的图。我们甚至可以在我们的图上使用更复杂的变换，例如使用我们的NRI模型中的自动编码器模型。
- en: Alternatively, we can transform all the individual graphs at each timestep into
    one single larger graph by creating a temporal adjacency matrix. This involves
    wrapping each timestep into a single graph that spans both per-timestep data as
    well as dynamic temporal data. Temporal adjacency matrices can be useful if a
    graph is small and we’re only interested in a few timesteps in the future. However,
    they can often become very large and difficult to work with. On the other hand,
    using temporal embedding methods can often involve multiple complicated subcomponents
    and become difficult to train. Unfortunately, there is no one-size-fits-all temporal
    graph, and the best approach is almost always problem specific.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以通过创建时间邻接矩阵将每个时间步长的所有单个图转换成一个更大的图。这涉及到将每个时间步长包裹成一个单一的图，该图跨越了每个时间步长的数据以及动态时间数据。如果图很小，我们只对未来的几个时间步长感兴趣，时间邻接矩阵可能很有用。然而，它们通常变得非常大且难以处理。另一方面，使用时间嵌入方法通常涉及多个复杂的子组件，并且变得难以训练。不幸的是，没有一种适用于所有时间图的通用方法，最佳方法几乎总是特定于问题的。
- en: 6.5.3 Combining autoencoders with RNNs
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.3 将自动编码器与RNN结合
- en: In this section, to build intuition around the NRI model, we’ll summarize its
    components and illustrate its application in predicting graph structures and node
    trajectories. To start, in figure 6.19, we repeat the schematic for the NRI model.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，为了对NRI模型建立直观理解，我们将总结其组件并说明其在预测图结构和节点轨迹中的应用。首先，在图6.19中，我们重复了NRI模型的示意图。
- en: '![figure](../Images/6-19.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-19.png)'
- en: 'Figure 6.19 Schematic for NRI (Source: Kipf et al. [2]). The model consists
    of an encoder and decoder layer and several message-passing steps. However, here
    the messages are passed in the encoder from node to edge, back from edge to node,
    and then back from node to edge again. For the decoder, messages are passed from
    node to edge and then from edge to node. The final step takes the latent representation
    and is used to predict the next step in the temporal evolution of the body.'
  id: totrans-339
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.19 NRI的示意图（来源：Kipf等人[2]）。该模型由编码器和解码器层以及几个消息传递步骤组成。然而，在这里，消息是从节点传递到边，然后从边传递回节点，然后再从节点传递回边。对于解码器，消息是从节点传递到边，然后从边传递回节点。最后一步使用潜在表示，并用于预测身体时间演变的下一步。
- en: In this model, there are two key components. First, we train an encoder to encode
    the graphs from each frame into the latent space. Explicitly, we use the encoder
    to predict the probability distribution, q[j](z|x) over the latent interactions
    (z), given the initial graphs (x). Once we’ve trained the encoder, we then use
    the decoder to convert samples from this probability distribution into trajectories
    using the latent encoding as well as previous timesteps. In practice, we use the
    encoder-decoder structure to infer the trajectories of nodes with different interaction
    types (or edges).
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，有两个关键组件。首先，我们训练一个编码器将每个帧的图编码到潜在空间中。具体来说，我们使用编码器来预测给定初始图（x）的潜在交互（z）的概率分布q[j](z|x)。一旦我们训练了编码器，我们就使用解码器将这个概率分布的样本转换为轨迹，使用潜在编码以及之前的时间步长。在实践中，我们使用编码器-解码器结构来推断具有不同交互类型（或边）的节点的轨迹。
- en: 'In this chapter, we’ve only considered two edge types: where there is or isn’t
    a physical connection between sensors. However, this method can be scaled to consider
    many different connections, all changing with time. Additionally, the decoder
    model needs an RNN to effectively capture the temporal data in our graph. To build
    some intuition around the NRI model, let’s repeat the process once more.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只考虑了两种边类型：传感器之间是否存在物理连接。然而，这种方法可以扩展到考虑许多不同的连接，所有这些连接都会随时间变化。此外，解码器模型需要一个RNN来有效地捕获我们图中的时间数据。为了对NRI模型有一个直观的了解，让我们再次重复这个过程。
- en: '*Input *—Node data.'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*输入*—节点数据。'
- en: '*Encoding *—'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*编码*—'
- en: The encoder receives the node data.
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器接收节点数据。
- en: The encoder converts the node data into edge data.
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器将节点数据转换为边数据。
- en: The encoder represents the edge data in a latent space.
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码器在潜在空间中表示边数据。
- en: '*Latent space *—The latent space represents probabilities of different edge
    types. Here, we have two edge types (connected and not connected), though multiple
    edge types are possible for more complex relationships. We always need to include
    at least two types as otherwise the model would assume all the nodes are connected
    or, worse, none of them are.'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*潜在空间*—潜在空间表示不同边类型的概率。在这里，我们有两种边类型（连接和不连接），尽管对于更复杂的关系，可能存在多种边类型。我们始终需要包括至少两种类型，否则模型会假设所有节点都是连接的，或者更糟糕的是，没有任何节点是连接的。'
- en: '*Decoding *—'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*解码*—'
- en: The decoder takes the edge type probabilities from the latent space.
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码器从潜在空间中获取边类型概率。
- en: The decoder learns to reconstruct the future graph state based on these probabilities.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码器学习根据这些概率重建未来的图状态。
- en: '*Prediction *—The model predicts future trajectories by learning to predict
    graph connectivity.'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*预测*—模型通过学习预测图连通性来预测未来的轨迹。'
- en: Note that this model gives us graph and trajectory predictions simultaneously!
    While this might not be helpful for our problem, for cases where we don’t know
    the underlying graph structure such as social media networks or sports teams,
    this can provide ways to discover new interaction patterns in a system.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个模型同时给出了图和轨迹预测！虽然这可能对我们的问题没有帮助，但对于我们不知道底层图结构的情况，例如社交媒体网络或体育队伍，这可以提供发现系统中新交互模式的方法。
- en: 6.5.4 Gumbel-Softmax
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.4 Gumbel-Softmax
- en: In the NRI model, there is an additional step before calculating both of these
    losses, which is calculating the probability of an edge using Gumbel-Softmax.
    The key reason we need to introduce Gumbel-Softmax is that our autoencoder is
    learning to predict the adjacency matrix representing our edges, that is, the
    network connectivity, rather than the nodes and their features. Therefore, the
    end predictions for the autoencoder have to be discrete. However, we’re also inferring
    a probability. Gumbel-Softmax is a popular approach whenever probability data
    needs to be made discrete.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在NRI模型中，在计算这两个损失之前有一个额外的步骤，即使用Gumbel-Softmax计算边的概率。我们需要引入Gumbel-Softmax的关键原因是我们的自动编码器正在学习预测表示我们边的邻接矩阵，即网络连通性，而不是节点及其特征。因此，自动编码器的最终预测必须是离散的。然而，我们也在推断一个概率。当需要将概率数据离散化时，Gumbel-Softmax是一种流行的方法。
- en: Here, we have two discrete types of edges, that is, whether something is or
    isn’t connected. This means that our data is *categorical *—each edge is either
    in category 0 (isn’t connected) or category 1 (connected). Gumbel-Softmax is used
    to draw and score samples from a categorical distribution. In practice, Gumbel-Softmax
    will approximate the output from our encoder, which comes in the form of log probabilities
    or *logits*, as a Gumbel distribution, which is an extreme value distribution.
    This approximates the continuous distribution of our data as a discrete one (edge
    types) and allows us to then apply a loss function to the distribution.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有两种离散的边类型，即某物是否连接。这意味着我们的数据是*分类的*——每条边要么属于类别0（未连接），要么属于类别1（连接）。Gumbel-Softmax用于从分类分布中抽取和评分样本。在实践中，Gumbel-Softmax将逼近来自我们的编码器的输出，这种输出以对数概率或*logits*的形式出现，作为一个Gumbel分布，它是一种极值分布。这将近似我们的数据的连续分布为一个离散的分布（边类型），并允许我们随后对分布应用损失函数。
- en: The temperature of a Gumbel distribution, one of our hyperparameters, reflects
    the “sharpness” of the distribution, similar to how variance controls the sharpness
    of a Gaussian distribution. In this chapter, we used a temperature of 0.5, which
    is about medium sharpness. We also specify `Hard` as a hyperparameter, which denotes
    whether one or more categories exist. As discussed, we want it to have two categories
    when training to represent whether an edge exists. This allows us to approximate
    the distribution as a continuous one, and then we can backpropagate this through
    our network as a loss. However, when testing, we can set `Hard` to `True`, which
    means that there is only one category. This makes the distribution fully discrete,
    meaning we can’t optimize using the loss, as discrete variables are nondifferentiable
    by definition. This is a useful control to make sure that our test loop doesn’t
    propagate any gradients.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: Gumbel分布的温度，作为我们的超参数之一，反映了分布的“尖锐度”，类似于方差如何控制高斯分布的尖锐度。在本章中，我们使用了0.5的温度，这大约是中等尖锐度。我们还指定`Hard`作为超参数，表示是否存在一个或多个类别。如前所述，我们希望在训练时有两个类别来表示是否存在边。这允许我们将分布近似为连续的，然后我们可以将其作为损失通过我们的网络进行反向传播。然而，在测试时，我们可以将`Hard`设置为`True`，这意味着只有一个类别。这使得分布完全离散，意味着我们无法使用损失进行优化，因为离散变量在定义上是非可微的。这是一个有用的控制，以确保我们的测试循环不会传播任何梯度。
- en: Summary
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: While some systems can use single snapshots of data to make predictions, others
    need to consider changes in time to avoid errors or vulnerabilities.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然一些系统可以使用单一数据快照进行预测，但其他系统需要考虑时间的变化以避免错误或漏洞。
- en: Spatiotemporal GNNs consider previous timesteps to model how graphs evolve over
    time.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间时间GNNs考虑之前的时刻来模拟图随时间演变的方式。
- en: Spatiotemporal GNNs can solve pose-estimation problems where we predict the
    next position of the body given some data on how the body position was in the
    recent past. In this case, nodes represent sensors placed on body joints, and
    edges represent the body connections between joints.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间时间GNNs可以解决姿态估计问题，其中我们根据身体在最近过去的位置数据预测身体的下一个位置。在这种情况下，节点代表放置在身体关节上的传感器，边代表关节之间的身体连接。
- en: Adjacency matrices can be adapted to consider temporal information by concatenating
    different adjacency matrices along the diagonal.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邻接矩阵可以通过沿对角线连接不同的邻接矩阵来调整，以考虑时间信息。
- en: Memory can be introduced into models, including GNNs, such as by using a recurrent
    neural network (RNN) or a gated recurrent unit network (GRU).
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记忆可以被引入模型中，包括图神经网络（GNNs），例如通过使用循环神经网络（RNN）或门控循环单元网络（GRU）。
- en: The neural relational inference (NRI) model combines recurrent networks such
    as a GRU with autoencoder GNNs. These models can infer temporal patterns, even
    where adjacency information is unknown.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经关系推理（NRI）模型结合了循环网络，如GRU，与自动编码器GNNs。这些模型可以推断时间模式，即使相邻信息未知。
