- en: Chapter 1\. AI Is Magic
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 AI是魔法
- en: “Any sufficiently advanced technology is indistinguishable from magic.”
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “任何足够先进的技术都是不可区分的魔法。”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Arthur C. Clarke
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —亚瑟·克拉克
- en: OK, AI is not actual magic. The truth is AI is a step above and beyond other
    technology to the point that it *feels* like magic. It’s easy enough to explain
    an effective sorting algorithm, but digging into intelligence itself touches the
    third rail and zaps us all into a whole new level of technological power. That
    exponential power-up is made possible through the wisdom and aptitude of TensorFlow.js.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，AI并不是真正的魔法。事实上，AI是超越其他技术的一步，以至于它*感觉*像魔法。解释一个有效的排序算法是很容易的，但深入研究智能本身会触及第三导轨，将我们全部带入一个全新的技术力量水平。这种指数级的能力提升是通过TensorFlow.js的智慧和才能实现的。
- en: For more than half a century scientists and engineers have re-created the metaphorical
    wheel in AI and fine-tuned the mechanics that control it. When we dig into AI
    in this book, we’ll grasp those concepts with the flexible yet durable framework
    of TensorFlow.js and, with it, bring our ideas to fruition in the expanding domain
    of JavaScript. Yes, JavaScript, the world’s most popular programming language.^([1](ch01.html#idm45049261920904))
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家和工程师们在AI领域已经重新创造了比喻性的轮子，并调整了控制它的机制。当我们在本书中深入研究AI时，我们将用TensorFlow.js灵活而坚固的框架掌握这些概念，并借此将我们的想法实现在JavaScript不断扩展的领域中。是的，JavaScript，世界上最流行的编程语言。
- en: The concepts and definitions provided here will equip you with tech-ray vision.
    You’ll cut through acronyms and buzzwords to see and understand the AI infrastructure
    that’s been emerging in every field around us. AI and machine learning concepts
    will become clear, and the definitions from this chapter can serve as a reference
    for identifying core principles that will fuel our academic blastoff into TensorFlow.js
    illumination.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供的概念和定义将为您提供技术射线视野。您将能够穿透首字母缩略词和流行词汇，看到并理解我们周围各个领域中不断出现的AI基础设施。AI和机器学习概念将变得清晰，本章的定义可以作为识别核心原则的参考，这些原则将推动我们在TensorFlow.js的学术发展中启程。
- en: 'We will:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将：
- en: Clarify the domain of AI and intelligence
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 澄清AI和智能的领域
- en: Discuss the types of machine learning
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论机器学习的类型
- en: Review and define common terminology
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾和定义常见术语
- en: Cross-examine concepts through the lens of TensorFlow.js
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过TensorFlow.js的视角审视概念
- en: Let’s begin!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If you’re already familiar with TensorFlow.js and machine learning terminology,
    philosophy, and fundamental applications, you may want to skip directly to [Chapter 2](ch02.html#the_chapter_2).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经熟悉TensorFlow.js和机器学习术语、哲学和基本应用，您可能希望直接跳转到[第2章](ch02.html#the_chapter_2)。
- en: The Path of AI in JavaScript
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JavaScript中的AI之路
- en: TensorFlow.js, to put it in the most mundane definition possible, is a framework
    for handling specific AI concepts in JavaScript. That’s all. Luckily for you,
    you’re in the right book at the right time in history. The AI industrial revolution
    has only just begun.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js，简单来说，是一个处理JavaScript中特定AI概念的框架。就是这样。幸运的是，您在正确的书籍中，处于历史上正确的时刻。AI工业革命才刚刚开始。
- en: When computers came into being, a person armed with a computer could do and
    nearly impossible tasks at significant scale. They could crack codes, instantly
    recall information from mountains of data, and even play games as if they were
    playing another human. What *was* impossible for one person to do became not only
    possible but customary. Since the dawn of that key digital invention, our goal
    has been to empower computers to simply “do more.” As singular human beings, we
    are capable of anything, but not everything. Computers expanded our limitations
    in ways that gave us all newfound power. Many of us spend our lives honing a few
    skills, and among those, even fewer become our specialties. We all build a lifetime’s
    worth of achievements, and some of us rise to the best in the world at one thing,
    a skill that could only be earned with luck, information, and thousands of days
    of effort…until now.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机出现时，一个拥有计算机的人可以在显著的规模上执行几乎不可能的任务。他们可以破解密码，从大量数据中瞬间提取信息，甚至像与另一个人玩游戏一样。一个人无法做到的事情不仅变得可能，而且变得司空见惯。自数字发明诞生以来，我们的目标一直是赋予计算机更多的能力。作为独立的人类，我们能够做任何事情，但不是所有事情。计算机以一种扩展我们限制的方式使我们获得了新的力量。我们中的许多人花费一生来磨练一些技能，而在这些技能中，甚至更少的人成为我们的专长。我们都在建立一生的成就，我们中的一些人在某一领域成为世界上最优秀的人，这种技能只能通过运气、信息和成千上万天的努力获得...直到现在。
- en: AI enables us to skip to the front of the line; to boldly build that which has
    never been built before. Daily we’re seeing companies and researchers take that
    computational leap over and over again. We’re standing at the entrance of a new
    industry that invites us to play a part in how the world will change.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI使我们能够跳到队伍的最前面；大胆地建造以前从未建造过的东西。每天我们都看到公司和研究人员一次又一次地迈出计算的飞跃。我们站在一个新行业的入口处，邀请我们参与世界将如何改变的过程。
- en: You’re in the driver’s seat, headed to the next big thing, and this book is
    your steering wheel. Our journey in learning the magic of AI will be limited only
    by the extent of your imagination. Armed with JavaScript-enabled machine learning,
    you’re able to tap into with cameras, microphones, instant updates, locations,
    and other physical sensors, services, and devices!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您掌握着方向盘，驶向下一个大事件，而这本书就是您的方向盘。我们学习AI魔法的旅程只会受到您想象力的限制。借助启用JavaScript的机器学习，您可以利用摄像头、麦克风、即时更新、位置和其他物理传感器、服务和设备！
- en: I’m sure you’re asking, “But why hasn’t AI been doing this before? Why is this
    important now?” To appreciate that, you’ll need to take a trip into humanity’s
    search for reproduced intelligence.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你会问，“为什么以前AI没有做到这一点？为什么现在这很重要？”要理解这一点，你需要踏上人类对再现智能的探索之旅。
- en: What Is Intelligence?
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是智能？
- en: Books upon books can be written on the concepts of thought and especially the
    path toward machine intelligence. And as with all philosophical endeavors, each
    concrete statement on intelligence can be argued along the way. You don’t need
    to know everything with certainty, but we need to understand the domain of AI
    so we can understand how we landed in a book on TensorFlow.js.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关于思想的概念，尤其是通向机器智能的道路，可以写成一本又一本的书。就像所有哲学努力一样，关于智能的每一个具体陈述都可以在途中争论。你不需要对一切都有确定的了解，但我们需要了解AI的领域，这样我们才能理解我们是如何来到TensorFlow.js这本书中的。
- en: Poets and mathematicians throughout the centuries waxed that human thought was
    nothing more than the combination of preexisting concepts. The appearance of life
    was considered a machination of god-like design; we all are simply “made” from
    the elements. Stories from Greek mythology had the god of invention, Hephaestus,
    create automated bronze robots that walked and acted as soldiers. Basically, these
    were the first robots. The concept of robots and intelligence has rooted itself
    in our foundation as an ultimate and divine craft from this ancient lore. [Talos](https://oreil.ly/L8Ng2),
    the gigantic animated warrior, was famously programmed to guard the island of
    Crete. While there was no actual bronze robot, the story served as fuel for mechanical
    aspiration. For hundreds of years, animatronic antiquity was always considered
    a path to what would seem like human “intelligence,” and centuries later, we’re
    starting to see life imitate art. As a child, I remember going to my local Chuck
    E. Cheese, a popular restaurant in the United States with animatronic musical
    performances for children. I remember believing, just for a moment, that the puppet-powered
    electric concert that ran every day was real. I was inspired by the same spark
    that’s driven scientists to chase intelligence. This spark has always been there,
    passed through stories, entertainment, and now science.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 诗人和数学家们几个世纪以来一直在说，人类的思想不过是预先存在的概念的组合。生命的出现被认为是一种类似神的设计；我们都只是由元素“制造”而成。希腊神话中有发明之神赫淮斯托斯创造了能行走和行动如士兵般的自动铜制机器人。基本上，这些就是第一批机器人。机器人和智能的概念已经根植于我们的基础，作为古代传说中的终极和神圣的工艺。巨大的活力战士[塔洛斯](https://oreil.ly/L8Ng2)被著名地编程来守护克里特岛。虽然没有实际的铜制机器人，但这个故事为机械的志向提供了动力。数百年来，机械古代一直被认为是通往看似人类“智能”的途径，几个世纪后，我们开始看到生活在模仿艺术。小时候，我记得去我当地的Chuck
    E. Cheese，这是美国一家受欢迎的餐厅，为儿童提供动画音乐表演。我记得曾经相信，就在那一刻，每天播放的木偶驱动的电子音乐会是真实的。我被激发了，这种激发驱使科学家追逐智能。这种火花一直存在，通过故事、娱乐，现在又通过科学传递。
- en: As the concepts of machines that can work autonomously and intelligently grew
    through history, we strived to define these conceptual entities. Scholars continued
    to research inference and learning with published works, all the while keeping
    their terminology in the realm of “machine” and “robot.” The imitation of intelligence
    from machinery was always held back by the lack of speed and electricity.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随着能够自主工作和智能地工作的机器的概念在历史上不断发展，我们努力定义这些概念实体。学者们继续研究推理和学习，并出版作品，同时保持他们的术语在“机器”和“机器人”的领域内。机械智能的模仿总是受限于速度和电力的缺乏。
- en: The concept of intelligence stayed fixed in human minds and far out of the reach
    of mechanical structures for hundreds of years, until the creation of the ultimate
    machine, computers. Computing was born like most machines—with a single purpose
    for the entire device. With the advent of computing, a new term emerged to illustrate
    a growing advancement in intelligence that significantly mirrors human intellect.
    The term AI stands for artificial intelligence and wasn’t coined until the 1950s.^([2](ch01.html#idm45049261893832))
    As computers grew to become general-purpose, the philosophies and disciplines
    began to combine. The concept of imitating intelligence leaped from mythology
    into a scientific field of study. Each electronic measuring device for humankind
    became a new sensory organ for computers and an exciting opportunity for electronic
    and intelligent science.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 智能的概念在数百年来一直固定在人类思想中，远远超出了机械结构的范围，直到最终机器的诞生，计算机。计算机的诞生与大多数机器一样，都是为整个设备的单一目的而生。随着计算机的出现，一个新术语出现了，用来说明智能的不断增长，这在很大程度上反映了人类的智力。术语AI代表人工智能，直到20世纪50年代才被创造出来。随着计算机变得通用，哲学和学科开始结合。模仿智能的概念从神话中跃入科学研究领域。每一种为人类而设计的电子测量设备都成为计算机的新感官器官，也是电子和智能科学的一个令人兴奋的机会。
- en: In a relatively short time, we have computers interfacing with humans and emulating
    human actions. The imitation of human-like activity provided a form of what we’re
    willing to call “intelligence.” *Artificial intelligence* is that blanket term
    for these strategic actions, regardless of the level of sophistication or technique.
    A computer that can play tic-tac-toe doesn’t have to win to be categorized as
    AI. AI is a low bar and shouldn’t be confused with the general intelligence of
    a person. The smallest bit of simplistic code can be legitimate AI, and the apocalyptic
    uprise of sentient machines from Hollywood is also AI.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在相对较短的时间内，我们已经有了与人类交互并模拟人类行为的计算机。对人类活动的模仿提供了一种我们愿意称之为“智能”的形式。*人工智能*是这些战略行动的总称，无论其复杂程度或技术水平如何。一台可以下井字棋的计算机不必赢才能被归类为AI。AI是一个低门槛，不应与人类的一般智能混淆。最简单的代码片段也可以是合法的AI，而好莱坞电影中的有感情机器的末日也是AI。
- en: When the term AI is used, it’s an umbrella term for intelligence that comes
    from an inert and generally nonbiological device. Regardless of the minimal threshold
    for the term, mankind, armed with a field of study and an ever-growing practical
    use, has a unifying term and straightforward goal. All that is measured is managed,
    and so humankind began measuring, improving, and racing to greater AI.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用术语AI时，它是指来自一种惰性和通常非生物的设备的智能的总称。无论术语的最低门槛是什么，人类，拥有一门研究和一个不断增长的实际用途，都有一个统一的术语和明确的目标。所有被衡量的都被管理，因此人类开始衡量、改进并竞相追求更高级的AI。
- en: The History of AI
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI的历史
- en: Frameworks for AI started by being terribly specific, but that’s not the case
    today. As you may or may not know, the concepts of TensorFlow.js as a framework
    can apply to music, video, images, statistics, and whatever data we can amass.
    But it wasn’t always that way. Implementations of AI started as domain-specific
    code that lacked any kind of dynamic capability.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AI框架最初非常具体，但今天不再是这样。正如您可能知道或不知道的那样，TensorFlow.js作为一个框架的概念可以应用于音乐、视频、图像、统计数据以及我们可以收集的任何数据。但并非总是这样。AI的实现最初是缺乏任何动态能力的特定领域代码。
- en: There are a few jokes floating around on the internet that AI is just a collection
    of IF/THEN statements, and in my opinion, they’re not 100% wrong. As we’ve already
    mentioned, AI is a blanket term for all kinds of imitation of natural intelligence.
    Even beginning programmers are taught programming by solving simple AI in exercises
    like [Ruby Warrior](https://oreil.ly/ze9mi). These programming exercises teach
    fundamentals of algorithms, and require relatively little code. The cost for this
    simplicity is that while it’s still AI, it’s stuck mimicking the intelligence
    of a programmer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上有一些笑话流传，称AI只是一堆IF/THEN语句的集合，而在我看来，它们并不完全错误。正如我们已经提到的，AI是对自然智能各种模仿的总称。即使是初学者程序员也是通过解决简单的AI问题来学习编程，比如[Ruby
    Warrior](https://oreil.ly/ze9mi)。这些编程练习教授算法的基础知识，并且需要相对较少的代码。这种简单性的代价是，虽然它仍然是AI，但它被困在模仿程序员智能的境地。
- en: For a long time, the prominent method of enacting AI was dependent on the skills
    and philosophies of a person who programs an AI are directly translated into code
    so that a computer can enact the instructions. The digital logic is carrying out
    the human logic of the people who communicated to make the program. This is, of
    course, the largest delay in creating AI. You need a person who knows how to make
    a machine that knows, and we’re limited by their understanding and ability to
    translate that understanding. AIs that are hardcoded are unable to infer beyond
    their instructions. This is likely the biggest blocker to translating any human
    intelligence into artificial intelligence. If you’re looking to teach a machine
    how to play chess, how do you teach it chess theory? If you want to tell a program
    the difference between cats and dogs, something that’s trivial for toddlers, would
    you even know where to start with an algorithm?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 很长一段时间以来，实施AI的主要方法依赖于一个编写AI程序的人的技能和哲学，这些技能和哲学直接转化为代码，以便计算机执行指令。数字逻辑正在执行那些传达程序的人的人类逻辑。当然，这是创建AI的最大延迟。您需要一个知道如何制造懂得的机器的人，我们受到他们的理解和翻译能力的限制。硬编码的AI无法推断超出其指令。这很可能是将任何人类智慧转化为人工智能的最大障碍。如果您想教会机器下棋，您如何教它下棋理论？如果您想告诉程序区分猫和狗，对于幼儿来说是微不足道的事情，您甚至知道从哪里开始编写算法吗？
- en: At the end of the ’50s and beginning of the ’60s, the idea of the teacher shifted
    from humans to algorithms that could read raw data. Arthur Samuel coined the term
    *machine learning* (ML) in an event that unhinged the AI from the practical limitations
    of the creators. A program could grow to fit the data and grasp concepts that
    the programmers of that program either couldn’t translate into code or themselves
    never understood.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在50年代末和60年代初，教师的概念从人类转变为能够阅读原始数据的算法。阿瑟·塞缪尔在一个事件中创造了术语*机器学习*（ML），这个事件使AI摆脱了创作者的实际限制。一个程序可以根据数据增长并掌握程序员无法将其转化为代码或自己从未理解的概念。
- en: The concept of using data to train the application or function of a program
    was an exciting ambition. Still, in an age where computers required entire rooms
    and data was anything but digital, it was also an insurmountable request. Decades
    passed before computers reached the critical tipping point to emulate human like
    capabilities of information and architecture.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 利用数据来训练程序的应用或功能是一个令人兴奋的抱负。但在计算机需要整个房间而数据远非数字化的时代，这也是一个不可逾越的要求。几十年过去了，计算机才达到了模拟人类信息和架构能力的关键转折点。
- en: In the 2000s, ML researchers began using the graphics processing unit (GPU)
    to get around the “lone channel between the CPU and memory,” known as the *von
    Neumann bottleneck*. In 2006, Geoffrey Hinton et al. leveraged data and neural
    networks (a concept that we will cover in our next section) to understand the
    patterns and have a computer read handwritten digits. This was a feat that was
    previously too volatile and imperfect for common computing. *Deep learning* was
    capable of reading and adapting to the randomness of handwriting to correctly
    identify characters at a state-of-the-art level of over 98%. In these published
    papers, the idea of data as a training agent jumps from the published works of
    academia into reality.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000年代，机器学习研究人员开始使用图形处理单元（GPU）来绕过“CPU和内存之间的孤立通道”，即*冯·诺伊曼瓶颈*。2006年，杰弗里·辛顿等人利用数据和神经网络（我们将在下一节中介绍的概念）来理解模式，并让计算机读取手写数字。这是一个以前对于普通计算来说太不稳定和不完美的壮举。*深度学习*能够读取和适应手写的随机性，以正确识别字符的最先进水平超过98%。在这些发表的论文中，数据作为训练代理的概念从学术界的发表作品跃升到现实。
- en: While Hinton was stuck crafting a ground-up academic proof that neural networks
    work, the “What number is this?” problem became a stalwart for machine learning
    practitioners. The problem has become one of the key trivial examples for machine
    learning frameworks. TensorFlow.js has a [demo](https://oreil.ly/vsANx) that solves
    this problem directly in your browser in less than two minutes. With the benefits
    of TensorFlow.js we can easily construct advanced learning algorithms that work
    seamlessly on websites, servers, and devices. But what are these frameworks actually
    doing?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当Hinton陷入制作一个从头开始的学术证明神经网络有效的困境时，“这是什么数字？”问题成为机器学习实践者的一个支柱。这个问题已经成为机器学习框架的关键简单示例之一。TensorFlow.js有一个[演示](https://oreil.ly/vsANx)，可以在不到两分钟的时间内直接在您的浏览器中解决这个问题。借助TensorFlow.js的优势，我们可以轻松构建在网站、服务器和设备上无缝运行的高级学习算法。但这些框架实际上在做什么呢？
- en: The greatest goal of AI was always to approach or even outperform human-like
    capabilities in a single task, and 98% accuracy on handwriting did just that.
    Hinton’s research kindled a focus on these productive machine learning methods
    and coined industry terms like *deep neural networks*. We’ll elaborate on why
    in the next section, but this was the start of applied machine learning, which
    began to flourish and eventually find its way into machine learning frameworks
    like TensorFlow.js. While new machine-based learning algorithms are created left
    and right, one source of inspiration and terminology becomes quite clear. We can
    emulate our internal biological systems to create something advanced. Historically,
    we used ourselves and our cerebral cortex (a layer of our brains) as the muse
    for structured training and intelligence.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: AI的最大目标一直是接近甚至超越人类的能力，98%的手写识别准确率正是如此。Hinton的研究引发了对这些高效机器学习方法的关注，并创造了行业术语如*深度神经网络*。我们将在下一节详细说明原因，但这是应用机器学习的开始，它开始蓬勃发展，并最终进入了像TensorFlow.js这样的机器学习框架。虽然新的基于机器的学习算法不断被创造出来，但一个灵感和术语的来源变得非常清晰。我们可以模拟我们内部的生物系统来创造出一些先进的东西。从历史上看，我们使用自己和我们大脑的皮层（我们大脑的一层）作为结构化训练和智能的灵感来源。
- en: The Neural Network
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: The idea of deep neural networks was always inspired by our human bodies. The
    digital nodes (sometimes called a *perceptron network*) simulate neurons in our
    own brains and activate like our own synapses to create a balanced mechanism of
    thought. This is why a neural network is called *neural*, because it emulates
    our brain’s bio-chemical structure. Many data scientists abhor the analogy to
    the human brain, yet it often fits. By connecting millions of nodes, we can build
    deep neural networks that are elegant digital machines for making decisions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络的概念始终受到我们人类身体的启发。数字节点（有时称为*感知器网络*）模拟我们大脑中的神经元，并像我们自己的突触一样激活，以创建一种平衡的思维机制。这就是为什么神经网络被称为*神经*，因为它模拟了我们大脑的生物化学结构。许多数据科学家厌恶与人脑的类比，但它通常是合适的。通过连接数百万个节点，我们可以构建优雅的深度神经网络，这些网络是用于做出决策的优雅数字机器。
- en: By increasing the neural pathways with more and more layers, we arrive at the
    term *deep learning*. Deep learning is a vastly layered (or deep) connection of
    hidden layers of nodes. You’ll hear these nodes called *neurons*, *artificial
    neurons*, *units*, and even *perceptrons*. The diversity of terminology is a testament
    to the wide array of scientists who have contributed to machine learning.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通过增加更多层的神经通路，我们到达了*深度学习*这个术语。深度学习是一个庞大的层层连接的隐藏节点。您会听到这些节点被称为*神经元*、*人工神经元*、*单元*，甚至*感知器*。术语的多样性证明了为机器学习做出贡献的广泛科学家的广泛性。
- en: This entire field of learning is just part of AI. If you’ve been following along,
    artificial intelligence has a subset or branch that is called machine learning,
    and inside that set, we have the idea of deep learning. Deep learning is primarily
    a class of algorithms that fuel machine learning, but it’s not the only one. See
    [Figure 1-1](#deep_diagram) for a visual representation of these primary terms.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这整个学习领域只是AI的一部分。如果您一直在关注，人工智能有一个称为机器学习的子集或分支，在这个集合内，我们有深度学习的概念。深度学习主要是一类推动机器学习的算法，但不是唯一的一种。请参见[图1-1](#deep_diagram)以获得这些主要术语的视觉表示。
- en: '![AI levels](assets/ltjs_0101.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![AI水平](assets/ltjs_0101.png)'
- en: Figure 1-1\. AI subdomains
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. AI子领域
- en: Just like a human, an iteration of teaching or “training” is used to properly
    balance and build out the neurons based on examples and data. At first, these
    neural networks are often wrong and random, but as they see example after example
    of data, their predictive power “learns.”
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就像人类一样，通过示例和数据来适当平衡和构建神经元的迭代教学或“训练”被用来。起初，这些神经网络通常是错误和随机的，但随着他们看到一个又一个数据示例，他们的预测能力“学习”。
- en: But our brains don’t perceive the world directly. Much like a computer, we depend
    on electrical signals that have been organized into coherent data to be sent to
    our brain. For computers, these electrical signals are analogous to a *tensor*,
    but we’ll cover that a bit more in [Chapter 3](ch03.html#the_chapter_3). TensorFlow.js
    embodies all these advancements that research and scientists have confirmed. All
    these techniques that help human bodies perform can be wrapped up in an optimized
    framework so that we can leverage decades of research that have been inspired
    by the human body.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们的大脑并不直接感知世界。就像计算机一样，我们依赖于被组织成连贯数据发送到我们大脑的电信号。对于计算机来说，这些电信号类似于*张量*，但我们将在[第3章](ch03.html#the_chapter_3)中更详细地介绍这一点。TensorFlow.js体现了研究和科学家们已经确认的所有这些进步。所有这些帮助人体执行的技术都可以包装在一个优化的框架中，这样我们就可以利用几十年来受人体启发的研究。
- en: For instance, our visual system, which starts in our retinas, uses ganglions
    to relay photoreceptive information to our brain to activate these neurons. As
    some of you remember from children’s biology, we have missing spots in our vision,
    and technically we see everything upside down. The signal isn’t sent to our brains
    “as is.” This visual system has technology built into it that we leverage in today’s
    software.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的视觉系统从视网膜开始，使用神经节将光感信息传递到大脑，以激活这些神经元。正如一些人从儿童生物学中记得的那样，我们的视觉中有一些盲点，技术上我们看到的一切都是颠倒的。信号并不是“原样”发送到我们的大脑。这个视觉系统内置了技术，我们在今天的软件中利用了这些技术。
- en: While we’re all excited to get our 8K resolution TV, you might believe our brains
    and vision are still beyond modern computing capabilities, but that’s not always
    the case. The wire connecting visual signals from our eyes to our brain has only
    about 10 Mb of bandwidth. That’s comparable to LAN connections in the early 1980s.
    Even a streaming broadband connection demands more bandwidth than that. But we
    perceive everything instantly and quickly, right? So what’s the trick? How are
    we getting superior signals over this surpassed hardware? The answer is that our
    retinas compress and “featurize” the data before sending it to our deeply connected
    neural network. So that’s what we started doing with computers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们都很兴奋地迎接我们的8K分辨率电视，你可能认为我们的大脑和视觉仍然超出了现代计算能力，但情况并非总是如此。连接我们眼睛到大脑的视觉信号的神经通道只有大约10
    Mb的带宽。这相当于上世纪80年代初的局域网连接。即使是流媒体宽带连接也需要比这更多的带宽。但我们却能瞬间和迅速地感知一切，对吧？那么这是怎么做到的？我们是如何在这种过时的硬件上获得优越的信号的？答案是我们的视网膜在将数据发送到我们深度连接的神经网络之前对数据进行了压缩和“特征化”。这就是我们开始在计算机上做的事情。
- en: Convolutional neural networks (CNNs) work on visual data the same way our eyes
    and brains work together to compress and activate our neural pathways. You’ll
    further understand and write your own CNN in [Chapter 10](ch10.html#the_chapter_10).
    We’re learning more about how we work every day, and we’re applying those millions
    of years of evolution directly to our software. While it’s great for you to understand
    how these CNNs work, it’s far too academic to write them ourselves. TensorFlow.js
    comes with the convolutional layers you’ll need to process images. This is the
    fundamental benefit of leveraging a machine learning framework.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）在视觉数据上的工作方式与我们的眼睛和大脑一起压缩和激活我们的神经通路的方式相同。您将在[第10章](ch10.html#the_chapter_10)中进一步了解并编写自己的CNN。我们每天都在了解我们的工作方式，并将这数百万年的进化直接应用于我们的软件。虽然了解这些CNN如何工作对您很有好处，但自己编写它们太学术化了。TensorFlow.js带有您需要处理图像的卷积层。这是利用机器学习框架的基本好处。
- en: 'You can spend years reading and researching all the unique tricks and hacks
    that make computer vision, neural networks, and human beings function effectively.
    But we’re in an era where these roots have had time to grow, branch, and finally
    produce fruit: these advanced concepts are accessible and built into services
    and devices all around us.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以花费数年时间阅读和研究使计算机视觉、神经网络和人类有效运作的所有独特技巧和黑客技术。但我们生活在一个这些根源已经有时间生长、分支并最终结果的时代：这些先进的概念是可访问的，并内置在我们周围的服务和设备中。
- en: Today’s AI
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 今天的人工智能
- en: Today we use these best practices with AI to empower machine learning. Convolutions
    for edge detection, attention to some regions more than others, and even multi-camera
    inputs for a singular item have given us a prechewed gold mine of data over a
    fiber-optic server farm of cloud machines training AI.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们使用这些最佳实践与人工智能相结合，以增强机器学习。卷积用于边缘检测，对某些区域的关注超过其他区域，甚至为一个单一项目提供多摄像头输入，为我们提供了一个在云机器训练AI的光纤服务器农场中的预先处理的数据宝库。
- en: In 2015 AI algorithms began outperforming humans in some visual tasks. As you
    might have heard in the news, AI has surpassed humans in [cancer detection](https://oreil.ly/ZCz0B)
    and even outperformed the US’s top lawyers in identifying [legal flaws](https://oreil.ly/9dW3S).
    As always with digital information, AI has done this in seconds, not hours. The
    “magic” of AI is awe-inspiring.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年，AI算法开始在某些视觉任务中胜过人类。正如你可能在新闻中听说的那样，AI已经在[癌症检测](https://oreil.ly/ZCz0B)方面超越了人类，甚至在识别[法律缺陷](https://oreil.ly/9dW3S)方面超过了美国顶级律师。正如数字信息一样，AI在几秒钟内完成了这些任务，而不是几小时。AI的“魔力”令人惊叹。
- en: People have been finding new and interesting ways to apply AI to their projects
    and even create completely new industries.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 人们一直在寻找将人工智能应用于他们的项目的新颖有趣的方法，甚至创造全新的行业。
- en: 'AI has been applied to:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: AI已被应用于：
- en: Generating new content in writing, music, and visuals
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成写作、音乐和视觉方面的新内容
- en: Recommending useful content
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐有用的内容
- en: Replacing simple statistics models
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取代简单的统计模型
- en: Deducing laws from data
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据中推断法则
- en: Visualizing classifiers and identifiers
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化分类器和识别器
- en: All of these breakthroughs have been aspects of deep learning. Today we have
    the necessary hardware, software, and data to enable groundbreaking changes with
    deep machine learning networks. Each day, community and *Fortune* 500 companies
    alike release new datasets, services, and architectural breakthroughs in the field
    of AI.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些突破都是深度学习的方面。今天我们拥有必要的硬件、软件和数据，可以通过深度机器学习网络实现突破性的变革。每天，社区和《财富》500强公司都在人工智能领域发布新的数据集、服务和架构突破。
- en: With the tools at your disposal and the knowledge in this book, you can easily
    create things that have never been seen before and bring them to the web. Be it
    for pleasure, science, or fortune, you can create a scalable, intelligent solution
    for any real-world problem or business.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借您手头的工具和本书中的知识，您可以轻松地创造以前从未见过的东西，并将其带到网络上。无论是为了娱乐、科学还是财富，您都可以为任何现实世界问题或业务创建一个可扩展的智能解决方案。
- en: If anything, the current problem with machine learning is that it’s a new superpower,
    and the world is vast. We don’t have enough examples to understand the full benefits
    of having AI in JavaScript. When batteries made a significant improvement in life
    span, they enabled a whole new world of devices, from more powerful phones to
    cameras that could last for months on a single charge. This single breakthrough
    brought countless new products to the market in only a few years. Machine learning
    makes breakthroughs constantly, leaving a whirl of advancement in new technology
    that we can’t even clarify or recognize because the deluge has exponentially accelerated.
    This book will focus on concrete *and* abstract examples in proper measure, so
    you can apply pragmatic solutions with TensorFlow.js.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果说目前机器学习的问题是它是一种新的超级能力，而世界是广阔的。我们没有足够的例子来理解在JavaScript中拥有人工智能的全部好处。当电池寿命有了显著改善时，它们为更强大的手机和相机等设备带来了一个全新的世界，这些设备可以在单次充电的情况下持续数月。这一突破带来了数年内市场上无数新产品。机器学习不断取得突破，带来了新技术的飞速发展，我们甚至无法澄清或认识到这种洪流的加速。本书将重点介绍具体和抽象的例子，以便您可以使用TensorFlow.js应用实用解决方案。
- en: Why TensorFlow.js?
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择TensorFlow.js？
- en: You have options. You could write your own machine learning model from scratch
    or choose from any existing framework in a variety of programming languages. Even
    in the realm of JavaScript, there are already competing frameworks, examples,
    and options. What makes TensorFlow.js capable of handling and carrying today’s
    AI?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您有选择。您可以从头开始编写自己的机器学习模型，也可以选择各种编程语言中的任何现有框架。即使在JavaScript领域，已经存在竞争框架、示例和选项。是什么使TensorFlow.js能够处理和承载今天的人工智能？
- en: Significant Support
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重要支持
- en: TensorFlow.js is created and maintained by Google. We’ll cover more about this
    in [Chapter 2](ch02.html#the_chapter_2), but it’s worth noting that some of the
    best developers in the world have come together to make TensorFlow.js happen.
    This also means, without any effort by the community, TensorFlow.js is capable
    of working with the latest and greatest groundbreaking developments.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js由Google创建和维护。我们将在[第2章](ch02.html#the_chapter_2)中更多地介绍这一点，但值得注意的是，世界上一些最优秀的开发人员已经齐心协力使TensorFlow.js成为可能。这也意味着，即使没有社区的努力，TensorFlow.js也能够与最新和最伟大的突破性发展一起工作。
- en: Unlike other JavaScript-based implementations of machine learning libraries
    and frameworks, TensorFlow.js supports optimized and tested GPU-accelerated code.
    This optimization is passed on to you and your machine learning projects.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他基于JavaScript的机器学习库和框架实现不同，TensorFlow.js支持经过优化和测试的GPU加速代码。这种优化传递给您和您的机器学习项目。
- en: Online Ready
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线就绪
- en: Most machine learning solutions are confined to a machine that is extremely
    customized. If you wanted to make a website to share your breakthrough technology,
    the AI is commonly locked behind an API. While this is completely doable with
    TensorFlow.js running in Node.js, it’s also doable with TensorFlow.js running
    directly in the browser. This no-install experience is rare in the world of machine
    learning, which gives you the ability to share your creations without barriers.
    You’re able to version and access a world of interactivity.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习解决方案都限制在一个非常定制的机器上。如果您想要创建一个网站来分享您的突破性技术，人工智能通常被锁在API后面。虽然在Node.js中运行TensorFlow.js是完全可行的，但在浏览器中直接运行TensorFlow.js也是可行的。这种无需安装的体验在机器学习领域是罕见的，这使您能够无障碍地分享您的创作。您可以版本化并访问丰富的互动世界。
- en: Offline Ready
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离线就绪
- en: Another benefit of JavaScript is that it runs everywhere. The code can be saved
    to the user’s device like a progressive web app (PWA), Electron, or React Native
    application, and then it can function consistently without any internet connection.
    It goes without saying that this also provides a significant speed and cost boost
    compared to hosted AI solutions. In this book, you’ll uncover countless examples
    that exist entirely on browsers that save you and your users from latency delays
    and hosting costs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript的另一个好处是它可以在任何地方运行。代码可以保存到用户的设备上，如渐进式Web应用程序（PWA）、Electron或React Native应用程序，然后可以在没有任何互联网连接的情况下始终如一地运行。不言而喻的是，与托管的AI解决方案相比，这也提供了显著的速度和成本提升。在本书中，您将发现许多完全存在于浏览器中的例子，这些例子可以使您和您的用户免受延迟和托管成本的困扰。
- en: Privacy
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私
- en: AI can help users identify diseases, tax anomalies, and other personal information.
    Sending sensitive data across the internet can be dangerous. On-device results
    stay on-device. You can even train an AI and store the results on the user’s machine
    with zero information ever leaving the safety of the browser.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可以帮助用户识别疾病、税收异常和其他个人信息。通过互联网发送敏感数据可能存在危险。设备上的结果保留在设备上。甚至可以训练一个人工智能并将结果存储在用户的设备上，而没有任何信息离开浏览器的安全性。
- en: Diversity
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多样性
- en: Applied TensorFlow.js has a powerful and broad stroke across the machine learning
    domain and platforms. TensorFlow.js can take advantage of running Web Assembly
    for CPUs or GPUs for beefier machines. The spectrum of AI with machine learning
    today is a significant and vast world of new terminology and complexity for newcomers.
    Having a framework that works with a variety of data is useful as it keeps your
    options open.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 应用TensorFlow.js在机器学习领域和平台上具有强大而广泛的影响。TensorFlow.js可以利用Web Assembly在CPU或GPU上运行，适用于性能更强大的机器。如今的机器学习AI领域的光谱对于新手来说是一个重要而庞大的新术语和复杂性的世界。拥有一个可以处理各种数据的框架是有用的，因为它保持了您的选择。
- en: Mastery of TensorFlow.js allows you to apply your skills to a wide variety of
    platforms that support JavaScript (see [Figure 1-2](#anywhere)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 精通TensorFlow.js使您能够将您的技能应用于支持JavaScript的各种平台（请参阅[图1-2](#anywhere)）。
- en: '![Demonstration of multiple platforms for TFJS.](assets/ltjs_0102.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![TFJS的多平台演示。](assets/ltjs_0102.png)'
- en: Figure 1-2\. TensorFlow.js platforms
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. TensorFlow.js平台
- en: With TensorFlow.js you’re free to choose, prototype, and deploy your skills
    to a variety of fields. To take full advantage of your machine learning freedom,
    you’ll need to get your footing with some terms that can help you launch into
    machine learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow.js，您可以自由选择、原型设计和部署您的技能到各种领域。为了充分利用您的机器学习自由度，您需要了解一些术语，这些术语可以帮助您进入机器学习领域。
- en: Types of Machine Learning
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习类型
- en: 'Lots of people break machine learning into three categories, but I believe
    we need to look at all of ML as four significant elements:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人将机器学习分为三类，但我认为我们需要将所有机器学习视为四个重要元素：
- en: Supervised
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督
- en: Unsupervised
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督
- en: Semisupervised
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督
- en: Reinforcement
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化
- en: Each of these elements deserves books upon books. The short definitions that
    follow are simple references to familiarize you with the terms you’ll hear in
    the field.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个元素都值得写成一本书。接下来的简短定义只是为了让您熟悉这个领域中会听到的术语。
- en: 'Quick Definition: Supervised Learning'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速定义：监督学习
- en: In this book, we’ll focus on the most common category of machine learning, *supervised
    machine learning* (sometimes called *supervised learning* or just *supervised*
    for short). Supervised ML simply means that we have an answer key for every question
    we’re using to train our machine. That is to say, our data is labeled. So if we’re
    trying to teach a machine to distinguish if a photo contains a bird, we can immediately
    grade the AI on whether it was right or wrong. Like a Scantron, we have the answer
    key. But unlike a Scantron and because it’s probability math, we can also identify
    how wrong the answer was.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将重点放在最常见的机器学习类别上，即*监督机器学习*（有时简称为*监督学习*或简称为*监督*）。监督机器学习简单地意味着我们对用于训练机器的每个问题都有一个答案。换句话说，我们的数据是有标签的。因此，如果我们试图教会机器区分一张照片是否包含鸟类，我们可以立即根据AI的答案是对还是错来评分。就像使用Scantron一样，我们有答案。但与Scantron不同的是，由于这是概率数学，我们还可以确定答案有多错。
- en: If an AI is 90% sure a photo of a bird is a bird, while it got the answer right,
    it could improve by 10%. This illuminates the “training” aspect of the AI with
    immediate data-driven gratification.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI对一张鸟类照片有90%的确定性，虽然它回答正确，但还可以提高10%。这突显了AI的“训练”方面，即通过即时数据驱动的满足感。
- en: Tip
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Don’t worry if you don’t have hundreds of ready-to-go labeled questions and
    answers. In this book, we’ll either provide you with labeled data or show you
    how to generate it yourself.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有成百上千个现成的标记问题和答案，也不用担心。在这本书中，我们要么为您提供标记数据，要么向您展示如何自己生成数据。
- en: 'Quick Definition: Unsupervised Learning'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速定义：无监督学习
- en: Unsupervised learning doesn’t require us to have an answer key. We only need
    questions. Unsupervised machine learning would be ideal, as most information in
    the world does not come with labels. This category of machine learning focuses
    on what a machine could learn and report from unlabeled data. While this subject
    might seem a bit confusing, humans perform it every day! For instance, if I gave
    you a photo of my garden and asked you how many different types of plants I own,
    you could tell me the answer, and you don’t have to know the genus and species
    of each plant. It’s a bit of how we make sense of our own worlds. A lot of unsupervised
    learning is focused on categorizing large amounts of data for use.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习不需要我们有答案。我们只需要问题。无监督机器学习是理想的，因为世界上大多数信息都没有标签。这类机器学习侧重于机器可以从未标记数据中学习和报告的内容。虽然这个主题可能有点令人困惑，但人类每天都在执行它！例如，如果我给你一张我的花园照片，并问你我拥有多少种不同类型的植物，你可以告诉我答案，而不必知道每株植物的属种。这有点类似于我们如何理解自己的世界。很多无监督学习都集中在对大量数据进行分类上。
- en: 'Quick Definition: Semisupervised Learning'
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速定义：半监督学习
- en: Most of the time, we don’t live with 100% unlabeled data. To bring back the
    garden example from earlier, you don’t know the genus and species of each plant,
    but you’re also not completely unable to classify the plants as As and Bs. You
    might tell me I have ten plants made up of three flowers and seven herbs. Having
    a small number of known labels goes a long way, and research today is on fire
    with semisupervised breakthroughs!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，我们并不是在处理100%未标记的数据。回到之前的花园例子，你可能不知道每株植物的属种，但也不完全无法对植物进行分类为A和B。你可能告诉我，我有十株植物，其中三株是花，七株是草本植物。拥有少量已知标签可以帮助很多，当今的研究在半监督突破方面取得了巨大进展！
- en: You might have heard the term *generative networks* or *generative adversarial
    networks* (GANs). These popular AI constructs are mentioned in numerous AI news
    articles and are derived from semisupervised learning tactics. Generative networks
    are trained on examples of what we would like the network to create, and through
    a semisupervised method, new examples are constructed. Generative networks are
    excellent at creating new content from a small subset of labeled data. Popular
    examples of GANs often get their own websites, like [*https://thispersondoesnotexist.com*](https://thispersondoesnotexist.com)
    are growing in popularity, and creatives are having a field day with semisupervised
    output.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能听说过术语*生成网络*或*生成对抗网络*（GANs）。这些流行的AI构造在许多AI新闻文章中被提及，并源自半监督学习策略。生成网络是根据我们希望网络创建的示例进行训练的，通过半监督方法，可以构建新的示例。生成网络非常擅长从少量标记数据中创建新内容。流行的GAN的例子通常有自己的网站，比如[*https://thispersondoesnotexist.com*](https://thispersondoesnotexist.com)，越来越受欢迎，创意人员正在享受半监督输出带来的乐趣。
- en: Note
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: GANs have been significant in generating new content. While popular GANs are
    semisupervised, the deeper concept of a GAN is not limited to semisupervised networks.
    People have adapted GANs to work on every type of learning we’ve defined.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: GAN在生成新内容方面发挥了重要作用。虽然流行的GAN是半监督的，但GAN的更深层概念并不局限于半监督网络。人们已经将GAN调整为适用于我们定义的每种学习类型。
- en: 'Quick Definition: Reinforcement Learning'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速定义：强化学习
- en: The simplest way to explain reinforcement learning is to show that it’s needed
    by handling a more real-world activity, versus the hypothetical constructs from
    earlier.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 解释强化学习最简单的方法是展示它在处理更真实的活动时是必需的，而不是之前的假设构造。
- en: For instance, if we’re playing chess and I start my game by moving a pawn, was
    that a good move or a bad move? Or if I want a robot to kick a ball through a
    hoop, and it starts by taking a step, is that good or bad? Just like with a human,
    the answer depends on the results. It’s a collection of moves for maximum reward,
    and there’s not always a singular action that produces a singular result. Training
    a robot to step first or look first matters, but probably not as much as what
    it does during other critical moments. And those critical moments are all powered
    by rewards as reinforcement.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们在下棋时，我开始游戏时移动一个兵，那是一个好动作还是坏动作？或者如果我想让一个机器人把球踢进篮筐，它开始迈步，这是好还是坏？就像对待人类一样，答案取决于结果。这是为了最大奖励而采取的一系列动作，不总是有一个动作会产生一个结果。训练机器人首先迈步或首先看很重要，但可能不如在其他关键时刻所做的事情重要。而这些关键时刻都是由奖励作为强化来驱动的。
- en: If I were teaching an AI to play *Super Mario Bros.*, do I want a high score
    or a speedy victory? The rewards teach the AI what combination of moves is optimal
    to maximize the goal. Reinforcement learning (RL) is an expanding field and has
    often been combined with other forms of AI to cultivate the maximum result.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我要教一个AI玩《超级马里奥兄弟》，我想要高分还是快速胜利？奖励教会AI什么组合动作是最优化的以实现目标。强化学习（RL）是一个不断发展的领域，经常与其他形式的人工智能结合以培养最大的结果。
- en: Information Overload
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信息过载
- en: It’s OK to be surprised by how many applications of machine learning were just
    mentioned. In a way, that’s why we’re in need of a framework like TensorFlow.js.
    We can’t even comprehend all the uses of these fantastic systems and their effects
    for decades to come! While we wrap our heads around this, the age of AI and ML
    is here, and we’re going to be part of it. Supervised learning is a great first
    step into all the benefits of AI.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于刚提到的机器学习的许多应用，感到惊讶是可以的。在某种程度上，这就是为什么我们需要像TensorFlow.js这样的框架。我们甚至无法理解所有这些奇妙系统的用途及其未来几十年的影响！在我们理解这一切的同时，人工智能和机器学习的时代已经到来，我们将成为其中的一部分。监督学习是进入人工智能所有好处的一个很好的第一步。
- en: 'We’ll cover some of the most exciting yet practical uses of machine learning
    together. In some aspects, we’ll only scratch the surface, while in others, we’ll
    dive deep into the heart of how they work. Here are some of the broad categories
    we’ll cover. These are all supervised learning concepts:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一起探讨一些最令人兴奋但实用的机器学习用途。在某些方面，我们只会触及表面，而在其他方面，我们将深入探讨它们的工作原理。以下是我们将涵盖的一些广泛类别。这些都是监督学习概念：
- en: Image categorization
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类
- en: Natural language processing (NLP)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）
- en: Image segmentation
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分割
- en: One of the main goals of this book is that while you can understand the concepts
    of the categories, you won’t be limited by them. We’ll lean into experimentation
    and practical science. Some problems can be solved by overengineering, and others
    can be solved by data engineering. Thinking in AI and machine learning is the
    key to seeing, identifying, and creating new tools with TensorFlow.js.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的主要目标之一是，虽然你可以理解这些类别的概念，但不会受到限制。我们将倾向于实验和实践科学。有些问题可以通过过度工程解决，而有些问题可以通过数据工程解决。AI和机器学习的思维是看到、识别和创建新工具的关键。
- en: AI Is Everywhere
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能无处不在
- en: We’re entering a world where AI is creeping into everything. Our phones are
    now accelerated into deep learning hardware. Cameras are applying real-time AI
    detection, and at the time of this writing, some cars are driving around our streets
    without a human being.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在进入一个人工智能渗透到一切的世界。我们的手机现在已经加速到深度学习硬件。摄像头正在应用实时人工智能检测，而在撰写本文时，一些汽车正在街上行驶，没有人类驾驶员。
- en: In the past year, I’ve even noticed my emails have started writing themselves
    with a “tab to complete” option for finishing my sentences. This feature, more
    often than I’d like to admit, is clearer and more concise than anything I would
    have originally written. It’s a significant visible achievement that overshadows
    the forgotten machine learning AI that’s been protecting us from spam in that
    same inbox for years.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的一年中，我甚至注意到我的电子邮件已经开始自动写作，提供了一个“按Tab键完成”选项来完成我的句子。这个功能，比我最初写的任何东西更清晰更简洁，这是一个显著的可见成就，超过了多年来一直在同一个收件箱中保护我们免受垃圾邮件的被遗忘的机器学习AI。
- en: As each of these plans for machine learning unfurl, new platforms become in
    demand. We’re pushing models further and further on edge devices like phones,
    browsers, and hardware. It makes sense that we’re looking for new languages to
    carry the torch. It was only a matter of time before the search would end with
    the obvious option of JavaScript.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每个机器学习计划的展开，新的平台变得需求量大。我们正在将模型推向边缘设备，如手机、浏览器和硬件。寻找新语言来传承是合理的。很快搜索就会以JavaScript为明显选择。
- en: A Tour of What Frameworks Provide
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 框架提供的一次导览
- en: What does machine learning look like? Here’s an accurate description that will
    make Ph.D. students cringe with its succinct simplicity.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是什么样子？以下是一个准确的描述，会让博士生因其简洁而感到不安。
- en: With normal code, a human writes the code directly, and a computer reads and
    interprets that code, or some derivative of it. Now we’re in a world where a human
    doesn’t write the algorithm, so what actually happens? Where does the algorithm
    come from?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常的代码中，人类直接编写代码，计算机读取和解释该代码，或者读取其某种派生形式。现在我们处于一个人类不编写算法的世界，那么实际发生了什么？算法从哪里来？
- en: It’s simply one extra step. A human writes the algorithm’s trainer. Assisted
    by a framework, or even from scratch, a human outlines in code the parameters
    of the problem, the desired structure, and the location of the data to learn from.
    Now the machine runs this program-training program, which continuously writes
    an ever-improving algorithm as the solution to that problem. At some point, you
    stop this program and take the latest algorithm result out and use it.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个额外的步骤。一个人编写算法的训练器。在框架的帮助下，甚至从头开始，一个人在代码中概述了问题的参数、所需的结构和要学习的数据的位置。现在，机器运行这个程序训练程序，不断地编写一个不断改进的算法作为解决问题的解决方案。在某个时候，您停止这个程序，取出最新的算法结果并使用它。
- en: '*That’s it!*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*就是这样！*'
- en: The algorithm is much smaller than the data that was used to create it. Gigabytes
    of movies and images can be used to train a machine learning solution for weeks,
    all just to create a few megabytes of data to solve a very specific problem.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 算法比用于创建它的数据要小得多。数千兆字节的电影和图像可以用来训练一个机器学习解决方案数周，所有这些只是为了创建几兆字节的数据来解决一个非常具体的问题。
- en: The resulting algorithm is essentially a collection of numbers that balance
    the outlined structure identified by the human programmer. The collection of numbers
    and their associated neural graph is often called a *model*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的算法本质上是一组数字，这些数字平衡了人类程序员所确定的结构。这组数字及其相关的神经图通常被称为*模型*。
- en: You’ve probably seen these graphs surfacing in technical articles, drawn as
    a collection of nodes from left to right like [Figure 1-3](#nn_example).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经在技术文章中看到这些图表，它们被绘制为从左到右的一组节点，就像[图1-3](#nn_example)。
- en: '![Neural Network](assets/ltjs_0103.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络](assets/ltjs_0103.png)'
- en: Figure 1-3\. Example of a densely connected neural network
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 密集连接神经网络的示例
- en: Our framework TensorFlow.js handles the API for specifying the structure or
    architecture of the model, loading data, passing data through our machine learning
    process, and ultimately tuning the machine to be better at predicting answers
    to the given input the next time. This is where the real benefits of TensorFlow.js
    come to bear. All we have to worry about is properly tuning the framework to solve
    the problem with sufficient data and then saving the resulting model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架TensorFlow.js处理了指定模型结构或架构的API，加载数据，通过我们的机器学习过程传递数据，并最终调整机器以更好地预测下次给定输入的答案。这就是TensorFlow.js真正的好处所在。我们只需要担心正确调整框架以解决问题，并保存生成的模型。
- en: What Is a Model?
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是模型？
- en: When you create a neural network in TensorFlow.js, it’s a code representation
    of the desired neural network. The framework generates a graph with intelligently
    selected randomized values for each neuron. The model’s file size is generally
    fixed at this point, but the contents will evolve. When a prediction is made by
    shoving data through an untrained network of random values, we get an answer that
    is generally as far away from the right answer as pure random chance. Our model
    hasn’t trained on any data, so it’s terrible at its job. So as a developer, our
    code that we write is complete, but the untrained result is poor.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在TensorFlow.js中创建一个神经网络时，它是所需神经网络的代码表示。该框架为每个神经元智能选择随机值生成一个图。此时，模型的文件大小通常是固定的，但内容会发展。当通过将数据传递给一个未经训练的具有随机值的网络进行预测时，我们得到的答案通常与正确答案相去甚远，就像纯随机机会一样。我们的模型没有经过任何数据训练，所以在工作中表现糟糕。因此，作为开发人员，我们编写的代码是完整的，但未经训练的结果很差。
- en: Once training iterations have occurred for some significant amount of time,
    the neural network weights are evaluated and then adjusted. The speed, often called
    the *learning rate*, affects the resulting solution. After taking thousands of
    these small steps at the learning rate, we start to see a machine that improves,
    and we are engineering a model with the probability of success far beyond the
    original machine. We have left randomness and converged on numbers that make the
    neural network work! Those numbers assigned to the neurons in a given structure
    are the trained model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练迭代发生了相当长的一段时间，神经网络的权重就会被评估然后调整。速度，通常被称为*学习率*，会影响结果。在以学习率为步长进行数千次这样的小步骤后，我们开始看到一个不断改进的机器，我们正在设计一个成功概率远远超出原始机器的模型。我们已经摆脱了随机性，收敛于使神经网络工作的数字！分配给给定结构中的神经元的那些数字就是训练好的模型。
- en: TensorFlow.js knows how to keep track of all these numbers and computational
    graphs so we don’t have to, and it also knows how to store this information in
    a proper and consumable format.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js知道如何跟踪所有这些数字和计算图，所以我们不必，它还知道如何以适当和可消费的格式存储这些信息。
- en: Once you have those numbers, our neural network model can stop training and
    just be used to make predictions. In programming terms, this has become a simple
    function. Data goes in, and data comes out.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您获得了这些数字，我们的神经网络模型就可以停止训练，只用来进行预测。在编程术语中，这已经变成了一个简单的函数。数据进去，数据出来。
- en: Feeding data through a neural network looks a lot like chance, as shown in [Figure 1-4](#nn_categorization),
    but in the world of computing it’s a delicate machine of balanced probability
    and sorting that has consistent and reproducible results. Data gets fed into the
    machine, and a probabilistic result comes out.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通过神经网络传递数据看起来很像机会，如[图1-4](#nn_categorization)所示，但在计算世界中，这是一个平衡概率和排序的精密机器，具有一致和可重复的结果。数据被输入到机器中，然后得到一个概率性的结果。
- en: '![Neural Network Categorizing](assets/ltjs_0104.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络分类](assets/ltjs_0104.png)'
- en: Figure 1-4\. A balanced network metaphor
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4. 一个平衡的网络隐喻
- en: In the next chapter, we’ll experiment with importing and predicting with an
    entirely trained model. We’ll utilize the power of hours of training to get an
    intelligent analysis in microseconds.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将尝试导入并使用一个完全训练好的模型进行预测。我们将利用数小时的训练来在微秒内得到智能分析。
- en: In This Book
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本书中
- en: This book is constructed so that you could pack it away for a vacation and,
    once you’ve found your small slice of heaven, read along with the book, learn
    the concepts, and review the answers. The images and screenshots should suffice
    for explaining the deep underbelly of TensorFlow.js.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的结构使您可以将其收起放在度假中，一旦找到您的小天堂，就可以跟着书本阅读，学习概念，并审查答案。图像和截图应该足以解释TensorFlow.js的深层原理。
- en: However, for you to really grasp the concepts, you’ll need to go beyond simply
    reading the book. As each concept unfolds, you should be coding, experimenting,
    and testing the boundaries of TensorFlow.js on an actual computer. For any of
    you who are new to machine learning as a field, it’s essential that you solidify
    the terminology and workflows you’re seeing for the first time. Take your time
    to work through the concepts and code from this book.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要真正掌握这些概念，您需要超越简单地阅读本书。随着每个概念的展开，您应该编写代码，进行实验，并在实际计算机上测试TensorFlow.js的边界。对于那些作为机器学习领域的新手的人来说，重要的是您巩固您第一次看到的术语和工作流程。花时间逐步学习本书中的概念和代码。
- en: Associated Code
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关代码
- en: Throughout the book, there is runnable source code to illustrate the lessons
    and functionality of TensorFlow.js. While in some cases the entire source is provided,
    in most cases the printed code will be limited to the salient portions. It’s advisable
    that you immediately download the source code that aligns with this book. Even
    if you plan on writing code from scratch alongside the examples, it’s likely that
    small configurations that you may struggle with will already be solved and referenceable
    in the associated code.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，有可运行的源代码来说明TensorFlow.js的课程和功能。在某些情况下提供整个源代码，但在大多数情况下，打印的代码将仅限于重要部分。建议您立即下载与本书相匹配的源代码。即使您计划在示例旁边从头编写代码，您可能会遇到的小配置问题已经在相关代码中得到解决并可引用。
- en: You can see the GitHub source page at [*https://github.com/GantMan/learn-tfjs*](https://github.com/GantMan/learn-tfjs).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[*https://github.com/GantMan/learn-tfjs*](https://github.com/GantMan/learn-tfjs)看到GitHub源页面。
- en: If you are unfamiliar with GitHub and Git, you can simply download the latest
    project source code in a single ZIP file and reference that.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对GitHub和Git不熟悉，可以简单地下载最新的项目源代码的单个ZIP文件并引用它。
- en: You can download the source ZIP file from [*https://github.com/GantMan/learn-tfjs/archive/master.zip*](https://github.com/GantMan/learn-tfjs/archive/master.zip).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[*https://github.com/GantMan/learn-tfjs/archive/master.zip*](https://github.com/GantMan/learn-tfjs/archive/master.zip)下载源ZIP文件。
- en: The source code is structured to match each chapter. You should be able to find
    all chapter resources in the folder with the same name. In each chapter folder,
    you will find at most four folders that contain the lesson information. This will
    be reviewed in [Chapter 2](ch02.html#the_chapter_2) when you run your first TensorFlow.js
    code. For now, familiarize yourself with the purpose of each folder so you can
    select the example code that works best for your learning needs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码结构化以匹配每个章节。您应该能够在具有相同名称的文件夹中找到所有章节资源。在每个章节文件夹中，您将找到最多四个包含课程信息的文件夹。当您运行第一个TensorFlow.js代码时，将在[第2章](ch02.html#the_chapter_2)中进行审查。现在，请熟悉每个文件夹的目的，以便选择最适合您学习需求的示例代码。
- en: The extra folder
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 额外文件夹
- en: This folder contains any extra materials referenced in a chapter, including
    documentation or additional reference material. The material in these sections
    are useful files for each chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件夹包含章节中引用的任何额外材料，包括文档或其他参考资料。这些部分的材料是每章的有用文件。
- en: The node folder
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 节点文件夹
- en: 'This folder contains a Node.js-specific implementation of the chapter’s code
    for a server-based solution. This folder will likely contain several specific
    projects within it. Node.js projects will come with some extra packages installed
    to simplify the experimentation process. The example projects for this book utilize
    the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件夹包含了章节代码的Node.js特定实现，用于基于服务器的解决方案。该文件夹可能包含其中几个特定项目。Node.js项目将安装一些额外的软件包，以简化实验过程。本书的示例项目使用以下内容：
- en: '`nodemon`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`nodemon`'
- en: Nodemon is a utility that will monitor for any changes in your source and automatically
    restart your server. This is used so you can save your files and immediately see
    their associated updates.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Nodemon是一个实用程序，将监视源中的任何更改并自动重新启动服务器。这样可以保存文件并立即查看其相关更新。
- en: '`ts-node`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`ts-node`'
- en: TypeScript has plenty of options, most notably strong typing. However, for approachability
    this book is focused on JavaScript and not TypeScript. The `ts-node` module is
    in place for ECMAScript support. You can write modern JavaScript syntax in these
    node samples, and via TypeScript, the code will work.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: TypeScript有很多选项，最明显的是强类型。然而，为了易于理解，本书专注于JavaScript而不是TypeScript。`ts-node`模块用于支持ECMAScript。您可以在这些节点示例中编写现代JavaScript语法，通过TypeScript，代码将正常工作。
- en: These dependencies are identified in the *package.json* file. The Node.js examples
    are to illustrate server solutions with TensorFlow.js and generally do not need
    to be opened in a browser.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这些依赖项在*package.json*文件中标识。Node.js示例用于说明使用TensorFlow.js的服务器解决方案，通常不需要在浏览器中打开。
- en: 'To run these examples, install the dependencies with either Yarn or Node Package
    Manager (NPM), and then execute the start script:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这些示例，请使用Yarn或Node Package Manager（NPM）安装依赖项，然后执行启动脚本：
- en: '[PRE0]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After starting the server, you will see the results of any console logs in your
    terminal. When you’re done reviewing the results, you can use Ctrl+C to exit the
    server.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 启动服务器后，您将在终端中看到任何控制台日志的结果。查看结果后，您可以使用Ctrl+C退出服务器。
- en: The simple folder
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单文件夹
- en: This folder will contain solutions where NPM was not used. All resources are
    simply placed in solitary HTML files to be served. This is by far the simplest
    solution and the most often used. This folder will most likely contain the most
    results.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件夹将包含没有使用NPM的解决方案。所有资源都简单地放在独立的HTML文件中进行服务。这绝对是最简单的解决方案，也是最常用的。这个文件夹很可能包含最多的结果。
- en: The web folder
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: web文件夹
- en: If you’re familiar with client-based NPM web applications, you will feel comfortable
    with the `web` folder. This folder will likely contain several specific projects
    within it. The `web` folder examples are bundled using [Parcel.js](https://parceljs.org).
    It is a fast multicore bundler for web projects. Parcel provides Hot Module Replacement
    (HMR) so you can save your files and immediately see the page reflect your code
    changes, while also providing friendly error logging and access to ECMAScript.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉基于客户端的NPM Web应用程序，您将会对`web`文件夹感到舒适。这个文件夹很可能包含其中的几个具体项目。`web`文件夹示例是使用[Parcel.js](https://parceljs.org)打包的。这是一个用于Web项目的快速多核打包工具。Parcel提供热模块替换（HMR），因此您可以保存文件并立即看到页面反映您的代码更改，同时还提供友好的错误日志记录和访问ECMAScript。
- en: 'To run these examples, install the dependencies with either Yarn or NPM, and
    then execute the start script:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这些示例，请使用Yarn或NPM安装依赖项，然后执行启动脚本：
- en: '[PRE1]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After running the bundler, a web page with your default browser will open and
    access a local URL for that project.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 运行打包程序后，将打开一个网页，使用您的默认浏览器访问该项目的本地URL。
- en: Tip
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If a project uses a resource like a photo, a *credit.txt* file will exist in
    that project’s root folder to properly credit the photographer and source.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果项目使用像照片这样的资源，那么该项目的根文件夹中将存在一个*credit.txt*文件，以正确归功于摄影师和来源。
- en: Chapter Sections
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 章节部分
- en: Each chapter begins by identifying the goals of the chapter and then dives in
    immediately. At the end of each chapter, you’re presented with a Chapter Challenge,
    which is a resource for you to immediately apply what you’ve just learned. The
    answers for each challenge can be found in [Appendix B](app02.html#appendix_b).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章都从确定章节目标开始，然后立即深入讨论。在每一章的末尾，您将看到一个章节挑战，这是一个资源，让您立即应用您刚学到的知识。每个挑战的答案可以在[附录B](app02.html#appendix_b)中找到。
- en: Finally, each chapter ends with a grouping of thought-provoking questions to
    verify you’ve internalized the information from the chapter. It’s advised that
    you verify the answers for yourself by code when possible, but the answers are
    also provided for you in [Appendix A](app01.html#book_appendix).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，每一章都以一组发人深省的问题结束，以验证您是否已内化了本章的信息。建议您尽可能通过代码验证答案，但答案也会在[附录A](app01.html#book_appendix)中提供给您。
- en: Common AI/ML Terminology
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的AI/ML术语
- en: You might be thinking to yourself, “Why isn’t a model just called a function?
    Models already have a meaning in programming, and they don’t need another!” The
    truth is this comes from the origin of problems that machine learning started
    with. Original data problems were rooted in statistics. Statistical models recognize
    patterns as statistical assumptions on sample data, and so our product from this
    mathematical operation on examples is a machine learning model. It’s quite common
    for machine learning terminology to heavily reflect the field and culture of the
    scientists who invented it.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想，“为什么模型不只是称为函数？模型在编程中已经有了意义，不需要另一个！”事实是这源自机器学习起源的问题。原始数据问题根植于统计学。统计模型将模式识别为样本数据的统计假设，因此我们从这些示例的数学运算中得到的产品是一个机器学习模型。机器学习术语通常会大量反映发明它的科学家的领域和文化。
- en: Data science comes with a good bit of mathematical terminology. We’ll see this
    as a theme throughout the book, and we’ll identify the reasons for each. Some
    terms make sense instantly, some collide with existing JavaScript and framework
    terms, and some new terminology collides with other new terminology! Naming things
    is hard. We’ll do our best to explain some key terms in a memorable way and elaborate
    on etymology along the way. The TensorFlow and TensorFlow.js docs are replete
    with new vocabulary for developers. Read through the following machine learning
    terminology and see if you can grasp these fundamental terms. It’s OK if you can’t.
    You can come back to this chapter and reference these definitions at any time
    as we progress forward.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学伴随着大量的数学术语。我们将在整本书中看到这一主题，并且我们将为每个术语找出原因。有些术语立即就有意义，有些与现有的JavaScript和框架术语冲突，有些新术语与其他新术语冲突！命名事物是困难的。我们将尽力以易记的方式解释一些关键术语，并在途中详细说明词源。TensorFlow和TensorFlow.js文档为开发人员提供了大量新词汇。阅读以下机器学习术语，看看您是否能掌握这些基本术语。如果不能，没关系。随着我们的进展，您可以随时回到本章并参考这些定义。
- en: Training
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: Training is the process of attempting to improve a machine learning algorithm
    by having it review data and improve its mathematical structure to make better
    predictions in the future.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是通过让机器学习算法审查数据并改进其数学结构以使其在未来做出更好的预测的过程。
- en: TensorFlow.js provides several methods to train and monitor training models,
    both on a machine and in a client browser.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js提供了几种方法来训练和监控训练模型，无论是在机器上还是在客户端浏览器上。
- en: e.g., “Please don’t touch my computer, it’s been training for three days on
    my latest air-bending algorithm.”
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“请不要触碰我的电脑，它已经在我的最新的空气弯曲算法上训练了三天。”
- en: Training set
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练集
- en: Sometimes called the *training data*, this is the data you’re going to show
    your algorithm for it to learn from. You might think, “Isn’t that all the data
    we have?” The answer is “no.”
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有时被称为“训练数据”，这是您将向算法展示的数据，让它从中学习。你可能会想，“这不就是我们拥有的所有数据吗？”答案是“不是”。
- en: Generally, most ML models can learn from examples they’ve seen before, but teaching
    the test doesn’t assure that our model can extrapolate to recognize data it has
    never seen before. It’s important that the data that we use to train the AI be
    kept separate for accountability and verification.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，大多数机器学习模型可以从它们以前见过的示例中学习，但测试并不能保证我们的模型可以推广到识别它以前从未见过的数据。重要的是，我们用来训练人工智能的数据要与验证和核实分开。
- en: e.g., “My model keeps identifying hot dogs as sub sandwiches, so I’ll need to
    add more photos to my training set.”
  id: totrans-176
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我的模型一直将热狗识别为三明治，所以我需要向我的训练集中添加更多照片。”
- en: Test set
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试集
- en: To test that our model can perform against data it has never seen before, we
    have to keep some data aside to test and never let our model train or learn from
    it. This is generally called the *test set* or *test data*. This set helps us
    test if we’ve made something that will generalize to new problems in the real
    world. The test set is generally significantly smaller than the training set.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的模型是否能够对从未见过的数据进行处理，我们必须保留一些数据进行测试，并且永远不让我们的模型从中学习。这通常被称为“测试集”或“测试数据”。这个集合帮助我们测试我们是否已经创建了一个可以推广到现实世界新问题的东西。测试集通常比训练集要小得多。
- en: e.g., “I made sure the test set was a good representation of the problem we’re
    trying to train a model to solve.”
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我确保测试集是我们试图训练模型解决的问题的一个很好的代表。”
- en: Validation sets
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证集
- en: This term is important to know even if you aren’t at the level where you need
    it. As you’ll hear often, training can sometimes take hours, days, or even weeks.
    It’s a bit alarming to kick off a long-running process just to come back and find
    out you’ve structured something wrong and you have to start all over again! While
    we probably won’t run into any of those mega-training needs in this book, those
    situations could use a group of data for quicker tests. When this is separate
    from your training data, it’s a “holdout method” for validation. Essentially,
    it’s a practice where a small set of training data is set aside to make validation
    tests before letting your model train on an expensive infrastructure or for an
    elongated time. This tuning and testing for validation is your validation set.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您还没有达到需要它的水平，这个术语也是很重要的。正如您经常会听到的，训练有时可能需要几小时、几天甚至几周。启动一个长时间运行的过程，只是回来发现您构建了错误的结构，必须重新开始，这有点令人担忧！虽然在本书中我们可能不会遇到任何这些大规模训练的需求，但这些情况可能需要一组数据进行更快的测试。当这与您的训练数据分开时，它是用于验证的“留出法”。基本上，这是一种实践，在让您的模型在昂贵的基础设施上训练或花费更长时间之前，将一小部分训练数据保留下来进行验证测试。这种调整和验证是您的验证集。
- en: There’s a lot of ways to select, slice, stratify, and even fold your validation
    sets. This goes into a science that is beyond the scope of this book, but it’s
    good to know for when you discuss or read and advance your own mega-datasets.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以选择、切片、分层甚至折叠您的验证集。这涉及到一种超出本书范围的科学，但当您讨论、阅读和提升自己的大型数据集时，了解这些知识是很有用的。
- en: TensorFlow.js has entire training parameters for identifying and graphing validation
    results during the training process.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js在训练过程中有整个训练参数，用于识别和绘制验证结果。
- en: e.g., “I’ve carved out a small validation set to use while we construct our
    model architecture.”
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我已经划分了一个小的验证集，在构建模型架构时使用。”
- en: Tensors
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 张量
- en: We’ll cover tensors in great detail in [Chapter 3](ch03.html#the_chapter_3),
    but it’s worth noting that tensors are the optimized data structure that allows
    for GPU and Web Assembly acceleration for immense AI/ML calculation sets. Tensors
    are the numerical holders of data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第3章](ch03.html#the_chapter_3)中详细介绍张量，但值得注意的是，张量是优化的数据结构，允许GPU和Web Assembly加速巨大的人工智能/机器学习计算集。张量是数据的数值持有者。
- en: e.g., “I’ve converted your photo into a grayscale tensor to see what kind of
    speed boost we can get.”
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我已经将您的照片转换为灰度张量，以查看我们可以获得什么样的速度提升。”
- en: Normalization
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 归一化
- en: Normalization is the action of scaling input values to a simpler domain. When
    everything becomes numbers, the difference in sparsity and magnitude of numbers
    can cause unforeseen issues.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化是将输入值缩放到更简单领域的操作。当一切都变成数字时，数字的稀疏性和数量的差异可能会导致意想不到的问题。
- en: For example, while the size of a house and the number of bathrooms in a house
    both affect the price, they are generally measured in different units with vastly
    different numbers. Not everything is measured in the same metric scale, and while
    AI can adapt to measure these fluctuations in patterns, one common trick is to
    simply scale data to the same small domain. This lets models train faster and
    find patterns more easily.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，房屋的大小和房屋中的浴室数量都会影响价格，但它们通常以完全不同的数字单位进行测量。并非所有事物都以相同的度量标准来衡量，虽然人工智能可以适应这些模式中的波动，但一个常见的技巧是简单地将数据缩放到相同的小领域。这样可以让模型更快地训练并更容易地找到模式。
- en: e.g., “I’ve applied some normalization to the house price and the number of
    bathrooms so our model can find patterns between the two more quickly.”
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我已经对房价和浴室数量进行了一些归一化，这样我们的模型可以更快地找到两者之间的模式。”
- en: Data augmentation
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强
- en: In photo editing software, we can take images and manipulate them to look like
    the same thing in a completely different setting. This method effectively makes
    an entirely new photo. Perhaps you want your logo on the side of a building or
    embossed on a business card. If we were trying to detect your logo, the original
    photo and some edited versions would be helpful in our machine learning training
    data.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在照片编辑软件中，我们可以拍摄图像并操纵它们，使其看起来像完全不同环境中的同一物体。这种方法有效地创建了一张全新的照片。也许您想要将您的标志放在建筑物的一侧或者压印在名片上。如果我们试图检测您的标志，原始照片和一些编辑过的版本将有助于我们的机器学习训练数据。
- en: Oftentimes, we can create new data from our original data that fits the goal
    of our model. For example, if our model is going to be trained to detect faces,
    a photo of a person and a mirrored photo of a person are both valid and significantly
    different photos!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们可以从原始数据中创建符合我们模型目标的新数据。例如，如果我们的模型将被训练来检测人脸，一个人的照片和一个镜像的人的照片都是有效的，而且明显不同的照片！
- en: TensorFlow.js has libraries dedicated to data augmentation. We will see augmented
    data later in this book.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js有专门用于数据增强的库。我们将在本书的后面看到增强的数据。
- en: e.g., “We’ve performed some data augmentation by mirroring all the pumpkins
    to double our training set.”
  id: totrans-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我们通过镜像所有南瓜进行了一些数据增强，以扩大我们的训练集。”
- en: Features and featurization
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征和特征化
- en: We mentioned featurizing earlier when we talked about the way eyes send what’s
    most important to the brain. We do the same thing with ML. If we were trying to
    make an AI that guesses how much a house is worth, we then have to identify what
    inputs are useful and what inputs are noise.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过特征化，当我们谈到眼睛如何将最重要的信息发送到大脑时。我们在机器学习中也是这样做的。如果我们试图制作一个猜测房子价值的AI，那么我们必须确定哪些输入是有用的，哪些输入是噪音。
- en: There’s no shortage of data on a house, from the number of bricks to the crown
    molding. If you watch a lot of home improvement TV, you know it’s smart to identify
    a house’s size, age, number of bathrooms, date the kitchen was last updated, and
    neighborhood. These are often key features in identifying a house’s price, and
    you’ll care more about feeding a model that information than something trivial.
    Featurization is the selection of these features from all the possible data that
    could be selected as inputs.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 房子上的数据不缺乏，从砖块的数量到装饰线。如果你经常看家装电视节目，你会知道识别房子的大小、年龄、浴室数量、厨房最后一次更新的日期和社区是明智的。这些通常是识别房价的关键特征，你会更关心提供给模型这些信息，而不是一些琐碎的东西。特征化是从所有可能的数据中选择这些特征作为输入的过程。
- en: If we decided to throw in all the data we could, we give our model the chance
    to find new patterns at the cost of time and effort. There’s no reason to choose
    features like the number of blades of grass, house smell, or natural lighting
    at noon, even if we have that information or we feel it’s important to us.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定把所有可能的数据都放进去，我们就给了我们的模型找到新模式的机会，但代价是时间和精力。没有理由选择像草叶的数量、房子的气味或正午的自然光线这样的特征，即使我们有这些信息或者我们觉得这对我们很重要。
- en: Even once we’ve selected our features, there are often errors and outliers that
    will slow the training of a practical machine learning model. Some data just doesn’t
    move the needle toward a more successful predictive model, and selecting smart
    features makes a quick-trained, smarter AI.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们选择了我们的特征，仍然会有错误和异常值会减慢实用机器学习模型的训练。有些数据只会让预测模型更成功的指针移动，选择明智的特征会使快速训练的智能AI。
- en: e.g., “I’m pretty sure counting the number of exclamation marks is a key feature
    for detecting these marketing emails.”
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，“我相当确定计算感叹号的数量是检测这些营销邮件的关键特征。”
- en: Chapter Review
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节回顾
- en: In this chapter, we’ve ensnared the terms and concepts of the umbrella term
    AI. We’ve also touched on the key principles of what we’ll cover in this book.
    Ideally, you are now more confident in the terms and structures that are essential
    in machine learning.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们已经掌握了总称AI的术语和概念。我们也触及了我们将在本书中涵盖的关键原则。理想情况下，你现在对机器学习中必不可少的术语和结构更有信心了。
- en: Review Questions
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复习问题
- en: 'Let’s take a moment and make sure you’ve fully grasped the concepts we mentioned.
    Take a moment to answer the following questions:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间确保你完全掌握了我们提到的概念。花点时间回答以下问题：
- en: Can you give an adequate definition of machine learning?
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能给出机器学习的充分定义吗？
- en: If a person identifies an idea for a machine learning project, but they have
    no labeled data, what would you recommend?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一个人想到了一个机器学习项目的想法，但是他们没有标记的数据，你会推荐什么？
- en: What kind of ML would be useful for beating your favorite video game?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么样的机器学习对打败你最喜欢的视频游戏有用？
- en: Is machine learning the only form of AI?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习是唯一的AI形式吗？
- en: Does a model hold all the training example data that was used to make it work?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个模型是否保存了用于使其工作的所有训练示例数据？
- en: How is machine learning data broken up?
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习数据是如何分解的？
- en: Solutions to these exercises are available in [Appendix A](app01.html#book_appendix).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解决方案可以在[附录A](app01.html#book_appendix)中找到。
- en: '^([1](ch01.html#idm45049261920904-marker)) Programming language stats: [*https://octoverse.github.com*](https://octoverse.github.com)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.html#idm45049261920904-marker)) 编程语言统计：[*https://octoverse.github.com*](https://octoverse.github.com)
- en: ^([2](ch01.html#idm45049261893832-marker)) *Artificial intelligence* was coined
    by John McCarthy in 1956 at the first academic conference on the subject.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.html#idm45049261893832-marker)) *人工智能*是由约翰·麦卡锡在1956年首次学术会议上创造的。
