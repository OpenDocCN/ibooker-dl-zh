- en: '2 Large Language Models: A Deep Dive Into Language Modeling'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 大型语言模型：深入探究语言建模
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章内容包括：
- en: Linguistic background for understanding meaning and interpretation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解含义和解释的语言学背景
- en: A comparative study on language modeling techniques
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模技术的比较研究
- en: Attention and the transformer architecture
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力和Transformer架构
- en: How Large Language Models both fit into and build upon these histories
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型如何融入和建立在这些历史之上
- en: All good stories start with “Once upon a time,” but unfortunately this isn’t
    a story, it’s a book on creating and productionizing LLMs. So instead this chapter
    delves into linguistics as it relates to the development of Large Language Models
    (LLMs), exploring the foundations of semiotics, linguistic features, and the progression
    of language modeling techniques that have shaped the field of natural language
    processing (NLP). We will begin by studying the basics of linguistics and its
    relevance to LLMs in section 2.1, highlighting key concepts such as syntax, semantics,
    and pragmatics, that form the basis of natural language and play a crucial role
    in the functioning of LLMs. We will delve into semiotics, the study of signs and
    symbols, and explore how its principles have informed the design and interpretation
    of LLMs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所有好故事都以“从前有一位”为开头，但不幸的是，本书不是故事，而是关于创建和生产化LLMs的书籍。因此，本章将深入探讨与大型语言模型（LLMs）的开发相关的语言学知识，探索形式语言学的基础、语言特征和塑造自然语言处理（NLP）领域的语言建模技术的演变。我们将从研究语言学的基础和其与LLMs的关联性开始，重点介绍句法、语义和语用等关键概念，这些概念构成了自然语言的基础，并在LLMs的运行中起着至关重要的作用。我们将深入探讨符号学，即符号和符号的研究，并探讨其原则如何影响LLMs的设计和解释。
- en: We will then trace the evolution of language modeling techniques in section
    2.2, providing an overview of early approaches, including N-grams, Naive Bayes
    classifiers, and neural network-based methods such as Multi-Layer Perceptrons
    (MLPs), Recurrent Neural Networks (RNNs), and Long Short-Term Memory (LSTM) networks.
    We will also discuss the groundbreaking shift to transformer-based models in section
    2.3, which have laid the foundation for the emergence of LLMs—which are just really
    big transformer based models. Finally, we will introduce LLMs in 2.4 and their
    distinguishing features, discussing how they have built upon and surpassed earlier
    language modeling techniques to revolutionize the field of Natural Language Processing
    (NLP).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将在2.2节中追溯语言建模技术的演变，概述了早期方法，包括N-Gram、朴素贝叶斯分类器以及基于神经网络的方法，如多层感知机（MLP）、循环神经网络（RNN）和长短期记忆（LSTM）网络。然后在2.3节中讨论了基于Transformer模型的革命性转变，这为大型语言模型（LLMs）的出现奠定了基础，而LLMs只是非常大型的基于Transformer模型。最后，在2.4节中介绍了LLMs及其独特的特点，讨论了它们如何在建立在并超过早期的语言建模技术基础上，从而彻底改变了自然语言处理（NLP）领域。
- en: This is a book about LLMs in production. We firmly believe that if you want
    to turn an LLM into an actual product, understanding the technology better will
    improve your results and save you from making costly and time-consuming mistakes.
    Any engineer can figure out how to lug a big model into production and throw a
    ton of resources at it to make it run, but that brain-dead strategy completely
    misses the lessons people have already learned trying to do the same thing before,
    which is what we are trying to solve with LLMs in the first place. Having a grasp
    of these fundamentals will better prepare you for the tricky parts, the gotchas,
    and the edge cases you are going to run into when working with LLMs. By understanding
    the context in which LLMs emerged, we can appreciate their transformative impact
    on NLP and how to enable them to create a myriad of applications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一本关于LLMs在生产中的书籍。我们坚决认为，如果你想将LLMs变成实际产品，更好地理解这项技术将提高你的成果，避免犯下代价高昂且耗时的错误。任何工程师都可以弄清楚如何将大型模型引入生产环境并投入大量资源使其运行，但这种愚蠢的策略完全忽略了人们在之前尝试做同样事情时已经学到的教训，而这正是我们首先要解决的问题。掌握这些基础知识将更好地为您准备处理LLMs时可能遇到的棘手部分、陷阱和边界情况。通过了解LLMs出现的背景，我们可以欣赏它们对NLP的变革性影响，以及如何使其能够创建各种应用程序。
- en: 2.1 Language Modeling
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 语言建模
- en: It would be a great disservice to address LLMs in any depth without first addressing
    language, to begin with. To that end, we will start with a brief but comprehensive
    overview of language modelling, focusing on the lessons that can help us with
    modern LLMs. Let’s first discuss levels of abstraction as it will help us garner
    an appreciation for language modelling.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论LLM之前，如果不首先讨论语言，那么就对LLM做了一个极大的伤害，首先我们将从简短但全面的语言模型概述开始，重点是可以帮助我们理解现代LLM的教训。让我们首先讨论抽象层级，因为这将帮助我们欣赏语言建模。
- en: Language, as a concept, is an abstraction of the feelings and thoughts that
    occur to us in our heads. Likewise, math is an abstraction of language, focusing
    on logic and provability, but as any mathematician will tell you, it is a subset
    of language used to describe and define in an organized and “logical” way. From
    math comes the language of binary, a base-2 system of numerical notation consisting
    of either on or off.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 语言作为一个概念，是我们头脑中产生的感觉和思维的抽象。同样，数学是语言的一种抽象，着重于逻辑和可证明性，但正如任何数学家所说的那样，它是一种用于有组织和“逻辑”方式描述和定义的语言的子集。二进制语言就源于数学，它是一种由`开`和`关`组成的二进制数字表示系统。
- en: Binary is very useful abstraction of math, which is an abstraction of language
    which is an abstraction of our feelings because it is what is used underneath
    the hood for everything to do with software, models, and computers in general.
    When computers were first made, we communicated with them through punched cards,
    or binary directly. Unfortunately, this ends up taking too long for humans to
    communicate important things in, so binary was also abstracted to assembly, a
    more human-comprehensible language for communicating with computers. This was
    further abstracted to the high-level assembly language, C, which has been even
    further abstracted to object-oriented languages like Python. The flow we just
    discussed is outlined in Figure 2.1.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制是数学的非常有用的抽象，它又是语言的抽象，而语言又是我们感觉的抽象，因为它是软件、模型和计算机中使用的底层工具。当计算机首次制造出来时，我们通过打孔卡片或直接使用二进制与它们交流。不幸的是，人类用这种方式沟通重要事物需要太长时间，因此二进制也被抽象为汇编语言，这是一种更符合人类理解的与计算机交流的语言。这又进一步抽象为高级汇编语言C，甚至进一步抽象为面向对象的编程语言如Python。我们刚才讨论的流程如图2.1所示。
- en: Figure 2.1 We compare cognitive layers of abstraction to programming layers
    of abstraction down to the logical binary abstraction. Python doesn’t come from
    C, nor does it compile into C. Python is, however, another layer of abstraction
    distant from binary. Similarly, language follows a similar path. Each layer of
    abstraction creates a potential point of failure. There are also several layers
    of abstraction to creating a model, each of which are important.
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1比较了认知抽象层级与编程抽象层级，直到逻辑二进制抽象。Python并不来自C，也不编译为C。然而，Python是另一种与二进制相距一定抽象层级的语言。类似地，语言也经过类似的路径。每一层的抽象都会造成潜在的错误点。创建模型也有多层次的抽象，每一层都很重要。
- en: '![](images/02__image002.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image002.png)'
- en: This is obviously a reduction, however, it’s useful to understand that the feelings
    you have in your head are the same number of abstractions away from binary, the
    language the computer actually reads, as the languages most people use to program
    in. Some people might argue that there are more steps between Python and binary,
    such as compilers or using assembly to support the C language, and that’s true,
    but there are more steps on the language side too, such as morphology, syntax,
    logic, and agreement.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这是一种简化，但了解一下，你在头脑中所感受到的情感与计算机实际读取的二进制相隔着相同数量的抽象层级，就像大多数人用来编程的语言一样。有些人可能会认为Python和二进制之间存在更多的步骤，例如编译器或使用汇编语言支持C语言，这是正确的，但在语言方面也有更多的步骤，例如形态学、语法、逻辑和一致性。
- en: This can help us understand how difficult the process of getting what we want
    to be understood by an LLM actually is, and even help us understand language modeling
    techniques better. The reason we focus on binary here is simply to illustrate
    that there are a similar number of abstract layers to get from an idea you have
    or from one of our code samples to a working model. Like the children’s telephone
    game where participants whisper into each other's ears, each abstraction layer
    creates a disconnect point or barrier where mistakes can be made.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以帮助我们理解让人工智能语言模型（LLM）理解我们想要表达的内容的过程有多困难，甚至可以帮助我们更好地理解语言建模技术。我们在这里专注于二进制的原因仅仅是为了说明从你有的想法或我们的代码示例之一到一个工作模型的抽象层次是相似的数量。就像儿童的电话游戏，参与者互相耳语一样，每一个抽象层次都会产生一个断开点或障碍，错误可能在这些地方发生。
- en: Figure 2.1 is also meant to illustrate the difficulty in not only creating reliable
    code and language input, but to draw attention to how important the intermediary
    abstraction steps like tokenization and embeddings are for the model itself. Even
    if you have perfectly reliable code and perfectly expressed ideas, the meaning
    may be fumbled by one of those processes before it ever reaches the LLM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1也旨在说明不仅创建可靠的代码和语言输入的困难，而且要引起注意的是中间的抽象步骤（如标记化和嵌入）对于模型本身是多么重要。即使你有完全可靠的代码和完美表达的想法，含义在到达LLM之前可能会在这些过程中被错误地处理。
- en: In this chapter we will try and help you understand what you can do to reduce
    the risks of these failure points, whether that be on the language, coding, or
    modeling side. Unfortunately, it’s a bit tricky to strike a balance between giving
    you too much linguistics that doesn’t immediately matter for the task at hand
    versus giving you too much technical knowledge that, while useful, doesn’t help
    you develop an intuition for language modeling as a practice. With this in mind,
    you should know that linguistics can be traced thousands of years back in our
    history and there’s lots to learn from it. We’ve included a ***brief*** overview
    for interested readers of how language modeling has progressed over time in Appendix
    A answer encourage you to take a look.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将尝试帮助您理解如何减少这些失败点的风险，无论是在语言、编码还是建模方面。不幸的是，在为当前任务不立即重要的语言学知识和为您提供太多的技术知识之间取得平衡有点棘手，尽管它们很有用，但并不能帮助您培养对语言建模作为一种实践的直觉。在此基础上，您应该知道语言学可以追溯到我们历史上数千年前，并且有很多可以从中学到的东西。我们在附录A中提供了一个***简要***的概述，供有兴趣的读者了解语言建模是如何随着时间的推移发展的，并鼓励您查阅。
- en: Let’s start with our focus on the building blocks that constitute language itself.
    We expect our readers to have at least attempted language modeling before and
    to maybe have heard of libraries like PyTorch and Tensorflow, but we do not expect
    most of our readers to have considered the language side of things before. By
    understanding the essential features that make up language, we can better appreciate
    the complexities involved in creating effective language models and how these
    features interact with one another to form the intricate web of communication
    that connects us all. In the following section, we will examine the various components
    of language, such as phonetics, pragmatics, morphology, syntax, and semantics,
    as well as the role they play in shaping our understanding and usage of languages
    around the world. Let’s take a moment to explore how we currently understand language
    along with the challenges we face that LLMs are meant to solve.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从我们专注于构成语言本身的基本组成部分开始。我们期望我们的读者至少在尝试过语言建模之前，并可能听说过像PyTorch和Tensorflow这样的库，但我们不指望大多数读者之前曾考虑过语言方面的问题。通过理解构成语言的基本特征，我们可以更好地欣赏创建有效语言模型所涉及的复杂性，以及这些特征如何相互作用形成我们所有人之间相互连接的复杂的交流网络。在接下来的章节中，我们将研究语言的各个组成部分，如语音学、语用学、形态学、语法和语义，以及它们在塑造我们对世界各地语言的理解和使用方面所起的作用。让我们花一点时间来探索我们目前如何理解语言以及我们面临的LLM意图解决的挑战。
- en: 2.1.1 Linguistic Features
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.1 语言特征
- en: 'Our current understanding of language is that language is made up of at least
    5 parts: Phonetics, Syntax, Semantics, Pragmatics, and Morphology. Each of these
    portions contributes significantly to the overall experience and meaning being
    ingested by the listener in any conversation. Not all of our communication uses
    all of these forms, for example, the book you’re currently reading is devoid of
    phonetics, which is one of the reasons why so many people think text messages
    are unsuited for a more serious or complex conversation. Let’s work through what
    each of these is to figure out how to present them to a language model for a full
    range of communicative power.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前对语言的理解是，语言由至少5个部分组成：语音学、句法学、语义学、语用学和形态学。这些部分中的每一个都对任何对话中听者所接受的整体体验和意义做出了重大贡献。并非所有的交流都使用所有这些形式，例如，你正在阅读的书籍中没有语音学，这就是为什么很多人认为短信不适合进行更严肃或更复杂的对话的原因之一。让我们仔细分析一下这些内容，以确定如何向语言模型呈现它们，以实现全面的沟通能力。
- en: Phonetics
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语音学
- en: Probably the easiest for a language model to ingest, phonetics involves the
    actual sound of the language. This is where accent manifests and deals with the
    production and perception of speech sounds, with phonology focusing on the way
    sounds are organized within a particular language system. Similarly to computer
    vision, while a sound isn’t something necessarily easy to deal with as a whole,
    there’s no ambiguity for how to parse, vectorize, or tokenize the actual sound
    waves. They have a numerical value attached to each part, the crest, the trough,
    and the slope during each frequency cycle. It is vastly easier than text to be
    tokenized and processed by a computer while being no less complex. Sound inherently
    contains more encoded meaning than the text as well, for example, imagine someone
    saying the words “yeah, right,” to you. Could be sarcastic, could be congratulatory,
    depending on the tone and English isn’t even tonal! Phonetics, unfortunately,
    doesn’t have Terabyte-sized datasets commonly associated with it, and performing
    data acquisition and cleaning on phonetic data, especially on the scale needed
    to train an LLM is difficult at best. In an alternate world where audio data was
    more prevalent than text data, and took up a smaller memory footprint, phonetic-based
    or phonetic-aware LLMs would be much more sophisticated, and creating that world
    is a solid goal to work towards.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于语言模型来说，语音学可能是最容易吸收的，它涉及到语言的实际发音。这就是口音的表现形式，涉及到语音的产生和感知，而音韵学则侧重于声音在特定语言系统内的组织方式。类似于计算机视觉，虽然作为一个整体来处理声音并不一定容易，但如何解析、向量化或标记实际的声波并不模糊。它们在每个部分都附有一个数字值，包括波峰、波谷以及每个频率周期内的斜率。相比文本，它更容易被计算机标记和处理，但同样复杂。声音本质上包含的编码意义比文本更多，例如，想象一下有人对你说“是的，对啊”。可能是讽刺的，也可能是祝贺的，这取决于语调，而英语甚至不是语调语言！不幸的是，语音学通常没有与之相关的千兆字节数据集，并且在语音数据的数据采集和清理方面，尤其是在需要训练LLM的规模上，这是非常困难的。在一个声音数据比文本数据更普遍且占用更小内存空间的替代世界中，基于语音或具有语音感知能力的LLM将会更加复杂，创造这样一个世界是一个可靠的目标。
- en: 'Anticipating this problem, a system created in 1888 called the International
    Phonetic Alphabet (IPA) has been revised in both the 20th and 21st centuries to
    be more concise, more consistent, and more clear, which could be a way to insert
    phonetic awareness into text data. IPA functions as an internationally standardized
    version of every language’s sound profile. A sound profile is the set of sounds
    that a language uses, for example in English, we never have the /ʃ/ (she, shirt,
    sh) next to the /v/ sound. IPA is used to write sounds, rather than writing an
    alphabet or logograms, as most languages do. For example, you could simply describe
    how to pronounce the word “cat” using these symbols: /k/, /æ/, and /t/. That’s
    of course a *very* simplified version of it, but for models it doesn’t have to
    be. You can describe tone and aspiration as well. This could be a happy medium
    between text and speech, capturing some phonetic information. Think of the phrase
    “what’s up?” Your pronunciation and tone can drastically change how you understand
    that phrase, sometimes sounding like a friendly “wazuuuuup,” and other an almost
    threatening, “‘sup,” which IPA would fully capture. IPA isn’t a perfect solution
    though, for example, it doesn’t solve the problem of replicating tone very well.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这个问题，创建于1888年的国际音标（IPA）在20世纪和21世纪都进行了修订，使其更加简洁、一致和清晰，这可能是将语音认知融入文本数据的一种方式。
    IPA作为每种语言的音韵特征的国际标准化版本。音韵特征是语言使用的一套音素，例如在英语中，我们绝不会把音素/ʃ/（she, shirt, sh）与/v/音放在一起。
    IPA用来书写音素，而不是像大多数语言那样书写字母或表意文字。例如，你可以用这些符号简单地描述如何发音单词“cat”：/k/、/æ/和/t/。当然这是一个*非常*简化的版本，但对于模型来说，不必太复杂。你还可以描述语调和送气。这可能是文本和语音之间的一种折中，捕捉到一些音韵信息。想想短语“what’s
    up?” 你的发音和语调可以极大地改变你理解这个短语的方式，有时听起来像友好的“wazuuuuup”，有时像一种几乎威胁的“‘sup”，而这些都会被IPA完全捕捉到。然而，IPA并不是一个完美的解决方案，例如，它并不能很好地解决模拟语调的问题。
- en: Phonetics is listed first here because it’s the place that LLMs have been applied
    to the least out of all the features and therefore have the largest space for
    improvement. Even modern TTS and Voice cloning models for the most part end up
    converting the sound to a spectrogram and analyzing that image rather than incorporating
    any type of phonetic language modeling. This is something to look for as far as
    research goes in the coming months and years.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 音韵学被列为首位，因为在所有特点中，LLMs对其应用最少，因此在改进空间方面有最大的可能性。即使是现代的TTS和语音合成模型大部分时间最终会将声音转换为频谱图，并分析该图像，而不是将任何类型的音韵语言建模纳入其中。这是未来几个月甚至几年研究的一个方向。
- en: Syntax
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语法
- en: This is the place where current LLMs are highest-performing, both in parsing
    syntax from the user and generating its own. Syntax is generally what we think
    of as grammar and word order, and is the study of how words can combine to form
    phrases, clauses, and sentences. Syntax is also the first place that language
    learning programs start to help people acquire new languages, especially based
    on where you’re coming from natively. For example, it is important for a native
    English speaker learning Turkish to know that the syntax is completely different,
    and you can often build entire sentences in Turkish that are just one long compound
    word, whereas in English, we never put our subject and verb together into one
    word.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是当前LLM性能最好的领域，既能从用户那里解析语法，又能生成自己的语法。语法通常是我们所说的语法和词序，研究单词如何组合形成短语、从句和句子。语法也是语言学习程序开始帮助人们习得新语言的第一个地方，特别是根据你的母语出发。例如，对于一个以英语为母语的人学习土耳其语来说，知道语法完全不同很重要，你可以经常构建完全由一个长复合词组成的土耳其语句子，而在英语中，我们从来不把主语和动词合为一个词。
- en: 'Syntax is largely separate from meaning in language, as the famous sentence
    from Noam Chomsky the so-called father of syntax demonstrates: “Colorless green
    ideas sleep furiously.” Everything about that sentence is both grammatically correct
    and semantically understandable. The problem isn’t that it doesn’t make sense,
    it’s that it does, and the encoded meanings of those words conflict. This is a
    reduction, however, you can think of all the times LLMs give nonsense answers
    as this phenomenon manifesting. Unfortunately for us, the syntax is also where
    ambiguity is the most commonly found. Consider the sentence, “I saw an old man
    and woman.” Now answer the question: is the woman also old? This is syntactic
    ambiguity, where we aren’t sure whether the modifier “old” applies to all people
    in the following phrase or just the one it immediately precedes. This is less
    consequential than the fact that semantic and pragmatic ambiguity also show up
    in syntax. Consider this sentence now, “I saw a man on a hill with a telescope,”
    and answer the question: Where is the speaker, and what are they doing? Is the
    speaker on the hill cutting a man in half using a telescope? Likely, you didn’t
    even consider this option when you read the sentence, because when we interpret
    syntax, all of our interpretations are at least semantically and pragmatically
    informed. We know from lived experience that that interpretation isn’t at all
    likely, so we throw it out immediately, usually without even taking time to process
    that we’re eliminating it from the pool of probable meanings. Think about this
    later as we’re doing projects with LLMs.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 语法与语言意义大体上是分开的，正如语法之父诺姆·乔姆斯基（Noam Chomsky）所说的那句名言：“无色的绿色思想在狂暴地睡眠。” 这句话的一切都在语法上是正确的，并且在语义上是可以理解的。问题不在于它毫无意义，而在于它确实有意义，而且这些词的编码意义相互冲突。然而，这只是一种简化，你可以把所有时候大型语言模型给出荒谬答案看作是这种现象的表现。不幸的是，语法也是歧义最常见的地方。考虑一下这个句子，“我看见一个老人和一个女人。”现在回答这个问题：这个女人也老吗？这是语法歧义，我们不确定修饰语“老”的范围是适用于后续短语中的所有人还是仅仅适用于紧接着的那个人。这比语义和语用歧义出现在语法中更不重要。现在考虑这个句子，“我在一个山上看见一个人，他手里拿着望远镜”，然后回答这个问题：说话者在哪里，正在做什么？说话者在山上用望远镜将一个人割开吗？可能你在读这个句子时甚至没有考虑到这个选项，因为当我们解释语法时，我们所有的解释至少在语义和语用上都是得到了启发的。我们从生活经验中知道，那种解释根本不可能发生，所以我们立即将其排除，通常甚至没有时间去处理我们将其从可能含义的范围中消除的事实。当我们与大型语言模型进行项目时，请稍后考虑这一点。
- en: It shouldn’t take any logical leap for why LLMs need to be syntax-aware in order
    to be high-performing. LLMs that don’t get word order correct or generate nonsense
    aren’t usually described as “good.” LLMs being syntax-dependent is something that
    has prompted even, Chomsky to call LLMs “stochastic parrots.” In the authors’
    opinions, GPT2 in 2018 was when language modeling solved syntax as a completely
    meaning-independent demonstration, and we’ve been happy to see the more recent
    attempts to combine the syntax that GPT2 output so well with encoded and entailed
    meaning, which we’ll get into now.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于为什么大型语言模型需要具备语法意识以实现高性能，不应该需要任何逻辑推理。那些不能正确排序单词或生成无意义内容的大型语言模型通常不被描述为“优秀”。大型语言模型对语法的依赖性是导致乔姆斯基甚至称大型语言模型为“随机鹦鹉”的原因之一。在作者看来，2018年的GPT2是语言建模将语法解决为完全独立于意义的演示，我们很高兴看到最近的尝试将GPT2如此出色的语法与编码和暗示的意义结合起来，我们将在接下来详细讨论。
- en: Semantics
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语义
- en: 'Semantics are the literal encoded meaning of words in utterances. People automatically
    optimize semantic meaning, only using words that they consider meaningful in the
    current language epoch. If you’ve ever created or used an embedding with language
    models (word2vec, ELMO, BERT [the E is for Embedding], MUSE, etc.]) you’ve used
    a semantic approximation. Words often go through semantic shifts, and while we
    won’t cover all of this topic nor go in-depth, here are some common ones you may
    already be familiar with: narrowing, a broader meaning to a more specific one,
    broadening, the inverse of narrowing going from a specific meaning to a broad
    one, and reinterpretations, going through whole or partial transformations. These
    shifts do not have some grand logical underpinning. They don’t even have to correlate
    with reality, nor do speakers of a language hardly ever consciously think about
    the changes as they’re happening. That doesn’t stop the change from occurring,
    and in the context of language modeling it doesn’t stop us from having to keep
    up with that change.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 语义是话语中词语的字面编码含义。人们会自动优化语义含义，只使用他们认为在当前语言时期有意义的词语。如果你曾经创建或使用过语言模型的嵌入（如word2vec、ELMO、BERT【E代表嵌入】、MUSE等），你就使用了语义近似。词语经常经历语义转变，虽然我们不会涵盖这个话题的全部内容，也不会深入讨论，但下面是一些你可能已经熟悉的常见情况：狭义化，从更广泛的含义变为更具体的含义；扩义，与狭义化相反，从具体含义变为广泛含义；重新解释，经历整体或部分转变。这些转变并没有某种伟大的逻辑基础。它们甚至不必与现实相关，说某种语言的人几乎从来不会在这些变化发生时有意识地考虑。但这并不妨碍变化的发生，在语言建模的背景下，这也不会阻止我们跟上这种变化的步伐。
- en: 'Some examples: narrowing includes “deer” which in Old and Middle English just
    meant any wild animal, even a bear or a cougar, and now means only one kind of
    forest animal. For broadening we have “dog” which used to refer to only one canine
    breed from England, and now can be used to refer to any domesticated canine. One
    fun tangent about dog-broadening is in the *FromSoft* game *Elden Ring,* where
    because of a limited message system between players, they will use “dog” to refer
    to anything from a turtle to a giant spider and literally everything in between.
    For reinterpretation, we can consider “pretty” which used to mean clever or well-crafted,
    not visually attractive. Another good example is “bikini” which went from referring
    to a particular atoll, to referring to clothing you might have worn when visiting
    that atoll to people acting as if the “bi-” was referring to the two-piece structure
    of the clothing, thus inventing the tankini and monokini. Based on expert research
    and decades of study, we can think of language as being constantly compared and
    reevaluated by native language speakers out of which common patterns emerge. The
    spread of those patterns is closely studied in sociolinguistics and is largely
    out-of-scope for the current purpose, but we encourage the reader to look into
    it if interested, as sociolinguistic phenomena such as prestige can help in designing
    systems that work well for everyone.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一些例子：狭义化包括“deer”，在古英语和中古英语中它只是指任何野生动物，甚至包括熊或美洲狮，而现在只指一种森林动物。扩义的例子是“dog”，它曾经只指英国的一种犬类，现在可以用来指任何驯化的犬类动物。关于“dog”扩义的有趣细节是在FromSoft的游戏《Elden
    Ring》中，由于玩家之间的信息传递系统有限，他们会用“dog”来指代从海龟到巨型蜘蛛甚至所有中间形态的任何东西。关于重新解释，我们可以考虑“pretty”，它曾经意味着聪明或制作精良，而不是视觉上吸引人。另一个很好的例子是“bikini”，它从指代一个特定的环礁，变成指代你在访问那个环礁时可能穿的衣服，最后人们把“bi-”解释为衣服的两部分结构，于是发明了泳装和连体泳衣。根据专家的研究和几十年的研究，我们可以把语言看作是由母语人士不断比较和重新评估的，其中会出现共同的模式。这些模式的传播在社会语言学中得到了密切研究，这在当前目的上大多不在讨论范围之内，但我们鼓励读者如果感兴趣可以研究一下，因为社会语言学现象如声望可以帮助设计对每个人都有效的系统。
- en: In the context of LLMs, so-called semantic embeddings are vectorized versions
    of text that attempt to mimic semantic meaning. The most popular way of doing
    this currently is by tokenizing or assigning an arbitrary number in a dictionary
    to each subword in an utterance (think prefixes, suffixes, and morphemes generally),
    applying a continuous language model to increase the dimensionality of each token
    within the vector so that there’s a larger vector representing each index of the
    tokenized vector, then applying a positional encoding to each of those vectors
    to capture word order. Each subword ends up being compared to other words in the
    larger dictionary based on how it’s used. We’ll show an example of this later.
    Something to consider when thinking about word embeddings is that they struggle
    to capture deep encoded meaning of those tokens, and simply adding more dimensions
    to the embeddings hasn’t shown marked improvement. One evidence that embeddings
    are working in a similar way to humans is that you can apply a distance function
    to related words and see that they are closer together than unrelated words. This
    is another area to expect groundbreaking research in the coming years and months
    for how to capture and represent meaning more completely.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的语境中，所谓的语义嵌入是文本的向量化版本，试图模拟语义含义。目前最流行的做法是通过对话中的每个子词（例如前缀、后缀和词素）进行标记或分配字典中的任意数字，应用连续语言模型来增加向量中每个令牌的维度，以便有一个更大的向量表示每个令牌的每个索引，然后对每个向量应用位置编码来捕获词序。每个子词最终都会根据其用法与较大词典中的其他词进行比较。考虑词嵌入时需要考虑的一点是，它们很难捕捉到这些令牌的深层编码含义，而仅仅增加嵌入的维度并没有显示出明显的改善。证明嵌入正在以类似于人类的方式工作的一个证据是，你可以将一个距离函数应用于相关的单词，看到它们比不相关的单词更接近。这是另一个可以期待在未来几年和几个月内进行开创性研究的领域，以更完整地捕捉和表示含义。
- en: Pragmatics
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实用语用学
- en: Sometimes omitted from linguistics, due to its referent being all the non-linguistic
    context affecting a listener’s interpretation and the speaker’s decision to express
    things in a certain way. Pragmatics refers in a large part to dogmas followed
    in cultures, regions, socio-economic classes, and shared lived experiences played
    off of to take shortcuts in conversations using entailment.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会被语言学省略，因为其指称对象是影响听者解释和说话者决定以某种方式表达事物的所有非语言语境。语用学在很大程度上指的是文化、地区、社会经济阶层和共同的生活经验中遵循的教条，通过使用蕴涵在对话中采取捷径。
- en: If I were to say, “A popular celebrity was just taken into the ICU,” your pragmatic
    interpretation based on lived experience might be to assume that a well-beloved
    person has been badly injured and is now undergoing medical treatment in a well-equipped
    hospital. You may wonder about which celebrity it is, whether they will have to
    pay for the medical bills, or if the injury was self-inflicted, also based on
    your lived experience. None of these things can be inferred directly from the
    text and its encoded meaning by itself. You would need to know that ICU stands
    for a larger set of words, and what those words are. You would need to know what
    a hospital is and why someone would need to be taken there instead of going there
    themselves. If any of these feel obvious, good. You live in a society and your
    pragmatic knowledge of that society overlaps well with the example provided. If
    I share an example from a less-populated society, “Janka got her grand-night lashings
    yesterday, she’s gonna get Peter tomorrow” you might be left scratching your head.
    If you are, realize this probably looks like how a lot of text data ends up looking
    to an LLM (anthropomorphization acknowledged). For those wondering, this sentence
    comes from Slovak Easter traditions. There’s a lot of meaning here that will just
    be missed and go unexplained if you are unaccustomed to these particular traditions
    as they stand in that culture. I personally have had the pleasure of trying to
    explain the Easter Bunny and its obsession with eggs to foreign colleagues and
    enjoyed the satisfaction of looking crazy.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我说，“一个知名的名人刚刚被送进了ICU”，根据生活经验，你可能会推断一位备受喜爱的人受了严重的伤，现在正在一家设备齐全的医院接受治疗。你可能会想知道是哪位名人，他们是否需要支付医疗费用，或者伤害是否是自己造成的，这些也是基于你的生活经验。这些都不能直接从文本及其编码的意义中推断出来。你需要知道ICU代表一系列更广泛的词语，以及这些词语是什么。你需要知道医院是什么，以及为什么有人需要被送到那里而不是自己去。如果这些都感觉很明显，那很好。你生活在一个社会中，你对社会的语用知识与提供的例子之间有很好的重叠。如果我分享一个来自人口较少的社会的例子，“Janka昨天晚上挨了打，明天轮到Peter了”，你可能会感到困惑。如果你确实感到困惑，意识到这可能就是LLM看待很多文本数据的方式（人格化得到认可）。对于那些想知道的人，这个句子来自斯洛伐克的复活节传统。这里有很多意义，如果你不习惯这个文化中这些特定传统，那么这些意义将被忽略和不解释。我个人有幸尝试向外国同事解释复活节兔子及其对蛋的痴迷，并享受着看起来像个疯子的满足感。
- en: In the context of LLMs, we can effectively group all out-of-text context into
    pragmatics. This means LLMs start without any knowledge of the outside world,
    and do not gain it during training. They only gain a knowledge of how humans respond
    to particular pragmatic stimuli. LLMs do not understand social class or race or
    gender or presidential candidates or anything else that might spark some type
    of emotion in you based on your life experience. Pragmatics isn’t something that
    we expect will be able to be directly incorporated into a model at any point,
    but we have already seen the benefits of incorporating it indirectly through data
    engineering and curation, prompting, and supervised fine-tuning on instruction.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的语境中，我们可以有效地将所有与文本无关的内容归为语用学范畴。这意味着LLM在开始时没有任何关于外部世界的知识，并且在训练过程中也不会获取。它们只会获取人类对特定语用刺激的反应知识。LLM并不理解社会阶级、种族、性别、总统候选人或者其他可能基于个人生活经验引发某种情绪的事物。语用学不是我们期望直接整合到模型中的内容，但我们已经通过数据工程和策划、提示以及指导下的监督微调看到了间接整合的好处。
- en: Pragmatic structure gets added whether you mean to add it or not as soon as
    you acquire the data you are going to train on. You can think of this type of
    pragmatic structure as bias, not inherently good or bad, but impossible to get
    rid of. Later down the line you get to pick what types of bias you’d like your
    data to keep by normalizing and curating, augmenting particular underrepresented
    points and cutting overrepresented or noisy examples.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你获得了要训练的数据，无论你是否打算，语用结构都会被添加进去。你可以将这种类型的语用结构视为偏见，它并非本质上的好或者坏，但无法摆脱。后面你可以通过规范化和策划来选择你希望你的数据保留的偏见类型，增加特定的代表不足的点，减少代表过多或噪音干扰的例子。
- en: There’s a fine line between data engineering and pragmatic context, and it’s
    just a matter of understanding what entailments exist in your data. An entailment,
    is a pragmatic marker within your data, as opposed to the literal text that your
    dataset contains. For example, let’s say you have a model attempting to take an
    input like “write me a speech about frogs eating soggy socks that doesn’t rhyme
    and where the first letters of each line spell amphibian,” and actually follow
    that instruction. You can immediately tell that this input is asking for a lot.
    The balance for you as a data engineer would be to make sure that everything the
    input is asking for is explicitly accounted for in your data. You need to have
    examples of speeches, examples of what frogs and socks are and how they behave,
    and examples of acrostic poems. If you don’t, the model might be able to understand
    just from whatever entailments exist in your dataset, but it’s pretty up in the
    air. If you go the extra mile and keep track of entailed vs explicit information
    and tasks in your dataset, along with data distributions, you’ll have examples
    to answer, “What is the garbage-in resulting in our garbage-out?”
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程和语用语境之间存在着微妙的界限，这只是理解你的数据中存在的蕴涵。蕴涵是你的数据中的语用标记，而不是你的数据集中包含的字面文本。例如，假设你有一个模型试图接受像“写一篇关于青蛙吃湿袜子的演讲，不要押韵，每行的首字母拼成两栖动物”这样的输入，并实际按照这个指令来操作。你可以立即知道这个输入要求很多。作为数据工程师，你的平衡点就是确保输入要求在你的数据中被明确考虑到。你需要有演讲的例子，青蛙和袜子以及它们的行为的例子，还有藏头诗的例子。如果没有这些，模型可能仅仅能够从数据集中存在的蕴涵中理解，但是结果可能不确定。如果你更上一层楼并且记录数据集中的蕴涵信息和显性信息以及任务，还有数据分布，你就会有例子来回答“碎垃圾导致了什么样的结果？”
- en: LLMs struggle to pick up on pragmatics, even more so than people, but they do
    pick up on the things that your average standard deviation of people would. They
    can even replicate responses from people outside that standard deviation, but
    pretty inconsistently without the exact right stimulus. This is where everything
    during and after training comes in. Instruction-based datasets attempt to manufacture
    those stimuli during training by asking questions that entail representative responses.
    It is impossible to account for every possible situation in training, and you
    may inadvertently create new types of responses from your end users by trying
    to account for everything. After training, you can coax particular information
    from your model through prompting, which has a skill ceiling based on what your
    data originally entailed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs很难理解语用语言学，甚至比人类更难，但它们能够捕捉到大多数人的平均标准差。它们甚至可以复制来自标准差之外的人的回答，但是在没有准确的刺激下很难保持一致。这就是培训期间和培训后的关键。基于指令的数据集试图通过在培训过程中问问题来制造这些刺激，从而得到代表性的回答。在培训中不可能考虑到每种可能的情况，而且你试图考虑到所有情况可能会无意中造成用户新类型的回答。在培训之后，你可以通过提示从模型中获取特定的信息，这取决于你的数据最初包含的内容而有一定的限度。
- en: Morphology
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 词形变化。
- en: Morphology is the study of word structures and how they are formed from smaller
    units called morphemes. Morphemes are the smallest units of meaning, like the
    "re-" in "redo" or "relearn." However, not all parts of words are morphemes, such
    as "ra-" in "ration" or "na-" in "nation."
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 词形变化是研究词结构以及词是如何由更小的单元（称为词素）组成的。词素是最小的具有意义的单位，例如“重新”在“重新做”或“重新学习”中。但是，并非所有单词的部分都是词素，比如“饲料”中的“ra-”或“国家”中的“na-”。
- en: Understanding how words are constructed helps create better language models
    and parsing algorithms, which are essential for tasks like tokenization. Tokens
    are somewhere between words and morphemes, they are statistically the most-likely
    candidates for units of meaning, but don’t necessarily correspond to existing
    morphemes. The effectiveness of a language model can depend on how well it can
    understand and process these tokens. For instance, in tokenization, a model needs
    to store a set of dictionaries to convert between words and their corresponding
    indices. One of these tokens is usually an "<UNK>" token, which represents any
    word that the model does not recognize. If this token is used too frequently,
    it can hinder the model's performance, either because the model's vocabulary is
    too small or because the tokenizer is not using the right algorithm for the task.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 理解单词构造的方式有助于创建更好的语言模型和解析算法，这对于诸如标记化之类的任务至关重要。标记介于单词和形态素之间，在统计上它们是最可能表示意义单位的候选词，但不一定对应现有的形态素。语言模型的有效性可能取决于它有多么好地理解和处理这些标记。例如，在标记化中，模型需要存储一组字典，以便在单词和它们对应的索引之间进行转换。其中一个标记通常是"<UNK>"标记，它代表着模型不认识的任何单词。如果这个标记使用得太频繁，它可能会妨碍模型的性能，要么是因为模型的词汇量太小，要么是因为标记器没有为任务使用正确的算法。
- en: Consider a scenario where you want to build a code completion model, but you're
    using a tokenizer that only recognizes words separated by whitespace, like the
    nltk "punkt" tokenizer. When it encounters the string "def add_two_numbers_together(x,
    y):," it will pass "[def, <UNK>, y]" to the model. This causes the model to lose
    valuable information, not only because it doesn't recognize the punctuation, but
    also because the important part of the function's purpose is replaced with an
    unknown token due to the tokenizer's morphological algorithm. To improve the model's
    performance, a better understanding of word structure and the appropriate parsing
    algorithms is needed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个场景，你想构建一个代码补全模型，但是你使用的标记器只识别由空格分隔的单词，就像nltk的"punkt"标记器一样。当它遇到字符串"def add_two_numbers_together(x,
    y):,"时，它会将"[def, <UNK>, y]"传递给模型。这导致模型丢失了宝贵的信息，不仅因为它无法识别标点符号，还因为函数的重要部分由于标记器的形态学算法而被替换为未知标记。要提高模型的性能，需要更好地理解单词结构和适当的解析算法。
- en: 2.1.2 Semiotics
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.2 符号学
- en: After exploring the fundamental features of language and examining their significance
    in the context of large language models, it is important to consider the broader
    perspective of meaning-making and interpretation in human communication. Semiotics,
    the study of signs and symbols, offers a valuable lens through which we can better
    understand how people interpret and process language. In the following section,
    we will delve into the realm of semiotics, examining the relationship between
    signs, signifiers, and abstractions, as well as how these elements are utilized
    by LLMs to generate meaningful output. This discussion will provide a deeper understanding
    of the intricate processes through which LLMs manage to mimic human-like understanding
    of language, while also shedding light on the challenges and limitations they
    face in this endeavor. It should be noted that the authors do not believe that
    mimicking human behavior is necessarily the right answer for LLM improvement,
    only that mimicry is how the field has evaluated itself so far.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 探讨了语言的基本特征并在大型语言模型的语境中考察它们的重要性之后，重要的是考虑人类交流中意义构建和解释的更广阔视角。符号学，即标志和符号的研究，为我们提供了一个宝贵的视角，通过这个视角我们可以更好地理解人们如何解释和处理语言。在接下来的部分中，我们将深入探讨符号学的领域，考察符号、指示符和抽象之间的关系，以及LLMs如何利用这些元素生成有意义的输出。这次讨论将更深入地理解LLMs模拟人类语言理解的复杂过程，同时也揭示了它们在这一努力中面临的挑战和局限性。值得注意的是，作者并不认为模仿人类行为对LLM的改进必然是正确答案，只是模仿是该领域迄今为止评估自己的方式。
- en: In our introduction to semiotics let’s consider Figure 2.2 an adapted Peircean
    semiotic triangle. These are used to organize base ideas into sequences of firstness,
    secondness, and thirdness, with firstness being at the top left, secondness at
    the bottom, and thirdness being at the top right. If you’ve ever seen a semiotic
    triangle before, you may be surprised at the number of corners and orientation.
    To explain, we’ve turned them upside down to make it slightly easier to read,
    and because the system is recursive, we’re showing how the system can model the
    entire process and each piece individually simultaneously. While the whole concept
    of these ideas is very cool, it’s outside of the scope of this book to really
    delve into the philosophy. Instead, we can focus on the cardinal parts of those
    words (first, second, third) as showing the sequence things are processed in.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们介绍符号学时，让我们考虑图 2.2 是一个改编的皮尔斯符号三角形。这些被用来将基本思想组织成第一性、第二性和第三性的序列，其中第一性位于左上角，第二性位于底部，而第三性位于右上角。如果你以前见过符号三角形，你可能会对角数和方向感到惊讶。为了解释，我们把它们倒过来，以便稍微容易阅读，并且因为该系统是递归的，我们展示了系统如何同时模拟整个过程以及每个单独部分。虽然这些想法的整个概念非常酷，但深入探讨哲学并不在本书的范围之内。相反，我们可以将焦点放在这些词（first、second、third）的基本部分上，显示事物处理的顺序。
- en: Figure 2.2 This is a recursive Peircean semiotic triangle. It’s a system of
    organizing the process of extracting meaning from anything, in our case from language.
    Each point on the triangle illustrates one of the minimal parts needed to synthesize
    meaning within whatever the system is being used to describe, so here, each of
    these points are minimal units in meaning for language. Firstness, Secondness,
    and Thirdness are not points on the triangle, more markers for the people versed
    in Semiotics to be able to orient themselves in this diagram.
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.2 这是一个递归的皮尔斯符号三角形。它是一个组织从任何事物中提取意义的过程的系统，在我们的案例中是从语言中提取的。三角形上的每个点都说明了在被用来描述的系统中合成意义所需的最小部分之一，所以在这里，每个这些点都是语言中的最小单位。Firstness、Secondness
    和 Thirdness 不是三角形上的点，更像是符号学家能够在这个图表中定位自己的标记。
- en: '![](images/02__image003.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image003.png)'
- en: We can also look at each intersection of each of the triangles to gain an idea
    of why things are presented in the order they are. Feelings can be attached to
    images and encodings way before they can be attached to words and tables. Ritual
    and common scripts give a space for interpreted action that’s just second nature
    and doesn’t have to be thought about, similarly to how most phrases just come
    together from words without the native speaker needing to perform metacognition
    about each word individually. All of these eventually lead towards an interpretation
    or a document (a collection of utterances), and in our case, that interpretation
    should be reached by the LLM. This is why, for example, prompt engineering can
    boost model efficacy. Foundation LLMs that have trained on millions of examples
    of ritual scripts are able to replicate the type of script significantly better
    when you explicitly tell the model in the prompt which script needs to be followed.
    Try asking the model to give a step-by-step explanation, maybe prepend your generation
    with “Let’s think about this step-by-step”, you will see the model will generate
    step by step scripts based on previous scripts it’s seen play out.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以看看每个三角形的每个交叉点，以了解为什么事物以它们的顺序呈现。感觉可以与图像和编码联系在一起，远在它们能够与单词和表联系在一起之前。仪式和常见脚本为被解释的动作提供了一个空间，这只是第二天性，不需要考虑，类似于大多数短语只是由单词组成，而母语使用者无需对每个单词进行元认知。所有这些最终都导向一种解释或文档（一系列话语），在我们的案例中，那种解释应该由
    LLM 达成。这就是为什么，例如，提示工程可以提高模型的效力。基础 LLM 在数百万个仪式脚本示例上进行了训练，当您明确告诉模型提示需要遵循哪个脚本时，它能够更好地复制这种类型的脚本。尝试要求模型给出一个逐步解释，也许在你的生成之前加上“让我们逐步思考”，你会看到模型会基于它之前看到的脚本逐步生成脚本。
- en: For those interested, there are specific ways of reading these figures and a
    whole field of semiotics to consider, however, it’s not guaranteed that you’ll
    be able to create the best LLMs by understanding the whole thing. Instead of diving
    really deeply into this, we’ll consider the bare minimum that can help you build
    the best models, UX, and UI for everyone to interact with. For example, one aspect
    of the process of creating meaning is recursiveness. When someone is talking to
    you, and they say something that doesn’t make sense (is “meaningless” to you),
    what do you do? Generally, people will ask one or more clarifying questions to
    figure out what the meaning is, and the process is started over and over until
    the meaning is put across. The most state-of-the-art models that are currently
    on the market do not do this, but they can be made to do it through very purposeful
    prompting, but many people wouldn’t even know to do that without having it pointed
    out to them. In other words, this is a brief introduction to semiotics. You don’t
    need to be able to give in-depth and accurate coordinate-specific explanations
    to experts in the semiotic field by the end of this section. The point I’m really
    trying to push is that this is an organizational system showcasing the minimum
    number of things you actually need to create a full picture of meaning for another
    person to interpret. We are not giving the same amount of the same kinds of information
    to our models during training, but if we did, it would result in a marked improvement
    in model behavior.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些感兴趣的人来说，有特定的方法来阅读这些图表，以及整个符号学领域需要考虑的内容，然而，并不能保证通过理解整个过程就能创建最好的LLM。与其深入研究这个问题，我们将考虑能帮助您为所有人构建最佳模型、用户体验和用户界面的最低要求。例如，创建意义的过程的一个方面是递归性。当有人对你说一些对你来说毫无意义的话时，你会怎么做？通常，人们会问一个或多个澄清问题，以弄清意思，这个过程一遍又一遍地开始，直到意思被传达。目前市场上最先进的模型并没有做到这一点，但通过非常有目的的提示可以做到这一点，但许多人甚至不知道要这样做，除非有人指出。换句话说，这是对符号学的简要介绍。你不需要能够在本节结束时向符号学领域的专家提供深入和准确的坐标特定解释。我真正想强调的是，这是一个组织系统，展示了你实际上需要创建另一个人能够解释的意义的完整图景的最少数量的事物。在训练过程中，我们没有向我们的模型提供相同数量和相同类型的信息，但如果我们这样做了，模型的行为将会显著改善。
- en: These figures are meant to represent a minimal organizational model, where each
    of these pieces is essential. Let’s consider Figure 2.3 which walks through an
    example of using a semiotic triangle. Consider Images, Pictures, and Memories
    and think about what it would be like to try and absorb the knowledge in this
    book without your eyes to process images, and without orthography (a writing system)
    to abstract the knowledge. Looking at Bullet Points, etc., how could you read
    this book without sections, whitespace between letters, and bullet points to show
    you the order and structure to process information with? Look at Semantics and
    literal encoded meaning and imagine the book without diagrams and words that didn’t
    have dictionary definitions. Looking at spreadsheets in the middle, that could
    be a book without any tables or comparative informational organizers, including
    these figures. What would it be like trying to read this book without a culture
    or society that has habits and dogma to use as a lens for our interpretations?
    All of these points form our ability to interpret information, along with the
    lens that we end up passing our information through to recognize patterns.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表旨在代表一个最小的组织模型，其中每个部分都是必不可少的。让我们考虑一下图2.3，它展示了使用符号三角形的示例。考虑一下图像、图片和记忆，并想象一下如果没有眼睛来处理图像，没有文字来抽象知识，那么试图吸收这本书中的知识会是什么样子。看看项目符号等，如果没有章节，字母之间的空白和项目符号来显示你处理信息的顺序和结构，你怎么能读这本书？看看语义学和文字编码的意义，想象一下如果没有图表和没有字典定义的词，这本书会是什么样子。看看中间的电子表格，那可能是一本没有任何表格或比较信息组织者的书，包括这些图表。如果没有一个习惯和教条的文化或社会来作为我们解释的镜头，那么试图读这本书会是什么样子？所有这些观点构成了我们解释信息的能力，以及我们最终通过的镜头来识别模式。
- en: Figure 2.3 Starting at the top left corner, follow the arrows to see the general
    order that we use to build our interpretations and extract meaning from things
    we interact with. Here, we’ve replaced the descriptive words with some examples
    of each point. Try to imagine interpreting this diagram without any words, without
    examples, without the arrows, or even without the pragmatic context of knowing
    what a figure in a book like this is supposed to be for.
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3 从左上角开始，按照箭头的方向看，我们使用的一般顺序来构建我们的解释和从我们所接触的事物中提取意义。在这里，我们用一些每个点的例子替换了描述性词语。试想一下在没有任何单词、没有例子、没有箭头，甚至没有知道这本书中的图是用来干什么的实际语境的情况下，你是如何解释这个图的。
- en: '![](images/02__image004.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image004.png)'
- en: 'So the important question then is: how many of these things do you see LLMs
    having access to to return meaningful interpretations? Does an LLM have access
    to feelings or societal rituals? Currently, they do not, but think about this
    as we go through traditional and newer techniques for NLP inference and think
    about what different models have access to.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的问题是：您认为LLM能够访问多少这样的事物以返回有意义的解释？LLM是否能够访问情感或社会习俗？目前，他们还不能，但在我们讨论传统和新型自然语言处理推理技术时，请考虑这一点，思考不同模型能够访问的内容。
- en: 2.1.3 Multilingual NLP
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.3 多语言自然语言处理
- en: The last challenge that we need to touch on before we evaluate previous NLP
    techniques and current-generation LLMs is the foundation of linguistics and the
    reason LLMs even exist. People have wanted to understand or exploit each other
    since the first civilizations made contact. These cases have resulted in the need
    for translators, and this need has only exponentially increased as the global
    economy has grown and flourished.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们评估以前的自然语言处理技术和当前一代LLM之前，我们需要提及的最后一个挑战是语言学的基础以及LLM的存在原因。自从最早的文明接触以来，人们就希望了解或利用彼此。这些情况导致了对翻译员的需求，随着全球经济的增长和繁荣，这种需求只是呈指数级增长。
- en: It’s pretty simple math for business as well. Did you know that there are almost
    as many native speakers of Bengali as there are native speakers of English? If
    this is the first time you’ve heard of the Bengali language, this should hopefully
    color your perception that there is a valuable market for multilingual models.
    There are billions of people in the world, but only about a third of one billion
    of them speak English natively. If your model is anglocentric, like most are,
    you are missing out on 95% of the people in the world as customers and users.
    Spanish and Mandarin Chinese are easy wins in this area, but more people don’t
    even go that far.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于商业而言，这其实是相当简单的数学问题。您知道孟加拉语的母语使用者几乎和英语的母语使用者一样多吗？如果这是您第一次听说孟加拉语，这应该会让您认识到多语言模型市场的价值。世界上有数十亿人口，但只有大约十亿人的母语是英语。如果您的模型像大多数模型一样以英语为中心，那么您将错过世界上95%的人口作为客户和用户。西班牙语和普通话在这方面都是很容易的选择，但更多的人甚至没有做到这一点。
- en: There are many more politically-charged examples of calling things the same
    or different languages that are out of the scope of this book. These are most
    often because of external factors like government involvement. Keeping these two
    points in mind–that a monolingual system focusing on English doesn’t have the
    coverage or profit potential as many businesses act like and that the boundaries
    between languages and dialects are unreliable at best and systematically harmful
    at worst–it should highlight the dangerous swamp of opinions. Many businesses
    and research scientists don’t even pretend to want to touch this swamp with a
    50-foot pole when designing a product or system.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多涉及政治的例子，涉及将事物称为相同或不同语言的范畴超出了本书的范围。这些通常是由于政府介入等外部因素引起的。牢记这两点——一个以英语为中心的单语系统并没有像许多企业所表现出的覆盖范围或利润潜力那样可靠，并且语言和方言之间的界限充其量是不可靠的，而在最坏的情况下是系统性有害的——这应该突显出危险的意见沼泽。许多企业和研究科学家在设计产品或系统时甚至都不假装想要触及这个沼泽。
- en: Unfortunately, no easy solutions exist at this time. However, the consideration
    of these factors can help you as a scientist or engineer (and hopefully an ethical
    person) to design LLMs that, at the very least, don’t exacerbate and negatively
    contribute to the problems that already exist. The first step in this process
    is deciding on a directional goal from the beginning of the project, either towards
    localization (L10n) or internationalization (I18n). Localization is an approach
    exemplified by Mozilla, which has a different version of their browser available
    through crowdsourced L10n in over 90 languages with no indications of stopping
    that effort. Internationalization is similar, but in the opposite direction, for
    example, Ikea tries to put as few words as possible in their instructional booklets,
    opting instead for internationally recognized symbols and pictures to help customers
    navigate the DIY projects. Deciding at the beginning of the project cuts down
    the effort required to expand to either solution exponentially. Large enough to
    switch the perception of translation and formatting from a cost to an investment.
    In the context of LLMs and their rapid expansion across the public consciousness,
    it becomes even more important to make that consideration early. Hitting the market
    with a world-changing technology that automatically disallows most of the world
    from interacting with it devalues those voices. Having to wait, jeopardizes their
    economic prospects.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，目前还没有简单的解决方案。然而，考虑到这些因素可以帮助你作为一名科学家或工程师（希望也是一名道德人士），设计出至少不会加剧和负面影响已经存在问题的LLMs。这个过程的第一步是从项目开始就确定一个方向性目标，要么朝着本地化（L10n）要么朝着国际化（I18n）。本地化是Mozilla的一种方法，他们通过众包L10n，在90多种语言中提供了不同版本的浏览器，而且没有停止这项工作的迹象。国际化类似，但方向相反，例如，宜家试图在他们的指南册中尽量少使用文字，而是选择使用国际通用的符号和图片来帮助顾客进行DIY项目的导航。在项目开始阶段做出决定将大大减少扩展到任一解决方案所需的努力。足够大到将翻译和格式化的看法从成本转变为投资。在LLMs及其在公众意识中的迅速扩展的背景下，及早考虑这一点变得更加重要。推出一项改变世界的技术，却自动排除了大多数世界的人与其互动，这会贬值那些声音。不得不等待会危及他们的经济前景。
- en: Before continuing, let’s take a moment to reflect on what we’ve discussed so
    far. We’ve hit important points in linguistics illustrating concepts for us to
    consider like understanding that the structure of language is separate from its
    meaning. We have demonstrated quite a journey that each of us takes, both personally
    and as a society, towards having the metacognition to understand and represent
    language in a coherent way for computers to work with. This understanding will
    only improve as we deepen our knowledge of cognitive fields, and as we solve for
    the linguistic features that we encounter. Going along with Figure 2.1, we will
    now demonstrate the computational path for language modeling that we have followed,
    and explore how it has and hasn’t solved for any of those linguistic features
    or strived to create meaning. Let’s move into evaluating the various techniques
    for representing a language algorithmically.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们花点时间反思一下我们到目前为止讨论的内容。我们触及了语言学中的重要观点，这些观点为我们说明了一些概念，比如理解语言的结构与其含义是分开的。我们展示了我们每个人以及作为一个社会所经历的旅程，向着具有元认知能力的方向发展，以便理解和表达语言，以一种计算机可以处理的连贯方式。随着我们加深对认知领域的知识，以及解决我们遇到的语言特征，我们的理解将不断提高。结合图2.1，我们将展示我们所遵循的语言建模的计算路径，并探讨它如何解决了哪些语言特征或努力创造了意义。让我们开始评估各种用于算法表示语言的技术。
- en: 2.2 Language Modeling Techniques
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 语言建模技术
- en: Having delved into the fundamental features of language, the principles of semiotics,
    and the ways in which large language models interpret and process linguistic information,
    we now transition into a more practical realm. In the following section, we will
    explore the various natural language processing techniques that have been developed
    and employed to create these powerful language models. By examining the strengths
    and weaknesses of each approach, we will gain valuable insights into the effectiveness
    of these techniques in capturing the essence of human language and communication.
    This knowledge will not only help us appreciate the advancements made in the field
    of NLP but also enable us to better understand the current limitations of these
    models and the challenges that lie ahead for future research and development.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过深入研究语言的基本特征、符号学的原则以及大型语言模型解释和处理语言信息的方式，我们现在将转向更加实际的领域。在接下来的部分中，我们将探讨各种自然语言处理技术的发展和应用，这些技术已被用于创建这些强大的语言模型。通过检验每种方法的优势和弱点，我们将对这些技术在捕捉人类语言和交流精髓方面的有效性获得宝贵的见解。这样的知识不仅将帮助我们欣赏自然语言处理领域取得的进步，而且还将使我们更好地了解这些模型当前的局限性以及未来研究和发展所面临的挑战。
- en: Let’s take a second to just go over some data processing that will be universal
    to all language modeling. First, we’ll need to decide how we want to break up
    the words and symbols that we’ll be passing into our model, effectively deciding
    what a token will be in our model. Then, we’ll need a way to convert those tokens
    to numerical values and back again. Then, we’ll need to pick how our model will
    actually process the tokenized inputs. Each of the following techniques will build
    upon the previous techniques in at least one of these ways.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一点时间来回顾一些数据处理，这些处理将适用于所有语言建模。首先，我们需要决定如何分割要传入模型的单词和符号，有效地决定我们模型中的一个标记将是什么。然后，我们需要找到一种方法将这些标记转换为数字值，然后再转换回来。接下来，我们需要选择我们的模型将如何处理标记化输入。以下每种技术都将至少在其中一种方面基于先前的技术进行构建。
- en: The first of these techniques is called a Bag of Words (BoW) model, and it consists
    of simply counting words as they appear in text. It can be accomplished very easily
    with a dictionary that scans through text, creating a new vocabulary entry for
    each new word as a key and an incrementing value starting at 1\. Considering its
    simplicity, even this model based entirely on frequency can be quite powerful
    when trying to gain insight into a speaker’s intentions or at least their idiosyncrasies.
    For example, you could run a simple BoW model on inaugural speeches of US presidents,
    searching for the words freedom, economy, and enemy to gain a pretty good insight
    about which presidents assumed office under peacetime, during wartime, and during
    times of monetary strife, just based on how many times each word was mentioned.
    The BoW model’s weaknesses are many, however, as the model provides no images,
    semantics, pragmatics, phrases, or feelings. It doesn’t have any mechanisms to
    evaluate context or phonetics, and because it divides words by default on white
    space (you can obviously tokenize however you want, but try tokenizing on subwords
    and see what happens with this model—spoiler it is bad), it doesn’t account for
    morphology either. Altogether, it should be considered a weak model for representing
    language, but a strong baseline for evaluating other models against. In order
    to solve the problem of Bag of Words models not capturing any sequence data, N-Gram
    models were conceived.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术中的第一种被称为词袋（BoW）模型，它只是简单地计算文本中单词的出现次数。它可以很容易地通过一个扫描文本的字典来完成，为每个新单词创建一个新的词汇表条目作为关键字，并以1开始递增的值。考虑到它的简单性，即使完全基于频率的这种模型在试图洞悉演讲者意图或至少是他们的怪癖时也可能非常有用。例如，你可以在美国总统就职演讲中运行一个简单的BoW模型，搜索自由、经济和敌人这几个词，以便从提及每个单词的次数多少来相当不错地洞悉哪位总统是在和平时期上任的、在战时上任的以及在货币困难时期上任的。然而，BoW模型也有很多弱点，因为这种模型不提供任何图像、语义、语用、短语或感情。它没有任何机制来评估上下文或语音学，并且因为它默认以空格划分单词（显然你可以按照自己的方式进行标记化，但尝试在子词上进行标记化并观察这个模型会发生什么事情——
    剧透，结果糟糕），它也不考虑形态。总的来说，它应该被认为是一种代表语言的弱模型，但也是评估其他模型的强基准。为了解决词袋模型不捕捉任何序列数据的问题，N-Gram模型应运而生。
- en: 2.2.1 N-Gram and Corpus-based techniques
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 N-Gram和基于语料库的技术
- en: N-Gram models represent a marked but efficient improvement to BoW, where you
    are able to give the model a sort of context, represented by N. They are relatively
    simple statistical models that allow you to generate words based on the N-1 context
    space. Looking at Listing 2.1, I’m using trigrams which means N=3\. I clean the
    text and give it minimal padding/formatting to help the model, then we train using
    everygrams, which is meant to prioritize flexibility over efficiency so that you
    could train a pentagram or a septagram (N=5, N=7) model if you wanted instead.
    At the end of the listing where I’m generating, I can give the model up to 2 tokens
    to help it figure out how to generate further. N-Gram models were not created,
    and have never even claimed to attempt, complete modeling systems of linguistic
    knowledge, but they are widely useful in practical applications. They ignore all
    linguistic features, including syntax, and only attempt to draw probabilistic
    connections between words appearing in an N-length phrase.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: N-Gram 模型是对 BoW 的显着但高效的改进，其中您可以给模型一种上下文，由 N 表示。它们是相对简单的统计模型，允许您根据 N-1 上下文空间生成单词。查看列表
    2.1，我正在使用三元组，这意味着 N=3。我清理文本并进行最小的填充/格式化，以帮助模型，然后我们使用 everygrams 进行训练，这意味着优先灵活性而不是效率，因此您也可以选择训练五元或七元（N=5，N=7）模型。在我生成的列表的末尾，我可以给模型多达
    2 个标记，以帮助它进一步生成。N-Gram 模型并未被创建，甚至从未声称尝试完整地对语言知识进行建模，但它们在实际应用中非常有用。它们忽略了所有语言特征，包括句法，只尝试在
    N 长度短语中的词之间建立概率连接。
- en: Looking at Figure 2.2, N-Grams really only use static signals (whitespace, orthography)
    and words to try to extract any meaning. It tries to measure phrases manually,
    assuming that all of the phrases will be the same length. That said, N-Grams can
    be used to create powerful baselines for text analysis, and if the pragmatic context
    of the utterance is already known by the analyst, they can be used to give quick
    and accurate insight into real-world scenarios. It is possible to make an N-Gram
    LLM by just making N=1000000000 or higher, but this doesn’t have any practical
    application, as 99.9% of all text and 100% of all meaningful text contains fewer
    than one billion tokens appearing more than once and that computational power
    can be much better spent elsewhere.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 查看图 2.2，N-Grams 实际上只使用静态信号（空白、正字法）和单词来尝试提取任何含义。它试图手动测量短语，假设所有短语的长度都相同。话虽如此，N-Grams
    可用于创建文本分析的强大基线，如果分析员已经了解话语的实用语境，它们可以用来快速而准确地洞察现实场景。可以通过设置 N=1000000000 或更高来制作
    N-Gram LLM，但这没有任何实际应用，因为 99.9% 的所有文本和 100% 的所有有意义的文本都包含少于十亿次出现的标记，并且计算能力可以更好地用在其他地方。
- en: Listing 2.1 Generative N-Grams Language Model Implementation
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.1 生成式 N-Grams 语言模型实现
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The above code is all that you need to create a generative N-gram model. For
    those of you interested in being able to evaluate that model further, we've included
    the below code to grab probabilities and log scores, or analyze the entropy and
    perplexity of a particular phrase. Because this is all frequency-based, even though
    it’s mathematically significant, it still does a pretty bad job of describing
    how perplexing or frequent real-world language actually is.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码就是创建生成式 N-Gram 模型所需的全部内容。对于那些希望能进一步评估该模型的人，我们在下面的代码中添加了获取概率和对数分数、分析特定短语的熵和困惑度的代码。因为这一切都是基于频率的，即使在数学上具有重要意义，它仍然不能很好地描述现实世界语言的困惑程度或频率。
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: While this code example illustrates creating a trigram language model, unfortunately,
    not all phrases needing to be captured are only 3 tokens long. For example, from
    Hamlet, “To be or not to be,” consists of one phrase with 2 words and one phrase
    with 4 words. This type of phrasal modeling also fails to capture any semantic
    encodings that individual words could have. In order to solve these problems,
    Bayesian statistics were applied to language modeling.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管此代码示例说明了创建三元语言模型，但遗憾的是，并非所有需要捕获的短语都只有 3 个标记。例如，来自《哈姆雷特》的“生存还是毁灭”，包含一个由 2 个词组成的短语和一个由
    4 个词组成的短语。这种短语建模也无法捕获单个词可能具有的任何语义编码。为了解决这些问题，贝叶斯统计学被应用于语言建模。
- en: 2.2.2 Bayesian Techniques
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 贝叶斯技术
- en: 'Bayes’ theorem is one of the most mathematically sound and simple theories
    present in describing the occurrence of your output within your input space. Essentially,
    it calculates the probability of an event occurring based on prior knowledge.
    The theorem posits that the probability of a hypothesis being true given evidence,
    for example that a sentence has a positive sentiment, is equal to the probability
    of the evidence occurring given the hypothesis is true multiplied by the probability
    of the hypothesis occurring, all divided by the probability of the evidence being
    true. Or, expressed mathematically:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是描述输出发生在输入空间中的最数学上严谨且简单的理论之一。基本上，它根据先前的知识计算事件发生的概率。定理认为，给定证据为真的情况下一个假设为真的概率（例如，一句话具有积极情感），等于证据发生在假设为真的情况下的概率乘以假设发生的概率，然后除以证据为真的概率。数学表示为：
- en: P(hypothesis | evidence) = (P(evidence | hypothesis) * P(hypothesis)) / P(evidence)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: P(hypothesis | evidence) = (P(evidence | hypothesis) * P(hypothesis)) / P(evidence)
- en: Or
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 或
- en: P(A|B) * P(B) = P(B|A) * P(A)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: P(A|B) * P(B) = P(B|A) * P(A)
- en: Because this is neither a math book, nor do we care to dive too much into theory,
    we’ll trust you can get further informed about this theorem.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这既不是一本数学书，也不想过多地深入理论，我们相信您可以进一步了解这个定理。
- en: Unfortunately, even though the theorem represents the data in a mathematically
    sound way, it doesn’t account for any stochasticity or multiple meanings of words.
    One word you can always throw at a Bayesian model to confuse it is the word, “it.”
    Any demonstrative pronoun ends up getting assigned values in the same LogPrior
    and LogLikelihood way as all of the other words and gets a static value, which
    is antithetical to the usage of those words. For example, if you’re trying to
    perform sentiment analysis on an utterance, it would be better for you to assign
    all pronouns a null value than to even let them go through the Bayesian training.
    It should be noted also that Bayesian techniques don’t end up creating generative
    language models the way the rest of these will. Because of the nature of Bayes’
    theorem validating a hypothesis, these models work for classification, and can
    bring powerful augmentation to a generative language model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，尽管该定理在数学上对数据进行了准确的描述，但它没有考虑到任何随机性或单词的多重含义。你可以用一个词来困惑贝叶斯模型，让其产生错误的结果，这个词就是"it"。任何指示代词最终都会被赋予与其他单词相同的LogPrior和LogLikelihood值，并且得到一个静态值，而这与这些单词的使用方式相悖。例如，如果你想对一个话语进行情感分析，最好给所有代词赋予一个空值，而不是让它们通过贝叶斯训练。还应该注意，贝叶斯技术并不像其他技术一样会创建生成式语言模型。由于贝叶斯定理验证一个假设，这些模型适用于分类，并且可以为生成式语言模型带来强大的增强。
- en: In Listing 2.2 we show how to create a Naive Bayes classification language model.
    Instead of using a package like sklearn or something that would make writing the
    code a little easier, we opted to write out what we were doing, so it’s a bit
    longer, but should be more informative about how it works. We are using the least-complex
    version of a Naive Bayes model. We haven’t made it multinomial or added anything
    fancy and this could obviously work better if you opted to upgrade it for any
    problem you want. And we highly recommend you do.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2.2节中，我们展示了如何创建一个朴素贝叶斯分类语言模型。我们选择了手写代码而不是使用像sklearn这样的软件包，虽然代码会更长一些，但应该更有助于理解其工作原理。我们使用的是最简化版本的朴素贝叶斯模型，没有添加任何复杂的内容，如果你选择对任何你想解决的问题进行升级，这些都可以得到改进。我们强烈建议您这样做。
- en: Listing 2.2 Categorical Naive Bayes Language Model Implementation
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第2.2节 朴素贝叶斯分类语言模型实现
- en: '[PRE2]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This theorem doesn’t create the same type of language model, but one with a
    list of probabilities associated with one hypothesis. As such, Bayesian language
    models can’t be used effectively to generate language, but it can be very powerfully
    implemented for classification tasks. In my opinion though, Bayesian models are
    often overhyped for even this task. One of the crowning achievements of my career
    was replacing and removing a Bayesian model from production.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定理并没有创建同类型的语言模型，而是一种与一个假设相关的概率列表。因此，贝叶斯语言模型不能有效地用于生成语言，但在分类任务中可以非常强大地应用。尽管如此，在我看来，贝叶斯模型往往被过度炒作，即使是在这个任务中也是如此。我职业生涯中的一个巅峰时刻就是将一种贝叶斯模型替换并从生产中移除。
- en: In Bayesian models one of the big issues is essentially that all sequences are
    completely unconnected, like BoW models, moving us to the opposite end of sequence
    modeling from N-Grams. Similarly to a pendulum, language modeling swings back
    towards sequence modeling and language generation with Markov Chains.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯模型中，一个重要的问题是所有序列实质上都是完全不相关的，就像 BoW 模型一样，将我们从 N-Grams 的序列建模的另一端移动过来。类似于钟摆一样，语言建模在马尔可夫链中再次摆回到序列建模和语言生成。
- en: 2.2.3 Markov Chains
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 马尔可夫链
- en: Often called Hidden Markov Models (HMMs), Markov Chains essentially add state
    to the N-Gram models mentioned before, storing probabilities using hidden states.
    They are often used to help parse text data for even larger models, doing things
    like Part-of-Speech tagging (PoS Tagging, marking words with their part of speech)
    and Named Entity Recognition (NER, marking identifying words with their referent
    and usually type, e.g. LA - Los Angeles - City) on textual data. Markov models,
    as opposed to previous Bayesian models, rely completely on stochasticity (predictable
    randomness) whereas the Bayesian models pretended it didn’t exist. The idea is
    similarly mathematically sound, however, that the probability of anything happening
    *next* depends completely upon the state of *now*. So instead of modeling words
    based solely on their historical occurrence and drawing a probability from that,
    we model their future and past collocation based on what is currently occurring.
    So the probability of “happy” occurring goes down to almost zero if “happy” was
    just output, but goes up significantly if “am” has just occurred. Markov chains
    are so intuitive that they were incorporated into later iterations of Bayesian
    statistics, and are still used in production systems today.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链通常称为隐马尔可夫模型（HMMs），本质上是在之前提到的 N-Gram 模型中添加了状态，使用隐藏状态存储概率。它们通常用于帮助解析文本数据以供更大的模型使用，执行诸如词性标注（Part-of-Speech
    tagging，将单词标记为它们的词性）和命名实体识别（NER，将标识性单词标记为它们的指示词和通常的类型，例如 LA - 洛杉矶 - 城市）等任务。与之前的贝叶斯模型不同，马尔可夫模型完全依赖于随机性（可预测的随机性），而贝叶斯模型则假装它不存在。然而，其思想同样在数学上是正确的，即任何事情发生的概率
    *下一个* 完全取决于 *现在* 的状态。因此，我们不是仅基于其历史发生情况对单词进行建模，并从中提取概率，而是基于当前正在发生的情况对其未来和过去的搭配进行建模。因此，“happy”
    发生的概率会几乎降至零，如果刚刚输出了“happy”，但如果刚刚发生了“am”，则会显着提高。马尔可夫链非常直观，以至于它们被纳入了贝叶斯统计学的后续迭代中，并且仍然在生产系统中使用。
- en: In Listing 2.3 we train a Markov chain generative language model. This is the
    first model where we’ve used a specific tokenizer, which in this case will just
    tokenize based on the white space between words. This is also only the second
    time we’ve referred to a collection of utterances meaning to be viewed together
    as a document. As you play around with this one, pay close attention and make
    some comparisons yourself for how well the HMM generates compared to even a large
    N-gram model.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单 2.3 中，我们训练了一个马尔可夫链生成式语言模型。这是我们第一次使用特定的标记器，本例中将基于单词之间的空格进行标记化。这也是我们第二次提到了一组意图作为文档一起查看的话语。当您尝试此模型时，请仔细注意并自行进行一些比较，看看
    HMM 的生成效果与即使是大型 N-Gram 模型相比如何。
- en: Listing 2.3 Generative Hidden Markov Language Model Implementation
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单 2.3 生成式隐马尔可夫语言模型实现
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code shows a basic implementation of a Markov model for generation, and
    we’d encourage the reader to experiment with it, give it text from songs from
    your favorite musicians or books from your favorite authors and see whether what
    comes out actually sounds like them. HMMs are incredible fast and often used in
    predictive text or predictive search applications. Markov models represent the
    first comprehensive attempt to actually model language from a descriptive linguistic
    perspective, as opposed to a prescriptive one, which is interesting, because Markov
    did not originally intend for linguistic modeling, only to win an argument about
    continuous independent states. Later, Markov used Markov Chains to model vowel
    distribution in a Pushkin novel, so he was at least aware of the possible applications.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码展示了一个用于生成的马尔可夫模型的基本实现，我们鼓励读者对其进行实验，将其与你最喜欢的音乐家的歌曲或最喜欢的作者的书籍进行结合，看看生成的内容是否真的听起来像他们。HMM
    非常快速，通常用于预测文本或预测搜索应用。马尔可夫模型代表了对语言进行描述性语言学建模的首次全面尝试，而不是规范性的尝试，这很有趣，因为马尔可夫最初并不打算用于语言建模，只是为了赢得关于连续独立状态的论战。后来，马尔可夫使用马尔可夫链来模拟普希金小说中的元音分布，所以他至少意识到了可能的应用。
- en: The difference between descriptive and prescriptive linguistics is that one
    focuses on how things *ought* to be, while the other focuses on how things *are*.
    From a language modeling perspective, it has proven vastly more effective to describe
    what language is doing from a corpus or Markov perspective, rather than to attempt
    to prescribe how language ought to behave. Unfortunately, a current state by itself
    cannot be used to give context beyond the now, so historical or societal context
    is unable to be represented effectively in a Markov model. Semantic encoding of
    words also becomes a problem, as is represented in the code example, Markov chains
    will output syntactically correct chains of words that semantically are nonsense,
    similar to “colorless green ideas sleep furiously.” To attempt to solve this problem,
    “continuous” models were developed to allow for a “semantic embedding” representation
    of tokens.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 描述性语言学和规范性语言学的区别在于一个关注事物*应该*如何，而另一个关注事物*是*如何。从语言建模的角度来看，从语料库或马尔可夫模型的角度描述语言正在做什么已被证明要比试图规定语言应该如何行为更加有效。不幸的是，仅有当前状态本身无法提供超越当下的背景，因此历史或社会背景无法在马尔可夫模型中有效地表示。单词的语义编码也成为问题，正如代码示例所示，马尔可夫链将输出语法上正确但语义上毫无意义的单词链，类似于“无色绿色思想狂暴地睡着了。”为了试图解决这个问题，发展出了“连续”模型，以允许对令牌进行“语义嵌入”表示。
- en: 2.2.4 Continuous Language Modeling
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 连续语言建模
- en: A Continuous Bag of Words (CBoW), much like its namesake, the Bag of Words,
    is a frequency-based approach to analyzing language, meaning that it models words
    based on how often they occur. The next word in an utterance has never been determined
    based on probability or frequency. Due to this, the example given will be for
    how to create word embeddings to be ingested or compared by other models using
    a CBoW. We’ll use a neural network for this to give you a good methodology.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 连续词袋（CBoW），就像它的名字一样，词袋一样，是一种基于频率的语言分析方法，意味着它根据单词出现的频率对单词进行建模。话语中的下一个单词从未基于概率或频率来确定。由于这个原因，所给出的示例将是如何使用CBoW创建要由其他模型摄取或比较的单词嵌入。我们将使用神经网络进行此操作，以为您提供一个良好的方法论。
- en: This is the first language modeling technique we’ll see that essentially slides
    a context window over a given utterance (the context window is an N-gram model)
    and attempts to guess what word is in the middle based upon surrounding words
    in the window. For example, let’s say your window has a length of 5, and your
    sentence is, “Learning about linguistics makes me happy,” you would give the CBoW
    [‘learning’, ‘about’, ‘makes’, ‘me’] and try to get the model to guess “linguistics,”
    based upon how many times the model has seen that word occur in similar places
    previously. This should show you why generation is difficult for models trained
    like this, because if you give the model [‘makes’, ’me’, ’</s>] as input, first
    of all it only has 3 pieces of information to try to figure out instead of 4,
    and it also will be biased towards only guessing words it has seen at the end
    of sentences before, as opposed to getting ready to start new clauses. It’s not
    all bad though, one feature that makes continuous models stand out for embeddings
    is that it doesn’t just have to look at words before the target word, they can
    also use words that come after the target to gain some semblance of context.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将看到的第一个语言建模技术，它基本上是在给定话语上滑动一个上下文窗口（上下文窗口是一个N-gram模型），并尝试根据窗口中的周围单词猜测中间的单词。例如，假设你的窗口长度为5，你的句子是“学习语言学让我感到快乐”，你会给出CBoW[‘学习’,
    ‘关于’, ‘使’, ‘我’]，并试图让模型猜测“语言学”，根据模型之前在类似位置看到该单词出现的次数。这应该会向你展示为什么像这样训练的模型难以生成，因为如果你给出[‘使’,
    ’我’, ’</s>]作为输入，首先它只有3个信息要尝试解决，而不是4个，它还将倾向于只猜测它之前在句子末尾看到过的单词，而不是准备开始新的从句。但情况并不完全糟糕，连续模型在嵌入方面突出的一个特征是，它不仅可以查看目标词之前的单词，还可以使用目标之后的单词来获得一些上下文的相似性。
- en: In Listing 2.4 we create our first continuous model. In our case, to keep things
    as simple as possible, we use a bag of words for the language processing and a
    one-layer neural network with two parameters for the embedding estimation, although
    both of those could be substituted out for any other models. For example, you
    could substitute N-grams for the BoW and a Naive Bayes for the neural network,
    and get a Continuous Naive N-gram model. The point is that the actual models used
    in this technique are a bit arbitrary, it’s more the Continuous technique that’s
    important. To illustrate this further, we don’t use any packages other than numpy
    to do the math for the neural network, even though it’s our first one appearing
    in this section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表2.4中，我们创建了我们的第一个连续模型。在我们的例子中，为了尽可能简单，我们使用词袋进行语言处理，使用一个两个参数的单层神经网络进行嵌入估计，尽管这两者都可以被替换为任何其他模型。例如，你可以将N-gram替换为词袋，将朴素贝叶斯替换为神经网络，得到一个连续朴素N-gram模型。重点是这种技术中使用的实际模型有点随意，更重要的是连续技术。为了进一步说明这一点，我们除了使用numpy做神经网络的数学运算外，没有使用任何其他包，尽管这是我们在本节中首次出现。
- en: Pay special attention to the steps below, initializing the model weights, the
    ReLU activation function, the final softmax layer, forward and backpropagation,
    and then how it all fits together in the `gradient_descent` function. These are
    pieces in the puzzle that you will see crop up again and again, regardless of
    programming language or framework. You will need to initialize models, pick activation
    functions, pick final layers, and define forward and backward propagation in Tensorflow,
    Pytorch and HuggingFace, and if you ever start creating your own models as opposed
    to using someone else’s.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 特别注意下面的步骤，初始化模型权重，ReLU激活函数，最终的softmax层，前向和反向传播，以及它们如何在`gradient_descent`函数中组合在一起。这些是拼图中的片段，你将一遍又一遍地看到它们出现，不论编程语言或框架如何。无论你使用Tensorflow、Pytorch还是HuggingFace，如果你开始创建自己的模型而不是使用别人的模型，你都需要初始化模型、选择激活函数、选择最终层，并在前向和反向传播中定义。
- en: Listing 2.4 Generative Continuous Bag of Words Language Model Implementation
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.4生成连续词袋语言模型实现
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The CBoW example is our first code example to showcase a full and effective
    training loop in machine learning. Within all of that, we asked the reader to
    pay special attention to the steps in a training loop, especially the activation
    function, ReLU. As we expect the reader to be at least familiar with various ML
    paradigms, including different activations, we won’t explain the ReLU here, rather
    why you should use it and why you shouldn’t. ReLUs, while solving the vanishing
    gradient problem, don't solve the exploding gradient problem, and they sharply
    destroy all negative comparisons within the model. Better situational variants
    include the ELU, which allows negative numbers normalizing to alpha, or the GEGLU/SWIGLU,
    which works well in increasingly perplex scenarios, like language. However, people
    often use ReLUs, not because they are the best in a situation, but because they
    are easy-to-understand, easy-to-code, and intuitive, even more so than the activations
    they were created to replace like the sigmoid or tanh.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: CBoW示例是我们的第一个代码示例，展示了机器学习中完整有效的训练循环。在所有这些中，我们要求读者特别注意训练循环中的步骤，特别是激活函数ReLU。由于我们希望读者至少熟悉各种ML范式，包括不同的激活函数，因此我们不会在这里解释ReLU，而是解释为什么应该使用它以及为什么不应该使用它。ReLU虽然解决了梯度消失问题，但并未解决梯度爆炸问题，并且会严重破坏模型内的所有负比较。更好的情况变体包括ELU，它允许负数归一化到alpha，或者GEGLU/SWIGLU，在越来越复杂的场景中表现良好，如语言。然而，人们经常使用ReLU，不是因为它们在某种情况下是最好的，而是因为它们易于理解、易于编码、直观，甚至比它们被创建来替代的激活函数如sigmoid或tanh更加直观。
- en: A lot of this ends up being abstracted with packages and the like, but knowing
    what’s going on under the hood will be very helpful for you as someone putting
    LLMs in production. You should be able to predict with some certainty how different
    models will behave in various situations. The next section will dive into one
    of those abstractions, in this case being the abstraction that is created by the
    continuous modeling technique.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 许多情况下都会使用包等进行抽象处理，但了解底层发生的情况对于你作为LLMs投入生产的人来说将非常有帮助。你应该能够相当肯定地预测不同模型在各种情况下的行为。接下来的部分将深入探讨其中一个抽象，这种情况下是由连续建模技术创建的抽象。
- en: 2.2.5 Embeddings
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.5嵌入
- en: Hearkening back to our features of language, it should be easy to connect why
    continuous-style language modeling was such a breakthrough. Embeddings take the
    tokenized vectors we’ve created that don’t contain any meaning, and attempt to
    insert that meaning based on observations that can be made about the text, such
    as word order and subwords appearing in similar contexts. Despite the primary
    mode of meaning being collocation (co-located, words that appear next to each
    other), they prove useful and even show some similarities to human-encoded word
    meaning.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们的语言特征，很容易理解为什么连续式语言建模是一次重大突破。嵌入接受我们创建的令牌化向量，这些向量不包含任何意义，并尝试根据可以从文本中得到的观察结果插入该意义，例如单词顺序和出现在相似上下文中的子词。尽管主要的意义模式是搭配（共同出现，即相邻的单词），但它们被证明是有用的，甚至显示出与人类编码的单词意义一些相似之处。
- en: The quintessential example from Word2Vec, one of the first pre-trained vector
    embeddings, was taking the vector for “king” subtracting the vector for “man”
    adding the vector for “woman” and finding the nearest neighbor to the sum was
    the vector for the word “queen”. This makes sense to us as it mimics human semantics.
    One of the major differences is one that’s already been mentioned a couple of
    times, pragmatics. Humans use pragmatic context to inform semantic meaning, understanding
    that just because you said, “I need food,” doesn’t mean you are actually in physical
    danger without it. Embeddings are devoid of any influence outside of pure usage,
    which feels like it could be how humans learn as well, and there are good arguments
    on all sides here. The one thing holding is that if we can somehow give models
    more sense data, that may open the door to more effective embeddings.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Word2Vec** 中的典型例子之一是，将“king”的向量减去“man”的向量，加上“woman”的向量，然后找到其总和的最近邻居，得到的词向量就是“queen”的向量。这对我们来说是有意义的，因为它模拟了人类的语义。其中一个主要区别已经提到了几次，即语用学。人类使用语用背景来确定语义意义，理解仅仅因为你说了“我需要食物”并不意味着你实际上没有食物就会有危险。嵌入是纯粹使用情境之外的任何影响，这感觉就像是人类学习的方式，各方面都有很好的论点。唯一的问题是，如果我们可以以某种方式为模型提供更多的感知数据，那可能会为更有效的嵌入打开大门。'
- en: In Listing 2.5, we’ll dive into how to visualize embeddings using pyplot. We
    will be going more in-depth into embeddings in later chapters. This is helpful
    for model explainability and also for validation during your pre-training step.
    If you see that your semantically similar embeddings are relatively close to each
    other on the graph, then you’re likely going in the right direction.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 2.5 节中，我们将深入探讨如何使用 pyplot 可视化嵌入。我们将在后面的章节中更深入地研究嵌入。这对于模型的可解释性以及在预训练步骤中进行验证都是有帮助的。如果您发现您的语义相似的嵌入在图上相对靠近彼此，那么您很可能朝着正确的方向前进了。
- en: Listing 2.5 Embedding Visualization
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.5 嵌入可视化
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Figure 2.4 A visualization technique for word embeddings. Visualizing embeddings
    can be important for model explainability.
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.4 一种用于词嵌入的可视化技术。可视化嵌入对于模型的可解释性非常重要。
- en: '![](images/02__image005.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image005.png)'
- en: As we can see in figure 2.4, this is a successful, but a very sparse embedding
    representation that we trained from our CBoW model. Getting those semantic representations
    (embeddings) to be denser is the main place that we can see improvement in this
    field, although many successful experiments have been run where denser semantic
    meaning has been supplanted with greater pragmatic context through instruct and
    different thought chaining techniques. We will address Chain of Thought (CoT)
    and other techniques later. For now, let’s pivot to discussing why our continuous
    embedding technique can even be successful, given frequency-based models are characteristically
    difficult to correlate with reality. All of this starts with the Multilayer Perceptron,
    more than half a century ago.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 2.4 所示，这是我们从 CBoW 模型训练得到的一个成功但非常稀疏的嵌入表示。让这些语义表示（嵌入）更密集是我们可以看到这一领域改进的主要地方，尽管许多成功的实验已经运行过，其中更密集的语义含义已经通过指导和不同的思维链技术取代了更大的语用背景。我们稍后将讨论“思维链”（CoT）和其他技术。现在，让我们转而讨论为什么我们的连续嵌入技术甚至可能成功，鉴于基于频率的模型通常很难与现实相关联。所有这一切都始于半个多世纪前的多层感知器。
- en: 2.2.6 Multilayer Perceptrons
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.6 多层感知器
- en: MLPs are the embodiment of the sentiment, “Machines are really good at doing
    one thing, so I wish we could just use a bunch of machines that are really good
    at the one thing to make one that’s good at a lot of things.” Every weight and
    bias in the neural network of the MLP is good at detecting one feature, so we
    bind a whole bunch of them together to detect larger, more complex features. MLPs
    serve as the primary building block in most neural network architectures. The
    key distinctions between architectures, such as convolutional neural networks
    and recurrent neural networks, mainly arise from data loading methods and the
    handling of tokenized and embedded data as it flows through the layers of the
    model, rather than the functionality of individual layers, particularly the fully-connected
    layers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: MLPs体现了这样一种情感，“机器在做一件事情时真的很擅长，所以我希望我们可以使用一堆真的擅长做这一件事情的机器来制造一个擅长做很多事情的机器。” MLP中的每个权重和偏置都擅长检测一个特征，所以我们将它们绑在一起以检测更大、更复杂的特征。MLPs在大多数神经网络架构中充当主要的构建模块。架构之间的关键区别，如卷积神经网络和循环神经网络，主要来自数据加载方法和处理标记化和嵌入数据在模型层之间流动的方式，而不是个别层的功能，特别是全连接层。
- en: In Listing 2.6 we provide a more dynamic class of neural network that can have
    as many layers and parameters as deemed necessary for your task. We give a more-defined
    and explicit class using pytorch to give you the tools to implement the MLP for
    use in whatever you’d like, both from scratch and in a popular framework.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在2.6中，我们提供了一个更动态的神经网络类，它可以根据您的任务需要拥有任意数量的层和参数。我们使用pytorch提供了一个更明确和明确的类，以便为您提供实现MLP的工具，无论您是从头开始还是在流行的框架中使用。
- en: Listing 2.6 Multilayer Perceptron Pytorch Class Implementation
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.6 多层感知机 Pytorch 类实现
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From the code we can see, as opposed to the CBoW implementation which had a
    static two layers, this MLP is not static in size until it has been instantiated.
    If you wanted to give this model one million layers, you would just have to put
    num_hidden_layers=1000000 when you instantiate the class, although just because
    you *can* give a model that many parameters it won’t make it immediately better.
    LLMs are more than just a lot of layers. Like RNNs and CNNs, the magic of LLMs
    is in how data goes in and moves through the model. To illustrate, let’s look
    at the RNN and one of its variations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码中我们可以看到，与具有静态两层的CBoW实现相反，直到实例化之前，这个MLP的大小是不固定的。如果您想给这个模型一百万层，您只需在实例化类时将num_hidden_layers=1000000，尽管仅仅因为您*可以*给模型那么多参数，并不意味着它会立即变得更好。LLMs不仅仅是很多层。像RNNs和CNNs一样，LLMs的魔力在于数据如何进入并通过模型。为了说明这一点，让我们看一下RNN及其一个变体。
- en: 2.2.7 RNNs and LSTMs
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.7 循环神经网络（RNNs）和长短期记忆网络（LSTMs）
- en: Recurrent Neural Networks (RNNs) are a class of neural networks designed to
    analyze sequences, based on the weaknesses in previous language modeling techniques.
    The logic goes that if language is presented in a sequence, then maybe it should
    be processed in a sequence, as opposed to one token at a time. RNNs accomplish
    this by using logic we’ve seen before, both in MLPs and in Markov Chains, where
    an internal state or memory is referred to when new inputs are processed, and
    creating cycles when connections between nodes are detected as being useful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNNs）是一类神经网络，设计用于分析序列，基于以前语言建模技术的弱点。其逻辑是，如果语言以序列的方式呈现，那么处理它的方式可能应该是按序列而不是逐个标记进行的。RNNs通过使用我们以前看到的逻辑来实现这一点，在MLPs和马尔科夫链中都看到过，即在处理新输入时引用内部状态或记忆，并在检测到节点之间的连接有用时创建循环。
- en: In fully recurrent networks, like the one in Listing 2.7, all nodes start out
    initially connected to all subsequent nodes, but those connections can be set
    to zero to simulate them being broken if they are not useful. This solves one
    of the biggest problems that earlier models suffered from, static input size,
    and enables an RNN and its variants to process variable length inputs. Unfortunately,
    longer sequences create a new problem. Because each neuron in the network has
    connections to subsequent neurons, longer sequences create smaller changes to
    the overall sum, making the gradients smaller and eventually vanishing, even with
    important words.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在完全递归网络中，如清单2.7中的网络，所有节点最初都连接到所有后续节点，但这些连接可以设置为零，以模拟它们被断开如果它们不是有用的。这解决了较早模型遇到的最大问题之一，即静态输入大小，并使得RNN及其变体能够处理可变长度的输入。不幸的是，较长的序列带来了一个新问题。因为网络中的每个神经元都与后续神经元连接，所以较长的序列对总和产生的改变较小，使得梯度变得较小，最终消失，即使有重要的词也是如此。
- en: For example, let’s consider these sentences with the task sentiment analysis,
    “I loved the movie last night,” and, “The movie I went to see last night was the
    very best I had ever expected to see.” These sentences can be considered semantically
    similar, even if they aren’t exactly the same. When moving through an RNN, each
    word in the first sentence is worth more, and the consequence is that the first
    sentence has a higher positive rating than the second sentence, just because of
    the first sentence being shorter. The inverse is true also, exploding gradients
    are also a consequence of this sequence processing, which makes training deep
    RNNs difficult.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑具有任务情感分析的这些句子，“昨晚我喜欢看电影”，以及，“昨晚我去看的电影是我曾经期望看到的最好的。”即使这些句子不完全相同，它们也可以被认为在语义上相似。在通过RNN时，第一句中的每个单词都更有价值，其结果是第一句的积极评分比第二句高，仅仅因为第一句更短。反之亦然，爆炸梯度也是这种序列处理的结果，这使得训练深层RNNs变得困难。
- en: To solve this problem, long short-term memories (LSTMs), which are a type of
    RNN, use memory cells and gating mechanisms to keep being able to process sequences
    of variable length, but without the problems of longer and shorter sequences being
    comprehended differently. Anticipating multilingual scenarios and understanding
    that people don’t think about language in only one direction, LSTMs can also process
    sequences bidirectionally by concatenating the outputs of two RNNs, one reading
    the sequence from left to right, and the other from right to left. This bidirectionality
    improves results, allowing for information to be seen and remembered even after
    thousands of tokens have passed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决这个问题，长短期记忆（LSTMs）作为一种RNN，使用记忆单元和门控机制，保持能够处理可变长度的序列，但没有较长和较短序列被理解为不同的问题。预见到多语言场景，并理解人们不只是单向思考语言，LSTMs还可以通过将两个RNNs的输出连接起来进行双向处理，一个从左到右读取序列，另一个从右到左。这种双向性提高了结果，允许信息即使在经过数千个标记之后也能被看到和记住。
- en: In Listing 2.7 we give classes for both an RNN and an LSTM. In the code in the
    repo associated with this book, you can see the results of training both the RNN
    and LSTM, where the takeaway is that the LSTM gets better accuracy on both training
    and validation sets in half as many epochs (25 vs 50 with RNN). One of the innovations
    to note is the packed embeddings that utilize padding, extending all variable-length
    sequences to the maximum length in order to allow processing any length input,
    as long as it is shorter than the maximum.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单2.7中，我们提供了RNN和LSTM的类。在与本书相关的存储库中的代码中，您可以看到训练RNN和LSTM的结果，结果是LSTM在训练集和验证集上的准确性都更好，而且仅需一半的时代（25次与RNN的50次）。需要注意的一个创新是利用填充的打包嵌入，将所有可变长度序列扩展到最大长度，以便处理任何长度的输入，只要它比最大长度短即可。
- en: Listing 2.7 Recurrent Neural Network and Long Short-Term Memory Pytorch Class
    Implementations
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单2.7 递归神经网络和长短期记忆Pytorch类实现
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Looking above at our classes and instantiations, you should see that the LSTM
    is not vastly different from the RNN. The only differences in the `init` input
    variables are `n_layers` (for convenience, you can also specify it with RNNs),
    `bidirectional`, and `dropout`. Bidirectional allows LSTMs to look ahead in sequences
    to help with meaning and context, but also drastically helps with multilingual
    scenarios, as left-to-right languages like English are not the only format for
    orthography. Dropout, another huge innovation, changes the paradigm of overfitting
    from being only data-dependent, and helps the model not overfit by turning off
    random nodes layer-by-layer during training to force all nodes not to correlate
    to each other. The only differences in the out-of-model parameters is that the
    best optimizer for an RNN is SGD, like our CBoW, and the LSTM uses Adam (could
    use any, including AdamW). Below, we define our training loop and train the LSTM.
    Compare this training loop to the one defined in Listing 2.4 in the `gradient_descent`
    function.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们的类和实例化，你会发现LSTM与RNN并没有太大的区别。 `init` 输入变量中唯一的区别是 `n_layers`（为了方便，你也可以用RNN指定它）、`bidirectional`
    和 `dropout`。双向性允许LSTM向前查看序列以帮助理解意义和上下文，但也极大地有助于多语言场景，因为像英语这样的从左到右的语言并不是正字法的唯一格式。丢失率是另一个巨大的创新，它改变了过拟合的范式，不再仅仅是数据相关，并通过在训练期间逐层关闭随机节点来帮助模型不过度拟合，强制所有节点不相互关联。在模型之外的唯一区别是，RNN
    的最佳优化器是 SGD，就像我们的 CBoW 一样，而 LSTM 使用 Adam（可以使用任何优化器，包括 AdamW）。下面，我们定义了我们的训练循环并训练了
    LSTM。将此训练循环与 `gradient_descent` 函数中的 Listing 2.4 中定义的训练循环进行比较。
- en: One of the amazing things demonstrated in the code here is how much quicker
    the LSTM can learn, compared to previous model iterations, thanks to both bidirectionality
    and dropout. The previous models, though training faster, take hundreds of epochs
    to get the same performance as an LSTM in just 25 epochs. The performance on the
    validation set, as its name implies, adds validity to the architecture, performing
    inference during training on examples it has not trained on and keeping accuracy
    fairly close to the training set.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本代码展示的一个惊人之处在于，与先前的模型迭代相比，LSTM的学习速度要快得多，这要归功于双向性和丢失率。尽管先前的模型训练速度更快，但需要数百个周期才能达到与仅需25个周期的LSTM相同的性能。验证集上的性能，正如其名称所示，为架构增添了有效性，在训练期间对未经训练的示例进行推断，并保持准确性与训练集相当。
- en: The problems with these models are not as pronounced, manifesting primarily
    as being incredibly resource-heavy, especially when being applied to longer, more
    detail-oriented problems, like healthcare and law. Despite the incredible advantages
    of Dropout and Bidirectional processing, they both at least double the amount
    of processing power required to train, so while inference ends up being only 2-3x
    as expensive as an MLP of the same size, training becomes 10-12x as expensive.
    They solved exploding gradients nicely, but exploded the compute required to train
    instead. To combat this a shortcut was devised and implemented which allowed any
    model, including an LSTM, to figure out which parts of a sequence were the most
    influential and which parts could be safely ignored, known as attention.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型的问题并不太明显，主要表现为资源消耗极大，尤其是在应用于更长、更注重细节的问题时，如医疗保健和法律领域。尽管丢失率和双向处理具有令人难以置信的优势，但它们至少会将训练所需的处理能力增加一倍，因此，虽然推断最终只会比相同规模的
    MLP 昂贵2-3倍，但训练则会变得10-12倍昂贵。它们很好地解决了爆炸梯度的问题，但却增加了训练所需的计算量。为了解决这个问题，设计并实施了一种快捷方式，使任何模型，包括
    LSTM，在一个序列中找出哪些部分是最有影响力的，哪些部分可以安全地忽略，这就是注意力。
- en: 2.2.8 Attention
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.8 注意力
- en: Attention is a mathematical shortcut for solving larger context windows faster
    by telling the model through an emergent mathematical formula which parts of an
    input to consider and how much. This is all based upon an upgraded version of
    a dictionary, where instead of just Key and Value pairs, a contextual Query is
    added. We will go more into Attention in later chapters. For now, know that the
    below code is the 10 steps taken from the original paper, and that it’s the big
    differentiator between older NLP techniques and modern ones.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力是通过一种新兴的数学公式告诉模型如何考虑输入的哪些部分以及多少来更快地解决更大上下文窗口的数学快捷方式。这一切都基于一个升级版本的字典，其中不仅仅是键值对，还增加了一个上下文查询。我们将在后面的章节中更深入地讨论注意力。现在，知道下面的代码是从原始论文中提取的10个步骤，它是老的自然语言处理技术和现代技术之间的重要区别。
- en: Attention solves the slowness of training LSTMs, but keeps the high performance
    on a low number of epochs. There are multiple types of attention as well. The
    dot product attention method captures the relationships between each word (or
    embedding) in your query and every word in your key. When queries and keys are
    part of the same sentences, this is known as bi-directional self-attention. However,
    in certain cases, it is more suitable to only focus on words that precede the
    current one. This type of attention, especially when queries and keys come from
    the same sentences, is referred to as causal attention. Language modeling further
    improves by masking parts of a sequence and forcing the model to guess what should
    be behind the mask. Both Dot Product Attention and masked attention are demonstrated
    with functions below.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制解决了训练LSTMs的缓慢问题，但在低数量的epochs上保持了高性能。同时，也有多种类型的注意力机制。点积注意力方法捕捉了查询中每个单词（或嵌入）与关键字中每个单词之间的关系。当查询和关键字是同一句子的一部分时，这被称为双向自注意力。然而，在某些情况下，仅集中在前面的单词更合适。这种类型的注意力，尤其是当查询和关键字来自相同的句子时，被称为因果注意力。通过屏蔽序列的部分并迫使模型猜测应该在掩码后面的内容，语言建模进一步得到改善。下面的函数演示了点积注意力和掩码注意力。
- en: Listing 2.8 Multi-Head Attention Implementation
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.8 多头注意力机制实现
- en: '[PRE8]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Above, in the full implementation of Attention you may have noticed some terminology
    you’re familiar with, namely Key and Value, but you may not have been introduced
    to Query before. Key and Value pairs are familiar because of dictionaries and
    lookup tables, where we map a set of keys to an array of values. Query should
    feel intuitive as a sort of search for retrieval. The Query is compared to the
    Keys, from which a Value is retrieved in a normal operation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面，在注意力的完整实现中，你可能已经注意到了一些你熟悉的术语，即关键字和值，但你可能之前没有听说过查询。关键字和值对因为字典和查找表而熟悉，我们在其中将一组关键字映射到一个值数组。查询应该感觉直观，就像搜索或检索一样。查询与关键字进行比较，从中检索一个值在正常操作中。
- en: In Attention, the Query and Keys undergo dot product similarity comparison to
    obtain an attention score, which is later multiplied by the Value in order to
    get an ultimate score for how much Attention the model should pay to that portion
    of the sequence. This can get more complex, depending upon your model’s architecture
    because both encoder and decoder sequence lengths have to be accounted for, but
    suffice it to say for now that the most efficient way to model in this space is
    to project all input sources into a common space and compare using dot product
    for efficiency.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在注意力中，查询和关键字经历点积相似性比较以获得一个注意力分数，稍后将该分数乘以值以获得模型应该关注序列中的那部分的最终分数。这可能会变得更复杂，这取决于你模型的架构，因为编码器和解码器序列长度都必须考虑在内，但现在可以简单地说，这个空间中建模的最有效方法是将所有输入源投影到一个共同的空间中，并使用点积进行比较以提高效率。
- en: 'This code explanation was a bit more math-heavy than the previous examples,
    but it is needed to illustrate the concept. The math behind Attention is truly
    innovative and has rocketed the field forward. Unfortunately, even with the advantages
    Attention brings to the process of sequence modeling, with LSTMs and RNNs there
    were still issues with speed and memory size. You may notice from the code and
    the math that there is a square root taken, meaning that attention as we use it
    is quadratic. Since then, there have been various techniques, including subquadratics
    like Hyena and the Recurrent Memory Transformer (RMT, basically an RNN combined
    with a transformer) to combat these problems, which we will cover in more detail
    later. For now, let’s move on to the ultimate application of Attention: the Transformer.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码解释比之前的例子更加数学密集，但这是必要的来说明概念。注意力背后的数学是真正创新的，它推动了该领域的进步。不幸的是，即使注意力给序列建模带来了优势，使用LSTMs和RNNs仍然存在速度和内存大小的问题。从代码和数学中你可能会注意到有一个平方根，这意味着我们使用的注意力是二次的。从那时起，出现了各种技术，包括次二次的技术，如Hyena和Recurrent
    Memory Transformer（RMT，基本上是RNN与transformers的组合），以应对这些问题，我们稍后将更详细地讨论。现在，让我们继续介绍注意力的最终应用：transformers。
- en: 2.3 Attention is All You Need
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注意力就是你所需要的一切
- en: 'In the seminal paper, Attention is All You Need[[1]](#_ftn1) Vaswani et al
    take the mathematical shortcut several steps further, positing that for performance
    absolutely no recurrence (the “R” in RNN) or any convolutions[[2]](#_ftn2) were
    needed at all. Instead, they opted to use only Attention and simply specify where
    Q, K, and V were taken from much more carefully. We’ll dive into this presently.
    In our review of this diverse range of NLP techniques, we have observed their
    evolution over time and the ways in which each approach has sought to improve
    upon its predecessors. From rule-based methods to statistical models and neural
    networks, the field has continually strived for more efficient and accurate ways
    to process and understand natural language. Now, we turn our attention to a groundbreaking
    innovation that has revolutionized the field of NLP: the Transformer architecture.
    In the following section, we will explore the key concepts and mechanisms that
    underpin Transformers, and how they have enabled the development of state-of-the-art
    language models that surpass the performance of previous techniques. We will also
    discuss the impact of Transformers on the broader NLP landscape and consider the
    potential for further advancements in this exciting area of research.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在开创性论文《Attention is All You Need》中[[1]](#_ftn1)，Vaswani等人进一步推进了数学上的捷径，假设为了性能绝对不需要任何重复(循环神经网络中的“R”)或任何卷积[[2]](#_ftn2)。相反，他们选择只使用注意力，并简单地指定Q、K和V从哪里被更加小心地取出。我们将立即深入讨论这一点。在我们对这一多样化的NLP技术的回顾中，我们观察到它们随着时间的推移的演变，以及每种方法试图改进其前身的方式。从基于规则的方法到统计模型和神经网络，该领域不断努力寻求更高效、更准确的处理和理解自然语言的方法。现在，我们将注意力转向了一项开创性的创新，彻底改变了NLP领域：transformers架构。在接下来的部分中，我们将探讨支撑transformers的关键概念和机制，以及它们如何使得先进的语言模型的开发超越了以前的技术。我们还将讨论transformers对更广泛的NLP景观的影响，并考虑在这一激动人心的研究领域中进一步进展的可能性。
- en: 2.3.1 Encoders
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 编码器
- en: Encoders are the first half of a full transformer model, excelling in areas
    like classification and feature engineering. One thing Vaswani et al. (2017) figured
    out is that after the embedding layer inside the encoder, any additional transformations
    done to the tensors could end up harming their ability to be compared “semantically,”
    which was the point of the embedding layer. These models rely heavily upon self-attention
    and a clever positional encoding to manipulate those vectors without significantly
    decreasing the similarity expressed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器是完整transformers模型的前半部分，在分类和特征工程等领域表现出色。Vaswani等人(2017)发现的一件事是，在编码器内部的嵌入层之后，对张量进行的任何附加转换都可能损害它们在“语义上”进行比较的能力，而这正是嵌入层的目的。这些模型在很大程度上依赖于自注意力和巧妙的位置编码来操纵这些向量，而不会显著降低所表达的相似性。
- en: 'Again, a key thing about embeddings: they are vector representations of data,
    in our case tokens. Tokens are whatever you pick to represent language. We recommend
    subwords as a general rule, but you will get a feel for which types of tokens
    work well where. Consider the sentence, “The cat in the hat rapidly leapt above
    the red fox and the brown unmotivated dog.” “Red,” and “brown,” should be semantically
    similar, and they are similarly represented after the embedding layer, but they
    fall on positions 10 and 14 respectively in the utterance, assuming that we’re
    tokenizing by word, therefore the positional encoding puts distance between them.
    However, once the sine and cosine functions[[3]](#_ftn3) are applied, it brings
    their meaning back to only a little further apart than they were after the encoding,
    and this encoding mechanism scales brilliantly with recurrence and more data.
    To illustrate, let’s say there was a 99% cosine similarity between [red], and
    [brown] after embedding. Encoding would drastically reduce that, to around 85-86%
    similarity. Applying sine and cosine methodologies as described brings their similarity
    back up to around 96%.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调嵌入的关键点：它们是数据的向量表示，在我们的案例中是令牌。令牌可以是用于表示语言的任何内容。我们通常建议使用子词，但您会对哪种类型的令牌在何处效果良好有所感觉。考虑这句话，“戴着帽子的猫迅速跳过了红狐狸和棕色的无动力狗。”
    “红色”和“棕色”在语义上应该是相似的，并且在嵌入层之后它们被类似地表示，但是在句子中分别占据第10和第14位置，假设我们按单词进行分词，因此位置编码在它们之间引入了距离。然而，一旦应用正弦和余弦函数[[3]](#_ftn3)，它会将它们的含义调整到编码后比之前稍微远一点的位置，并且此编码机制随着循环和更多数据的增加而扩展得非常出色。举例来说，假设嵌入后[红色]和[棕色]之间的余弦相似度为99%。编码将极大地减少这一相似度，降至大约85-86%。按照所述的正弦和余弦方法，将它们的相似度调整回大约96%。
- en: BERT was one of the first architectures to come after the original paper and
    are examples of encoder-only transformers. BERT is an incredibly powerful model
    architecture for how small it is that it is still used in production systems today.
    BERT was the first encoder-only transformer to surge in popularity, showcasing
    that performing continuous modeling using a transformer results in much better
    embeddings than Word2Vec. We can see that these embeddings were better because
    they could be very quickly applied to new tasks and data with minimal training,
    with human-preferred results over Word2Vec embeddings. This resulted in most people
    using BERT-based models for few-shot learning tasks on smaller datasets for a
    while. BERT puts state-of-the-art performance within arms reach for most researchers
    and businesses with minimal effort required.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: BERT是原始论文后出现的第一批体系结构之一，并且是仅编码器的变换器的示例。 BERT是一个非常强大的模型架构，尽管体积小，但至今仍在生产系统中使用。
    BERT是第一个仅编码器的变换器在流行中迅速崛起的例子，展示了使用变换器进行连续建模比Word2Vec获得更好的嵌入。 我们可以看到这些嵌入更好是因为它们可以在最少的训练下很快地应用于新任务和数据，并且与Word2Vec嵌入相比，获得了人们更喜欢的结果。
    这导致大多数人在一段时间内将基于BERT的模型用于较小数据集上的少量学习任务。 BERT使得最先进的性能对大多数研究人员和企业来说只需付出最少的努力就能轻松实现。
- en: Figure 2.5 An Encoder, visualized. Encoders are the first half of the full transformer
    architecture, and excel in NLU tasks like classification or NER. Encoder models
    improve upon previous designs by not requiring any priors or recurrence, and use
    clever positional encoding and multihead attention.
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5 编码器，可视化。编码器是完整变换器架构的前半部分，在诸如分类或命名实体识别（NER）等NLU任务中表现出色。编码器模型改进了以前的设计，不需要任何先验知识或循环，并且使用了巧妙的位置编码和多头注意力。
- en: '![](images/02__image006.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image006.png)'
- en: 'Strengths:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：
- en: Classification and hierarchical tasks showcasing understanding
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类和展示理解的层次任务
- en: Blazing fast, considering the long-range dependency modeling
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在考虑长期依赖建模时极快速度。
- en: Builds off of known models, CBoW in Embedding, MLP in Feed Forward, etc.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立在已知模型的基础上，嵌入中的CBoW，前馈中的MLP等。
- en: 'Weaknesses:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 弱点：
- en: As suggested, requires lots of data to be effective (although less than RNNs)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如建议所示，需要大量数据才能发挥效果（尽管比RNN少）。
- en: Even more complex architecture
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更复杂的架构
- en: 2.3.2 Decoders
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 解码器
- en: Decoder models, as shown below, are larger versions of encoders that have 2
    multi-head attention blocks and 3 sum and normalize layers in their base form.
    They are the 2nd half of a transformer behind an encoder. This results in a model
    that is very good at masked language modeling and learning and applying syntax
    super quickly leading to the almost immediate idea that decoder-only models are
    needed to achieve Artificial General Intelligence. A useful reduction of encoder
    vs decoder tasks is that encoders excel in natural language understanding (NLU)
    tasks, while decoders excel in natural language generation (NLG) tasks. Some examples
    of decoder-only transformer architectures are the Generative Pretrained Transformer
    (GPT) family of models. These models follow the logic of transformational generative
    grammar being completely syntax based, allowing for infinite generation of all
    possible sentences in a language.[[4]](#_ftn4)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器模型（如下所示）是编码器的较大版本，具有2个多头注意力块和3个求和和标准化层。它们是transformers的后半部分。 这导致模型在屏蔽语言建模、学习和应用语法等方面非常强大，从而立即想到需要仅解码器模型以实现人工智能。编码器与解码器任务的有用区分是，编码器在自然语言理解（NLU）任务中表现出色，而解码器在自然语言生成（NLG）任务中表现出色。一些仅解码器的transformers体系结构的示例是产生预训练的transformers（GPT）系列模型。这些模型遵循转换生成语法的逻辑，完全基于语法，允许语言中所有可能句子的无限生成。[[4]](#_ftn4)
- en: Figure 2.6 a decoder visualized. Decoders are the second half of a full transformer,
    and they excel in NLG tasks like chatbots and storytelling. Decoders improve upon
    previous architectures in the same way as encoders, but they add shifting their
    output one space to the right for next-word generation to help utilize the advantages
    of multihead self-attention.
  id: totrans-153
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6解码器的可视化。解码器是完整transformers的第二个部分，擅长于像聊天机器人和讲故事这样的自然语言生成任务。解码器在以前的架构上做出了改进，但它们将其输出向右移动一个空格以用于下一个词汇的生成，从而帮助利用多头自我关注的优势。
- en: '![](images/02__image007.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image007.png)'
- en: 'Strengths:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 优势：
- en: Generating the next token in a sequence (shifted right means taking already-generated
    tokens into account)
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成序列中的下一个标记（向右移动意味着考虑到已生成的标记）
- en: Building off of both known models and also encoders
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于已知模型和编码器的构建
- en: Can be streamed during generation for great UX
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在生成过程中进行流式传输，提供良好的用户体验
- en: 'Weaknesses:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 弱点：
- en: Syntax only models can often struggle to insert the expected or intended meaning
    (see all “I force an AI to watch 1000 hours of x and generated” memes from 2018-present)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅基于语法的模型经常难以插入预期或意图（请参见自2018年以来所有的“我强迫AI观看1000小时x并生成”模因）
- en: Hallucinations
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幻觉
- en: 2.3.3 Transformers
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3transformers
- en: The full transformer architecture takes advantage of both encoders and decoders,
    passing the understanding of the encoder into the second Multi-Head Attention
    block of the decoder before giving output. As each piece of the transformer has
    a specialty in either understanding or generation, it should feel intuitive for
    the full product to be best at conditional generation tasks like translation or
    summarization, where some level of understanding is required before generation
    occurs. Encoders are geared towards processing input at a high level, and decoders
    focus more on generating coherent output, the full transformer architecture can
    successfully understand, then generate based on that understanding. Transformer
    models have an advantage in that they are built around parallelization, which
    adds speed that can’t currently be replicated in LSTMs. If LSTMs ever get to a
    point where they can run as quickly as transformers, they may become competitive
    in the state-of-the-art field. The Text-To-Text Transfer Transformer (T5) family
    of models are examples of transformers.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 全面的transformers架构利用了编码器和解码器，将编码器的理解传递到解码器的第二个多头注意力块中，然后才能输出。由于transformers的每个部分都专门负责理解或生成，因此对于条件生成任务（如翻译或摘要），整个产品应该感觉很直观，在生成之前需要一定程度的理解。编码器旨在以高层次处理输入，解码器则更专注于生成连贯的输出，全面的transformers架构可以成功地理解，然后基于这种理解进行生成。transformers模型具有优势，因为它们围绕着并行构建，这增加了速度，目前在LSTMs中无法复制。如果LSTM能够达到可以像transformers一样快速运行的点，它们可能会在最先进的领域竞争。文本到文本转移transformers（T5）系列模型是transformers的示例。
- en: Figure 2.7 A full transformer visualized. A full transformer combines both the
    encoder and the decoder and does well on all of the tasks of each, as well as
    conditional generation tasks such as summarization and translation. Because transformers
    are bulkier and slower than each of their halves, researchers and businesses have
    generally opted to use those halves over the whole thing, despite the speed and
    memory boosts being minimal.
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.7 一个完整的变换器可视化。一个完整的变换器结合了编码器和解码器，并在每个任务以及条件生成任务（如摘要和翻译）上表现良好。由于变换器比它们的各半部分更笨重和更慢，因此研究人员和企业通常选择使用这些半部分而不是整个东西，尽管速度和内存增益都很小。
- en: '![](images/02__image008.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image008.png)'
- en: 'Strengths:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 优点：
- en: Both an encoder and decoder, so is good at everything each of those are good
    at
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时具有编码器和解码器，因此擅长于它们各自擅长的一切
- en: Highly parallelized for speed and efficiency
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高度并行化以提高速度和效率
- en: 'Weaknesses:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 弱点：
- en: Memory intensive, but still less than LSTMs of the same size
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 占用内存多，但仍然比相同大小的 LSTM 少
- en: Requires large amounts of data and VRAM for training
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要大量数据和 VRAM 进行训练
- en: As you’ve probably noticed, most of the models we’ve discussed aren’t at all
    linguistically focused, being heavily syntax-focused, if attempting to model real
    language at all. Models, even state-of-the-art transformers only have semantic
    approximations, no pragmatics, no phonetics, and only really utilize morphology
    during tokenization. This doesn’t mean the models can’t learn these, nor does
    it mean that, for example, transformers can’t take audio as an input, just that
    the average usage doesn’t. With this in mind, it is nothing short of a miracle
    that they work as well as they do, and they really should be appreciated as such.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，我们讨论的大多数模型根本不是语言学焦点，而是非常注重语法，即使在尝试模拟真实语言时也是如此。模型，即使是最先进的变换器，也只有语义近似，没有语用学、音韵学，而且在分词期间只真正利用形态。这并不意味着模型无法学习这些知识，也不意味着例如变换器无法将音频作为输入，只是平均使用情况下并没有这样做。考虑到这一点，它们能够表现得如此出色简直就是一个奇迹，而且确实应该被当作奇迹来欣赏。
- en: 'Through this chapter so far we’ve attempted to highlight where the current
    limitations are in models, and we will dive into where to go to improve upon them
    in the rest of this book. One such route is one that’s already been and being
    explored to great success, transfer learning and finetuning large foundational
    models. This technique came about soon after BERT’s initial release, when researchers
    discovered that although BERT performed generally well on a large number of tasks,
    if they wanted it to perform better on a particular task or data domain, all they
    needed to do was retrain the model on data representative of the task or domain,
    but not from scratch. Take all of the pretrained weights that BERT learned while
    creating the semantic approximation embeddings on a much larger dataset, then
    significantly less data is required to get state-of-the-art (SotA) performance
    on the portion that you need. We’ve seen this with BERT, and with the GPT family
    of models as they’ve come out respectively, and now we’re seeing it again to solve
    exactly the challenges brought up: semantic approximation coverage, domain expertise,
    availability of data.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章至今，我们试图突出当前模型存在的限制，并将在本书的其余部分深入探讨如何改进它们的方法。其中一条路线是已经被探索并取得了巨大成功的迁移学习和对大型基础模型进行微调。这项技术在
    BERT 初始发布后不久就出现了，当研究人员发现，虽然 BERT 在大量任务上表现得普遍良好，但如果他们想让它在特定任务或数据领域上表现更好，他们只需在代表该任务或领域的数据上重新训练模型，而不是从头开始。获取
    BERT 在创建语义近似嵌入时学到的所有预训练权重，然后就可以用较少的数据在你需要的部分上获得最先进的性能。我们已经在 BERT 和 GPT 系列模型上看到了这一点，它们分别问世时也是如此，现在我们又再次看到它们解决了带来的挑战：语义近似覆盖、领域专业知识、数据的可用性。
- en: 2.4 Really Big Transformers
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 非常大的变换器
- en: Enter the Large Language Model. Since their introduction transformer based models
    have continued to only get larger and larger, and not just by their size and number
    of parameters, but also the size of their training datasets and training cycles
    has gotten larger and longer as well. If you ever studied machine learning or
    deep learning during the 2010s, you likely heard the moniker, “more layers doesn’t
    make the model better.” LLMs prove this both wrong and right. Wrong because their
    performance is unparalleled, oftentimes even matching smaller models that have
    been meticulously finetuned on a particular domain and dataset, even the ones
    trained on proprietary data. Right because of the challenges that come with both
    training and deploying them.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 进入大型语言模型。自引入基于 transformer 的模型以来，它们只变得越来越大，不仅是它们的大小和参数数量，而且它们的训练数据集和训练周期也越来越大和长。如果您在
    2010 年代学习机器学习或深度学习，您可能已经听说过“层数越多，模型就不一定越好”这个口号。LLM 证明了这一点既对又错。错误是因为它们的性能无与伦比，通常甚至可以与在特定领域和数据集上进行精细微调的较小模型相匹配，甚至是那些在专有数据上训练的模型。正确的是由于训练和部署它们所带来的挑战。
- en: One of the major differences between LLMs and LMs involves transfer learning
    and finetuning. Exactly the same as the previously-large LMs, LLMs are pretrained
    on massive text corpora, enabling them to learn general language features and
    representations that can be finetuned for specific tasks. Because LLMs are so
    massive though and their training datasets so large LLMs are able to achieve better
    performance with less labeled data, which was a significant limitation of earlier
    language models. Often times you can finetune an LLM to do highly specialized
    tasks with only a dozen or so examples.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大型语言模型）和 LM（语言模型）之间的一个主要区别在于迁移学习和微调。与先前的大型 LM 一样，LLM 在大规模文本语料库上进行预训练，使其能够学习通用语言特征和表示，以便进行特定任务的微调。由于
    LLM 如此庞大，其训练数据集也很大，因此L LM 能够在较少的标记数据的情况下获得更好的性能，这是早期语言模型的一个重要局限性。通常情况下，您可以使用仅十几个示例微调
    LLM，使其执行高度专业化的任务。
- en: However, what really makes LLMs powerful and has opened the door to widespread
    business use cases is their ability to do specialized tasks without any finetuning,
    but just simple prompting. Just give a few examples of what you want in your query
    and the LLM is able to produce results. This is called few-shot prompting when
    it’s trained on smaller labeled data sizes, one-shot, when given only one example,
    and zero-shot, when the task is totally novel. LLMs, especially those trained
    using RLHF and prompt engineering methodologies, can perform few-shot learning
    on a whole new level, where they can generalize and solve tasks with only a few
    examples. This ability is a significant advancement over earlier models that required
    extensive fine-tuning or large amounts of labeled data for each specific task.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，真正让 LLM 强大并打开了广泛业务应用的大门的是它们能够在没有任何微调的情况下执行专门的任务，只需一个简单提示即可。只需给出您查询中想要的内容的几个示例，LLM
    就能产生结果。这称为少量提示，当其在较小的标记数据大小上进行训练时，称为单次，当只给出一个示例时，称为零次，当任务是全新时。特别是使用 RLHF 和提示工程方法训练的
    LLM 可以在一个全新的层次上执行少量提示学习，从而能够在仅有少量示例的情况下进行任务的广义求解。这种能力是早期模型的一个重大进展，早期的模型需要用于每个特定任务进行大量的微调或标记数据。
- en: LMs previously have shown promise in the few and zero-shot learning domains,
    and LLMs have proven that promise to be true. As models have gotten larger we
    find they are capable of accomplishing new tasks where smaller models can’t. We
    call this emergent behaviors[[5]](#_ftn5) and figure 2.8 demonstrates eight different
    tasks that LMs couldn’t perform better than random, then suddenly once the models
    got large enough they could.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的语言模型已经展示出在几次提示学习领域和零次提示学习领域上的潜力，而 LLM 证明了这个潜力的真实。随着模型变得越来越大，我们发现它们能够执行新任务，而较小的模型则无法做到。我们称之为新兴行为[[5]](#_ftn5)，而图
    2.8 说明了八个不同的任务，其中 LMs 不能比随机更好地完成，而一旦模型足够大，它们就可以做到。
- en: Figure 2.8 Examples of LLMs demonstrating emergent behaviors when tasked with
    few-shot prompting tasks after the model scale reaches a certain size.
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.8 显示了 LLM 在模型规模达到一定大小后执行几次提示任务时所显示出的新兴行为的示例。
- en: '![](images/02__image009.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image009.png)'
- en: LLMs have demonstrably great Zero-Shot capabilities as well, which is both due
    to their vast parameter sizes, and also the main reason for their popularity and
    viability in the business world. LLMs also exhibit improved handling of ambiguity
    due to their large size and capacity. They are better at disambiguating words
    with multiple meanings and understanding the nuances of language, resulting in
    more accurate predictions and responses. This isn’t because of an improved ability
    or architecture as they share their architecture with smaller transformers, but
    because they have vastly more examples of how people generally disambiguate. LLMs
    therefore respond with the same disambiguation as is generally represented in
    the dataset. Thanks to the diverseness of the text data LLMs are trained on, they
    exhibit increased robustness in handling various input styles, noisy text, and
    grammatical errors.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 也具有明显优异的零样本能力，这既归因于它们庞大的参数大小，也是它们在商业世界中受欢迎和可行的主要原因。LLM 由于其巨大的大小和容量，还表现出对歧义的改进处理能力。它们更擅长消除具有多重含义的词语并理解语言的细微差别，从而产生更准确的预测和响应。这不是因为它们具有改进的能力或架构，因为它们与较小的transformers共享架构，而是因为它们具有更多关于人们通常如何消除歧义的示例。因此，LLM
    响应的歧义消除与数据集中通常表示的歧义消除相同。由于 LLM 所训练的文本数据的多样性，它们在处理各种输入样式、嘈杂文本和语法错误方面表现出了增强的鲁棒性。
- en: Another key difference between LLMs and LMs is input space. A larger input space
    is important since it makes few-shot prompting tasks that much more viable. Many
    LLMs have max input sizes of 8000+ tokens (GPT-4 currently sports 32k), and while
    all the models previously discussed in the chapter could also have input spaces
    that high, they generally aren’t considered to. We have recently seen a boom in
    this field as well, with techniques like Recurrent Memory Transformer (RMT) allowing
    1,000,000+ token context spaces, which rocket LLMs even more towards proving that
    bigger models really are always better. LLMs are designed to capture long-range
    dependencies within text, allowing them to understand context more effectively
    than their predecessors. This improved understanding enables LLMs to generate
    more coherent and contextually relevant responses in tasks like machine translation,
    summarization, and conversational AI.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 和 LM 之间的另一个关键区别是输入空间。较大的输入空间很重要，因为它使得少样本提示任务变得更加可行。许多 LLM 的最大输入大小为 8000+
    令牌（GPT-4 目前支持 32k），虽然在本章讨论的所有模型也可以具有如此高的输入空间，但它们通常不会被考虑进去。我们最近也看到了这一领域的蓬勃发展，如递归记忆transformers（RMT）等技术使得上下文空间可达
    1,000,000+ 令牌，这使得 LLM 更加向着证明更大的模型总是更好的方向迈进。LLM 旨在捕捉文本中的长距离依赖关系，使它们能够比其前身更有效地理解上下文。这种改进的理解使得
    LLM 在任务中生成更连贯和上下文相关的响应，例如机器翻译、摘要和对话 AI。
- en: LLMs have revolutionized NLP by offering powerful solutions to problems that
    were challenging for earlier language models. They bring substantial improvements
    in contextual understanding, transfer learning, and few-shot learning. As the
    field of NLP continues to evolve, researchers are actively working to maximize
    the benefits of LLMs while mitigating all potential risks. Because a better way
    to approximate semantics hasn’t been found, they make bigger and more dimensional
    approximations. Because a good way of storing pragmatic context hasn’t been found,
    LLMs often allow inserting context either into the prompt directly, into a part
    of the input set aside for context, or even through sharing of databases with
    the LLM at inference. This doesn’t create pragmatics or a pragmatic system within
    the models, same as embeddings don’t create semantics, but it allows the model
    to correctly generate syntax that mimics how humans respond to those pragmatic
    and semantic stimuli. Phonetics is a place where LLMs could likely make gigantic
    strides, either as completely text-free models, or as a text-phonetic hybrid model,
    maybe utilizing IPA in addition to or instead of text. It is exciting to consider
    the possible developments that we are watching sweep this field right now.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs通过提供强大的解决方案，彻底改变了NLP中那些对早期语言模型具有挑战性的问题。它们在上下文理解、迁移学习和少样本学习方面带来了显著的改进。随着NLP领域的不断发展，研究人员正在积极努力最大限度地利用LLMs的优势，同时减轻所有潜在风险。由于还没有找到更好的近似语义的方法，它们做出了更大更多维度的近似。由于还没有找到存储实用语境的良好方法，LLMs通常允许将上下文插入到提示中，插入到专门用于上下文的输入部分中，甚至通过在推断时与LLM共享数据库来进行插入。这并不会在模型中创建实用语境或实用语境系统，就像嵌入并不会创建语义一样，但它允许模型正确生成模仿人类对这些实用语境和语义刺激做出反应的句法。语音学是LLMs可能会取得巨大进展的地方，可以作为完全无文本的模型，或者作为文本-语音混合模型，也许还可以使用国际音标而不是文本。考虑到我们正在目睹的这一领域的可能发展，令人兴奋。
- en: At this point you should have a pretty good understanding of what LLMs are and
    some key principles of linguistics that will come in handy when putting LLMs in
    Production. Mainly, you should be able to now start reasoning what type of products
    will be easier or harder to build. Consider figure 2.9, tasks in the lower left
    hand corner like Writing Assistants and ChatBots are LLMs bread and butter. Text
    generation based on a little context from a prompt are problems that are strictly
    syntax based, with a large enough model trained on enough data we can do this
    pretty easily. A Shopping Assistant is pretty similar and rather easy to build
    as well, however, we are just missing pragmatics. The assistant needs to know
    a bit more about the world like products, stores, and prices. With a little engineering
    we can add this information into a database and give this context to the model
    through prompting.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该对LLM是什么以及在将LLM投入生产时将会用到的一些语言学关键原理有相当清楚的理解了。主要的是，现在你应该能够开始思考哪种类型的产品会更容易或更难构建。考虑图2.9，像写作助手和聊天机器人这样的任务位于左下角，是LLMs的主要应用场景。基于提示中的一点上下文进行文本生成的问题严格来说是基于句法的，通过足够大的模型在足够多的数据上进行训练，我们可以相当轻松地完成这个任务。购物助手也是相当相似且相对容易构建的，然而，我们只是缺少实用语境。助手需要了解更多关于世界的信息，比如产品、商店和价格。通过一点工程技术，我们可以将这些信息添加到数据库中，并通过提示将这些上下文提供给模型。
- en: On the other end consider a ChessBot. LLMs *can* play chess. They aren’t any
    good. They have been trained on chess games and understand that “E4” is a common
    first move, but their understanding is completely syntactical. LLMs really only
    understand that the text they should generate should contain a letter between
    A and H and a number between 1 and 8\. Like the Shopping Assistant, they are missing
    pragmatics and don’t have a clear model of the game of chess. In addition, they
    are also missing semantics. Encoders might help us understand the words “King”
    and “Queen” are similar to each other, but they don’t really help us understand
    that “E4” is a great move one moment for one player and that same “E4” move is
    a terrible move the very next moment for a different player. LLMs are also completely
    lacking knowledge based on phonetics and morphology for chess as well, but these
    are not as important for this case. Either way, we hope this exercise will better
    inform you and your team on your next project.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，考虑一下象棋机器人。LLM*能够*下棋。但是它们不擅长。它们经过了象棋比赛的训练，并理解“E4”是一个常见的首步，但是它们的理解完全是语法上的。LLM实际上只理解它们应该生成的文本应该包含A到H之间的一个字母和1到8之间的一个数字。就像购物助手一样，它们缺少语用学，对象棋游戏没有一个清晰的模型。此外，它们也缺乏语义。编码器可能会帮助我们理解“国王”和“皇后”这两个词是相似的，但它们并没有真正帮助我们理解“E4”对于一个玩家来说是一个伟大的着法，但对于另一个玩家来说，同样的“E4”着法可能是一个糟糕的着法。LLM也完全缺乏基于音韵学和形态学的关于象棋的知识，但这些对于这个案例来说不是很重要。无论如何，我们希望这个练习能够更好地为您和您的团队在下一个项目中提供信息。
- en: Figure 2.9 How difficult or easy certain tasks are for LLMs and what approaches
    to solve them.
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.9 LLM对于某些任务的难易程度以及解决这些任务的方法。
- en: '![](images/02__image010.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image010.png)'
- en: LLMs have amazing benefits, but with all of these capabilities come some limitations.
    Foundational LLMs require vast computational resources for training, making them
    less accessible for individual researchers and smaller organizations. This is
    being remedied with techniques we’ll talk about throughout the book like Quantization,
    Textual Embeddings, Low-Rank Adaptation, Parameter-Efficient Fine Tuning, and
    Graph Optimization, but foundation models are still currently solidly out of the
    average individual’s ability to train effectively. Beyond that, there are concerns
    that the energy consumption associated with training LLMs could have significant
    environmental impact and problems associated with sustainability. This is a complex
    issue largely out of the scope of this book, but we would be remiss not to bring
    it up. Last, but not least, since LLMs are trained on large-scale datasets containing
    real-world text, they may learn and perpetuate biases present in the data, leading
    to ethical concerns, not by the fault of the researchers or the algorithms, more
    because real-world people aren’t censoring themselves to provide optimal unbiased
    data. For example, if you ask a text-to-image diffusion LLM to generate 1000 images
    of “leader,” 99% of the images feature men, and 95% of the images feature people
    with white skin. The concern here isn’t that men or white people aren’t or shouldn’t
    be depicted as leaders, rather that it shows that the model isn’t truly representing
    the world accurately.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大型语言模型）有着惊人的好处，但是随着所有这些能力的出现也带来了一些限制。基础性的LLM需要庞大的计算资源进行训练，这使得它们对个人研究人员和较小的组织来说不太容易接触。我们将在本书中讨论一些技术，比如量化、文本嵌入、低秩调整、参数高效微调和图优化等技术来解决这个问题，但是基础模型目前仍然完全超出了普通个人有效训练的能力范围。此外，人们担心LLM的训练能耗可能会对环境产生重大影响，并伴随着可持续性的问题。这是一个复杂的问题，主要超出了本书的范围，但我们不提及这一点就不妥。最后但同样重要的是，由于LLM是在包含真实世界文本的大规模数据集上进行训练的，它们可能会学习并延续数据中存在的偏见，引发伦理关切，这并不是研究人员或算法的过错，而更多是因为现实世界的人们没有自我审查提供最佳无偏数据。例如，如果你要求一个文本到图像扩散的LLM生成1000张“领导者”的图像，其中99%的图像会以男性为特征，95%的图像会以白人为特征。这里的问题不是男性或白人不应该被描绘为领导者，而是显示出模型并没有真实准确地代表世界。
- en: Figure 2.10 Midjourney 5, which is currently the most popular text2img model
    on the market, when prompted with only one token, “Leader,”(Shown Left) changed
    a well-known popular feminist icon, Rosie the Riveter into a male depiction. ChatGPT
    (Shown Right) writes a function to place you in your job based on your race, gender,
    and age. These are examples of unintended outputs.
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.10 中的 Midjourney 5，目前是市场上最受欢迎的文本转图像模型，当只有一个标记“领导者”（左图所示）时，将一个众所周知的流行女性主义象征，罗西·飞弹手，变成了男性形象。ChatGPT（右图所示）编写了一个函数，根据您的种族、性别和年龄来安排您的工作。这些都是意想不到的输出示例。
- en: '![](images/02__image011.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](images/02__image011.png)'
- en: Sometimes, more nuanced bias is brought out, for example, in the Midjourney
    example demonstrated in Figure 2.10 a popular feminist icon “Rosie the Riveter,”
    without being prompted at all (the only prompt given to the model was the word
    “leader”) was changed to a man. The model didn’t think about this change at all,
    it just determined during its sampling steps that the prompt “leader,” looks more
    like a man. Many people will argue about what “good,” and “bad,” mean in this
    context, and instead of entering that discussion we’ll simply talk about what
    accurate means. LLMs are trained on a plethora of data with the purpose of returning
    the most accurate representations possible. When they are still unable to return
    accurate representations, especially with their heightened abilities to disambiguate,
    we can view that as bias that is harmful to the model’s ability to fulfill its
    purpose. Later we will discuss techniques to combat this harmful bias, not for
    any political purpose, but to allow you as an LLM creator to get the exact outputs
    that you intend and minimize the number of outputs that you do not intend.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，更微妙的偏见会显现出来，例如，在图 2.10 中展示的 Midjourney 示例中。一个广受欢迎的女性主义象征“罗西·飞弹手”（Rosie the
    Riveter），在没有任何提示的情况下（模型仅给出的提示是“领导者”一词），被改变为了一个男性。模型根本没有考虑到这种改变，它只是在采样步骤中确定，“领导者”这个提示更像是一个男人。很多人会争论在这种情况下“好”和“坏”意味着什么，但我们将简单地讨论准确意味着什么。LLM（大型语言模型）被训练在大量数据上，目的是返回可能最准确的表示。当它们仍然无法返回准确的表示时，特别是在它们有能力消除歧义时，我们可以将其视为对模型实现其目的的有害偏见。后面我们将讨论对抗这种有害偏见的技术，不是出于任何政治目的，而是为了让您作为LLM创建者获得您想要的确切输出，并尽量减少您不想要的输出的数量。
- en: Alright, we’ve been building up to this the entire chapter let’s go ahead and
    run our first LLM! In listing 2.9 we download the Bloom model, one of the first
    open source LLMs to be created, and generate text! Very exciting stuff.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，我们整整一个章节都在建立到这一点，让我们继续运行我们的第一个LLM！在清单 2.9 中，我们下载了 Bloom 模型，这是第一个开源LLM之一，并生成了文本！非常令人兴奋的事情。
- en: Listing 2.9 Running our first LLM
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 清单 2.9 运行我们的第一个LLM
- en: '[PRE9]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Did you try to run it?!? If you did, you probably just crashed your laptop.
    Oopsie! Forgive me for a little harmless MLOps hazing, but getting some first-hand
    experience on how large these models can get and how difficult they can be to
    run is helpful experience to have. We will be talking more about the difficulties
    of running LLMs and give you some of the tools you need to actually run this in
    the next chapter. If you don’t want to wait and would like to get a similar but
    much smaller LLM running change the model name to `“bigscience/bloom-3b”` and
    run it again. It should work just fine this time on most hardware.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你试过跑它了吗？！如果你试过，你可能刚刚让你的笔记本电脑崩溃了。糟糕！原谅我这一点无害的MLOps入门，但亲身体验一下这些模型有多大，以及它们运行起来有多困难，是有帮助的经验。我们将在下一章更多地讨论运行LLM的困难，并为您提供一些实际运行它所需的工具。如果你不想等待，并想要运行一个类似但规模小得多的LLM，将模型名称更改为`“bigscience/bloom-3b”`，然后再次运行。这次它应该在大多数硬件上都能正常工作。
- en: All in all, LLMs are an amazing technology that allow our imaginations to run
    wild with possibility, and deservedly so. The number one use case for considering
    an LLM over a smaller LM is for when few-shot capabilities will come into play
    for whoever the model will be helping, such as helping a CEO when raising funds
    or a software engineer when writing code. They have this ability precisely because
    of their size. The larger number of parameters in LLMs directly enable the ability
    to generalize over smaller spaces in larger dimensions. In this chapter, we’ve
    hit the lesser-known side to LLMs, the linguistic and language modeling side.
    In the next chapter, we’ll cover the other half, the MLOps side, where we dive
    into exactly how that large parameter size affects the model and the systems designed
    to support that model and make it accessible to the customers or employees the
    model is intended for.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 总而言之，LLM 是一项令人惊奇的技术，可以让我们的想象力充满可能性，并且理所当然。考虑使用 LLM 而不是较小的 LM 的头等用例是，当模型将帮助的人需要使用少量样本功能时，比如帮助首席执行官筹集资金或帮助软件工程师编写代码。他们之所以具有这种能力，正是因为他们的规模。LLM
    中更多的参数直接使其能够在更大维度的较小空间上进行概括。在本章中，我们介绍了 LLMS 的较少知名的一面，即语言学和语言建模方面。在下一章中，我们将涵盖另一半，即
    MLOps 方面，其中我们将深入研究大参数大小如何影响模型以及旨在支持该模型并使其可供其预期客户或员工使用的系统。
- en: 2.5 Summary
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 总结
- en: The five components of linguistics are phonetics, syntax, semantics, pragmatics,
    and morphology.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言学的五个组成部分是语音学、句法学、语义学、语用学和形态学。
- en: Phonetics can be added through a multimodal model that processes audio files
    and is likely to improve LLMs in the future, but current datasets are too small.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过处理音频文件的多模态模型可以添加语音学，这可能会在未来改进 LLM，但当前数据集太小。
- en: Syntax is what current models are good at.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语法是当前模型擅长的领域。
- en: Semantics is added through the embedding layer.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过嵌入层添加了语义。
- en: Pragmatics can be added through engineering efforts.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过工程努力可以添加语用学。
- en: Morphology is added in the tokenization layer.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形态学添加在标记化层中。
- en: Language does not necessarily correlate with reality. Understanding the process
    that people use to create meaning outside of reality is useful to training meaningful
    (to people) models.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言不一定与现实相关。了解人们在现实之外创造意义的过程对于训练有意义（对于人们来说）的模型是有用的。
- en: Proper tokenization can be a major hurdle due to too many <UNK> tokens, especially
    when it comes to specialized problems like code or math.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适当的标记化可能是一个主要障碍，因为有太多的 <UNK> 标记，特别是当涉及到代码或数学等专业问题时。
- en: Multilingual processing has always outperformed monolingual processing, even
    on monolingual tasks without models.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多语言处理一直表现优于单语言处理，即使在没有模型的单语言任务中也是如此。
- en: Each language model type has been built specifically to combat the weaknesses
    of the previous models, as opposed to trying to solve for particular features
    of language.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每种语言模型类型都是专门构建的，以解决先前模型的弱点，而不是试图解决语言的特定特征。
- en: Language modeling has seen an exponential increase in efficacy, correlating
    to how linguistics-focused the modeling has been.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模的有效性呈指数增长，与建模的语言学关注度相关。
- en: Attention is a mathematical shortcut for solving larger context windows faster
    and is the backbone of modern architectures - Encoders, Decoders, and Transformers.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力是解决更大上下文窗口的数学快捷方式，是现代架构 - 编码器、解码器和transformers的支柱。
- en: Encoders improve the semantic approximations in embeddings.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器改进了嵌入中的语义近似。
- en: Decoders are best at text generation.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器在文本生成方面表现最佳。
- en: Transformers combine the two.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: transformers将这两者结合起来。
- en: Larger models demonstrate emergent behavior suddenly being able to accomplish
    tasks they couldn’t before.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较大的模型展示了突然能够完成以前无法完成的任务的新兴行为。
- en: '[[1]](#_ftnref1) Vaswani et al 2017 Attention Is All You Need [https://arxiv.org/abs/1706.03762](abs.html)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]](#_ftnref1) Vaswani 等人 2017 年 Attention Is All You Need [https://arxiv.org/abs/1706.03762](abs.html)'
- en: '[[2]](#_ftnref2) We didn’t go over these because they aren’t good for NLP,
    but they are popular especially in computer vision'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2]](#_ftnref2) 我们没有讨论这些，因为它们对自然语言处理来说并不好，但它们在计算机视觉中尤其流行'
- en: '[[3]](#_ftnref3) Not a math or history book'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[[3]](#_ftnref3) 不是数学或历史书籍'
- en: '[[4]](#_ftnref4) See Appendix A'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[[4]](#_ftnref4) 请参阅附录 A'
- en: '[[5]](#_ftnref5) J. Wei et al., “Emergent Abilities of Large Language Models,”
    Transactions on Machine Learning Research, Aug. 2022, Available: [https://openreview.net/forum?id=yzkSU5zdwD](openreview.net.html)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[[5]](#_ftnref5) J. Wei等，“大型语言模型的新兴能力”，机器学习研究交易，2022年8月，可用：[https://openreview.net/forum?id=yzkSU5zdwD](openreview.net.html)。'
