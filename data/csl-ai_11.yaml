- en: 9 The general counterfactual inference algorithm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 一般反事实推理算法
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Implementing the general counterfactual inference algorithm
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一般反事实推理算法
- en: Directly implementing a parallel world DAG as a causal graphical model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接将并行世界DAG作为因果图模型实现
- en: Using a variational inference to implement the algorithm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用变分推理实现算法
- en: Building counterfactual deep generative models of images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建图像的反事实深度生成模型
- en: The previous chapter taught you how to formalize counterfactuals and use the
    parallel world graph to reason across possible worlds. In this chapter, I’ll introduce
    an algorithm for inferring counterfactual queries. Then I’ll present three case
    studies showing implementations of the algorithm using different probabilistic
    ML approaches.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章教了你如何形式化反事实并使用并行世界图在可能的世界中进行推理。在本章中，我将介绍一个用于推断反事实查询的算法。然后，我将展示三个案例研究，展示使用不同的概率机器学习方法实现该算法。
- en: I call the algorithm we’ll discuss in this chapter the “general” algorithm for
    probabilistic counterfactual inference because you can infer any counterfactual
    query with this algorithm. The catch is that you need an SCM. Moreover, differences
    between your SCM and the ground-truth SCM can lead to inaccuracies in your counterfactual
    inferences. We’ll look more closely at this issue when we discuss identification
    in chapter 10, where you’ll also learn ways of inferring counterfactuals without
    knowing the ground-truth SCM. In this chapter, you’ll see the power of this SCM-based
    approach, especially in machine learning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我将本章中我们将讨论的算法称为“一般”概率反事实推理算法，因为你可以使用这个算法推断任何反事实查询。问题是你需要一个SCM。此外，你的SCM与真实SCM之间的差异可能导致你的反事实推理不准确。我们将在第10章讨论识别问题时更仔细地研究这个问题，你也将学习到在不了解真实SCM的情况下推断反事实的方法。在本章中，你将看到基于SCM的方法的强大之处，尤其是在机器学习中。
- en: 9.1 Algorithm walkthrough
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 算法概述
- en: 'In this section, we’ll do a high-level walkthrough of the general algorithm
    probabilistic counterfactual inference. The algorithm has three steps commonly
    called *abduction*, *action*, and *prediction*:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将对概率反事实推理的一般算法进行高级概述。该算法有三个步骤，通常被称为*归因*、*行动*和*预测*：
- en: '*Abduction*—Infer the distribution of the exogenous variables given the factual
    conditions.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*归因*—在给定事实条件的情况下推断外生变量的分布。'
- en: '*Action*—Implement the hypothetical condition as an ideal intervention (graph
    surgery) in the hypothetical world.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*行动*—在假设世界中将假设条件作为理想干预（图手术）实现。'
- en: '*Prediction*—Use the conditional distribution on the exogenous variables from
    step 1 to derive the distributions of the hypothetical outcomes.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*预测*—使用步骤1中的外生变量的条件分布来推导假设结果的分布。'
- en: I’ll illustrate how we can perform these steps using the parallel world graph
    for our online gaming example, shown again as a parallel world graph in figure
    9.1.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用我们的在线游戏示例的并行世界图来说明如何执行这些步骤，如图9.1所示。
- en: '![figure](../Images/CH09_F01_Ness.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F01_Ness.png)'
- en: Figure 9.1 A parallel world graph for the online gaming example
  id: totrans-15
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.1 在线游戏示例的并行世界图
- en: Recall that in this example, guild member *G* is a cause of side-quest engagement
    *E* and in-game purchases *I*. Side-quest engagement is also a cause of in-game
    purchases.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在这个例子中，公会成员*G*是侧任务参与度*E*和游戏内购买*I*的原因。侧任务参与度也是游戏内购买的原因。
- en: Note  This example changes the condition *I* < $50 used in chapter 8 to *I*
    = $50 in order to make the explanations a bit less verbose. Either condition would
    work with the algorithm we’re discussing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：这个例子将第8章中使用的条件*I* < $50更改为*I* = $50，以便使解释更加简洁。这两种条件都可以与我们所讨论的算法一起使用。
- en: Let’s suppose our counterfactual question is “For a player with low side-quest
    engagement and $50 of in-game purchases, what would their level of in-game purchases
    be if their side-quest engagement were high?” The corresponding query is *P*(*IE*
    =“high”|*E*=“low”, *I*=50). Let’s examine how to apply the algorithm to this query.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的反事实问题是“对于一个低侧任务参与度和50美元游戏内购买的玩家，如果他们的侧任务参与度很高，他们的游戏内购买水平会是什么？”相应的查询是*P*(*IE*
    =“high”|*E*=“low”，*I*=50)。让我们看看如何将算法应用于这个查询。
- en: '9.1.1 Abduction: Infer the exogenous variables given the observed endogenous
    variables'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 归因：在给定的观察到的内生变量下推断外生变量
- en: The term “abduction” refers to doing *abductive inference*, meaning we’re inferring
    causes from observed outcomes. In our online gaming SCM, we want to infer the
    latent exogenous variables (*N*[*G*], *N*[*E*], and *N*[*I*]) from the factual
    conditions (*E*=“low” and *I*=50).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “推理”这个术语指的是进行*推理推断*，意味着我们从观察到的结果中推断原因。在我们的在线游戏SCM中，我们想要从事实条件(*E*=“低”和*I*=50)中推断潜在的变量(*N**[G*],
    *N**[E*], 和*N**[I*])。
- en: In our probabilistic modeling approach, we treat the exogenous variables as
    latent variables and target them with probabilistic inference. In our example,
    we infer *N*[*E*] from observing *E*=“low”. Figures 9.2 and 9.3 illustrate the
    d-connected paths to inference of *N*[*G*] and *N*[*I*], respectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的概率建模方法中，我们将外生变量视为潜在变量，并使用概率推理针对它们进行目标定位。在我们的例子中，我们从观察*E*=“低”推断*N**[E*]。图9.2和图9.3分别说明了到*N**[G*]和*N**[I*]的d连通路径。
- en: 'As you can see in figure 9.2, we have a path from *E* to *N*[*G*] through the
    path *E*←*G*←*N*[*G*]. Further, observing both *E* and *I* opens a collider path
    to *N*[*G*]: *E*→*I*←*G*←*N*[*G*]. Similarly, in figure 9.3, observing *E* and
    *I* also opens a collider path to *N*[*I*] via *E*→*I*←*N*[*I*].'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在图9.2中可以看到的，我们有一条从*E*到*N**[G*]的路径，通过路径*E*←*G*←*N**[G]*。此外，观察*E*和*I*通过路径*E*→*I*←*G*←*N**[G*]开启了到*N**[G*]的碰撞路径。同样，在图9.3中，观察*E*和*I*也通过路径*E*→*I*←*N**[I*]开启了到*N**[I*]的碰撞路径。
- en: '![figure](../Images/CH09_F02_Ness.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F02_Ness.png)'
- en: Figure 9.2 To infer the counterfactual outcomes, we infer the exogenous variables
    conditional on observed outcomes in the actual world. There is a path from *E*
    to *N**[G]* through the path *E*←*G*←*N**[G]*. Also, observing *E* and *I* opens
    a collider path *E*→*I*←*G*←*N**[G]*.
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.2 为了推断反事实结果，我们在实际世界中观察到的结果条件下推断外生变量。从*E*到*N**[G]*有一条路径，通过路径*E*←*G*←*N**[G]*。此外，观察*E*和*I*通过路径*E*→*I*←*G*←*N**[G]*开启了碰撞路径。
- en: '![figure](../Images/CH09_F03_Ness.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F03_Ness.png)'
- en: Figure 9.3 Observing *E* and *I* opens a collider path to *N**[I]* via *E*→*I*←*N**[I]*.
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.3 观察*E*和*I*通过*E*→*I*←*N**[I]*开启了通往*N**[I]*的碰撞路径。
- en: Finally, observing *E* has a directly connecting path to *N*[*E*], as shown
    in figure 9.4.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，观察*E*有一个直接连接到*N**[E]*的路径，如图9.4所示。
- en: '![figure](../Images/CH09_F04_Ness.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F04_Ness.png)'
- en: Figure 9.4 *E* is a direct child of *N**[E]*, so observing *E* gives direct
    information about *N**[E]*.
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.4 *E*是*N**[E]*的直接子节点，因此观察*E*会直接提供关于*N**[E]*的信息。
- en: Our SCM is a probabilistic model. In the abduction step, we use this model to
    infer *P*(*N*[*G*], *N*[*E*], *N*[*I*]| *E*=“low”, *I*=50). That inference will
    follow these paths of dependence.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结构化因果模型（SCM）是一个概率模型。在推理步骤中，我们使用此模型来推断*P*(*N**[G*], *N**[E*], *N**[I*]| *E*=“低”，*I*=50)。这个推断将遵循这些依赖路径。
- en: '9.1.2 Action: Implementing the hypothetical causes'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 行动：实施假设原因
- en: Recall from chapter 8 that we use the ideal intervention to implement hypothetical
    conditions. Our hypothetical condition is “if their side-quest engagement were
    high,” and we implement this with an ideal intervention that sets *E* to “high”
    in the hypothetical world. Since we’re using a graph, we implement the intervention
    with graph surgery as in figure 9.5.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 回想第8章，我们使用理想干预来实施假设条件。我们的假设条件是“如果他们的支线任务参与度很高”，我们通过将假设世界中的*E*设置为“高”的理想干预来实施这个条件。由于我们使用的是图，所以我们通过如图9.5所示的图手术来实施干预。
- en: '![figure](../Images/CH09_F05_Ness.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F05_Ness.png)'
- en: Figure 9.5 Implement the hypothetical condition as an ideal intervention (via
    graph surgery) in the hypothetical world.
  id: totrans-34
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.5 在假设世界中，将假设条件作为理想干预（通过图手术）实施。
- en: Now the parallel worlds differ. Note that the probability distributions on the
    exogenous variables have been updated with information from the actual world during
    the abduction step. In the final step, we’ll propagate this information through
    this modified hypothetical world.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在平行世界不同了。请注意，在推理步骤中，外生变量的概率分布已经根据实际世界的信息进行了更新。在最后一步，我们将通过这个修改后的假设世界传播这些信息。
- en: '9.1.3 Prediction: Inferring hypothetical outcomes'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 预测：推断假设结果
- en: We’re working with an SCM, so the values of the variables in the hypothetical
    world are set deterministically by the exogenous variables. Having updated the
    exogenous variable distributions conditional on observations in the actual world,
    we’ll now propagate that actual world information from the exogenous variables
    to the endogenous variables in the hypothetical world. If we hadn’t applied the
    intervention in the hypothetical world, the hypothetical world would mirror everything
    we observed in the actual world by the law of consistency (see the definition
    in chapter 8). However, since we applied an intervention in the hypothetical world,
    the hypothetical variable distributions downstream of that intervention can differ
    from those in the actual world.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在处理一个结构化因果模型（SCM），因此假设世界中变量的值是由外生变量确定性设置的。在更新了实际世界中观察到的外生变量分布之后，我们现在将实际世界信息从外生变量传播到假设世界中的内生变量。如果我们没有在假设世界中应用干预，根据一致性法则，假设世界将反映我们在实际世界中观察到的所有内容（参见第8章的定义）。然而，由于我们在假设世界中应用了干预，干预之后的假设变量分布可能与实际世界中的不同。
- en: '![figure](../Images/CH09_F06_Ness.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F06_Ness.png)'
- en: Figure 9.6 Paths for inferring the hypothetical distribution of *I* from the
    conditional distribution *P*(*N**[G]*, *N**[E]*, *N**[I]*| *E*=“low”, *I*=50)
    on the exogenous variables, given the observed actual world outcomes
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.6 从外生变量条件分布 *P*(*N**[G]*, *N**[E]*, *N**[I]*| *E*=“low”, *I*=50) 推断假设分布 *I*
    的路径，给定观察到的实际世界结果
- en: In our gaming example, our query *P*(*I*[*E*][=“high”]|*E*=“low”, *I* = 50)
    targets the hypothetical value of *I*[*E*][=“high”]. Figure 9.6 illustrates the
    path of inference from the exogenous variables to the hypothetical value of *I*[*E*][=][“high”].
    Note that in this example, the paths of influence only come from *N*[*G*] and
    *N*[*I*], since the intervention on *E* cut *N*[*E*]’s bridge to the hypothetical
    world.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的游戏示例中，我们的查询 *P*(*I*[*E*][=“high”]|*E*=“low”，*I* = 50) 旨在获取 *I*[*E*][=][“high”]
    的假设值。图9.6说明了从外生变量到 *I*[*E*][=][“high”] 假设值的推理路径。请注意，在这个例子中，影响路径仅来自 *N*[*G*] 和
    *N*[*I*]，因为对 *E* 的干预切断了 *N*[*E*] 与假设世界之间的桥梁。
- en: Be careful about d-connection and d-separation on parallel world graphs
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在平行世界图上小心处理d连接和d分离
- en: Recall that with a causal DAG, we can use a graphical criterion called d-separation/d-connection
    to reason about conditional independence in the data generating process using
    a causal DAG. Indeed, this is what I do when I highlight paths of inference to
    *I**[E]*[=“high”] given *E* and *I* via *N**[I]* and *N**[G]*. I do this to explain
    the abduction and prediction steps of the algorithm. However, in general, one
    cannot rely on d-separation and d-connection to reason about the dependence between
    endogenous variables across worlds. That’s because the law of consistency requires
    that the same endogenous variables across worlds must have the same value (unless
    one of the pairs is impacted by an intervention). Two variables always having
    the same value is a *perfect* dependence; the rules of d-separation do not capture
    that dependence on the parallel world graph.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，使用因果有向图（DAG），我们可以使用一个称为d分离/d连接的图形标准来使用因果DAG在数据生成过程中推理条件独立性。实际上，这就是我在通过
    *N**[I]* 和 *N**[G]* 高亮 *E* 和 *I* 给定 *I**[E]*[=“high”] 的推理路径时所做的事情。我这样做是为了解释算法的归纳和预测步骤。然而，在一般情况下，人们不能依赖于d分离和d连接来推理不同世界之间内生变量之间的依赖关系。这是因为一致性法则要求不同世界中的相同内生变量必须具有相同的值（除非一对受到干预的影响）。两个变量总是具有相同的值是一种*完美*的依赖；d分离的规则没有捕捉到平行世界图上的这种依赖。
- en: In the next chapter, I’ll introduce *counterfactual graphs*, a causal DAG derived
    from a parallel world graph where the connections between d-separation and independence
    hold across worlds.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我将介绍*反事实图*，这是一种从平行世界图中导出的因果DAG，其中d分离和独立性之间的联系在各个世界之间保持。
- en: 'We can see how information flows during inference from factual conditions *E*=“low”
    and *I*=50 in the actual world, through the exogenous variables, to our target
    variable *I*[*E*][=“high”] in the hypothetical world. How we implement the inference
    depends on our preference for inference algorithms. For example, suppose *f*[*G*],
    and *f*[*I*] represent the SCM’s assignment functions for *G* and *I*. We could
    use a simple forward-sampling algorithm:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从实际世界中事实条件 *E*=“low” 和 *I*=50 的信息流，通过外生变量，到假设世界中我们的目标变量 *I*[*E*][=“high”]，来观察推理过程中的信息流动。我们如何实现推理取决于我们对推理算法的偏好。例如，假设
    *f*[*G*] 和 *f*[*I*] 代表SCM对 *G* 和 *I* 的分配函数。我们可以使用一个简单的正向采样算法：
- en: Draw a sample of exogenous values *n*[*G*], *n*[*E*], and *n*[*I*] from *P*(*N*[*G*],
    *N*[*E*], *N*[*I*]| *E*=“low”, *I*=50).
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *P*(*N*[*G*], *N*[*E*], *N*[*I*]| *E*=“low”， *I*=50) 中抽取外生值 *n*[*G*]， *n*[*E*]，和
    *n*[*I*] 的样本。
- en: Derive a sample of the hypothetical value of guild membership *g*^* = *f*[*G*](*n*[*G*]).
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推导出公会成员假设值 *g*^* = *f*[*G*](*n*[*G*]) 的样本。
- en: Derive a sample of the hypothetical value of in-game purchases *i*^* = *f*[*I*](*E*=“high”,
    *g*^*, *n*[*I*]).
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推导出游戏内购买假设值 *i*^* = *f*[*I*](*E*=“high”， *g*^*, *n*[*I*]) 的样本。
- en: Repeat many times to get samples from the distribution *P*(*I*[*E*][=“high”]|*E*=“low”,
    *I* = 50).
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复多次以从分布 *P*(*I*[*E*][=“high”]|*E*=“low”， *I* = 50) 中获取样本。
- en: This would give us samples from our target *P*(*I*[*E*][=“high”]|*E*=“low”,
    *I* = 50).
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将给我们提供目标 *P*(*I*[*E*][=“high”]|*E*=“low”， *I* = 50) 的样本。
- en: 9.1.4 Counterfactual Monte Carlo
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.4 反事实蒙特卡洛
- en: The output of the general probabilistic counterfactual inference algorithm produces
    samples from a distribution. Recall from chapter 2 that once you can sample from
    a distribution, you can apply the Monte Carlo techniques to make inferences based
    on that distribution. That same is true with counterfactual distributions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通用概率反事实推理算法的输出产生分布的样本。回想第2章，一旦你可以从分布中采样，你就可以应用蒙特卡洛技术来根据该分布进行推理。反事实分布也是如此。
- en: For example, in chapter 8, I introduced the idea of regret, where we compare
    counterfactual outcomes. For our player who had low engagement and only spent
    $50, we might ask how much *more* their in-game purchases would have been had
    engagement been high. Given the gamer spent $50, we can define a regret variable
    as *R*[*E*][=][*e*] = *I*[*E*][=][*e*] – 50\. By taking our samples from *P*(*I*[*E*][=“high”]
    |*E*=“low”, *I*=50) and subtracting 50, we get samples from *P*(*R*[*E*][=“high”]
    |*E*=“low”, *I* = 50). We can also take the average of those differences to estimate
    expected regret *E*(*R*[*E*][=“high”] |*E*=“low”, *I* = 50). Note that *E*(…)
    here refers to the expectation operator, not to side-quest engagement.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在第8章中，我介绍了遗憾的概念，其中我们比较反事实结果。对于参与度低且仅花费50美元的玩家，我们可能会问，如果参与度高，他们的游戏内购买会多出多少。鉴于玩家花费了50美元，我们可以定义一个遗憾变量为
    *R*[*E*][=][*e*] = *I*[*E*][=][*e*] – 50。通过从 *P*(*I*[*E*][=“high”] |*E*=“low”，
    *I*=50) 中采样并减去50，我们得到 *P*(*R*[*E*][=“high”] |*E*=“low”， *I* = 50) 的样本。我们还可以取这些差异的平均值来估计期望遗憾
    *E*(*R*[*E*][=“high”] |*E*=“low”， *I* = 50)。请注意，这里的 *E*(…) 指的是期望算子，而不是支线任务参与度。
- en: When we want to use these counterfactual Monte Carlo techniques in automated
    decision-making algorithms, we are typically posing counterfactual questions about
    *policies*. Suppose, for example, a recommendation algorithm recommends certain
    content to a player based on their profile. We can contrast the amount of in-game
    purchases they made under one recommendation policy to the amount they would have
    made under a different policy. We can then adjust the recommendation algorithm
    in a way that would have minimized cumulative regret across players. We’ll look
    at automated decision-making more closely in chapter 12.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想在自动化决策算法中使用这些反事实蒙特卡洛技术时，我们通常是在提出关于 *policies* 的反事实问题。例如，假设一个推荐算法根据玩家的个人资料向玩家推荐某些内容。我们可以对比他们在一种推荐策略下做出的游戏内购买量与在另一种策略下会做出的购买量。然后我们可以调整推荐算法，以最小化玩家之间的累积遗憾。我们将在第12章更详细地探讨自动化决策。
- en: Next, we’ll explore a few case studies of various ways to implement this algorithm
    in code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨几种在代码中实现此算法的案例研究。
- en: 9.1.5 Introduction to the case studies
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.5 案例研究简介
- en: There are several ways we can implement this algorithm using modern probabilistic
    ML tools. In sections 9.2–9.4, we’ll explore three case studies.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过多种方式使用现代概率机器学习工具来实现此算法。在第9.2-9.4节中，我们将探讨三个案例研究。
- en: Monty Hall problem
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 蒙提霍尔问题
- en: The first case study will focus on the Monty Hall problem discussed earlier
    in section 6.3\. We’ll use the pgmpy library to implement a full parallel-world
    graphical SCM. We’ll use pgmpy’s `TabularCPD` to implement SCM assignment functions,
    something it wasn’t designed to do. In exchange for this awkwardness, we’ll be
    able to leverage pgmpy’s graph-based inference algorithm (`VariableElimination`)
    to collapse the abduction and prediction steps into one inference step. Using
    graph-based inference will save us from implementing an inference algorithm for
    abduction; we only have to build the model, apply the action step, and run inference.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个案例研究将专注于第6.3节中讨论过的蒙提霍尔问题。我们将使用pgmpy库来实现一个完整的并行世界图形SCM。我们将使用pgmpy的`TabularCPD`来实现SCM分配函数，这是它没有设计来做的。作为这种尴尬的交换，我们将能够利用pgmpy基于图的推理算法（`VariableElimination`）将推理和预测步骤合并为一个推理步骤。使用基于图的推理将使我们免于实现推理算法；我们只需要构建模型，应用动作步骤，并运行推理。
- en: Femur length and height
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 股骨长度和身高
- en: Next, we’ll revisit the forensics example from section 6.1, where we have an
    SCM in which femur length is a cause of height. This example will show us how
    to do the abduction step with variational inference, a modern and popular probabilistic
    inference technique that works well with cutting-edge deep learning frameworks.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将回顾第6.1节中的法医示例，其中我们有一个SCM，其中股骨长度是身高的原因。这个例子将向我们展示如何使用变分推理来完成推理步骤，这是一种现代且流行的概率推理技术，与最前沿的深度学习框架配合得很好。
- en: In this example, we’ll implement the SCM in Pyro, a PyTorch-based library for
    probabilistic ML. Using Pyro will feel less awkward than pgmpy because Pyro modeling
    abstractions are more flexible. The trade-off is that we must write explicit inference
    code for the abduction step.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用Pyro实现SCM，Pyro是一个基于PyTorch的概率机器学习库。使用Pyro会比pgmpy感觉不那么尴尬，因为Pyro建模抽象更灵活。权衡是，我们必须为推理步骤编写显式的推理代码。
- en: 'The example is simple: the data is small, each variable has only one dimension,
    and the relationships are linear. However, we can use the same variational inference-based
    abduction technique with the large, high-dimensional, and nonlinear data settings
    where variational inference shines.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子很简单：数据很小，每个变量只有一个维度，关系是线性的。然而，我们可以使用相同的基于变分推理的推理技术，在大型、高维和非线性数据设置中使用，在这些设置中变分推理表现出色。
- en: Semantic image editing with counterfactuals
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于反事实的语义图像编辑
- en: In the final case study, we’ll examine how we’d apply the counterfactual inference
    algorithm using a pretrained generative image model in PyTorch. While the Monty
    Hall and femur length problems are simple problems with simple math, this case
    study demonstrates the use of the algorithm on a modern problem with image generation
    in deep generative AI.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后的案例研究中，我们将研究如何使用预训练的生成图像模型在PyTorch中应用反事实推理算法。虽然蒙提霍尔和股骨长度问题是简单的问题，简单的数学，但这个案例研究展示了算法在现代问题上的应用，即深度生成人工智能中的图像生成。
- en: '9.2 Case study 1: Monty Hall problem'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 案例研究1：蒙提霍尔问题
- en: We’ll start by revisiting the SCM for the Monty Hall problem. Summarizing again,
    there is a game show where the player starts with a choice of three doors. Behind
    one door is a car. The player picks a door, say the first door, and the host,
    who knows what’s behind the doors, opens another door, say the third, which does
    not have the car. The host gives the player the opportunity to switch doors. In
    this case, since the player picked the first door and the host revealed that the
    car is not behind the third door, the player can switch to the second door. The
    question is whether a strategy of staying with the original choice or switching
    doors is better.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先回顾蒙提霍尔问题的SCM。再次总结，这是一个游戏节目，玩家从三个门的选择开始。其中一扇门后面有一辆车。玩家选择一扇门，比如说第一扇门，主持人，他知道门后面是什么，会打开另一扇门，比如说第三扇门，这扇门后面没有车。主持人给玩家一个换门的机会。在这种情况下，因为玩家选择了第一扇门，而主持人揭示车不在第三扇门后面，玩家可以切换到第二扇门。问题是坚持原来的选择还是换门哪种策略更好。
- en: The answer is, counterintuitively to many, that a switching strategy is better—two
    times out of three, the switching strategy leads to a win. Figure 9.7 illustrates
    the possible outcomes of switching.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是，对许多人来说反直觉，换门策略更好——三分之二的情况下，换门策略会导致胜利。图9.7说明了换门的可能结果。
- en: '![figure](../Images/CH09_F07_Ness.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F07_Ness.png)'
- en: Figure 9.7 The Monty Hall problem. Assuming the player initially chooses the
    first door, two out of three times the switching strategy will lead to a win.
    This illustration assumes the first door is chosen, but the results are the same
    regardless of the initial choice of door.
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.7 摩纳哥大厅问题。假设玩家最初选择了第一个门，三分之二的情况下，换门策略将导致获胜。这个插图假设选择了第一个门，但无论初始选择哪个门，结果都是相同的。
- en: 'We’ll explore two counterfactual questions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨两个反事实问题：
- en: For a player who stayed with their first door and lost, what is the probability
    that they would have won if they switched doors?
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个坚持最初选择的大门并输掉游戏的玩家，如果他们换门，他们获胜的概率是多少？
- en: For a player who lost, what is the probability that they would have won if they
    switched doors?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个输掉游戏的玩家，如果他们换门，他们获胜的概率是多少？
- en: 'We’ll answer these questions with the following steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤回答这些问题：
- en: Build the parallel world model as a generative graphical model in pgmpy.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 pgmpy 中将并行世界模型构建为生成性图形模型。
- en: Condition on evidence in one world to do inference of outcomes in the other.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个世界中基于证据进行推理，以推断另一个世界中的结果。
- en: 'Before we start, we’ll download some tools to help us with the analysis. Listing
    9.1 downloads some helper functions for working with pgmpy: the `do` function
    for implementing ideal interventions and `clone` for duplicating a `TabularCPD`
    object. Also, to generate the visualizations, you’ll need to install the Graphviz
    visualization library.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们将下载一些工具来帮助我们进行分析。列表 9.1 下载了一些用于与 pgmpy 一起工作的辅助函数：用于实现理想干预的 `do` 函数和用于复制
    `TabularCPD` 对象的 `clone`。此外，为了生成可视化，你需要安装 Graphviz 可视化库。
- en: Setting up your environment
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 设置你的环境
- en: The code in this chapter was tested with pgmpy version 0.1.25 and Pyro version
    1.9.1\. I use Matplotlib 3.7 for plotting. Plotting of the DAGs relies on Graphviz.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码使用 pgmpy 版本 0.1.25 和 Pyro 版本 1.9.1 进行了测试。我使用 Matplotlib 3.7 进行绘图。DAG 的绘图依赖于
    Graphviz。
- en: Graphviz installation depends on your environment. Using Ubuntu 22.04, I installed
    graphvizl via libgraphviz-dev, and then I installed the Python libraries Graphviz
    version 0.20.3, PyGraphviz version 1.13, and NetworkX version 3.3\.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Graphviz 的安装取决于你的环境。使用 Ubuntu 22.04，我通过 libgraphviz-dev 安装了 graphvizl，然后我安装了
    Python 库 Graphviz 版本 0.20.3、PyGraphviz 版本 1.13 和 NetworkX 版本 3.3。
- en: Depending on your environment, you may need to install pydot version 3.0\. Graphviz
    and pydot are for plotting only, so if you get stuck, you could forgo plotting
    in the rest of the code.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的环境，你可能需要安装 pydot 版本 3.0。Graphviz 和 pydot 仅用于绘图，所以如果你遇到困难，你可以放弃在其余代码中的绘图。
- en: Listing 9.1 Installing Graphviz and helper functions
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.1 安装 Graphviz 和辅助函数
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Install Graphviz libraries for visualization, and create a helper function
    for plotting graphs. This was tested in Ubuntu 22.04.3 but may depend on your
    environment. If you have trouble, you can forgo graph plotting and run the rest
    of the code.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 安装用于可视化的 Graphviz 库，并创建一个用于绘图的帮助函数。这在 Ubuntu 22.04.3 上进行了测试，但可能取决于你的环境。如果你遇到麻烦，你可以放弃图形绘图并运行其余的代码。'
- en: '#2 Helper function for downloading some utilities from GitHub'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 用于从 GitHub 下载一些实用工具的辅助函数'
- en: '#3 Download code for a “do” function for applying ideal interventions.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 下载用于应用理想干预的“do”函数的代码。'
- en: '#4 Download code for a “clone” helper function for cloning assignment functions
    across worlds.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 下载用于跨世界复制分配函数的“clone”辅助函数的代码。'
- en: '#5 It’s good security practice to inspect the downloaded code before executing.
    Uncomment the “exec” calls to execute the downloaded code.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 在执行之前检查下载的代码是良好的安全实践。取消注释“exec”调用以执行下载的代码。'
- en: Next, we’ll build the full parallel world model as a graphical model. Our first
    step is to specify the exogenous variable distributions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建完整的并行世界模型作为图形模型。我们的第一步是指定外生变量分布。
- en: 9.2.1 Specifying the exogenous variables
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 指定外生变量
- en: We want to implement the model as an SCM, so we’ll create exogenous variables
    with distributions that entail all the random elements of the game. In other words,
    given the outcomes of these random elements and the host’s and player’s choices,
    the outcome of the game will be deterministic.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望将模型实现为 SCM，因此我们将创建具有分布的外生变量，这些分布包含游戏中的所有随机元素。换句话说，给定这些随机元素的结果以及主持人和玩家的选择，游戏的结果将是确定的。
- en: Specifically, we’ll introduce two rolls of three-sided dice and a coin flip.
    We’ll call the first die roll *Car Door Die Roll*; it selects a door for placement
    of the car. The player rolls the second die, a variable we’ll call *1st Choice
    Die Roll*, to select the player’s first door selection. Both dice rolls assign
    a 1/3 probability to each outcome. Next, we have a coin flip, which we’ll just
    call *Coin Flip*, which I’ll explain shortly.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将介绍两个三面骰子和一次抛硬币。我们将第一个骰子滚动称为**车门骰子滚动**；它选择放置汽车的车门。玩家滚动第二个骰子，我们将称之为**第一次选择骰子滚动**，以选择玩家的第一个门选择。这两个骰子滚动将每个结果分配1/3的概率。接下来，我们有一个抛硬币，我们将其称为**硬币抛掷**，我将稍后解释。
- en: 'Listing 9.2 Model building: Specify distributions for exogenous variables'
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.2 建模：指定外生变量的分布
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 Prior distribution on exogenous variable for the three-sided die roll that
    selects which door gets the car'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 为选择哪个门得到汽车的三面骰子滚动的外生变量的先验分布'
- en: '#2 Prior distribution on the exogenous variable for the three-sided die roll
    that selects the player’s first choice of door'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 为选择玩家第一个选择门的三个面骰子滚动的外生变量的先验分布'
- en: '#3 Prior distribution on the exogenous variable for the coin flip. The host
    flips a coin that determines which door the host chooses to reveal as carless
    and whether the player chooses a stay or switch strategy.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 对硬币抛掷的外生变量的先验分布。主持人抛硬币以确定主持人选择揭示为无车的门以及玩家选择保持或换门策略。'
- en: Next, we’ll build assignment functions for our endogenous variables.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将为我们的内生变量构建分配函数。
- en: 9.2.2 Specifying the assignment functions for the endogenous variables
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 指定内生变量的分配函数
- en: Our endogenous variables will be *Host Door Selection*, *Strategy* (whether
    taking a switch or stay strategy), *2nd Choice* (choosing door 1, 2, 3 based on
    one’s strategy), and *Win or Lose* (the outcome of the game).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内生变量将是**主持人门选择**、**策略**（是否采取换门或保持策略）、**第二次选择**（根据策略选择门1、2、3）和**赢或输**（游戏的结局）。
- en: 'Our definition of the SCM in chapter 6 assumes a one-to-one pairing between
    endogenous and exogenous variables—we typically make that assumption of independent
    exogenous variables because if we knew of a common cause, we’d usually model it
    explicitly. Here, we’ll relax that assumption and match each exogenous variable
    to two endogenous variables:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第6章中定义的SCM假设内生变量和外生变量之间是一对一的配对——我们通常假设外生变量是独立的，因为如果我们知道一个共同的原因，我们通常会明确地建模它。在这里，我们将放宽这个假设，将每个外生变量匹配到两个内生变量：
- en: '*1st Choice Die Roll* will drive *Host Door Selection* and *2nd Choice*'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一次选择骰子滚动**将驱动**主持人门选择**和**第二次选择**'
- en: '*Coin Flip* will drive *Host Door Selection* and *Strategy*'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬币抛掷**将驱动**主持人门选择**和**策略**'
- en: '*Car Door Die Roll* will drive *Host Door Selection* and *Win or Lose*'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**车门骰子滚动**将驱动**主持人门选择**和**赢或输**'
- en: We’ll use this simplified approach of matching one exogenous variable to two
    endogenous variables because it will require less code. This shortcut works well
    in this case because the exogenous variables precisely encode all the exogenous
    random elements of the game—these elements completely determine the game’s outcome.
    We could use the traditional formulation (where each endogenous variable has a
    unique exogenous variable) and get the same results.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这种简化的方法，将一个外生变量匹配到两个内生变量，因为它将需要更少的代码。在这种情况下，这种方法很有效，因为外生变量精确地编码了游戏的所有外生随机元素——这些元素完全决定了游戏的结果。我们也可以使用传统的公式（其中每个内生变量都有一个独特的外生变量）并得到相同的结果。
- en: Let’s walk through the steps of the game and then construct the DAG.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步分析游戏步骤，然后构建DAG。
- en: Strategy
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 策略
- en: The player will use *Coin Flip* as the basis of their *Strategy* decision—if
    the host flips heads, the player will adopt a switch door strategy. Otherwise,
    they’ll adopt a strategy of keeping their original choice.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家将使用**硬币抛掷**作为他们**策略**决策的基础——如果主持人抛出正面，玩家将采用换门策略。否则，他们将保持他们的原始选择。
- en: Listing 9.3 Create the assignment function for *Strategy*
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.3 为**策略**创建分配函数
- en: '[PRE2]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Host door selection
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 主持人门选择
- en: '*Host Door Selection* depends on which door has the car (*Car Door Die Roll*)
    and the player’s initial choice of door (*1st Choice Die Roll*). The host will
    use *Coin Flip* to select a door from two available doors in the event that the
    winning door and the first choice door are the same. If *Coin Flip* is heads,
    they’ll choose the right-most door, otherwise the left-most.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*主持人门选择*取决于哪个门有车（*汽车门骰子滚动*）以及玩家的初始门选择（*第一次选择骰子滚动*）。如果获胜门和第一次选择门相同，主持人将使用*硬币翻转*从两个可用的门中选择一个门。如果*硬币翻转*是正面，他们将选择最右边的门，否则是左边的。'
- en: Listing 9.4 Create the assignment function for *Host Door Selection*
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.4 为*主持人门选择*创建分配函数
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 2nd choice
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二选择
- en: '*2nd Choice*, the player’s choice of which door to pick in the second round,
    depends on *Strategy*, *Host Door Selection* (the player can’t switch to the door
    the host opened), and *1st Choice Die Roll* (the player must stay with or switch
    from the door selected in the first round).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*第二选择*，玩家在第二轮中选择哪个门的决策，取决于*策略*、*主持人门选择*（玩家不能切换到主持人打开的门）以及*第一次选择骰子滚动*（玩家必须坚持或从第一轮选择的门切换）。'
- en: Listing 9.5 Create an assignment function for *2nd Choice*
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.5 为*第二选择*创建一个分配函数
- en: '[PRE4]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Win or Lose
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 胜或负
- en: '*Win or Lose* depends on which door the player picked in *2nd Choice* and whether
    that door is the winning door (*Car Door Die Roll*).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*胜或负*取决于玩家在*第二选择*中选择的门以及该门是否是获胜门（*汽车门骰子滚动*）。'
- en: Listing 9.6 Create an assignment function for *Win or Lose*
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.6 为*胜或负*创建一个分配函数
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With the exogenous variable distributions and the assignment functions complete,
    we can build the full parallel world graphical model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成外生变量分布和分配函数后，我们可以构建完整的并行世界图形模型。
- en: 9.2.3 Building the parallel world graphical model
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 构建并行世界图形模型
- en: We can now begin building the full parallel world model. First we’ll add the
    edges that are in the graph.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始构建完整的并行世界模型。首先，我们将添加图中存在的边。
- en: Listing 9.7 Build the parallel world graphical model
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.7 构建并行世界图形模型
- en: '[PRE6]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Specify lists of the exogenous and endogenous variables in the causal DAG.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在因果DAG中指定外生和内生变量的列表。'
- en: '#2 Specify the edges of the SCM.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 指定SCM的边。'
- en: '#3 Clone the edges for the hypothetical world.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 复制假设世界的边。'
- en: Next, we’ll compile and plot the graph.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将编译并绘制图形。
- en: Listing 9.8 Compiling and visualizing the parallel world graph
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.8 编译和可视化并行世界图
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Create the parallel world graph.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建并行世界图。'
- en: '#2 Plot the parallel world graph.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 绘制并行世界图。'
- en: '#3 Add probability distributions on exogenous variables.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 在外生变量上添加概率分布。'
- en: '#4 Add assignment functions from the SCM.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 添加来自SCM的分配函数。'
- en: '#5 Clone the assignment functions.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 复制分配函数。'
- en: The preceding code prints the parallel world graph in figure 9.8.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码打印出图9.8中的并行世界图。
- en: '![figure](../Images/CH09_F08_Ness.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F08_Ness.png)'
- en: Figure 9.8 The full parallel world graph for our counterfactual question. Hypothetical
    world variables have the suffix “Hyp.”
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.8 我们反事实问题的完整并行世界图。假设的世界变量有“Hyp.”后缀
- en: Before we answer our counterfactual questions, we’ll do a quick sanity check
    to confirm that our model can generate the result that the switching strategy
    leads to a win two-thirds of the time.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们回答反事实问题之前，我们将进行快速合理性检查，以确认我们的模型可以生成切换策略导致三分之二的时间获胜的结果。
- en: Listing 9.9 Confirm correct probability of winning given a switch strategy
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.9 确认给定切换策略的正确获胜概率
- en: '[PRE8]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Instantiate the inference algorithm with variable elimination.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用变量消除实例化推理算法。'
- en: '#2 Infer the probability distribution of “Win or Lose” given that the player
    uses a switch strategy.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 推断玩家使用切换策略时“胜或负”的概率分布。'
- en: This prints the following table.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下表格。
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As we expect, we win two-thirds of the time when we adopt a strategy of switching
    doors.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所预期，当我们采用换门策略时，我们三分之二的时间会获胜。
- en: 9.2.4 Running the counterfactual inference algorithm
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 运行反事实推理算法
- en: 'Finally, we’ll use inference to answer our counterfactual questions:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用推理来回答我们的反事实问题：
- en: For a player who stayed with their first door and lost, what is the probability
    that they would have won if they switched doors?
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于坚持第一门并输掉的玩家，如果他们换门，他们获胜的概率是多少？
- en: For a player who lost, what is the probability that they would have won if they
    switched doors?
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个输掉游戏的玩家，如果他们换门，他们获胜的概率是多少？
- en: Again, we use variable elimination as our choice of inference algorithm. We’ll
    use the `do` function to do the action step and implement the hypothetical condition
    of switching. Then we’ll use the `VariableElimination` inference algorithm to
    do the abduction and prediction steps all in one go.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们使用变量消除作为我们的推理算法选择。我们将使用`do`函数来执行动作步骤并实现切换的假设条件。然后我们将使用`VariableElimination`推理算法一次性完成推理和预测步骤。
- en: Listing 9.10 Infer the counterfactual distributions
  id: totrans-154
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.10 推理反事实分布
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Action step: Set “Strategy Hyp” to “switch” using “do”, an implementation
    of an ideal intervention.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 动作步骤：使用“do”将“策略假设”设置为“切换”，这是一个理想干预的实现。'
- en: '#2 Apply variable elimination as our inference algorithm on the parallel world
    graph.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 在并行世界图中应用变量消除作为我们的推理算法。'
- en: '#3 This inference query answers “For a player who used the stay strategy and
    lost, would they have won if they used the switch strategy?” Conditional on “Strategy
    == stay” and “Win or Lose == lose,” we infer the probability distribution of “Win
    or Lose Hyp” on the parallel world graph.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 这个推理查询回答了“对于一个使用停留策略并输掉的玩家，如果他们使用切换策略，他们会赢吗？”在“策略 == 停留”和“赢或输 == 输”的条件下，我们在并行世界图中推断“赢或输假设”的概率分布。'
- en: '#4 This inference query answers “For a player who lost, would they have won
    if they used the switch strategy?” Conditional on “Win or Lose == lose,” we infer
    the probability distribution of “Win or Lose Hyp” on the parallel world graph.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 这个推理查询回答了“对于一个输掉的玩家，如果他们使用切换策略，他们会赢吗？”在“赢或输 == 输”的条件下，我们在并行世界图中推断“赢或输假设”的概率分布。'
- en: 'For the question “For a player who stayed with their first door and lost, what
    is the probability that they would have won if they switched doors?” we have the
    following probability table:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对于问题“对于一个坚持第一个门并输掉的玩家，他们如果换门会赢的概率是多少？”我们有以下概率表：
- en: '[PRE11]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The result of the first question is obvious. If the player lost on a stay strategy,
    their first choice did not have the car. Therefore, one of the other two doors
    must have had the car. Of those two, the host would have had to open the one without
    the car. The remaining door would then have had the car. That is the only door
    the player could switch to on a switch strategy. So, conditional on losing with
    a stay strategy, the chances they would have won with a switch strategy are 100%.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题的结果是显而易见的。如果玩家在停留策略中输了，他们的第一个选择没有车。因此，另外两个门中必有一个有车。在这两个门中，主持人必须打开那个没有车的门。剩下的门就会有车。这就是玩家在切换策略中唯一可以切换的门。所以，在停留策略输的条件下，他们通过切换策略获胜的概率是100%。
- en: 'For the question “For a player who lost, what is the probability that they
    would have won if they switched doors?” we have the following probability table:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于问题“对于一个输掉的玩家，他们如果换门会赢的概率是多少？”我们有以下概率表：
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The answer to the second question extends from the first. We know from the original
    results of the model that if a player lost, there is a 2/3 chance they used a
    stay strategy. As we saw from the first question, in this case, flipping to a
    switch strategy has a 100% chance of winning. There is a 1/3 chance it was a stay
    strategy, in which case, by the consistency rule, there is 100% chance of losing.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题的答案扩展自第一个。我们知道从模型的原有结果来看，如果一个玩家输了，他们有2/3的概率使用了停留策略。正如我们从第一个问题中看到的，在这种情况下，切换到切换策略有100%的获胜机会。有1/3的概率是停留策略，在这种情况下，根据一致性规则，有100%的输掉概率。
- en: Using pgmpy’s graphical model inference algorithms enables counterfactual reasoning
    for discrete variable problems like the Monty Hall problem. In the next case study,
    we will solve the abduction step with variational inference, which generalizes
    to a broader class of problems and leverages modern deep learning.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pgmpy的图形模型推理算法可以为离散变量问题（如蒙提霍尔问题）进行反事实推理。在下一个案例研究中，我们将使用变分推理来解决推理步骤，这可以推广到更广泛的问题类别，并利用现代深度学习。
- en: '9.3 Case study 2: Counterfactual variational inference'
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 案例研究2：反事实变分推理
- en: In this next case study, we’ll implement the counterfactual inference algorithm
    using a generative model in the PyTorch-based probabilistic modeling library Pyro.
    Here we’ll focus on the example of a forensic SCM where femur length is a cause
    of human height (discussed earlier in section 6.1).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个案例研究中，我们将使用基于PyTorch的概率建模库Pyro中的生成模型来实现反事实推理算法。在这里，我们将关注一个法医SCM的例子，其中股骨长度是人类身高（在6.1节中讨论过）的原因。
- en: In the Monty Hall example, all the variables were discrete, and the exogenous
    causes completely captured the game’s random elements. That allowed us to implement
    the SCM (albeit awkwardly) using `TabularCPD` for assignment functions in pgmpy,
    and then explicitly create a parallel world graphical model. Once that was accomplished,
    the graphical modeling inference algorithm `VariableElimination` handled the abduction
    and prediction steps for us.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在蒙提霍尔例子中，所有变量都是离散的，外生原因完全捕捉了游戏的随机元素。这使得我们能够在pgmpy中使用`TabularCPD`为分配函数实现SCM（尽管有些笨拙），然后显式创建一个并行世界图形模型。一旦完成，图形建模推理算法`VariableElimination`就为我们处理了推理和预测步骤。
- en: In contrast, our second case study presents an approach that generalizes to
    more types of problems. We’ll use the PyTorch-based deep probabilistic modeling
    library Pyro. We’ll handle the abduction step using variational inference, a popular
    inference algorithm in the deep learning era.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，我们的第二个案例研究提出了一种可以推广到更多类型问题的方法。我们将使用基于PyTorch的深度概率建模库Pyro。我们将使用变分推理处理推理步骤，这是深度学习时代的一种流行推理算法。
- en: 'In this example, we’ll use this modeling approach to contrast two questions:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用这种建模方法来对比两个问题：
- en: 'A conditional hypothetical: “What would an individual’s height be if their
    femur length was 46 cm?” *P*(*H*[*F*][=46])'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个条件假设：“如果一个人的股骨长度是46厘米，那么他的身高会是多少？” *P*(*H*[*F*][=46])
- en: 'A parallel-world counterfactual: “An individual’s femur is 44 cm, and their
    height is 165 cm. What would their height be if femur length was 46 cm?” *P*(*H*[*F*][=46]|*F*=44,
    *H*=165)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个并行世界的反事实：“一个人的股骨长度是44厘米，身高是165厘米。如果股骨长度是46厘米，那么他的身高会是多少？” *P*(*H*[*F*][=46]|*F*=44,
    *H*=165)
- en: In both cases, we infer a distribution on *H*[*F*][=46] (where *H* is height
    and *F* is femur length), but in the counterfactual case, we condition on having
    observed *F*=44 and *H*=165\. Implementing code that contrasts these two distributions
    on *H*[*F*][=46] will help us understand what makes counterfactual queries unique.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们推断*H*[*F*][=46]（其中*H*是身高，*F*是股骨长度）上的分布，但在反事实情况下，我们基于观察到的*F*=44和*H*=165进行条件推断。实现对比这两个分布的*H*[*F*][=46]的代码将帮助我们理解反事实查询的独特之处。
- en: 9.3.1 Building the model
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 构建模型
- en: To make things more interesting, we’ll modify the model by adding a variable
    for biological sex, which drives both femur length and height. Figure 9.9 illustrates
    the new causal DAG. Notice that our questions do not mention anything about sex,
    so we’ll expect to see sex-related variance in our distributions *P*(*H*[*F*][=46])
    and *P*(*H*[*F*][=46]|*F*=44, *H*=165).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更有趣，我们将通过添加一个生物性别变量来修改模型，该变量驱动股骨长度和身高。图9.9说明了新的因果图。请注意，我们的问题没有提到任何关于性别的内容，因此我们预计会在我们的分布*P*(*H*[*F*][=46])和*P*(*H*[*F*][=46]|*F*=44,
    *H*=165)中看到与性别相关的方差。
- en: '![figure](../Images/CH09_F09_Ness.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F09_Ness.png)'
- en: Figure 9.9 The causal DAG for the relationship between femur length and height.
    Both are driven by biological sex.
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.9 股骨长度与身高之间关系的原因图。两者都由生物性别驱动。
- en: The following code below implements the model in Pyro. Note the creation and
    use of a `PseudoDelta` distribution function. Endogenous variables are deterministic
    functions of the exogenous variables, but for variational inference to work, we
    must assign the endogenous variables a distribution using `pyro.sample`. We could
    use the Dirac delta distribution, which would assign all probability value to
    the output of a variable’s assignment function. But gradient-based optimization
    won’t work in this case. Instead, we’ll approximate inference with a “pseudo-delta”
    distribution—a normal distribution with a very small scale parameter.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码在Pyro中实现了模型。注意创建和使用`PseudoDelta`分布函数。内生变量是外生变量的确定性函数，但为了变分推理能够工作，我们必须使用`pyro.sample`为内生变量分配一个分布。我们可以使用狄拉克delta分布，它将所有概率值分配给变量的分配函数的输出。但在这种情况下，基于梯度的优化将不起作用。相反，我们将使用“伪delta”分布——一个具有非常小的尺度参数的正态分布。
- en: Listing 9.11 Implement the femur SCM in Pyro
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.11 在Pyro中实现股骨SCM
- en: '[PRE13]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Enable approximate inference with a “pseudo-delta” distribution to emulate
    a deterministic delta distribution.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用“伪delta”分布启用近似推理以模拟确定性delta分布。'
- en: '#2 The assignment function for biological sex'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 生物性别的分配函数'
- en: '#3 The assignment function for femur length in cm. The assignment uses two
    linear functions, one for each sex.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 厘米单位股骨长度的分配函数。分配使用两个线性函数，每个性别一个。'
- en: '#4 The assignment function for height. Again, it uses two linear functions,
    one for each sex.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 身高分配函数。同样，它使用两个线性函数，每个性别一个。'
- en: '#5 Sample from the exogenous variable prior distributions'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 从外生变量先验分布中提取样本'
- en: '#6 Obtain the endogenous variables given the exogenous variables.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 在给定外生变量的情况下获取内生变量。'
- en: '#7 Specify the prior distributions for the exogenous variables.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 指定外生变量的先验分布。'
- en: 'Again, there are three steps to our counterfactual inference algorithm:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们的反事实推理算法有三个步骤：
- en: Abduction
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归纳
- en: Action
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 行动
- en: Prediction
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测
- en: Unlike our pgmpy model, we won’t need to clone all the variables for the parallel
    world. We’ll just use the intervention operator `pyro.do` to apply the intervention
    and get an intervention model. For *P*(*H*[*F*][=][46]), we’ll generate from the
    intervention model based on samples from *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]).
    For the counterfactual distribution, we’ll do the abduction step using a variational
    inference algorithm to learn *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|F=44,
    H=165). Then we’ll generate from the intervention model again, but this time based
    on samples from *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|F=44, H=165).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的pgmpy模型不同，我们不需要克隆并行世界中的所有变量。我们只需使用干预操作符`pyro.do`来应用干预并获取干预模型。对于*P*(*H*[*F*][=][46])，我们将根据从*P*(*N*[*Sex*]，*N*[*Femur*]，*N*[*Height*])中采样的样本从干预模型中生成。对于反事实分布，我们将使用变分推理算法进行归纳步骤，以学习*P*(*N*[*Sex*]，*N*[*Femur*]，*N*[*Height*]|F=44,
    H=165)。然后我们再次从干预模型中生成，但这次是基于从*P*(*N*[*Sex*]，*N*[*Femur*]，*N*[*Height*]|F=44, H=165)中采样的样本。
- en: Dealing with intractable likelihoods
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理难以处理的似然
- en: We use variational inference to do the abduction step, inferring the exogenous
    variables given observed endogenous variables. Variational inference is a likelihood-based
    technique. Typically, we get likelihoods by sampling from a distribution and then
    getting the probability value for that sampled value using the distribution’s
    probability mass/density function. But we can’t do that for SCMs because endogenous
    variable values are set by the assignment functions rather than being sampled.
    The code in this forensic example uses sampling from a “pseudo”-Dirac delta distribution,
    meaning a normal distribution with a very small scale parameter. This approach,
    which provides likelihood values from a normal distribution, falls into a class
    of methods called *approximate Bayesian computation**, a*nd it shares some of
    the trade-offs with other members of that class.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用变分推理来进行归纳步骤，根据观察到的内生变量推断外生变量。变分推理是一种基于似然的技术。通常，我们通过从分布中采样并使用分布的概率质量/密度函数来获取该采样值的概率值来获得似然。但对于SCMs，我们无法这样做，因为内生变量的值是由分配函数设置的，而不是通过采样。在这个法医示例中的代码使用从“伪”狄拉克δ分布中进行采样，这意味着一个具有非常小的尺度参数的正态分布。这种方法，它从正态分布中提供似然值，属于称为*近似贝叶斯计算*的方法类别，并且与其他该类成员共享一些权衡。
- en: One alternative is to use *amortized inference*. In this method, you sample
    many exogenous variable values and use these to calculate many endogenous variable
    values. Finally, you use these samples to train a model that predicts the exogenous
    variable value, given the endogenous variable value. You then use this trained
    model during the abduction step.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一种替代方法是使用*摊销推理*。在这种方法中，你采样许多外生变量值，并使用这些值来计算许多内生变量值。最后，你使用这些样本来训练一个模型，该模型根据内生变量值预测外生变量值。然后你在归纳步骤中使用这个训练好的模型。
- en: Dealing with intractable likelihoods is a broader challenge in probabilistic
    machine learning, which is beyond the scope of this book. See the chapter notes
    at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to additional references and resources.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 处理难以处理的似然是概率机器学习中的一个更广泛挑战，这超出了本书的范围。有关附加参考文献和资源的链接，请参阅章节注释[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)。
- en: 9.3.2 Implementing an intervention with pyro.do
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 使用pyro.do实现干预
- en: Now let’s pose the conditional hypothetical, “What would height be if femur
    length was 46 cm?” Figure 9.10 illustrates the modified DAG representing the ideal
    intervention that sets femur length to 46.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提出条件假设，“如果股骨长度为46厘米，身高会是什么样子？”图9.10说明了表示将股骨长度设置为46的理想干预措施的修改后的DAG。
- en: '![figure](../Images/CH09_F10_Ness.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F10_Ness.png)'
- en: Figure 9.10 We represent the hypothetical condition with an ideal intervention
    and graph surgery on the causal DAG.
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.10 我们用理想的干预措施表示假设条件，并在因果DAG上表示图手术。
- en: In Pyro, we’ll apply `pyro.do` to the original model and get an intervention
    model. We’ll then repeatedly call the algorithm with the prior on the exogenous
    variable distribution and return generated endogenous values. We’ll repeat this
    several times and visualize the intervention distribution on height with a histogram.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pyro中，我们将对原始模型应用`pyro.do`以获取干预模型。然后我们将反复调用算法，使用外生变量分布的先验，并返回生成的内生值。我们将重复几次，并使用直方图可视化身高上的干预分布。
- en: Listing 9.12 Sampling from the intervention distribution of “if femur length
    were 46cm”
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.12 从“如果股骨长度为46cm”的干预分布中抽取样本
- en: '[PRE14]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Implement the hypothetical condition “...if femur length were 46 cm” with
    pyro.do, which returns a new model that implements the intervention.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pyro.do实现假设条件“...如果股骨长度为46厘米”的模拟，这将返回一个实现干预措施的新模型。
- en: '#2 Sample from the intervention distribution.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 从干预分布中抽取样本。'
- en: '#3 Visualize the intervention distribution with a histogram of samples.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用样本直方图可视化干预分布。'
- en: Figure 9.11 shows the resulting histogram of samples from *P*(*H*[*F*][=46]).
    We’ll contrast this with the histogram from *P*(*H*[*F*][=46]|*F*=44, *H*=165).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11显示了从*P*(*H*[*F*][=46])中抽取的样本的直方图。我们将将其与*P*(*H*[*F*][=46]|*F*=44, *H*=165)的直方图进行对比。
- en: '![figure](../Images/CH09_F11_Ness.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F11_Ness.png)'
- en: Figure 9.11 This histogram of samples visualizes the interventional distribution—the
    *x*-axis corresponds to different ranges of height values, and the *y*-axis is
    proportions of the sampled heights that fall within each range.
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.11这个样本直方图可视化了干预分布——*x*轴对应不同的身高值范围，*y*轴是落在每个范围内的抽样身高的比例。
- en: Now we’ll do the counterfactual inference.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将进行反事实推理。
- en: 9.3.3 Implementing the abduction step with variational inference
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 使用变分推理实现推理步骤
- en: '![figure](../Images/CH09_F12_Ness.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F12_Ness.png)'
- en: Figure 9.12 The parallel world graph for the femur length counterfactual
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.12股骨长度反事实的平行世界图
- en: 'Our conditional hypothetical question was, “What would an individual’s height
    be if their femur length was 46 cm?” Now we want to answer the counterfactual:
    “An individual’s femur is 44 cm, and their height is 165 cm. What would their
    height be if their femur length was 46 cm?” In other words, we want to extend
    *P*(*H*[*F*][=][46]) to *P*(*H*[*F*][=][46]|*F*=44, *H*=165). Figure 9.12 illustrates
    the corresponding parallel world graph.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的假设条件问题是，“如果一个人的股骨长度是46厘米，那么这个人的身高会是多少？”现在我们想要回答反事实问题：“一个人的股骨长度是44厘米，身高是165厘米。如果他们的股骨长度是46厘米，他们的身高会是多少？”换句话说，我们想要将*P*(*H*[*F*][=][46])扩展到*P*(*H*[*F*][=][46]|*F*=44,
    *H*=165)。图9.12说明了相应的平行世界图。
- en: Following the counterfactual inference algorithm, we need to do the abduction
    step and infer *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|*F*=44, *H*=165). We’ll
    use variational inference, where we’ll specify a *guide function*—a function with
    trainable parameters representing a distribution *Q*(*N*[*Sex*], *N*[*Femur*],
    *N*[*Height*]). The training procedure optimizes the parameters of the guide such
    that *Q*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]) closely approximates *P*(*N*[*Sex*],
    *N*[*Femur*], *N*[*Height*]|*F*=44, *H*=165).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循反事实推理算法，我们需要进行推理步骤并推断*P*(*N*[*性别*], *N*[*股骨*], *N*[*身高*]|*F*=44, *H*=165)。我们将使用变分推理，其中我们将指定一个*引导函数*——一个具有可训练参数的函数，代表一个分布*Q*(*N*[*性别*],
    *N*[*股骨*], *N*[*身高*])。训练过程优化引导函数的参数，使得*Q*(*N*[*性别*], *N*[*股骨*], *N*[*身高*])与*P*(*N*[*性别*],
    *N*[*股骨*], *N*[*身高*]|*F*=44, *H*=165)紧密近似。
- en: 'Refresher: Proposal distributions and Pyro’s guide function'
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 复习：提议分布和Pyro的引导函数
- en: Pyro’s use of “guide functions” enables the developer to write their own proposal
    distributions that “propose” values for variables in the target distributions.
    Sampling-based inference algorithms (e.g., importance sampling or MCMC) use the
    proposal to generate samples and then operate on the samples so they represent
    the target distribution. Variational inference optimizes the parameters of the
    proposal distribution such that it becomes close to (or “approximates”) the target
    distribution. In contrast to pgmpy’s automatic inference algorithms, guide functions
    let the developer “guide” inference as they see fit.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro使用“引导函数”允许开发者编写他们自己的提议分布，为目标分布中的变量“提议”值。基于抽样的推理算法（例如，重要性抽样或MCMC）使用提议生成样本，然后对样本进行操作，以便它们代表目标分布。变分推理优化提议分布的参数，使其接近（或“近似”）目标分布。与pgmpy的自动推理算法相比，引导函数允许开发者根据他们的需求“引导”推理。
- en: Listing 9.13 Specifying the guide function for variational inference
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.13 指定变分推理的引导函数
- en: '[PRE15]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 The exogenous prior distribution is passed to the guide function. The function
    won’t use this argument, but the signatures of the guide and the model functions
    must match.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将外生先验分布传递给引导函数。该函数不会使用此参数，但引导函数和模型函数的签名必须匹配。'
- en: '#2 The guide function tries to approximate P(N_sex|femur, height) from a Bernoulli
    distribution. Optimization targets the parameter of this Bernoulli distribution.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 引导函数试图从伯努利分布中近似 P(N_sex|femur, height)。优化目标是这个伯努利分布的参数。'
- en: '#3 n_sex is either 0 or 1\. When passed as a parameter to a Bernoulli, the
    outcome is deterministic.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 n_sex 要么是 0，要么是 1。当作为伯努利分布的参数传递时，结果是确定的。'
- en: '#4 The guide function tries to approximate P(N_femur|femur, height) from a
    normal distribution. Optimization targets the location and scale parameters of
    this normal distribution.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 引导函数试图从正态分布中近似 P(N_femur|femur, height)。优化目标是这个正态分布的位置和尺度参数。'
- en: '#5 The guide function tries to approximate P(N_height|femur, height), also
    from a normal distribution.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 引导函数试图从正态分布中近似 P(N_height|femur, height)。'
- en: '#6 Since we condition on femur and height, they are not needed in the guide
    function. But it is useful to have them in case we want to condition on different
    outcomes in a new analysis.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 由于我们对股骨和身高进行了条件化，它们在引导函数中不是必需的。但如果我们想在新的分析中对不同的结果进行条件化，它们是有用的。'
- en: Deterministic abduction
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 确定性归因
- en: 'A special case of the abduction step is when both of the following are true:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 当以下两个条件都成立时，归因步骤是一个特殊情况：
- en: You observe all the endogenous variables.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你观察到所有内生变量。
- en: The SCM assignment functions are invertible.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SCM 赋值函数是可逆的。
- en: 'In that case, given observations of all the endogenous variables, you can calculate
    exact point values for the exogenous variables with the inverted assignment functions.
    Consequently, you apply the assignment functions in the hypothetical world to
    get point values of the hypothetical outcomes. However, most practical examples
    fall in the following general case:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在那种情况下，给定所有内生变量的观测值，你可以使用逆赋值函数计算外生变量的精确点值。因此，你在假设世界中应用赋值函数以获得假设结果的点值。然而，大多数实际例子都落在以下一般情况中：
- en: You only condition on some endogenous variables.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你只对一些内生变量进行条件化。
- en: The SCM assignment functions are not invertible.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SCM 赋值函数是不可逆的。
- en: In our abduction step, we first condition the model on observed values of femur
    and height.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的归因步骤中，我们首先根据股骨和身高的观测值对模型进行条件化。
- en: Listing 9.14 Conditioning on actual values of femur and height
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.14 基于股骨和身高实际值的条件化
- en: '[PRE16]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, we infer the exogenous variable, given femur and height, using variational
    inference.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用变分推理根据股骨和身高推断外生变量。
- en: Listing 9.15 Implementing the abduction step with variational inference
  id: totrans-238
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.15 使用变分推理实现归因步骤
- en: '[PRE17]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Set a seed for reproducibility.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 设置一个种子以实现可重复性。'
- en: '#2 Clear any current parameter values.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 清除任何当前的参数值。'
- en: '#3 Initialize the stochastic variational inference algorithm.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 初始化随机变分推理算法。'
- en: '#4 Optimize the parameters with a learning rate of .003.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用学习率为 .003 优化参数。'
- en: '#5 Use (negative) evidence lower bound (ELBO) as the loss function.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 使用（负）证据下界（ELBO）作为损失函数。'
- en: '#6 Initialize a list to store loss values for plotting.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 初始化一个列表以存储用于绘图的损失值。'
- en: '#7 Run the optimization for 5,000 steps. The SVI’s step object has the same
    signature as the model and the guide, so any model/guide arguments must be passed
    in here.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 运行优化 5,000 步。SVI 的步骤对象与模型和引导函数具有相同的签名，因此必须在此处传递任何模型/引导参数。'
- en: '#8 Plot the loss during training.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 绘制训练过程中的损失图。'
- en: Figure 9.13 shows loss during training indicating variational inference converged.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13 显示了训练过程中的损失，表明变分推理已收敛。
- en: '![figure](../Images/CH09_F13_Ness.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F13_Ness.png)'
- en: Figure 9.13 Loss during optimization of the parameters of the distribution approximating
    *P*(*N**[Sex]*, *N**[Femur]*, *N**[Height]*|*F*=44, *H*=165)
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.13 显示了近似 *P*(*N**[Sex]*, *N**[Femur]*, *N**[Height]*|*F*=44, *H*=165) 分布的参数优化过程中的损失
- en: After training is completed, we extract the optimized parameters for our updated
    exogenous variable distribution.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，我们提取更新后的外生变量分布的优化参数。
- en: Listing 9.16 Extract parameters of updated exogenous distribution
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.16 提取更新后的外生分布的参数
- en: '[PRE18]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#1 Extract the parameter values.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 提取参数值。'
- en: '#2 Do the abduction by using the optimized parameters to create new “posterior”
    exogenous variable distributions.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用优化后的参数进行推理，创建新的“后验”外生变量分布。'
- en: One thing to note is that while we typically specify independent prior distributions
    for exogenous variables in an SCM, exogenous variables are generally conditionally
    dependent given endogenous variables (because of collider paths!). However, I
    wrote a guide function that samples the exogenous variables independently, ignoring
    this conditional dependence. Writing a guide that treats dependent variables as
    independent is convenient and is common practice, but doing so will add some bias
    to the results. You can avoid this by doing the extra work of writing a guide
    function that maintains the dependencies implied by the graph.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，虽然我们在结构因果模型（SCM）中通常为外生变量指定独立的先验分布，但外生变量在给定内生变量的情况下通常是条件相关的（因为存在碰撞路径！）。然而，我编写了一个指导函数，独立地采样外生变量，忽略了这种条件相关性。编写将依赖变量视为独立的指导函数既方便又是常见做法，但这样做会在结果中引入一些偏差。你可以通过编写一个维护图中隐含依赖关系的指导函数来避免这种情况。
- en: Counterfactual modeling with ChiRho
  id: totrans-257
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 ChiRho 进行反事实建模
- en: ChiRho is a causal extension of Pyro that seeks to more seamlessly blend the
    probabilistic modeling approach of Pyro with causal inference. ChiRho has parallel
    world abstractions and abstractions for implementing counterfactual inference
    with normalizing flows and the variational inference approach discussed in this
    example. As an extension to Pyro, the modeling techniques discussed in this case
    study will also work with ChiRho.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ChiRho 是 Pyro 的因果扩展，旨在更无缝地将 Pyro 的概率建模方法与因果推理相结合。ChiRho 具有并行世界抽象以及使用正态化流和本例中讨论的变分推理方法实现反事实推理的抽象。作为
    Pyro 的扩展，本案例研究中讨论的建模技术也将适用于 ChiRho。
- en: 9.3.4 Implementing the action and prediction steps
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.4 实现行动和预测步骤
- en: In the Monty Hall example, we built the parallel world model explicitly. In
    this example, we can just perform the action step by using `pyro.do` to get the
    hypothetical world model, and sample from this model using the updated exogenous
    variable distribution.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在蒙提霍尔例子中，我们明确构建了并行世界模型。在这个例子中，我们可以通过使用 `pyro.do` 来执行行动步骤，从而获取假设的世界模型，并使用更新后的外生变量分布从该模型中采样。
- en: 'We’ll repeat the procedure of generating samples from the intervention model
    that set femur length to 46 cm. Recall that we already created the intervention
    model in listing 9.11 with this line:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重复从设置股骨长度为 46 厘米的干预模型中生成样本的步骤。回想一下，我们已经在列表 9.11 中创建了该干预模型，如下所示：
- en: '[PRE19]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: To sample from the intervention distribution, we called `int_model` on our original
    `exogenous` variable distribution. Now, for the prediction step, we’ll call it
    again, this time with `exogenous_posterior` instead of `exogenous`, because `exogenous_posterior`
    encodes all the information from the actual world.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从干预分布中采样，我们在原始的外生变量分布上调用 `int_model`。现在，在预测步骤中，我们再次调用它，这次使用 `exogenous_posterior`
    而不是 `exogenous`，因为 `exogenous_posterior` 编码了实际世界中的所有信息。
- en: Listing 9.17 Sampling from the counterfactual distribution
  id: totrans-264
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.17 从反事实分布中采样
- en: '[PRE20]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Finally, we overlay a histogram of samples from the counterfactual distribution
    against the interventional distribution histogram in figure 9.14, and we can see
    the clear differences between these distributions.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在图 9.14 中叠加了来自反事实分布的样本直方图与干预分布直方图，我们可以清楚地看到这些分布之间的差异。
- en: Listing 9.18 Comparing the interventional and counterfactual distributions
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.18 比较干预和反事实分布
- en: '[PRE21]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The resulting plot, shown in figure 9.14, contrasts histograms of the interventional
    and counterfactual samples.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图，如图 9.14 所示，对比了干预和反事实样本的直方图。
- en: '![figure](../Images/CH09_F14_Ness.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F14_Ness.png)'
- en: Figure 9.14 Histograms of generated samples from the interventional and counter-factual
    distributions encoded by the causal model
  id: totrans-271
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.14 由因果模型编码的干预和反事实分布生成的样本直方图
- en: Figure 9.14 illustrates how the counterfactual distribution generally has much
    less spread than an interventional distribution representing the same hypothetical
    conditions. The counterfactual distribution essentially filters the interventional
    distribution down to cases where the conditions observed in the actual world are
    true. In this case, we have two height bell curves corresponding to two sexes.
    Those bell curves have a stronger overlap in the interventional distribution.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14说明了反事实分布通常比表示相同假设条件的干预分布具有更小的分散。反事实分布本质上将干预分布过滤到实际世界中观察到的条件为真的案例。在这种情况下，我们有两个对应于两种性别的身高钟形曲线。这些钟形曲线在干预分布中具有更强的重叠。
- en: In a final example, we’ll evaluate how to run the counterfactual inference algorithm
    in the context of a generative AI image model.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个例子中，我们将评估如何在生成式AI图像模型的背景下运行反事实推理算法。
- en: '9.4 Case study 3: Counterfactual image generation with a deep generative model'
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 案例研究3：使用深度生成模型进行反事实图像生成
- en: In generative AI, the user provides an input, and the algorithm generates some
    output. For example, suppose I wanted to write a script for an alternative history
    where Harriet Tubman was a pirate captain. I turned to a generative image model
    for some concept art, posing the text question, “What would Harriet Tubman look
    like as a pirate captain?” The model generated the image in figure 9.15.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式AI中，用户提供输入，算法生成一些输出。例如，假设我想写一个关于哈丽特·塔布曼成为海盗船长的替代历史的脚本。我转向一个生成式图像模型来获取一些概念艺术，提出了文本问题：“哈丽特·塔布曼作为海盗船长的样子会是什么样子？”该模型生成了图9.15中的图像。
- en: '![figure](../Images/CH09_F15_Ness.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F15_Ness.png)'
- en: Figure 9.15 The output of a generative AI image model, given the natural language
    input prompt “What would Harriet Tubman look like as a pirate captain?”
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.15 生成式AI图像模型根据自然语言输入提示“哈丽特·塔布曼作为海盗船长的样子会是什么样子？”的输出。
- en: The question itself is a counterfactual—Harriet Tubman was not a pirate. We’ll
    explore natural language counterfactuals with large language models in chapter
    13\. Here, we’ll reason counterfactually about the image in figure 9.15.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题本身就是一个反事实——哈丽特·塔布曼并不是海盗。在第13章中，我们将探讨使用大型语言模型进行自然语言反事实。在这里，我们将对图9.15中的图像进行反事实推理。
- en: Suppose I like this image, but I want to make an edit—I want to change this
    image to remove the glasses. One way of doing this is to use a tool like “in-fill,”
    where I select the pixels with the glasses and indicate that I want whatever is
    in the pixels to go away. This would be directly editing the form of the image.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我喜欢这幅图像，但我想进行编辑——我想将这幅图像修改为去除眼镜。一种方法是用像“填充”这样的工具，我选择带有眼镜的像素，并指示我希望像素中的内容消失。这将直接编辑图像的形式。
- en: An alternative approach would be *semantic editing*, where rather than manipulating
    the pixels in the image, I manipulate some latent representation of the image
    corresponding to “glasses.” In effect, I pose the counterfactual question, “what
    would this image look like if the subject were not wearing glasses?” Figure 9.16
    contrasts the original and “counterfactual” versions of the image.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可以是**语义编辑**，在这种方法中，我并不是直接操作图像中的像素，而是操作与“眼镜”相对应的图像的某些潜在表示。实际上，我提出了一个反事实问题：“如果主体没有戴眼镜，这幅图像会是什么样子？”图9.16对比了图像的原始版本和“反事实”版本。
- en: '![figure](../Images/CH09_F16_Ness.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F16_Ness.png)'
- en: Figure 9.16 Given the generated image on the left, the user might prompt the
    generative AI with the counterfactual question, “What would this image look like
    without the glasses?” They would expect something like the image on the right,
    where conceptual elements of the image not causally downstream of glasses removal
    should be unaffected.
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.16 给定左侧生成的图像，用户可能会向生成式AI提出一个反事实问题：“如果没有眼镜，这幅图像会是什么样子？”他们期望得到类似右侧的图像，其中图像的概念元素在眼镜去除后不应受到影响。
- en: This is an attractive use case, as manipulating underlying concepts is often
    preferable to manipulating form, especially when the edits you want to make aren’t
    all located in the same specific area of pixels. This is especially attractive
    if our conceptual model is a causal model, so the downstream causal consequences
    of changing a concept are reflected in the image, while the law of consistency
    prevents change in the parts of the image that should be unaffected by the change
    in concept.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有吸引力的用例，因为操纵基本概念通常比操纵形式更可取，尤其是在你想要进行的编辑不是所有都位于像素的同一特定区域时。如果我们的概念模型是一个因果模型，那么特别有吸引力，因为改变概念的下流因果后果会反映在图像中，而一致性法则会防止图像中不受概念改变影响的部分发生变化。
- en: With this use case in mind, this section will use our counterfactual algorithm
    to implement a form of semantic editing. We’ll start with the actual image. In
    the abduction step, we’ll infer some latent representation of the image. In the
    action step, we’ll propose the desired edit, and in the prediction step, we’ll
    generate the new image.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这个用例，本节将使用我们的反事实算法实现一种语义编辑形式。我们将从实际图像开始。在推理步骤中，我们将推断图像的一些潜在表示。在动作步骤中，我们将提出所需的编辑，在预测步骤中，我们将生成新的图像。
- en: In this example, we’ll use an SCM built with a variational autoencoder in PyTorch.
    We’ll also use a simple dataset called dSprites for proof of concept. The dSprites
    data demonstrates the idea and is simple enough to train a model quickly on an
    ordinary laptop. See the chapter notes at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for references with more practical counterfactual image modeling examples.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用在PyTorch中构建的变分自动编码器构建的SCM。我们还将使用一个名为dSprites的简单数据集来证明概念。dSprites数据展示了这个想法，并且足够简单，可以在普通笔记本电脑上快速训练模型。有关更多实际反事实图像建模示例的参考，请参阅章节注释[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)。
- en: 9.4.1 The dSprites data
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 dSprites数据
- en: 'The dSprites dataset consists of 2D shapes, each rendered in 8 possible positions,
    6 possible scales, and 40 possible rotations. The shapes are composed of 5 independent
    factors: shape, scale, rotation, *x*-position, and *y*-position. Figure 9.17 demonstrates
    samples from the dataset.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: dSprites数据集由2D形状组成，每个形状渲染在8个可能的位置、6个可能的尺度和40个可能的旋转中。形状由5个独立因素组成：形状、尺度、旋转、*x*-位置和*y*-位置。图9.17展示了数据集的样本。
- en: '![figure](../Images/CH09_F17_Ness.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F17_Ness.png)'
- en: 'Figure 9.17 The dSprites data features images causally determined by five independent
    causal factors: shape, scale, rotation, *x*-position, and *y*-position.'
  id: totrans-289
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.17 dSprites数据具有由五个独立因果因素（形状、尺度、旋转、*x*-位置和*y*-位置）因果决定的图像特征。
- en: We’ll treat each of these factors as causes of an image variable, as illustrated
    in the causal DAG in figure 9.18.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这些因素视为图像变量的原因，如图9.18中的因果DAG所示。
- en: '![figure](../Images/CH09_F18_Ness.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F18_Ness.png)'
- en: Figure 9.18 The causal DAG for a dSprites image, displayed as a plate model
    to highlight the shape of *N**[I]* and *I*. *N**[i]* is the exogenous variable
    for the image. The model is trained with an encoder-decoder framework that uses
    a 50 × 1 dimensional image encoding to represent *N**[I]*.
  id: totrans-292
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.18 dSprites图像的因果DAG，以板模型的形式显示以突出*N**[I]*和*I*的形状。*N**[i]*是图像的外生变量。该模型使用编码器-解码器框架进行训练，该框架使用50
    × 1维度的图像编码来表示*N**[I]*。
- en: In the following code, we load a specific image from the dSprites dataset.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们加载dSprites数据集中的一个特定图像。
- en: Listing 9.19 Load a dSprites image
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.19 加载dSprites图像
- en: '[PRE22]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Download dSprites example from GitHub and load it.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从GitHub下载dSprites示例并加载它。'
- en: '#2 Plot the dSprites image.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 绘制dSprites图像。'
- en: '#3 The causal factors of the example are [0 0 1 13 26 14], the first element
    is always 0, and the second element corresponds to “square” and is represented
    by 0\. The remaining elements correspond to scale, orientation, and X and Y positions.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 示例的因果因素为[0 0 1 13 26 14]，第一个元素始终为0，第二个元素对应于“正方形”并由0表示。其余元素对应于尺度、方向和X和Y位置。'
- en: This plots the image in figure 9.19.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图显示了图9.19中的图像。
- en: '![figure](../Images/CH09_F19_Ness.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F19_Ness.png)'
- en: Figure 9.19 A single example from the dSprites data
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.19 dSprites数据的一个示例
- en: Printing `causal_factor` produces `tensor ([[ 0, 0, 1, 13, 26, 14`]]). The first
    element is 0 for all examples in the data. The second element of the causal factor
    vector corresponds to shape. Square, ellipse, and heart are represented by 0,
    1, and 2, respectively. The image contains a square (*P*=0) with scale *S*=1,
    orientation *O*=13, and position *X*=26 and *Y*=14\.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 打印`causal_factor`产生`tensor ([[ 0, 0, 1, 13, 26, 14]])`。对于数据中的所有示例，第一个元素都是0。因果因素向量的第二个元素对应于形状。正方形、椭圆和心形分别用0、1和2表示。图像包含一个正方形（*P*=0），比例*S*=1，方向*O*=13，位置*X*=26和*Y*=14。
- en: In this case study, we’ll ask, “What would this image look like if the shape
    were a heart instead of a square?” This suggests the parallel-world network in
    figure 9.20.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们将问：“如果形状是心形而不是正方形，这幅图像会是什么样子？”这暗示了图9.20中的并行世界网络。
- en: '![figure](../Images/CH09_F20_Ness.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F20_Ness.png)'
- en: Figure 9.20 The parallel world graph implied by the question “Given the image,
    what would it look like if the shape were a heart?”
  id: totrans-305
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.20 问题“给定图像，如果形状是心形会是什么样子？”所暗示的并行世界图。
- en: First, we’ll load a pretrained encoder to map from the image to the exogenous
    variable for the causal factors. In this simple model, we’ll assume the assignment
    functions for the exogenous variables of the causal factors are identity functions,
    i.e., the causal factors and their exogenous variables will have the same values.
    Let’s start by initializing the encoder.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载一个预训练的编码器，将图像映射到因果因素的因果变量。在这个简单模型中，我们将假设因果因素的外生变量的赋值函数是恒等函数，即因果因素及其外生变量将具有相同的值。让我们先初始化编码器。
- en: Listing 9.20 Load the encoder of causal factors
  id: totrans-307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.20 加载因果因素的编码器
- en: '[PRE23]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '#1 Cardinality in each dimensionality of the causal factors'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 因果因素在每个维度上的基数'
- en: '#2 Encoder for the vector of exogenous parents of the causal factors'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 因果因素的外生父向量编码器'
- en: '#3 The hidden layers have a length of 1,000.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 隐藏层长度为1,000。'
- en: '#4 Using linear transforms passed through Softplus activation functions'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用通过Softplus激活函数传递的线性变换'
- en: '#5 The final activation is a sigmoid function.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 最终激活是一个sigmoid函数。'
- en: '#6 Flatten the image.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 展平图像。'
- en: '#7 Calculate the hidden layers.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 计算隐藏层。'
- en: '#8 The output layer generates a probability vector that Is used as the parameter
    of a OneHotCategorical distribution.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 输出层生成一个概率向量，用作OneHotCategorical分布的参数。'
- en: '#9 Initialize the encoder. The image dimension is 64 × 64 pixels, and the six
    elements of the causal factor vector are one-hot encoded into a vector of length
    1 + 3 + 6 + 40 + 32 + 32 = 114.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '#9 初始化编码器。图像维度是64 × 64像素，因果因素向量的六个元素被one-hot编码成一个长度为1 + 3 + 6 + 40 + 32 + 32
    = 114的向量。'
- en: Next, we’ll download and load pretrained weights into this encoder from the
    book’s GitHub repo.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从本书的GitHub仓库下载并加载预训练的权重到这个编码器中。
- en: Listing 9.21 Download and load pretrained weights into the encoder of causal
    factors
  id: totrans-319
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.21 下载并加载预训练权重到因果因素编码器
- en: '[PRE24]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: First, we’ll test that the encoder can recover the causal factors from the image.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将测试编码器能否从图像中恢复出因果因素。
- en: Listing 9.22 Generate examples of causal exogenous factors
  id: totrans-322
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.22 生成因果外生因素的示例
- en: '[PRE25]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#1 Helper function that decodes the one-hot encoded output of the encoder'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 解码编码器one-hot编码输出的辅助函数'
- en: '#2 Samples from the output probability vector of encoder_causal_factors'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 来自编码器_causal_factors输出概率向量的样本'
- en: '#3 Use the encoder to predict causal factors.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用编码器预测因果因素。'
- en: 'Encoding the sampled image prints the causal factors: `[ 0, 0, 1, 13, 26, 14].`
    The encoder accurately recovers the causal factors from the image.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 对采样图像进行编码会打印出因果因素：`[ 0, 0, 1, 13, 26, 14]`。编码器准确地从图像中恢复了因果因素。
- en: Next, we’ll initialize an encoder that we’ll use for inference of *N*[*I*],
    the exogenous variable for the image. This encoder takes an image and an instance
    of the causal factor vector as an input.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将初始化一个编码器，我们将用它来推理*N*[*I*]，图像的外生变量。这个编码器接受一个图像和一个因果因素向量的实例作为输入。
- en: Listing 9.23 An encoder for inference of *N**[I]*
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.23 用于*N**[I]*推理的编码器
- en: '[PRE26]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#1 Encoder used for inference of N [I], which serves as both the exogenous
    variable for the image in causal terms, and the encoding of the image in VAE terms'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 用于*N*[*I*]推理的编码器，它既是图像的因果外生变量，也是VAE中的图像编码'
- en: '#2 Using linear transforms passed into a Softplus activation function'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用传递到Softplus激活函数的线性变换'
- en: '#3 Flatten the image.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 展平图像。'
- en: '#4 Concatenate the image and the causal factor vector.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 连接图像和因果因素向量。'
- en: '#5 Calculate the hidden layers.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 计算隐藏层。'
- en: '#6 Calculate the location and scale parameter of multivariate normal distribution
    on N [I].'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 在N [I]上计算多元正态分布的位置和尺度参数。'
- en: '#7 Initialize the encoder.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 初始化编码器。'
- en: The encoder of the noise variable requires the causal factors to be one-hot
    encoded, so we’ll create a helper function to do just that.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声变量的编码器需要因果因素进行one-hot编码，因此我们将创建一个辅助函数来完成这项工作。
- en: Listing 9.24 Create a function for one-hot encoding
  id: totrans-339
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.24 创建一个用于one-hot编码的函数
- en: '[PRE27]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Again, we’ll download and load pretrained weights for the encoder.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将下载并加载编码器的预训练权重。
- en: Listing 9.25 Load pretrained weights for encoder for inference of *N**[I]*
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.25 加载用于推理*N**[I]*的编码器预训练权重
- en: '[PRE28]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '#1 Load the pretrained weights.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 加载预训练的权重。'
- en: '#2 Pass the image and causal factors into the encoder, and obtain N [I] location
    and scale parameters.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将图像和因果因素传递到编码器中，并获取N [I]位置和尺度参数。'
- en: '#3 Generate from the posterior distribution on N [I].'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 从N [I]的后验分布中生成。'
- en: Finally, we’ll load a decoder that maps from *N*[*I*] and a causal factor back
    to an image. In causal terms, the decoder is part of the assignment function for
    the image.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将加载一个将*N*[*I*]和因果因素映射回图像的解码器。在因果意义上，解码器是图像的分配函数的一部分。
- en: Listing 9.26 Load and initialize the decoder that maps causes and *N**[I]* to
    images
  id: totrans-348
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.26 加载并初始化将原因和*N**[I]*映射到图像的解码器
- en: '[PRE29]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#1 The decoder maps from causal factors and N_image to generate a parameter
    for a multivariate Bernoulli distribution on images.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 解码器将因果因素和N_image映射以生成图像上多元伯努利分布的参数。'
- en: '#2 The model uses linear transforms, a Softplus activate for hidden layers,
    and sigmoid activate on the output layer.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 模型使用线性变换，隐藏层使用Softplus激活，输出层使用sigmoid激活。'
- en: '#3 The network concatenates n_image and factors in the input layer.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 网络在输入层中连接n_image和因素。'
- en: '#4 The input is passed through three hidden layers with Softplus activation
    functions.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 输入通过三个具有Softplus激活函数的隐藏层。'
- en: '#5 The output is a probability parameter passed to a multivariate Bernoulli
    distribution on image pixels.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 输出是一个传递到图像像素上多元伯努利分布的概率参数。'
- en: '#6 Initialize the encoder.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 初始化编码器。'
- en: Again, we’ll download and load pretrained weights into the decoder.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将下载并加载解码器的预训练权重。
- en: Listing 9.27 Download and load the decoder weights
  id: totrans-357
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.27 下载并加载解码器权重
- en: '[PRE30]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Before we generate the counterfactual image, we’ll create a helper function
    to plot it.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们生成反事实图像之前，我们将创建一个辅助函数来绘制它。
- en: Listing 9.28 Helper function for plotting the counterfactual image
  id: totrans-360
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.28 用于绘制反事实图像的辅助函数
- en: '[PRE31]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now, we’ll specify the SCM. We’ll write a `p_n_image` function that generates
    from *P*(*N*[*image*]) and an `f_image` assignment function for the image.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将指定SCM。我们将编写一个`p_n_image`函数，它从*P*(*N*[*image*])生成，并为图像编写一个`f_image`分配函数。
- en: Listing 9.29 Create an exogenous distribution and assignment function for the
    image
  id: totrans-363
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.29 创建图像的外生分布和分配函数
- en: '[PRE32]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '#1 A function that generates a variate from the N_image exogenous distribution'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 一个从N_image外生分布生成随机变量的函数'
- en: '#2 The parameters of N_image’s distribution include location and scale parameters
    for a normal distribution and the upper bound of a uniform distribution.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 N_image分布的参数包括正态分布的位置和尺度参数以及均匀分布的上限。'
- en: '#3 Sample a normal random variate from the normal distribution.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 从正态分布中采样一个正态随机变量。'
- en: '#4 Sample a uniform random variate from a uniform distribution.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 从均匀分布中采样一个均匀随机变量。'
- en: '#5 Combine these into a single n_image object.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将这些合并成一个n_image对象。'
- en: '#6 Assignment function for the image'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 图像的分配函数'
- en: '#7 The exogenous noise variable decomposes into one normal and one uniform
    random variate.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 外生噪声变量分解为一个正态随机变量和一个均匀随机变量。'
- en: '#8 The normal random variate is passed through the decoder to get a probability
    vector for the pixels.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 正态随机变量通过解码器传递以获得像素的概率向量。'
- en: '#9 Each pixel is set deterministically with an indicator function that returns
    1 if an element of the uniform variate is less than the corresponding element
    of the probability vector, or otherwise returns 0.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '#9 每个像素都通过一个指示函数确定性地设置，如果均匀随机变量的一个元素小于概率向量的相应元素，则返回1，否则返回0。'
- en: Finally, we can run through the steps of the counterfactual inference algorithm
    to answer the question, “What would this image look like if it was a heart?”
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以运行反事实推理算法的步骤来回答问题：“如果这张图像是心脏，它会是什么样子？”
- en: Listing 9.30 Generate a counterfactual image
  id: totrans-375
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.30 生成反事实图像
- en: '[PRE33]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '#1 Abduction step: infer the exogenous variable given the image.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 推理步骤：根据图像推断外生变量。'
- en: '#2 Infer the parameters of N_I. First, this includes two parameters of a normal
    distribution.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 推断N_I的参数。首先，这包括正态分布的两个参数。'
- en: '#3 Second, we infer the upper bound of a uniform distribution and apply smoothing
    so it is not exactly 1 or 0.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 其次，我们推断均匀分布的上限，并应用平滑使其不是正好为1或0。'
- en: '#4 Combine these together into one inferred parameter set.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将这些合并成一个推断参数集。'
- en: '#5 Action step: Apply the intervention that sets the shape element to “heart”
    (represented by the integer 2).'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 行动步骤：应用将形状元素设置为“心形”（用整数2表示）的干预措施。'
- en: '#6 Prediction step: Generate n_image from P(N_image), and pass this through
    an assignment function to generate an image.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 预测步骤：从P(N_image)生成n_image，并通过一个赋值函数生成一个图像。'
- en: '#7 Apply all three steps: abduct the n_image, apply the intervention, and forward
    generate the counterfactual image.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 应用所有三个步骤：推断n_image，应用干预措施，并正向生成反事实图像。'
- en: '#8 Plot the result.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 绘制结果。'
- en: Figure 9.21 shows the results.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.21显示了结果。
- en: '![figure](../Images/CH09_F21_Ness.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F21_Ness.png)'
- en: Figure 9.21 The original (left) and counterfactually generated image (right)
  id: totrans-387
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.21 原始图像（左）和反事实生成的图像（右）
- en: This is a proof of concept—there is additional nuance in counterfactual image
    generation. I’m cheating a bit with this dSprites example. The counterfactual
    generation works because the causal factors are independent and because the data
    is quite simple. For counterfactual image generation to work in general, we need
    to understand and satisfy certain assumptions.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个概念验证——在反事实图像生成中存在一些额外的细微差别。我在这个dSprites示例中有点作弊。反事实生成之所以有效，是因为因果因素是独立的，而且数据相当简单。为了使反事实图像生成在一般情况下有效，我们需要理解和满足某些假设。
- en: 9.4.2 Assumptions needed for counterfactual image generation
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 反事实图像生成所需的假设
- en: In the next chapter, we’ll tackle the problem of identification. Identification
    is determining what causal questions we can answer, given our modeling assumptions
    and the data available to us. The counterfactual inference algorithm assumes you
    have the ground-truth SCM. If you can make that assumption, you can use the algorithm
    to answer any counterfactual (or interventional) query.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将解决识别问题。识别是在给定的建模假设和我们可用的数据的基础上确定我们可以回答哪些因果问题。反事实推理算法假设您拥有真实世界的结构化因果模型（SCM）。如果您能做出这个假设，您就可以使用该算法来回答任何反事实（或干预）查询。
- en: In most cases, we can’t practicably assume we have the ground-truth SCM. At
    best, you’ll have an SCM that acts as an approximation of the ground truth. For
    example, the true process that generated the dSprites images certainly didn’t
    involve a decoder neural network—we used deep learning with this decoder architecture
    to approximate that process. As you’ll see in the next chapter, such learned approximations
    are not guaranteed to produce counterfactuals faithful to the ground-truth data
    generating process.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，我们无法实际假设我们拥有真实世界的SCM。最多，您将有一个作为真实世界近似值的SCM。例如，生成dSprites图像的真实过程肯定没有涉及解码器神经网络——我们使用具有这种解码器架构的深度学习来近似这个过程。您将在下一章中看到，这种学习到的近似并不保证产生忠实于真实数据生成过程的反事实。
- en: But there is something special about the counterfactual generation of images
    and other media modalities (e.g., text, audio, video). In these cases, mathematical
    guarantees are less critical when we can simply *look* (read, listen, etc.) at
    the generated counterfactual media and evaluate whether it aligns with what we
    imagine it *should* be. Does the image in figure 9.21 look like what you imagined
    replacing the square with a heart would look like? Does the image of pirate captain
    Harriet Tubman without the spectacles align with your expectations? If so, the
    tool is quite useful, even without identification guarantees. Here, utility is
    in terms of aligning with human counterfactual imagination rather than ground-truth
    accuracy. I have the concept image of Captain Tubman that I wanted, and I can
    move on to my next creative task.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 但在图像和其他媒体模态（例如，文本、音频、视频）的反事实生成方面，有一些特殊之处。在这些情况下，当我们可以直接查看（阅读、聆听等）生成的反事实媒体并评估其是否符合我们想象中的样子时，数学保证就不那么关键了。图9.21中的图像看起来像你想象中将正方形换成心形的样子吗？没有眼镜的哈里特·塔布曼海盗船长的形象是否符合你的预期？如果是这样，这个工具就非常有用，即使没有识别保证。在这里，效用是指与人类的反事实想象相一致，而不是与事实准确性相符。我有了我想要的塔布曼船长的概念图像，然后我可以继续我的下一个创意任务。
- en: Summary
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The counterfactual inference algorithm requires an SCM and involves three steps:
    abduction, action, and prediction.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反事实推理算法需要一个SCM，并涉及三个步骤：归纳、行动和预测。
- en: In the abduction step, we infer the exogenous variables, given observed endogenous
    variables.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在归纳步骤中，我们根据观察到的内生变量推断外生变量。
- en: In the action step, we use an ideal intervention to implement the hypothetical
    condition in the counterfactual query.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在行动步骤中，我们使用理想干预措施来实现反事实查询中的假设条件。
- en: In the prediction step, we predict the hypothetical outcomes given the hypothetical
    condition and the distribution of the exogenous variables learned in the abduction
    step.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在预测步骤中，我们根据假设条件和在归纳步骤中学习到的外生变量分布，预测假设结果。
- en: We can implement the counterfactual inference algorithm using different probabilistic
    machine learning frameworks.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用不同的概率机器学习框架来实现反事实推理算法。
- en: We can use a causal graphical modeling library like pgmpy to directly implement
    a generative SCM on a parallel world graph, and use graphical model inference
    algorithms with graph surgery to infer the counterfactual query.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用像pgmpy这样的因果图模型库，在并行世界图上直接实现生成性结构因果模型（SCM），并使用图形模型推理算法和图手术来推断反事实查询。
- en: We can use modern probabilistic deep learning techniques such as variational
    inference and normalizing flows to do the abduction step of the counterfactual
    inference algorithm.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用现代概率深度学习技术，如变分推理和归一化流，来完成反事实推理算法的归纳步骤。
- en: Deep generative models can often be modified to enable counterfactual generation
    of media (text, images, audio, video, etc.). While there may be identification
    questions, you can typically examine the generated counterfactual artifact and
    validate that it matches your expectations.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度生成模型通常可以被修改以实现媒体的反事实生成（文本、图像、音频、视频等）。虽然可能存在识别问题，但通常可以检查生成的反事实工件并验证其是否符合你的预期。
