- en: 'Part 3\. Context: Customizing LLMs for testing contexts'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分. 背景：为测试环境定制LLMs
- en: Throughout the previous chapters, we’ve seen how generalized prompts that are
    lacking in hints toward how our products work or what rules and expectations are
    in place return less valuable prompts. Although slicing our tasks down to a sensible
    size is key, providing that vital information to set clear boundaries on an LLM’s
    output can make or break a response. That’s why we’ll conclude the final part
    of the book with an exploration on embedding context into our work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经看到，缺乏对我们产品工作方式或现有规则和期望的提示的泛化提示会返回更少的提示价值。虽然将我们的任务削减到合理的规模是关键，但提供那些必要的信息来明确LLM输出的边界，可能会使响应成功或失败。这就是为什么我们将以探索将上下文嵌入到我们的工作中来结束本书的最后一部分。
- en: In the following chapters, we’ll depart a little from the techniques we’ve learned
    so far and explore different ways in which context can be retrieved and added
    to LLMs and prompts alike. This means dipping our toes into more advanced topics
    such as retrieval-augmented generation and fine-tuning, not to make us experts
    in these fields, but rather to appreciate how they work and how they can be utilized
    to get the most out of LLMs. So, let’s dive in and see what exciting options await
    us to take LLMs to the next level as testing assistants.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将稍微偏离我们迄今为止学到的技术，探索不同方式来检索和添加上下文到LLMs和提示中。这意味着我们将涉足更高级的主题，如检索增强生成和微调，不是为了使我们成为这些领域的专家，而是为了欣赏它们是如何工作的，以及它们如何被利用来从LLMs中获得最大价值。因此，让我们深入探讨，看看有哪些令人兴奋的选项等待我们将LLMs提升到下一个层次，作为测试助手。
