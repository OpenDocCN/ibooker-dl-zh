- en: 1 The amazing world of TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 TensorFlow的惊人世界
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的内容
- en: What TensorFlow is
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow是什么
- en: 'Hardware in machine learning: GPUs and CPUs'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中的硬件：GPU和CPU
- en: When and when not to use TensorFlow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时以及何时不使用TensorFlow
- en: What this book teaches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书教授的内容
- en: Who this book is for
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书适合谁
- en: Why we should care about TensorFlow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们应该关注TensorFlow
- en: More than 5 million gigabytes—that’s how much data is predicted to be generated
    a second by 2025 ([https://www.weforum.org](https://www.weforum.org)). Those tiny
    contributions we make using Google search queries, tweets, Facebook photos, and
    voice commands to Alexa will add up to unprecedented amounts of data. Therefore,
    there’s no better time than the present to fight on the frontier of artificial
    intelligence, to make sense of and most importantly leverage the ever-growing
    universe of digital data. It is a no-brainer that data itself is not very useful
    until we elicit information from it. For example, an image is more useful if the
    machine knows what’s in that image; a voice command is more useful if the machine
    can articulate/transcribe what was said. Machine learning is the gatekeeper that
    lets you cross from the world of data into the realm of information (e.g., actionable
    insights, useful patterns) by allowing machines to learn from data. Machine learning,
    particularly deep learning methods, deliver unparalleled performance in the presence
    of abundant data. With the explosive growth of data, more and more use cases will
    emerge for deep learning to be applied in. Of course, we cannot ignore the possibility
    of a better technique drowning the popular deep learning methods. However, it
    is an irrefutable reality that, to date, deep learning has been constantly outperforming
    other algorithms, particularly when ample data is present.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到2025年，每秒预计将产生超过5百万吉字节的数据（[https://www.weforum.org](https://www.weforum.org)）。我们通过Google搜索查询、推特、Facebook照片和对Alexa的语音命令所做出的微小贡献将积累成空前数量的数据。因此，现在正是在人工智能前沿进行斗争、理解并利用不断增长的数字数据宇宙的最佳时机。毫无疑问，数据本身在我们从中提取信息之前并不是非常有用。例如，如果机器知道图像中有什么，图像就会更有用；如果机器能够表达/转录出说过的话，语音命令就会更有用。机器学习是让你从数据世界跨入信息领域（例如，可操作的见解、有用的模式）的门卫，通过允许机器从数据中学习。机器学习，特别是深度学习方法，在充足的数据存在的情况下提供了无与伦比的性能。随着数据的爆炸式增长，越来越多的用例将出现，可以应用深度学习。当然，我们不能忽视更好的技术淹没了流行的深度学习方法的可能性。然而，无可辩驳的现实是，迄今为止，深度学习一直在不断地胜过其他算法，特别是在充足的数据存在时。
- en: What is machine learning?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: 'Machine learning is a process where we train and deploy a computational model
    to predict some output given the data as input. A machine learning problem typically
    consists of the following steps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个过程，我们在给定数据作为输入的情况下训练和部署一个计算模型来预测一些输出。机器学习问题通常包括以下步骤：
- en: '*Understanding/exploratory analysis of data*—This is where you will explore
    the data provided to you (e.g., understand the dependent/independent variables).'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*理解/探索性数据分析*——这是您将要探索的提供给您的数据的地方（例如，了解因变量/自变量）。'
- en: '*Cleaning data*—Real-world data is usually messy, so data cleaning is of the
    utmost importance to make sure the model sees high-quality data.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*清理数据*——现实世界的数据通常是混乱的，因此数据清理对确保模型看到高质量数据至关重要。'
- en: '*Feature engineering*—New features need to be engineered from the existing
    features or raw data.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*特征工程*——需要从现有特征或原始数据中构建新特征。'
- en: '*Modeling*—In this stage, you train a model using the selected features and
    corresponding targets.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*建模*——在这个阶段，您使用选定的特征和相应的目标来训练模型。'
- en: '*Evaluation*—After training the model, you must ensure it is reliable and can
    perform well on unseen data (e.g., test data).'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*评估*——在训练模型之后，您必须确保它是可靠的，并且可以在未见过的数据（例如，测试数据）上表现良好。'
- en: '*Creating a user interface for stakeholders to use the model*—In most cases,
    you will need to provide a dashboard/user interface for users to interact with
    the model.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*为利益相关者创建用户界面以使用该模型*——在大多数情况下，您需要为用户提供一个仪表板/用户界面，让他们与模型进行交互。'
- en: Though it looks like a well-defined set of steps, a typical machine learning
    problem does not involve a straight path from A to B, but a rather convoluted
    path consisting of repetitive cycles or iterations. For example, during the feature
    engineering phase, you might realize that you haven’t explored a certain aspect
    of the data, which warrants more data exploration.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管看起来像是一套明确定义的步骤，但典型的机器学习问题并不是从 A 到 B 的直线路径，而是由重复的循环或迭代组成的错综复杂的路径。例如，在特征工程阶段，您可能会意识到您尚未探索某些数据方面，这需要更多的数据探索。
- en: Deep learning models can easily exceed millions (and recently billions) of parameters
    (i.e., weights and biases), and they have a large appetite for data. This signifies
    the need for frameworks that allow us to train and infer from deep learning models
    efficiently while utilizing optimized hardware such as graphical processing units
    (GPUs) or tensor processing units (TPUs) ([http://mng.bz/4j0g](http://mng.bz/4j0g)).
    One aspect of achieving this is to develop highly scalable data pipelines that
    can read and process data efficiently.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型很容易超过数百万（最近甚至数十亿）的参数（即权重和偏差），它们对数据有很大的需求。这意味着我们需要框架来有效地训练和推断深度学习模型，同时利用优化的硬件，如图形处理单元（GPU）或张量处理单元（TPU）
    ([http://mng.bz/4j0g](http://mng.bz/4j0g))。实现这一目标的一方面是开发高度可扩展的数据管道，可以高效地读取和处理数据。
- en: 1.1 What is TensorFlow?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 什么是 TensorFlow？
- en: 'TensorFlow is a machine learning framework and has been making its mark in
    the community of machine learning for almost five years. It is an end-to-end machine
    learning framework that is designed to run faster on optimized hardware (e.g.,
    GPUs and TPUs). A machine learning framework provides the tools and operations
    needed to implement machine learning solutions easily. Though TensorFlow is not
    limited to implementing deep neural networks, that has been its main use. TensorFlow
    also supports the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是一个机器学习框架，在机器学习社区中已经留下了近五年的烙印。它是一个端到端的机器学习框架，旨在在优化的硬件上（例如 GPU 和 TPU）运行得更快。一个机器学习框架提供了实现机器学习解决方案所需的工具和操作。尽管
    TensorFlow 不局限于实现深度神经网络，但这一直是它的主要用途。TensorFlow 还支持以下内容：
- en: Implementing probabilistic machine learning models ([https://www.tensorflow.org/probability](https://www.tensorflow.org/probability))
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现概率机器学习模型 ([https://www.tensorflow.org/probability](https://www.tensorflow.org/probability))
- en: Computer graphics-related computations ([https://www.tensorflow.org/graphics](https://www.tensorflow.org/graphics))
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与计算机图形相关的计算 ([https://www.tensorflow.org/graphics](https://www.tensorflow.org/graphics))
- en: Reusing (pretrained) models ([https://www.tensorflow.org/hub](https://www.tensorflow.org/hub))
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复使用（预训练）模型 ([https://www.tensorflow.org/hub](https://www.tensorflow.org/hub))
- en: Visualizing/debugging TensorFlow models ([https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard))
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化/调试 TensorFlow 模型 ([https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard))
- en: 'TensorFlow was one of the earliest frameworks to enter the bustling market
    of machine learning. Developed and maintained by Google, TensorFlow has released
    more than 100 versions with around 2,500 contributors, making the product bigger
    and better every day. It has evolved to become a holistic ecosystem that moves
    from the early prototyping stage to productionizing the model. Between these stages,
    TensorFlow supports a range of functionalities:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是最早进入繁荣的机器学习市场的框架之一。由 Google 开发和维护，TensorFlow 已发布了100多个版本，拥有约 2500
    名贡献者，使产品日益壮大和改进。它已经发展成为一个从早期原型制作阶段到模型产业化阶段的整体生态系统。在这些阶段之间，TensorFlow 支持一系列功能：
- en: '*Model development*—Building deep learning models easily by stacking predefined
    layers or creating custom layers'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型开发* —— 通过堆叠预定义的层或创建自定义层来轻松构建深度学习模型'
- en: '*Performance monitoring*—Monitoring performance of the model as it is trained'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*性能监控* —— 在模型训练时监控模型的性能'
- en: '*Model debugging*—Debugging any issues, such as numerical errors, that occur
    during model training/prediction'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型调试* —— 调试模型训练/预测过程中出现的任何问题，如数值错误'
- en: '*Model serving*—Once the model is trained, deploying the model to the wider
    public so that it can be used in the real world'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型服务* —— 模型训练完成后，将模型部署到更广泛的公众中，以便在真实世界中使用'
- en: As you can see, TensorFlow supports almost all the stages of building your machine
    learning solutions and eventually serving it to users in the real world. All these
    services are made into and shipped in a single convenient package, which will
    be at your disposal with a single line of installation instructions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，TensorFlow 几乎支持构建机器学习解决方案的所有阶段，并最终将其提供给实际用户。所有这些服务都被制作成一个单一便捷的包，并通过一条安装说明即可随时使用。
- en: Other deep learning frameworks
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其他深度学习框架
- en: 'There are several competing deep learning frameworks on the market that enable
    you to implement and productionize deep learning models quite easily:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 市场上有几个竞争激烈的深度学习框架，它们使您能够轻松实现和生产化深度学习模型：
- en: '*PyTorch* ([https://pytorch.org](https://pytorch.org/))—PyTorch is a framework
    that is predominantly implemented using a machine library called Torch that is
    built on the programming language Lua. PyTorch and TensorFlow have similar functionality.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PyTorch* ([https://pytorch.org](https://pytorch.org/))—PyTorch 是一个框架，主要是使用一个名为
    Torch 的机器库实现的，该机器库是基于 Lua 编程语言构建的。PyTorch 和 TensorFlow 具有类似的功能。'
- en: '*MXNet* ([https://mxnet.apache.org](https://mxnet.apache.org))—MXNet is another
    machine learning framework maintained by the Apache Software Foundation.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MXNet* ([https://mxnet.apache.org](https://mxnet.apache.org))—MXNet 是由 Apache
    软件基金会维护的另一个机器学习框架。'
- en: '*DeepLearning4J* ([https://deeplearning4j.konduit.ai/](https://deeplearning4j.konduit.ai/))—DeepLearning4J
    is a Java-based deep learning framework.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DeepLearning4J* ([https://deeplearning4j.konduit.ai/](https://deeplearning4j.konduit.ai/))—DeepLearning4J
    是一个基于 Java 的深度学习框架。'
- en: The various components that come together to solve an ML problem will be discussed
    in detail in the coming sections.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 解决 ML 问题所需的各种组件将在接下来的章节中详细讨论。
- en: Next, we will discuss different components of TensorFlow. These components will
    go from raw data all the way to deploying models to be accessed by customers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论 TensorFlow 的不同组件。这些组件将从原始数据一直到部署模型供客户访问。
- en: 1.1.1 An overview of popular components of TensorFlow
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 TensorFlow 热门组件概览
- en: 'As previously mentioned, TensorFlow is an end-to-end machine learning framework.
    This means TensorFlow needs to support many different capabilities and stages
    of a machine learning project. After a business problem is identified, any machine
    learning project starts with data. An important step is to perform exploratory
    data analysis. Typically, this is done using a mix of TensorFlow and other data
    manipulating libraries (e.g., pandas, NumPy). In this step, we try to understand
    our data because that will determine how well we can use it to solve the problem.
    With a solid understanding of the data (e.g., data types, data-specific attributes,
    various cleaning/processing that needs to be done before feeding data to the model),
    the next step is to find an efficient way to consume data. TensorFlow provides
    a comprehensive API (application programming interface), known as the tf.data
    API (or tensorflow.data API) ([https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)),
    that enables you to harness the data found in the wild. Specifically, this API
    provides various objects and functions to develop highly flexible custom-input
    data pipelines. Depending on your needs, you have several other options for retrieving
    data in TensorFlow:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如先前提到的，TensorFlow 是一个端到端的机器学习框架。这意味着 TensorFlow 需要支持机器学习项目的许多不同能力和阶段。在确定了业务问题之后，任何机器学习项目都是从数据开始的。一个重要的步骤是进行探索性数据分析。通常情况下，这是通过使用
    TensorFlow 和其他数据操作库（例如，pandas、NumPy）的组合来完成的。在这一步中，我们试图理解我们的数据，因为这将决定我们能够多好地使用它来解决问题。通过对数据有扎实的理解（例如，数据类型、数据特定属性、在将数据提供给模型之前需要进行的各种清理/处理），下一步是找到一种有效的方式来使用数据。TensorFlow
    提供了一个全面的 API（应用程序编程接口），称为 tf.data API（或 tensorflow.data API）（[https://www.tensorflow.org/guide/data](https://www.tensorflow.org/guide/data)），它使您能够利用野外发现的数据。具体来说，这个
    API 提供了各种对象和函数来开发高度灵活的自定义输入数据管道。根据您的需求，您在 TensorFlow 中有几种其他检索数据的选项：
- en: tensorflow-datasets—Provides access to a collection of popular machine learning
    data sets that can be downloaded with a single line of code.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tensorflow-datasets—提供访问一系列流行的机器学习数据集的方法，只需一行代码即可下载。
- en: Keras data generators—Keras is a submodule in TensorFlow and provides various
    high-level functionality built on top of the TensorFlow’s low-level API. The data
    generators provide ways to load specific types of data (e.g., images or time series
    data) from various sources (e.g., disk).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 数据生成器—Keras 是 TensorFlow 的一个子模块，并提供了基于 TensorFlow 低级 API 构建的各种高级功能。数据生成器提供了从各种来源（例如磁盘）加载特定类型的数据（例如图像或时间序列数据）的方法。
- en: A brief history of Keras
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 简史
- en: 'Keras was initially founded by François Chollet as a platform-agnostic, high-level
    API that can use one of two popular low-level symbolic math libraries at a time:
    TensorFlow or Theano. Specifically, Keras provides layers (e.g., fully connected
    layers, convolution layers, etc.), which encapsulate core computations of neural
    networks.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 最初由 François Chollet 创建，作为一个与平台无关的高级 API，可以同时使用两种流行的低级符号数学库之一：TensorFlow
    或 Theano。具体来说，Keras 提供了层（例如全连接层、卷积层等），这些层封装了神经网络的核心计算。
- en: Furthermore, Keras provides pretrained models that can be downloaded and used
    conveniently. As Theano retired in 2017, TensorFlow became the go-to backend for
    Keras. In 2017 (TensorFlow v1.4 upward), Keras was integrated into TensorFlow
    and is now a submodule in TensorFlow that provides a wide variety of reusable
    layers that can be used to build deep learning models as well as pretrained models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Keras 提供了可下载并方便使用的预训练模型。由于 Theano 在 2017 年退出，TensorFlow 成为 Keras 的首选后端。在
    2017 年（TensorFlow v1.4 及以上版本），Keras 被整合到 TensorFlow 中，现在是 TensorFlow 的一个子模块，提供了各种可重复使用的层，可用于构建深度学习模型以及预训练模型。
- en: Using any of these elements (or a combination of them), you can write a data-processing
    pipeline (e.g., a Python script). Data would vary depending on the problem you
    are trying to solve. For example, in an image recognition task, data would be
    images and their respective classes (e.g., dog/cat). For a sentiment analysis
    task, the data would be movie reviews and their respective sentiments (e.g., positive/negative/neutral).
    The purpose of this pipeline is to produce a batch of data from these data sets.
    The data sets typically fed to deep learning models can have tens of thousands
    (if not more) data points and would never fit fully in limited computer memory,
    so we feed a small batch of data (e.g., few hundred data points) at a time and
    iterate through the full data set in batches.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些元素中的任何一个（或它们的组合），您可以编写一个数据处理流水线（例如一个 Python 脚本）。数据会根据您试图解决的问题而变化。例如，在图像识别任务中，数据将是图像及其相应的类别（例如，狗/猫）。对于情感分析任务，数据将是电影评论及其相应的情感（例如，积极/消极/中性）。该流水线的目的是从这些数据集中产生一批数据。通常馈送给深度学习模型的数据集可能有数万（甚至更多）个数据点，并且永远不会完全适合有限的计算机内存，因此我们一次馈送一小批数据（例如，几百个数据点），并以批次方式遍历整个数据集。
- en: 'Next up is the model-building phase. Deep learning models come in many flavors
    and sizes. There are four main types of deep networks: fully connected, convolutional
    neural, recurrent neural, and Transformer. These models have different capabilities,
    strengths, and weaknesses, as you will see in later chapters. TensorFlow also
    offers different APIs that have varying degrees of control for building models.
    First, in its most raw form, TensorFlow provides various primitive operations
    (e.g., matrix multiplication) and data structures to store inputs and outputs
    of the models (e.g., n-dimensional tensors). These can be used as building blocks
    to implement any deep learning models from the ground up.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是模型构建阶段。深度学习模型有许多不同的类型和规模。有四种主要类型的深度网络：全连接、卷积神经、循环神经和 Transformer。正如您将在后续章节中看到的，这些模型具有不同的能力、优势和劣势。TensorFlow
    还提供了不同的 API，用于构建模型的控制程度各不相同。首先，在其最原始的形式中，TensorFlow 提供了各种基本操作（例如矩阵乘法）和用于存储模型输入和输出的数据结构（例如
    n 维张量）。这些可以用作构建块，从零开始实现任何深度学习模型。
- en: 'However, it can be quite cumbersome to build models using the low-level TensorFlow
    API, as you need to repetitively use various low-level operations in TensorFlow
    and ensure the correctness of the computations happening in the model. This is
    where Keras comes in. Keras (now a submodule in TensorFlow) offers several advantages
    over the TensorFlow API:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用低级 TensorFlow API 构建模型可能会相当麻烦，因为您需要反复使用 TensorFlow 中的各种低级操作，并确保模型中正在进行的计算的正确性。这就是
    Keras 的用武之地。Keras（现在是 TensorFlow 的一个子模块）相比 TensorFlow API 提供了几个优势：
- en: '*It provides* Layer objects that encapsulate various common functionality that
    repeatedly happens in neural networks. We will learn what layers are available
    to us in more detail in the coming chapters.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*它提供* 封装了神经网络中经常发生的各种常见功能的层对象。我们将在接下来的章节中更详细地了解可用的层。'
- en: It provides several high-level model-building APIs (e.g., Sequential, functional,
    and subclassing). For example, the Sequential API is great for building simple
    models that go from an input to an output through a series of layers, whereas
    the functional API is better if you are working with more complex models. We will
    discuss these APIs in more detail in chapter 3.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了几种高级模型构建 API（例如，Sequential、functional 和 subclassing）。例如，Sequential API 适用于构建从输入到输出经过一系列层的简单模型，而
    functional API 更适用于处理更复杂的模型。我们将在第 3 章中更详细地讨论这些 API。
- en: As you can imagine, these features drastically lower the barriers for using
    TensorFlow. For example, if you need to implement a standard neural network, all
    you need to do is stack a few standard Keras layers, which, if you were to do
    the same with the low-level TensorFlow API, would cost you hundreds of lines of
    code. But, if you need the flexibility to go wild and implement complicated models,
    you still have the freedom to do so.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可以想象的那样，这些功能大大降低了使用 TensorFlow 的障碍。例如，如果您需要实现一个标准的神经网络，您只需要堆叠几个标准的 Keras
    层，而如果您要使用低级 TensorFlow API 做同样的事情，那将会花费您数百行代码。但是，如果您需要灵活性来实现复杂的模型，您仍然有自由去这样做。
- en: Finally, TensorFlow offers its most abstract API known as the Estimator API
    ([https://www.tensorflow.org/guide/estimator](https://www.tensorflow.org/guide/estimator)).
    This API is designed to be very robust against any user-induced errors. The robustness
    is guaranteed by a very restricted API, exposing the user to the bare minimum
    functionality to train, predict from, and evaluate models.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，TensorFlow 提供了其最抽象的 API，称为 Estimator API（[https://www.tensorflow.org/guide/estimator](https://www.tensorflow.org/guide/estimator)）。这个
    API 的设计非常健壮，能够抵御任何用户引起的错误。这种健壮性是通过一个非常受限的 API 来保证的，向用户公开了训练、预测和评估模型的最低功能。
- en: When you build the model, TensorFlow creates what’s known as a data-flow graph.
    This graph is a representation of what your model looks like and the operations
    it executes. Then, if you have optimized hardware (e.g., a GPU), TensorFlow will
    identify those devices and place parts of this graph on that special hardware
    so that any operations you run on the model are executed as quickly as possible.
    Appendix A provides detailed instructions for setting up TensorFlow and other
    required dependencies to run the code.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当您构建模型时，TensorFlow 将创建所谓的数据流图。这个图是您的模型的表示以及它执行的操作。然后，如果您有优化的硬件（例如，GPU），TensorFlow
    将识别出这些设备，并将此图的部分放置在该特殊硬件上，以便您对模型执行的任何操作尽可能快地执行。附录 A 提供了设置 TensorFlow 和其他所需依赖项以运行代码的详细说明。
- en: 1.1.2 Building and deploying a machine learning model
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 构建和部署机器学习模型
- en: After you build the model, you can train it with the data you prepared using
    the tf.data API. The model’s training process is critical, as for deep learning
    models, it is quite time-consuming, so you need a way to periodically monitor
    the progress of the model and make sure the performance stays at a reasonable
    level during the course of training. For that we write the loss value, the evaluation
    metric for performance on both training and validation data, so if something goes
    wrong, you can intervene as soon as possible. There are more advanced tools in
    TensorFlow that will allow you to monitor the performance and health of your model
    with more options and convenience. TensorBoard ([https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard))
    is a visualization tool that comes with TensorFlow and can be used to visualize
    various model metrics (e.g., accuracy, precision, etc.) while the model is trained.
    All you need to do is log the metrics you’d like to visualize to a directory and
    then start the TensorBoard server, providing the directory as an argument. TensorBoard
    will automatically visualize the logged metrics on a dashboard. This way, if something
    goes wrong, you’ll quickly notice it, and the logged metrics will help pinpoint
    any issues with the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型之后，你可以使用准备好的数据通过 tf.data API 对其进行训练。模型的训练过程非常重要，对于深度学习模型来说，它非常耗时，所以你需要一种方式来定期监视模型的进展，并确保在训练过程中性能保持在合理水平。为此，我们会记录
    loss 值，这是对训练和验证数据性能的评估指标，因此如果出现问题，你可以尽快介入。TensorFlow 中有更高级的工具，可以让你以更多选项和便利的方式监视模型的性能和健康状况。TensorBoard（[https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)）是一个随
    TensorFlow 一起提供的可视化工具，可以用于可视化模型的各种指标（例如准确率、精确度等）在训练过程中的变化。你只需要将你想要可视化的指标记录到一个目录中，然后启动
    TensorBoard 服务器，并提供该目录作为参数。TensorBoard 将自动在一个仪表盘上可视化记录的指标。这样，如果出现问题，你将很快注意到，并且记录的指标将帮助你定位模型中的问题。
- en: After (or even during) the training process, you need to save the model; otherwise,
    it will be destroyed right after you exit the Python program. Also, if your training
    process gets interrupted during training, you can restore the model and continue
    training (if you saved it). In TensorFlow you can save models in several ways.
    You can simply save a model in HDF5 format (i.e., a format for large file storage).
    Another recommended method is saving it as a SavedModel ([https://www.tensorflow.org/guide/saved_model](https://www.tensorflow.org/guide/saved_model)),
    the standard way to save models adopted by TensorFlow. We will see how to save
    different formats in the coming chapters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中（甚至在训练过程期间），你需要保存模型，否则在退出 Python 程序后模型将被销毁。此外，如果训练过程在训练中断时被中断，你可以恢复模型并继续训练（如果你已经保存了它）。在
    TensorFlow 中，可以以几种方式保存模型。你可以简单地将模型保存为 HDF5 格式（即用于大型文件存储的格式）。另一种推荐的方法是将其保存为 SavedModel（[https://www.tensorflow.org/guide/saved_model](https://www.tensorflow.org/guide/saved_model)），这是
    TensorFlow 采用的保存模型的标准方式。在接下来的章节中，我们将看到如何保存不同的格式。
- en: All the great work you’ve done has paid off. Now you want to joyfully tell the
    world about the very smart machine learning model you built. You want users to
    use the model and be amazed by it and for it to find its way into a news headline
    on artificial intelligence. To take the model to users, you need to provide an
    API. For this, TensorFlow has what is known as TensorFlow serving ([https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)).
    TensorFlow serving helps you to deploy the trained models and implement an API
    for users and customers to use. It is a complex topic and involves many different
    subtopics, and we’ll discuss it in a separate chapter.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你所完成的所有出色工作都已经得到了回报。现在，你想要欢快地向世界展示你构建的非常聪明的机器学习模型。你希望用户使用这个模型并对其感到惊叹，并且希望它能够成为关于人工智能的新闻标题。为了将模型介绍给用户，你需要提供一个
    API。为此，TensorFlow 提供了称为 TensorFlow Serving 的功能（[https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)）。TensorFlow
    Serving 帮助你部署训练好的模型并为用户和客户提供 API。这是一个复杂的主题，涉及许多不同的子主题，我们将在另一章中讨论它。
- en: We have gone on a long journey from mere data to deploying and serving models
    to customers. Next, let’s compare several popular hardware choices used in machine
    learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从单纯的数据出发，进行了一次漫长的旅程，最终将模型部署和提供给客户使用。接下来，我们将比较在机器学习中使用的几种流行硬件选择。
- en: 1.2 GPU vs. CPU
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 GPU vs. CPU
- en: If you have implemented simple computer programs (e.g., a commercial website)
    or worked with standard data science tools like NumPy, pandas, or scikit-learn,
    you would have heard the term *GPU*. To reap real benefits, TensorFlow relies
    on special hardware, such as GPUs. In fact, the progress we have achieved so far
    in deep neural networks can be heavily attributed to the advancement of GPUs in
    the last few years. What is so special about GPUs? How are they different from
    the brains of the computer, the *central processing unit* (CPU)?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你实现过简单的计算机程序（例如商业网站）或者使用过标准数据科学工具如 NumPy、pandas 或者 scikit-learn，你应该听过 *GPU*
    这个术语。为了获得真正的好处，TensorFlow 依赖于特殊的硬件，比如 GPU。事实上，我们在深度神经网络方面取得的进展很大程度上归功于过去几年 GPU
    的进步。GPU 有何特殊之处？它们与计算机的大脑、*中央处理单元*（CPU）有何不同？
- en: Let’s understand this with an analogy. Remind yourself of how you commute to
    work. If you get ready early and have some time to spare, you might take the bus.
    However, if you only have 10 minutes to spare for the important meeting happening
    at 9:00 a.m., you might decide to take your car. What is the difference between
    these two types of transportation? What different purposes do they serve? A car
    is designed to get a few people (e.g., four) quickly to a destination (i.e., low
    latency). On the other hand, a bus is slow but carries more people (e.g., 60)
    in a single trip (i.e., high throughput). Additionally, a car is fitted with various
    sensors and equipment that will make your drive/ride comfortable (e.g., parking
    sensors, lane detection, seat heaters, etc.). But the design of a bus would focus
    more on providing basic needs (e.g., seats, stop buttons, etc.) for a lot of people
    with limited options to make your ride joyful (figure 1.1).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过类比来理解这一点。想想你通勤上班的方式。如果你早早准备好并有些时间可以浪费，你可能会坐公交车。但是如果你只有 10 分钟的时间参加早上 9 点的重要会议，你可能会决定开车。这两种交通方式有什么不同？它们分别有什么不同的用途？汽车的设计是为了快速将少数人（例如四个）送到目的地（即低延迟）。另一方面，公共汽车慢但可以在一次行程中运载更多人（例如
    60 人）（即高吞吐量）。此外，汽车配备了各种传感器和设备，使您的驾驶/乘车更加舒适（例如停车传感器、车道检测、座椅加热器等）。但公共汽车的设计更注重为大量乘客提供基本需求（例如座位、停车按钮等），选项有限使您的乘车愉快（见图
    1.1）。
- en: '![01-01](../../OEBPS/Images/01-01.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![01-01](../../OEBPS/Images/01-01.png)'
- en: Figure 1.1 Comparing a CPU, a GPU, and a TPU. A CPU is like a car, which is
    designed to transport a few people quickly. A GPU is like a bus, which transports
    many people slowly. A TPU is also like a bus, but it operates well in only specific
    scenarios.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 比较 CPU、GPU 和 TPU。CPU 就像一辆汽车，设计用于快速运输少数人。GPU 就像一辆公共汽车，慢慢地运输许多人。TPU 也像一辆公共汽车，但只在特定场景下运行良好。
- en: A CPU is like a car, and a GPU is like a bus. A typical CPU has a handful of
    cores (e.g., eight). A CPU core does many things (I/O operations, coordinating
    communications between different devices, etc.) fast, but at a small scale. To
    support a variety of operations, CPUs need to support a large set of instructions.
    And to make these run fast, a CPU relies on expensive infrastructure (e.g., more
    transistors, different levels of caches, etc.). To summarize, CPUs execute a large
    set of instructions very fast at a small scale. In contrast, a typical GPU has
    many cores (e.g., more than a thousand). But a GPU core supports a limited set
    of instructions and focuses less on running them fast.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 就像一辆汽车，GPU 就像一辆公共汽车。一个典型的 CPU 有少数核心（例如，八个）。CPU 核心快速地执行多种任务（例如 I/O 操作，协调不同设备之间的通信等），但规模较小。为了支持各种操作，CPU
    需要支持大量指令。为了使这些指令运行得快，CPU 依赖昂贵的基础设施（例如更多的晶体管、不同级别的缓存等）。总之，CPU 在小规模上快速执行大量指令。相反，一个典型的
    GPU 有许多核心（例如，一千多个）。但是 GPU 核心支持有限的指令集，不太注重快速执行它们。
- en: In the context of machine learning, particularly in deep learning, we mostly
    need to perform lots of matrix multiplications repeatedly to train and infer from
    models. Matrix multiplication is a functionality GPUs are highly optimized for,
    which makes GPUs desirable.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，特别是在深度学习中，我们大多需要重复执行大量的矩阵乘法来训练和推断模型。矩阵乘法是 GPU 高度优化的功能，这使得 GPU 成为理想选择。
- en: We shouldn’t forget our friends, TPUs, which are the latest well-known addition
    to an optimized hardware list. TPUs were invented by Google and can be thought
    of as stripped-down GPUs. They are application-specific integrated circuits (ASICs)
    targeted for machine learning and AI applications. They were designed for low-precision
    high-volume operations. For example, a GPU typically uses 32-bit precision, whereas
    a TPU uses a special data type known as *bfloat16* (which uses 16 bits) ([http://mng.bz/QWAe](http://mng.bz/QWAe)).
    Furthermore, TPUs lack graphic-processing capabilities such as rasterizing/ texture
    mapping. Another differentiating characteristic of TPUs is that they are much
    smaller compared to GPUs, meaning more TPUs can be fit in a smaller physical space.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应忘记我们的朋友 TPU，它们是优化硬件清单的最新知名添加。TPU 由 Google 发明，可以被视为简化的 GPU。它们是专门针对机器学习和人工智能应用的应用特定集成电路（ASIC）。它们被设计用于低精度高容量运算。例如，GPU
    通常使用 32 位精度，而 TPU 使用一种称为 *bfloat16* 的特殊数据类型（使用 16 位）（[http://mng.bz/QWAe](http://mng.bz/QWAe)）。此外，TPU
    缺乏图形处理功能，如光栅化/纹理映射。TPU 的另一个区别特征是它们比 GPU 要小得多，意味着可以在更小的物理空间内容纳更多的 TPU。
- en: To extend our car-bus analogy to TPUs, you can think of a TPU as an economical
    bus that is designed to travel short distances in remote areas. It cannot be used
    as a normal bus to travel long distances comfortably or to suit a variety of road/weather
    conditions, but it gets you from point A to point B, so it gets the job done.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的汽车-公交车类比扩展到 TPU，你可以将 TPU 视为经济型公交车，设计用于在偏远地区短距离旅行。它不能像普通公交车那样舒适地长途旅行或适应各种道路/天气条件，但它可以将你从
    A 点运送到 B 点，因此可以完成任务。
- en: 1.3 When and when not to use TensorFlow
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 TensorFlow 的使用时机
- en: A key component in knowing or learning TensorFlow is knowing what and what not
    to use TensorFlow for. Let’s look at this through a deep learning lens.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 了解或学习 TensorFlow 的关键组成部分是知道何时以及何时不应该使用 TensorFlow。让我们通过深度学习的视角来看一下这一点。
- en: 1.3.1 When to use TensorFlow
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 TensorFlow 的使用时机
- en: TensorFlow is not a silver bullet for any machine learning problem by any means.
    You will get the maximum output by knowing what TensorFlow is good for.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 绝不是任何机器学习问题的万能解决方案。只有了解 TensorFlow 的适用范围，才能获得最佳效果。
- en: Prototyping deep learning models
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型的原型设计
- en: 'TensorFlow is a great tool for prototyping models (e.g., fully connected networks,
    convolutional neural networks, long short-term memory networks), as it provides
    layer objects (in Keras), such as the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是原型设计模型的绝佳工具（例如，全连接网络、卷积神经网络、长短期记忆网络），因为它提供了层对象（在 Keras 中），例如以下内容：
- en: Dense layers for fully connected networks
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接网络的密集层
- en: Convolution layers for convolutional neural networks
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络的卷积层
- en: RNN (recurrent neural network)/LSTM (long short-term memory)/GRU (gated recurrent
    unit) layers for sequential models
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于顺序模型的 RNN（循环神经网络）/ LSTM（长短期记忆）/ GRU（门控循环单元）层
- en: (You do not need to know the underlying mechanics of these layers, as they will
    be discussed in depth in the chapters ahead.) TensorFlow even offers a suite of
    pretrained models, so you can develop a simple model with a few layers or a complex
    ensemble model that consists of many models with fewer lines of code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: （你不需要了解这些层的底层机制，因为它们将在后面的章节中深入讨论。）TensorFlow 甚至提供了一套预训练模型，因此你可以用更少的代码开发一个简单的模型，包括几个层，或者一个由许多模型组成的复杂集成模型。
- en: Implementing models that can run faster on optimized hardware
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 实现可以在优化硬件上更快运行的模型
- en: TensorFlow contains kernels (implementations of various low-level operations;
    e.g., matrix multiplication) that are optimized to run faster on GPUs and TPUs.
    Therefore, if your model can take advantage of such optimized operations (e.g.,
    linear regression), and you need to run the model on large amounts of data repetitively,
    TensorFlow will help to run your model faster.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 包含核心（各种低级操作的实现；例如，矩阵乘法）进行了优化，以便在 GPU 和 TPU 上更快地运行。因此，如果你的模型可以利用这些优化的操作（例如，线性回归），并且需要重复运行大量数据的模型，TensorFlow
    将有助于更快地运行模型。
- en: Controlling TensorFlow code on hardware
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 控制 TensorFlow 代码在硬件上的运行
- en: 'As much as it’s important to leverage the power of GPUs/TPUs to run TensorFlow
    code, it’s also important to know that we can control resource utilization (e.g.,
    memory) when running the code. The following are the main aspects you can control
    when running TensorFlow code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管利用 GPU/TPU 运行 TensorFlow 代码非常重要，但同样重要的是我们可以在运行代码时控制资源利用（例如，内存）。以下是运行 TensorFlow
    代码时可以控制的主要方面：
- en: '*Where specific TensorFlow operations should run*—Normally you wouldn’t need
    to do this, but you can specify whether a certain operation should run on the
    CPU/GPU/TPU or which GPU/TPU to use, should you have multiple.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特定 TensorFlow 操作的运行位置* —— 通常情况下你不需要这样做，但是你可以指定某个操作应在 CPU/GPU/TPU 上运行，或者指定使用哪个
    GPU/TPU，特别是当你拥有多个 GPU/TPU 时。'
- en: '*The amount of memory to be used on the GPU*—You can tell TensorFlow to allocate
    only a certain percentage of the total GPU memory. This is quite handy for making
    sure that there will be some portion of GPU memory available for any graphics-related
    processes (e.g., used by the operating system).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GPU中的内存使用量* —— 你可以告诉 TensorFlow 只分配总 GPU 内存的一定百分比。这对确保 GPU 内存中有一个用于任何涉及图形处理的进程（例如操作系统使用）非常方便。'
- en: Productionize models/serving on cloud
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上运行模型/服务化
- en: The most common goal of a machine learning model is to serve in solving a real-world
    problem; thus the model needs to be exposed for predictions to interested stakeholders
    via a dashboard or an API. A unique advantage of TensorFlow is that you do not
    need to leave it when your model reaches this stage. In other words, you can develop
    your model-serving API via TensorFlow. Additionally, if you have lavish hardware
    (e.g., GPUs/TPUs), TensorFlow will make use of that when making predictions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的最常见目标是为解决现实世界的问题服务；因此，模型需要通过仪表板或 API 向感兴趣的利益相关者提供预测。TensorFlow 的一个独特优势是，当模型达到这个阶段时，你不需要离开它。换句话说，你可以通过
    TensorFlow 开发你的模型服务 API。此外，如果你有豪华的硬件（例如 GPU/TPU），TensorFlow 在进行预测时会利用它。
- en: Monitoring models during model training
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 监控模型的训练过程中的模型性能。
- en: During the training of the model, it is crucial that you keep tabs on model
    performance to prevent overfitting or underfitting. Training deep learning models
    can be tedious, even with access to GPUs, due to their high computational demand.
    This makes it more difficult to monitor these models than simpler ones that run
    in minutes. If you want to monitor a model that runs in a few minutes, you can
    print the metrics to the console and log to a file for reference.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练期间，关注模型性能以防止过度拟合或欠拟合非常关键。即使有 GPU 的帮助，训练深度学习模型仍然可能很繁琐，因为它们的计算需求很高。这使得监控这些模型比运行几分钟的简单模型更加困难。如果要监视运行几分钟的模型，可以将指标打印到控制台并记录到文件中以供参考。
- en: However, due to the high number of training iterations deep learning models
    go through, it is easier to absorb information when these metrics are visualized
    in graphs. TensorBoard provides exactly this functionality. All you need to do
    is log and persist your performance metrics in TensorFlow and point TensorBoard
    to the log directory. TensorBoard will take care of the rest by automatically
    converting this information in the log directory to graphs, which we can use to
    analyze the quality of our model.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，由于深度学习模型经历了大量的训练迭代，当这些指标以图形方式可视化时更容易吸收信息。TensorBoard 正是提供这种功能。你只需要在 TensorFlow
    中记录和保持你的性能指标，并将 TensorBoard 指向该记录目录。TensorBoard 将通过自动将此信息转换为图形来处理此操作目录中的信息，我们可以用来分析模型的质量。
- en: Creating heavy-duty data pipelines
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 创建重型数据管道
- en: 'We have stated several times that deep learning models have a big appetite
    for data. Typically, data sets that deep learning models sit on do not fit in
    memory. This means that we need to feed large amounts of data with low latency
    in smaller, more manageable batches of data. As we have already seen, TensorFlow
    provides rich APIs for streaming data to deep learning models. Most of the heavy
    lifting has been done for us. All we need to do is understand the syntax of the
    functions provided and use them appropriately. Some example scenarios of such
    data pipelines include the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次指出，深度学习模型对数据有很大的需求量。通常，深度学习模型所依赖的数据集不适合内存。这意味着我们需要以更小、更易处理的数据批次，以低延迟的方式提供大量的数据。正如我们已经看到的，TensorFlow
    提供了丰富的 API 来向深度学习模型流式传输数据。我们所需要做的就是理解所提供函数的语法并适当地使用它们。此类数据管道的一些示例情景包括以下内容：
- en: A pipeline that consumes large amounts of images and preprocesses them
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个消费大量图像并对其进行预处理的管道
- en: A pipeline that consumes large amounts of structured data in a standard format
    (e.g., CSV [comma separated value]) and performs standard preprocessing (e.g.,
    normalization)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个消费大量以标准格式（例如 CSV [逗号分隔值]）呈现的结构化数据并执行标准预处理（例如归一化）的管道。
- en: A pipeline that consumes large amounts of text data and performs only simple
    preprocessing (e.g., text lowering, removing punctuation)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个处理大量文本数据并执行简单预处理（例如，文本小写化，去除标点符号）的流水线
- en: 1.3.2 When not to use TensorFlow
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 不适用 TensorFlow 的情况
- en: It’s important to know the don’ts as well as the do’s when it comes to mastering
    a tool or a framework. In this section, we will discuss some of the areas where
    other tools might make you more efficient than TensorFlow.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握工具或框架时了解不应该做什么同样重要。在这一部分，我们将讨论其他工具可能比 TensorFlow 更高效的一些领域。
- en: Implementing traditional machine learning models
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 实现传统的机器学习模型
- en: Machine learning has a large portfolio of models (e.g., linear/logistic regression,
    supporting vector machines, decision trees, k-means) that fall under various categories
    (e.g., supervised versus unsupervised learning) and have different motivations,
    approaches, strengths, and weaknesses. There are many models used where you will
    not see much performance improvement using optimized hardware (e.g., decision
    trees, k-means, etc.) because these models aren’t inherently parallelizable. Sometimes
    you’ll need to run these algorithms as a benchmark for a new algorithm you developed
    or to get a quick ballpark figure as to how easy a machine learning problem is.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习拥有大量的模型（例如，线性/逻辑回归、支持向量机、决策树、K 均值），这些模型属于不同类别（例如，监督与非监督学习），并且具有不同的动机、方法、优势和劣势。有许多模型被使用，您不会看到太多性能提升使用优化的硬件（例如，决策树、K
    均值等），因为这些模型不具有固有的可并行性。有时您需要运行这些算法作为您开发的新算法的基准，或者以了解机器学习问题的难易程度。
- en: Using TensorFlow to implement such methods would cost you more time than it
    should. In such situations, scikit-learn ([https://scikit-learn.org/stable/](https://scikit-learn.org/stable/))
    is a better alternative, as the library provides a vast number of models readily
    implemented. TensorFlow does support some algorithms, such as boosted-tree-based
    models ([http://mng.bz/KxPn](http://mng.bz/KxPn)). But from my experience, using
    XGBoost (extreme gradient boosting) ([https://xgboost.readthedocs.io/en/latest/](https://xgboost.readthedocs.io/en/latest/))
    to implement boosted trees has been more convenient, as it is more widely supported
    by other libraries than the TensorFlow alternative. Furthermore, should you need
    GPU-optimized versions of scikit-learn algorithms, NVIDIA also provides some of
    these algorithms that are adapted and optimized for GPUs ([https://rapids.ai/](https://rapids.ai/)).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 实现这些方法将会花费比应该更多的时间。在这种情况下，scikit-learn ([https://scikit-learn.org/stable/](https://scikit-learn.org/stable/))
    是一个更好的选择，因为该库提供了大量已实现的模型。TensorFlow 确实支持一些算法，如基于提升树的模型 ([http://mng.bz/KxPn](http://mng.bz/KxPn))。但根据我的经验，使用
    XGBoost (极端梯度提升) ([https://xgboost.readthedocs.io/en/latest/](https://xgboost.readthedocs.io/en/latest/))
    实现提升树更加方便，因为它受到其他库的更广泛支持。此外，如果您需要 GPU 优化版本的 scikit-learn 算法，NVIDIA 也提供了一些适用于 GPU
    的算法 ([https://rapids.ai/](https://rapids.ai/))。
- en: Manipulating and analyzing small-scale structured data
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 操纵和分析小规模结构化数据
- en: Sometimes we will work with relatively small-structure data sets (e.g., 10,000
    samples) that can easily fit in memory. If the data can be loaded into memory
    fully, pandas and NumPy are much better alternatives for exploring and analyzing
    data. These are libraries that are equipped with highly optimized C/C++ implementations
    of various data manipulation (e.g., indexing, filtering, grouping) and statistics-related
    operations (e.g., mean, sum). For a small data set, TensorFlow can cause significant
    overhead (transferring data between the CPU and the GPU, launching computational
    kernels on the GPU), especially if a high volume of smaller, less expensive operations
    is run. Additionally, pandas/NumPy would be much more expressive in terms of how
    you can manipulate the data, as it’s their primary focus.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们将使用相对较小结构的数据集（例如，10,000 个样本），这些数据集可以轻松放入内存。如果数据可以完全加载到内存中，pandas 和 NumPy
    是探索和分析数据的更好选择。这些是配备有高度优化的 C/C++ 实现的各种数据操作（例如，索引、过滤、分组）和统计相关操作（例如，平均值、总和）的库。对于小数据集，TensorFlow
    可能会造成显著的开销（在 CPU 和 GPU 之间传输数据，在 GPU 上启动计算内核），特别是如果运行大量较小、成本较低的操作。此外，pandas/NumPy
    在如何操作数据方面更具表现力，因为这是它们的主要关注点。
- en: Creating complex natural language processing pipelines
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 创建复杂的自然语言处理流水线
- en: If you are developing a natural language processing (NLP) model, you would rarely
    pass data to the model without doing at least simple preprocessing on the data
    (e.g., text lowering, removing punctuation). But the actual steps that dictate
    your preprocessing pipeline will depend on your use case and your model. For example,
    there will be instances where you will have a handful of simple steps (e.g., case
    lowering, removing punctuation), or you might have a fully blown preprocessing
    pipeline that requires complex tasks (e.g., stemming, lemmatizing, correcting
    spelling). In the former case, TensorFlow is a good choice as it provides some
    simple text preprocessing functionality (e.g., case lowering, replacing text,
    string splitting, etc.). However, in the latter case, where costly steps such
    as lemmatization, stemming, spelling correction, and so on dominate the preprocessing
    pipeline, TensorFlow will hinder your progress. For this, spaCy ([https://spacy.io/](https://spacy.io/))
    is a much stronger candidate, as it provides an intuitive interface and readily
    available models to perform standard NLP processing tasks.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在开发自然语言处理（NLP）模型，则很少会将数据传递给模型而不对数据进行至少简单的预处理（例如，文本小写化、去除标点符号）。但指导您的预处理流水线的实际步骤将取决于您的用例和您的模型。例如，有时会有一些简单步骤（例如，小写化、去除标点符号），或者您可能有一个完整的预处理流水线，需要进行复杂的任务（例如，词干提取、词形还原、拼写纠正）。在前一种情况下，TensorFlow
    是一个不错的选择，因为它提供了一些简单的文本预处理功能（例如，小写化、替换文本、字符串分割等）。然而，在后一种情况下，如果诸如词形还原、词干提取、拼写纠正等昂贵步骤主导着预处理流水线，TensorFlow
    将阻碍您的进展。对此，spaCy ([https://spacy.io/](https://spacy.io/)) 是一个更强大的选择，因为它提供了直观的界面和可用的模型，用于执行标准的
    NLP 处理任务。
- en: spaCy does support including TensorFlow models (through a special wrapper) when
    defining pipelines. But as a rule of thumb, try to avoid this when possible. Integrations
    between different libraries are generally time-consuming and can even be error
    prone in complex setups.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 在定义流水线时支持包含 TensorFlow 模型（通过一个特殊包装器）。但作为一个经验法则，在可能的情况下尽量避免这样做。不同库之间的集成通常耗时，并且在复杂设置中甚至可能出错。
- en: Table 1.1 summarizes various strengths and weaknesses of TensorFlow.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 总结了 TensorFlow 的各种优点和缺点。
- en: Table 1.1 Summary of TensorFlow benefits and drawbacks
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 TensorFlow 优缺点总结
- en: '| **Task** | **Yes** | **No** |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **任务** | **是** | **否** |'
- en: '| Prototyping deep learning models | X |  |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 原型化深度学习模型 | X |  |'
- en: '| Implementing models (including non-deep learning) that can run faster on
    optimized hardware | X |  |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 实现在优化硬件上运行更快的模型（包括非深度学习） | X |  |'
- en: '| Productionizing models/serving on cloud | X |  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 在云端将模型投入生产/服务 | X |  |'
- en: '| Monitoring models during model training | X |  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 在模型训练期间监控模型 | X |  |'
- en: '| Creating heavy-duty data pipelines | X |  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 创建重型数据流水线 | X |  |'
- en: '| Implementing traditional machine learning models |  | X |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 实现传统机器学习模型 |  | X |'
- en: '| Manipulating and analyzing small-scale structured data |  | X |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 操纵和分析小规模结构化数据 |  | X |'
- en: '| Creating complex NLP pipelines |  | X |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 创建复杂的自然语言处理流水线 |  | X |'
- en: 1.4 What will this book teach you?
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 本书将教授您什么？
- en: In the coming chapters, this book will teach you some vital skills that will
    help you use TensorFlow principally and effectively for research problems.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，本书将教授您一些至关重要的技能，这些技能将帮助您主要且有效地解决研究问题。
- en: 1.4.1 TensorFlow fundamentals
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 TensorFlow 基础知识
- en: First, we will learn the basics of TensorFlow. We will learn the different execution
    styles it provides, primary building blocks that are used to implement any TensorFlow
    solution (e.g., tf.Variable, tf.Operation), and various functionalities as low-level
    operations. Then we will explore various model-building APIs exposed by Keras
    (a submodule in TensorFlow) to users and their benefits and limitations, which
    will help with making decisions such as when to use a certain model-building API.
    We will also study various ways we can retrieve data for TensorFlow models. Unlike
    traditional methods, deep learning models consume large amounts of data, so having
    an efficient and scalable data ingestion pipeline (i.e., input pipeline) is of
    paramount importance.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将学习 TensorFlow 的基础知识。我们将学习它提供的不同执行方式，用于实现任何 TensorFlow 解决方案的主要构建模块（例如，tf.Variable、tf.Operation），以及各种低级操作的功能。然后我们将探索由
    Keras（TensorFlow 的一个子模块）向用户公开的各种模型构建 API，以及它们的优点和局限性，这将有助于做出何时使用特定模型构建 API 的决定。我们还将研究我们可以为
    TensorFlow 模型获取数据的各种方法。与传统方法不同，深度学习模型消耗大量数据，因此拥有高效且可扩展的数据摄入管道（即输入管道）至关重要。
- en: 1.4.2 Deep learning algorithms
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.2 深度学习算法
- en: Implementing efficient deep learning models is one of the primary purposes of
    TensorFlow. Therefore, we will be discussing the architectural details of various
    deep learning algorithms such as full connected neural networks, convolutional
    neural networks (CNNs), and recurrent neural networks (RNNs). Note that investigating
    theories of these models is not an objective of this book. We will only be discussing
    these models at a level that helps us understand how to implement them comfortably
    with TensorFlow/Keras.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 实现高效的深度学习模型是 TensorFlow 的主要目的之一。因此，我们将讨论各种深度学习算法的架构细节，如全连接神经网络、卷积神经网络（CNN）和循环神经网络（RNN）。请注意，研究这些模型的理论不是本书的目标。我们将只讨论这些模型，以便帮助我们理解如何在
    TensorFlow/Keras 中舒适地实现它们。
- en: We will further hone our understanding of these models by implementing and applying
    these models to popular computer vision and NLP applications such as image classification,
    image segmentation, sentiment analysis, and machine translation. It will be interesting
    to see how well these models do when it comes to such tasks, with no human-engineered
    features.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实施和应用这些模型到流行的计算机视觉和 NLP 应用程序，如图像分类、图像分割、情感分析和机器翻译，我们将进一步磨练我们对这些模型的理解。看到这些模型在这些任务上的表现如何，没有人工设计的特征将会很有趣。
- en: Then, we will discuss a new family of models that have emerged, known as Transformers.
    Transformers are very different from both convolutional and recurrent neural networks.
    Unlike CNNs and RNNs, which can only see part of a time-series sequence at a time,
    Transformers can see the full sequence of data, leading to better performance.
    In fact, Transformers have been surpassing the previously recorded state-of-the-art
    models in many NLP tasks. We will learn how we can incorporate such models in
    TensorFlow to improve the performance of various downstream tasks.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们将讨论一类新的模型，称为 Transformers。Transformers 与卷积神经网络和循环神经网络非常不同。与 CNN 和 RNN 不同，它们每次可以看到完整的时间序列数据，从而导致更好的性能。事实上，Transformers
    在许多 NLP 任务上已经超过了以前记录的最先进模型。我们将学习如何在 TensorFlow 中引入这些模型，以提高各种下游任务的性能。
- en: 1.4.3 Monitoring and optimization
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.3 监控和优化
- en: It is not enough to know how to implement a model in TensorFlow. Close inspection
    and monitoring of model performance are vital steps in creating a reliable machine
    learning model. Using visualization tools such as TensorBoard to visualize performance
    metrics and feature representations is an important skill to have. Model explainability
    has also emerged as an important topic, as black-box models like neural networks
    are becoming commodities in machine learning. TensorBoard has certain tools for
    interpreting models or explaining why a model made a certain decision.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何在 TensorFlow 中实现模型是不够的。仔细检查和监视模型性能是创建可靠机器学习模型的重要步骤。使用可视化工具，如 TensorBoard
    来可视化性能指标和特征表示是必备的技能。模型可解释性也已经成为一个重要的话题，因为像神经网络这样的黑盒模型正在成为机器学习中的常见商品。TensorBoard
    有一些工具来解释模型或解释为什么模型做出了某个决定。
- en: Next, we will investigate ways we can make models train faster. The training
    time is one of the most prominent bottlenecks in using deep learning models, so
    we will discuss some techniques to make the models train faster!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何使模型训练速度更快。训练时间是使用深度学习模型中最突出的瓶颈之一，因此我们将讨论一些使模型训练更快的技术！
- en: 1.5 Who is this book for?
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 这本书是为谁写的？
- en: 'This book is written for a broader audience in the machine learning community
    to provide a somewhat easy entry for novices, as well as machine learning practitioners
    with basic to medium knowledge/experience, to push their TensorFlow skills further.
    In order to get the most out of this book, you need the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是为机器学习社区中更广泛的读者群写的，旨在为初学者提供一个相对容易的入门，以及具有基本到中等知识/经验的机器学习从业者，以进一步推动他们的 TensorFlow
    技能。为了充分利用本书，您需要以下内容：
- en: Experience in the model development life cycle (through a research/industry
    project)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过研究/行业项目在模型开发生命周期中的经验
- en: Moderate knowledge of Python and object-oriented programming (OOP) (e.g., classes/generators/list
    comprehension)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 Python 和面向对象编程（OOP）的中等知识（例如，类/生成器/列表推导式）
- en: Basic knowledge of NumPy/pandas libraries (e.g., computing summary statistics,
    what pandas series DataFrame objects are)
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy/pandas 库的基本知识（例如，计算摘要统计信息，pandas series DataFrame 对象是什么）
- en: Basic knowledge of linear algebra (e.g., basic mathematics, vectors, matrices,
    n-dimensional tensors, tensor operations, etc.)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对线性代数有基本的了解（例如，基本数学，向量，矩阵，n维张量，张量操作等）
- en: Basic familiarity with the different deep neural networks available
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对不同的深度神经网络有基本的熟悉
- en: You will greatly benefit from this book if you are someone who has
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是以下的人，那么你将会从这本书中受益匪浅
- en: At least several months of experience as a machine learning researcher, data
    scientist, machine learning engineer, or even as a student during a university/
    school project in which you used machine learning
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少有几个月的机器学习研究员，数据科学家，机器学习工程师，甚至是在大学/学校项目中作为学生拥有使用机器学习的经验
- en: Worked closely with other machine learning libraries (e.g., scikit-learn) and
    has heard of amazing feats of deep learning and is keen to learn more about how
    to implement them
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他机器学习库密切合作（例如，scikit-learn），并听说过深度学习的惊人成绩，并渴望学习如何实现它们
- en: Experience with basic TensorFlow functionality but wants to write better TensorFlow
    code
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对基本的 TensorFlow 功能有所了解，但希望写出更好的 TensorFlow 代码
- en: 'You might be thinking, with the plethora of resources available (e.g., TensorFlow
    documentation, StackOverFlow.com, etc.), isn’t it easy (and free) to learn TensorFlow?
    Yes and no. If you just need “some” solution to a problem you’re working on, you
    might be able to hack one using the resources out there. But chances are that
    it will be a suboptimal solution, because to come up with an effective one, you
    need to build a strong mental image of how TensorFlow executes code, understand
    the functionality provided in the API, understand limitations, and so on. It is
    also important to understand TensorFlow and gain knowledge in an incremental and
    structured manner, which is very difficult to do by simply reading freely available
    resources at random. A strong mental image and solid knowledge come with many
    years of experience (while keeping a close eye on new features available, GitHub
    issues, and [stackoverflow.com](http://stackoverflow.com) questions) or from a
    book written by a person with many years of experience. The million-dollar question
    here is not “How do I use TensorFlow to solve my problem?” but “How do I use TensorFlow
    *effectively* to solve my problem?” Coming up with an effective solution requires
    a solid grokking of TensorFlow. An effective solution, in my mind, can be one
    that does (but is not limited to) the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在想，在有着大量资源可用的情况下（例如 TensorFlow 文档，StackOverFlow.com 等），学习 TensorFlow 不是很容易（且免费）吗？是和不。如果你只是需要针对问题工作的“一些”解决方案，你可能能够使用现有的资源进行hack。但很可能这将是一个次优解，因为为了提出一个有效的解决方案，你需要建立对
    TensorFlow 执行代码的强大心理形象，理解 API 中提供的功能，理解限制等。同时，逐渐有序地了解 TensorFlow 并理解它也非常困难，而仅仅是随机阅读免费资料是无法做到的。坚实的心理形象和牢固的知识来自于多年的经验（并密切关注新功能，GitHub
    问题和 [stackoverflow.com](http://stackoverflow.com) 问题），或者来自于一位具有多年经验的作者编写的书籍。这里的重要问题不是“我该如何使用
    TensorFlow 解决我的问题？”，而是“我该如何*有效地*使用 TensorFlow 解决我的问题？”提出一个有效的解决方案需要对 TensorFlow
    有扎实的理解。在我看来，一个有效的解决方案可以做到（但不限于）以下几点：
- en: Keeps the code relatively concise without sacrificing readability too much (e.g.,
    avoiding redundant operations, aggregating operations when possible)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持相对简洁的代码，同时又不牺牲可读性太多（例如，避免冗余操作，在可能的情况下聚合操作）
- en: Uses the latest and greatest features available in the API to avoid reinventing
    the wheel and to save time
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 API 中最新最棒的特性，避免重复发明轮子，节省时间
- en: Utilizes optimizations whenever possible (e.g., avoiding loops and using vectorized
    operations)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能利用优化（例如，避免循环，使用矢量化操作）
- en: If you asked me to summarize this book into a few words, I would say “enabling
    the reader to write effective TensorFlow solutions.”
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你让我用几个词来概括这本书，我会说“让读者能够编写有效的 TensorFlow 解决方案”。
- en: 1.6 Should we really care about Python and TensorFlow 2?
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 我们真的应该关心 Python 和 TensorFlow 2吗？
- en: 'Here we will get to know about the two most important technologies you’ll be
    studying heavily: Python and TensorFlow. Python is the foundational programming
    language we will be using to implement various TensorFlow solutions. But it is
    important to know that TensorFlow supports many different languages, such as C++,
    Go, JavaScript, and so on.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们将了解到你将会大量学习的两项最重要的技术：Python 和 TensorFlow。Python 是我们将使用来实现各种 TensorFlow 解决方案的基础编程语言。但重要的是要知道，TensorFlow
    支持许多不同的语言，比如 C++，Go，JavaScript 等等。
- en: The first question we should try to answer is “Why are we picking Python as
    our choice of programming language?” Python’s popularity has recently increased,
    especially in the scientific community, due to the vast number of libraries that
    have fortified Python (e.g., pandas, NumPy, scikit-learn), which has made conducting
    a scientific experiment/simulation and logging/visualizing/reporting the results
    much easier. In figure 1.2, you can see how Python has become the most popular
    search term (at least in the Google search engine). If you narrow the results
    to just the machine learning community, you will see an even higher margin.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该试图回答的第一个问题是：“为什么我们选择 Python 作为我们的编程语言？” Python 的流行度近年来有所增加，特别是在科学界，这是因为大量的库加强了
    Python（例如 pandas、NumPy、scikit-learn），这使得进行科学实验/模拟以及记录/可视化/报告结果变得更加容易。在图1.2中，您可以看到
    Python 如何成为最受欢迎的搜索词（至少在 Google 搜索引擎中是如此）。如果将结果仅限于机器学习社区，您将看到更高的差距。
- en: '![01-02](../../OEBPS/Images/01-02.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![01-02](../../OEBPS/Images/01-02.png)'
- en: Figure 1.2 Popularity of different programming languages (2015-2020)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 不同编程语言的流行程度（2015-2020）
- en: The next question to answer is “Why did we pick TensorFlow?” TensorFlow has
    been there almost since deep learning became popular ([http://mng.bz/95P8](http://mng.bz/95P8)).
    TensorFlow has been refined and revised over roughly five years, becoming more
    and more stable over time. Furthermore, unlike other counterpart libraries, TensorFlow
    provides an ecosystem of tools to satisfy your machine learning needs, from prototyping
    to model training to models. In figure 1.3, you can see how TensorFlow compares
    to one of its popular competitors, PyTorch.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个要回答的问题是：“我们为什么选择 TensorFlow？” TensorFlow 几乎从深度学习开始流行就一直存在([http://mng.bz/95P8](http://mng.bz/95P8))。
    TensorFlow 在大约五年的时间里不断改进和修订，随着时间的推移变得越来越稳定。此外，与其他类似的库不同，TensorFlow 提供了一个生态系统的工具，以满足您的机器学习需求，从原型设计到模型训练再到模型。在图1.3中，您可以看到
    TensorFlow 与其一个流行竞争对手 PyTorch 的比较。
- en: '![01-03](../../OEBPS/Images/01-03.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![01-03](../../OEBPS/Images/01-03.png)'
- en: Figure 1.3 Popularity of TensorFlow and PyTorch (2015-2020)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 TensorFlow 和 PyTorch 的流行程度（2015-2020）
- en: 'It’s also worth inspecting how much of a performance increase we gain as the
    size of the data grows. Figure 1.4 compares a popular scientific computation library
    (NumPy) to TensorFlow in a matrix multiplication task. This was tested on an Intel
    i5 ninth-generation processor and an NVIDIA 2070 RTX 8 GB GPU. Here, we are multiplying
    two randomly initialized matrices (each having size n × n). We have recorded the
    time taken for n = 100, 1000, 5000, 7500, 1000. On the left side of the graph,
    you can see the difference in time growth. NumPy shows an exponential growth of
    time taken as the size of the matrix grows. However, TensorFlow shows approximately
    linear growth. On the right side you can see how many seconds it takes if a TensorFlow
    operation takes one second. The message is clear: TensorFlow does much better
    than NumPy as the amount of data grows.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也值得检查随着数据量的增长，我们所获得的性能增长有多大。图1.4比较了一个流行的科学计算库（NumPy）与 TensorFlow 在矩阵乘法任务中的表现。这是在
    Intel i5 第九代处理器和 NVIDIA 2070 RTX 8 GB GPU 上测试的。在这里，我们正在乘以两个随机初始化的矩阵（每个矩阵大小为 n
    × n）。我们记录了 n = 100、1000、5000、7500、1000 时所花费的时间。在图的左侧，您可以看到时间增长的差异。NumPy 显示随着矩阵大小的增长，所花费时间呈指数增长。但是，TensorFlow
    显示出大致线性的增长。在图的右侧，您可以看到如果 TensorFlow 操作需要一秒钟需要多少秒。这一信息很清楚：随着数据量的增长，TensorFlow 比
    NumPy 做得更好。
- en: '![01-04](../../OEBPS/Images/01-04.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![01-04](../../OEBPS/Images/01-04.png)'
- en: Figure 1.4 Comparing NumPy and TensorFlow computing libraries in a matrix multiplication
    task
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 在矩阵乘法任务中比较 NumPy 和 TensorFlow 计算库
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has become a hot topic due to the unprecedented performance it
    delivers when provided ample amounts of data.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于提供了大量数据时提供的卓越性能，深度学习已成为一个热门话题。
- en: TensorFlow is an end-to-end machine learning framework that provides ecosystem-facilitating
    model prototyping, model building, model monitoring, model serving, and more.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 是一个端到端的机器学习框架，提供生态系统支持的模型原型设计、模型构建、模型监控、模型服务等。
- en: TensorFlow, just like any other tool, has strengths and weaknesses. Therefore,
    it is up to the user to weigh these against the problem they are trying to solve.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 和任何其他工具一样，都有优势和劣势。因此，用户需要权衡这些因素，以解决他们试图解决的问题。
- en: TensorFlow is a great tool to quickly prototype deep learning models with a
    vast range of complexities.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 是一个非常好的工具，可以快速原型设计各种复杂度的深度学习模型。
- en: TensorFlow is not suited to analyzing/manipulating a small-structure data set
    or developing complex text-processing data pipelines.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow并不适合分析/操作小型数据集或开发复杂的文本处理数据管道。
- en: This book goes beyond teaching the reader to implement some TensorFlow solution
    and teaches the reader to implement *effective* solutions with minimal effort
    while reducing the chance of errors.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书不仅教读者如何实现某些TensorFlow解决方案，更教授读者如何在最小化工作量的情况下实现*有效的*解决方案，同时减少错误的可能性。
