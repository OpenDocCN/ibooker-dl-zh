- en: Part 3\. Deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分\. 部署
- en: '*I*n part 3, we’ll look at how to get our models to the point where they can
    be used. We saw how to build models in the previous parts: part 1 introduced the
    building and training of models, and part 2 thoroughly covered an example from
    start to finish, so the hard work is done.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*在第三部分中，我们将看看如何使我们的模型达到可以使用的程度。我们在前几部分中看到了如何构建模型：第一部分介绍了模型的构建和训练，第二部分从头到尾详细介绍了一个示例，所以辛苦的工作已经完成了。'
- en: But no model is useful until you can actually use it. So, now we need to put
    the models out there and apply them to the tasks they are designed to solve. This
    part is closer to part 1 in spirit, because it introduces a lot of PyTorch components.
    As before, we’ll focus on applications and tasks we wish to solve rather than
    just looking at PyTorch for its own sake.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在你真正能够使用模型之前，没有任何模型是有用的。因此，现在我们需要将模型投入使用，并将其应用于它们设计解决的任务。这部分在精神上更接近第一部分，因为它介绍了许多PyTorch组件。与以往一样，我们将专注于我们希望解决的应用和任务，而不仅仅是为了看PyTorch本身。
- en: In part 3’s single chapter, we’ll take a tour of the PyTorch deployment landscape
    as of early 2020\. We’ll get to know and use the PyTorch just-in-time compiler
    (JIT) to export models for use in third-party applications to the C++ API for
    mobile support.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三部分的单一章节中，我们将了解2020年初的PyTorch部署情况。我们将了解并使用PyTorch即时编译器（JIT）将模型导出以供第三方应用程序使用，以及用于移动支持的C++
    API。
