- en: Chapter 3\. Making Training Repeatable
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章\. 使训练可重复
- en: In [Chapter 2](ch02.html#ch02_model_development_on_kubernetes_1738498450538975),
    you learned about techniques for customizing a model, including fine-tuning, a
    special case of model training. Once you’ve fine-tuned or trained your model for
    the first time, you might be tempted to think that you are done with model development
    and all you have left is to evaluate and deploy your model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.html#ch02_model_development_on_kubernetes_1738498450538975)中，你学习了定制模型的技术，包括微调，这是模型训练的一个特殊情况。一旦你完成了模型的微调或首次训练，你可能会想你已经完成了模型开发，剩下的只是评估和部署模型。
- en: You’d be half right. But because the data that informs the model will likely
    change over time, the model must be regularly retrained throughout its lifetime
    to ensure that it can continue to deliver value. In this chapter, you will dive
    into the AI model lifecycle, learning how to track model versions, automate model
    training, and implement GitOps for model training pipelines.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你说的对了一半。但是，由于为模型提供信息的资料很可能会随时间而变化，因此模型在其整个生命周期内必须定期重新训练，以确保它能够继续提供价值。在本章中，你将深入了解人工智能模型的生命周期，学习如何跟踪模型版本、自动化模型训练以及为模型训练管道实施GitOps。
- en: Retraining and the Model Development Lifecycle
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新训练和模型开发生命周期
- en: The world changes. The data that we use to describe the real world, then, must
    change too. Consequently, if the data changes, then any models that attempt to
    model a problem in the real world must also change.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 世界在变化。我们用来描述现实世界的资料，因此也必须变化。因此，如果资料发生变化，那么任何试图模拟现实世界问题的模型也必须发生变化。
- en: Since models in production are static, over time the input data that a given
    model will process in production for inference requests will differ from the data
    that the model was trained on. This variability can come from any number of sources,
    such as changing user behavior over time, seasonality effects in the data, changes
    to the input data format, etc. The phenomenon is called *data drift*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生产中的模型是静态的，随着时间的推移，给定模型在生产中处理推理请求的输入数据将与模型训练时的数据不同。这种变化可能来自任何数量的来源，例如用户行为随时间的变化、数据中的季节性效应、输入数据格式的变化等。这种现象被称为*数据漂移*。
- en: Data drift isn’t the only reason to retrain a model, however. Retraining is
    a good option when a metric that is monitored in production (such as accuracy,
    model responsiveness, compute resources, etc.) falls outside its optimal range.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移并不是重新训练模型的唯一原因。当生产中监控的指标（如准确度、模型响应性、计算资源等）超出其最佳范围时，重新训练是一个不错的选择。
- en: 'When and how often a model should be retrained are two key considerations,
    and they depend heavily on your use case and training data. There are two main
    choices here: either regularly retrain the model on some fixed cadence, or retrain
    the model on demand.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 模型何时以及多久应该重新训练是两个关键考虑因素，并且它们在很大程度上取决于你的用例和训练数据。这里有两种主要选择：要么定期以某种固定的时间间隔重新训练模型，要么根据需要重新训练模型。
- en: Retraining a model at a fixed cadence can be costly if the cadence is rapid
    or if the retraining doesn’t actually show any improvement. This method assumes
    that the data changes according to some predictable pattern that can be detected
    at a chosen retraining cadence. If retraining doesn’t show any improvement, it’s
    possible that the data isn’t changing in such a way to be captured by the regular
    cadence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果时间间隔很快或者重新训练实际上没有显示出任何改进，那么以固定时间间隔重新训练模型可能会很昂贵。这种方法假设数据会根据某种可预测的模式变化，这种模式可以在选择的重新训练时间间隔内检测到。如果重新训练没有显示出任何改进，那么可能是因为数据没有以这种方式变化，以至于无法被常规时间间隔所捕获。
- en: The other option is to retrain your model on demand. This ensures that models
    are not retrained unnecessarily, but it requires reliable monitoring of the performance
    of the current version of the model (discussed in [Chapter 4](ch04.html#ch04_model_deployment_and_monitoring_1738498450837987))
    and well-defined thresholds for when the performance has sufficiently degraded.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是在需要时重新训练模型。这确保了模型不会被不必要地重新训练，但它需要可靠地监控当前模型版本的性能（在第4章中讨论），以及当性能足够下降时明确定义的阈值。
- en: The full lifecycle of a model, then, looks something like [Figure 3-1](#ch03_figure_1_1738498450651715).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型的完整生命周期看起来就像[图3-1](#ch03_figure_1_1738498450651715)所示。
- en: '![](assets/skia_0301.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/skia_0301.png)'
- en: Figure 3-1\. The full lifecycle of an AI model
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 人工智能模型的完整生命周期
- en: In practice, this is a never-ending cycle, which repeats most often from the
    evaluation and monitoring stages, where unacceptable performance is typically
    discovered.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这是一个永无止境的循环，它通常从评估和监控阶段开始重复，在这些阶段通常会发现不可接受的表现。
- en: Where [Figure 1-1](ch01.html#ch01_figure_1_1738498450402392) was focused on
    the model development cycle (stage 2), [Figure 3-1](#ch03_figure_1_1738498450651715)
    zooms out to view the entire lifecycle of a model. The lifecycle starts with gathering
    data, continues through developing training code, executing the training job,
    evaluating the trained model, promoting the model to production, and monitoring
    the served model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图1-1](ch01.html#ch01_figure_1_1738498450402392)关注模型开发周期（阶段2）时，[图3-1](#ch03_figure_1_1738498450651715)则扩展到查看整个模型的生命周期。生命周期从收集数据开始，继续通过开发训练代码，执行训练作业，评估训练好的模型，将模型推广到生产，并监控所提供的服务模型。
- en: Crucially, this lifecycle can repeat at any stage (with the exception of training
    code development, which typically remains static), most commonly after the evaluation
    and monitoring stages (4 and 6). From those, it’s common to discover that either
    the training job needs to be run again, or that more or higher quality data needs
    to be collected. If more data is to be collected, typically the existing training
    code can be used as-is. In this case, stage 3 would follow stage 1.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的是，这个生命周期可以在任何阶段重复（除了通常保持静态的训练代码开发），最常见的是在评估和监控阶段（4和6）之后。从这些阶段，通常会发现要么需要再次运行训练作业，要么需要收集更多或更高质量的数据。如果需要收集更多数据，通常可以直接使用现有的训练代码。在这种情况下，阶段3将跟随阶段1。
- en: Tracking Model Versions
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪模型版本
- en: While they iterate on developing a model, data scientists will run many experiments
    by varying the dataset they use to create the model, the model’s architecture,
    the hyperparameters used for training the model, and more. Even after the initial
    handoff of the model to production, future retraining cycles of the model will
    yield new variants.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当他们在开发模型时，数据科学家将通过改变用于创建模型的dataset、模型的架构、用于训练模型的超参数等来运行许多实验。即使在将模型最初交付到生产后，模型的未来重新训练周期也会产生新的变体。
- en: Enterprises need robust solutions for tracking all of these versions of a given
    model. While version control systems have been table stakes for traditional software
    projects for decades now, model version control systems are still in their infancy
    despite the heavy reliance on models by enterprises of all sizes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 企业需要强大的解决方案来跟踪给定模型的这些版本。虽然版本控制系统几十年来一直是传统软件项目的标准，但模型版本控制系统尽管企业对模型的重度依赖，仍处于起步阶段。
- en: Model version tracking benefits the whole enterprise, from unlocking the ability
    of data scientists to recreate previous experiments, share their experiments with
    colleagues, and revert to a model from a previous experiment, to enabling model
    auditing and ensuring responsible AI use. For example, in order to explain a given
    model’s results and how it was created, it is necessary to know which version
    of a model was served in production at what time and how that model was created,
    including the data sources that went into the model.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 模型版本跟踪对整个企业都有益处，从解锁数据科学家重现以前实验的能力，与同事分享他们的实验，以及从以前的实验中回滚到模型，到实现模型审计和确保负责任的AI使用。例如，为了解释给定模型的结果及其创建方式，有必要知道在什么时间生产中使用了哪个版本的模型，以及该模型是如何创建的，包括进入模型的数据源。
- en: More and more often, enterprises use a centralized model registry throughout
    the model’s lifecycle, and this is rapidly becoming a recognized best practice.
    During model training and development, model training code should integrate with
    the model registry to register each subsequent version of the model as a distinct
    model artifact. Alongside the model artifact, model training code should register
    metadata about the training data and code that was used to create the model. The
    model registry should also be integrated at model deployment and monitoring stages,
    which will be discussed in [Chapter 4](ch04.html#ch04_model_deployment_and_monitoring_1738498450837987).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的企业在整个模型的生命周期中使用集中的模型注册表，这正在迅速成为一种公认的最佳实践。在模型训练和开发期间，模型训练代码应与模型注册表集成，将每个后续版本的模型作为独立的模型工件进行注册。与模型工件一起，模型训练代码还应注册有关用于创建模型的数据和代码的元数据。模型注册表还应集成在模型部署和监控阶段，这将在[第4章](ch04.html#ch04_model_deployment_and_monitoring_1738498450837987)中讨论。
- en: Many training platforms that are available today offer model registries as part
    of their product lineup. It is important to choose a platform with a strong model
    registry that is well integrated into the platform’s distributed training engine.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，许多可用的训练平台将其产品组合中的模型注册表作为其产品的一部分。选择一个具有强大模型注册表且与平台分布式训练引擎良好集成的平台非常重要。
- en: The [Kubeflow project](https://kubeflow.org) offers a powerful integrated solution,
    where the Kubeflow Training Operator, Kubeflow Pipelines, [Katib](https://oreil.ly/NgK4E),
    and the Kubeflow Model Registry can be used together to track training results
    in a central database. Similarly, the [MLflow project](https://mlflow.org) offers
    a robust model registry solution that can be combined with MLflow Runs and Experiments
    to streamline tracking of model versions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kubeflow项目](https://kubeflow.org)提供了一个强大的集成解决方案，其中Kubeflow Training Operator、Kubeflow
    Pipelines、[Katib](https://oreil.ly/NgK4E)和Kubeflow Model Registry可以一起使用，以在中央数据库中跟踪训练结果。同样，[MLflow项目](https://mlflow.org)提供了一个健壮的模型注册表解决方案，可以与MLflow
    Runs和Experiments结合使用，以简化模型版本的跟踪。'
- en: Today, proper model versioning tends to require behavior change by data scientists
    to deliberately integrate model version tracking into their training code and
    workflows. As projects like MLflow and Kubeflow evolve and become better integrated
    with frameworks like PyTorch, you can expect model version tracking capabilities
    to integrate seamlessly out of the box.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，适当的模型版本控制往往需要数据科学家改变行为，故意将模型版本跟踪集成到他们的训练代码和工作流程中。随着像MLflow和Kubeflow这样的项目的发展并更好地与PyTorch等框架集成，您可以期待模型版本跟踪功能能够无缝集成。
- en: Automating Model Training
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化模型训练
- en: 'Training a model is just like any other regularly repeated computing activity:
    it must be automated. Failure to do so leads to several negative outcomes:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型就像任何其他定期重复的计算活动一样：它必须自动化。未能这样做会导致几个负面结果：
- en: Wasted human resources by having to manually rerun training
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于需要手动重新运行训练而浪费人力资源
- en: Unpredictability in model retraining cadence
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型重新训练时间表的不可预测性
- en: Inconsistency in the model’s performance through discrepancies (deliberate or
    accidental) in the model training process
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型性能的不一致性，这是由于模型训练过程中的差异（故意或意外）造成的
- en: 'Initial model development, then, should not be considered complete until the
    training process is automated end to end. A fully featured automated training
    process should include at the very least:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，初始模型开发不应被视为完成，直到训练过程完全自动化。一个功能齐全的自动化训练过程至少应包括以下内容：
- en: Input parameters that specify any variables that typically need to be tweaked
    (e.g., a version identifier for the training code or training data, or *hyperparameters*—parameters
    that define how training is done—for the training job)
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入参数指定任何通常需要调整的变量（例如，训练代码或训练数据的版本标识符，或*超参数*——定义如何进行训练的参数——对于训练作业）
- en: Any necessary data preparation or preprocessing to collect data from any storage
    locations and prepare it for training
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何必要的数据准备或预处理，以从任何存储位置收集数据并为其训练做准备
- en: Fetching and executing the training job
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取并执行训练作业
- en: Storing the model and related artifacts in a chosen storage endpoint
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型和相关工件存储在选择的存储端点
- en: Registering the model and related artifacts in the model registry
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型注册表中注册模型和相关工件
- en: Evaluating the performance of the trained model
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估训练模型的性能
- en: Another feature that is nice to have but by no means essential is an automated
    process that promotes a trained model to production or any other post-training
    steps if the model meets some minimum performance thresholds.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个很好的功能，但并非必不可少的功能是，如果模型达到某些最低性能阈值，则自动将训练好的模型推广到生产或任何其他训练后的步骤。
- en: Warning
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: For many teams, promoting a model to production without any human oversight
    may not be appropriate. When evaluating a tool that has this feature, be sure
    to weigh the trade-offs of not having human review of a trained model’s metrics
    against keeping a human in the loop.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多团队来说，在没有人工监督的情况下将模型推广到生产可能不合适。在评估具有此功能的工具时，请确保权衡没有人工审查训练模型指标与保持人工参与之间的权衡。
- en: This process (and the software that implements it) is often referred to as a
    *pipeline* or *workflow*. These pipelines are usually authored by data scientists,
    data engineers, machine learning engineers, and/or MLOps teams, with Python being
    the prevailing language of choice.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程（以及实现它的软件）通常被称为“管道”或“工作流”。这些管道通常由数据科学家、数据工程师、机器学习工程师和/或 MLOps 团队编写，Python
    是首选的语言。
- en: For enterprises that have adopted Kubernetes as their model development and
    serving platform, we strongly recommend adopting a pipeline engine that is Kubernetes
    native and thus is able to leverage the existing Kubernetes infrastructure, integrating
    seamlessly with the overall MLOps infrastructure in use.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经采用 Kubernetes 作为其模型开发和部署平台的企业，我们强烈建议采用原生 Kubernetes 的管道引擎，这样就能够利用现有的 Kubernetes
    基础设施，并与使用的整体 MLOps 基础设施无缝集成。
- en: 'There are three major open source pipeline engines that have strong community
    adoption and should be considered for your training infrastructure:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个主要的开源管道引擎在社区中得到了广泛的应用，应该考虑用于您的训练基础设施：
- en: Airflow
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow
- en: '[Airflow](https://airflow.apache.org) is typically preferred by data scientists
    and tends to present the cleanest experience for authoring pipelines—or directed
    acyclic graphs (DAGs) in Airflow’s parlance)—but Airflow is not strictly Kubernetes
    native, which presents challenges when operationalizing it at scale on Kubernetes.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[Airflow](https://airflow.apache.org) 通常被数据科学家所青睐，并且通常为编写管道（或按照 Airflow 的说法，为有向无环图（DAGs））提供最干净的使用体验——但是
    Airflow 并非严格的原生 Kubernetes，这在将其大规模部署到 Kubernetes 上时带来了挑战。'
- en: Kubeflow Pipelines
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines
- en: A part of the broader Kubeflow project, [Kubeflow Pipelines](https://oreil.ly/0bP2X)
    is Kubernetes native at its core, making it more customizable, scalable, and well
    suited to enterprises with large or multiple data science teams wishing to share
    Kubernetes infrastructure, or with central IT/MLOps teams managing consistent
    infrastructure across teams.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为更广泛 Kubeflow 项目的组成部分，[Kubeflow Pipelines](https://oreil.ly/0bP2X) 在核心上原生支持
    Kubernetes，这使得它更加可定制、可扩展，非常适合拥有大型或多个数据科学团队的企业，这些企业希望共享 Kubernetes 基础设施，或者有中央 IT/MLOps
    团队管理跨团队的一致基础设施。
- en: MLflow
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow
- en: '[MLflow](https://mlflow.org) excels at model version tracking, making it easy
    for data scientists to adopt and track multiple versions of their models over
    time. However, MLflow requires more effort by operations teams to deploy and scale
    on Kubernetes.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLflow](https://mlflow.org) 在模型版本跟踪方面表现出色，使得数据科学家能够轻松地随时间跟踪其模型的多个版本。然而，MLflow
    需要运维团队付出更多努力，以便在 Kubernetes 上部署和扩展。'
- en: Tip
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Do you want to see what a continuous model training pipeline looks like in action?
    Red Hat offers an [MLOps lab exercise](https://oreil.ly/l04gD) that helps you
    build one yourself.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你想看看一个连续的模型训练流程在实际操作中是什么样子吗？红帽提供了一个[MLOps实验室练习](https://oreil.ly/l04gD)，帮助你自己构建一个。
- en: GitOps for Model Training Pipelines
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GitOps for Model Training Pipelines
- en: Model training pipelines are like code and should be treated accordingly. Pipeline
    definitions should be stored in source control and versioned, just like traditional
    application code. And like traditional application code, authors of pipeline definitions
    should follow a robust peer review process when making changes to the definitions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练管道就像代码一样，应该相应地对待。管道定义应该存储在源代码控制中并版本化，就像传统的应用程序代码一样。并且，就像传统的应用程序代码一样，当对定义进行更改时，管道定义的作者应该遵循稳健的同行评审流程。
- en: Production training runs, then, should run from clean versions of these pipelines,
    pulled from a well-defined version (such as a branch or tag) of the pipeline in
    version control. This is [GitOps](https://oreil.ly/u9oe-) in a nutshell. GitOps
    is a recent development in traditional software operations whereby applications
    are cleanly deployed from version control and continuously reconciled to ensure
    that the deployed application matches the desired state in version control. When
    teams wish to change the state of the application in production, they do so by
    changing the application’s definition in version control.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，生产训练运行应该从这些管道的干净版本中运行，这些版本是从版本控制中定义良好的版本（如分支或标签）中拉取的。这简而言之就是[GitOps](https://oreil.ly/u9oe-)。GitOps
    是传统软件操作领域的一项最新发展，其中应用程序从版本控制中干净地部署，并持续进行协调，以确保部署的应用程序与版本控制中的期望状态相匹配。当团队希望更改生产中应用程序的状态时，他们通过更改版本控制中的应用程序定义来实现。
- en: Kubernetes’ declarative approach to deploying applications, along with the reconciliation
    loop that keeps Kubernetes applications in their desired state, make Kubernetes
    an ideal platform for managing pipelines with GitOps.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes部署应用的声明式方法，以及保持Kubernetes应用处于期望状态的协调循环，使Kubernetes成为使用GitOps管理管道的理想平台。
- en: For managing applications on Kubernetes, one of the most popular projects is
    [Argo CD](https://oreil.ly/2yB2U). Argo CD is a continuous delivery tool for Kubernetes
    that allows users to implement GitOps principles into their workflow. While deploying
    pipeline definitions with Argo CD typically requires the development of custom
    code to convert pipeline definitions from version control into runnable training
    jobs, this is an area of rapid innovation, especially from the Kubeflow project,
    to allow for simpler pipeline definition management.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在Kubernetes上管理应用，最受欢迎的项目之一是[Argo CD](https://oreil.ly/2yB2U)。Argo CD是Kubernetes的持续交付工具，允许用户将GitOps原则融入到他们的工作流程中。虽然使用Argo
    CD部署管道定义通常需要开发自定义代码将管道定义从版本控制转换为可运行的训练作业，但这是一个快速创新的领域，特别是来自Kubeflow项目，以允许更简单的管道定义管理。
- en: 'Now that you’ve learned how to reliably retrain a model, keep track of its
    versions (and that of the data and training pipelines), and build a more robust
    open source MLOps infrastructure, you are prepared to move on to the next step
    of the AI model lifecycle: deployment and monitoring.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何可靠地重新训练模型，跟踪其版本（以及数据和训练管道的版本），并构建更健壮的开源MLOps基础设施，你已经准备好进入AI模型生命周期的下一步：部署和监控。
