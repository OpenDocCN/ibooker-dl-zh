- en: 4 Crowdsourced relevance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 众包相关性
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Harnessing your users’ collective insights to improve the relevance of your
    search platform
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用用户集体洞察力提高搜索平台的相关性
- en: Collecting and working with user behavioral signals
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集和使用用户行为信号
- en: Using reflected intelligence to create self-tuning models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用反射智能创建自调优模型
- en: Building an end-to-end signals boosting model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建端到端信号增强模型
- en: In chapter 1, we introduced the dimensions of user intent as content understanding,
    user understanding, and domain understanding. To create an optimal AI-powered
    search platform, we need to be able to combine each of these contexts to understand
    our users’ query intent. The question, though, is how do we derive these understandings?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们介绍了用户意图的维度，即内容理解、用户理解和领域理解。为了创建一个最佳的AI驱动搜索平台，我们需要能够结合每个这些上下文来理解我们的用户查询意图。然而，问题是我们是如何得出这些理解的？
- en: 'We can learn from many sources of information: documents, databases, internal
    knowledge graphs, user behavior, domain experts, and so on. Some organizations
    have teams that manually tag documents with topics or categories, and some even
    outsource these tasks using tools like Amazon Mechanical Turk, which allows them
    to crowdsource answers from people all around the world. For identifying malicious
    behavior or errors on websites, companies often allow their users to report problems
    and even suggest corrections. All of these are examples of crowdsourcing—relying
    upon input from many people to learn new information.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从许多信息来源中学习：文档、数据库、内部知识图谱、用户行为、领域专家等等。一些组织有团队手动用主题或类别标记文档，有些甚至使用像Amazon Mechanical
    Turk这样的工具外包这些任务，这使他们能够从世界各地的人那里众包答案。为了识别网站上的恶意行为或错误，公司通常允许用户报告问题甚至建议更正。所有这些都是众包的例子——依赖于许多人的输入来学习新信息。
- en: When it comes to search relevance, crowdsourcing can play a vital role, though
    it is usually important not to annoy your valued customers by constantly asking
    them for help. Fortunately, it is often possible to learn implicitly from your
    users, based on their behaviors. For example, to discover the most relevant documents
    for a query, we can examine logs to determine the documents most clicked on by
    other users when running that same search. Those clicks provide signals of which
    results are the most relevant for the query.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索相关性方面，众包可以发挥至关重要的作用，尽管通常重要的是不要通过不断请求帮助而惹恼您的宝贵客户。幸运的是，根据他们的行为，通常可以从用户那里隐式地学习。例如，为了发现查询的最相关文档，我们可以检查日志，以确定在运行相同搜索时其他用户点击最多的文档。这些点击提供了关于哪些结果对查询最相关的信号。
- en: In this chapter, we’ll explore how we can collect, analyze, and generate insights
    from these signals to crowdsource relevance. We’ll also cover the reflected intelligence
    process, introducing three key types of models for popularized relevance (signals
    boosting), for personalized relevance (collaborative filtering), and for generalized
    relevance (learning to rank). You’ll also index an e-commerce dataset and build
    your very first reflected intelligence model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何收集、分析和从这些信号中生成洞察力以众包相关性。我们还将介绍反射智能过程，介绍三种用于普及相关性（信号增强）、个性化相关性（协同过滤）和泛化相关性（学习排序）的关键模型类型。您还将索引一个电子商务数据集并构建您自己的第一个反射智能模型。
- en: 4.1 Working with user signals
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 与用户信号合作
- en: Every time a customer takes an action—such as issuing a query or purchasing
    a product—this provides a signal of that user’s intent. We can log and process
    these signals to learn insights about each user, different groups of users, or
    our entire user base.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 每当客户采取行动——例如发布查询或购买产品——这都为该用户的意图提供了信号。我们可以记录和处理这些信号，以了解每个用户、不同用户群体或我们整个用户群体的洞察力。
- en: This section introduces the power of using user signals with a sample e-commerce
    dataset we’ll use throughout the book, and it walks you through the mechanics
    of collecting, storing, and processing these signals.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了使用用户信号的力量，并使用我们在整本书中都会使用的示例电子商务数据集，引导您了解收集、存储和处理这些信号的机制。
- en: 4.1.1 Content vs. signals vs. models
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1 内容 vs. 信号 vs. 模型
- en: 'When building search engines, two high-level sources of data affect search
    relevance: content and signals. Most content is in the form of documents, which
    can represent web pages, product listings, computer files, images, videos, facts,
    or any other type of searchable information. Content documents usually contain
    text or embedding fields that are used to search, along with other fields representing
    attributes related to the content (author, size, color, dates, and so on). The
    defining characteristic of the content documents is that they contain information
    users search on and ideally the answers to their queries.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建搜索引擎时，两个高级数据源会影响搜索的相关性：内容和信号。大多数内容以文档的形式存在，可以代表网页、产品列表、计算机文件、图像、视频、事实或任何其他可搜索信息。内容文档通常包含用于搜索的文本或嵌入字段，以及代表与内容相关的属性（作者、大小、颜色、日期等）的其他字段。内容文档的标志性特征是它们包含用户搜索的信息，以及在理想情况下，它们的查询答案。
- en: When a user sees content in response to a query, they may click on a result,
    add it to their shopping cart, or take some other actions. These actions are signals,
    and they’re key to providing insights into how users engage with the content.
    These signals can later be aggregated and used to build models to improve the
    relevance of your matching and ranking algorithms. The defining characteristic
    of signals is that they are user-supplied insights for demonstrating how users
    want to interact with content.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在查询的响应中看到内容时，他们可能会点击结果、将其添加到购物车或采取其他行动。这些行动是信号，它们对于提供用户如何与内容互动的见解至关重要。这些信号可以随后汇总并用于构建模型，以改进匹配和排名算法的相关性。信号的标志性特征是它们是用户提供的见解，用于展示用户希望如何与内容互动。
- en: Sometimes it can also be useful to rely on external data sources—or *models*—as
    part of the search experience. This can include querying a knowledge graph, referencing
    a list of entities, or invoking a large language model (LLM) or other foundation
    model that has been trained on external data sources. These external models can
    be used to better interpret user queries, reason about and understand the content,
    or even summarize or generate new content to return. While we can consider models
    as a third source of data for our search engine, they are trained on content and/or
    signals and thus serve as a derivative and refined representation of those two
    original data sources.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，依赖外部数据源——或称为*模型*——作为搜索体验的一部分也可能很有用。这可以包括查询知识图谱、引用实体列表或调用在外部数据源上训练的大型语言模型（LLM）或其他基础模型。这些外部模型可以用来更好地解释用户查询、推理和理解内容，甚至总结或生成新的内容以返回。虽然我们可以将模型视为我们搜索引擎的第三种数据源，但它们是在内容和/或信号上训练的，因此作为这两个原始数据源的衍生和精炼表示。
- en: 'In summary, we use three main sources of information to improve search: the
    attributes of the items (content), the observed user interactions with content
    (signals), and external models (which are derived from content and/or signals).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们使用三个主要信息来源来改进搜索：项目的属性（内容）、用户与内容的观察到的交互（信号）以及外部模型（这些模型是从内容和/或信号中派生出来的）。
- en: For many tasks we undertake when building AI-powered search, we can derive similar
    outcomes using either content or signals, but they give us two different perspectives
    of relevance. In ideal cases, we can apply both perspectives to build an even
    smarter system, but it is useful to understand their strengths and weaknesses
    to best employ them.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建人工智能驱动的搜索时，我们执行许多任务，可以使用内容或信号来得出相似的结果，但它们为我们提供了两种不同的相关性视角。在理想情况下，我们可以应用这两种视角来构建一个更智能的系统，但了解它们的优缺点对于最佳地使用它们是有用的。
- en: For example, when trying to find a synonym for the word “driver”, we can look
    through the text content for words that commonly appear in the same documents.
    We may, in this case, find words (in priority order by the percentage of documents
    they appear within) like “taxi” (40%), “car” (35%), “golf” (15%), “club” (12%),
    “printer” (3%), “linux” (3%), and “windows” (1%). Similarly, we can look at the
    signals from users who searched for “driver” and aggregate common keywords from
    their other searches in priority order like “screwdriver” (50%), “printer” (30%),
    “windows” (25%), “mac” (15%), “golf” (2%), and “club” (2%). The lists derived
    from signals versus content might be similar, or they could look very different.
    The content-based approach tells us the most-represented meanings within our documents,
    whereas the signals-based approach tells us the most-represented meanings being
    looked for by our users.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当试图寻找“driver”这个词的同义词时，我们可以查看文本内容中常见于同一文档中的词语。在这种情况下，我们可能会找到一些词语（按它们在文档中出现的百分比优先排序）如“taxi”（40%）、“car”（35%）、“golf”（15%）、“club”（12%）、“printer”（3%）、“linux”（3%）和“windows”（1%）。同样，我们可以查看搜索“driver”的用户发出的信号，并按优先顺序汇总他们其他搜索中的常见关键词，如“screwdriver”（50%）、“printer”（30%）、“windows”（25%）、“mac”（15%）、“golf”（2%）和“club”（2%）。从信号和内容中得出的列表可能相似，也可能非常不同。基于内容的方法告诉我们文档中最常见的意义，而基于信号的方法告诉我们用户正在寻找的最常见的意义。
- en: Since our end goal is to present users with what they are looking for, it’s
    often more effective to rely on the signals-derived meanings than the content-derived
    meanings. But what if we don’t have good content that maps to the signals-derived
    meaning? Do we use the content-derived meaning, or do we try to suggest other
    related searches based on the signals data? What if we don’t have enough signals
    or if the signals data is not very clean? Can we somehow clean up the signals-derived
    data using the content-derived data?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的最终目标是向用户提供他们所寻找的内容，因此通常更有效地依赖于从信号中得出的意义，而不是从内容中得出的意义。但如果我们没有与从信号中得出的意义相对应的良好内容呢？我们是使用从内容中得出的意义，还是尝试根据信号数据建议其他相关搜索？如果我们没有足够的信号，或者信号数据不是很干净呢？我们能否以某种方式使用从内容中得出的数据清理信号中得出的数据？
- en: We run into similar issues with recommendations. Content-based recommendations
    use attributes in documents but don’t understand users, whereas signals-based
    recommendations don’t understand content attributes and won’t work without sufficient
    interactions. Content-based recommendations may be based on features that are
    unimportant to users, whereas signals-based recommendations can create self-reinforcing
    loops where users only interact with items they are recommended, but those items
    are only recommended because users are interacting with them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在推荐方面遇到类似的问题。基于内容的推荐使用文档中的属性，但不了解用户，而基于信号的推荐不了解内容属性，没有足够的交互将无法工作。基于内容的推荐可能基于对用户不重要的特征，而基于信号的推荐可能会创建自我强化的循环，其中用户只与推荐的物品互动，而这些物品只被推荐是因为用户与它们互动。
- en: Ideally, we want to create a balanced system that can use the best of both content-derived
    and signals-derived intelligence. While this chapter focuses primarily on signals-derived,
    crowdsourced intelligence, a major goal of this book is to show you how to balance
    and combine both approaches to yield a more optimal AI-powered search experience.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望创建一个平衡的系统，能够利用从内容中得出的和从信号中得出的智能的最好部分。虽然本章主要关注基于信号的、众包的智能，但本书的一个主要目标是如何平衡和结合这两种方法，以产生更优化的AI驱动搜索体验。
- en: 4.1.2 Setting up our product and signals datasets (RetroTech)
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2 设置我们的产品和信号数据集（RetroTech）
- en: We’ll use various datasets throughout this book as we explore different use
    cases, but it is also valuable to have a consistent example that we can build
    on as we progress. We’ll benefit by having a robust search use case with lots
    of data and user interactions, and we’ll set that up in the section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索不同的用例时，本书将使用各种数据集，但拥有一个一致的示例，随着我们的进展可以在此基础上构建，也是非常宝贵的。我们将通过拥有一个具有大量数据和用户交互的强大搜索用例而受益，我们将在该部分中设置它。
- en: It’s worth noting that most techniques in this book apply across almost all
    search cases. The deciding factor for when to use a particular technique typically
    depends more on the volume and variety of content and signals than on the specific
    use case.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，本书中的大多数技术几乎适用于所有搜索案例。何时使用特定技术的决定因素通常更多地取决于内容和信号的量与种类，而不是具体的用例。
- en: 'E-commerce search provides one of the most concrete use cases for the value
    of AI-powered search techniques, and it is also one of the most well-understood
    problems among likely readers, so we’ve created an e-commerce dataset to help
    us explore this domain: the RetroTech dataset.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 电子商务搜索为AI驱动的搜索技术的价值提供了一个最具体的用例，并且它也是潜在读者中最容易理解的问题之一，因此我们创建了一个电子商务数据集，以帮助我们探索这个领域：RetroTech数据集。
- en: The RetroTech use case
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RetroTech用例
- en: With aggressive competition among retailers selling cutting-edge electronics,
    multimedia, and tech products, it is hard for a small online business to compete.
    However, a niche but emerging segment of the population chooses to avoid the latest
    and greatest products and instead falls back to the familiar technology of decades
    past. The RetroTech company was launched to meet the needs of this unique group
    of consumers, offering vintage hardware, software, and multimedia products that
    may be hard to find on today’s shelves.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在零售商之间激烈的竞争，销售尖端电子产品、多媒体和科技产品的情况下，小型在线业务很难竞争。然而，一个细分但正在兴起的群体选择避免最新的最优秀的产品，而是回归到几十年前的熟悉技术。RetroTech公司成立是为了满足这一独特消费者群体的需求，提供可能难以在当今货架上找到的复古硬件、软件和多媒体产品。
- en: Let’s load the dataset for the RetroTech company so we can get started learning
    about the relationships between documents and user signals, and about how crowdsourced
    intelligence can improve our search relevance.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载RetroTech公司的数据集，这样我们就可以开始学习文档与用户信号之间的关系，以及众包智能如何提高我们的搜索相关性。
- en: Loading the product catalog
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加载产品目录
- en: The RetroTech website has around 50,000 products available for sale, which we
    need to load into our search engine. If you built the AI-Powered Search codebase
    to run the chapter 3 examples, then your search engine is already up and running.
    Otherwise, the instructions for building and running all the book’s examples can
    be found in appendix A.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: RetroTech网站上有大约50,000种产品可供销售，我们需要将这些产品加载到我们的搜索引擎中。如果你构建了AI驱动的搜索代码库以运行第3章的示例，那么你的搜索引擎已经启动并运行。否则，构建和运行本书所有示例的说明可以在附录A中找到。
- en: With your search engine up, the next thing you need to do is download the RetroTech
    dataset that accompanies this book. The dataset includes two CSV files, one containing
    all of RetroTech’s products, and another containing one year of signals data from
    RetroTech’s users. The following listing shows a few rows of the product catalog
    dataset to get you familiar with the format.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的搜索引擎启动后，你需要做的下一件事是下载本书附带的RetroTech数据集。该数据集包括两个CSV文件，一个包含所有RetroTech的产品，另一个包含RetroTech用户一年的信号数据。以下列表展示了产品目录数据集的一些行，以便你熟悉其格式。
- en: Listing 4.1 Exploring the RetroTech product catalog
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.1 探索RetroTech产品目录
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can see that the products are identified by a UPC (Universal Product Code)
    and also have a name, a manufacturer, and both a short description (used as a
    teaser in search results) and a long description (the full description used on
    the product details pages).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，产品通过UPC（通用产品代码）进行标识，并且还有一个名称、制造商，以及一个简短描述（用作搜索结果中的预告）和一个长描述（用于产品详情页面上的完整描述）。
- en: Since we’re trying to search for products, our next step is to send them to
    the search engine to be indexed. To enable search on our RetroTech product catalog,
    let’s run the document indexing code in the following listing to send the product
    documents to the search engine.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在尝试搜索产品，我们的下一步是将它们发送到搜索引擎进行索引。为了在我们的RetroTech产品目录上启用搜索，让我们运行以下列表中的文档索引代码，将产品文档发送到搜索引擎。
- en: Listing 4.2 Send product documents to the search engine
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.2 将产品文档发送到搜索引擎
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Output:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Finally, to verify that the documents are now indexed and searchable, let’s
    run an example keyword search. The following listing shows an example search for
    `ipod`, a true classic device!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了验证文档现在已被索引并可搜索，让我们运行一个示例关键词搜索。以下列表展示了搜索`ipod`这个真正的经典设备的示例！
- en: Listing 4.3 Running a search on the product catalog
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.3 在产品目录上运行搜索
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The results of the preceding `ipod` search are shown in figure 4.1, demonstrating
    that our products are now indexed and searchable. Unfortunately, the relevance
    of the results is quite poor.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的`ipod`搜索结果如图4.1所示，表明我们的产品现在已被索引并可搜索。不幸的是，结果的相关性相当差。
- en: '![figure](../Images/CH04_F01_Grainger.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F01_Grainger.png)'
- en: Figure 4.1 Product search results. We can see that the product catalog has been
    indexed and a query for `ipod` now returns search results.
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1 产品搜索结果。我们可以看到产品目录已被索引，现在对`ipod`的查询返回了搜索结果。
- en: While the quality of the search results ranking is not yet very good, we have
    an out-of-the-box “keyword matching” search engine that we can begin improving.
    We’ll use this as our base and start introducing more intelligent AI-powered search
    features throughout the rest of the book. Our next step is to introduce our signals
    data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然搜索结果排名的质量还不是很好，但我们有一个现成的“关键词匹配”搜索引擎，我们可以开始改进它。我们将以此为基础，并在本书的其余部分介绍更多智能AI驱动的搜索功能。我们的下一步是介绍我们的信号数据。
- en: Loading the signals data
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加载信号数据
- en: Because RetroTech is running on your computer, no live users are searching,
    clicking, or otherwise generating signals. Instead, we’ve generated a dataset
    that approximates the kind of signal activity you’d expect in similar real-world
    datasets.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因为RetroTech运行在您的计算机上，没有真实用户在搜索、点击或其他方式生成信号。相反，我们生成了一个数据集，它近似于您在类似现实世界数据集中期望的信号活动类型。
- en: For simplicity, we’ll store our signals in the search engine so they can be
    accessed both in real-time search scenarios and for external processing. Running
    the following listing will simulate and index some sample signals that we can
    use throughout the rest of the chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，我们将把我们的信号存储在搜索引擎中，以便在实时搜索场景和外部处理中都可以访问。运行以下列表将模拟并索引一些样本信号，我们可以在本章的其余部分使用这些信号。
- en: Listing 4.4 Indexing the user signals dataset
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.4 索引用户信号数据集
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: With our RetroTech product and signals data all loaded, we’ll soon begin exploring
    ways we can use the signals data to enhance search relevance. Let’s first familiarize
    ourselves with the signals data so we can understand how signals are structured,
    used, and collected in real-world systems.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载了我们的RetroTech产品和信号数据后，我们将很快开始探索如何使用信号数据来增强搜索相关性。首先，让我们熟悉信号数据，以便我们了解信号在现实世界系统中是如何结构化、使用和收集的。
- en: 4.1.3 Exploring the signals data
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.3 探索信号数据
- en: Different types of signals have different attributes that need to be recorded.
    For a “query” signal, we want to record the user’s keywords. For a “click” signal,
    we want to record which document was clicked upon, as well as which query resulted
    in the click. For later analysis, we’d also want to record which documents were
    returned to and possibly viewed by a user after a query.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的信号有不同的属性需要记录。对于“查询”信号，我们希望记录用户的搜索关键词。对于“点击”信号，我们希望记录被点击的文档以及导致点击的查询。为了后续分析，我们还希望记录查询后返回并可能被用户查看的文档。
- en: To make the examples more extensible and avoid custom code for every new signal
    type, we’ve adopted a generic format for representing signals in this book. This
    format may differ from how you currently log signals, but as long as you can ultimately
    map your signals into this format, all the code in this book should work without
    requiring use-case-specific modifications.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使示例更具可扩展性并避免为每种新的信号类型编写自定义代码，我们在本书中采用了表示信号的通用格式。这个格式可能与您目前记录信号的方式不同，但只要您最终可以将您的信号映射到这个格式，本书中的所有代码都应该可以在不进行特定用例修改的情况下工作。
- en: 'The signals format we use in this book is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书中使用的信号格式如下：
- en: '`query_id`—A unique ID for the query signal that originated this signal'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_id`—产生此信号的查询信号的唯一ID'
- en: '`user`—An identifier representing a specific user of the search engine'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user`—代表搜索引擎特定用户的标识符'
- en: '`type`—What kind of signal (“query”, “click”, “purchase”, and so on)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`—信号的类型（“查询”、“点击”、“购买”等）'
- en: '`target`—The content to which the signal at this `signal_time` applies'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target`—在`signal_time`时此信号应用的 内容'
- en: '`signal_time`—The date and time the signal occurred'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`signal_time`—信号发生的时间和日期'
- en: 'As an example, assume a user performed the following sequence of actions:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设用户执行了以下一系列操作：
- en: Issued a query for `ipad` and had three documents (doc1, doc2, and doc3) returned.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询了`ipad`，并返回了三个文档（doc1、doc2和doc3）。
- en: Clicked on doc1\.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击了doc1。
- en: Went back and clicked on doc3\.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回并点击了doc3。
- en: Added doc3 to the shopping cart.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将doc3添加到购物车中。
- en: Went back and searched for `ipad` `cover` and had two documents returned (doc4
    and doc5).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回并搜索了`ipad` `cover`，并返回了两个文档（doc4和doc5）。
- en: Clicked on doc4\.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击了doc4。
- en: Added doc4 to the shopping cart.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将doc4添加到购物车中。
- en: Purchased the items in the shopping cart (doc3 and doc4).
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 购买了购物车中的商品（doc3和doc4）。
- en: These interactions would result in the signals shown in Table 4.1.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这些交互将导致表4.1中显示的信号。
- en: Table 4.1 Example signals format
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.1 示例信号格式
- en: '| query_id | user | type | target | signal_time |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| query_id | user | type | target | signal_time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | u123  | query  | ipad  | 2024-05-01-09:00:00  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | query  | ipad  | 2024-05-01-09:00:00  |'
- en: '| 1  | u123  | results  | doc1,doc2,doc3  | 2024-05-01-09:00:00  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | results  | doc1,doc2,doc3  | 2024-05-01-09:00:00  |'
- en: '| 1  | u123  | click  | doc1  | 2024-05-01-09:00:10  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | click  | doc1  | 2024-05-01-09:00:10  |'
- en: '| 1  | u123  | click  | doc3  | 2024-05-01-09:00:29  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | click  | doc3  | 2024-05-01-09:00:29  |'
- en: '| 1  | u123  | add-to-cart  | doc3  | 2024-05-01-09:03:40  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | add-to-cart  | doc3  | 2024-05-01-09:03:40  |'
- en: '| 2  | u123  | query  | ipad cover  | 2024-05-01-09:04:00  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 2  | u123  | query  | ipad cover  | 2024-05-01-09:04:00  |'
- en: '| 2  | u123  | results  | doc4,doc5  | 2024-05-01-09:04:00  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 2  | u123  | results  | doc4,doc5  | 2024-05-01-09:04:00  |'
- en: '| 2  | u123  | click  | doc4  | 2024-05-01-09:04:40  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 2  | u123  | click  | doc4  | 2024-05-01-09:04:40  |'
- en: '| 2  | u123  | add-to-cart  | doc4  | 2024-05-01-09:05:50  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 2  | u123  | add-to-cart  | doc4  | 2024-05-01-09:05:50  |'
- en: '| 1  | u123  | purchase  | doc3  | 2024-05-01-09:07:15  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 1  | u123  | purchase  | doc3  | 2024-05-01-09:07:15  |'
- en: '| 2  | u123  | purchase  | doc4  | 2024-05-01-09:07:15  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 2  | u123  | purchase  | doc4  | 2024-05-01-09:07:15  |'
- en: 'There are a few things to note about the format of the signals:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 关于信号格式的几点需要注意：
- en: '*The “query” type and the “results” type are broken into separate signals.*
    This isn’t necessary, as they occur at the same time, but this allows us to keep
    the table structure consistent and not have to add an extra results column that
    would only apply to the query signal. Also, if the user clicks the Next Page link
    or scrolls down the page and sees additional results, this structure allows us
    to create a new signal without having to go back and modify the original signal.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“查询”类型和“结果”类型被拆分为单独的信号*。这并不是必要的，因为它们同时发生，但这样做可以保持表格结构的一致性，并且不需要添加一个仅适用于查询信号的额外结果列。此外，如果用户点击下一页链接或向下滚动页面并看到更多结果，这种结构允许我们创建一个新的信号，而无需返回并修改原始信号。'
- en: '*Every signal ties back to the* `query_id` *of the original “query” signal
    that started the series of content interactions.* The `query_id` is not merely
    a reference to the keywords entered by the user but is instead a reference to
    the specific “query” signal identifying a time-stamped instance of the user’s
    query keywords. Because results for the same query keywords can change over time,
    this enables us to do more sophisticated processing of how users reacted to the
    specific set of results they were shown for a query.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*每个信号都关联回原始“查询”信号*的`query_id`，该信号启动了内容交互系列。`query_id`不仅仅是对用户输入的关键词的引用，而是对特定“查询”信号的引用，该信号标识了用户查询关键词的时间戳实例。因为针对相同查询关键词的结果可能会随时间变化，这使得我们能够更深入地处理用户对特定查询结果的反应。'
- en: '*Most signal types contain one item in the* `target`*, but the “results” signal
    type contains an ordered list of documents.* The order of results will matter
    for some algorithms we introduce later in the book, to measure relevance. It’s
    thus important to preserve the exact ordering of the search results. The `target`
    is an ordered list of documents in this case, instead of a single document.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大多数信号类型在* `target` *中只包含一个项目，但“结果”信号类型包含一个有序的文档列表*。结果的顺序对于我们在本书后面介绍的一些算法来说很重要，用于衡量相关性。因此，保留搜索结果的精确顺序是很重要的。在这种情况下，`target`是一个有序的文档列表，而不是单个文档。'
- en: '*The checkout resulted in a separate “purchase” signal for each item instead
    of just one “checkout” signal.* This is done so we can track whether each purchase
    originated from separate queries. A “checkout” signal type could additionally
    be added to track the transaction, and possibly could list the two purchases as
    the `target`, but this is superfluous for our needs in this book.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*结账产生了每个商品的单独“购买”信号，而不是只有一个“结账”信号*。这样做是为了我们可以追踪每个购买是否来自不同的查询。可以额外添加一个“结账”信号类型来跟踪交易，并且可能将两个购买列为`target`，但这对于本书中的需求来说是多余的。'
- en: With these raw signals available as our building blocks, we can now start thinking
    about how we could link the signals together to begin learning about our users
    and their interests. In the next section, we’ll discuss ways to model users, sessions,
    and requests within our search platform.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了这些原始信号作为我们的构建块之后，我们现在可以开始思考如何将这些信号链接起来，以开始了解我们的用户及其兴趣。在下一节中，我们将讨论在搜索平台内建模用户、会话和请求的方法。
- en: 4.1.4 Modeling users, sessions, and requests
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.4 用户、会话和请求的建模
- en: In the last section, we looked at the structure of user signals as a list of
    independent interactions tied back to an original query. We assumed that a “user”
    was present with a unique ID, but how does one identify and track a unique user?
    Furthermore, once you have identified how to track unique users, what is the best
    way to break their interactions up into sessions to understand when their context
    may have changed?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们研究了用户信号的结构，作为与原始查询相关联的独立交互列表。我们假设有一个“用户”存在，并且有一个唯一的ID，但如何识别和追踪一个唯一的用户？此外，一旦你确定了如何追踪唯一用户，最好的方法是将他们的交互分解成会话，以了解他们的上下文何时可能发生变化？
- en: The concept of a user in web search can be quite fluid. If your search engine
    has authenticated (logged-in) users, then you already have an internal user ID
    to track them. If your search engine supports unauthenticated access or is publicly
    available, however, you’ll have many users running searches with no formal user
    ID. That doesn’t mean you can’t track them, however; it just requires a more fluid
    interpretation of what a “user” means. A unified tracking identifier allows us
    to relate multiple signals from the same user to learn their interaction patterns.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 网络搜索中的“用户”概念可能相当灵活。如果你的搜索引擎有经过认证（登录）的用户，那么你已经有一个内部用户ID来追踪他们。如果你的搜索引擎支持未认证访问或公开可用，那么你将有许多没有正式用户ID的用户在运行搜索。但这并不意味着你不能追踪他们；只是需要更灵活地解释“用户”的含义。一个统一的追踪标识符使我们能够将来自同一用户的多个信号联系起来，以了解他们的交互模式。
- en: 'If we think of the trackable information as a hierarchy from the most durable
    representation of a user to the least, it will look something like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们认为可追踪的信息是一个从用户最持久的表示到最不持久的表示的层次结构，它看起来可能像这样：
- en: '*User ID*—A unique user ID that persists across devices (authenticated)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户ID*—一个在所有设备上持续存在的唯一用户ID（经过认证）'
- en: '*Device ID*—A unique ID that persists across sessions on the same device (such
    as a device ID or an IP address plus a device fingerprint)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设备ID*—一个在相同设备上的会话中持续存在的唯一ID（例如设备ID或IP地址加上设备指纹）'
- en: '*Browser ID*—A unique ID that persists across sessions in the same application
    or browser only (a persistent cookie ID)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*浏览器ID*—一个只在相同应用或浏览器会话中持续存在的唯一ID（持久cookie ID）'
- en: '*Session ID*—A unique ID that persists across a single session (such as a cookie
    in a browser’s incognito mode)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*会话ID*—一个在单个会话中持续存在的唯一ID（例如浏览器隐身模式中的cookie）'
- en: '*Request ID*—A unique ID that only persists for a single request (a browser
    with cookies turned off)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*请求ID*—一个只在单个请求中持续存在的唯一ID（关闭了cookies的浏览器）'
- en: In most modern search applications, and certainly in most e-commerce applications,
    we typically need to deal with all of these. As a rule of thumb, you want to tie
    a user to the most durable identifier—the one as high up the list as possible.
    Both the links between request IDs and session IDs, as well as the links between
    session IDs and browser IDs, are through the user’s cookie, so ultimately the
    browser ID (persistent unique ID stored in the cookie) is the common denominator
    for each of these.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数现代搜索应用中，尤其是在大多数电子商务应用中，我们通常需要处理所有这些。作为一个经验法则，你希望将用户与最持久的标识符联系起来——尽可能高的列表中的那个。请求ID和会话ID之间的链接，以及会话ID和浏览器ID之间的链接，都是通过用户的cookie实现的，所以最终浏览器ID（存储在cookie中的持久唯一ID）是这些中的共同分母。
- en: Specifically,
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，
- en: If a user has persistent cookies enabled, one browser ID can have many session
    IDs, which can have many request IDs.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户启用了持久cookies，一个浏览器ID可以有多个会话ID，这些会话ID可以有多个请求ID。
- en: If a user clears cookies after each session (such as by using incognito mode),
    each browser ID has only one session ID, which can have many request IDs.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户在每次会话后清除cookies（例如使用隐身模式），则每个浏览器ID只有一个会话ID，这个会话ID可以有许多请求ID。
- en: If a user turns off cookies, then each request ID has a new session ID and a
    new browser ID.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户关闭了cookies，那么每个请求ID都有一个新的会话ID和一个新的浏览器ID。
- en: When building search platforms, most organizations do not properly plan for
    and design their signals-tracking mechanisms. If they’re not able to correlate
    visitors’ queries with subsequent actions, it becomes difficult to maximize the
    capabilities of their AI-powered search platform. In some cases, it’s possible
    to derive missing signals-tracking information after the fact (such as by modeling
    signals into likely sessions using timestamps), but it’s usually best to design
    the system upfront to better handle user tracking to prevent potential information
    loss. In the next section, we’ll discuss how these rich signals can be used to
    improve relevance through a process known as “reflected intelligence”.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建搜索平台时，大多数组织没有正确规划和设计它们的信号跟踪机制。如果它们无法将访客的查询与随后的行动相关联，那么最大化其人工智能搜索平台的能力就会变得困难。在某些情况下，可以在事后推导出缺失的信号跟踪信息（例如，通过使用时间戳将信号建模到可能的会话中），但通常最好在设计系统时提前考虑，以更好地处理用户跟踪，防止潜在的信息丢失。在下一节中，我们将讨论如何通过称为“反射智能”的过程使用这些丰富的信号来提高相关性。
- en: 4.2 Introducing reflected intelligence
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 介绍反射智能
- en: In the last section, we covered how to capture signals from users as they interact
    with our search engine. While the signals themselves are useful to help us understand
    how our search engine is being used, they also serve as the primary inputs for
    building models that can continually learn from user interactions and enable our
    search engine to self-tune its relevance model. In this section, we’ll introduce
    how these self-tuning models work through the concept of reflected intelligence.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了如何捕捉用户与我们搜索引擎交互时的信号。虽然这些信号本身有助于我们了解我们的搜索引擎是如何被使用的，但它们也作为构建模型的输入，这些模型可以从用户交互中不断学习，并使我们的搜索引擎能够自我调整其相关性模型。在本节中，我们将通过反射智能的概念介绍这些自我调整模型的工作原理。
- en: 4.2.1 What is reflected intelligence?
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 什么是反射智能？
- en: Imagine you are an employee at a hardware store. Someone asks you where they
    can find a hammer, and you tell them “aisle two”. A few minutes later you see
    the same person walk from aisle two to aisle five without a hammer, and then they
    walk out of aisle five holding a hammer. The next day someone else asks for a
    hammer, you again tell them “aisle two”, and you observe a nearly identical pattern
    of behavior. You would be a lousy employee if you didn’t spot this pattern and
    adjust your advice going forward to provide a better experience for your customers.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你是一家五金店的员工。有人问你他们可以在哪里找到一把锤子，你告诉他们“第二通道”。几分钟后，你看到同一个人从第二通道走到第五通道，但没有拿锤子，然后他们从第五通道拿着锤子走了出来。第二天，另一个人要求一把锤子，你又告诉他们“第二通道”，并且你观察到几乎相同的模式。如果你没有注意到这个模式并调整你的建议，以提供更好的客户体验，你将是一个糟糕的员工。
- en: Unfortunately, most search engines function in this manner by default—they have
    a largely static set of documents that are returned for each query, regardless
    of who each user is or how prior users have reacted to the list of documents shown.
    By applying machine learning to the collected signals, however, we can learn about
    users’ intent and reflect that knowledge to improve future search results. This
    process is called *reflected intelligence*.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数搜索引擎默认以这种方式运行——它们为每个查询返回大量静态的文档集，无论每个用户是谁或先前用户如何对显示的文档列表做出反应。然而，通过将机器学习应用于收集到的信号，我们可以了解用户的意图，并将这些知识反映出来以改善未来的搜索结果。这个过程被称为*反射智能*。
- en: Reflected intelligence is all about creating feedback loops that constantly
    learn and improve based on evolving user interactions. Figure 4.2 demonstrates
    a high-level overview of a reflected intelligence process.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 反射智能的核心是创建反馈循环，这些循环不断学习并基于不断发展的用户交互进行改进。图4.2展示了反射智能过程的高级概述。
- en: '![figure](../Images/CH04_F02_Grainger.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F02_Grainger.png)'
- en: Figure 4.2 The reflected intelligence process. A user issues a query, sees results,
    and takes a set of actions. Those actions (signals) are then processed to create
    learned relevance models that improve future searches.
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.2 反射智能过程。用户提出查询，查看结果，并采取一系列行动。然后对这些行动（信号）进行处理，以创建学习相关性模型，从而改善未来的搜索。
- en: 'In figure 4.2., a user (Alonzo) runs a search, entering the query `ipad` in
    the search box. A query signal is logged, containing the list of all search results
    displayed to Alonzo. Alonzo then sees the list of search results and takes two
    actions: clicking on a document (doc22) and then purchasing the product that document
    represents. Those two additional actions are logged as additional signals. All
    Alonzo’s signals, along with the signals from every other user, can then be aggregated
    and processed by various machine learning algorithms to create learned relevance
    models.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 4.2 中，用户（Alonzo）运行了一个搜索，在搜索框中输入查询 `ipad`。记录了一个查询信号，其中包含显示给 Alonzo 的所有搜索结果列表。Alonzo
    然后看到搜索结果列表并采取两个行动：点击一个文档（doc22）然后购买该文档所代表的商品。这两个额外的行动被记录为额外的信号。Alonzo 的所有信号以及来自每个其他用户的信号，然后可以被各种机器学习算法聚合和处理，以创建学习相关性模型。
- en: These learned relevance models may boost the most popular results for specific
    queries, personalize results for each user, or even learn which document attributes
    are generally most important across all users. The models could also learn how
    to better interpret user queries, such as identifying common misspellings, phrases,
    synonyms, or other linguistic patterns and domain-specific terminology.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些学习相关性模型可能会提高特定查询的最受欢迎的结果，为每个用户个性化结果，甚至学习在所有用户中通常最重要的文档属性。这些模型还可以学习如何更好地解释用户查询，例如识别常见的拼写错误、短语、同义词或其他语言模式和特定领域的术语。
- en: Once these learned relevance models are generated, they can then be deployed
    back into the production search engine and immediately applied to enhance the
    outcomes of future queries. The process then begins again, with the next user
    running a search, seeing (now hopefully improved) search results, and interacting
    with those results. This process creates a self-learning system that improves
    with every additional user interaction, getting continually smarter and more relevant
    over time and automatically adjusting as user interests and content evolve.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成这些学习相关性模型，它们就可以部署回生产搜索引擎，并立即应用于增强未来查询的结果。然后，这个过程再次开始，下一个用户运行搜索，看到（现在希望是改进的）搜索结果，并与这些结果进行交互。这个过程创建了一个自我学习系统，随着每个额外用户交互的进行而不断改进，随着时间的推移变得越来越智能和相关性更强，并自动调整以适应用户兴趣和内容的演变。
- en: 'In the following sections, we’ll explore a few categories of reflected intelligence
    models, including signals boosting (popularized relevance), collaborative filtering
    (personalized relevance), and learning to rank (generalized relevance). We’ll
    start with one of the simplest and most effective: signals-boosting models.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将探讨几种反射智能模型类别，包括信号增强（流行相关性）、协同过滤（个性化相关性）和排序学习（泛化相关性）。我们将从最简单且最有效的一种开始：信号增强模型。
- en: 4.2.2 Popularized relevance through signals boosting
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 通过信号增强实现流行相关性
- en: The most popular queries sent to your search engine tend to also be the most
    important ones to optimize from a relevance standpoint. Thankfully, since more
    popular queries generate more signals, we can often aggregate and boost the relevance
    of documents with the highest number of signals for each query. This kind of *popularized
    relevance* is known as *signals boosting*. It is one of the simplest forms of
    reflected intelligence and also one of the most effective for improving the relevance
    of your most popular, highest-volume queries. The following listing demonstrates
    an out-of-the-box search with the query `ipad` in our RetroTech search engine,
    prior to any signals boosting being applied.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 发送到您搜索引擎的最受欢迎的查询通常也是从相关性角度优化最重要的查询。幸运的是，由于更受欢迎的查询会产生更多信号，我们通常可以聚合并提高每个查询中具有最高信号数量文档的相关性。这种被称为
    *信号增强* 的 *流行相关性* 是最简单形式的反射智能之一，也是提高您最受欢迎、最高流量查询相关性的最有效方法之一。以下列表展示了在我们的 RetroTech
    搜索引擎中应用任何信号增强之前，使用查询 `ipad` 的即插即用搜索。
- en: Listing 4.5 Executing a keyword search for products matching `ipad`
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.5 执行针对匹配 `ipad` 的产品的关键词搜索
- en: '[PRE5]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As expected, this query returns many documents containing the keyword `ipad`,
    with the documents containing `ipad` typically ranking highest. Figure 4.3 shows
    the results for this query.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，这个查询返回了许多包含关键词 `ipad` 的文档，通常包含 `ipad` 的文档排名最高。图 4.3 显示了此查询的结果。
- en: '![figure](../Images/CH04_F03_Grainger.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F03_Grainger.png)'
- en: Figure 4.3 Results of a keyword search for the query `ipad`. Results are returned
    primarily based on the number of occurrences of the keyword, so accessories mentioning
    the keyword multiple times rank higher than the actual product the user intended
    to see.
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.3 查询“ipad”的关键词搜索结果。结果主要基于关键词出现的次数返回，因此提及关键词多次的配件比用户意图看到的实际产品排名更高。
- en: While these results all contain the word “ipad” in their content multiple times,
    most users would be disappointed with these results, since they are secondary
    accessories as opposed to the main product type that was the focus of the search.
    This is a significant limitation when ranking just by document text. For very
    popular queries, however, it’s likely that many customers will run the same queries
    repeatedly and fight through the frustrating search results to find the actual
    products they are seeking. We can tie these repeated searches into a feedback
    loop that continuously updates a signals-boosting model based on new signals,
    as shown in figure 4.4.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些结果的内容中都多次包含“ipad”这个词，但大多数用户会对这些结果感到失望，因为它们是次要配件，而不是搜索焦点的主要产品类型。仅根据文档文本进行排名时，这是一个重大的限制。然而，对于非常流行的查询，许多客户可能会反复运行相同的查询，并忍受令人沮丧的搜索结果，以找到他们真正寻求的实际产品。我们可以将这些重复的搜索与一个反馈循环联系起来，该循环基于新的信号持续更新信号增强模型，如图
    4.4 所示。
- en: '![figure](../Images/CH04_F04_Grainger.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F04_Grainger.png)'
- en: Figure 4.4 Signals-boosting feedback loop. A user’s search is logged, and the
    current signals-boosting model is applied to return the boosted results. After
    users take action on those results, all user interaction signals with documents
    are aggregated by the originating query to generate an updated model to further
    improve future searches.
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.4 信号增强反馈循环。用户的搜索被记录下来，并将当前的信号增强模型应用于返回增强后的结果。用户对这些结果采取行动后，所有与文档的用户交互信号都会由原始查询聚合，以生成一个更新的模型，以进一步改进未来的搜索。
- en: Once your products are indexed and you’ve started collecting signals for your
    users’ queries and document interactions, the only additional steps necessary
    for implementing signals boosting are to aggregate your signals and then add your
    aggregated signals as boosts to either your queries or your documents. Listing
    4.6 demonstrates a simple model for aggregating signals into a sidecar collection.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的产品被索引并且您已经开始收集用户查询和文档交互的信号，实施信号增强所需的额外步骤仅包括聚合您的信号，然后将您的聚合信号作为增强添加到您的查询或文档中。列表
    4.6 展示了将信号聚合到辅助集合的简单模型。
- en: Sidecar collections
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 辅助集合
- en: Sidecar collections are additional collections that sit in your search engine
    alongside a primary collection and that contain other useful data to improve your
    search application. In our e-commerce example, our primary collection is `products`.
    Our `signals` collection, which has already been added, can be considered a sidecar
    collection. We’ll add another sidecar collection, `signals_boosting`, which we’ll
    use at query time to enhance our queries. Throughout the book, we’ll introduce
    many other sidecar collections to store the inputs for and outputs of our generated
    models.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助集合是位于您的搜索引擎中与主集合并排的额外集合，其中包含其他有助于改进您的搜索应用的有用数据。在我们的电子商务示例中，我们的主集合是“products”。我们已添加的“signals”集合可以被视为辅助集合。我们将添加另一个辅助集合“signals_boosting”，我们将在查询时使用它来增强我们的查询。在本书中，我们将介绍许多其他辅助集合来存储我们生成的模型的输入和输出。
- en: Listing 4.6 Creating a signals-boosting model by aggregating signals
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.6 通过聚合信号创建信号增强模型
- en: '[PRE6]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Creates a view to make the signals collection queryable with SQL'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建一个视图，使信号集合可使用 SQL 查询'
- en: '#2 Counts total clicks for each document for each keyword'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 为每个关键词统计每个文档的总点击量'
- en: '#3 Executes the signals aggregation SQL query'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 执行信号聚合 SQL 查询'
- en: '#4 Writes the results to a new signals_boosting collection'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将结果写入新的 signals_boosting 集合'
- en: The most important part of listing 4.6 is the `signals_aggregation_query`, defined
    as a SQL query for readability. For every query, we will get the list of documents
    that users have clicked on in the search results for that query, along with a
    count of how many times the document has been clicked on. By ordering the documents
    by the click count for each query, we get an ordered list of the documents ranked
    by popularity.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.6最重要的部分是`signals_aggregation_query`，它被定义为可读性的SQL查询。对于每个查询，我们将获取用户在搜索结果中点击过的文档列表，以及文档被点击的次数。通过按每个查询的点击次数对文档进行排序，我们得到一个按流行度排序的文档列表。
- en: The idea here is that users tend to choose the products they believe are the
    most relevant, so if we were to boost these documents, we would expect our top
    search results to become more relevant. We’ll test this theory in the next listing
    by using these aggregated counts as signals boosts. Let’s revisit our previous
    query for `ipad`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的想法是，用户倾向于选择他们认为最相关的产品，因此如果我们提升这些文档，我们预计我们的顶级搜索结果将变得更加相关。我们将在下一个列表中通过使用这些聚合计数作为信号提升来测试这个理论。让我们回顾一下之前的`ipad`查询。
- en: Listing 4.7 Searching with signals boosting to improve relevance
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表4.7 使用信号提升来提高相关性的搜索
- en: '[PRE7]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Boost documents:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 提升文档：
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Boost query:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 提升查询：
- en: '[PRE9]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The query in listing 4.7 does two noteworthy things:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.7中的查询做了两件值得注意的事情：
- en: It queries the `signals_boosting` sidecar collection for ranked documents by
    boost and transforms those signals boosts into another query.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它查询`signals_boosting`辅助集合中按提升排序的文档，并将这些信号提升转换为另一个查询。
- en: It then passes that boosting query to the search engine as a query-time boost
    in the `query_boosts` parameter. In the case of Solr (our default search engine),
    this translates internally to a `boost` parameter of `sum(1,query($boost_query))`
    being added to the search request to multiply the relevance score by `1` (so it
    always increases) plus the calculated relevance score of the `boost_query`. (See
    section 3.2 if you want a refresher on influencing ranking like this through functions
    and multiplicative boosts.)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，它将这个提升查询作为查询时间的提升传递给搜索引擎，作为`query_boosts`参数。在Solr（我们的默认搜索引擎）的情况下，这内部转换为在搜索请求中添加一个`boost`参数`sum(1,query($boost_query))`，将相关性分数乘以`1`（因此总是增加）加上`boost_query`计算出的相关性分数。（如果你想要复习如何通过函数和乘法提升来影响排名，请参阅第3.2节。）
- en: If you remember from figure 4.3, our original keyword search for `ipad` returned
    mostly iPad accessories, as opposed to actual iPad devices. Figure 4.5 demonstrates
    the improved results after signals boosting is applied to that original query.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得图4.3，我们原始的`ipad`关键字搜索主要返回了iPad配件，而不是实际的iPad设备。图4.5展示了在原始查询上应用信号提升后的改进结果。
- en: '![figure](../Images/CH04_F05_Grainger.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F05_Grainger.png)'
- en: Figure 4.5 Search results with signals boosting enabled. Instead of iPad accessories
    showing up as before, we now see actual iPads, because we have crowdsourced the
    answers based on the documents that users choose to interact with.
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.5展示了启用信号提升的搜索结果。与之前只显示iPad配件不同，我们现在看到了实际的iPad，因为我们基于用户选择的互动文档进行了众包。
- en: The new results are significantly better than the keyword-only results. We now
    see products that the user was more likely looking for—iPads! You can expect to
    see similar improvements for most other popular queries in your search engine.
    Of course, as we move further down the list of popular products, the relevance
    improvements from signals boosting will start to decline, and with insufficient
    signals we may even reduce relevance. Thankfully, we’ll introduce many other techniques
    to improve relevance for queries with inadequate signals volume.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 新的结果比仅关键字的结果要好得多。我们现在看到了用户更有可能寻找的产品——iPad！你可以期待在你的搜索引擎中，大多数其他流行查询也会看到类似的改进。当然，当我们向下移动到流行产品列表时，信号提升的相关性改进将开始下降，并且由于信号不足，我们甚至可能会降低相关性。幸运的是，我们将介绍许多其他技术来提高信号量不足的查询的相关性。
- en: The goal of this section was to walk you through an initial, concrete example
    of implementing an end-to-end reflected intelligence model. The signals aggregation
    used in this implementation was very simple, though the results speak for themselves.
    There are many considerations and nuances to consider when implementing a signals-boosting
    model—whether to boost at query time or index time, how to increase the weight
    of newer signals versus older signals, how to avoid malicious users trying to
    boost particular products in the search results by generating bogus signals, how
    to introduce and blend signals from different sources, and so on. We’ll cover
    each of these topics in detail in chapter 8.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是向您展示实现端到端反射智能模型的初始、具体示例。在这个实现中使用的信号聚合非常简单，尽管结果不言自明。在实现信号增强模型时有许多考虑和细微差别——是在查询时间还是索引时间增强，如何增加新信号与旧信号之间的权重，如何避免恶意用户通过生成虚假信号试图在搜索结果中提升特定产品，如何引入和融合来自不同来源的信号，等等。我们将在第8章中详细讨论这些主题。
- en: Let’s move on from popularized relevance and signals boosting for now and discuss
    a few other types of reflected intelligence models.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时放下流行的相关性提升和信号增强，讨论几种其他类型的反射智能模型。
- en: 4.2.3 Personalized relevance through collaborative filtering
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3 通过协同过滤实现个性化相关性
- en: Let’s now look at a reflected intelligence approach called collaborative filtering,
    which we’ll categorize as *personalized relevance*. Whereas popularized relevance
    determines which results are usually the most popular across many users, personalized
    relevance focuses on determining which items are most likely to be relevant for
    a specific user.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一种称为协同过滤的反射智能方法，我们将它归类为*个性化相关性*。而流行的相关性确定通常在许多用户中哪些结果最受欢迎，个性化相关性则专注于确定哪些项目最有可能对特定用户相关。
- en: '*Collaborative filtering* is the process of using observations about the preferences
    of some users to predict the preferences of other users. It is the most popular
    type of algorithm used by recommendation engines, and it is the source of the
    common “users who liked this item also liked these items” recommendation lists
    that appear on many websites. Figure 4.6 demonstrates how collaborative filtering
    follows this same reflected intelligence feedback loop that we saw for signals-boosting
    models.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*协同过滤*是使用关于某些用户偏好的观察来预测其他用户偏好的过程。它是推荐引擎中最受欢迎的算法类型，也是许多网站上常见的“喜欢这个项目的用户还喜欢这些项目”推荐列表的来源。图4.6展示了协同过滤如何遵循我们之前看到的信号增强模型的相同反射智能反馈循环。'
- en: '![figure](../Images/CH04_F06_Grainger.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F06_Grainger.png)'
- en: Figure 4.6 Collaborative filtering for user-to-item recommendations. Based upon
    his past behavior, our user (Alonzo) receives recommendations based on items other
    users liked, where those users also interacted with some of the same items as
    Alonzo.
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.6 用户到项目推荐的协同过滤。根据他的过去行为，我们的用户（Alonzo）接收到基于其他用户喜欢的项目的推荐，其中这些用户也与其他一些项目与Alonzo进行了交互。
- en: Like signals boosting, collaborative filtering involves a continuous feedback
    loop. Signals are collected, models are built by those signals, recommendations
    are generated by those models, and interactions against those recommendations
    are then logged again as additional signals. Collaborative filtering approaches
    typically generate a user-item interaction matrix, mapping each user to each item
    (document), with the relationship strength between each user and item being based
    on the strength of the positive interactions (clicks, purchases, ratings, and
    so on).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与信号增强类似，协同过滤涉及一个连续的反馈循环。收集信号，通过这些信号构建模型，由这些模型生成推荐，然后记录与这些推荐的交互作为额外的信号。协同过滤方法通常生成一个用户-项目交互矩阵，将每个用户映射到每个项目（文档），每个用户和项目之间的关系强度基于积极的交互强度（点击、购买、评分等）。
- en: If the interaction matrix is sufficiently populated, it’s possible to infer
    recommendations from it for any user or item with interaction data. This is done
    by directly looking up the other users who interacted with the same item and then
    boosting other items (similar to signals boosting) that those users also interacted
    with. If the user-item interaction matrix is too sparse, however, a matrix factorization
    approach will typically need to be applied.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果交互矩阵足够丰富，就可以从中推断出任何具有交互数据的用户或项目的推荐。这是通过直接查找与同一项目交互的其他用户，然后增强那些用户也交互的其他项目（类似于信号增强）来实现的。然而，如果用户-项目交互矩阵过于稀疏，通常需要应用矩阵分解方法。
- en: '*Matrix factorization* is the process of breaking the user-item interaction
    matrix into two matrices: one mapping users to latent features (or *factors*),
    and another mapping those latent factors to items. This is similar to the dimensionality
    reduction approach we described in chapter 3, where we switched from representing
    food items with many exact keywords (a vector including a feature for every word
    in the inverted index) to using a much smaller number of meaningful dimensions
    (a vector with eight features describing the food items) that we compressed the
    data into. This matrix factorization makes it possible to derive user preferences
    for items, as well as the similarity between items, by distilling limited signals
    data into a smaller number of more meaningful dimensions that better generalize
    the similarity between items.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*矩阵分解*是将用户-项目交互矩阵分解成两个矩阵的过程：一个将用户映射到潜在特征（或*因素*），另一个将那些潜在因素映射到项目。这与我们在第3章中描述的降维方法类似，我们当时从使用包含倒排索引中每个单词特征的大多数精确关键词（一个包括倒排索引中每个单词特征的向量）来表示食品项目，转变为使用更少的具有意义的维度（一个包含八个特征描述食品项目的向量）来压缩数据。这种矩阵分解使得通过将有限的信号数据提炼成更少的、更有意义的维度，从而更好地泛化项目之间的相似性，从而能够推导出用户对项目的偏好以及项目之间的相似性。'
- en: In the context of matrix factorization for collaborative filtering, the latent
    factors represent attributes of our documents that are learned to be important
    indicators of shared interests across users. By matching other documents based
    on these factors, we are using crowdsourcing to find other similar documents matching
    the same shared interests.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在协同过滤的矩阵分解背景下，潜在因素代表了我们文档的属性，这些属性被学习为用户之间共享兴趣的重要指标。通过根据这些因素匹配其他文档，我们正在使用众包来找到其他具有相同共享兴趣的相似文档。
- en: As powerful as collaborative filtering can be for learning user interests and
    tastes based entirely on crowdsourced relevance, it suffers from a major flaw
    known as the *cold start problem*. This is a scenario where the returning of results
    is dependent upon the existence of signals, but where new documents that have
    never generated signals will not be returned. This creates a catch-22 situation
    where new content is unlikely to be shown to users (a prerequisite for generating
    signals) because it has not yet generated any signals (which are required for
    the content to be shown). To some degree, signals-boosting models demonstrate
    a similar problem, where documents that are already popular tend to receive a
    higher boost, resulting in them getting even more signals, while unseen documents
    continue to not receive signals boosting. This process creates a self-reinforcing
    cycle that can lead to a lack of diversity in search results. This problem is
    called *presentation bias*, and we’ll show how to overcome it in chapter 12\.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管协同过滤在基于众包相关性学习用户兴趣和品味方面可能非常强大，但它存在一个被称为*冷启动问题*的主要缺陷。这是一个结果返回依赖于信号存在的情况，但新文档由于从未生成信号而不会被返回。这创造了一个恶性循环，新内容不太可能被展示给用户（生成信号的前提），因为它尚未生成任何信号（这是内容被展示所必需的）。在一定程度上，信号增强模型也表现出类似的问题，即已经流行的文档往往会获得更高的提升，从而获得更多的信号，而未知的文档则继续没有信号增强。这个过程创造了一个自我强化的循环，可能导致搜索结果缺乏多样性。这个问题被称为*展示偏差*，我们将在第12章中展示如何克服它。
- en: You can also generate recommendations in other ways, such as through content-based
    recommendations, which we’ll explore in the next chapter (section 5.4.6). Collaborative
    filtering is unique, however, in that it can learn the preferences and tastes
    of users for other documents without having to know anything about the content
    of the documents. This is because all decisions are made entirely by observing
    the interactions of users with content and determining the strength of the similarity
    based on those observations. We’ll take a deeper dive into collaborative filtering
    when implementing personalized search in chapter 9.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过其他方式生成推荐，例如通过基于内容的推荐，我们将在下一章（5.4.6节）中探讨。然而，协同过滤是独特的，因为它可以在不知道任何关于文档内容的情况下，学习用户对其他文档的偏好和口味。这是因为所有决策都是通过观察用户与内容的互动，并根据这些观察确定相似性的强度来做出的。我们将在第9章实现个性化搜索时，更深入地探讨协同过滤。
- en: Instead of only utilizing popularized and personalized relevance models (which
    function best when documents already have signals), a search engine can also benefit
    from a more generalized relevance model that can apply to all searches and documents.
    This goes a long way toward solving the cold-start problem. We’ll next explore
    how crowdsourced relevance can be generalized through a technique called “learning
    to rank”.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 除了仅利用流行和个性化相关性模型（在文档已经具有信号时表现最佳）之外，搜索引擎还可以从一种更广义的相关性模型中受益，该模型可以应用于所有搜索和文档。这有助于解决冷启动问题。接下来，我们将探讨如何通过称为“学习排序”的技术将众包相关性进行推广。
- en: 4.2.4 Generalized relevance through learning to rank
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.4 通过学习排序实现广义相关性
- en: Because signals boosting (popularized relevance, section 4.2.2) and collaborative
    filtering (personalized relevance, section 4.2.3) only work on documents that
    already have signals, a substantial proportion of queries won’t benefit until
    documents receive traffic. This is where learning to rank proves valuable as a
    form of generalized relevance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 由于信号增强（流行相关性，4.2.2节）和协同过滤（个性化相关性，4.2.3节）仅适用于已经具有信号的文档，因此在文档获得流量之前，大量查询不会受益。这就是学习排序作为一种广义相关性的形式证明有价值的地方。
- en: '*Learning to rank* (LTR), also known as *machine-learned ranking*, is the process
    of building and using a ranking classifier that can score how well any document
    matches any arbitrary query. You can think of the ranking classifier as a trained
    relevance model. Instead of manually tuning search boosts and other parameters,
    the LTR process trains a machine learning model that can understand the important
    features of your documents and then score search results appropriately. Figure
    4.7 shows the general flow for rolling out LTR.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习排序*（LTR），也称为*机器学习排序*，是构建和使用一种排序分类器的过程，该分类器可以评估任何文档与任何任意查询的匹配程度。你可以将排序分类器视为一个训练好的相关性模型。而不是手动调整搜索增强和其他参数，LTR过程训练了一个机器学习模型，该模型可以理解你文档的重要特征，然后适当地评分搜索结果。图4.7展示了推出LTR的一般流程。'
- en: '![figure](../Images/CH04_F07_Grainger.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F07_Grainger.png)'
- en: Figure 4.7 Learning to rank (generalized relevance). A ranking classifier is
    built from user judgments about the known relevance of documents for each query
    (training set). That ranking classifier model is then used to rerank search results
    so that the top-ranked documents are more relevant.
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.7 学习排序（广义相关性）。排序分类器是根据用户对每个查询（训练集）中已知文档相关性的判断构建的。然后使用该排序分类器模型重新排序搜索结果，以便排名靠前的文档更具相关性。
- en: In an LTR system, the same high-level reflected intelligence process applies
    as in signals boosting and collaborative filtering (refer to figure 4.2). The
    difference is that LTR can use relevance judgment lists (maps of queries to their
    ideal ranked set of documents) to automatically train a relevance model that can
    then be applied generally to all queries. You’ll see that the output of the “Build
    ranking classifier” step in figure 4.7 is a model of relevance features (`title_match_any_terms`,
    `is_known_category`, `popularity`, and `content_age`), and that model is deployed
    into the production search engine periodically to enhance search results ranking.
    The features in a very simple machine-learned ranking model might be readable
    like this, but there is no requirement that a ranking classifier be interpretable
    or explainable, and many advanced, deep-learning-based ranking classifiers are
    not.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在LTR系统中，与信号增强和协同过滤中相同的高级反射智能过程适用（参见图4.2）。区别在于LTR可以使用相关性判断列表（查询到其理想排名文档集的映射）来自动训练一个相关性模型，然后可以将其普遍应用于所有查询。您将看到图4.7中“构建排名分类器”步骤的输出是一个相关性特征模型（`title_match_any_terms`、`is_known_category`、`popularity`和`content_age`），并且该模型定期部署到生产搜索引擎中以提高搜索结果排名。一个非常简单的机器学习排名模型的特征可能看起来像这样，但并没有要求排名分类器必须是可解释或可解释的，而且许多基于深度学习的先进排名分类器都不是。
- en: In figure 4.7, notice that the live user flow starts with a query for `ipad`.
    The initial search results are then run through the deployed learning-to-rank
    classifier, which returns the final reranked set of search results. Since the
    ranking classifier is typically much more intelligent and uses more complicated
    ranking parameters than a traditional keyword-ranking relevance model, it is usually
    way too slow to use the ranking classifier to score all the matching documents
    in the search engine. Instead, LTR will often use an initial, faster ranking function
    (such as BM25) to find the top-N documents (usually hundreds or thousands of documents)
    and then only run that subset of documents through the ranking classifier. It
    is possible to use the ranking classifier as the main relevance function instead
    of applying this reranking technique, but it’s more common to see a reranking
    approach, as it’s typically much faster while still yielding approximately the
    same results.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在图4.7中，请注意，实时用户流从对`ipad`的查询开始。然后，初始搜索结果通过部署的排序学习分类器运行，该分类器返回最终的重新排序搜索结果集。由于排名分类器通常比传统的基于关键词的排名相关性模型更智能，并且使用更复杂的排名参数，因此通常使用排名分类器对搜索引擎中所有匹配的文档进行评分会非常慢。相反，LTR通常会使用一个初始的、更快的排名函数（如BM25）来找到前N个文档（通常是数百或数千个文档），然后只将这部分文档通过排名分类器。虽然可以使用排名分类器作为主要的相关性函数而不是应用这种重新排序技术，但更常见的是看到重新排序的方法，因为它通常要快得多，同时仍然产生大约相同的结果。
- en: LTR can use either explicit relevance judgments (created manually by experts)
    or implicit judgments (derived from user signals), or some combination of the
    two. We’ll cover examples of implementing LTR from both explicit and implicit
    judgment lists in chapters 10–12\.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: LTR可以使用显式相关性判断（由专家手动创建）或隐式判断（从用户信号中提取），或者两者的组合。我们将在第10章至第12章中介绍从显式和隐式判断列表实现LTR的示例。
- en: 4.2.5 Other reflected intelligence models
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.5 其他反射智能模型
- en: In addition to diving deeper into signals boosting (chapter 8), collaborative
    filtering (chapter 9), and learning to rank (chapter 10), we’ll explore many other
    kinds of reflected intelligence throughout this book. In chapter 6, we’ll explore
    mining user queries to automatically learn domain-specific phrases, common misspellings,
    synonyms, and related terms, and in chapters 11–12 we’ll explore automated ways
    of learning relevance judgments from users’ interactions so we can automatically
    generate training data for interesting machine learning approaches.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 除了深入探讨信号增强（第8章）、协同过滤（第9章）和排序学习（第10章）之外，我们将在本书中探索许多其他类型的反射智能。在第6章中，我们将探讨挖掘用户查询以自动学习特定领域的短语、常见拼写错误、同义词和相关术语，而在第11章至第12章中，我们将探讨从用户交互中自动学习相关性判断的自动化方法，以便我们可以自动生成用于有趣机器学习方法的训练数据。
- en: In general, every interaction between a user and content creates a connection—an
    edge in a graph—that we can use to understand emerging relationships and derive
    deeper insights. Figure 4.8 demonstrates some of the various relationships we
    can learn by exploring this interaction graph. The same incoming signals data
    can be processed differently, through various signals aggregation and machine
    learning approaches, to learn
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，用户与内容之间的每一次交互都会创建一个连接——图中的一个边——我们可以用它来理解新兴关系并得出更深入的见解。图4.8展示了通过探索这个交互图我们可以学习到的各种关系。相同的传入信号数据可以通过不同的信号聚合和机器学习方法进行处理，以学习
- en: The similarity between users and items (user-item recommendations)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户与项目之间的相似性（用户-项目推荐）
- en: The similarity between items and other items (item-item recommendations)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目与项目之间的相似性（项目-项目推荐）
- en: Specific attribute-based preferences that can generate a profile of a user’s
    interests
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以生成用户兴趣概要的特定属性偏好
- en: The similarity between queries and items
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询与项目之间的相似性
- en: '![figure](../Images/CH04_F08_Grainger.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F08_Grainger.png)'
- en: Figure 4.8 Many reflected intelligence models. The leftmost box represents user-to-item
    similarity for recommendations, the next shows learning specific attribute-based
    preferences for a user’s profile, the third shows learning item-to-item–based
    similarity for recommendations, and the rightmost shows learning query-to-item
    recommendations.
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.8 多种反射智能模型。最左边的框表示推荐中的用户到项目的相似性，接下来显示的是根据用户个人资料学习特定属性偏好，第三个显示的是根据推荐学习项目到项目的相似性，最右边显示的是学习查询到项目的推荐。
- en: We’ll continue to explore these techniques in the chapters to come, but it’s
    good to keep in mind that signals data contains a treasure trove of potential
    insights and often provides just as much benefit as the content of the documents
    receiving the user interactions. Reflected intelligence and crowdsourcing are
    not limited to only the signals boosting, collaborative filtering, and learning-to-rank
    techniques we’ve described. They can also be derived from content instead of signals,
    as we’ll discuss in the next section.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中继续探讨这些技术，但记住，信号数据包含了一个宝库的潜在见解，并且通常提供与用户交互的文档内容一样多的好处。反射智能和众包不仅限于我们描述的信号提升、协同过滤和学习排序技术。它们也可以从内容而不是信号中得出，正如我们将在下一节中讨论的。
- en: 4.2.6 Crowdsourcing from content
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.6 从内容中进行众包
- en: While we typically think of crowdsourcing as asking users to provide input,
    we’ve seen in this chapter that implicit feedback can often provide as much or
    even more value in aggregate across many user signals. While this chapter has
    been entirely focused on using user signals to do this crowdsourcing, it’s also
    important to point out that content itself can be used as crowdsourced intelligence
    for your AI-powered search platform.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们通常认为众包是要求用户提供输入，但我们在这个章节中看到，隐式反馈通常可以在许多用户信号中提供同样多的甚至更多的价值。虽然这个章节完全专注于使用用户信号来进行这种众包，但也很重要的是要指出，内容本身也可以用作你人工智能搜索平台的众包智能。
- en: For example, if you’re trying to figure out the general quality of your documents,
    you may be able to look at customer reviews to generate a product rating or to
    see if the product has been reported as abusive or spam. If the customer has left
    comments, you may be able to run a *sentiment analysis* algorithm on the text,
    denoting if the comments are positive, neutral, or negative. Based on the detected
    sentiment, you can boost or penalize the source documents accordingly. This process
    is essentially deriving signals from user-submitted content, so it’s still a form
    of crowdsourcing, albeit from other content provided by the users.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你试图了解你文档的一般质量，你可能能够查看客户评论来生成产品评分或查看产品是否被报告为滥用或垃圾邮件。如果客户留下了评论，你可能能够在文本上运行*情感分析*算法，以确定评论是积极的、中性的还是消极的。根据检测到的情感，你可以相应地提高或惩罚源文档。这个过程本质上是从用户提交的内容中提取信号，因此它仍然是一种众包形式，尽管是从用户提供的其他内容中进行的。
- en: We mentioned that in chapter 6 we’ll walk through how we can mine user signals
    to automatically learn domain-specific terminology (phrases, misspellings, synonyms,
    and so on). Just as you can take user queries and interactions to learn this terminology,
    you should also realize that documents are typically written by people and that
    very similar kinds of relationships between terminology are therefore reflected
    in the written content. We’ll explore these content-based relationships further
    in the next chapter.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到，在第6章中，我们将介绍如何挖掘用户信号来自动学习特定领域的术语（短语、拼写错误、同义词等）。就像您可以通过用户查询和交互来学习这种术语一样，您也应该意识到文档通常是由人编写的，因此，术语之间非常相似的关系因此反映在书面内容中。我们将在下一章进一步探讨这些基于内容的关系。
- en: One of the best-known search algorithms in existence is the *Page Rank* algorithm—the
    breakthrough algorithm that initially enabled Google to rise to prominence as
    the most relevant web search engine. Page Rank goes beyond the text of any given
    web page and looks at the implied behavior of all other web page creators to see
    how they have linked to other web pages. By measuring the incoming and outgoing
    links, it’s possible to measure a web page’s “quality” on the assumption that
    websites are more likely to link to higher-quality, more authoritative sources
    and that those higher-quality sources are less likely to link to lower-quality
    sources. This idea of going beyond the content within a single document and relating
    it to other documents—whether by direct links between them, user comments or feedback,
    any other user interactions, or even just the use of terminology in different,
    nuanced ways across documents—is incredibly powerful. The art and science of using
    all the available information about your content and from your users is key to
    building a highly relevant AI-powered search engine. In chapter 5, we’ll look
    into the concept of knowledge graphs and how we can use some of the relationships
    embedded within the implied links between documents to automatically further domain
    understanding.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 存在的最著名的搜索算法之一是*Page Rank*算法——这个突破性的算法最初使谷歌成为最相关的网络搜索引擎而闻名。Page Rank超越了任何给定网页的文本，并查看所有其他网页创建者的隐含行为，以了解他们如何链接到其他网页。通过测量
    incoming 和 outgoing 链接，可以测量网页的“质量”，假设网站更有可能链接到高质量、更权威的来源，而那些高质量来源不太可能链接到低质量来源。这种超越单个文档内容并将其与其他文档相关联的想法——无论是通过它们之间的直接链接、用户评论或反馈、任何其他用户交互，甚至是文档中术语的不同、细微的使用方式——是非常强大的。利用您的内容和用户的所有可用信息的艺术和科学是构建高度相关的AI搜索引擎的关键。在第5章中，我们将探讨知识图的概念以及我们如何使用文档之间隐含链接中嵌入的一些关系来自动进一步理解特定领域。
- en: Summary
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Content, signals, and models (which are derived from content and signals) are
    the three main sources of “fuel” to power an AI-powered search engine, with signals
    being the primary source for crowdsourced relevance.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容、信号和模型（这些是从内容和信号中派生出来的）是驱动一个AI搜索引擎的三个主要“燃料”来源，其中信号是众包相关性的主要来源。
- en: Reflected intelligence is the process of creating learning feedback loops that
    improve from each user interaction and reflect that learned intelligence back,
    to continuously increase the relevance of future results.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反射智能是创建学习反馈循环的过程，它从每个用户交互中改进，并将学习到的智能反映回来，以持续提高未来结果的相关性。
- en: Signals boosting is a form of “popularized relevance”, which usually has the
    biggest effect on your highest-volume, most popular queries.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号增强是一种“普及化相关性”的形式，通常对您最高流量、最受欢迎的查询影响最大。
- en: Collaborative filtering is a form of “personalized relevance”, which can use
    patterns of user interaction with items to learn user preferences or the strength
    of relationships between items and to then recommend similar items based upon
    those learned relationships.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同过滤是一种“个性化相关性”的形式，它可以使用用户与物品的交互模式来学习用户偏好或物品之间关系的强度，然后根据这些学习到的关系推荐类似物品。
- en: Learning to rank (LTR) is a form of “generalized relevance” and is the process
    of training a ranking classifier based on relevance judgment lists (queries mapping
    to correctly ranked documents). LTR can be applied to rank all documents and avoid
    the cold-start problem.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习排序（LTR）是一种“广义相关性”的形式，它是基于相关性判断列表（查询映射到正确排序的文档）来训练排序分类器的过程。LTR可以应用于对所有文档进行排序，并避免冷启动问题。
- en: Other kinds of reflected intelligence exist, including techniques for using
    content (instead of just signals) for crowdsourced relevance.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他类型的反射智能存在，包括使用内容（而不仅仅是信号）进行众包相关性的技术。
