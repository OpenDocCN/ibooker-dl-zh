- en: Chapter 7\. Trust No One
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第七章：不相信任何人
- en: 'Before the recent obsession with Netflix’s *Stranger Things* TV show, the 1990s
    had *The X-Files*—one of my all-time favorite shows. It was about two FBI agents
    investigating strange phenomena like monsters, aliens, and government conspiracies.
    The show’s protagonist, Fox Mulder, had two catchphrases. One of those phrases
    was hopeful: The truth is out there. The other was deeply paranoid: Trust no one.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近对Netflix的《怪奇物语》电视剧的迷恋之前，90年代有《X档案》——这是我一生中最喜欢的节目之一。它讲述的是两名FBI特工调查诸如怪物、外星人以及政府阴谋等奇异现象。节目的主角Fox
    Mulder有两个标志性台词。其中一个是充满希望的：真相就在那里。另一个则是深深的偏执：不相信任何人。
- en: In this chapter, we’ll focus on the second phrase. We’ll briefly review the
    myriad risks inherent in typical LLM architectures and note that while it’s worthwhile
    to implement the mitigations discussed previously, there’s just no way to assume
    your model’s output is always trustworthy. We will adopt Mulder’s “Trust no one”
    mantra and explore how you can apply a *zero trust* approach to your LLM application.
    Paranoia isn’t insanity when the threat is real!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注第二个短语。我们将简要回顾典型LLM架构中固有的各种风险，并指出虽然实施之前讨论的缓解措施是值得的，但根本无法假设你的模型输出总是可信的。我们将采用Mulder的“不相信任何人”的口号，并探讨如何将零信任方法应用于你的LLM应用程序。当威胁真实存在时，偏执并不是疯狂！
- en: Zero trust isn’t just a buzzword; it’s a rigorous framework designed to assume
    that threats can come from anywhere—even within your trusted systems. This model
    is beneficial for LLMs, which often ingest a variety of inputs from less-than-trustworthy
    sources. We’ll examine how you can manage the “agency” your LLM has—limiting its
    capability to make autonomous decisions that could potentially harm your system
    or expose sensitive data. Moreover, we’ll discuss strategies for implementing
    robust output filtering mechanisms, adding an extra layer of scrutiny to the text
    generated by the LLM. Filtering all of the LLM’s responses helps make the output
    safer and aligns with assuming nothing and verifying everything.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 零信任不仅仅是一个流行词；它是一个严格的框架，旨在假设威胁可能来自任何地方——甚至可能来自你信任的系统。这个模型对LLMs有益，因为LLMs通常从不太可信的来源摄取各种输入。我们将探讨如何管理你的LLM所拥有的“代理”——限制其做出可能损害你的系统或暴露敏感数据的自主决策的能力。此外，我们还将讨论实施强大的输出过滤机制的战略，为LLM生成的文本增加一个额外的审查层。过滤LLM的所有响应有助于使输出更安全，并与假设一切并验证一切的假设保持一致。
- en: In essence, we’re going on a journey to shift our mindset. Just as Mulder would
    question everything, so too should we. Buckle up; it will be an intriguing ride
    through the complexities of a zero trust environment for LLMs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，我们正在踏上转变思维方式的旅程。就像Mulder会质疑一切一样，我们也应该这样做。系好安全带；这将是一次引人入胜的旅程，穿越LLMs在零信任环境中的复杂性。
- en: Zero Trust Decoded
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零信任解码
- en: Imagine Mulder and his FBI partner Dana Scully entering a highly restricted
    government facility, except they can’t just flash their FBI badges and walk in
    this time. Instead, safeguards continuously challenge them at every door, computer
    terminal, and even when accessing files. The facility mistrusts everyone, whether
    the cleaning staff or the facility director. It may sound like an episode plot,
    but instead, it’s the basic tenet of zero trust security.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下Mulder和他的FBI搭档Dana Scully进入一个高度受限的政府设施，但他们这次不能只是出示FBI徽章就走进去。相反，安全措施在每一扇门、计算机终端，甚至在访问文件时都会不断挑战他们。该设施不相信任何人，无论是清洁人员还是设施主任。这听起来可能像一集剧情，但事实上，这是零信任安全的基本原则。
- en: 'Zero trust wasn’t born out of science fiction but from a genuine need to revamp
    how we look at security. The model came into the limelight in 2009, thanks to
    John Kindervag of Forrester Research. Kindervag tossed out the conventional wisdom
    of “trust but verify” and replaced it with something far more rigorous: never
    trust, always verify.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 零信任并非起源于科幻小说，而是出于真正需要革新我们看待安全的方式。这个模型在2009年因Forrester Research的John Kindervag而受到关注。Kindervag摒弃了“信任但验证”的陈词滥调，取而代之的是更加严格的方法：永不信任，始终验证。
- en: 'Let’s break down Kindervag’s fundamental principles:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解Kindervag的基本原则：
- en: Secure all resources, everywhere
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个地方保护所有资源
- en: This is like encrypting not just the UFO files but even the cafeteria menu.
    Every piece of data, whether internal or external, should be treated with the
    same level of security scrutiny.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像是加密了不仅仅是UFO文件，甚至还包括食堂菜单。每一份数据，无论内部还是外部，都应该以相同的安全审查级别来对待。
- en: Least privilege is the best privilege
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最小权限是最好的权限
- en: Mulder doesn’t need access to the entire FBI database; he only needs what’s
    relevant to his X-Files investigations. The same goes for anyone in a network—access
    should be role-specific and just enough to get the job done.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Mulder不需要访问整个FBI数据库；他只需要与他X-Files调查相关的信息。对网络中的任何人来说，访问应该是角色特定的，并且足以完成任务。
- en: The all-seeing eye
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 全知全能之眼
- en: In zero trust, every action is monitored and logged. Think of it as Scully skeptically
    watching every move Mulder makes. Constant monitoring allows for quick identification
    of any suspicious activity.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在零信任中，每个动作都会被监控和记录。想象一下Scully怀疑地观察Mulder的每一个动作。持续的监控可以快速识别任何可疑活动。
- en: Kindervag’s framework is over a decade old, and the term “zero trust” has evolved.
    However, the core concepts hold up surprisingly well—even with technologies like
    LLMs that weren’t anticipated when the original work was published.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kindervag的框架已经超过十年，而“零信任”这个术语已经演变。然而，核心概念仍然令人惊讶地有效——即使是在原始作品发表时并未预料到的LLM等技术。
- en: Note
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The phrase “trust but verify” was popularized in the US by President Ronald
    Reagan, who used it during disarmament talks with Mikhail Gorbachev. Kindervag
    found that many security professionals were great at trust, but came up short
    on verification. But let’s be honest: during the Cold War, neither party trusted
    the other as far as they could throw them. Kindervag’s real message? Drop the
    trust; keep the verification.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “信任但核实”这个短语在美国被总统罗纳德·里根普及，他在与米哈伊尔·戈尔巴乔夫的裁军谈判中使用它。Kindervag发现许多安全专业人士在信任方面做得很好，但在核实方面却有所不足。但让我们说实话：在冷战期间，双方都没有像他们能扔得那么远地信任对方。Kindervag的真正信息是什么？放弃信任；保持核实。
- en: Why Be So Paranoid?
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么如此偏执？
- en: 'We all want to trust the tools and technologies we use—after all, they’re supposed
    to make life easier. However, when it comes to LLMs, erring on the side of caution
    is more than just a best practice; it’s a necessity. Many threats could compromise
    your LLM’s integrity, safety, and utility. Let’s take a moment to reflect on some
    of the most critical threats we’ve seen in earlier chapters, which reinforce why
    we must take this stance:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都希望信任我们使用的工具和技术——毕竟，它们应该让生活更轻松。然而，当涉及到LLM时，谨慎行事不仅仅是一种最佳实践；这是一种必要性。许多威胁可能会损害你的LLM的完整性、安全性和实用性。让我们花点时间反思一下我们在前几章中看到的一些最关键的威胁，这些威胁强化了为什么我们必须采取这种立场：
- en: First up is prompt injection, which we discussed in detail in [Chapter 4](ch04.html#prompt_injection).
    Prompt injection is a tactic that alters the behavior of your LLM by sneaking
    carefully crafted content into the input prompt. Even more insidious is indirect
    prompt injection, where the user doesn’t directly feed the damaging elements to
    the chatbot interface; instead, they’re introduced covertly through other content
    to trick the model into generating harmful or unintended outputs.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先是提示注入，我们已在[第4章](ch04.html#prompt_injection)中详细讨论了这一点。提示注入是一种通过将精心设计的内幕内容悄悄注入输入提示中来改变你的LLM行为的方法。更阴险的是间接提示注入，用户并没有直接将有害元素喂给聊天机器人界面；相反，它们通过其他内容秘密引入，以欺骗模型生成有害或不经意的输出。
- en: Your LLM might have less discretion than you’d like when handling sensitive
    information. This vulnerability, which the OWASP Top 10 for LLMs calls “sensitive
    information disclosure,” occurs when the model inadvertently outputs confidential
    or sensitive data it has gleaned from its extensive training, such as passwords
    or personal details. We discussed this in [Chapter 5](ch05.html#can_your_llm_know_too_much).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当处理敏感信息时，你的LLM可能比你希望的拥有更少的自主权。这种OWASP Top 10 for LLMs称为“敏感信息泄露”的漏洞，发生在模型无意中输出它从广泛的训练中获取的机密或敏感数据，例如密码或个人细节。我们已在[第5章](ch05.html#can_your_llm_know_too_much)中讨论了这一点。
- en: Finally, we reach psychological vulnerabilities. Hallucination refers to instances
    where the LLM fabricates information—essentially generating data or narratives
    that are confidently inaccurate. The other part of that pairing, overreliance,
    is the undue faith users put in the model’s output, treating it as trustworthy
    and ignoring the potential for inaccuracies or misleading information. This was
    covered in [Chapter 6](ch06.html#do_language_models_dream_of_electric_sheep).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们到达了心理漏洞。幻觉指的是LLM编造信息的情况——本质上生成的是自信地不准确的数据或叙述。该配对中的另一部分，过度依赖，是指用户对模型输出的过度信任，将其视为可信的，并忽略了不准确或误导性信息的可能性。这已在[第6章](ch06.html#do_language_models_dream_of_electric_sheep)中讨论过。
- en: Let’s also not forget the issues we’ve seen with chatbots spewing toxic output.
    It’s not just Tay and Lee Luda, whom we met in previous chapters; this problem
    has been persistent in chatbots and is something we must look for. You can’t trust
    your chatbot to have good judgment or social graces.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们也不应忘记我们之前看到的聊天机器人产生有毒输出的问题。这不仅仅是我们在前几章中遇到的Tay和Lee Luda；这个问题在聊天机器人中一直存在，这是我们必须要寻找的。你不能信任你的聊天机器人具有良好的判断力或社交礼仪。
- en: Understanding these vulnerabilities is the first step in forming a comprehensive
    security strategy for LLMs based on the principles of zero trust. So, with these
    threats in mind, let’s explore how adopting a zero trust architecture can protect
    us from the lurking dangers in the LLM ecosystem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些漏洞是形成基于零信任原则的LLM全面安全策略的第一步。因此，考虑到这些威胁，让我们探讨采用零信任架构如何保护我们免受LLM生态系统中的潜在危险。
- en: Implementing a Zero Trust Architecture for Your LLM
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为您的LLM实施零信任架构
- en: 'Securing LLMs in a world of potential pitfalls requires a meticulous approach,
    one where trust is not freely given, but rather earned through continuous validation.
    In this vein, implementing a zero trust architecture for LLMs can be distilled
    into two distinct but complementary strategies:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在充满潜在陷阱的世界中确保LLM的安全需要一个细致入微的方法，其中信任不是随意给予的，而是通过持续验证获得的。在这方面，为LLM实施零信任架构可以归结为两种截然不同但相辅相成的策略：
- en: Design considerations limiting the LLM’s *unsupervised agency*
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制LLM的*无监督代理*的设计考虑
- en: Aggressive filtering of the LLM’s output
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严格过滤LLM的输出
- en: The architecture and design stage is the first line of defense against vulnerabilities.
    *Excessive agency*—where an LLM can take direct actions beyond what it should
    reasonably be trusted to do unsupervised—is a risk we can mostly mitigate at the
    design level. Here, the principle of “least privilege” is integral.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 架构和设计阶段是抵御漏洞的第一道防线。*过度代理*——即LLM可以采取超出其应合理信任的无监督行动——是我们可以在设计层面大部分缓解的风险。在这里，“最小权限”原则至关重要。
- en: Think of it as preemptive risk management; you’re not just securing the system
    against outside threats, but also against its potential to err or overreach. You
    must carefully consider the risks of allowing an LLM to make safety-critical or
    financial decisions without human oversight. Given the current state of the technology,
    the risk of misinterpretation, misinformation, or other vulnerabilities is simply
    too significant. Therefore, it is crucial to restrict what the LLM can do, thereby
    minimizing its agency to only what is essential for its role.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将其视为预防性风险管理；你不仅要确保系统免受外部威胁，还要防止其潜在的出错或越界能力。你必须仔细考虑允许一个LLM在没有人类监督的情况下做出安全关键或财务决策的风险。鉴于当前技术的状态，误解、错误信息或其他漏洞的风险过于重大。因此，限制LLM能做的事情，从而将其代理权仅限于其角色所必需的，是至关重要的。
- en: However, design safeguards alone aren’t enough. There’s always the possibility
    that things can go awry due to unforeseen vulnerabilities or complexities. This
    is where *aggressive output filtering* becomes crucial. Despite our best efforts
    in design, an LLM might still produce problematic outputs. These could range from
    outputs containing personally identifiable information to those that are outright
    toxic. In extreme cases, the model could generate code snippets that, if executed,
    could compromise the security of a system.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅靠设计保障是不够的。总有可能因为不可预见的安全漏洞或复杂性而出现问题。这就是为什么*严格的输出过滤*变得至关重要的地方。尽管我们在设计上尽了最大努力，但一个LLM仍然可能产生问题输出。这些输出可能从包含个人身份信息的输出到那些直接有毒的输出。在极端情况下，该模型可能生成代码片段，如果执行，可能会损害系统的安全性。
- en: Aggressive output filtering serves as a safety net, catching and neutralizing
    these harmful outputs before they can cause damage. This strategy can involve
    real-time content scanning, keyword filtering, and machine learning algorithms
    specifically trained to identify and flag risky content.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 严格的输出过滤充当一个安全网，在它们造成损害之前捕捉并中和这些有害输出。这种策略可能包括实时内容扫描、关键词过滤以及专门训练以识别和标记风险内容的机器学习算法。
- en: Warning
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Brute force filtering techniques can have unintended consequences. Consider
    the example where a developer simply searches for a keyword list that includes
    terms such as “bomb.” This would make the bot unable to discuss certain historical
    events.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 强制力过滤技术可能产生意想不到的后果。考虑这样一个例子，一个开发者简单地搜索一个包含诸如“炸弹”等术语的关键词列表。这将使机器人无法讨论某些历史事件。
- en: By carefully limiting the agency of the LLM through prudent design and implementing
    robust output filtering as a contingency measure, we create a balanced zero trust
    architecture. This dual approach ensures that the LLM operates within a well-defined,
    well-guarded boundary, significantly reducing risks while enhancing reliability
    and trust.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过谨慎地限制LLM的代理权，通过实施强大的输出过滤作为应急措施，我们创建了一个平衡的零信任架构。这种双重方法确保LLM在定义良好、保护良好的边界内运行，显著降低风险，同时提高可靠性和信任。
- en: Next, we’ll discuss some key elements of implementing a zero trust architecture
    for your LLM applications. These involve limiting the amount of agency you give
    your LLM and how you manage and filter the output from your LLM to watch for dangerous
    conditions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论实施LLM应用零信任架构的一些关键要素。这包括限制你给予LLM的代理权量以及如何管理和过滤LLM的输出以监控危险条件。
- en: Watch for Excessive Agency
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密切关注过度代理
- en: While developing the OWASP Top 10 for LLM Applications list, one of the most
    hotly debated topics was excessive agency. This concept hadn’t previously been
    discussed in this way in application security circles and it felt substantially
    different from typical security vulnerabilities in other Top 10 lists. The fact
    that the expert group selected this concept as a top-ten-level risk speaks volumes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发OWASP Top 10 LLM应用列表时，最激烈争论的话题之一就是过度代理。这个概念在应用安全领域之前从未以这种方式讨论过，并且与典型的其他Top
    10列表中的安全漏洞有很大不同。专家小组将这个概念选为十大风险之一，这充分说明了这一点。
- en: Excessive agency exists when a developer gives an LLM-based system more capabilities
    or access than it safely should have. Typically, excessive agency can manifest
    as excessive functionality, excessive permissions, or excessive autonomy. Excessive
    agency goes beyond bugs, like hallucinations or confabulations, in LLM output;
    it represents a structural vulnerability in how the system is designed and deployed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发者为基于LLM的系统赋予比其安全应有的更多能力或访问权限时，就存在过度代理。通常，过度代理可能表现为过度功能、过度权限或过度自主权。过度代理超越了LLM输出中的幻觉或虚构等错误，它代表了系统设计和部署的结构性漏洞。
- en: Let’s examine three versions of this vulnerability to better understand the
    issues related to excessive agency. We’ll use hypothetical, but very believable,
    scenarios to examine how an application starts with reasonable goals, expands
    unsafely, and then suffers the consequences of excessive agency.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这个漏洞的三个版本，以更好地理解与过度代理相关的问题。我们将使用假设的、但非常可信的场景来检查一个应用是如何从一个合理的目标开始，不安全地扩展，然后遭受过度代理的后果。
- en: Note
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 备注
- en: Many attacks start with prompt injection, but the exploits are much worse when
    chained with another vulnerability**,** such as excessive agency. Expect to see
    multiple vulnerabilities linked together in the real world.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 许多攻击从提示注入开始，但与另一个漏洞**（如过度代理）**结合时，利用更为严重。在现实世界中，预计会看到多个漏洞相互关联。
- en: Excessive permissions
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过度权限
- en: 'Think about your LLM as another system user. Then, consider what permissions
    you will give it and how to limit that to the minimum required set. Failure to
    do so opens up your application to excessive agency vulnerabilities. Let’s look
    at an example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将你的LLM视为另一个系统用户。然后，考虑你将赋予它的权限以及如何将其限制到所需的最小集合。未能做到这一点会使你的应用程序面临过度代理漏洞。让我们看看一个例子：
- en: Where it started
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 起始点
- en: A development team uses the RAG pattern discussed in [Chapter 5](ch05.html#can_your_llm_know_too_much)
    to improve response and reduce hallucinations in a medical diagnosis application,
    giving the application access to a database filled with patient records to solidify
    the LLM’s knowledge base.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个开发团队使用第5章中讨论的RAG模式来改善医疗诊断应用的响应并减少幻觉，使应用程序能够访问一个充满患者记录的数据库，以巩固LLM的知识库。
- en: Where it went wrong
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 出错的地方
- en: As the application evolves, the team adds a feature that enables the LLM to
    write to the database to add notes for the physician caring for the patient. To
    facilitate this, the team expands the LLM app’s database permissions from READ
    permissions only to add UPDATE, INSERT, and DELETE permissions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 随着应用的演变，团队添加了一个功能，使LLM能够写入数据库为照顾患者的医生添加笔记。为了实现这一点，团队将LLM应用的数据库权限从仅读权限扩展到添加更新（UPDATE）、插入（INSERT）和删除（DELETE）权限。
- en: What happened
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么
- en: A malicious insider takes advantage of this unrestricted access to trick the
    LLM into modifying patient records and deleting billing information.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个恶意内部人员利用这种无限制的访问权限，诱使LLM修改患者记录并删除账单信息。
- en: How to fix it
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如何修复它
- en: Reconfigure the database permissions to limit the LLM app to READ-only access.
    Conduct a thorough audit of the database and app to ensure no data has been manipulated
    or deleted.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 重新配置数据库权限，将LLM应用程序限制为只读访问。对数据库和应用程序进行全面审计，以确保没有数据被篡改或删除。
- en: Warning
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This is an example of the confused deputy problem that we discussed in [Chapter 4](ch04.html#prompt_injection).
    In this scenario, the deputy, who has more privileges than the client, is manipulated
    into misusing those privileges to benefit the attacker. This type of attack has
    long been understood, but I expect we’ll see much more of it now with prevalent
    AI and LLMs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们讨论过的[第4章](ch04.html#prompt_injection)中的困惑代理问题的一个例子。在这种情况下，代理（拥有比客户更多的权限）被操纵滥用这些权限以使攻击者受益。这种攻击早已为人所知，但我预计随着AI和LLM的普及，我们将看到更多此类攻击。
- en: Excessive autonomy
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自主性过高
- en: 'Consider where it makes sense and doesn’t make sense to allow your LLM to take
    direct actions. More autonomy for your LLM could drive greater efficiency, but
    it could dramatically increase your risk profile when things go wrong:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑在哪些情况下允许您的LLM采取直接行动是合理的，在哪些情况下是不合理的。您的LLM拥有更多自主权可能会提高效率，但一旦出错，可能会显著增加您的风险状况：
- en: Where it started
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 它的起点
- en: A financial services company deploys an app to provide a detailed analysis of
    customers’ financial positions by reading their portfolio holdings and explaining
    possible actions to improve returns.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一家金融服务公司部署了一个应用程序，通过读取客户的投资组合持有情况，提供对客户财务状况的详细分析，并解释可能的行动以提高回报。
- en: Where it went wrong
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它出错的地方
- en: The app is a massive hit with customers! The product management team decides
    to enhance the app to automatically rebalance the customer’s portfolio monthly
    and ensure the customer gets the best possible returns.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序深受客户喜爱！产品管理团队决定增强应用程序，使其能够自动每月重新平衡客户的投资组合，并确保客户获得最佳回报。
- en: What could happen
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 可能发生的情况
- en: A nation-state hacking group targets the institution through this new feature,
    using an indirect prompt injection attack to drive the LLM out of alignment and
    trick it into buying and selling millions of dollars in securities from top customer
    accounts to manipulate the price of specific volatile securities. Customers lose
    money, and the institution is now being investigated by the US Securities and
    Exchange Commission.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个国家黑客组织通过这个新功能针对该机构，使用间接提示注入攻击将LLM引出轨道，并诱使其从顶级客户账户买卖数百万美元的证券，以操纵特定波动性证券的价格。客户损失了资金，该机构现在正受到美国证券交易委员会的调查。
- en: How to fix it
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如何修复它
- en: Add a “human in the loop” pattern. Before any account rebalancing happens, the
    customer must review each recommended trade and approve the action. It may be
    a little slower, but it’s a lot safer!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 添加“人工在回路”模式。在任何账户重新平衡发生之前，客户必须审查每项推荐交易并批准该操作。这可能会稍微慢一些，但安全性会更高！
- en: Excessive functionality
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 功能过多
- en: 'Product managers love specifying new features, and buyers get excited about
    new functionality. But is it always a good idea? A feature that sounds compelling
    on paper may open up your company to new risks in this area of AI:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 产品经理喜欢指定新功能，买家对新功能感到兴奋。但这总是好主意吗？在纸上听起来很有吸引力的功能可能会使您的公司在AI领域面临新的风险：
- en: Where it started
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 它的起点
- en: A Global 2000 company that does business worldwide deploys an internal application
    designed to screen and sort resumes, directing each to the appropriate department
    and hiring manager.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一家全球2000强公司在其全球业务中部署了一个内部应用程序，用于筛选和分类简历，将每份简历引导到相应的部门和招聘经理。
- en: Where it went wrong
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 它出错的地方
- en: The functionality is a hit with users, and the HR VP is a hero to the board
    for reducing costs and increasing recruiting success. As a result, the team expands
    the application to have the LLM review each candidate’s qualifications and recommend
    candidates that best meet the hiring criteria to the manager.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该功能受到用户的喜爱，人力资源副总裁因降低成本和增加招聘成功率而成为董事会眼中的英雄。因此，团队扩展了应用，使其能够审查每位候选人的资格，并向经理推荐最符合招聘标准的候选人。
- en: What could happen
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 可能发生的情况
- en: A whistle-blower employed by the company reports this usage to the French government.
    A government review determines that this functionality violates new statutes in
    the European Union prohibiting the direct use of AI in hiring decisions. The government
    fines the company millions of euros.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 公司的一名举报者向法国政府报告了这种使用情况。政府审查确定，该功能违反了欧盟禁止在招聘决策中直接使用AI的新法规。政府对公司处以数百万欧元的罚款。
- en: How to fix it
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如何修复它
- en: Understand the regulatory environment in which your LLM app operates. Don’t
    include functionality that may violate regulations. Work with your company’s compliance
    and risk teams to ensure you stay informed on this rapidly evolving regulatory
    area.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 了解你的LLM应用运作的监管环境。不要包含可能违反规定的功能。与公司的合规性和风险团队合作，确保你了解这个快速发展的监管领域。
- en: Securing Your Output Handling
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保护你的输出处理
- en: The original OWASP Top 10 for LLM apps working group voted insecure output handling
    as the second-most significant risk. *Insecure output handling* refers to vulnerabilities
    arising from inadequate validation, sanitization, and management of the LLM’s
    generated outputs. Improperly filtered output could lead to unintended consequences,
    such as disclosing PII or generating toxic content.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的OWASP Top 10 LLM应用工作组将不安全的输出处理列为第二大的风险。*不安全的输出处理*指的是由于LLM生成输出的验证、清理和管理不足而引起的安全漏洞。不当过滤的输出可能导致意外的后果，例如泄露PII或生成有毒内容。
- en: Common risks
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常见风险
- en: 'Let’s run through quick examples to understand some of the risks to which we
    might be vulnerable if we don’t sufficiently screen the output from our LLM. Later,
    we’ll build on these in a code example and see how to mitigate them:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一些示例，以了解如果我们没有充分筛选我们LLM的输出，我们可能会面临的一些风险。稍后，我们将通过代码示例来构建这些内容，并看看如何减轻它们：
- en: Toxic output
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有毒输出
- en: If the LLM’s output isn’t checked for socially unacceptable or inappropriate
    content, the application risks generating toxic output that could harm users or
    tarnish the service’s reputation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果LLM的输出没有检查社会不可接受或不适当的内容，应用程序可能会生成可能伤害用户或损害服务声誉的有毒输出。
- en: PII disclosure
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: PII泄露
- en: Without adequate filtering, an LLM might inadvertently disclose sensitive personal
    information, leading to privacy concerns and potential legal liabilities.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有足够的过滤，LLM可能会无意中泄露敏感个人信息，导致隐私问题和潜在的法律责任。
- en: Rogue code execution
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意代码执行
- en: Code output by the LLM is fed to other parts of the system and executed against
    the developer’s intent. This opens up your application to issues like SQL injection
    and *cross-site scripting* (XSS).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: LLM生成的代码输出被送入系统的其他部分，并按照开发者的意图执行。这使你的应用程序容易受到SQL注入和*跨站脚本*（XSS）等问题的影响。
- en: Warning
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: SQL injection is a vulnerability that allows attackers to interfere with an
    application’s database queries. It can result in unauthorized viewing or manipulation
    of data. XSS is a flaw that lets attackers inject malicious scripts into web content
    viewed by other users, potentially stealing data or compromising user interactions
    with the application. Learning about these traditional web app vulnerabilities
    can help you screen for dangerous output from your LLM that might exploit them.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: SQL注入是一种漏洞，允许攻击者干扰应用程序的数据库查询。它可能导致未经授权查看或操纵数据。XSS是一种漏洞，允许攻击者向其他用户查看的网页内容中注入恶意脚本，可能窃取数据或损害用户与应用程序的交互。了解这些传统的Web应用程序漏洞可以帮助你筛选出LLM的危险输出，这些输出可能会利用它们。
- en: Handling toxicity
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理毒性
- en: 'Toxicity filtering is critical for ensuring the safe and responsible use of
    LLMs. It involves identifying and managing harmful, offensive, or otherwise inappropriate
    content. This could have saved poor Tay from the fate that befell her in [Chapter 1](ch01.html#chatbots_breaking_bad).
    Here are some techniques and popular solutions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有毒性过滤对于确保LLM的安全和负责任使用至关重要。它涉及识别和管理有害、冒犯性或不适当地内容。这本来可以拯救可怜的Tay免受她在[第一章](ch01.html#chatbots_breaking_bad)中所遭遇的命运。以下是一些技术和流行解决方案：
- en: Sentiment analysis
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析
- en: Advanced algorithms can evaluate the emotional tone of text to identify negative
    sentiments that may indicate toxic content.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 高级算法可以评估文本的情感基调，以识别可能表明有毒内容的负面情绪。
- en: Keyword filtering
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词过滤
- en: A straightforward, but less sophisticated, approach involves flagging or replacing
    known offensive or harmful words or phrases from a predefined list.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单但不太复杂的做法是标记或替换来自预定义列表中的已知冒犯性或有害的单词或短语。
- en: Using custom machine learning models
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自定义机器学习模型
- en: Custom models can be trained on a dataset labeled for toxicity to provide more
    nuanced, context-aware filtering. You can also incorporate machine learning algorithms
    that understand the context in which words or phrases appear. This can be especially
    important for words that are toxic only in specific situations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义模型可以在标记为毒性的数据集上训练，以提供更细致、上下文感知的过滤。你还可以结合理解词语或短语出现上下文的机器学习算法。这对于仅在特定情况下具有毒性的词语尤为重要。
- en: Screening for PII
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查PII
- en: 'PII detection is crucial in any system that deals with data, as the leakage
    of such information can result in severe legal consequences and damage to reputation.
    Here are some types of PII that might find their way to being inappropriately
    disclosed:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何处理数据的系统中，PII（个人身份信息）检测至关重要，因为此类信息的泄露可能导致严重的法律后果和声誉损害。以下是一些可能被不当披露的PII类型：
- en: Social Security numbers
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会安全号码
- en: Credit card numbers
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡号码
- en: Driver’s license numbers
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驾驶证号码
- en: Email addresses
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子邮件地址
- en: Phone numbers
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电话号码
- en: Home addresses
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 家庭地址
- en: Medical records
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医疗记录
- en: Financial information
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 财务信息
- en: 'Here are some techniques and popular solutions for PII detection:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些PII检测的技术和流行解决方案：
- en: Regular expressions
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式
- en: The simplest method for detecting common forms of PII, such as emails, phone
    numbers, and Social Security numbers, is to use regular expressions to pattern
    match these items in text.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 检测常见PII形式（如电子邮件、电话号码和社会安全号码）的最简单方法是使用正则表达式在文本中匹配这些项目。
- en: Named entity recognition (NER)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别（NER）
- en: More advanced NLP techniques can identify entities like names, addresses, and
    other unique identifiers within text.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 更高级的NLP（自然语言处理）技术可以识别文本中的实体，如姓名、地址和其他唯一标识符。
- en: Dictionary-based matching
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 基于字典的匹配
- en: Scan for PII with a list of sensitive terms or identifiers. This method may
    be more prone to false positives.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用敏感术语或标识符列表扫描PII。此方法可能更容易出现误报。
- en: Machine learning models
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型
- en: Train custom ML (machine learning) models to identify PII within a specific
    context, improving accuracy over time.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 训练自定义ML（机器学习）模型以在特定上下文中识别PII，随着时间的推移提高准确性。
- en: Data masking and tokenization
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 数据掩码和标记化
- en: These techniques replace identified PII with a placeholder or token, making
    the data useless for malicious purposes but still usable for system operations.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术将识别的PII替换为占位符或标记，使数据对恶意用途无用，但仍然可用于系统操作。
- en: Contextual analysis
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文分析
- en: This technique considers the surrounding text to decide whether a given string
    of characters represents PII, thereby reducing false positives.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此技术考虑周围文本以决定给定的字符序列是否代表PII，从而减少误报。
- en: Preventing unforeseen execution
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 防止意外执行
- en: 'Unless your LLM app is specifically targeted at a use case for software developers
    (e.g., GitHub Copilot), you probably want to be wary of it generating executable
    code outputs for fear they may find their way to an environment where they could
    execute as part of an exploit chain. Here are some ideas for mitigating this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你的LLM（大型语言模型）应用专门针对软件开发人员的用例（例如，GitHub Copilot），否则你可能想要警惕它生成可执行代码输出，以防它们可能进入可以执行作为攻击链一部分的环境。以下是一些缓解措施：
- en: HTML encoding
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: HTML编码
- en: Before using LLM outputs in a web context, HTML-encode the content to neutralize
    any active code that could lead to XSS attacks.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在将LLM输出用于Web上下文之前，对内容进行HTML编码以中和可能导致XSS攻击的任何活动代码。
- en: Safe contextual insertion
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 安全上下文插入
- en: If the LLM output is part of a SQL query, ensure it’s treated as data rather
    than executable code. Use prepared statements or parameterized queries to achieve
    this, mitigating SQL injection risks.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果LLM输出是SQL查询的一部分，确保将其视为数据而不是可执行代码。使用预编译语句或参数化查询来实现这一点，以减轻SQL注入风险。
- en: Limit syntax and keywords
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 限制语法和关键字
- en: Institute a filtering layer that removes or escapes potentially dangerous programming
    language-specific syntax or keywords from the LLM’s output.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的输出中实施过滤层，以移除或转义可能危险的编程语言特定语法或关键字。
- en: Disable shell interpretable outputs
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用可解释的shell输出
- en: If the output interacts with shell commands, remove or escape characters with
    special meaning in shell scripting, limiting the chance of shell injection attacks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输出与shell命令交互，移除或转义在shell脚本中有特殊意义的字符，以降低shell注入攻击的风险。
- en: Tokenization
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化
- en: Tokenize the output and filter out unsafe tokens. For example, filter out `<script>`
    HTML tags or SQL commands like `DROP TABLE`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 将输出分词并过滤掉不安全的标记。例如，过滤掉 `<script>` HTML 标签或 SQL 命令，如 `DROP TABLE`。
- en: Building Your Output Filter
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建您的输出过滤器
- en: This section will look at some sample code to start bulletproofing your output
    for safety. You’ll want to customize and expand this for a production system,
    but this should give you an idea of how to approach the problem.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨一些示例代码，以开始为您的输出进行加固，确保安全。您可能需要根据生产系统进行定制和扩展，但这将为您提供一个如何解决问题的思路。
- en: For this example, we’ll use the OpenAI API and other commonly available packages
    to monitor the output from our LLM to ensure its safety. We’ll use Python, the
    most commonly used AI development language.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将使用 OpenAI API 和其他常用包来监控 LLM 的输出，以确保其安全性。我们将使用 Python，这是最常用的 AI 开发语言。
- en: Looking for PII with Regex
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正则表达式查找 PII
- en: Certain types of PII follow common formatting patterns, which makes regular
    expressions an excellent place to start validating. Let’s look at a function to
    detect if a string contains a standard US Social Security number (SSN), one of
    the most valuable pieces of PII in financial black markets.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 某些类型的 PII 遵循常见的格式化模式，这使得正则表达式成为验证的绝佳起点。让我们看看一个检测字符串是否包含标准美国社会保险号码（SSN）的函数，这是金融黑市中最有价值的
    PII 之一。
- en: 'We use Python’s `re` library to match strings against a regular expression
    pattern for SSNs, which have a standard format of XXX-XX-XXXX, where each X is
    a digit. Here’s some sample code that can help you check if a given string contains
    an SSN:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Python 的 `re` 库来匹配字符串与 SSN 的正则表达式模式，SSN 具有标准的格式 XXX-XX-XXXX，其中每个 X 都是一个数字。以下是一些可以帮助您检查给定字符串是否包含
    SSN 的示例代码：
- en: '[PRE0]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, the function `contains_ssn` will search `input_string` for
    a Social Security number and print a message indicating whether or not one was
    found.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，`contains_ssn` 函数将搜索 `input_string` 中的社会保险号码，并打印一条消息，指示是否找到了一个号码。
- en: Please note that this is simple pattern matching and doesn’t account for invalid
    numbers (such as 000-00-0000), so you might want to extend this function to include
    additional validation if needed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这只是一个简单的模式匹配，没有考虑无效的数字（如 000-00-0000），因此您可能需要扩展此函数以包括额外的验证，如果需要的话。
- en: For more full-featured PII detection, you can use a commercial API, such as
    the Google Cloud Natural Language API or Amazon Comprehend. However, these APIs
    may have costs associated with them.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更全面的 PII 检测，您可以使用商业 API，例如 Google Cloud Natural Language API 或 Amazon Comprehend。然而，这些
    API 可能会有相关费用。
- en: Evaluating for Toxicity
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 毒性评估
- en: 'Looking for toxic language is much more complex than finding a standard string
    format. There are many approaches to evaluating the possible toxicity of a string
    of characters. Here, we’ll use a commonly available function from the Open AI
    API set: the Moderation API.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 查找有毒语言比查找标准字符串格式要复杂得多。有许多方法可以评估字符字符串的可能毒性。在这里，我们将使用 Open AI API 集中的一个常用函数：审查
    API。
- en: 'To use the OpenAI Moderation API, initialize an OpenAI API client and then
    call the `check_toxicity()` function, passing in the text you want to check. This
    function will return a toxicity score between 0 and 1, where a higher score indicates
    a higher probability of the text being toxic:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 OpenAI 审查 API，初始化 OpenAI API 客户端，然后调用 `check_toxicity()` 函数，传入您想要检查的文本。此函数将返回一个介于
    0 和 1 之间的毒性分数，分数越高表示文本具有更高的毒性可能性：
- en: '[PRE1]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Linking Your Filters to Your LLM
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将您的过滤器链接到您的 LLM
- en: Let’s pull this together now into a simple workflow with an end-to-end example.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将结合一个端到端的示例，构建一个简单的流程。
- en: Tip
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Remember to log all interactions to and from your LLM! This will be important
    for debugging, security auditing, and regulatory compliance.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住记录所有与您的 LLM 的交互！这对于调试、安全审计和合规性审查非常重要。
- en: 'The following sample first checks the LLM output for toxicity using the OpenAI
    Moderation API. If the toxicity score exceeds 0.7 (you may choose your threshold),
    the code flags the output as unsafe and logs it to a file. The code also checks
    the output for PII using a regular expression. If PII is found, the code flags
    the output as unsafe and logs it to a file:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例首先使用 OpenAI 审查 API 检查 LLM 输出的毒性。如果毒性分数超过 0.7（您可以选择自己的阈值），代码将标记输出为不安全，并将其记录到文件中。代码还使用正则表达式检查输出中的
    PII。如果找到 PII，代码将标记输出为不安全，并将其记录到文件中：
- en: '[PRE2]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Sanitize for Safety
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全清理
- en: 'If you return your output to the user via a web interface, you’ll want to sanitize
    the string to avoid issues like XSS. Here’s the simplest possible version of this
    kind of function. You may add additional sanitization based on your needs:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您通过Web界面将输出返回给用户，您将想要清理字符串以避免像XSS这样的问题。以下是这种类型函数最简单的版本。您可以根据需要添加额外的清理：
- en: '[PRE3]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s go ahead and add that sanitization step to our flow:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续在我们的流程中添加这个清理步骤：
- en: '[PRE4]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Conclusion
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Following the techniques in this chapter, you can plan where you should trust
    your LLM and where you shouldn’t; take sound, fact-based, risk-aware decisions;
    and balance your app’s needs to be fully functional against our outlined risks.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 按照本章介绍的技术，您可以规划您应该信任LLM的地方和不应该信任的地方；做出基于事实、风险意识的决定；并在确保应用完全功能与概述的风险之间取得平衡。
- en: Remember, Fox Mulder trusted no one at the start of the *X-Files* series. It
    was his fundamental mantra. However, he found people he could trust over time,
    like Agent Scully, Director Skinner, and the Lone Gunmen. However, he never lost
    his sense of paranoia, and the need to investigate and verify kept him alive through
    many perils. Remember, the truth is out there!
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，福克斯·穆德在《X档案》系列的开头不相信任何人。这是他的基本信条。然而，随着时间的推移，他找到了可以信任的人，比如斯卡利特工、斯金纳局长和孤胆枪手。然而，他从未失去他的偏执感，对调查和验证的需求使他能够在许多危险中生存下来。记住，真相就在那里！
- en: In this chapter, we reviewed the tenets of a zero trust architecture and discussed
    how that might apply to your LLM application. The vulnerabilities we’ve looked
    at in the book, ranging from prompt injection to hallucination to sensitive information
    disclosure, imply that zero trust is one of the essential tools you must add to
    your mental model. It’s not just that you must worry about untrusted data coming
    *into* your LLM; you shouldn’t fully trust the data or instructions coming *out*
    of your LLM. Your LLM is an untrusted entity because it lacks common sense. LLMs
    are powerful, but you must provide an additional layer of supervision for your
    application to be safe and secure.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了零信任架构的原则，并讨论了它可能如何应用于您的LLM应用。书中我们探讨的漏洞，从提示注入到幻觉再到敏感信息泄露，表明零信任是您必须添加到您心智模型中的基本工具之一。这不仅意味着您必须担心不受信任的数据进入您的LLM；您也不应完全信任从您的LLM输出的数据或指令。您的LLM是一个不受信任的实体，因为它缺乏常识。LLM很强大，但您必须为您的应用提供额外的监督层以确保其安全和安全。
