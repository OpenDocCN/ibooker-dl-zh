- en: '6 Accelerating productivity: Machine-augmented work'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 加速生产力：机器增强工作
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using LLMs in professional and personal settings
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在专业和个人环境中使用LLMs
- en: Discussing the use and misuse of generative AI tools in education
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论在教育中使用和误用生成式AI工具的情况
- en: Exploring methods to detect machine-generated content
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索检测机器生成内容的方法
- en: Examining the overall economic effect of generative AI tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查生成式AI工具的整体经济影响
- en: 'Everyone has, at some point in their life, experienced what in positive psychology
    is known as the concept of *flow*: you’re deeply absorbed in what you’re working
    on and perhaps lose track of time because you’re so focused. And, most likely,
    you also experienced sudden interruptions, maybe the need to look something up
    or attend to something else, that break the flow. This frustration was top of
    mind for then GitHub CEO Nat Friedman when he announced the release of GitHub’s
    coding assistant, Copilot. “It helps you quickly discover alternative ways to
    solve problems, write tests, and explore new APIs without having to tediously
    tailor a search for answers on the internet,” Friedman wrote [[1]](https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/).
    Integrating into Microsoft’s code editor, Visual Studio Code, was a crucial component:
    Copilot would plug directly into coders’ existing workflows.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人在其一生中的某个时刻都经历过在积极心理学中被称为“心流”的概念：你深深地沉浸在你正在从事的工作中，可能因为太过专注而失去了时间感。而且，很可能是你经历了突然的干扰，比如需要查找某物或处理其他事情，这打破了心流。这种挫败感是当时GitHub首席执行官Nat
    Friedman在宣布GitHub的编码助手Copilot发布时最关心的问题。“它可以帮助你快速发现解决问题的替代方法、编写测试和探索新的API，而不必在互联网上繁琐地搜索答案，”Friedman写道
    [[1]](https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/)。集成到微软的代码编辑器Visual
    Studio Code是一个关键组成部分：Copilot将直接连接到编码者的现有工作流程。
- en: In programming and other fields, people are using large language models (LLMs)
    and other types of generative AI as a means of accelerating the work that they
    already do, whether that’s designing a curriculum or a workout plan. In this chapter,
    we investigate the current usage of LLMs in personal, professional, and educational
    settings. We also consider the possible shifts that this technology will cause
    in education and the economy.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程和其他领域，人们正在使用大型语言模型（LLMs）和其他类型的生成式AI作为加速他们已经做的工作的手段，无论是设计课程还是制定锻炼计划。在本章中，我们调查了LLMs在个人、专业和教育环境中的当前使用情况。我们还考虑了这项技术将对教育和经济造成的影响的可能转变。
- en: Using LLMs in the professional space
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在专业领域使用LLMs
- en: In the previous chapter, we discussed examples of occupational misuse of chatbots
    in such highly regulated industries as medicine, finance, and law. The focus of
    this section is the beneficial uses of chatbots across those professions and others.
    The consensus is that LLMs will be transformative, but what those effects will
    be remains unclear. Already, the use of LLMs is prompting existential questions
    about these professional fields. What does it mean to be a doctor? What does it
    mean to be a lawyer? Fundamentally, jobs have long been understood to imbue us
    with a sense of purpose—chatbots might cause professional identity crises by taking
    on some portion of these services. On the bright side, sectors such as medicine,
    law, and finance provide critical services in today’s society, and those services
    aren’t always accessible to people who need them. Although LLMs aren’t replacements
    for experienced people working in these fields, they might help to shoulder the
    load.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了在高度监管的行业，如医疗、金融和法律中，职业滥用聊天机器人的例子。本节的重点是聊天机器人在这些职业以及其他职业中的有益用途。共识是，大型语言模型（LLMs）将带来变革，但这些影响将是什么仍然不清楚。已经，LLMs的使用正在引发对这些专业领域的存在性疑问。成为一名医生意味着什么？成为一名律师意味着什么？从根本上说，长期以来，工作一直被认为赋予我们一种使命感——聊天机器人通过承担这些服务的一部分，可能会引发职业身份危机。从积极的一面来看，医疗、法律和金融等行业在当今社会中提供关键服务，而这些服务并不总是对需要它们的人可及。尽管LLMs不能替代这些领域经验丰富的人，但它们可能有助于分担负担。
- en: LLMs assisting doctors with administrative tasks
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLMs协助医生处理行政任务
- en: 'Primary care providers today often spend more time doing nonpatient-facing
    tasks than patient-facing tasks. Dr. James Barnett, a clinical associate professor
    at the University of Illinois College of Medicine Peoria, wrote about the “exhausting
    time burden” placed on medical practitioners, and quoted a physician colleague
    who said:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的初级保健提供者往往花费更多的时间在非患者接触任务上，而不是在患者接触任务上。伊利诺伊大学医学学院皮奥里亚分校的临床副教授詹姆斯·巴内特博士撰写了一篇关于医疗从业者所承受的“令人筋疲力尽的时间负担”的文章，并引用了一位医生同事的话说：
- en: Providing good medical care and taking care of patients is why I enjoy my career . . . With
    administrative overload, I find myself getting by with the minimal required care,
    compassion, and understanding of my patients. Satisfaction in my career suffers.
    [[2]](https://peoria.medicine.uic.edu/administrative-tasks-take-up-more-time-than-patient-care-for-many-pcps/)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 提供优质的医疗服务和照顾患者是我享受职业生涯的原因……由于行政负担过重，我发现自己只能提供最低限度的护理、同情和理解。我的职业满意度受到了影响。[[2]](https://peoria.medicine.uic.edu/administrative-tasks-take-up-more-time-than-patient-care-for-many-pcps/)
- en: Such administrative overload includes managing emails and phone calls, writing
    progress notes and charts, and interacting with health insurance providers over
    claims or appeals. One study showed that this nonpatient-facing work takes up
    about 60% of primary care providers’ time; another concluded that the real total
    is at least two-thirds [[2]](https://peoria.medicine.uic.edu/administrative-tasks-take-up-more-time-than-patient-care-for-many-pcps/).
    Given this reality in the United States and many other nations, it’s no wonder
    that early adopters have begun to see LLMs as a potential solution.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行政负担包括管理电子邮件和电话、撰写进度记录和图表，以及与医疗保险提供商就索赔或上诉进行互动。一项研究表明，这种非患者接触的工作占初级保健提供者时间的约60%；另一项研究得出结论，实际总数至少是三分之二
    [[2]](https://peoria.medicine.uic.edu/administrative-tasks-take-up-more-time-than-patient-care-for-many-pcps/)。鉴于美国和其他许多国家的这一现实，难怪早期采用者已经开始将LLMs视为一种潜在解决方案。
- en: Dr. Richard Stern, a Dallas-based rheumatologist, asked GPT-4 to write a letter
    of appeal to an insurer that had denied coverage of off-label use of the drug
    Anakinra for a patient with persistent chronic inflammatory disease. Stern sent
    the letter produced by the LLM to the insurer, which then granted the request,
    sparing the patient $1,500 a month in out-of-pocket costs. Stern told the *New
    York Times* that GPT-4 had made his time with patients significantly more productive
    and that his practice now use the model to compose email replies and responses
    to common questions from patients and to fill out paperwork. It’s not only the
    administrative work that doctors have started to lean on LLMs to do. Dr. Michael
    Pigone, the chair of the internal medicine department at Dell Medical School at
    the University of Texas at Austin, asked his team for a script that doctors could
    use to talk to patients with alcohol use disorder who had “not responded to behavioral
    interventions,” and were still drinking too much. “A week later, no one had done
    it,” said Pigone, but when he asked ChatGPT, the model immediately produced a
    usable script that hit all of the main talking points. Asked to rewrite it for
    patients with little medical knowledge, it then produced a more accessible version
    that began with, “If you think you drink too much alcohol, you’re not alone. Many
    people have this problem, but there are medicines that can help you feel better
    and have a happier, healthier life” [[3]](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.xhtml).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 达拉斯的风湿病学家理查德·斯特恩博士要求GPT-4为一位患有持续慢性炎症性疾病的患者的安卡瑞拉药物非标签使用申请保险赔偿写一封上诉信。斯特恩将LLM生成的信件发送给保险公司，该公司随后批准了请求，使患者免去了每月1500美元的自付费用。斯特恩告诉《纽约时报》，GPT-4使他与患者的时间变得更有生产力，现在他的诊所使用该模型来撰写电子邮件回复和对患者常见问题的回答，以及填写文件。医生们开始依赖LLMs来处理的工作不仅仅是行政工作。德克萨斯大学奥斯汀分校德尔医疗学院内科系主任迈克尔·皮戈内博士要求他的团队编写一个医生可以用来与患有酒精使用障碍且“对行为干预没有反应”且饮酒过多的患者交谈的脚本。皮戈内说：“一周后，没有人去做这件事，”但当他在ChatGPT上询问时，该模型立即生成了一份实用的脚本，涵盖了所有主要谈话要点。当要求为医学知识较少的患者重写时，它又产生了一个更易于理解版本，开头是：“如果你认为你饮酒过多，你并不孤单。许多人都有这个问题，但有一些药物可以帮助你感觉更好，过上更快乐、更健康的生活”
    [[3]](https://www.nytimes.com/2023/06/12/health/doctors-ChatGPT-artificial-intelligence.xhtml)。
- en: Using LLMs to write scripts for delivering messages to patients in a more empathetic
    manner is more controversial than things like summarizing patient notes because
    of its intrinsically interpersonal nature. In the same *New York Times* report,
    a few medical professionals expressed umbrage at the idea of working doctors outsourcing
    empathy to an LLM, while others cautioned against confusing ChatGPT’s good bedside
    manner with good medical advice. A particularly striking anecdote details a doctor
    asking ChatGPT for the words he needs to comfort not a patient but a friend with
    an advanced form of terminal cancer. Dr. Gregory Moore, formerly a practicing
    physician in diagnostic radiology and neurology, then an executive leading health
    and life sciences at Microsoft, reported being blown away by the quality of ChatGPT’s
    responses, which offered empathy and encouragement without false hope. “I wish
    I would have had this when I was in training,” said Moore. “I have never seen
    or had a coach like this” [[3]](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.xhtml).
    Anthropic AI’s LLM, Claude, generated the script in figure 6.1, following a prompt
    about talking to patients about quitting smoking.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM编写脚本以更富有同理心的方式向患者传达信息，比总结患者笔记等事情更具争议性，因为其本质上具有人际互动的性质。在同样的《纽约时报》报道中，一些医疗专业人士对医生将同理心外包给LLM的想法表示不满，而其他人则警告不要将ChatGPT的良好床边风度与良好的医疗建议混淆。一个特别引人注目的轶事是一位医生向ChatGPT寻求安慰患有晚期癌症朋友的词语，而不是安慰患者。格雷戈里·穆尔博士，曾是一名诊断放射学和神经学的执业医生，后来是微软健康和生命科学部门的负责人，报告称他对ChatGPT的回应质量感到震惊，这些回应提供了同理心和鼓励，而没有虚假的希望。“我希望我在培训时就有这样的工具，”穆尔说。“我从未见过或有过这样的教练”
    [[3]](https://www.nytimes.com/2023/06/12/health/doctors-ChatGPT-artificial-intelligence.xhtml)。Anthropic
    AI的LLM，Claude，根据关于与患者谈论戒烟的提示生成了图6.1中的脚本。
- en: '![](../../OEBPS/Images/CH06_F01_Dhamani.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 Claude对戒烟脚本请求的回应开始](../../OEBPS/Images/CH06_F01_Dhamani.png)'
- en: Figure 6.1 The beginning of a response written by Claude to a request for a
    script about smoking cessation
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 Claude撰写的关于戒烟的脚本请求的回应开头
- en: LLMs for legal research, discovery, and documentation
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 法律研究、发现和文档的LLM
- en: 'The takeover of administrative work is far from limited to the medical field.
    According to a 2017 survey of 2,915 legal professionals in the United States,
    lawyers spend about half of their time on administrative tasks [[4]](https://www.law.com/2017/09/26/what-do-lawyers-really-do-with-their-time/).
    Most private lawyers and firms use the billable hours system, where employees
    assiduously track the time spent working on a particular case, often in six-minute
    intervals. Because the tasks involved with managing a legal practice that aren’t
    directly related to a case aren’t billable, legal firms are especially incentivized
    to automate this overhead. LLMs might be used to respond to client or potential
    client communications, as an example. But the real value that LLMs could unlock
    is in the very meat and potatoes of lawyering: discovery and legal research, and
    document drafting.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 行政工作的接管远不止局限于医疗领域。根据2017年对美国2,915名法律专业人士的调查，律师大约有一半的时间花在行政工作上 [[4]](https://www.law.com/2017/09/26/what-do-lawyers-really-do-with-their-time/).
    大多数私人律师和律师事务所使用计费小时制度，员工们勤奋地追踪他们在特定案件上花费的时间，通常以六分钟为一个间隔。由于与法律实践管理相关的任务中不直接与案件相关的工作是不可计费的，因此律师事务所特别有动力自动化这部分开销。例如，LLM可以用来回应客户或潜在客户的沟通。但LLM真正能解锁的价值在于律师工作的核心：发现和法律研究，以及文件起草。
- en: '*Discovery* is “the formal process of exchanging information between the parties
    about the witnesses and evidence they’ll present at trial” [[5]](https://www.americanbar.org/groups/public_education/resources/law_related_education_network/how_courts_work/discovery/),
    and, depending on the lawsuit, can take months or years and involve the exchange
    of thousands of documents. E-discovery software applications, designed to help
    index these documents to locate salient information, have been a standard tool
    in legal practice for more than a decade. However, it typically relies on the
    user searching for a specific term, almost like a search engine for discovery
    materials. If prompted or fine-tuned for this task, LLMs could present brief summaries
    of documents, or even identify which materials support a particular argument.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “发现”是“在审判中双方之间交换关于他们将提供的证人和证据的正式程序”[[5]](https://www.americanbar.org/groups/public_education/resources/law_related_education_network/how_courts_work/discovery/)，根据诉讼的不同，可能需要数月或数年，并涉及数千份文件的交换。旨在帮助索引这些文件以定位重要信息的电子发现软件应用，已经超过十年成为法律实践中的标准工具。然而，它通常依赖于用户搜索特定术语，几乎就像一个发现材料的搜索引擎。如果被提示或微调来完成这项任务，LLMs可以提供文件的简要总结，甚至可以识别支持特定论点的材料。
- en: Another key component of practicing law is reading through case law and preceding
    decisions to draw comparisons and contrasts. Existing AI-based solutions already
    aim to find relevant decisions through techniques such as document embeddings
    and similarity (see chapter 1’s discussion of embeddings). Due to their rich internal
    representations, LLMs could do a better job of finding related cases and could
    also explain their similarities and differences, a feature that is well beyond
    the ability of non-LLM-based methods.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个法律实践的关键组成部分是阅读案例法和先前的判决，以进行比较和对比。现有的基于AI的解决方案已经通过诸如文档嵌入和相似性等技术来寻找相关的判决（参见第1章关于嵌入的讨论）。由于它们丰富的内部表示，LLMs可以更好地找到相关案例，并且还可以解释它们的相似性和差异性，这是非LLM方法远远无法做到的。
- en: 'Drafting documents is a more challenging but potentially transformative application
    of generative AI. Andrew Perlman, dean and professor at Suffolk University Law
    School, is the author of an article entitled “The Implications of ChatGPT for
    Legal Services and Society” published in Harvard Law School Center on the Legal
    Profession’s *The Practice* magazine. In reality, however, he has a coauthor:
    as Perlman freely admits, ChatGPT did most of the writing [[6]](https://clp.law.harvard.edu/article/the-implications-of-chatgpt-for-legal-services-and-society/).
    Within the piece, Perlman includes examples of ChatGPT-written drafts of a legal
    complaint, a will, and contracts pertaining to the sale of real estate and a car.
    Each was generated with a separate prompt—the prompt for the car contract reads
    as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 撰写文件是生成式AI更具挑战性但可能具有变革性应用的例子。萨福克大学法学院院长兼教授Andrew Perlman是发表在哈佛法学院法律职业中心《实践》杂志上的一篇文章《ChatGPT对法律服务和社会的影响》的作者。然而，实际上，他有一个合著者：正如Perlman坦白承认的那样，ChatGPT完成了大部分写作[[6]](https://clp.law.harvard.edu/article/the-implications-of-ChatGPT-for-legal-services-and-society/)。在文章中，Perlman包括了ChatGPT撰写的法律诉讼状、遗嘱以及与房地产和汽车销售相关的合同草稿。每个草稿都是通过单独的提示生成的——汽车合同的提示如下：
- en: Create a contract for the sale of a 2018 Toyota Prius from Jane Smith to John
    Doe in Massachusetts for the sale price of $15,000\. The contract should contain
    the usual representations and warranties of such a sale.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为2018年款丰田普锐斯（Toyota Prius）的出售，从Jane Smith到John Doe在马萨诸塞州的交易，价格为$15,000，创建一份合同。该合同应包含此类销售通常的陈述和保证。
- en: 'Assessing the chatbot’s responses, Perlman calls the legal documents incomplete,
    but surprisingly sophisticated. While ChatGPT won’t be replacing top lawyers anytime
    soon, Perlman says that Bing Chat is “already operating at the level of a B/B+
    law student, and it will only get better with time.” Like the doctors who used
    ChatGPT, however, he sees AI as a tool that will become essential in the legal
    profession:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 评估聊天机器人的回复时，Perlman称法律文件不完整，但出人意料地复杂。尽管ChatGPT不会很快取代顶尖律师，但Perlman表示，Bing Chat“已经达到B/B+法学学生的水平，并且随着时间的推移只会变得更好。”然而，就像使用ChatGPT的医生一样，他认为AI将成为法律职业中不可或缺的工具：
- en: AI will not eliminate the need for lawyers, but it does portend the end of lawyering
    as we know it. Many clients, especially those facing complex issues, will still
    need lawyers to offer expertise, judgment, and counsel, but those lawyers will
    increasingly need AI tools to deliver those services efficiently and effectively.
    [[6]](https://clp.law.harvard.edu/article/the-implications-of-chatgpt-for-legal-services-and-society/)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: AI不会消除律师的需求，但它预示着我们所知的律师行业的终结。许多客户，尤其是面临复杂问题的客户，仍然需要律师提供专业知识、判断力和咨询，但这些律师将越来越多地需要AI工具来高效有效地提供这些服务
    [[6]](https://clp.law.harvard.edu/article/the-implications-of-ChatGPT-for-legal-services-and-society/)
- en: Perlman also notes that 90% of low-income Americans and a majority of middle-income
    Americans receive “no meaningful assistance when facing important civil legal
    issues,” including child custody, eviction, foreclosure, and debt collection.
    If AI-powered tools could be safely used to explain in plain language what rights
    people were entitled to given their situation, as illustrated in figure 6.2, it
    could be an extremely powerful equalizer in these types of very common cases that
    aren’t typically legally complicated and have an enormous effect on people’s lives.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Perlman还指出，90%的低收入美国人和大多数中等收入美国人，在面临重要的民事法律问题时，“没有获得任何有意义的帮助”，包括儿童监护权、驱逐、抵押贷款违约和债务追收。如果AI驱动的工具可以安全地用普通语言解释人们根据其情况应享有的权利，如图6.2所示，它可以在这些非常常见的案件中成为一个极其强大的平衡器，这些案件通常不复杂，对人们的生活有巨大影响。
- en: '![](../../OEBPS/Images/CH06_F02_Dhamani.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F02_Dhamani.png)'
- en: Figure 6.2 Part of Bard’s response to a query from a renter about a dispute
    with their landlord
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 Bard对租户关于与房东纠纷的查询的部分回应
- en: LLMs augmenting financial investing and bank customer service
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLMs增强金融投资和银行客户服务
- en: In the financial industry, the gauntlet has been thrown by Bloomberg, the business
    and finance data, news, and analytics company, with the release of BloombergGPT.
    According to the press release, BloombergGPT is a 50-billion-parameter LLM trained
    on “a wide range of financial data” [[7]](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)
    and is designed for finance-related natural language processing tasks, presumably
    to help investment analysts process market news and information as quickly as
    possible. The effect of such a tool isn’t yet known, but in the world of high
    finance, any edge could potentially be worth billions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融行业，彭博社，一家商业和金融数据、新闻和分析公司，通过发布BloombergGPT发出了挑战。根据新闻稿，BloombergGPT是一个在“广泛金融数据”上训练的50亿参数LLM，旨在用于与金融相关的自然语言处理任务，预计可以帮助投资分析师尽可能快地处理市场新闻和信息。这种工具的影响尚不清楚，但在高金融领域，任何优势都可能潜在地价值数十亿。
- en: Banks have also long relied on chatbots for customer service, and an optimistic
    view is that LLMs could improve the quality of these interactions. According to
    the Consumer Financial Protection Bureau, 37% of the US population interacted
    with a bank’s chatbot in 2022, a staggering figure that is only projected to get
    larger, and all 10 of the largest banks in the country deploy chatbots on their
    websites. LLM-based chatbots could help address some of the existing problems,
    such as frustrating interactions where the bots don’t understand what the user
    wants or is trying to do. However, they also carry a greater risk of responding
    inappropriately, possibly by hallucinating about the bank’s offerings. Therefore,
    any financial usage should be vetted extremely thoroughly before deployment, especially
    given that incorrect responses may be a violation of consumer financial protection
    laws [[8]](https://www.consumerfinance.gov/about-us/newsroom/cfpb-issue-spotlight-analyzes-artificial-intelligence-chatbots-in-banking/).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 银行也长期依赖聊天机器人提供客户服务，一种乐观的观点是，LLMs可以提高这些互动的质量。根据消费者金融保护局的数据，2022年美国有37%的人口与银行的聊天机器人进行了互动，这个令人震惊的数字预计只会越来越大，并且该国的10家最大银行都在其网站上部署了聊天机器人。基于LLM的聊天机器人可以帮助解决一些现有问题，例如，当机器人不理解用户想要什么或试图做什么时的令人沮丧的互动。然而，它们也带来了更大的风险，可能会不适当地回应，例如对银行的提供内容进行幻觉。因此，在部署之前，任何金融用途都应该进行极其彻底的审查，尤其是考虑到不正确的回应可能违反消费者金融保护法
    [[8]](https://www.consumerfinance.gov/about-us/newsroom/cfpb-issue-spotlight-analyzes-artificial-intelligence-chatbots-in-banking/)。
- en: LLMs as collaborators in creativity
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLMs作为创造力的合作伙伴
- en: LLMs are most readily suited to generative tasks because of the probabilistic
    nature of their outputs—they can produce lots of different suitable responses,
    rather than a single “correct” answer. A Reddit thread surveying users on how
    they were using LLMs at their work included lots of descriptions of everyday tasks
    that people had successfully outsourced to chatbots [[9]](https://www.reddit.com/r/ChatGPT/comments/12fhcec/how_are_you_using_chatgpt_at_work/).
    Teachers have used them for creating lesson plans and teaching materials; social
    media marketers have used them to write short-form copy for networks such as Twitter
    and Instagram, and then expand the same key ideas into longer-form copy for blog
    posts.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs最适合生成性任务，因为它们的输出具有概率性质——它们可以产生许多不同的合适响应，而不是单一的“正确”答案。一个Reddit帖子调查了用户在工作场所如何使用LLMs，其中包含了许多描述人们如何成功将日常任务外包给聊天机器人的描述[[9]](https://www.reddit.com/r/ChatGPT/comments/12fhcec/how_are_you_using_ChatGPT_at_work/).
    教师们使用它们来创建教学计划和教学材料；社交媒体营销人员使用它们为Twitter和Instagram等网络撰写简短形式的文案，然后将相同的关键思想扩展为博客文章的更长形式。
- en: Naturally, then, LLMs are beginning to be used even more heavily in creative
    domains. Noah Brier, a serial entrepreneur in marketing and technology, launched
    BrXnd.ai to “explore the intersection between brands and AI” [[10]](https://brxnd.ai/).
    The organization’s inaugural event featured a competition billed as the first
    “ad Turing test,” where brand and advertising experts were tasked with identifying
    which of 10 posters advertising the same fictional energy drink were created by
    teams of marketing students and which were generated by AI [[11]](https://www.contagious.com/news-and-views/experts-stumped-by-ad-turing-test).
    A sample poster generated by AI is shown in figure 6.3.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，LLMs（大型语言模型）开始在创意领域被更加广泛地使用。Noah Brier，一位在营销和技术领域的连续创业者，推出了BrXnd.ai，旨在“探索品牌与AI的交汇点”[[10]](https://brxnd.ai/).
    该组织的首届活动是一场被称为首个“广告图灵测试”的竞赛，品牌和广告专家的任务是识别10张宣传同一虚构能量饮料的海报中，哪些是由市场营销学生团队创作的，哪些是由AI生成的[[11]](https://www.contagious.com/news-and-views/experts-stumped-by-ad-turing-test).
    图6.3展示了由AI生成的一张海报样本。
- en: '![](../../OEBPS/Images/CH06_F03_Dhamani.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH06_F03_Dhamani.png)'
- en: Figure 6.3 An AI-generated advertisement, created with the prompt “poster for
    a new energy drink called Buzz” by the open source image-generation model Stable
    Diffusion
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 一个由AI生成的广告，使用开源图像生成模型Stable Diffusion，以“新能量饮料Buzz的海报”为提示创建
- en: The expert panel achieved an accuracy of 57%; the 300-person audience could
    only tell the difference between the human-created and machine-created ads with
    53% accuracy, close to what we would expect from random guessing. Additionally,
    Brier submitted the ads generated with AI to System1, a marketing agency that
    measures people’s emotional response to ads at scale to predict their efficacy.
    The ads scored an average of 1.83 on the System1 rating scale, only slightly below
    the national average for a print advertisement, 1.9 [[12]](https://system1group.com/work).
    The teams that used AI were prevented from altering the model’s output in any
    way, and, in effect, the resulting ads were roughly indistinguishable from those
    conceived of, designed, and produced by humans. The models, of course, also generated
    their ads much more quickly, and could theoretically produce many different concepts
    within the same time that human teams took, for a lower cost.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 专家小组的准确率为57%；300人的观众只能以53%的准确率区分出人类创作的广告和机器生成的广告，接近我们预期的随机猜测水平。此外，Brier将AI生成的广告提交给了System1，这是一家衡量人们对广告情感反应的营销机构，以预测其效果。这些广告在System1评分标准上的平均得分为1.83，仅略低于全国印刷广告的平均水平1.9
    [[12]](https://system1group.com/work). 使用AI的团队被禁止以任何方式更改模型的输出，因此，生成的广告与由人类构思、设计和生产的广告在效果上大致无法区分。当然，模型生成广告的速度也更快，理论上可以在人类团队所需的时间内产生许多不同的概念，成本更低。
- en: 'However, the competition between humans and AI is a false one, as one of the
    teams demonstrated: they admitted from the outset that although they had been
    assigned to use AI, they used the models to generate assets, and then put the
    final poster together themselves. Brier took their ad out of the Turing test event,
    but still scored its emotional response with System1, and the human-AI collaboration
    received a higher score (2.8) than any entry produced by humans or AI alone. In
    an interview with Contagious about the results, Brier said that while he doesn’t
    expect AI to replace human creativity, “It is the most amazing creative accelerant
    I’ve ever experienced” [[11]](https://www.contagious.com/news-and-views/experts-stumped-by-ad-turing-test).
    Although working with AI tools might not be for everyone, in the best case, humans
    and machines can function as collaborators, combining human imagination with AI’s
    ability to synthesize inputs and generate outputs rapidly.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，人类与AI之间的竞争是一种虚假的竞争，正如一个团队所展示的：他们从一开始就承认，尽管他们被分配使用AI，但他们使用模型生成资产，然后自己制作最终的海报。Brier将他们的广告从图灵测试活动中移除，但仍然用System1对其情感反应进行了评分，而人机协作获得了比人类或AI单独产生的任何作品都高的评分（2.8）。在采访中，Brier关于结果表示，尽管他不期望AI取代人类的创造力，“这是我经历过的最令人惊叹的创造力加速剂”
    [[11]](https://www.contagious.com/news-and-views/experts-stumped-by-ad-turing-test)。尽管与AI工具合作可能不是每个人都适合的，但在最好的情况下，人类和机器可以作为合作伙伴工作，将人类的想象力与AI快速综合输入和生成输出的能力结合起来。
- en: 'Counterintuitively, LLMs seem to be good at almost exactly the opposite things
    that we expect computers to be good at. Where typical machines produce responses
    deterministically and excel at math and logic, LLMs and the chatbots they power
    sometimes make mistakes in math, or make up facts entirely. On the other hand,
    LLMs excel at writing poetry and making conversation. There are many traits that
    we consider to be so interconnected with our concept of humanity that it once
    seemed impossible for machines to display them—empathy and creativity chief among
    them. Now, chatbots can produce responses that not only display these traits but
    also sometimes outperform humans as evaluated by other humans. This accomplishment
    shouldn’t be diminished, nor should it be overstated: the chatbots aren’t themselves
    empathetic, but they have learned to produce empathetic messages.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与直觉相反，LLMs似乎擅长几乎正好与我们期望计算机擅长的事情相反。典型的机器以确定性产生响应，在数学和逻辑上表现出色，而LLMs和它们所驱动的聊天机器人有时会在数学上犯错误，或者完全编造事实。另一方面，LLMs在写诗和进行对话方面表现出色。有许多我们认为与我们对人性的概念紧密相连的特质，曾经似乎不可能让机器展现出来——同理心和创造力最为突出。现在，聊天机器人可以产生不仅显示出这些特质，而且有时在人类评估中甚至超越人类的响应。这一成就不应被贬低，也不应被过度夸大：聊天机器人本身并不具有同理心，但它们已经学会了产生同理心的信息。
- en: For now, chatbots are best viewed as tools that make professionals more efficient
    and productive. They are valuable—and might soon become invaluable—but their work
    might be incomplete, or they might not pick up on the types of details that an
    experienced professional might. In other ways, though, they already far outperform
    humans, such as their ability to correlate vast amounts of data. More effective
    than either the AI or the human alone is the human-AI “team,” with the AI providing
    an initial analysis or first draft, and the human reviewing their work. Already,
    this ability and other skills have made chatbots valuable in all manner of workplaces.
    This might be uncomfortable for many people, but it could also be liberating,
    enabling professionals to have more control over how they spend their time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，将聊天机器人视为使专业人士更高效和更有生产力的工具为宜。它们很有价值——并且可能很快变得无价——但它们的工作可能是不完整的，或者它们可能无法捕捉到经验丰富的专业人士可能会注意到的细节。然而，在其他方面，它们已经远远超过了人类，比如它们关联大量数据的能力。比单独的AI或人类更有效的是人机“团队”，其中AI提供初步分析或初稿，而人类则审查他们的工作。目前，这种能力和其他技能已经使聊天机器人在各种工作场所变得有价值。这可能对许多人来说是不舒服的，但它也可能是一种解放，使专业人士能够更多地控制他们如何度过他们的时间。
- en: LLMs as a programming sidekick
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs作为编程助手
- en: Perhaps unsurprisingly, many of the earliest adopters of LLMs are technologists
    and programmers. One of the most common practical applications of LLMs is as an
    aid in writing code. We’ve previously highlighted GitHub Copilot as the leading
    product in this space; Copilot is based on OpenAI’s Codex model, which has been
    fine-tuned for writing code on millions of GitHub repositories [[13]](https://ghdocs-prod.azurewebsites.net/en/copilot).
    Other code generation models include Amazon’s CodeWhisperer (see [http://mng.bz/QPAe](http://mng.bz/QPAe)),
    Replit’s Ghostwriter (see [http://mng.bz/XNvM](http://mng.bz/XNvM)), and the open
    source model StarCoder (see [http://mng.bz/yQlE](http://mng.bz/yQlE)). In some
    ways, writing code is easier for a model than other types of generative tasks
    because there is a lot of structure and repeating patterns. In prose, people rarely
    use the same phrases more than once, but we expect to see functions called multiple
    times in code. These models are designed to be pair programmers and provide “autocomplete-style
    suggestions” as you code. You can specify the language and write a natural language
    description, as a comment or docstring (used to document a specific segment of
    code) of what you want a function to do. The model will then take a pass at implementing
    that function. While there are certainly failure modes, especially for complex
    functions, it often does a reasonable first attempt, making it much quicker to
    iterate.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 也许并不令人意外，最早采用大型语言模型（LLM）的许多用户是技术专家和程序员。LLM最常见的一个实际应用是作为编写代码的辅助工具。我们之前已经强调GitHub
    Copilot是这个领域的领先产品；Copilot基于OpenAI的Codex模型，该模型经过微调，适用于在数百万个GitHub仓库中编写代码[[13]](https://ghdocs-prod.azurewebsites.net/en/copilot)。其他代码生成模型包括亚马逊的CodeWhisperer（见[http://mng.bz/QPAe](http://mng.bz/QPAe)）、Replit的Ghostwriter（见[http://mng.bz/XNvM](http://mng.bz/XNvM)）和开源模型StarCoder（见[http://mng.bz/yQlE](http://mng.bz/yQlE)）。在某种程度上，对于模型来说，编写代码比其他类型的生成任务更容易，因为代码有很多结构和重复的模式。在散文中，人们很少会重复使用相同的短语，但我们期望在代码中看到多次调用的函数。这些模型被设计成搭档程序员，并在你编写代码时提供“自动完成式建议”。你可以指定语言并写一个自然语言描述，作为注释或文档字符串（用于记录代码的特定段），说明你希望函数执行的操作。然后模型将尝试实现该函数。虽然确实存在失败模式，尤其是对于复杂的函数，但它通常能做出合理的初次尝试，这使得迭代过程变得更快。
- en: Generative models have been trained to interpret code, making it possible to
    use some LLMs as a computer terminal or command-line prompt or as toy databases.
    DiagramGPT, powered by GPT-4 and created by Eraser, a developer of brainstorming
    and diagram tools, is just one example of novel LLM-powered capabilities (see
    [http://mng.bz/MBNm](http://mng.bz/MBNm)). It takes a schema, infrastructure definition,
    or code snippet as input and produces a diagram for the system described so that
    a person unfamiliar with the code or schema can easily visualize what’s going
    on.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型已经被训练来解释代码，这使得可以使用一些LLM作为计算机终端或命令行提示符，或者作为玩具数据库。由Eraser公司（一家脑力激荡和图表工具的开发者）创建的、由GPT-4驱动的DiagramGPT是LLM新能力的例子之一（见[http://mng.bz/MBNm](http://mng.bz/MBNm)）。它接受一个模式、基础设施定义或代码片段作为输入，并为所描述的系统生成一个图表，以便不熟悉代码或模式的人可以轻松地可视化正在发生的事情。
- en: In keeping with the theme of using LLMs to take on rote tasks, another coding-related
    application that these models excel at is writing documentation. The usual privacy
    concerns apply—it’s inadvisable to paste proprietary code into an external application
    programming interface (API)—but for functions that aren’t sensitive, you can prompt
    Copilot or another LLM with the code and request that the model generate comments
    explaining the function, adding docstrings and type hints, and making other improvements
    that can make already-written code more readable. Figure 6.4\. depicts an example
    of an AI-generated docstring.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用LLM承担重复性任务的主题保持一致，这些模型在编写文档方面的另一个应用是它们在这方面表现出色。通常的隐私问题同样适用——将专有代码粘贴到外部应用程序编程接口（API）中是不明智的——但对于不敏感的函数，你可以提示Copilot或另一个LLM使用代码，并要求模型生成解释函数的注释，添加文档字符串和类型提示，以及进行其他改进，使已编写的代码更易于阅读。图6.4展示了由AI生成的文档字符串示例。
- en: '![](../../OEBPS/Images/CH06_F04_Dhamani.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F04_Dhamani.png)'
- en: Figure 6.4 The docstring produced by ChatGPT correctly describes the function
    given and each input.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 ChatGPT生成的文档字符串正确地描述了给定的函数及其每个输入。
- en: 'Some LLMs that aren’t designed explicitly for pair programming can also be
    coding resources. For example, regular expressions (regexes) are famously tricky
    but powerful paradigms in programming. A regex defines some criteria for a string
    of text and then provides functionality for fast and efficient searches for bits
    of text that match the criteria. Different characters can signify what characters
    to look for, how many characters to expect, and which parts of the string to ignore.
    Regexes are often used to parse out things such as email addresses or phone numbers.
    To illustrate, a regex for extracting email addresses looks like this: /^([a-z0-9_\.-]+)@([\da-z\.-]+)\.([a-z\.]{2,63})$/.
    Recently, one of us needed a rather messy regex and asked GPT-4 to write it for
    us. Not only did GPT-4 produce the correct regex, but the model was able to explain
    its own answer, and what each symbol in the regex represented. ChatGPT’s generation
    for a simpler regex is shown in figure 6.5; other people have reported using ChatGPT
    to write Excel macros in a similar fashion [[14]](https://www.adventuresincre.com/openai-gpt-3-excel-macro-real-estate-model/).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一些并非专门为配对编程设计的LLM也可以作为编码资源。例如，正则表达式（regexes）在编程中是著名的既复杂又强大的范式。正则表达式定义了一些文本字符串的准则，然后提供快速高效搜索匹配这些准则的文本片段的功能。不同的字符可以表示要查找的字符，预期的字符数量，以及要忽略的字符串部分。正则表达式通常用于解析诸如电子邮件地址或电话号码之类的信息。为了说明，提取电子邮件地址的正则表达式看起来像这样：/^([a-z0-9_\.-]+)@([\da-z\.-]+)\.([a-z\.]{2,63})$/.
    最近，我们中的一人需要一个相当混乱的正则表达式，并请求GPT-4为我们编写它。GPT-4不仅生成了正确的正则表达式，而且模型还能解释自己的答案，以及正则表达式中的每个符号代表什么。ChatGPT生成的一个更简单的正则表达式如图6.5所示；其他人也报告说使用ChatGPT以类似方式编写Excel宏
    [[14]](https://www.adventuresincre.com/openai-gpt-3-excel-macro-real-estate-model/)。
- en: '![](../../OEBPS/Images/CH06_F05_Dhamani.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F05_Dhamani.png)'
- en: Figure 6.5 A partial response from ChatGPT when prompted to give a regex for
    social media handles. The full response gave regexes for Twitter, Instagram, Facebook,
    and LinkedIn usernames. We note here that the regex is correctly described, but
    Twitter handles actually range from 4 to 15 characters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 当ChatGPT被提示给出社交媒体用户名的正则表达式时的一部分响应。完整的响应给出了Twitter、Instagram、Facebook和LinkedIn用户名的正则表达式。我们在此指出，正则表达式描述正确，但Twitter用户名的长度实际上是从4个字符到15个字符不等。
- en: Writing code is a collaborative endeavor, in that people have always shared,
    reused, and repurposed code. Consider Stack Exchange, mentioned in chapter 2 as
    a popular data source for training LLMs. Its flagship Q&A website, Stack Overflow,
    is devoted to people asking each other questions about snippets of code—usually,
    question askers describe what they are trying to do, paste a few lines of code
    that reproduces the error that they are running into, and then wait for knowledgeable
    people to respond. The best answers on Stack Overflow provide not only the corrected
    code snippet but also detailed explanations about why the original poster’s attempt
    failed, perhaps due to concepts they misunderstood or quirks of particular programming
    languages. LLMs could serve functionally the same purpose as a community of millions
    of people and provide answers faster than the fastest of Stackers.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码是一项协作性的工作，因为人们一直都在共享、重用和重新利用代码。考虑一下第2章中提到的Stack Exchange，它是一个流行的LLM训练数据源。其旗舰问答网站Stack
    Overflow致力于人们相互询问关于代码片段的问题——通常，提问者会描述他们试图做什么，粘贴几行代码以重现他们遇到的问题，然后等待有知识的人回答。Stack
    Overflow上最好的答案不仅提供了修正后的代码片段，而且还详细解释了为什么原始发帖者的尝试失败，可能是由于他们误解了某些概念或特定编程语言的怪癖。LLM可以发挥与数百万人的社区相同的功能，并且比最快的Stacker提供答案更快。
- en: In the world of LLM coding assistants, expertise still matters. Copilot can
    produce programs like a human because it was trained on human-written code. Just
    like human-generated code, though, its solutions might be inefficient or may fail
    to consider edge cases. LLMs are specialists in reproducing coding patterns and
    styles, but developers still need to exercise critical thinking around the composition
    and requirements of a given program. Knowledge of core concepts of computer science
    and best practices in software engineering may, if anything, become even more
    important, with LLMs capable of doing most boilerplate scripting. We expect that
    in the near term, the greatest utility will be derived from programmers leaning
    on LLMs such as Copilot to speed up their workflow and learn about specific syntaxes
    or libraries quickly, rather than from LLMs replacing programmers entirely.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM编码助手的世界里，专业知识仍然很重要。Copilot能够像人类一样生成程序，因为它是在人类编写的代码上训练的。然而，就像人类编写的代码一样，它的解决方案可能效率低下，或者可能没有考虑到边缘情况。LLM是复制编码模式和风格的专家，但开发者仍然需要在给定程序的组成和要求方面进行批判性思考。计算机科学的核心概念和软件工程的最佳实践，如果有什么的话，可能变得更加重要，因为LLM能够完成大部分样板脚本。我们预计，在短期内，最大的效用将来自于程序员依靠Copilot等LLM来加速他们的工作流程并快速了解特定的语法或库，而不是LLM完全取代程序员。
- en: LLMs in daily life
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日常生活中的LLM
- en: Although we’ve discussed at length the possible uses of generative models, the
    best method of uncovering applications is through experimentation. In addition
    to using LLMs to either speed up or replace parts of professional workflows, people
    have found all manners of ways to use the models for hobbies, projects, self-improvement,
    education, and entertainment. We expect that as users become familiar with these
    tools, and share their experiences, novel use cases will emerge as the design
    and capabilities of generative models continue to evolve. In this section, we’ll
    explore the ways that people are using generative models in their daily lives.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经详细讨论了生成模型的潜在用途，但揭示应用的最佳方法还是通过实验。除了使用大型语言模型（LLM）来加速或替代部分专业工作流程之外，人们还找到了各种方法来利用这些模型进行爱好、项目、自我提升、教育和娱乐。我们预计，随着用户对这些工具的熟悉和经验的分享，随着生成模型的设计和能力持续发展，新的用例将会出现。在本节中，我们将探讨人们如何在日常生活中使用生成模型。
- en: Communal prompting
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 共享提示
- en: 'Online resources abound for sharing interesting or especially fruitful prompts
    for LLMs. The practice of structuring and refining prompts to elicit certain types
    of responses from LLMs is called *prompt engineering*. PromptHero bills itself
    as the “#1 website for prompt engineering” and showcases millions of AI-generated
    images and texts along with the prompts that produced them (see [https://prompthero.com/](https://prompthero.com/)).
    PromptHero and other websites like it address a real need: the prompts given to
    LLMs and image-generation models affect the outputs quite a bit and sometimes
    in unpredictable ways. Communities of users sharing their best prompts allow those
    users to iterate more quickly and get better results, especially while prompting
    continues to be both powerful and not well understood.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在线资源丰富，用于分享对LLM有趣或特别有成效的提示。将提示结构化和细化以从LLM中获得特定类型响应的实践被称为*提示工程*。PromptHero自称是“#1提示工程网站”，展示了数百万由AI生成的图像和文本及其产生的提示（见[https://prompthero.com/](https://prompthero.com/））。PromptHero和其他类似网站解决了实际需求：提供给LLM和图像生成模型的提示会相当大地影响输出，有时甚至以不可预测的方式。用户社区分享他们最好的提示，使得这些用户能够更快地迭代并获得更好的结果，尤其是在提示仍然强大但理解不足的情况下。
- en: Stack Overflow is only one of a variety of services that people have suggested
    might be replaced entirely by LLMs. It’s also possible that these services will
    either integrate LLMs into their offerings or simply continue to exist as an alternative.
    We know that LLMs can perform translation, so Google Translate might not be needed
    as much on its own, but the language-learning app Duolingo has already launched
    an integration with GPT-4\. With Duolingo Max, the LLM provides explanations for
    incorrect answers and lets users role-play their own scenarios, rather than simply
    participating in conversations written by Duolingo [[15]](https://blog.duolingo.com/duolingo-max/).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Stack Overflow只是人们建议可能完全被LLMs取代的众多服务之一。也有可能这些服务将要么将LLMs整合到他们的产品中，要么简单地作为替代品继续存在。我们知道LLMs可以进行翻译，因此Google
    Translate可能不再那么必要，但语言学习应用Duolingo已经推出了与GPT-4的集成。在Duolingo Max中，LLM为错误答案提供解释，并允许用户进行角色扮演自己的场景，而不仅仅是参与Duolingo编写的对话[[15]](https://blog.duolingo.com/duolingo-max/)。
- en: 'One of the areas with the most potential to be affected by LLMs is education,
    including but not limited to language learning. While we’ll delve more deeply
    into the structural effect of generative AI on education in the next section,
    here we’ll also highlight how the applications we’ve discussed previously can
    be applied to self-teaching new concepts. In chapter 1, we compared the success
    of various LLMs at summarization and question-answering tasks. People interested
    in brushing up on history or following the latest developments in some scientific
    field or ongoing political conflict could ask LLMs to provide accessible summaries
    for them (see chapter 5, section Hallucinations for a discussion of retrieval).
    Students have successfully used LLMs to explain concepts as a means of exam prep:
    similar to Stack Exchange but more irreverent, the subreddit ELI5 (for “Explain
    like I’m five”) is filled with questions that posters want the answers to, including
    queries about machines, animals and nature, physics and the universe, and a whole
    bunch of assorted topics. As shown in figure 6.6, a student preparing for a physics
    exam might use the prompt “Explain string theory in simple terms” to grasp the
    basics of difficult concepts and could then ask follow-up questions on any aspects
    that they were struggling with (of course, it would be wise to double-check the
    responses with a credible source).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）最有可能受到影响的一个领域是教育，包括但不限于语言学习。虽然我们将在下一节更深入地探讨生成式AI对教育结构的影响，但在这里我们也将强调我们之前讨论的应用如何应用于自学新概念。在第1章中，我们比较了各种LLMs在总结和问答任务中的成功情况。对历史感兴趣或想了解某些科学领域最新发展或持续的政治冲突的人可以要求LLMs为他们提供易于理解的总结（参见第5章，关于幻觉的讨论）。学生已经成功使用LLMs来解释概念，作为考试准备的手段：类似于Stack
    Exchange但更加不拘一格，ELI5（“像对我五岁孩子解释”的缩写）subreddit充满了发帖者想要得到答案的问题，包括关于机器、动物和自然、物理和宇宙以及一大堆各种主题的查询。如图6.6所示，一个准备物理考试的学生可能会使用提示“用简单的话解释弦理论”来掌握困难概念的基本知识，然后可以就他们遇到的任何困难方面提出后续问题（当然，最好与可信来源双重检查回答）。
- en: '![](../../OEBPS/Images/CH06_F06_Dhamani.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F06_Dhamani.png)'
- en: Figure 6.6 The partial response of ChatGPT to a prompt about string theory
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 ChatGPT对一个关于弦理论的提示的部分响应
- en: 'Today, most people look for information about products and services to buy
    primarily via search engines and sometimes review sites or large online retailers.
    When we’re looking for something to do, we might search for events in our local
    area this weekend, movies that are out in theaters, or shows that are popular
    on streaming services. When we’re about to make a large purchase—let’s say expensive
    cookware—there is often a fair amount of research involved: you might first Google
    for the best slow cooker, then click on a few options on Amazon, and read their
    reviews and ratings. Or, you might prefer to read reviews in home-related magazines
    or newspapers instead, and then buy the selected option from the retailer’s website.
    Although chatbots that don’t perform retrieval (web search) will be of limited
    value when it comes to new products, bots that do can synthesize this information
    as a sort of shopping assistant, like Bard’s response in figure 6.7.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，大多数人主要通过搜索引擎寻找有关要购买的产品和服务的相关信息，有时也会查看评论网站或大型在线零售商。当我们寻找周末要参加的活动时，我们可能会搜索当地地区的事件、电影院上映的电影或流媒体服务上流行的节目。当我们即将进行大额购买——比如说昂贵的厨具——时，通常需要进行相当多的研究：你可能会首先在谷歌上搜索最好的慢炖锅，然后在亚马逊上点击几个选项，并阅读它们的评论和评分。或者，你可能更喜欢在家居相关的杂志或报纸上阅读评论，然后从零售商的网站上购买所选选项。尽管不执行检索（网络搜索）的聊天机器人在新产品方面价值有限，但执行检索的机器人可以将这些信息综合起来作为购物助手，就像图6.7中Bard的回应一样。
- en: '![](../../OEBPS/Images/CH06_F07_Dhamani.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F07_Dhamani.png)'
- en: Figure 6.7 Bard’s partial response to a query about possible grills to purchase.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 Bard对关于可能购买的烧烤架查询的部分回应。
- en: Indeed, this is the ultimate vision for virtual assistants, which began with
    natural-language assistants including Siri and Alexa. However, Siri, Alexa, and
    Google Assistant are (at least for now) “command-and-control systems,” meaning
    that they understand a finite list of requests, and can’t respond intelligently
    to requests outside of that list—they will simply decline to answer. LLM-powered
    chatbots, on the other hand, will by default respond to any question or request,
    if sometimes too confidently. That said, because of the relatively controlled
    manner in which the command-and-control systems operate, these assistants have
    already been connected to various other systems, whether to make adjustments in
    the home (turning off lights, changing thermostat settings) or to make purchases
    on Amazon.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这是虚拟助手的终极愿景，这一愿景始于包括Siri和Alexa在内的自然语言助手。然而，Siri、Alexa和Google Assistant目前（至少目前）是“命令和控制系统”，这意味着它们只能理解有限列表中的请求，并且无法对列表之外的请求做出智能响应——它们会简单地拒绝回答。另一方面，由LLM（大型语言模型）驱动的聊天机器人默认情况下会对任何问题或请求做出回应，尽管有时过于自信。尽管如此，由于命令和控制系统相对受控的运行方式，这些助手已经连接到各种其他系统，无论是为了在家中进行调整（如关闭灯光、更改恒温器设置）还是为了在亚马逊上购物。
- en: In AI, an *agent* is a system that can pursue goals flexibly [[16]](https://www.lesswrong.com/posts/dcoxvEhAfYcov2LA6/agentized-llms-will-change-the-alignment-landscape).
    In effect, this means that the system must be able to interact with its environment
    and respond to changes in the environment. Capabilities such as changing the light
    settings or online shopping are examples of interacting with an environment—in
    this case, the real world. Siri and Alexa aren’t agents because they don’t adapt
    their goals, which is required to perform complex, multistep tasks. For example,
    let’s say that you ask Siri to recommend an outfit for you based on the weather
    forecast for your specific location as well as your agenda for the day. The assistant
    will be able to retrieve the weather but can’t execute the plan of retrieving
    the weather, reading your calendar, and then coming up with a reasonable suggestion
    for articles of clothing unless specifically programmed to do so. On the other
    hand, an LLM could break down the task into its component parts. If asked, it
    could likely respond with the steps required, and, if enabled to retrieve weather
    data and calendar information, could perform each step in a sequence. Accessing
    external data or using APIs to respond to a query is an example of agentic or
    agentized behavior in LLMs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能领域，*代理*是一个能够灵活追求目标的系统 [[16]](https://www.lesswrong.com/posts/dcoxvEhAfYcov2LA6/agentized-llms-will-change-the-alignment-landscape)。实际上，这意味着系统必须能够与其环境互动并对环境的变化做出响应。例如，改变灯光设置或在线购物都是与环境互动的例子——在这种情况下，是现实世界。Siri和Alexa不是代理，因为它们不会调整自己的目标，而这对于执行复杂的多步骤任务是必需的。例如，假设你要求Siri根据你所在位置的天气预报以及你当天的日程为你推荐一套服装。助手能够获取天气信息，但不能执行检索天气、阅读你的日历并据此提出合理的服装建议的计划，除非特别编程来这样做。另一方面，一个LLM可以将任务分解为其组成部分。如果被要求，它可能会提供所需的步骤，并且如果能够检索天气数据和日历信息，它将能够按顺序执行每个步骤。访问外部数据或使用API来响应查询是LLM中代理或代理化行为的例子。
- en: Agent is a system that can pursue goals flexibly, where the system must be able
    to interact with its environment and respond to changes in the environment.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是一个能够灵活追求目标的系统，其中系统必须能够与其环境互动并对环境的变化做出响应。
- en: Agentizing LLMs is the next logical step in several existing commercial applications.
    For example, Expedia, a travel planning website, has an integration with ChatGPT
    that enables users to have open-ended conversations with the bot to get flight,
    hotel, and activity recommendations for their planned trips [[17]](https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx).
    The bot doesn’t actually book these recommendations, but all that would be required
    would be connecting the model to some sort of payment API. Of course, there are
    many valid reasons for not yet doing this; the bot might hallucinate flights that
    don’t exist or misunderstand users’ preferences. But it’s only a matter of time
    before applications like this become a reality. We’ll dig into more details about
    how agentized LLMs work in chapter 8.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将大型语言模型（LLM）代理化是现有几个商业应用中的下一个逻辑步骤。例如，Expedia，一个旅行规划网站，已经与ChatGPT进行了集成，使用户能够与机器人进行开放式对话，以获取他们计划旅行所需的航班、酒店和活动推荐
    [[17]](https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/ChatGPT-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx)。机器人实际上并不会预订这些推荐，但只需将模型连接到某种支付API即可。当然，目前还没有这样做有许多合理的理由；机器人可能会幻想出不存在的航班或误解用户的偏好。但这样的应用成为现实只是时间问题。我们将在第8章中深入探讨代理化LLM的工作原理。
- en: 'Already, there has been a flurry of activity in the open source world in agentizing
    LLMs. Projects such as LangChain (see [http://mng.bz/a1WY](http://mng.bz/a1WY))
    focus on the development of applications around LLMs that are both agentic, that
    is, interacting with an environment, and data-aware, meaning that they can access
    external data sources. Auto-GPT is an open source project that describes itself
    as “push[ing] the boundaries of what is possible with AI” by prompting GPT-4 to
    perform long-term planning for goal achievement. For now, this is still very challenging
    for AI, even GPT-4: Auto-GPT’s documentation reads in its section on limitations,
    “May not perform well in complex, real-world business scenarios. In fact, if it
    actually does, please share your results!” [[18]](https://github.com/Significant-Gravitas/Auto-GPT).
    Despite the lofty ambitions of Auto-GPT, models of today tend to get stuck on
    intermediate steps or forget their previous work. The execution aspect isn’t there
    yet, but it seems imminent that more people will test it out on a limited number
    of tasks, and LLMs already have shown some utility in generating plans given specified
    objectives.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 已经，开源世界在将LLM代理化的方面已经出现了一阵活跃。例如LangChain（见[http://mng.bz/a1WY](http://mng.bz/a1WY)）等项目专注于围绕LLM开发既具有代理性（即与环境交互）又具有数据感知性（即可以访问外部数据源）的应用。Auto-GPT是一个开源项目，它将自己描述为通过提示GPT-4进行长期规划以实现目标，从而“推动AI可能性的边界”。目前，即使是GPT-4，这也仍然是非常具有挑战性的：Auto-GPT的文档在其关于限制的部分中写道，“可能在复杂、现实世界的商业场景中表现不佳。实际上，如果它真的做到了，请分享你的结果！”
    [[18]](https://github.com/Significant-Gravitas/Auto-GPT)。尽管Auto-GPT有着宏伟的抱负，但今天的模型往往会在中间步骤上卡住或忘记之前的工作。执行方面尚未实现，但似乎更多的人将开始在有限的任务上测试它，而LLM在根据特定目标生成计划方面已经显示出一些实用性。
- en: 'For the more productivity-minded among us, chatbots might provide a structured
    plan for achieving goals, such as sticking to an exercise regimen or getting weekly
    chores done. Bryan X. Chen, the lead consumer technology writer for the *New York
    Times*, explains that for best results, you should reference a particular self-help
    book with advice relevant to the task, to steer the chatbot in the right direction
    [[19]](https://www.nytimes.com/2023/06/23/technology/ai-chatbot-life-coach.xhtml).
    Chen uses the example of aiming to run a marathon. The prompt that he suggests
    reads:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们中那些更注重生产力的人来说，聊天机器人可能提供了一种实现目标的结构化计划，例如坚持锻炼计划或完成每周的家务。纽约时报的主要消费技术作家Bryan
    X. Chen解释说，为了获得最佳效果，你应该参考一本与任务相关的特定自助书籍的建议，以引导聊天机器人走向正确的方向 [[19]](https://www.nytimes.com/2023/06/23/technology/ai-chatbot-life-coach.xhtml)。Chen以目标为跑马拉松为例。他建议的提示如下：
- en: 'I want you to act as a life coach. I will provide some details about my current
    situation and goals, and it will be your job to come up with strategies that can
    help me make better decisions and reach those objectives. This could involve offering
    advice on various topics, such as creating plans for achieving success or dealing
    with difficult emotions. My first request is: My goal this fall is to run a marathon.
    Come up with a three-month plan using the principles of the book “Slow AF Run
    Club.”'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我想让你扮演一个生活教练的角色。我会提供一些关于我当前情况和目标的具体细节，而你的任务是提出可以帮助我做出更好决策并实现这些目标的策略。这可能包括在各个主题上提供建议，例如制定实现成功的计划或处理困难情绪。我的第一个请求是：今年秋天我的目标是跑一场马拉松。请根据《Slow
    AF Run Club》一书的原理制定一个三个月的计划。
- en: This prompt is descriptive, relies on a trusted source, and provides examples
    of the kinds of responses Chen is seeking. A simpler prompt, such as “Write me
    a marathon training plan,” will also yield results with ChatGPT, but they might
    not align as well with what Chen was looking for. Because the plan is generated
    by an LLM instead of posted on a website, the user could also ask for as many
    tweaks as they wanted until they were happy with the results. Theoretically, this
    might be used for achieving any type of goal.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示是描述性的，依赖于可信的来源，并提供了陈所寻求的响应类型的示例。一个更简单的提示，例如“为我写一个马拉松训练计划”，在ChatGPT上也会产生结果，但它们可能不会与陈所寻找的结果完全一致。由于该计划是由LLM生成而不是在网站上发布的，用户也可以要求进行尽可能多的调整，直到他们对结果满意。从理论上讲，这可以用来实现任何类型的目标。
- en: Finally, LLMs are of course used for all kinds of writing-related tasks. As
    generative models, they are well-suited for volleying ideas and brainstorming
    as you would a writing partner. LLMs will occasionally produce funny or creative
    texts, especially given an interesting prompt or one set to high temperature,
    but often—given the probabilistic generation of likely tokens—their generations
    are, well, predictable. This makes them also ideal candidates for the type of
    formulaic writing that many of us do daily, such as emails, meeting notes, and
    performance reviews.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，LLMs当然被用于各种与写作相关的任务。作为生成模型，它们非常适合像对待写作伙伴一样进行思想交流和头脑风暴。LLMs偶尔会生成有趣或富有创意的文本，尤其是在给出有趣的提示或将其设置为高温时，但通常——鉴于可能生成的标记的概率性——它们的生成是，嗯，可预测的。这使得它们也成为我们日常进行的公式化写作的理想人选，例如电子邮件、会议记录和绩效评估。
- en: In section Professional Applications, we noted that evidence shows that even
    doctors spend a lot of time doing administrative tasks rather than interfacing
    directly with patients. The late anthropologist David Graeber documented the explosion
    of pointless paperwork, reports, and so-called “box-ticking” exercises in the
    past several decades in his best-selling book *Bullshit Jobs*. Though Graeber
    has his own theories about why box-ticking jobs seem to abound in today’s economy,
    it’s true that despite an ever-present specter of a leisure-filled future brought
    about by technological progress, we haven’t made great strides in this direction.
    John Maynard Keynes predicted in 1930 that within a century, people would mostly
    be fighting against boredom rather than fatigue, and would perhaps work three
    or so hours a day just to feel productive.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在“专业应用”这一章节中，我们提到证据显示，即使是医生也花费大量时间处理行政任务，而不是直接与患者互动。已故的人类学家大卫·格雷伯在其畅销书《无聊工作》中记录了过去几十年中无意义的文书工作、报告以及所谓的“打勾”练习的激增。尽管格雷伯有自己的理论来解释为什么在当今经济中“打勾”工作似乎无处不在，但事实是，尽管科技进步带来的充满休闲的未来一直存在，但我们在这方面的进步并不大。约翰·梅纳德·凯恩斯在1930年预测，在一百年内，人们将主要是在与无聊作斗争，而不是与疲劳作斗争，也许每天只需工作三小时左右就能感到自己有所成就。
- en: Needless to say, Keynes’ prediction hasn’t come to fruition. The hopeful outlook
    is that with LLMs, office workers everywhere could outsource some of the duller
    or more formulaic work to models and focus their energies on what interests them
    most. At the same time, there exists an interesting feedback cycle where the less
    high-quality, human-generated content is available, the more steadily models might
    degrade. A 2023 paper shows that a significant percentage of crowd workers who
    are responsible for labeling AI outputs are themselves using AI [[20]](https://www.technologyreview.com/2023/06/22/1075405/the-people-paid-to-train-ai-are-outsourcing-their-work-to-ai/).
    It’s hard to begrudge any of them for leaning on AI for their work, but if model-generated
    text becomes the norm on the internet, it could have big implications for future
    LLMs trained on internet data, as well as the experience of surfing the web. We
    would see comparatively less original content, whether that content is insightful
    cultural commentary or an innovative meme format. We may enter a phase wherein
    services such as coaching, creative copywriting, and personal training become
    premium experiences, with LLMs providing a lower-cost alternative. Ultimately,
    these tools are excellent resources, but, to date, there is no substitute for
    human experience and ingenuity.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 不言而喻，凯恩斯的预测并未实现。有希望的是，随着大型语言模型（LLMs）的出现，全世界的办公室工作人员可以将一些枯燥或公式化的工作外包给模型，并将精力集中在他们最感兴趣的事情上。同时，存在一个有趣的反馈循环：高质量的人类生成内容越少，模型可能退化得越快。2023年的一篇论文显示，负责为AI输出进行标注的众包工作者中，有相当一部分人自己也在使用AI
    [[20]](https://www.technologyreview.com/2023/06/22/1075405/the-people-paid-to-train-ai-are-outsourcing-their-work-to-ai/)。很难责怪他们依赖AI来完成工作，但如果模型生成的文本成为互联网上的常态，这可能会对基于互联网数据进行训练的未来LLMs以及上网体验产生重大影响。我们可能会看到原创内容相对较少，无论是深刻的文化评论还是创新的梗格式。我们可能会进入一个阶段，其中像教练、创意文案写作和个人训练等服务成为高端体验，而LLMs则提供低成本替代方案。最终，这些工具是极好的资源，但到目前为止，人类经验和独创性还没有替代品。
- en: Generative AI’s footprint on education
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式AI在教育领域的足迹
- en: As with any “revolutionary” technology, ChatGPT caused some people’s jaws to
    drop and others’ brows to furrow. Its release was met with concern and criticism
    from some educators who feared that students could misuse the tool for cheating
    on assignments. Albeit prematurely, *The Atlantic*, an American magazine, went
    so far as to say that it’s “The End of High School English” [[21]](https://www.theatlantic.com/technology/archive/2022/12/openai-chatgpt-writing-high-school-english-essay/672412/)
    and “The College Essay Is Dead” [[22]](https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/).
    Ethan Mollick, a professor at the University of Pennsylvania’s Wharton School
    of Business, tweeted, “AI has basically ruined homework” [[23]](https://twitter.com/emollick/status/1603762000815091714?s=20&t=fVkX0l5OhVN2Pfp3Wfymow).
    In a frenzy, schools started responding to these fears by blocking access to the
    chatbot. Citing “concerns about negative impacts on student learning, and concerns
    regarding the safety and accuracy of content,” the New York City education department
    blocked access to ChatGPT on all department devices and networks [[24]](https://ny.chalkbeat.org/2023/1/3/23537987/nyc-schools-ban-chatgpt-writing-artificial-intelligence).
    Meanwhile, Peter Wang, cofounder and CEO of Anaconda, tweeted, “I think we can
    basically re-invent the concept of education at scale. College as we know it will
    cease to exist” [[25]](https://twitter.com/pwang/status/1599520310466080771).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何“革命性”的技术一样，ChatGPT让一些人瞠目结舌，也让另一些人皱起了眉头。它的发布引起了一些教育工作者的担忧和批评，他们担心学生可能会滥用这个工具来完成作业。尽管有些过早，但美国杂志《大西洋》甚至说这是“高中英语的终结”
    [[21]](https://www.theatlantic.com/technology/archive/2022/12/openai-ChatGPT-writing-high-school-english-essay/672412/)
    和“大学论文的终结” [[22]](https://www.theatlantic.com/technology/archive/2022/12/ChatGPT-ai-writing-college-student-essays/672371/)。宾夕法尼亚大学沃顿商学院的教授伊森·莫利克在推特上写道，“AI基本上毁了家庭作业”
    [[23]](https://twitter.com/emollick/status/1603762000815091714?s=20&t=fVkX0l5OhVN2Pfp3Wfymow)。在一片混乱中，学校开始对这些担忧做出回应，封锁了对聊天机器人的访问。纽约市教育局以“对学生学习产生负面影响”和“对内容的安全性和准确性表示担忧”为由，封锁了所有部门设备和网络对ChatGPT的访问
    [[24]](https://ny.chalkbeat.org/2023/1/3/23537987/nyc-schools-ban-ChatGPT-writing-artificial-intelligence)。与此同时，Anaconda的联合创始人兼首席执行官王鹏在推特上写道，“我认为我们可以基本上重新发明大规模教育的概念。我们所知道的大学将不复存在”
    [[25]](https://twitter.com/pwang/status/1599520310466080771)。
- en: For some educators, cheating is a practical fear—students are using ChatGPT
    to write essays and research papers, as well as solve math and science word problems,
    plagiarizing the AI-written work. Teachers and school administrators were caught
    off guard by the chatbot’s abilities, as they scrambled not only to catch students
    who were using the tool to cheat but also revamp their lesson plans accordingly.
    Some teachers are worried that students will never need to learn to write or be
    able to start an essay or paper from scratch. Adding to their concerns, the answers
    generated by ChatGPT and similar tools aren’t always accurate (see chapter 5,
    section Hallucinations). The chatbot tends to make up citations, include inaccurate
    facts, or repeatedly reference the same source—but the information can often be
    so specific and plausible-sounding that it can be an added step for teachers to
    carefully verify and corroborate the references and facts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些教育工作者来说，作弊是一个实际的担忧——学生们正在使用ChatGPT来撰写论文和研究报告，以及解决数学和科学词汇问题，剽窃AI生成的作品。教师和学校管理者对聊天机器人的能力感到措手不及，他们不仅忙于捕捉使用该工具作弊的学生，还要相应地修改课程计划。一些教师担心学生将永远不需要学习写作，或者无法从头开始撰写论文。更令他们担忧的是，ChatGPT和类似工具生成的答案并不总是准确的（参见第5章，幻觉部分）。聊天机器人倾向于编造引文，包含不准确的事实，或者反复引用同一来源——但信息往往非常具体且听起来合理，这可能会让教师额外的一步是仔细验证和核实引文和事实。
- en: While some teachers have prohibited the use of ChatGPT, others have embraced
    the tool. For one, the chatbot is hardly an A+ student—it’s an excellent synthesizer,
    but not a critical thinker [[26]](http://www.brookings.edu/blog/education-plus-development/2023/01/09/chatgpt-educational-friend-or-foe/).
    Secondly, with or without ChatGPT, stopping cheating entirely is likely an impossible
    task. ChatGPT is just another tool to aid in cheating, similar to ordering essays
    online from Kenyan workers [[27]](https://www.bbc.com/news/blogs-trending-58465189)
    or copying answers on online exams from Chegg, an edtech company that provides
    homework help and other student services [[28]](https://www.cnbc.com/2021/03/21/how-college-students-learned-new-ways-to-cheat-during-covid-.xhtml).
    Finally, banning the use of ChatGPT will *just not work*. Students can easily
    cheat the system by accessing the tool outside of class, on their personal devices,
    or perhaps by using a virtual private network (VPN) on school networks. Of course,
    teachers and school administrators who forbid using tools like ChatGPT will expect
    some students to use them anyway, so they will need to quickly find ways to detect
    content that is machine-generated, which as we’ve discussed previously (and we’ll
    further discuss in the next section), is a *very* difficult problem. Tools to
    classify text as machine-generated, such as OpenAI’s classifier and GPTZero (see
    [https://gptzero.me/](https://gptzero.me/)), are unreliable and limited in nature.
    If students edit the machine-generated text, then these tools can also be easily
    evaded. On the other hand, if teachers solely rely on such tools to catch cheating,
    then they may falsely identify the text as machine-generated, putting a student’s
    academic career in jeopardy.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些教师禁止使用ChatGPT，但其他人却拥抱了这个工具。一方面，这个聊天机器人几乎算不上一个A+学生——它是一个出色的综合者，但不是一个批判性思考者
    [[26]](http://www.brookings.edu/blog/education-plus-development/2023/01/09/ChatGPT-educational-friend-or-foe/).
    另一方面，无论是否有ChatGPT，完全停止作弊可能是一项不可能完成的任务。ChatGPT只是帮助作弊的另一个工具，类似于从肯尼亚工人那里在线订购论文 [[27]](https://www.bbc.com/news/blogs-trending-58465189)
    或者在Chegg（一家提供家庭作业帮助和其他学生服务的教育科技公司）的在线考试中抄袭答案 [[28]](https://www.cnbc.com/2021/03/21/how-college-students-learned-new-ways-to-cheat-during-covid-.xhtml).
    最后，禁止使用ChatGPT将*根本不起作用*。学生可以轻易地通过在课外、在他们的个人设备上，或者在学校网络上使用虚拟私人网络（VPN）来绕过系统作弊。当然，禁止使用像ChatGPT这样的工具的教师和学校管理者会预期一些学生仍然会使用它们，因此他们需要迅速找到方法来检测机器生成的内容，正如我们之前所讨论的（我们将在下一节进一步讨论），这是一个*非常*困难的问题。将文本分类为机器生成的工具，如OpenAI的分类器和GPTZero（见[https://gptzero.me/](https://gptzero.me/)），是不可靠的，并且本质上有限。如果学生编辑了机器生成的文本，那么这些工具也可以轻易地被规避。另一方面，如果教师仅仅依赖这些工具来捕捉作弊，那么他们可能会错误地将文本识别为机器生成的，从而危及学生的学术生涯。
- en: Not too long after ChatGPT’s public debut, a survey from Stanford University
    suggested that students were already using the tool to complete assignments and
    exams [[29]](https://stanforddaily.com/2023/01/22/scores-of-stanford-students-used-chatgpt-on-final-exams-survey-suggests/).
    As some colleges grapple with the emergence of ChatGPT, many have already incorporated
    the usage of generative AI tools in their academic integrity policies and provided
    guidance for teachers for incorporating AI tools in the classroom [[30]](https://www.uvm.edu/wid/artificial-intelligence)
    [[31]](https://ctl.wustl.edu/resources/chatgpt-and-ai-composition-tools/). In
    the same vein, many educators advocating for ChatGPT in academia believe that,
    if used appropriately, it can be an effective teaching tool. Ditch That Textbook,
    a teaching blog, lists a multitude of ways that ChatGPT (or similar tools) can
    be used to enhance the learning experience for both the teacher and the student,
    some of which are shown in figure 6.8 (see [https://ditchthattextbook.com/ai/](https://ditchthattextbook.com/ai/)).
    Teachers can use it to assist with lesson plan writing, perhaps even creating
    personalized learning experiences based on each student’s needs and abilities,
    or even asking for feedback on students’ work. Students could use it as a starting
    point for an assignment, evaluate the tool’s initial response, and then critically
    think about how to further revise it for improvement. It can be used to supplement
    in-person instruction by providing resources for students outside of the classroom,
    such as using it for after-hours tutoring to explain concepts or assistance for
    English language learners to improve their writing skills. ChatGPT can also be
    creatively incorporated into lesson plans, such as using it as a tool to hone
    their debating skills or asking students to grade the output from the chatbot.
    Similarly, educational technology (EdTech) start-ups have also used LLMs for teaching
    and learning purposes—a few examples include an AI tutor (see [https://riiid.com/](https://riiid.com/)),
    a personalized learning platform (see [www.alefeducation.com/](https://www.alefeducation.com/)),
    and a conversational virtual assistant for learning science (see [www.cognii.com/](https://www.cognii.com/)).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在ChatGPT公开亮相不久之后，斯坦福大学的一项调查表明，学生已经开始使用这个工具来完成作业和考试 [[29]](https://stanforddaily.com/2023/01/22/scores-of-stanford-students-used-ChatGPT-on-final-exams-survey-suggests/)。随着一些大学在与ChatGPT的出现作斗争，许多大学已经将生成式AI工具的使用纳入其学术诚信政策中，并为教师提供了在课堂上融入AI工具的指导
    [[30]](https://www.uvm.edu/wid/artificial-intelligence) [[31]](https://ctl.wustl.edu/resources/ChatGPT-and-ai-composition-tools/)。同样，许多在学术界倡导ChatGPT的教育工作者认为，如果使用得当，它可以成为一个有效的教学工具。Ditch
    That Textbook教学博客列出了ChatGPT（或类似工具）可以用来增强教师和学生学习体验的多种方式，其中一些在图6.8中展示（见[https://ditchthattextbook.com/ai/](https://ditchthattextbook.com/ai/))）。教师可以使用它来协助编写课程计划，甚至根据每个学生的需求和能力创建个性化的学习体验，或者甚至要求对学生的作业提供反馈。学生可以用它作为作业的起点，评估工具的初始响应，然后批判性地思考如何进一步修改以改进。它可以用来补充课堂上的面对面教学，为学生提供课堂外的资源，例如在课后辅导中解释概念或帮助英语学习者提高写作技能。ChatGPT还可以创造性地融入课程计划中，例如用作磨练辩论技能的工具，或者要求学生评估聊天机器人的输出。类似地，教育技术（EdTech）初创公司也使用了LLMs进行教学和学习目的——一些例子包括人工智能辅导老师（见[https://riiid.com/](https://riiid.com/))）、个性化学习平台（见[www.alefeducation.com/](https://www.alefeducation.com/))和用于学习科学的对话式虚拟助手（见[www.cognii.com/](https://www.cognii.com/))。
- en: '![](../../OEBPS/Images/CH06_F08_Dhamani.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F08_Dhamani.png)'
- en: Figure 6.8 Examples of how to use chatbots in the classroom
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8课堂中使用聊天机器人的示例
- en: 'Sure, a tool like ChatGPT is certainly disruptive to a classroom setting, but
    the tool doesn’t need to be something that educators fear or are threatened by.
    Generative AI tools can be used for deeper, more engaged learning, especially
    because this is the world we live in now. Disruptive technology has always been
    met with excitement and fear—critics of the telephone feared that phones would
    disrupt face-to-face communication; with the invention of the television, some
    worried about the potential harm of creating a society of couch potatoes. Sam
    Altman, cofounder of OpenAI, responded to educators’ concerns about cheating in
    school by comparing the generative text to a calculator:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，像ChatGPT这样的工具对课堂环境确实具有颠覆性，但这个工具并不需要成为教育工作者害怕或感到威胁的东西。生成式AI工具可以用于更深入、更投入的学习，尤其是因为我们现在生活在这个世界中。颠覆性技术总是伴随着兴奋和恐惧——电话的批评者担心电话会干扰面对面的交流；电视的发明让一些人担心会创造出一个沙发土豆社会。OpenAI的联合创始人山姆·奥特曼（Sam
    Altman）通过将生成文本与计算器进行比较来回应教育工作者对学校作弊的担忧：
- en: We adapted to calculators and changed what we tested for in math class, I imagine.
    This is a more extreme version of that, no doubt, but also the benefits of it
    are more extreme, as well. [[32]](https://gizmodo.com/chatgpt-openai-ceo-sam-altman-schools-cheating-1850011314)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们适应了计算器，并改变了数学课上我们测试的内容，我想是这样的。这无疑是一个更极端的版本，但它的好处也同样极端。[32](https://gizmodo.com/ChatGPT-openai-ceo-sam-altman-schools-cheating-1850011314)
- en: While Altman downplays legitimate concerns around misuse and limitations of
    the tool, educators do need to figure out a way to adjust to these tools instead
    of outright banning them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然奥特曼淡化了对工具滥用和局限性的合法担忧，但教育工作者确实需要找到一种方法来适应这些工具，而不是直接禁止它们。
- en: Adjusting to new technology is rarely easy, and while tools such as ChatGPT
    are posed to change how we teach and learn, it’s not the end of formal education.
    In a *VentureBeat* article, Andrew Ng, a globally recognized leader in AI, and
    Andrea Passerini, the CEO of Kira Learning, urged schools to teach AI and coding
    to prepare students for an AI-powered world [[33]](https://venturebeat.com/ai/schools-should-teach-ai-to-every-child-according-to-andrew-ng-and-andrea-pasinetti/).
    Similarly, Harvard University released the AI Pedagogy Project to help educators
    engage their students in discussions about the capabilities and limitations of
    AI systems (see [https://aipedagogy.org/](https://aipedagogy.org/)). Whether we
    love them or fear them, we live in a world with generative AI tools, and students
    need to understand how to work alongside them. We need to teach them their strengths
    and weaknesses—how they can be used for productivity and creativity, but also
    how they can be misused and their risks. When used appropriately, ChatGPT and
    similar tools can augment the learning experience and help students navigate a
    world in which AI works with humans.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 适应新技术通常并不容易，尽管像ChatGPT这样的工具可能会改变我们的教学和学习方式，但这并不意味着正规教育的终结。在*VentureBeat*的一篇文章中，全球公认的AI领导者安德鲁·吴（Andrew
    Ng）和Kira Learning的首席执行官安德烈亚·帕斯纳尼（Andrea Passerini）敦促学校教授AI和编程，以帮助学生为AI驱动的世界做好准备[33](https://venturebeat.com/ai/schools-should-teach-ai-to-every-child-according-to-andrew-ng-and-andrea-pasinetti/)。同样，哈佛大学发布了AI教学法项目，以帮助教育工作者让学生参与关于AI系统能力和局限性的讨论（见[https://aipedagogy.org/](https://aipedagogy.org/)）。无论我们喜欢它们还是害怕它们，我们都生活在一个拥有生成式AI工具的世界中，学生需要了解如何与它们并肩工作。我们需要教他们它们的优点和缺点——它们如何用于生产力和创造力，但同时也可能被滥用及其风险。当适当使用时，ChatGPT和类似工具可以增强学习体验，帮助学生在一个AI与人类共同工作的世界中导航。
- en: Detecting AI-generated text
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测AI生成的文本
- en: In chapters 4 and 5, we discussed several efforts to detect machine-generated
    content, some of which are being used by educators to detect AI-plagiarized homework.
    While there have been promising results in developing detection methods, there
    are no silver bullet solutions—this is an extremely hard problem to solve, and
    it’s only getting harder with advancements in generative models. It’s also worth
    noting that this problem isn’t as well-posed as it seems. If we change one word,
    or maybe two words, in AI-generated text, then is the text still considered AI-generated?
    The ill-posed nature of this problem adds to the complexity of developing reliable
    detection methods. In this section, we’ll dive deeper into detection methods for
    AI-generated text.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4章和第5章中，我们讨论了检测机器生成内容的一些努力，其中一些被教育工作者用于检测AI剽窃的作业。虽然检测方法的发展已经取得了一些有希望的结果，但并没有一劳永逸的解决方案——这是一个极其困难的问题，随着生成模型的进步，它变得更加困难。还值得注意的是，这个问题并不像看起来那样容易解决。如果我们改变AI生成文本中的一个词，或者可能两个词，那么文本是否仍然被认为是AI生成的？这个问题的不良设定性质增加了开发可靠检测方法的复杂性。在本节中，我们将更深入地探讨AI生成文本的检测方法。
- en: Traditional approaches to detecting machine-generated text involve statistical
    outlier detection methods, such as GLTR (discussed in chapter 5, section Adversarial
    Narratives). GLTR assumes that machine-generated text sticks to a limited subset
    of most probable words at each position in the sentence, whereas natural writing
    more frequently selects unpredictable words that make sense in that context [[34]](https://arxiv.org/pdf/1906.04043.pdf).
    This method makes use of fundamental statistical techniques, that is, distributional
    estimates, to distinguish machine-generated text from human-written text. Another
    statistical approach, DetectGPT, uses a probability curvature–based criterion
    to detect if the generated text is from an LLM [[35]](https://arxiv.org/pdf/2301.11305.pdf).
    Here, when a model generates a sentence, it calculates how likely, or probable,
    each word is to appear in a correct sentence. It makes the assumption that the
    model might think that minor edits to the sentence are less likely to be correct
    because they may not match well with what it was trained on, but the human-written
    text can be different in many ways.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的检测机器生成文本的方法涉及统计异常检测方法，例如GLTR（在第5章的“对抗性叙事”部分中讨论）。GLTR假设机器生成的文本在每个句子位置都坚持于一个有限的、最可能词的子集，而自然写作则更频繁地选择在该语境中有意义的不可预测的词
    [[34]](https://arxiv.org/pdf/1906.04043.pdf)。这种方法利用基本的统计技术，即分布估计，来区分机器生成的文本和人工撰写的文本。另一种统计方法，DetectGPT，使用基于概率曲率的准则来检测生成的文本是否来自大型语言模型
    [[35]](https://arxiv.org/pdf/2301.11305.pdf)。在这里，当模型生成一个句子时，它会计算每个词出现在正确句子中的可能性或概率。它假设模型可能会认为对句子进行的小幅编辑不太可能是正确的，因为它们可能与其训练的内容不太匹配，但人工撰写的文本在许多方面可能有所不同。
- en: As discussed in the previous chapters, classifiers are commonly used to detect
    machine-generated text. Here, a classifier is an algorithm that is used to categorize
    data into distinct groups or classes. OpenAI released an “imperfect” classifier
    in January 2023 to distinguish between AI-generated and human-written text, which
    is a helpful example of how classifiers can be used in this context. They acknowledge
    that it’s impossible to reliably detect *all* AI-generated text, but their classifier
    could be used to complement other methods for detecting AI-generated text rather
    than as a primary decision-making tool (though—as noted in chapter 4—the OpenAI
    classifier was taken down in five months after its release due to accuracy problems)
    [[36]](https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text).
    While good classifiers have their place in detecting machine-generated text, it’s
    important to recognize their limitations (as with any technical approaches for
    this task) and understand that it’s not a bulletproof way to identify AI-written
    text. It’s also worth noting that classifiers often overfit to a specific generator’s
    distribution. In other words, a classifier designed to detect text from GPT-4
    will likely not perform as well when detecting text generated by other chatbots,
    such as Bard or Bing Chat. However, they have shown promise in informing mitigations
    for misuses of machine-generated text, especially in combination with other sociotechnical
    methods to determine the source of a piece of content.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所述，分类器通常用于检测机器生成的文本。在这里，分类器是一种用于将数据分类到不同组或类的算法。OpenAI在2023年1月发布了一个“不完美”的分类器，用于区分AI生成文本和人类撰写的文本，这是分类器在此背景下如何使用的有益示例。他们承认，可靠地检测*所有*AI生成文本是不可能的，但他们的分类器可以用于补充其他检测AI生成文本的方法，而不是作为主要的决策工具（尽管——如第4章所述——OpenAI的分类器在发布五个月后因准确性问题被下线
    [[36](https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text)]）。虽然好的分类器在检测机器生成文本方面有其位置，但重要的是要认识到它们的局限性（就像任何用于此任务的技术方法一样），并了解这并不是识别AI撰写文本的万无一失的方法。还值得注意的是，分类器往往会过度拟合到特定生成器的分布。换句话说，设计用于检测GPT-4文本的分类器在检测由其他聊天机器人（如Bard或Bing
    Chat）生成的文本时可能表现不佳。然而，它们在告知机器生成文本的滥用缓解方面显示出希望，尤其是在与其他社会技术方法结合确定内容来源时。
- en: Given the increasing difficulty of reliably detecting AI-generated content,
    researchers are exploring a novel technique known as *watermarking*. Historically,
    watermarks have been used in images and videos to protect copyrighted content
    and prevent intellectual property theft. In an innovative approach, researchers
    have shown how to incorporate watermarking into text generated by LLMs to assist
    with the identification of AI-generated text [[37]](https://arxiv.org/pdf/2301.10226.pdf).
    Watermarking in text works by changing the pattern of words in the generated text,
    that is, altering the probabilities of certain special words to make them easier
    to detect later. Let’s visualize this concept (shown in figure 6.9)—imagine a
    list of words that make up the language model’s vocabulary, which is randomly
    divided in half into a “greenlist” and a “redlist.” Then, when an LLM, such as
    ChatGPT, generates text, it can insert a watermark by prompting the model to choose
    more greenlisted words than a human would be expected to use. So, the more words
    in the greenlist that are in a piece of content, the more likely it is that the
    content was generated by a machine. In comparison, text written by humans would
    likely be a more random mix of words.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于可靠检测AI生成内容的难度日益增加，研究人员正在探索一种名为*水印技术*的新方法。历史上，水印在图像和视频中用于保护版权内容并防止知识产权盗窃。在一种创新的方法中，研究人员展示了如何将水印技术融入LLM生成的文本中，以帮助识别AI生成的文本
    [[37](https://arxiv.org/pdf/2301.10226.pdf)]。文本水印的工作原理是通过改变生成文本中的单词模式，即改变某些特殊单词的概率，使其更容易在以后检测到。让我们可视化这个概念（如图6.9所示）——想象一个由语言模型词汇组成的单词列表，这些单词随机分成一半的“绿色列表”和“红色列表”。然后，当LLM，如ChatGPT生成文本时，它可以通过提示模型选择比人类预期使用更多的绿色列表单词来插入水印。因此，绿色列表中的单词在内容中越多，该内容是由机器生成的可能性就越大。相比之下，人类撰写的文本可能是一个更随机的单词混合。
- en: Watermarking in text works by changing the pattern of words in the generated
    text, that is, altering the probabilities of certain special words to make them
    easier to detect later.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 文本水印的工作原理是通过改变生成文本中的单词模式，即改变某些特殊单词的概率，使其更容易在以后检测到。
- en: '![](../../OEBPS/Images/CH06_F09_Dhamani.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH06_F09_Dhamani.png)'
- en: Figure 6.9 Illustration of how a chatbot could embed watermarking in the text
    it generates
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9展示了一个聊天机器人如何在它生成的文本中嵌入水印
- en: These watermarks are meant to be invisible to the human eye—if someone tried
    to bypass the watermark by editing the text, they wouldn’t know which words to
    change. While this approach has shown more promise than statistical or classification
    techniques, it doesn’t come without limitations. First, this technique should
    ideally be implemented in the LLM from the very beginning. Making watermarking
    work for large models like ChatGPT without compromising the quality of the outputs
    is no easy feat.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这些水印旨在对人类眼睛不可见——如果有人试图通过编辑文本来绕过水印，他们将不知道要更改哪些单词。虽然这种方法比统计或分类技术显示出更多的希望，但它并非没有局限性。首先，这种技术理想情况下应该从LLM的最初阶段就开始实施。对于像ChatGPT这样的大型模型来说，在不影响输出质量的情况下实现水印功能并非易事。
- en: Next, for watermarking to truly be a successful detection technique, all the
    big players building generative language models need to unilaterally agree to
    incorporate it within their AI systems. This, in itself, may prove to be challenging,
    if not impossible (at least without government regulation). For the general public
    using watermark detection tools (e.g., educators trying to determine if the student’s
    essay is machine-generated), it could be quite cumbersome to check the text against
    multiple tools unless all the AI companies decide on an industry standard for
    watermark implementation, which again, is a far-fetched goal. However, open-sourcing
    the watermark implementation, or making it public, isn’t the answer either because
    anyone would be able to deduce the watermark pattern, then defeating their purpose.
    OpenAI has announced that they have been working on watermarking text [[38]](https://scottaaronson.blog/?p=6823),
    among other provenance techniques for detection. Perhaps the closest thing to
    an industry standard may be for organizations using OpenAI’s models to adopt their
    specific watermarking technique, which would place an immense amount of unregulated
    power and trust in the company.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了使水印真正成为一种成功的检测技术，所有构建生成语言模型的大公司都需要单方面同意将其纳入他们的AI系统中。这本身可能是一项挑战，如果不是不可能的（至少在没有政府监管的情况下）。对于使用水印检测工具的公众（例如，试图确定学生的论文是否为机器生成的教育工作者）来说，除非所有AI公司决定采用水印实施行业标准，否则检查文本将非常繁琐，而这又是一个遥不可及的目标。然而，开源水印实现或使其公开也不是答案，因为任何人都可以推断出水印模式，从而破坏其目的。OpenAI已宣布他们一直在研究水印文本[[38]](https://scottaaronson.blog/?p=6823)，以及其他用于检测的来源技术。可能最接近行业标准的是，使用OpenAI模型的组织采用他们特定的水印技术，这将赋予该公司巨大的未受监管的权力和信任。
- en: Outside of the successful adoption of an industry standard for watermarking,
    people will likely figure out how much text they need to change to bypass detection
    tools. Regrettably, that’s the problem with all detection tools—the tools *can*
    make it easier to avoid detection. In other words, people could repeatedly modify
    machine-generated text and check it against a detection tool until it no longer
    classifies it as machine-generated. This suggests some concern with rolling out
    detection tools to the general public as adversaries could learn how to “fool”
    or bypass them. However, repeatedly modifying machine-generated text and checking
    it against detection tools can be a fairly time-consuming exercise to pass off
    the machine-generated text as one’s own, which may still deter the behavior.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除了成功采用水印的行业标准之外，人们可能会弄清楚需要更改多少文本才能绕过检测工具。遗憾的是，这是所有检测工具的问题——工具*可以*使避免检测变得更容易。换句话说，人们可以反复修改机器生成的文本，并对照检测工具进行检查，直到它不再将其归类为机器生成。这表明将检测工具推广到公众可能会引起一些担忧，因为对手可能会学会如何“欺骗”或绕过它们。然而，反复修改机器生成的文本并与检测工具对照可能会是一项相当耗时的任务，以将机器生成的文本冒充为自己的，这可能会阻止这种行为。
- en: While we’ve discussed several notable technical solutions in this section, remember
    that there are no silver bullet solutions—given the complexity of this problem,
    there is no single solution that will reliably detect every piece of machine-generated
    content every single time. We probably won’t ever get to live in a world with
    a mythical detection tool that reliably detects machine-generated content. As
    we develop more novel techniques to detect content from machines, we’ll *also*
    get better at generating more human-like content. This is why it’s necessary to
    adopt a comprehensive framework for detecting the misuse of AI-generated content
    that doesn’t solely rely on technical solutions, including AI education in schools
    and the workplace, so we can better understand its risks and limitations, and
    learn to use them to enhance our lives.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在本节中讨论了几个显著的技术解决方案，但请记住，没有一劳永逸的解决方案——鉴于这个问题的复杂性，没有单一的方法能够每次都可靠地检测到每一份机器生成的内容。我们可能永远无法生活在一个拥有神话般的检测工具的世界里，这个工具能够可靠地检测到机器生成的内容。随着我们开发出更多新颖的技术来检测机器内容，我们也会变得更擅长生成更类似人类的内容。这就是为什么有必要采用一个全面的框架来检测AI生成内容的滥用，这个框架不仅仅依赖于技术解决方案，包括在学校和工作场所进行AI教育，这样我们才能更好地理解其风险和限制，并学会如何利用它们来提升我们的生活。
- en: How LLMs affect jobs and the economy
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）对工作和经济的影响
- en: 'ChatGPT, and similar tools, will undoubtedly only get better and harder to
    detect, with billions of dollars being poured into the development of AI technology.
    As the general public becomes more and more aware that such tools are here to
    stay, many are speculating about how they will disrupt their day-to-day lives.
    In this chapter, we discussed how several occupations are using generative language
    models to make their jobs more efficient and productive, how people are using
    these tools in their everyday lives, and how the education industry was quickly
    disrupted with ChatGPT’s public release. Now, we’ll touch on the global economic
    effect and try to answer the question: What does this mean for all of us?'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT和类似工具无疑会变得越来越难以检测，因为数十亿美元的资金正被投入到AI技术的开发中。随着公众越来越意识到这些工具将长期存在，许多人都在猜测它们将如何扰乱他们的日常生活。在本章中，我们讨论了几个职业如何使用生成式语言模型来提高工作效率和生产力，人们如何在日常生活中使用这些工具，以及教育行业如何随着ChatGPT的公开发布而迅速受到冲击。现在，我们将探讨全球经济的影响，并试图回答这个问题：这对我们所有人意味着什么？
- en: 'First, let’s discuss the optimistic view—generative AI tools are expected to
    make many workers more efficient and increase productivity while boosting the
    overall economy. Productivity, a key part of economic growth, has slowed down
    in the past two decades. A report from the Brookings Institution, *Machines of
    Mind: The Case for an AI-Powered Productivity Boom*, argues that generative language
    models will provide a much-needed boost to productivity [[39]](https://www.brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/).
    While we’ve discussed several limitations of LLMs, including bias and hallucinations,
    which require human oversight in the workplace, proponents of AI-driven productivity
    gains claim that “their economic value depends not on whether they are flawless,
    but on whether they can be used productively” [[39]](https://www.brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/).
    In one scenario, the Brookings analysis illustrates a decade of productivity growth
    increases, leaving the economy 5% larger, and then compounding every year thereafter.
    Another report by Goldman Sachs suggests that generative AI could raise the global
    gross domestic product (GDP) by 7%, or 7 trillion dollars [[40]](https://www.ft.com/content/50b15701-855a-4788-9a4b-5a0a9ee10561).
    This is a significant effect for a single technology to have on the metrics that
    determine the long-term prosperity and wealth of our nations.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们讨论乐观的观点——生成式人工智能工具预计将使许多工人更加高效，提高生产力，同时提振整体经济。作为经济增长的关键部分，过去二十年中的生产力已经放缓。布鲁金斯学会的报告《心智之机：人工智能驱动生产力繁荣的案例》认为，生成式语言模型将为生产力提供急需的提振
    [[39](https://www.brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/)]。虽然我们已经讨论了LLMs的几个局限性，包括偏见和幻觉，这些都需要在工作场所进行人工监督，但AI驱动生产力增长的倡导者声称，“它们的经济价值不在于它们是否完美，而在于它们是否能够被有效地使用”
    [[39](https://www.brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/)]。在一个情景中，布鲁金斯的分析展示了十年生产力增长的提升，使经济规模扩大5%，此后每年都在增长。高盛的另一份报告建议，生成式人工智能可以将全球国内生产总值（GDP）提高7%，或7000亿美元
    [[40](https://www.ft.com/content/50b15701-855a-4788-9a4b-5a0a9ee10561)]。这对于一项技术对决定我们国家长期繁荣和财富的指标产生的影响来说是一个重大影响。
- en: In a 2023 report by OpenAI, OpenResearch, and the University of Pennsylvania,
    the authors noted that LLMs could affect 80% of the US workforce in some form
    [[41]](https://arxiv.org/pdf/2303.10130.pdf). Other reports stated GitHub CoPilot
    could help software engineers code twice as fast [[42]](https://github.blog/2022-09-07-research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/),
    writing tasks could also be completed twice as fast [[43]](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf),
    economists could be 10%–20% more productive [[44]](https://doi.org/10.3386/w30957),
    and customer service workers 14% more productive. [[45]](https://www.bloomberg.com/news/articles/2023-04-24/generative-ai-boosts-worker-productivity-14-new-study-finds)
    More notably, generative models can help a wide group of less-skilled workers
    upskill to be able to compete with people who have more credentials or experience.
    In a productivity study for using ChatGPT in professional writing tasks, such
    as marketing and HR, the authors demonstrate the inequality decrease between workers—that
    is, the less skilled workers get quantifiably better, while the more experienced
    workers get a little faster [[46]](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年OpenAI、OpenResearch和宾夕法尼亚大学的一份报告中，作者指出，大型语言模型（LLMs）可能会以某种形式影响美国80%的劳动力
    [[41](https://arxiv.org/pdf/2303.10130.pdf)]。其他报告称，GitHub CoPilot可以帮助软件工程师将编码速度提高一倍
    [[42](https://github.blog/2022-09-07-research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/)]，写作任务也可以完成得快一倍
    [[43](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf)]，经济学家可以提高10%–20%的生产率
    [[44](https://doi.org/10.3386/w30957)]，客户服务人员可以提高14%的生产率 [[45](https://www.bloomberg.com/news/articles/2023-04-24/generative-ai-boosts-worker-productivity-14-new-study-finds)]。更有意义的是，生成式模型可以帮助大量技能较低的工人提升技能，使他们能够与拥有更多证书或经验的人竞争。在一项关于在专业写作任务中使用ChatGPT的生产力研究中，例如市场营销和人力资源，作者展示了工人之间不平等性的减少——也就是说，技能较低的工人会得到量化的提升，而经验较多的工人则会稍微快一点
    [[46](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf)]。
- en: 'On the other hand, generative AI tools could possibly do little to help overall
    economic growth. More pessimistically, they could be used to replace humans with
    machines, drive down wages, and exacerbate the inequality between wealth and income.
    In *The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence*,
    Erik Brynjolfsson argues that AI developers are too focused on imitating human
    intelligence instead of creating technology to give people new abilities [[47]](https://www.amacad.org/publication/turing-trap-promise-peril-human-artificial-intelligence).
    He believes that this pursuit of mimicking human-like capabilities, which replace
    humans with machines is the “single biggest explanation” for wealth inequality
    [[48]](https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/).
    In that vein, companies that design and develop these AI tools may potentially
    influence the effect on the economy. As discussed in chapter 1, the computational
    cost required to build and run LLMs creates a barrier of entry for anyone looking
    to compete in this space, leaving the power in the hands of the same big companies
    that already control so much of the technology world. There have, however, been
    strides made in the open source community to develop LLMs, BLOOM, Falcon, Stable
    LM, MPT-7B, Dolly, RedPajama, and OpenLLaMa. It’s also important to note that
    Meta’s LLaMa and Llama 2, which have been open sourced by the company, have greatly
    accelerated the development of these models. These efforts could help decentralize
    the power that is concentrated within a few big technology companies and help
    break their control over such technology in the future.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，生成式AI工具可能对整体经济增长的贡献甚微。更为悲观的是，它们可能被用来用机器取代人类，降低工资，并加剧财富与收入之间的不平等。在《图灵陷阱：类人人工智能的承诺与危险》一书中，埃里克·布林约尔森认为，AI开发者过于专注于模仿人类智能，而不是创造技术来赋予人们新的能力[[47]](https://www.amacad.org/publication/turing-trap-promise-peril-human-artificial-intelligence)。他相信，这种模仿人类类似能力的追求，即用机器取代人类，是财富不平等“单一最大的解释”[[48]](https://www.technologyreview.com/2023/03/25/1070275/ChatGPT-revolutionize-economy-decide-what-looks-like/)。在这方面，设计和开发这些AI工具的公司可能潜在地影响其对经济的影响。正如第1章所讨论的，构建和运行大型语言模型（LLMs）所需的计算成本为想要在这个领域竞争的任何人设置了一道门槛，使得权力仍然掌握在那些已经控制了大部分科技世界的同一些大公司手中。然而，开源社区在开发LLMs、BLOOM、Falcon、Stable
    LM、MPT-7B、Dolly、RedPajama和OpenLLaMa等方面已经取得了进展。还值得注意的是，Meta公司开源的LLaMa和Llama 2大大加速了这些模型的发展。这些努力有助于分散集中在少数大科技公司手中的权力，并有助于在未来打破他们对这种技术的控制。
- en: 'Now, let’s get back to the question at the beginning of this section: What
    does this mean for all of us? For some, generative AI tools have been met with
    panic and concern that they may be out of a job soon. Goldman Sachs predicted
    that 300 million full-time jobs will be lost to AI [[49]](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/).
    But it’s important to keep the bigger picture in mind—this isn’t the first time
    that technology has disrupted our lives. Many experts think that this disruption
    could perhaps even create more new job opportunities than it would displace. In
    2021, a report noted that 60% of the jobs done didn’t exist in 1940 [[50]](https://www.bbc.com/worklife/article/20230515-workplace-ai-how-artificial-intelligence-will-transform-the-workday).
    In other words, technology over the past 80 years created new industries and jobs,
    and we could potentially expect to see a similar movement with generative AI.
    Economists are also uncertain about the productivity boom and net benefits, as
    well as how jobs may be affected. Paul Krugman, professor emeritus at Princeton
    University, said, “Predictions about the economic impact of technology are notoriously
    unreliable,” asserting that LLMs should not affect economic projections in the
    next few years, or even the next decade. He further says “History suggests that
    large economic effects from A.I. will take longer to materialize than many people
    currently seem to expect” [[51]](https://fortune.com/2023/04/03/nobel-laureate-paul-krugman-ai-chatgpt-economy/).
    Regardless of when it takes place, we should expect an evolution, not a revolution,
    with generative AI.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到本节开头的问题：这对我们所有人意味着什么？对于一些人来说，生成式AI工具的出现引起了恐慌和担忧，他们担心自己很快就会失业。高盛预测，将有3亿个全职工作因AI而消失[[49]](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/)。但重要的是要记住更大的图景——这不是技术第一次颠覆我们的生活。许多专家认为，这种颠覆可能会创造出比它取代的更多新的工作机会。2021年的一份报告指出，60%的工作在1940年并不存在[[50]](https://www.bbc.com/worklife/article/20230515-workplace-ai-how-artificial-intelligence-will-transform-the-workday)。换句话说，过去80年来的技术创造了新的产业和就业机会，我们可能期待看到生成式AI带来类似的变革。经济学家也对生产力激增和净收益以及工作可能受到的影响感到不确定。普林斯顿大学荣誉退休教授保罗·克鲁格曼说：“关于技术对经济影响的预测历来是不可靠的，”他坚称，大型语言模型（LLMs）不应影响未来几年甚至十年内的经济预测。他进一步说，“历史表明，人工智能带来的重大经济影响将比许多人目前似乎预期的要长[[51]](https://fortune.com/2023/04/03/nobel-laureate-paul-krugman-ai-ChatGPT-economy/)。无论何时发生，我们都应该期待生成式AI带来的是一种演变，而不是革命。
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: People are already using generative AI tools to assist with both personal and
    professional tasks, especially to offload more administrative and repetitive work.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们已经开始使用生成式AI工具来协助个人和职业任务，特别是卸载更多行政和重复性工作。
- en: 'Coding assistants such as Copilot, CodeWhisperer, and Ghostwriter can be helpful
    throughout the software engineering workflow: from thinking through architectures
    to writing code to generating documentation and diagrams.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如Copilot、CodeWhisperer和Ghostwriter之类的编码助手可以在整个软件工程工作流程中提供帮助：从思考架构到编写代码，再到生成文档和图表。
- en: Prompts, follow-up questions, and feedback affect model results, and the best
    results seem to be produced by prompts that are detailed, instructive, and contain
    references or examples.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示、后续问题和反馈会影响模型结果，而最佳结果似乎是由详细、指导性且包含参考或例子的提示产生的。
- en: Some of the more powerful proposed applications of LLMs require the models to
    be agents, meaning that they will be able to interact with their environment and
    adapt accordingly.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些更强大的LLM应用建议需要模型成为代理，这意味着它们将能够与环境互动并相应地适应。
- en: Educators will need to adapt to a world in which generative AI tools exist by
    working alongside them in the classroom, as well as helping students learn about
    and navigate an AI-powered world.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育工作者需要适应一个存在生成式AI工具的世界，通过在课堂上与他们一起工作，以及帮助学生了解和导航一个由AI驱动的世界。
- en: Efforts to detect machine-generated text include statistical techniques, classifier-based
    detectors, and watermarking text.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测机器生成文本的努力包括统计技术、基于分类器的检测器和文本水印。
- en: '*Watermarking* in text works by changing the pattern of words in the generated
    text or prompting the model to choose certain special words to make them easier
    to detect later.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本中的*水印*通过改变生成文本中的单词模式或提示模型选择某些特殊单词来使其更容易在以后检测到。
- en: There is no single technical solution to reliably detect every piece of machine-generated
    content every single time.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有任何单一的技术解决方案可以可靠地检测到每次机器生成内容的每一部分。
- en: Economists are uncertain about the productivity boom and net benefits, as well
    as how jobs may be affected.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经济学家对生产力激增和净收益存在不确定性，以及工作可能受到的影响。
- en: With generative AI tools, we should expect an evolution, not a revolution.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI工具，我们应该期待的是一种演变，而不是一场革命。
