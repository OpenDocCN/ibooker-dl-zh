- en: Chapter 8\. The PyTorch Ecosystem and Additional Resources
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章. PyTorch生态系统和其他资源
- en: In the previous chapters, you’ve learned everything you need to design and deploy
    deep learning models with PyTorch. You have learned how to build, train, test,
    and accelerate your models across different platforms and how to deploy those
    models to the cloud and edge devices. As you’ve seen, PyTorch has powerful capabilities
    in both development and deployment environments and is highly extensible, allowing
    you to create customizations tailored to your needs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，您已经学会了使用PyTorch设计和部署深度学习模型所需的一切。您已经学会了如何在不同平台上构建、训练、测试和加速您的模型，以及如何将这些模型部署到云端和边缘设备。正如您所见，PyTorch在开发和部署环境中都具有强大的功能，并且高度可扩展，允许您创建符合您需求的定制化。
- en: To conclude this reference guide, we’ll explore the PyTorch Ecosystem, other
    supporting libraries, and additional resources. The PyTorch Ecosystem is one of
    the most powerful advantages of PyTorch. It provides a rich set of projects, tools,
    models, libraries, and platforms to explore AI and accelerate your AI development.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个参考指南，我们将探索PyTorch生态系统、其他支持库和额外资源。PyTorch生态系统是PyTorch最强大的优势之一。它提供了丰富的项目、工具、模型、库和平台，用于探索人工智能并加速您的人工智能开发。
- en: The PyTorch Ecosystem includes projects and libraries created by researchers,
    third-party vendors, and the PyTorch community. These projects are well maintained
    and have been vetted by the PyTorch team to ensure their quality and utility.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch生态系统包括由研究人员、第三方供应商和PyTorch社区创建的项目和库。这些项目得到了PyTorch团队的认可，以确保它们的质量和实用性。
- en: In addition, the PyTorch project includes other libraries that support specific
    domains, including Torchvision for computer vision and Torchtext for NLP. PyTorch
    also supports other packages like TensorBoard for visualization, and there’s an
    abundance of learning resources for further study, like Papers with Code and PyTorch
    Academy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，PyTorch项目还包括支持特定领域的其他库，包括用于计算机视觉的Torchvision和用于NLP的Torchtext。PyTorch还支持其他包，如TensorBoard用于可视化，还有大量的学习资源供进一步研究，如Papers
    with Code和PyTorch Academy。
- en: In this chapter, we’ll begin with an overview of the PyTorch Ecosystem and a
    high-level view of its supported projects and tools. Then we’ll dig a little deeper
    into some of the most powerful and popular resources, with reference material
    about their usage and APIs provided along the way. Finally, I’ll show you how
    to learn more with a variety of tutorials, books, courses, and other training
    resources.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先概述PyTorch生态系统及其支持的项目和工具的高级视图。然后，我们将深入了解一些最强大和流行的资源，提供关于它们的使用和API的参考资料。最后，我将向您展示如何通过各种教程、书籍、课程和其他培训资源进一步学习。
- en: Let’s start by looking at all the Ecosystem has to offer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始看看生态系统提供了什么。
- en: The PyTorch Ecosystem
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch生态系统
- en: As of early 2021, the [PyTorch Ecosystem](https://pytorch.tips/ecosystem) features
    over 50 libraries and projects, and the list continues to grow. Some of these
    are domain-specific projects, such as those specifically for computer vision or
    NLP solutions. Other projects, such as PyTorch Lightning and fastai, provide frameworks
    for writing concise code, while projects like PySyft and Crypten support security
    and privacy. There are also projects that support reinforcement learning, gaming
    models, model interpretability, and acceleration. In this section, we’ll explore
    projects included in the PyTorch Ecosystem.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2021年初，[PyTorch生态系统](https://pytorch.tips/ecosystem)拥有超过50个库和项目，这个列表还在不断增长。其中一些是特定领域的项目，例如专门用于计算机视觉或NLP解决方案的项目。其他项目，如PyTorch
    Lightning和fastai，提供了编写简洁代码的框架，而像PySyft和Crypten这样的项目支持安全性和隐私性。还有支持强化学习、游戏模型、模型可解释性和加速的项目。在本节中，我们将探索包含在PyTorch生态系统中的项目。
- en: '[Table 8-1](#table_eco_cv) provides a list of the Ecosystem projects that support
    *computer vision* applications.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-1](#table_eco_cv)提供了支持*计算机视觉*应用的生态系统项目列表。'
- en: Table 8-1\. Computer vision projects
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-1. 计算机视觉项目
- en: '| Project | Description |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Torchvision | PyTorch’s computer vision library that provides common transforms,
    models, and utilities to support computer vision applications ([*https://pytorch.tips/torchvision*](https://pytorch.tips/torchvision))
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| Torchvision | PyTorch的计算机视觉库，提供常见的转换、模型和实用程序，以支持计算机视觉应用（[*https://pytorch.tips/torchvision*](https://pytorch.tips/torchvision)）|'
- en: '| Detectron2 | Facebook’s objection detection and segmentation platform ([*https://pytorch.tips/detectron2*](https://pytorch.tips/detectron2))
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Detectron2 | Facebook的目标检测和分割平台（[*https://pytorch.tips/detectron2*](https://pytorch.tips/detectron2)）|'
- en: '| Albumentations | Image augmentation library ([*https://pytorch.tips/albumentations*](https://pytorch.tips/albumentations))
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| Albumentations | 图像增强库（[*https://pytorch.tips/albumentations*](https://pytorch.tips/albumentations)）|'
- en: '| PyTorch3D | Collection of reusable components for 3D computer vision ([*https://pytorch.tips/pytorch3d*](https://pytorch.tips/pytorch3d))
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch3D | 用于3D计算机视觉的可重用组件集合（[*https://pytorch.tips/pytorch3d*](https://pytorch.tips/pytorch3d)）|'
- en: '| Kornia | Library of differentiable modules for computer vision ([*https://pytorch.tips/kornia*](https://pytorch.tips/kornia))
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| Kornia | 用于计算机视觉的可微分模块库（[*https://pytorch.tips/kornia*](https://pytorch.tips/kornia)）|'
- en: '| MONAI | Framework for deep learning in healthcare imaging ([*https://pytorch.tips/monai*](https://pytorch.tips/monai))
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| MONAI | 用于医疗影像深度学习的框架（[*https://pytorch.tips/monai*](https://pytorch.tips/monai)）|'
- en: '| TorchIO | Toolkit for 3D medical images ([*https://pytorch.tips/torchio*](https://pytorch.tips/torchio))
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| TorchIO | 用于3D医学图像的工具包（[*https://pytorch.tips/torchio*](https://pytorch.tips/torchio)）|'
- en: Torchvision is one of the most powerful libraries for computer vision applications
    and is included in the PyTorch project. It’s also maintained by the PyTorch development
    team. We’ll cover the Torchvision API in more detail later in this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision是计算机视觉应用中最强大的库之一，包含在PyTorch项目中。它也由PyTorch开发团队维护。我们将在本章后面更详细地介绍Torchvision
    API。
- en: PyTorch3D and TorchIO provide additional support for 3D imaging, while TorchIO
    and MONAI focus on medical imaging applications. Detectron2 is a powerful platform
    for object detection. If you’re conducting computer vision research and development,
    these extensions may help accelerate your results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch3D和TorchIO为3D成像提供了额外支持，而TorchIO和MONAI专注于医学成像应用。Detectron2是一个强大的物体检测平台。如果您正在进行计算机视觉研究和开发，这些扩展可能有助于加速您的结果。
- en: As with computer vision, there have been major advances in NLP research over
    the past decade, and NLP applications are also well supported by PyTorch.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 与计算机视觉一样，过去十年来在NLP研究中取得了重大进展，NLP应用也得到了PyTorch的良好支持。
- en: '[Table 8-2](#table_eco_nlp) provides a list of the Ecosystem projects that
    support *NLP and audio-based* applications.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-2](#table_eco_nlp)提供了支持*NLP和基于音频*应用的生态系统项目列表。'
- en: Table 8-2\. NLP and audio projects
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-2. NLP和音频项目
- en: '| Project | Description |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Torchtext | PyTorch’s NLP and text processing library ([*https://pytorch.tips/torchtext*](https://pytorch.tips/torchtext))
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Torchtext | PyTorch的自然语言处理和文本处理库（[*https://pytorch.tips/torchtext*](https://pytorch.tips/torchtext)）|'
- en: '| Flair | Simple framework for NLP ([*https://pytorch.tips/flair*](https://pytorch.tips/flair))
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Flair | NLP的简单框架（[*https://pytorch.tips/flair*](https://pytorch.tips/flair)）|'
- en: '| AllenNLP | Library for designing and evaluating NLP models ([*https://pytorch.tips/allennlp*](https://pytorch.tips/allennlp))
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| AllenNLP | 用于设计和评估NLP模型的库（[*https://pytorch.tips/allennlp*](https://pytorch.tips/allennlp)）|'
- en: '| ParlAI | Framework for sharing, training, and testing dialogue models ([*https://pytorch.tips/parlai*](https://pytorch.tips/parlai))
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| ParlAI | 用于共享、训练和测试对话模型的框架（[*https://pytorch.tips/parlai*](https://pytorch.tips/parlai)）|'
- en: '| NeMo | Toolkit for conversational AI ([*https://pytorch.tips/nemo*](https://pytorch.tips/nemo))
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| NeMo | 用于会话AI的工具包（[*https://pytorch.tips/nemo*](https://pytorch.tips/nemo)）|'
- en: '| PyTorch NLP | Basic utilities for NLP ([*https://pytorch.tips/pytorchnlp*](https://pytorch.tips/pytorchnlp))
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch NLP | NLP的基本工具（[*https://pytorch.tips/pytorchnlp*](https://pytorch.tips/pytorchnlp)）|'
- en: '| Translate | Facebook’s machine translation platform ([*https://pytorch.tips/translate*](https://pytorch.tips/translate))
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Translate | Facebook的机器翻译平台（[*https://pytorch.tips/translate*](https://pytorch.tips/translate)）|'
- en: '| TorchAudio | PyTorch’s library for audio preprocessing ([*https://pytorch.tips/torchaudio*](https://pytorch.tips/torchaudio))
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| TorchAudio | PyTorch的音频预处理库（[*https://pytorch.tips/torchaudio*](https://pytorch.tips/torchaudio)）|'
- en: Like Torchvision, Torchtext is included as part of the PyTorch project and is
    maintained by the PyTorch development team. Torchtext provides powerful functionality
    for processing text data and developing NLP-based models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与Torchvision一样，Torchtext作为PyTorch项目的一部分包含在内，并由PyTorch开发团队维护。Torchtext为处理文本数据和开发基于NLP的模型提供了强大的功能。
- en: Flair, AllenNLP, and PyTorch NLP provide additional capabilities for text-based
    processing and NLP model development. ParlAI and NeMo provide tools to develop
    dialogue and conversational AI systems, while Translate focuses on machine translation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Flair、AllenNLP和PyTorch NLP为基于文本的处理和NLP模型开发提供了额外功能。ParlAI和NeMo提供了开发对话和会话AI系统的工具，而Translate专注于机器翻译。
- en: TorchAudio provides functions for handling audio files like speech and music.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: TorchAudio提供处理音频文件（如语音和音乐）的功能。
- en: Reinforcement learning and gaming are also rapidly growing fields of research,
    and there are tools to support them using PyTorch.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习和游戏也是研究的快速增长领域，有工具支持它们使用PyTorch。
- en: '[Table 8-3](#table_eco_gaming) provides a list of the Ecosystem projects that
    support *gaming and reinforcement learning* applications.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-3](#table_eco_gaming)提供了支持*游戏和强化学习*应用的生态系统项目列表。'
- en: Table 8-3\. Gaming and reinforcement learning projects
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-3. 游戏和强化学习项目
- en: '| Project | Description |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ELF | Project for training and testing algorithms in game environments ([*https://pytorch.tips/elf*](https://pytorch.tips/elf))
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| ELF | 用于在游戏环境中训练和测试算法的项目（[*https://pytorch.tips/elf*](https://pytorch.tips/elf)）|'
- en: '| PFRL | Library of deep reinforcement algorithms ([*https://pytorch.tips/pfrl*](https://pytorch.tips/pfrl))
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| PFRL | 深度强化学习算法库（[*https://pytorch.tips/pfrl*](https://pytorch.tips/pfrl)）|'
- en: ELF (extensive, lightweight, and flexible platform for game research) is an
    open source project developed by Facebook that reimplements gaming algorithms
    like AlphaGoZero and AlphaZero. PFRL (preferred reinforcement learning) is a PyTorch-based
    open source deep reinforcement learning library developed by Preferred Networks,
    the creators of Chainer and ChainerRL. It can be used to create baseline algorithms
    for reinforcement learning. PFRL currently has reproducibility scripts for 11
    key deep reinforcement learning algorithms based on original research papers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ELF（广泛、轻量级、灵活的游戏研究平台）是Facebook开发的开源项目，重新实现了像AlphaGoZero和AlphaZero这样的游戏算法。PFRL（首选强化学习）是由Preferred
    Networks开发的基于PyTorch的开源深度强化学习库，是Chainer和ChainerRL的创造者。它可以用来创建强化学习的基线算法。PFRL目前为11个基于原始研究论文的关键深度强化学习算法提供了可重现性脚本。
- en: As you’ve seen in this book, PyTorch is a highly customizable framework. This
    characteristic sometimes results in the need to write the same boilerplate code
    often for common tasks. To help developers write code faster and eliminate the
    need for boilerplate code, several PyTorch projects provide high-level programming
    APIs or compatibility with other high-level frameworks like scikit-learn.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在本书中所看到的，PyTorch是一个高度可定制的框架。这种特性有时会导致需要为常见任务经常编写相同的样板代码。为了帮助开发人员更快地编写代码并消除样板代码的需要，几个PyTorch项目提供了高级编程API或与其他高级框架（如scikit-learn）的兼容性。
- en: '[Table 8-4](#table_eco_hlp) provides a list of the Ecosystem projects that
    support *high-level programming*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-4](#table_eco_hlp)提供了支持*高级编程*的生态系统项目列表。'
- en: Table 8-4\. High-level programming projects
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-4. 高级编程项目
- en: '| Project | Description |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| fastai | Library that simplifies training using modern practices ([*https://pytorch.tips/fastai*](https://pytorch.tips/fastai))
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| fastai | 简化使用现代实践进行训练的库（[*https://pytorch.tips/fastai*](https://pytorch.tips/fastai)）
    |'
- en: '| PyTorch Lightning | Customizable Keras-like ML library that eliminates boilerplate
    code ([*https://pytorch.tips/lightning*](https://pytorch.tips/lightning)) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch Lightning | 可定制的类Keras ML库，消除样板代码（[*https://pytorch.tips/lightning*](https://pytorch.tips/lightning)）
    |'
- en: '| Ignite | Library for writing compact, full-featured training loops ([*https://pytorch.tips/ignite*](https://pytorch.tips/ignite))
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Ignite | 用于编写紧凑、功能齐全的训练循环的库（[*https://pytorch.tips/ignite*](https://pytorch.tips/ignite)）
    |'
- en: '| Catalyst | Framework for compact reinforcement learning pipelines ([*https://pytorch.tips/catalyst*](https://pytorch.tips/catalyst))
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Catalyst | 用于紧凑强化学习流水线的框架（[*https://pytorch.tips/catalyst*](https://pytorch.tips/catalyst)）
    |'
- en: '| skorch | Provides PyTorch compatibility with scikit-learn ([*https://pytorch.tips/skorch*](https://pytorch.tips/skorch))
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| skorch | 提供与scikit-learn兼容的PyTorch（[*https://pytorch.tips/skorch*](https://pytorch.tips/skorch)）
    |'
- en: '| Hydra | Framework for configuring complex applications ([*https://pytorch.tips/hydra*](https://pytorch.tips/hydra))
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Hydra | 用于配置复杂应用程序的框架（[*https://pytorch.tips/hydra*](https://pytorch.tips/hydra)）
    |'
- en: '| higher | Facilitates the implementation of complex meta-learning algorithms
    ([*https://pytorch.tips/higher*](https://pytorch.tips/higher)) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| higher | 促进复杂元学习算法实现的库（[*https://pytorch.tips/higher*](https://pytorch.tips/higher)）
    |'
- en: '| Poutyne | Keras-like framework for boilerplate code ([*https://pytorch.tips/poutyne*](https://pytorch.tips/poutyne))
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Poutyne | 用于样板代码的类Keras框架（[*https://pytorch.tips/poutyne*](https://pytorch.tips/poutyne)）
    |'
- en: Fastai is a research and learning framework built on PyTorch. It has comprehensive
    documentation and has provided a high-level API for PyTorch since the library’s
    early days. You can get up to speed with the framework quickly by consultng its
    documentation and free [online courses](https://pytorch.tips/fastai) or reading
    the book [*Deep Learning for Coders with fastai and PyTorch*](https://pytorch.tips/fastai-book)
    by Jeremy Howard and Sylvain Gugger (O’Reilly).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Fastai是建立在PyTorch上的研究和学习框架。它有全面的文档，并自早期提供了PyTorch的高级API。您可以通过查阅其文档和免费的[在线课程](https://pytorch.tips/fastai)或阅读Jeremy
    Howard和Sylvain Gugger（O'Reilly）合著的书籍[*使用fastai和PyTorch进行编码的深度学习*](https://pytorch.tips/fastai-book)来快速掌握该框架。
- en: PyTorch Lightning has also become one a very popular high-level programming
    API for PyTorch. It provides all the necessary boilerplate code for training,
    validation, and test loops while allowing you to easily add customizations for
    your methods.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning也已成为PyTorch非常受欢迎的高级编程API之一。它为训练、验证和测试循环提供了所有必要的样板代码，同时允许您轻松添加自定义方法。
- en: Ignite and Catalyst are also popular high-level frameworks, while skorch and
    Poutyne provide scikit-learn and Keras-like interfaces, respectively. Hydra and
    higher are used to simplify the configuration of complex applications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Ignite和Catalyst也是流行的高级框架，而skorch和Poutyne分别提供了类似于scikit-learn和Keras的接口。Hydra和higher用于简化复杂应用程序的配置。
- en: In addition to high-level frameworks, there are packages in the Ecosystem that
    support hardware acceleration and optimized inference.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了高级框架外，生态系统中还有支持硬件加速和优化推理的软件包。
- en: '[Table 8-5](#table_eco_inference) provides a list of ecosystem projects that
    support *inference acceleration* applications.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-5提供了支持*推理加速*应用程序的生态系统项目列表。
- en: Table 8-5\. Inference projects
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-5。推理项目
- en: '| Project | Description |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Glow | ML compiler for hardware acceleration ([*https://pytorch.tips/glow*](https://pytorch.tips/glow))
    |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Glow | 用于硬件加速的ML编译器（[*https://pytorch.tips/glow*](https://pytorch.tips/glow)）
    |'
- en: '| Hummingbird | Compiles trained models for faster inference ([*https://pytorch.tips/hummingbird*](https://pytorch.tips/hummingbird))
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Hummingbird | 编译经过训练的模型以实现更快推理的库（[*https://pytorch.tips/hummingbird*](https://pytorch.tips/hummingbird)）
    |'
- en: Glow is a machine learning compiler and execution engine for hardware accelerators,
    and it can be used as a backend for high-level deep learning frameworks. The compiler
    allows state-of-the-art optimizations and code generation of neural network graphs.
    Hummingbird is an open source project developed by Microsoft. It is a library
    for compiling trained, traditional ML models into tensor computations and seamlessly
    leverages PyTorch to accelerate traditional ML models.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Glow是用于硬件加速器的机器学习编译器和执行引擎，可以用作高级深度学习框架的后端。该编译器允许进行最先进的优化和神经网络图的代码生成。Hummingbird是由微软开发的开源项目，是一个库，用于将经过训练的传统ML模型编译为张量计算，并无缝地利用PyTorch加速传统ML模型。
- en: In addition to accelerating inference, the PyTorch Ecosystem also contains projects
    to accelerate training and optimize models using distributed training.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了加速推理外，PyTorch生态系统还包含用于加速训练和使用分布式训练优化模型的项目。
- en: '[Table 8-6](#table_eco_distributed) provides a list of ecosystem projects that
    support *distributed training and model optimization*.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-6提供了支持*分布式训练和模型优化*的生态系统项目列表。
- en: Table 8-6\. Distributed training and model optimization projects
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-6。分布式训练和模型优化项目
- en: '| Project | Description |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Ray | Fast, simple framework for building and running distributed applications
    ([*https://pytorch.tips/ray*](https://pytorch.tips/ray)) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Ray | 用于构建和运行分布式应用程序的快速、简单框架（[*https://pytorch.tips/ray*](https://pytorch.tips/ray)）
    |'
- en: '| Horovod | Distributed deep learning training framework for TensorFlow, Keras,
    PyTorch, and Apache MXNet ([*https://pytorch.tips/horovod*](https://pytorch.tips/horovod))
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Horovod | 用于TensorFlow、Keras、PyTorch和Apache MXNet的分布式深度学习训练框架（[*https://pytorch.tips/horovod*](https://pytorch.tips/horovod)）
    |'
- en: '| DeepSpeed | Optimization library ([*https://pytorch.tips/deepspeed*](https://pytorch.tips/deepspeed))
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| DeepSpeed | 优化库（[*https://pytorch.tips/deepspeed*](https://pytorch.tips/deepspeed)）
    |'
- en: '| Optuna | Automated hyperparameter search and optimization ([*https://pytorch.tips/optuna*](https://pytorch.tips/optuna))
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Optuna | 自动化超参数搜索和优化（[*https://pytorch.tips/optuna*](https://pytorch.tips/optuna)）
    |'
- en: '| Polyaxon | Platform for building, training, and monitoring large-scale deep
    learning applications ([*https://pytorch.tips/polyaxon*](https://pytorch.tips/polyaxon))
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Polyaxon | 用于构建、训练和监控大规模深度学习应用程序的平台（[*https://pytorch.tips/polyaxon*](https://pytorch.tips/polyaxon))
    |'
- en: '| Determined | Platform that trains models using shared GPUs and collaboration
    ([*https://pytorch.tips/determined*](https://pytorch.tips/determined)) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Determined | 使用共享GPU和协作训练模型的平台（[*https://pytorch.tips/determined*](https://pytorch.tips/determined))
    |'
- en: '| Allegro Trains | Library that contains a deep learning experiment manager,
    versioning, and machine learning ops ([*https://pytorch.tips/allegro*](https://pytorch.tips/allegro))
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Allegro Trains | 包含深度学习实验管理器、版本控制和机器学习操作的库（[*https://pytorch.tips/allegro*](https://pytorch.tips/allegro))
    |'
- en: Ray is a Python API for building distributed applications and is packaged with
    other libraries for accelerating machine learning workloads. We used one of these
    packages, Ray Tune, in [Chapter 6](ch06.xhtml#pytorth_acceleration_and_optimization)
    to tune hyperparameters on a distributed system. Ray is a very powerful package
    that can also support scalable reinforcement learning, distributed training, and
    scalable serving. Horovod is another distributed framework. It is focused on distributed
    training and can be used with Ray.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Ray是一个用于构建分布式应用程序的Python API，并打包了其他库以加速机器学习工作负载。我们在[第6章](ch06.xhtml#pytorth_acceleration_and_optimization)中使用了其中一个软件包Ray
    Tune来在分布式系统上调整超参数。Ray是一个非常强大的软件包，还可以支持可扩展的强化学习、分布式训练和可扩展的服务。Horovod是另一个分布式框架。它专注于分布式训练，并可与Ray一起使用。
- en: DeepSpeed, Optuna, and Allegro Trains also support hyperparameter tuning and
    model optimization. Polyaxon can be used to train and monitor models at scale,
    and Determined focuses on sharing GPUs for accelerated training.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed、Optuna和Allegro Trains还支持超参数调优和模型优化。Polyaxon可用于规模化训练和监控模型，而Determined专注于共享GPU以加速训练。
- en: With the growth in PyTorch’s popularity, there have been quite a few specialized
    packages developed to support niche domains and specific tools. Many of these
    tools aim to improve models or the preprocessing of data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 随着PyTorch的流行，已经开发了许多专门的软件包来支持特定领域和特定工具。这些工具中的许多旨在改进模型或数据的预处理。
- en: '[Table 8-7](#table_eco_modeling) provides a list of the Ecosystem projects
    that support *modeling and data processing*.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-7](#table_eco_modeling)提供了支持*建模和数据处理*的生态系统项目列表。'
- en: Table 8-7\. Modeling and data processing projects
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-7. 建模和数据处理项目
- en: '| Project | Description |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TensorBoard | TensorBoard’s data and model visualization tool is integrated
    into PyTorch ([*https://pytorch.tips/pytorch-tensorboard*](https://pytorch.tips/pytorch-tensorboard))
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| TensorBoard | TensorBoard的数据和模型可视化工具已集成到PyTorch中（[*https://pytorch.tips/pytorch-tensorboard*](https://pytorch.tips/pytorch-tensorboard))
    |'
- en: '| PyTorch Geometric | Geometric deep learning extension library for PyTorch
    ([*https://pytorch.tips/geometric*](https://pytorch.tips/geometric)) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch Geometric | 用于PyTorch的几何深度学习扩展库（[*https://pytorch.tips/geometric*](https://pytorch.tips/geometric))
    |'
- en: '| Pyro | Flexible and extensible deep probabilistic modeling ([*https://pytorch.tips/pyro*](https://pytorch.tips/pyro))
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Pyro | 灵活且可扩展的深度概率建模（[*https://pytorch.tips/pyro*](https://pytorch.tips/pyro))
    |'
- en: '| Deep Graph Library (DGL) | Library for implementation of graph neural networks
    ([*https://pytorch.tips/dgl*](https://pytorch.tips/dgl)) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Deep Graph Library (DGL) | 用于实现图神经网络的库（[*https://pytorch.tips/dgl*](https://pytorch.tips/dgl))
    |'
- en: '| MMF | Facebook’s modular framework for multi-model deep learning (vision
    and language) ([*https://pytorch.tips/mmf*](https://pytorch.tips/mmf)) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| MMF | Facebook的多模型深度学习（视觉和语言）模块化框架（[*https://pytorch.tips/mmf*](https://pytorch.tips/mmf))
    |'
- en: '| GPyTorch | Library for creating scalable Gaussian process models ([*https://pytorch.tips/gpytorch*](https://pytorch.tips/gpytorch))
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPyTorch | 用于创建可扩展高斯过程模型的库（[*https://pytorch.tips/gpytorch*](https://pytorch.tips/gpytorch))
    |'
- en: '| BoTorch | Library for Bayesian optimization ([*https://pytorch.tips/botorch*](https://pytorch.tips/botorch))
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| BoTorch | 用于贝叶斯优化的库（[*https://pytorch.tips/botorch*](https://pytorch.tips/botorch))
    |'
- en: '| Torch Points 3D | Framework for unstructured 3D spatial data ([*https://pytorch.tips/torchpoints3d*](https://pytorch.tips/torchpoints3d))
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Torch Points 3D | 用于非结构化3D空间数据的框架（[*https://pytorch.tips/torchpoints3d*](https://pytorch.tips/torchpoints3d))
    |'
- en: '| TensorLy | High level API for tensor methods and deep tensorized neural networks
    ([*https://pytorch.tips/tensorly*](https://pytorch.tips/tensorly))([*https://pytorch.tips/advertorch*](https://pytorch.tips/advertorch))
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| TensorLy | 用于张量方法和深度张量神经网络的高级API（[*https://pytorch.tips/tensorly*](https://pytorch.tips/tensorly))([*https://pytorch.tips/advertorch*](https://pytorch.tips/advertorch))
    |'
- en: '| BaaL | Implements active learning from Bayesian theory ([*https://pytorch.tips/baal*](https://pytorch.tips/baal))
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| BaaL | 从贝叶斯理论中实现主动学习（[*https://pytorch.tips/baal*](https://pytorch.tips/baal))
    |'
- en: '| PennyLane | Library for quantum ML ([*https://pytorch.tips/pennylane*](https://pytorch.tips/pennylane))
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| PennyLane | 量子机器学习库（[*https://pytorch.tips/pennylane*](https://pytorch.tips/pennylane))
    |'
- en: TensorBoard is a very popular visualization tool developed for TensorFlow that
    can be used for PyTorch as well. We’ll cover this tool and its PyTorch API later
    in this chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard是为TensorFlow开发的非常流行的可视化工具，也可以用于PyTorch。我们将在本章后面介绍这个工具及其PyTorch API。
- en: PyTorch Geometric, Pyro, GPyTorch, BoTorch, and BaaL all support different types
    of modeling, such as geometric, probabilistic, Gaussian modeling, and Bayesian
    optimization.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Geometric、Pyro、GPyTorch、BoTorch和BaaL都支持不同类型的建模，如几何建模、概率建模、高斯建模和贝叶斯优化。
- en: Facebook’s MMF is a feature-rich package for multi-modal modeling, and Torch
    Points 3D can be used to model generic 3D spatial data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook的MMF是一个功能丰富的多模态建模软件包，而Torch Points 3D可用于对通用的3D空间数据进行建模。
- en: PyTorch’s maturity and stability as a tool shows in the advent of packages used
    to support security and privacy. Security and privacy concerns are becoming more
    important as regulations require systems to be compliant in these domains.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch作为一个工具的成熟和稳定性体现在用于支持安全和隐私的软件包的出现。随着法规要求系统在这些领域合规，安全和隐私问题变得更加重要。
- en: '[Table 8-8](#table_eco_sec) provides a list of ecosystem projects that support
    *security and privacy*.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-8](#table_eco_sec)提供了支持*安全性和隐私性*的生态系统项目列表。'
- en: Table 8-8\. Security and privacy projects
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-8\. 安全和隐私项目
- en: '| Project | Description |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| AdverTorch | Modules for adversarial examples and defending against attacks
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| AdverTorch | 用于对抗性示例和防御攻击的模块 |'
- en: '| PySyft | Library for model encryption and privacy ([*https://pytorch.tips/pysyft*](https://pytorch.tips/pysyft))
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| PySyft | 用于模型加密和隐私的库（[*https://pytorch.tips/pysyft*](https://pytorch.tips/pysyft))
    |'
- en: '| Opacus | Library for training models with differential privacy ([*https://pytorch.tips/opacus*](https://pytorch.tips/opacus))
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Opacus | 用于训练具有差分隐私的模型的库（[*https://pytorch.tips/opacus*](https://pytorch.tips/opacus))
    |'
- en: '| CrypTen | Framework for privacy preserving ML ([*https://pytorch.tips/crypten*](https://pytorch.tips/crypten))
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| CrypTen | 隐私保护ML的框架（[*https://pytorch.tips/crypten*](https://pytorch.tips/crypten))
    |'
- en: PySyft, Opacus, and CrypTen are PyTorch packages that support security and privacy.
    They add features to protect and encrypt models and the data used to create them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: PySyft、Opacus和CrypTen是支持安全性和隐私性的PyTorch包。它们添加了保护和加密模型以及用于创建模型的数据的功能。
- en: 'Often deep learning seems like a black box, where developers have no idea why
    models make the decisions they make. Today, however, this lack of transparency
    is no longer acceptable: there is a growing awareness that companies and their
    executives must be held accountable for the fairness and operations of their algorithms.
    Model interpretability is important for researchers, developers, and company executives
    to understand why models produce their results.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，深度学习似乎是一个黑匣子，开发人员不知道模型为什么做出决策。然而，如今，这种缺乏透明度已不再可接受：人们越来越意识到公司及其高管必须对其算法的公平性和运作负责。模型可解释性对于研究人员、开发人员和公司高管来说很重要，以了解模型为何产生其结果。
- en: '[Table 8-9](#table_eco_interpret) shows the ecosystem project that support
    *model* *interpretability*.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-9](#table_eco_interpret)显示了支持*模型* *可解释性*的生态系统项目。'
- en: Table 8-9\. Model interpretability projects
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-9\. 模型可解释性项目
- en: '| Project | Description |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Captum | Library for model interpretability ([*https://pytorch.tips/captum*](https://pytorch.tips/captum))
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Captum | 用于模型可解释性的库（[*https://pytorch.tips/captum*](https://pytorch.tips/captum))
    |'
- en: '| Visual attribution | PyTorch implementation of recent visual attribution
    methods for model interpretability ([*https://pytorch.tips/visual-attribution*](https://pytorch.tips/visual-attribution))
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 视觉归因 | 用于模型可解释性的最新视觉归因方法的PyTorch实现（[*https://pytorch.tips/visual-attribution*](https://pytorch.tips/visual-attribution))
    |'
- en: Currently, Captum is the premier PyTorch project that supports model interpretability.
    The Visual attribution package is useful for interpreting computer vision models
    and identifying image saliency. As the field expands, more projects are sure to
    enter this space.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Captum是支持模型可解释性的首要PyTorch项目。视觉归因包对解释计算机视觉模型和识别图像显著性很有用。随着领域的扩展，更多的项目肯定会进入这个领域。
- en: As you can see, the PyTorch Ecosystem includes a broad range of open source
    projects that can assist you in many different ways. Perhaps you are working on
    a project that could benefit other researchers. If you’d like to make your project
    a part of the official PyTorch Ecosystem, visit the [PyTorch Ecosystem application
    page](https://pytorch.tips/join-ecosystem).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，PyTorch生态系统包括广泛的开源项目，可以在许多不同的方面帮助您。也许您正在开展一个可以使其他研究人员受益的项目。如果您希望将您的项目纳入官方PyTorch生态系统，请访问[PyTorch生态系统申请页面](https://pytorch.tips/join-ecosystem)。
- en: 'When considering applications, the PyTorch team looks for projects that meet
    the following requirements:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑应用程序时，PyTorch团队寻找符合以下要求的项目：
- en: Your project uses PyTorch to improve the user experience, add new capabilities,
    or speed up training/inference.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的项目使用PyTorch来改善用户体验、添加新功能或加快训练/推理速度。
- en: Your project is stable, well maintained, and includes adequate infrastructure,
    documentation, and technical support.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的项目稳定、维护良好，并包含足够的基础设施、文档和技术支持。
- en: The Ecosystem is constantly growing. To access the latest list of projects,
    visit the [PyTorch Ecosystem website.](https://pytorch.tips/ecosystem) To update
    us on new projects for the book, please email the author at [jpapa@joepapa.ai](mailto:jpapa@joepapa.ai).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 生态系统不断增长。要获取最新的项目列表，请访问[PyTorch生态系统网站](https://pytorch.tips/ecosystem)。要向我们更新书中的新项目，请发送电子邮件至[作者邮箱jpapa@joepapa.ai](mailto:jpapa@joepapa.ai)。
- en: Next, we will go a little deeper into some of the PyTorch project’s supporting
    tools and libraries. We obviously can’t cover all of the available libraries and
    tools in this book, but in the following sections we’ll explore a few of the most
    popular and useful ones to give you a deeper understanding of their APIs and usage.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更深入地了解一些PyTorch项目的支持工具和库。显然，我们无法在本书中涵盖所有可用的库和工具，但在接下来的章节中，我们将探索一些最受欢迎和有用的库，以帮助您更深入地了解它们的API和用法。
- en: Torchvision for Image and Video
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Torchvision用于图像和视频
- en: We’ve used Torchvision through this book, and it is one of the most powerful
    and useful PyTorch libraries for computer vision research. Technically, the Torchvision
    package is part of the PyTorch project. It consists of a selection of popular
    datasets, model architectures, and common image transformations.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书中使用了Torchvision，它是计算机视觉研究中最强大和有用的PyTorch库之一。从技术上讲，Torchvision包是PyTorch项目的一部分。它包括一系列流行的数据集、模型架构和常见的图像转换。
- en: Datasets and I/O
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集和I/O
- en: 'Torchvision provides a large assortment of datasets. They are included in the
    `torchvision.datasets` library and can be accessed by creating a dataset object,
    as shown in the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision提供了大量的数据集。它们包含在`torchvision.datasets`库中，可以通过创建数据集对象来访问，如下面的代码所示：
- en: '[PRE0]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You simply call the constructor function and pass in the appropriate options.
    This code creates a dataset object from the CIFAR-10 dataset using the training
    data with no transforms. It look for the dataset files in the current directory,
    and if they don’t exist, it will download them.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需调用构造函数并传入适当的选项。此代码使用训练数据从CIFAR-10数据集创建数据集对象，不使用任何转换。它会在当前目录中查找数据集文件，如果文件不存在，它将下载它们。
- en: '[Table 8-10](#table_torchvision_datasets) provides a comprehensive list of
    datasets available from Torchvision.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-10](#table_torchvision_datasets)提供了Torchvision提供的数据集的全面列表。'
- en: Table 8-10\. Torchvision datasets
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-10。Torchvision数据集
- en: '| Dataset | Description |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 描述 |'
- en: '| --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| CelebA | Large-scale face attributes dataset with more than 200,000 celebrity
    images, each with 40 attribute annotations. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| CelebA | 大规模人脸属性数据集，包含超过200,000张名人图像，每张图像有40个属性注释。 |'
- en: '| CIFAR-10 | CIFAR-10 dataset consisting of 60,000 32 × 32 color images in
    10 classes, split into 50,000 training and 10,000 test images. The CIFAR-100 dataset,
    which has 100 classes, is also available. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | CIFAR-10数据集包含60,000个32×32彩色图像，分为10个类别，分为50,000个训练图像和10,000个测试图像。还提供了包含100个类别的CIFAR-100数据集。
    |'
- en: '| Cityscapes | Large-scale dataset containing video sequences recorded in street
    scenes from 50 different cities, with annotations. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Cityscapes | 包含来自50个不同城市街景记录的视频序列的大规模数据集，带有注释。 |'
- en: '| COCO | Large-scale object detection, segmentation, and captioning dataset.
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| COCO | 大规模目标检测、分割和字幕数据集。 |'
- en: '| DatasetFolder | Used to create any dataset from files in a folder structure.
    |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| DatasetFolder | 用于从文件夹结构中创建任何数据集。 |'
- en: '| EMNIST | An extension of MNIST to handwritten letter. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| EMNIST | MNIST的手写字母扩展。 |'
- en: '| FakeData | A fake dataset that returns randomly generated images as PIL images.
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| FakeData | 一个返回随机生成图像作为PIL图像的虚假数据集。 |'
- en: '| Fashion-MNIST | Dataset of Zalando’s clothing images matching the MNIST format
    (60,000 training examples, 10,000 test examples, 28 × 28 grayscale images, 10
    classes). |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Fashion-MNIST | Zalando服装图像数据集，符合MNIST格式（60,000个训练示例，10,000个测试示例，28×28灰度图像，10个类别）。
    |'
- en: '| Flickr | Flickr 8,000-image dataset. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Flickr | Flickr 8,000张图像数据集。 |'
- en: '| HMDB51 | Large human motion database of video sequences. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| HMDB51 | 大型人体运动视频序列数据库。 |'
- en: '| ImageFolder | Used to create an image dataset from files in a folder structure.
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| ImageFolder | 用于从文件夹结构中创建图像数据集。 |'
- en: '| ImageNet | Image classification dataset with 14,197,122 images and 21,841
    word phrases. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet | 包含14,197,122张图像和21,841个单词短语的图像分类数据集。 |'
- en: '| Kinetics-400 | Large-scale action recognition video dataset with 650,000
    10-second video clips that cover up to 700 human action classes such as playing
    instruments, shaking hands, and hugging. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Kinetics-400 | 大规模动作识别视频数据集，包含650,000个持续10秒的视频剪辑，涵盖高达700个人类动作类别，如演奏乐器、握手和拥抱。
    |'
- en: '| KMNIST | Kuzushiji-MNIST, a drop-in replacement for the MNIST dataset (70,000
    28 × 28 grayscale images) where one character represents each of the 10 rows of
    Hiragana. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| KMNIST | Kuzushiji-MNIST，MNIST数据集的替代品（70,000个28×28灰度图像），其中每个字符代表平假名的10行之一。
    |'
- en: '| LSUN | One million labeled images for each of 10 scene categories and 20
    object categories. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| LSUN | 每个10个场景类别和20个对象类别的一百万标记图像。 |'
- en: '| MNIST | Handwritten, single-digit numbers as 28 × 28 grayscale images with
    60,000 training and 10,000 test samples. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| MNIST | 手写的单个数字，28×28灰度图像，有60,000个训练和10,000个测试样本。 |'
- en: '| Omniglot | Human-generated dataset of 1,623 different handwritten characters
    from 50 different alphabets. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Omniglot | 由50种不同字母表的1,623个不同手写字符生成的数据集。 |'
- en: '| PhotoTour | Photo tourism dataset consisting of 1,024 × 1,024 bitmap images,
    each containing a 16 × 16 array of image patches. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| PhotoTour | 包含1,024×1,024位图图像的照片旅游数据集，每个图像包含一个16×16的图像块数组。 |'
- en: '| Places365 | Dataset of 10 million images comprising 400+ unique scene categories
    with 5,000 to 30,000 training images per class. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Places365 | 包含400多个独特场景类别的10,000,000张图像数据集，每个类别有5,000至30,000张训练图像。 |'
- en: '| QMNIST | Facebook’s project to generate an MNIST dataset from the original
    data found in the NIST Special Database 19. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| QMNIST | Facebook的项目，从NIST特殊数据库19中找到的原始数据生成MNIST数据集。 |'
- en: '| SBD | Semantic boundaries dataset that contains annotations from 11,355 images
    for semantic segmentation. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| SBD | 包含11,355张图像的语义分割注释的语义边界数据集。 |'
- en: '| SBU | Stony Brook University (SBU) captioned photo dataset containing over
    1 million captioned images. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| SBU | Stony Brook大学（SBU）标题照片数据集，包含超过1,000,000张带标题的图像。 |'
- en: '| STL10 | CIFAR-10-like dataset used for unsupervised learning. 10 classes
    of 96 × 96 color images with 5,000 training, 8,000 test, and 100,000 unlabeled
    images. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| STL10 | 用于无监督学习的类似于CIFAR-10的数据集。96×96彩色图像的10个类别，包括5,000个训练图像，8,000个测试图像和100,000个未标记图像。
    |'
- en: '| SVHN | Street view house numbers dataset, similar to MNIST but with 10× more
    data in natural scene color images. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| SVHN | 街景房屋号码数据集，类似于MNIST，但是在自然场景彩色图像中有10倍的数据。 |'
- en: '| UCF101 | Action recognition dataset with 13,320 videos from 101 action categories.
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| UCF101 | 包含来自101个动作类别的13,320个视频的动作识别数据集。 |'
- en: '| USPS | Dataset of 16 × 16 handwritten text images with 10 classes, 7,291
    training and 2,007 test images. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| USPS | 包含16×16手写文本图像的数据集，有10个类别，7,291个训练图像和2,007个测试图像。 |'
- en: '| VOC | PASCAL visual object classes image datasets for object class recognition.
    The 2012 version has 20 classes, 11,530 training/validation images with 27,450
    region of interest (ROI) annotated objects and 6,929 segmentations. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| VOC | 用于目标类别识别的PASCAL视觉对象类别图像数据集。2012年版本有20个类别，11,530个训练/验证图像，27,450个感兴趣区域（ROI）标注对象和6,929个分割。
    |'
- en: More datasets are being added to Torchvision all the time. For an up-to-date
    list, visit the [Torchvision documentation](https://pytorch.tips/torchvision-datasets).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision不断添加更多数据集。要获取最新列表，请访问[Torchvision文档](https://pytorch.tips/torchvision-datasets)。
- en: Models
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: 'Torchvision also provides an extensive list of models, containing both the
    module architectures and pretrained weights if available. The model object is
    easily created by calling the corresponding constructor function, as shown here:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还提供了一个广泛的模型列表，包括模块架构和预训练权重（如果有的话）。通过调用相应的构造函数，可以轻松创建模型对象，如下所示：
- en: '[PRE1]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code creates a VGG16 model with random weights since the pretrained weights
    are not used. You can instantiate many different computer vision models by using
    a similar constructor and setting the appropriate parameters. Torchvision provides
    pretrained models using the PyTorch `torch.utils.model_zoo`. These can be constructed
    by passing `pretrained=True`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建了一个带有随机权重的VGG16模型，因为没有使用预训练权重。通过使用类似的构造函数并设置适当的参数，可以实例化许多不同的计算机视觉模型。Torchvision使用PyTorch的`torch.utils.model_zoo`提供预训练模型。可以通过传递`pretrained=True`来构建这些模型。
- en: '[Table 8-11](#table_torchvision_models) provides a comprehensive list of models
    included in Torchvision, by category. These models are well known in the research
    community, and the table includes references to the research papers associated
    with each model.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-11](#table_torchvision_models)提供了Torchvision中包含的模型的全面列表，按类别分类。这些模型在研究界广为人知，表中包含了与每个模型相关的研究论文的参考文献。'
- en: Table 8-11\. Torchvision models
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-11. Torchvision模型
- en: '| Model | Paper |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 论文 |'
- en: '| --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Classification** |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| **分类** |  |'
- en: '| AlexNet | “One Weird Trick for Parallelizing Convolutional Neural Networks,”
    by Alex Krizhevsky |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | “用于并行化卷积神经网络的一个奇怪技巧,” 作者：Alex Krizhevsky |'
- en: '| VGG | “Very Deep Convolutional Networks for Large-Scale Image Recognition,”
    by Karen Simonyan and Andrew Zisserman |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| VGG | “用于大规模图像识别的非常深度卷积网络,” 作者：Karen Simonyan和Andrew Zisserman |'
- en: '| ResNet | “Deep Residual Learning for Image Recognition,” by Kaiming He et
    al. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| ResNet | “用于图像识别的深度残差学习,” 作者：Kaiming He等 |'
- en: '| SqueezeNet | “SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters
    and <0.5MB Model Size,” by Forrest N. Iandola et al. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| SqueezeNet | “SqueezeNet: AlexNet级别的准确性，参数减少50倍，模型大小<0.5MB,” 作者：Forrest N.
    Iandola等 |'
- en: '| DenseNet | “Densely Connected Convolutional Networks,” by Gao Huang et al.
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| DenseNet | “密集连接的卷积网络,” 作者：Gao Huang等 |'
- en: '| Inception v3 | “Rethinking the Inception Architecture for Computer Vision,”
    by Christian Szegedy et al. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Inception v3 | “重新思考计算机视觉中的Inception架构,” 作者：Christian Szegedy等 |'
- en: '| GoogLeNet | “Going Deeper with Convolutions,” by Christian Szegedy et al.
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| GoogLeNet | “使用卷积深入研究,” 作者：Christian Szegedy等 |'
- en: '| ShuffleNet v2 | “ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture
    Design,” by Ningning Ma et al. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| ShuffleNet v2 | “ShuffleNet V2: 高效CNN架构设计的实用指南,” 作者：马宁宁等 |'
- en: '| MobileNet v2 | “MobileNetV2: Inverted Residuals and Linear Bottlenecks,”
    by Mark Sandler et al. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| MobileNet v2 | “MobileNetV2: 反向残差和线性瓶颈,” 作者：Mark Sandler等 |'
- en: '| ResNeXt | “Aggregated Residual Transformations for Deep Neural Networks,”
    by Saining Xie et al. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| ResNeXt | “用于深度神经网络的聚合残差变换,” 作者：Saining Xie等 |'
- en: '| Wide ResNet | “Wide Residual Networks,” by Sergey Zagoruyko and Nikos Komodakis
    |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Wide ResNet | “宽残差网络,” 作者：Sergey Zagoruyko和Nikos Komodakis |'
- en: '| MNASNet | “MnasNet: Platform-Aware Neural Architecture Search for Mobile,”
    by Mingxing Tan et al. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| MNASNet | “MnasNet: 面向移动设备的神经架构搜索,” 作者：Mingxing Tan等 |'
- en: '| **Semantic segmentation** |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| **语义分割** |  |'
- en: '| FCN ResNet50 | “Fully Convolutional Networks for Semantic Segmentation,”
    by Jonathan Long et al. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| FCN ResNet50 | “用于语义分割的全卷积网络,” 作者：Jonathan Long等 |'
- en: '| FCN ResNet101 | See above |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| FCN ResNet101 | 参见上文 |'
- en: '| DeepLabV3 ResNet50 | “Rethinking Atrous Convolution for Semantic Image Segmentation,”
    by Liang-Chieh Chen et al. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| DeepLabV3 ResNet50 | “重新思考空洞卷积用于语义图像分割,” 作者：Liang-Chieh Chen等 |'
- en: '| DeepLabV3 ResNet101 | See above |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| DeepLabV3 ResNet101 | 参见上文 |'
- en: '| **Object detection** |  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| **目标检测** |  |'
- en: '| Faster R-CNN ResNet-50 | “FPNFaster R-CNN: Towards Real-Time Object Detection
    with Region Proposal Networks,” by Shaoqing Ren et al. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Faster R-CNN ResNet-50 | “FPNFaster R-CNN: 实时目标检测与区域建议网络,” 作者：Shaoqing Ren等
    |'
- en: '| Mask R-CNN ResNet-50 FPN | “Mask R-CNN,” by Kaiming He et al. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Mask R-CNN ResNet-50 FPN | “Mask R-CNN,” 作者：Kaiming He等 |'
- en: '| **Video classification** |  |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| **视频分类** |  |'
- en: '| ResNet 3D 18 | “A Closer Look at Spatiotemporal Convolutions for Action Recognition,”
    by Du Tran et al. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| ResNet 3D 18 | “仔细研究时空卷积用于动作识别,” 作者：Du Tran等 |'
- en: '| ResNet MC 18 | See above |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| ResNet MC 18 | 参见上文 |'
- en: '| ResNet (2+1)D | See above |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| ResNet (2+1)D | 参见上文 |'
- en: New computer vision models are also being added to Torchvision all the time.
    For an up-to-date list, visit the [Torchvision documentation](https://pytorch.tips/torchvision-models).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还在不断添加新的计算机视觉模型。要获取最新列表，请访问[Torchvision文档](https://pytorch.tips/torchvision-models)。
- en: Transforms, Operations, and Utilities
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变换、操作和实用程序
- en: 'Torchvision also provides a comprehensive collection of transforms, operations,
    and utilities to assist in image preprocessing and data preparation. A common
    approach to applying transforms is to form a composition of transforms and pass
    this `transforms` object into the dataset constructor function, as shown in the
    following code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还提供了一套全面的变换、操作和实用程序集合，以帮助图像预处理和数据准备。应用变换的常见方法是形成一组变换的组合，并将这个`transforms`对象传递给数据集构造函数，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we create a composite transform that converts the data to a tensor using
    `ToTensor()` then normalizes the image data using predetermined means and standard
    deviations for each channel. Setting the `transform` parameter to this `train_transforms`
    object configures the dataset to apply the sequence of transforms when data is
    accessed.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个复合变换，使用`ToTensor()`将数据转换为张量，然后使用预定的均值和标准差对图像数据进行归一化。将`transform`参数设置为`train_transforms`对象会配置数据集在访问数据时应用一系列变换。
- en: '[Table 8-12](#table_torchvision_transforms) provides a complete list of available
    transforms from `torchvision.transforms`. Transforms that appear in *`italics`*
    in this and [Table 8-13](#table_torchvision_transforms_pil) are currently not
    supported by TorchScript.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-12](#table_torchvision_transforms)提供了`torchvision.transforms`中可用转换的完整列表。在本表和[表8-13](#table_torchvision_transforms_pil)中以*`斜体`*显示的转换目前不受TorchScript支持。'
- en: Table 8-12\. Torchvision transforms
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-12\. Torchvision 转换
- en: '| Transform | Description |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 转换 | 描述 |'
- en: '| --- | --- |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Operational transforms** |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| **操作转换** |  |'
- en: '| `Compose()` | Creates a transform based on a sequence of other transforms
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| `Compose()` | 基于其他转换序列创建一个转换 |'
- en: '| `CenterCrop(size)` | Crops an image in the center with the given size |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| `CenterCrop(size)` | 以给定大小在中心裁剪图像 |'
- en: '| `ColorJitter(brightness=0,` `contrast=0,` `saturation=0, hue=0)` | Randomly
    changes the brightness, contrast, saturation, and hue of an image |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| `ColorJitter(brightness=0,` `contrast=0,` `saturation=0, hue=0)` | 随机改变图像的亮度、对比度、饱和度和色调
    |'
- en: '| `FiveCrop(size)` | Crops an image into four corners and the center crop |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| `FiveCrop(size)` | 将图像裁剪成四个角和中心裁剪 |'
- en: '| `Grayscale(num_output_channels=1)` | Converts a color image to grayscale
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| `Grayscale(num_output_channels=1)` | 将彩色图像转换为灰度图像 |'
- en: '| `Pad(`*`padding`*`,` `fill=0,` `padding_mode=constant)` | Pads the edges
    of an image with the given value |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| `Pad(`*`padding`*`,` `fill=0,` `padding_mode=constant)` | 使用给定值填充图像的边缘 |'
- en: '| `RandomAffine(`*`degrees`*`,` `translate=None,` `scale=None, shear=None,
    resample=0, fillcolor=0)` | Randomly applies an affine transformation |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| `RandomAffine(`*`degrees`*`,` `translate=None,` `scale=None, shear=None,
    resample=0, fillcolor=0)` | 随机应用仿射变换 |'
- en: '| `RandomApply(transforms, p=0.5)` | Randomly applies a list of transforms
    with a given probability |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| `RandomApply(transforms, p=0.5)` | 以给定概率随机应用一系列转换 |'
- en: '| `RandomCrop(`*`size`*`,` `padding=None, pad_if_needed=False, fill=0,` `padding_mode=constant)`
    | Crops an image at a random location |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| `RandomCrop(`*`size`*`,` `padding=None, pad_if_needed=False, fill=0,` `padding_mode=constant)`
    | 在随机位置裁剪图像 |'
- en: '| `RandomGrayscale(p=0.1)` | Randomly converts an image to grayscale with a
    given probability |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| `RandomGrayscale(p=0.1)` | 以给定概率随机将图像转换为灰度图像 |'
- en: '| `RandomHorizontalFlip(p=0.5)` | Randomly flips an image horizontally with
    a given probability |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| `RandomHorizontalFlip(p=0.5)` | 以给定概率随机水平翻转图像 |'
- en: '| `RandomPerspective(distor⁠⁠tion_​scale=0.5, p=0.5,` `interpolation=2,` `fill=0)`
    | Applies a random perspective transformation |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| `RandomPerspective(distor⁠⁠tion_​scale=0.5, p=0.5,` `interpolation=2,` `fill=0)`
    | 应用随机透视变换 |'
- en: '| `RandomResizedCrop(`*`size`*`,` `scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333),`
    `interpolation=2)` | Resizes an image with a random size and aspect ratio |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| `RandomResizedCrop(`*`size`*`,` `scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333),`
    `interpolation=2)` | 使用随机大小和长宽比调整图像 |'
- en: '| `RandomRotation(`*`degrees`*`,` `resample=False,` `expand=False,` `center=None,`
    `fill=None)` | Rotates an image randomly |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| `RandomRotation(`*`degrees`*`,` `resample=False,` `expand=False,` `center=None,`
    `fill=None)` | 随机旋转图像 |'
- en: '| `RandomVerticalFlip(p=0.5)` | Randomly flips an image vertically with a given
    probability |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| `RandomVerticalFlip(p=0.5)` | 以给定概率随机垂直翻转图像 |'
- en: '| `Resize(`*`size`*`,` `interpolation=2)` | Resizes an image to a random size
    |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| `Resize(`*`size`*`,` `interpolation=2)` | 将图像调整为随机大小 |'
- en: '| `TenCrop(`*`size`*`,` `vertical_flip=False)` | Crops an image into four corners
    and the center crop and additionally provides a flipped version of each |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| `TenCrop(`*`size`*`,` `vertical_flip=False)` | 将图像裁剪成四个角和中心裁剪，并额外提供每个的翻转版本
    |'
- en: '| `GaussianBlur(`*`kernel_size`*`,` `sigma=(0.1, 2.0))` | Applies a Gaussian
    blur with a random kernel |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| `GaussianBlur(`*`kernel_size`*`,` `sigma=(0.1, 2.0))` | 使用随机核应用高斯模糊 |'
- en: '| **Conversion transforms** |  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| **转换转换** |  |'
- en: '| *`ToPILImage(mode=None)`* | Converts a tensor or `numpy.ndarray` to a PIL
    image |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| *`ToPILImage(mode=None)`* | 将张量或`numpy.ndarray`转换为PIL图像 |'
- en: '| *`ToTensor()`* | Converts a PIL image or `ndarray` to a tensor |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| *`ToTensor()`* | 将PIL图像或`ndarray`转换为张量 |'
- en: '| **Generic transforms** |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| **通用转换** |  |'
- en: '| *`Lambda(lambda)`* | Applies a user-defined `lambda` as a transform |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| *`Lambda(lambda)`* | 将用户定义的`lambda`作为转换应用 |'
- en: Most of the transforms can operate on images in tensor or PIL format with a
    `[..., C, H, W]` shape, where `...` means an arbitrary number of leading dimensions.
    However, some transforms only operate on PIL images or tensor image data.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数转换可以在张量或PIL格式的图像上进行操作，其形状为`[..., C, H, W]`，其中`...`表示任意数量的前导维度。然而，一些转换只能在PIL图像或张量图像数据上操作。
- en: The transforms listed in [Table 8-13](#table_torchvision_transforms_pil) operate
    only on PIL images. These transforms are currently not supported by TorchScript.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表8-13](#table_torchvision_transforms_pil)中列出的转换仅适用于PIL图像。这些转换目前不受TorchScript支持。
- en: Table 8-13\. Torchvision PIL-only transforms
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-13\. Torchvision 仅支持PIL的转换
- en: '| Transform | Description |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 转换 | 描述 |'
- en: '| --- | --- |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| *`RandomChoice(transforms)`* | Applies a single transform picked randomly
    from a list |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| *`RandomChoice(transforms)`* | 从列表中随机选择一个转换应用 |'
- en: '| *`RandomOrder(transforms)`* | Applies a sequence of transforms in random
    order |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| *`RandomOrder(transforms)`* | 以随机顺序应用一系列转换 |'
- en: The transforms listed in [Table 8-14](#table_torchvision_transforms_tensor)
    operate only on tensor images.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表8-14](#table_torchvision_transforms_tensor)中列出的转换仅适用于张量图像。
- en: Table 8-14\. Torchvision tensor-only transforms
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-14\. Torchvision 仅支持张量的转换
- en: '| Transform | Description |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 转换 | 描述 |'
- en: '| --- | --- |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `LinearTransformation(​trans⁠⁠formation_matrix,` `mean_vector)` | Applies
    a linear transformation to a tensor image based on a square transformation matrix
    and a `mean_vector` computed offline. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| `LinearTransformation(​trans⁠⁠formation_matrix,` `mean_vector)` | 根据离线计算的方形变换矩阵和`mean_vector`对张量图像应用线性变换。
    |'
- en: '| `Normalize(mean, std, inplace=False)` | Normalizes a tensor image with a
    given mean and standard deviation. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| `Normalize(mean, std, inplace=False)` | 使用给定的均值和标准差对张量图像进行归一化。 |'
- en: '| `RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)`
    | Randomly chooses a rectangle region and erases its pixels. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| `RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)`
    | 随机选择一个矩形区域并擦除其像素。 |'
- en: '| `ConvertImageDtype(dtype: torch.dtype)` | Converts a tensor image to a new
    data type and automatically scales its values to match the type |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| `ConvertImageDtype(dtype: torch.dtype)` | 将张量图像转换为新的数据类型，并自动缩放其值以匹配该类型 |'
- en: Note
  id: totrans-246
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Use `torch.nn.Sequential()` instead of `torchvi⁠sion.​transforms.Compose()`
    when scripting transforms for C++ usage. The following code shows an example:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在为C++使用脚本转换时，请使用`torch.nn.Sequential()`而不是`torchvision.transforms.Compose()`。以下代码显示了一个示例：
- en: '[PRE3]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Many of the transforms listed in the previous tables contain a random number
    generator for specifying the parameter. For example, `RandomResizedCrop()` crops
    an image to a random size and aspect ratio.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的表中列出的许多转换包含用于指定参数的随机数生成器。例如，`RandomResizedCrop()`将图像裁剪为随机大小和长宽比。
- en: Torchvision also provides functional transforms as part of the `torchvision.transforms.functional`
    package. You can use these transforms to perform transformations with a specific
    set of parameters that you choose. For example, you could call `torchvision.transforms.functional.adjust_brightness()`
    to adjust the brightness of one on more images.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还提供了功能性转换作为`torchvision.transforms.functional`包的一部分。您可以使用这些转换来执行具有您选择的特定参数集的转换。例如，您可以调用`torchvision.transforms.functional.adjust_brightness()`来调整一个或多个图像的亮度。
- en: '[Table 8-15](#table_torchvision_functional) provides a list of the supported
    functional transforms.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-15](#table_torchvision_functional)提供了支持的功能性转换列表。'
- en: Table 8-15\. Torchvision functional transforms
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-15。Torchvision功能性转换
- en: '| Functional transforms and utilities |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: 功能性转换和实用程序
- en: '| --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| `adjust_brightness(`*`img: torch.Tensor,`* *`brightness_factor: float`*`)`
    |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| `adjust_brightness(`*`img: torch.Tensor,`* *`brightness_factor: float`*`)`
    |'
- en: '| `adjust_contrast(`*`img: torch.Tensor,`* *`contrast_factor: float`*`)` |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| `adjust_contrast(`*`img: torch.Tensor,`* *`contrast_factor: float`*`)` |'
- en: '| `adjust_gamma(`*`img: torch.Tensor, gamma: float,`* *`gain: float = 1`*`)`
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| `adjust_gamma(`*`img: torch.Tensor, gamma: float,`* *`gain: float = 1`*`)`
    |'
- en: '| `adjust_hue(`*`img: torch.Tensor, hue_factor: float`*`)` → *`torch.Tensor`*
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| `adjust_hue(`*`img: torch.Tensor, hue_factor: float`*`)` → *`torch.Tensor`*
    |'
- en: '| `adjust_saturation(`*`img: torch.Tensor,`* *`saturation_factor: float`*`)`
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| `adjust_saturation(`*`img: torch.Tensor,`* *`saturation_factor: float`*`)`
    |'
- en: '| `affine(`*`img: torch.Tensor, angle: float,`* *`translate: List[int],`* *`scale:
    float, shear: List[float],`* *`resample: int = 0, fillcolor: Optional[int] = None`*`)`
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| `affine(`*`img: torch.Tensor, angle: float,`* *`translate: List[int],`* *`scale:
    float, shear: List[float],`* *`resample: int = 0, fillcolor: Optional[int] = None`*`)`
    |'
- en: '| `center_crop(`*`img: torch.Tensor, output_size: List[int]`*`)` |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| `center_crop(`*`img: torch.Tensor, output_size: List[int]`*`)` |'
- en: '| `convert_image_dtype(`*`image: torch.Tensor,`* *`dtype: torch.dtype = torch.float32`*`)`
    |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| `convert_image_dtype(`*`image: torch.Tensor,`* *`dtype: torch.dtype = torch.float32`*`)`
    |'
- en: '| `crop(`*`img: torch.Tensor, top: int, left: int,`* *`height: int, width:
    int`*`)` |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| `crop(`*`img: torch.Tensor, top: int, left: int,`* *`height: int, width:
    int`*`)` |'
- en: '| `erase(`*`img: torch.Tensor, i: int, j: int, h: int,`* *`w: int, v: torch.Tensor,
    inplace: bool = False`*`)` |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| `erase(`*`img: torch.Tensor, i: int, j: int, h: int,`* *`w: int, v: torch.Tensor,
    inplace: bool = False`*`)` |'
- en: '| `five_crop(`*`img: torch.Tensor, size: List[int]`*`)` |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| `five_crop(`*`img: torch.Tensor, size: List[int]`*`)` |'
- en: '| `gaussian_blur(`*`img: torch.Tensor, kernel_size: List[int], sigma: Optional[List[float]]
    = None`*`)` |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| `gaussian_blur(`*`img: torch.Tensor, kernel_size: List[int], sigma: Optional[List[float]]
    = None`*`)` |'
- en: '| `hflip(`*`img: torch.Tensor`*`)` |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| `hflip(`*`img: torch.Tensor`*`)` |'
- en: '| `normalize(`*`tensor: torch.Tensor, mean: List[float], std: List[float],
    inplace: bool = False`*`)` |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| `normalize(`*`tensor: torch.Tensor, mean: List[float], std: List[float],
    inplace: bool = False`*`)` |'
- en: '| `pad(`*`img: torch.Tensor, padding: List[int],`* *`fill: int = 0, padding_mode:
    str = constant`*`)` |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| `pad(`*`img: torch.Tensor, padding: List[int],`* *`fill: int = 0, padding_mode:
    str = constant`*`)` |'
- en: '| `perspective(`*`img: torch.Tensor, startpoints: List[List[int]], endpoints:
    List[List[int]],`* *`interpolation: int = 2, fill: Optional[int] = None`*`)` |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| `perspective(`*`img: torch.Tensor, startpoints: List[List[int]], endpoints:
    List[List[int]],`* *`interpolation: int = 2, fill: Optional[int] = None`*`)` |'
- en: '| `pil_to_tensor(`*`pic`*`)` |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| `pil_to_tensor(`*`pic`*`)` |'
- en: '| `resize(`*`img: torch.Tensor, size: List[int],`* *`interpolation: int = 2`*`)`
    |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| `resize(`*`img: torch.Tensor, size: List[int],`* *`interpolation: int = 2`*`)`
    |'
- en: '| `resized_crop(`*`img: torch.Tensor, top: int, left: int, height: int, width:
    int, size: List[int],`* *`interpolation: int = 2`*`)` |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| `resized_crop(`*`img: torch.Tensor, top: int, left: int, height: int, width:
    int, size: List[int],`* *`interpolation: int = 2`*`)` |'
- en: '| `rgb_to_grayscale(`*`img: torch.Tensor,`* *`num_output_channels: int = 1`*`)`
    |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| `rgb_to_grayscale(`*`img: torch.Tensor,`* *`num_output_channels: int = 1`*`)`
    |'
- en: '| `rotate(`*`img: torch.Tensor, angle: float,`* *`resample: int = 0, expand:
    bool = False,`* *`center: Optional[List[int]] = None,`* *`fill: Optional[int]
    = None`*`)` |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| `rotate(`*`img: torch.Tensor, angle: float,`* *`resample: int = 0, expand:
    bool = False,`* *`center: Optional[List[int]] = None,`* *`fill: Optional[int]
    = None`*`)` |'
- en: '| `ten_crop(`*`img: torch.Tensor, size: List[int],`* *`vertical_flip: bool
    = False`*`)` |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| `ten_crop(`*`img: torch.Tensor, size: List[int],`* *`vertical_flip: bool
    = False`*`)` |'
- en: '| `to_grayscale(`*`img, num_output_channels=1`*`)` |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| `to_grayscale(`*`img, num_output_channels=1`*`)` |'
- en: '| `to_pil_image(`*`pic, mode=None`*`)` |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| `to_pil_image(`*`pic, mode=None`*`)` |'
- en: '| `to_tensor(`*`pic`*`)` |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| `to_tensor(`*`pic`*`)` |'
- en: '| `vflip(`*`img: torch.Tensor`*`)` |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| `vflip(`*`img: torch.Tensor`*`)` |'
- en: '| `utils.save_image(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], fp:
    Union[str, pathlib.Path,`* *`BinaryIO],`* *`nrow: int = 8, padding: int = 2, normalize:
    bool = False, range: Optional[Tuple[int, int]] = None, scale_each: bool = False,
    pad_value: int = 0, format: Optional[str] = None`*`)` |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| `utils.save_image(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], fp:
    Union[str, pathlib.Path,`* *`BinaryIO],`* *`nrow: int = 8, padding: int = 2, normalize:
    bool = False, range: Optional[Tuple[int, int]] = None, scale_each: bool = False,
    pad_value: int = 0, format: Optional[str] = None`*`)` |'
- en: '| `utils.make_grid(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], nrow:
    int = 8, padding: int = 2, normalize: bool = False, range: Optional[Tuple[int,
    int]] = None, scale_each: bool = False,`* *`pad_value: int = 0`*`)` |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| `utils.make_grid(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], nrow:
    int = 8, padding: int = 2, normalize: bool = False, range: Optional[Tuple[int,
    int]] = None, scale_each: bool = False,`* *`pad_value: int = 0`*`)` |'
- en: As you can see in the table above, Torchvision provides a robust set of functional
    operations that you can use to process your image data. Each one has its own set
    of parameters for robust control.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如上表所示，Torchvision提供了一组强大的功能操作，可用于处理图像数据。每个操作都有自己的一组参数，用于强大的控制。
- en: In addition, Torchvision provides functions to facilitate I/O and operations.
    [Table 8-16](#table_torchvision_io_ops) provides a list of some of these functions.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Torchvision提供了用于简化I/O和操作的函数。[表8-16](#table_torchvision_io_ops)列出了其中一些函数。
- en: Table 8-16\. Torchvision functions for I/O and operations
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-16\. Torchvision的I/O和操作函数
- en: '| Function |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 函数 |'
- en: '| --- |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Video** |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **视频** |'
- en: '| `io.read_video(`*`filename: str, start_pts: int = 0, end_pts: Optional[float]
    = None, pts_unit: str = pts`*`)` |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| `io.read_video(`*`filename: str, start_pts: int = 0, end_pts: Optional[float]
    = None, pts_unit: str = pts`*`)` |'
- en: '| `io.read_video_timestamps9`*`filename: str, pts_unit: str = pts`*`)` |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| `io.read_video_timestamps9`*`filename: str, pts_unit: str = pts`*`)` |'
- en: '| `io.write_video9`*`filename: str, video_array:`* *`torch.Tensor,`* *`_fps:
    float, video_codec: str = *libx264*, options: Optional[Dict[str, Any]] = None`*`)`
    |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| `io.write_video9`*`filename: str, video_array:`* *`torch.Tensor,`* *`_fps:
    float, video_codec: str = *libx264*, options: Optional[Dict[str, Any]] = None`*`)`
    |'
- en: '| **Fine-grained video** |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| **细粒度视频** |'
- en: '| `io.VideoReader(`*`path, stream=video`*`)` |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| `io.VideoReader(`*`path, stream=video`*`)` |'
- en: '| **Image** |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| **图像** |'
- en: '| `io.decode_image(`*`input: torch.Tensor`*`)` |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| `io.decode_image(`*`input: torch.Tensor`*`)` |'
- en: '| `io.encode_jpeg(`*`input: torch.Tensor, quality: int = 75`*`)` |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| `io.encode_jpeg(`*`input: torch.Tensor, quality: int = 75`*`)` |'
- en: '| `io.read_image(`*`path: str`*`)` |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| `io.read_image(`*`path: str`*`)` |'
- en: '| `io.write_jpeg(`*`input: torch.Tensor, filename: str,`* *`quality: int =
    75`*`)` |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| `io.write_jpeg(`*`input: torch.Tensor, filename: str,`* *`quality: int =
    75`*`)` |'
- en: '| `io.encode_png(`*`input: torch.Tensor, compression_level: int = 6`*`)` |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| `io.encode_png(`*`input: torch.Tensor, compression_level: int = 6`*`)` |'
- en: '| `io.write_png(`*`input: torch.Tensor, filename: str,`* *`compression_level:
    int = 6`*`)` |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| `io.write_png(`*`input: torch.Tensor, filename: str,`* *`compression_level:
    int = 6`*`)` |'
- en: The preceding functions are provided so that you can quickly read and write
    video and image files in multiple formats. They allow you to speed up your image
    and video processing without the need to write these functions from scratch.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数是为了让您能够快速读取和写入多种格式的视频和图像文件。它们让您能够加快图像和视频处理的速度，而无需从头开始编写这些函数。
- en: As you can see, Torchvision is a feature-rich, well-supported, and mature PyTorch
    package. This section provided a quick reference to the Torchvision API. In the
    next section, we’ll explore another popular PyTorch package for NLP and text applications
    called Torchtext.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Torchvision是一个功能丰富、得到良好支持且成熟的PyTorch包。本节提供了Torchvision API的快速参考。在下一节中，我们将探索另一个用于NLP和文本应用的流行PyTorch包Torchtext。
- en: Torchtext for NLP
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Torchtext用于NLP
- en: The Torchtext package consists of a collection of data-processing utilities
    and popular datasets for NLP. The Torchtext API is slightly different from the
    Torchvision API, but the overall approach is the same.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext包含一系列用于数据处理的实用工具和流行的NLP数据集。Torchtext API与Torchvision API略有不同，但整体方法是相同的。
- en: Create a Dataset Object
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据集对象
- en: 'First you create a dataset and describe a preprocessing pipeline, as we did
    with Torchvision transforms. Torchtext provides a set of well-known datasets out
    of the box. For example, we can load the IMDb dataset as shown in the following
    code:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建一个数据集，并描述一个预处理流水线，就像我们在Torchvision转换中所做的那样。Torchtext提供了一组知名数据集。例如，我们可以加载IMDb数据集，如下面的代码所示：
- en: '[PRE4]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We automatically create an iterator and can access the data using `next()`.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们自动创建一个迭代器，并可以使用`next()`访问数据。
- en: Warning
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Torchtext significantly changed its API in PyTorch 1.8\. If the code in this
    section returns errors, you may need to upgrade your version of PyTorch.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext在PyTorch 1.8中显著改变了其API。如果本节中的代码返回错误，您可能需要升级PyTorch的版本。
- en: Preprocess Data
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理数据
- en: Torchtext also provides features to preprocess text and create data pipelines.
    Preprocessing tasks may include defining tokenizers, vocabularies, and numerical
    embeddings.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext还提供了预处理文本和创建数据管道的功能。预处理任务可能包括定义分词器、词汇表和数值嵌入。
- en: 'In the new Torchtext API, you can access different tokenizers using the `data.get_tokenizer()`
    function, as shown in the following code:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的Torchtext API中，您可以使用`data.get_tokenizer()`函数访问不同的分词器，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Creating vocabularies in the new API is also flexible. You can build a vocabulary
    directly with the `Vocab` class, as shown in the following code:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在新API中创建词汇表也是灵活的。您可以直接使用`Vocab`类构建词汇表，如下面的代码所示：
- en: '[PRE6]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, we can set the `min_freq` to specify the cutoff frequency in
    the vocabulary. We can also assign tokens to special symbols like `<BOS>` and
    `<EOS>`, as shown in the constructor of the `Vocab` class.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们可以设置`min_freq`来指定词汇表中的截止频率。我们还可以将特殊符号分配给特殊符号，比如`<BOS>`和`<EOS>`，如`Vocab`类的构造函数所示。
- en: 'Another useful feature is to define transforms for text and labels, as shown
    in the following code:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的功能是为文本和标签定义转换，如下面的代码所示：
- en: '[PRE7]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We pass in a text string to our transforms, and we use the vocabulary and tokenizer
    to preprocess the data.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将文本字符串传递给我们的转换，然后使用词汇表和分词器对数据进行预处理。
- en: Create a Dataloader for Batching
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建用于批处理的数据加载器
- en: 'Now that we have loaded and preprocessed our data, the last step is to create
    a dataloader to sample and batch data from the dataset. We can create a dataloader
    with the following code:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载并预处理了数据，最后一步是创建一个数据加载器，以从数据集中对数据进行采样和批处理。我们可以使用以下代码创建一个数据加载器：
- en: '[PRE8]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You may notice that this code is similar to the code with which we created a
    dataloader in Torchvision. Instead of passing in the dataset object, we pass the
    `train_iter` cast as a `list()`. The `DataLoader()` constructor also accepts `batch_sampler`
    and `collate_fcn` parameters (not shown in the preceding code; see the [documentation](https://pytorch.tips/data))
    so you can customize how the dataset is sampled and collated. After you create
    the dataloader, use it to train your model, as shown in the preceding code comments.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到，这段代码与我们在Torchvision中创建数据加载器的代码相似。我们不是传入数据集对象，而是将`train_iter`转换为`list()`传入。`DataLoader()`构造函数还接受`batch_sampler`和`collate_fcn`参数（在上述代码中未显示；请参阅[文档](https://pytorch.tips/data)），因此您可以自定义数据集的采样和整理方式。创建数据加载器后，使用它来训练您的模型，如上述代码注释所示。
- en: Torchtext has many useful features. Let’s explore what’s available from the
    API.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext具有许多有用的功能。让我们探索API中提供的内容。
- en: Data (torchtext.data)
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据（torchtext.data）
- en: The `torchtext.data` API provides functions for creating text-based dataset
    objects in PyTorch. [Table 8-17](#table_torchtext_data) lists the available functions
    in `torchtext.data`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '`torchtext.data` API提供了在PyTorch中创建基于文本的数据集对象的函数。[表8-17](#table_torchtext_data)列出了`torchtext.data`中可用的函数。'
- en: Table 8-17\. Torchtext data
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-17\. Torchtext数据
- en: '| Function | Description |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 函数 | 描述 |'
- en: '| --- | --- |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **`torchtext.data.utils`** |  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| **`torchtext.data.utils`** |  |'
- en: '| `get_tokenizer(`*`tokenizer,`* *`language=en`*`)` | Generates a tokenizer
    function for a string sentence |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| `get_tokenizer(`*`tokenizer,`* *`language=en`*`)` | 为字符串句子生成一个分词器函数 |'
- en: '| `ngrams_itera⁠⁠tor(`*`token_​list, ngrams`*`)` | Returns an iterator that
    yields the given tokens and their ngrams |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| `ngrams_itera⁠⁠tor(`*`token_​list, ngrams`*`)` | 返回一个迭代器，产生给定标记及其ngrams |'
- en: '| **`torchtext.data.functional`** |  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| **`torchtext.data.functional`** |  |'
- en: '| `generate_sp_model(​`*`file⁠⁠name, vocab_size=20000, model_type=unigram,
    model_prefix=m_user`*`)` | Trains a `SentencePiece` tokenizer |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| `generate_sp_model(​`*`file⁠⁠name, vocab_size=20000, model_type=unigram,
    model_prefix=m_user`*`)` | 训练一个`SentencePiece`分词器 |'
- en: '| `load_sp_model(`*`spm`*`)` | Loads a `SentencePiece` model from a file |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| `load_sp_model(`*`spm`*`)` | 从文件加载一个`SentencePiece`模型 |'
- en: '| `sentencepiece_​numeri⁠⁠cal⁠⁠izer(`*`sp_model`*`)` | Creates a generator
    that takes in a text sentence and outputs the corresponding identifiers based
    on a `SentencePiece` model |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| `sentencepiece_​numeri⁠⁠cal⁠⁠izer(`*`sp_model`*`)` | 创建一个生成器，接受文本句子并根据`SentencePiece`模型输出相应的标识符
    |'
- en: '| `sentencepiece_​token⁠⁠izer(`*`sp_model`*`)` | Creates a generator that takes
    in a text sentence and outputs the corresponding tokens based on a `SentencePiece`
    model |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| `sentencepiece_​token⁠⁠izer(`*`sp_model`*`)` | 创建一个生成器，接受文本句子并根据`SentencePiece`模型输出相应的标记
    |'
- en: '| `custom_replace(`*`replace_​pat⁠⁠tern`*`)` | Acts as a transform to convert
    text strings |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| `custom_replace(`*`replace_​pat⁠⁠tern`*`)` | 作为一个转换器，将文本字符串转换 |'
- en: '| `simple_space_split(​`*`itera⁠⁠tor`*`)` | Acts as a transform to split text
    strings by spaces |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| `simple_space_split(​`*`itera⁠⁠tor`*`)` | 作为一个转换器，通过空格分割文本字符串 |'
- en: '| `numerical⁠⁠ize_tokens_​from_iterator(`*`vocab,`* *`iterator,`* *`removed_tokens=None`*`)`
    | Yields a list of identifiers from a token iterator with a `vocab` |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| `numerical⁠⁠ize_tokens_​from_iterator(`*`vocab,`* *`iterator,`* *`removed_tokens=None`*`)`
    | 从一个标记迭代器中产生一个标识符列表，使用`vocab` |'
- en: '| **`torchtext.data.metrics`** |  |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| **`torchtext.data.metrics`** |  |'
- en: '| `bleu_score(`*`candidate_​cor⁠⁠pus, references_corpus, max_n=4, weights=[0.25,
    0.25, 0.25, 0.25]`*`)` | Computes the BLEU score between a candidate translation
    corpus and a reference translation corpus |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| `bleu_score(`*`candidate_​cor⁠⁠pus, references_corpus, max_n=4, weights=[0.25,
    0.25, 0.25, 0.25]`*`)` | 计算候选翻译语料库和参考翻译语料库之间的BLEU分数 |'
- en: As you can see, the `torchtext.data` submodule supports functions for creating
    dataset objects based on fields aas well as for loading, preprocessing, and iterating
    through batches. Next let’s see what NLP datasets are available from the Torchtext
    library.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，`torchtext.data`子模块支持根据字段创建数据集对象的函数，以及加载、预处理和迭代批次。接下来让我们看看Torchtext库中提供的NLP数据集有哪些。
- en: Datasets (torchtext.datasets)
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集（torchtext.datasets）
- en: Torchtext supports loading datasets from popular papers and research. You can
    find datasets for language modeling, sentiment analysis, text classification,
    question classification, entailment, machine translation, sequence tagging, question
    answering, and unsupervised learning.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext支持从流行论文和研究中加载数据集。您可以找到用于语言建模、情感分析、文本分类、问题分类、蕴涵、机器翻译、序列标记、问题回答和无监督学习的数据集。
- en: '[Table 8-18](#table_torchtext_datasets) provides a comprehensive list of the
    datasets included in Torchtext.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-18](#table_torchtext_datasets)提供了Torchtext中包含的数据集的全面列表。'
- en: Table 8-18\. Torchtext datasets
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-18\. Torchtext数据集
- en: '| Function | Description |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 函数 | 描述 |'
- en: '| --- | --- |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Text classification** |  |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| **文本分类** |  |'
- en: '| `TextClassificationDataset(`*`vocab, data, labels`*`)` | Generic text-classification
    dataset |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| `TextClassificationDataset(`*`vocab, data, labels`*`)` | 通用文本分类数据集 |'
- en: '| `IMDB(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Binary sentiment
    analysis dataset consisting of 50,000 reviews labeled as positive or negative
    from IMDb |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| `IMDB(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | 包含来自IMDb的50,000条评论，标记为正面或负面的二元情感分析数据集
    |'
- en: '| `AG_NEWS(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset of
    news articles labeled with four topics |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| `AG_NEWS(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | 包含四个主题标记的新闻文章数据集
    |'
- en: '| `SogouNews(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of news
    articles labeled with five topics |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| `SogouNews(`*`root=*.data*, split=(*train*, *test*`*`))` | 包含五个主题标记的新闻文章数据集
    |'
- en: '| `DBpedia(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of news
    articles labeled with 14 categories |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| `DBpedia(`*`root=*.data*, split=(*train*, *test*`*`))` | 包含14个类别标记的新闻文章数据集
    |'
- en: '| `YelpReviewPolarity(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset
    of 500,000 Yelp reviews with binary classification |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| `YelpReviewPolarity(`*`root=*.data*, split=(*train*, *test*`*`))` | 包含50万条Yelp评论的二元分类数据集
    |'
- en: '| `YelpReviewFull(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of
    500,000 Yelp reviews with fine-grained (five-class) classification |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| `YelpReviewFull(`*`root=*.data*, split=(*train*, *test*`*`))` | 包含50万条Yelp评论的数据集，具有细粒度（五类）分类
    |'
- en: '| `YahooAnswers(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset
    of Yahoo answers labeled in 10 different categories |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| `YahooAnswers(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | 包含10个不同类别的Yahoo答案的数据集
    |'
- en: '| `AmazonReviewPolarity(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))`
    | Dataset of Amazon reviews with binary classification |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| `AmazonReviewPolarity(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))`
    | 包含亚马逊评论的数据集，具有二元分类 |'
- en: '| `AmazonReviewFull(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset
    of Amazon reviews with fine-grained (five-class) classification |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| `AmazonReviewFull(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | 包含亚马逊评论的数据集，具有细粒度（五类）分类
    |'
- en: '| **Language modeling** |  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| **语言建模** |  |'
- en: '| `LanguageModelingDataset(`*`path, text_field, newline_eos=True,`* *`encoding=*utf-8*,
    **kwargs`*`)` | General language modeling dataset class |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| `LanguageModelingDataset(`*`path, text_field, newline_eos=True,`* *`encoding=*utf-8*,
    **kwargs`*`)` | 通用语言建模数据集类 |'
- en: '| `WikiText2(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` |
    WikiText long-term dependency language modeling dataset, a collection of over
    100 million tokens extracted from the set of verified “Good” and “Featured” articles
    on Wikipedia |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| `WikiText2(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` |
    WikiText长期依赖语言建模数据集，从维基百科上经过验证的“优秀”和“精选”文章中提取的超过1亿个标记的集合 |'
- en: '| `WikiText103(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | Larger WikiText dataset |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| `WikiText103(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | 更大的WikiText数据集 |'
- en: '| `PennTreebank(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | A relatively small dataset originally created for part of speech (POS) tagging
    |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| `PennTreebank(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | 最初为词性（POS）标记创建的相对较小的数据集 |'
- en: '| **Machine translation** |  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| **机器翻译** |  |'
- en: '| `TranslationDataset(`*`path, exts, fields, **kwargs`*`)` | Generic translation
    dataset class |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| `TranslationDataset(`*`path, exts, fields, **kwargs`*`)` | 通用翻译数据集类 |'
- en: '| `IWSLT2016(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`*`)`*`,`* *`valid_set=*tst2013*, test_set=*tst2014*`*`)`
    | International Conference on Spoken Language Translation (IWSLT) 2016 TED talk
    translation task |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| `IWSLT2016(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`)`*`,`* *`valid_set=*tst2013*, test_set=*tst2014*`*`)`
    | 国际口语翻译会议（IWSLT）2016 TED演讲翻译任务 |'
- en: '| `IWSLT2017(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`*`))` | International Conference on Spoken Language
    Translation (IWSLT) 2017 TED talk translation task |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| `IWSLT2017(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`*`))` | 国际口语翻译会议（IWSLT）2017 TED演讲翻译任务 |'
- en: '| **Sequence tagging** |  |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| **序列标记** |  |'
- en: '| `SequenceTaggingDataset(`*`path, fields, encoding=*utf-8*,`* *`separator=*t*,
    **kwargs`*`)` | Generic sequence-tagging dataset class |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| `SequenceTaggingDataset(`*`path, fields, encoding=*utf-8*,`* *`separator=*t*,
    **kwargs`*`)` | 通用序列标记数据集类 |'
- en: '| `UDPOS(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` | Universal
    dependencies version 2 POS-tagged data |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| `UDPOS(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` | 通用依存关系版本2词性标记数据
    |'
- en: '| `CoNLL2000Chunking(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` |
    Command that downloads and loads the Conference on Computational Natural Language
    Learning (CoNLL) 2000 chunking dataset |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| `CoNLL2000Chunking(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` |
    下载和加载Conference on Computational Natural Language Learning (CoNLL) 2000分块数据集的命令
    |'
- en: '| **Question answering** |  |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| **问答** |  |'
- en: '| `SQuAD1(`*`root=*.data*, split=`*`(`*`*train*, *dev*`*`))` | Creates the
    Stanford Question Answering Dataset (SQuAD) 1.0 dataset, a reading comprehension
    dataset consisting of questions posed by crowdworkers on a set of Wikipedia articles
    |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| `SQuAD1(`*`root=*.data*, split=`*`(`*`*train*, *dev*`*`))` | 创建斯坦福问答数据集（SQuAD）1.0数据集，这是一个由众包工作者在一组维基百科文章上提出的问题的阅读理解数据集
    |'
- en: '| `SQuAD2(`*`root=.data, split=`*`(`*`train, dev`*`))` | Creates the Stanford
    Question Answering Dataset (SQuAD) 2.0 dataset, a dataset that extends the 1.0
    dataset by adding over 50,000 unanswerable questions |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| `SQuAD2(`*`root=.data, split=`*`(`*`train, dev`*`))` | 创建斯坦福问答数据集（SQuAD）2.0数据集，该数据集通过添加超过5万个无法回答的问题扩展了1.0数据集
    |'
- en: Torchtext developers are always adding new datasets. For the most updated list,
    visit the [Torchtext datasets documentation](https://pytorch.tips/torchtext-datasets).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext开发人员始终在添加新的数据集。要获取最新列表，请访问[Torchtext数据集文档](https://pytorch.tips/torchtext-datasets)。
- en: Once you load data, whether from existing datasets or ones that you create,
    you will need to convert the text data to numeric data before training a model
    and running inference. To do so, we use vocabularies and word embeddings that
    provide the maps to perform these conversions. Next, we’ll examine the Torchtext
    functions used to support vocabularies.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据后，无论是来自现有数据集还是您创建的数据集，您都需要在训练模型和运行推理之前将文本数据转换为数值数据。为此，我们使用提供映射以执行这些转换的词汇表和词嵌入。接下来，我们将检查用于支持词汇表的Torchtext函数。
- en: Vocabularies (torchtext.vocab)
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词汇表（torchtext.vocab）
- en: Torchtext provides generic classes and specific classes for popular vocabularies.
    [Table 8-19](#table_torchtext_vocab) provides a list of classes in `torchtext.vocab`
    to support the creation and use of vocabularies.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: Torchtext提供了通用类和特定类来支持流行的词汇表。[表8-19](#table_torchtext_vocab)提供了`torchtext.vocab`中的类列表，以支持词汇表的创建和使用。
- en: Table 8-19\. Torchtext vocabularies
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-19. Torchtext词汇表
- en: '| Function | Description |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 功能 | 描述 |'
- en: '| --- | --- |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Vocabulary classes** |  |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| **词汇表类** |  |'
- en: '| `Vocab(counter, max_size=None, min_freq=1,` `specials=(<unk>,` `<pad>),`
    *`vectors=None,`* *`unk_init=None,`* *`vectors_cache=None,`* *`specials_first=True`*`)`
    | Defines a vocabulary object that will be used to numericalize a field |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| `Vocab(counter, max_size=None, min_freq=1,` `specials=(<unk>,` `<pad>),`
    *`vectors=None,`* *`unk_init=None,`* *`vectors_cache=None,`* *`specials_first=True`*`)`
    | 定义将用于数值化字段的词汇表对象 |'
- en: '| `SubwordVocab(`*`counter, max_size=None,`* *`specials=<pad>,`* *`vectors=None,`*
    *`unk_init=<method zero_of torch._C._TensorBase objects>`*`)` | Creates a `revtok`
    subword vocabulary from a `collections.Counter` |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| `SubwordVocab(`*`counter, max_size=None,`* *`specials=<pad>,`* *`vectors=None,`*
    *`unk_init=<method zero_of torch._C._TensorBase objects>`*`)` | 从`collections.Counter`创建一个`revtok`子词汇表
    |'
- en: '| `Vectors(`*`name, cache=None, url=None, unk_init=None,`* *`max_vectors=None`*`)`
    | Generic class for word vector embeddings |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| `Vectors(`*`name, cache=None, url=None, unk_init=None,`* *`max_vectors=None`*`)`
    | 用于词向量嵌入的通用类 |'
- en: '| **Pretrained word embeddings** |  |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| **预训练词嵌入** |  |'
- en: '| `GloVe(`*`name=*840B*, dim=300, **kwargs`*`)` | Global vectors (GloVe) model
    for distributed word representation, developed at Stanford |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| `GloVe(`*`name=*840B*, dim=300, **kwargs`*`)` | 全局向量（GloVe）模型，用于分布式词表示，由斯坦福大学开发
    |'
- en: '| `FastText(`*`language=en, **kwargs`*`)` | Pretrained word embeddings for
    294 languages, created by Facebook’s AI Research lab |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| `FastText(`*`language=en, **kwargs`*`)` | 294种语言的预训练词嵌入，由Facebook的AI研究实验室创建
    |'
- en: '| `CharNGram(`*`**kwargs`*`)` | CharNGram embeddings, a simple approach for
    learning character-based compositional models to embed textual sequences |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| `CharNGram(`*`**kwargs`*`)` | CharNGram嵌入，一种学习基于字符的组合模型以嵌入文本序列的简单方法 |'
- en: '| **Miscellaneous** |  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| **杂项** |  |'
- en: '| `build_vocab_from_​itera⁠⁠tor(​`*`iter⁠⁠ator, num_lines=None`*`)` | Builds
    a vocabulary by cycling through an iterator |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| `build_vocab_from_​itera⁠⁠tor(​`*`iter⁠⁠ator, num_lines=None`*`)` | 通过循环遍历迭代器构建词汇表
    |'
- en: As you can see, Torchtext provides a robust set of functionality to support
    text-based modeling and NLP research. For more information, visit the [Torchtext
    documentation](https://pytorch.tips/torchtext).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，Torchtext提供了一套强大的功能，支持基于文本的建模和NLP研究。欲了解更多信息，请访问[Torchtext文档](https://pytorch.tips/torchtext)。
- en: Whether you’re developing deep learning models for NLP, computer vision, or
    another field, it’s helpful to be able to visualize models, data, and performance
    metrics as you go. In the next section, we’ll explore another powerful package
    for visualization called TensorBoard.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是为NLP、计算机视觉或其他领域开发深度学习模型，能够在开发过程中可视化模型、数据和性能指标是很有帮助的。在下一节中，我们将探索另一个强大的用于可视化的包，称为TensorBoard。
- en: TensorBoard for Visualization
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于可视化的TensorBoard
- en: TensorBoard is a visualization toolkit that’s included in PyTorch’s major competing
    deep learning framework, TensorFlow. Instead of developing its own visualization
    toolkit, PyTorch integrates with TensorBoard and leverages its visualization capabilities
    natively.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard是一个可视化工具包，包含在PyTorch的主要竞争深度学习框架TensorFlow中。PyTorch没有开发自己的可视化工具包，而是与TensorBoard集成，并原生地利用其可视化能力。
- en: With TensorBoard, you can visualize learning curves, scalar data, model architectures,
    weight distributions, and 3D data embeddings, as well as keep track of hyperparameter
    experiment results. This section will show you how to use TensorBoard with PyTorch
    and provide a reference to the TensorBoard API.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard，您可以可视化学习曲线、标量数据、模型架构、权重分布和3D数据嵌入，以及跟踪超参数实验结果。本节将向您展示如何在PyTorch中使用TensorBoard，并提供TensorBoard
    API的参考。
- en: The TensorBoard application is run on a local or remote server, and the display
    and user interface run in a browser. We can also run TensorBoard inside Jupyter
    Notebook or Google Colab.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard应用程序在本地或远程服务器上运行，显示和用户界面在浏览器中运行。我们还可以在Jupyter Notebook或Google Colab中运行TensorBoard。
- en: 'I’ll use Colab in this book to demonstrate the capabilities of TensorBoard,
    but the process is very similar for running it locally or remotely in the cloud.
    Colab comes with TensorBoard preinstalled, and you can run it directly in a cell
    using magic commands, as shown in the following code:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在本书中使用Colab来演示TensorBoard的功能，但在本地或远程云中运行它的过程非常类似。Colab预装了TensorBoard，您可以直接在单元格中使用魔术命令运行它，如下所示的代码：
- en: '[PRE9]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: First we load the `tensorboard` extension and then we run `tensorboard` and
    specify the log directory that holds the event files. Event files hold the data
    from PyTorch that will be displayed in the TensorBoard application.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们加载`tensorboard`扩展，然后运行`tensorboard`并指定保存事件文件的日志目录。事件文件保存了来自PyTorch的数据，将在TensorBoard应用程序中显示。
- en: Since we haven’t created any event files yet, you will see an empty display,
    as shown in [Figure 8-1](#fig_0801).
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们尚未创建任何事件文件，您将看到一个空的显示，如[图8-1](#fig_0801)所示。
- en: '![“TensorBoard Application”](Images/ptpr_0801.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![“TensorBoard应用程序”](Images/ptpr_0801.png)'
- en: Figure 8-1\. TensorBoard application
  id: totrans-406
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1\. TensorBoard应用程序
- en: By clicking on the arrow next to INACTIVE in the upper-right menu, you will
    see the possible display tabs. One commonly used display tab is the SCALARS tab.
    This tab can display any scalar value over time. We often use the SCALARS display
    to view loss and accuracy training curves. Let’s see how you can save scalar values
    for TensorBoard in your PyTorch code.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 通过单击右上角菜单中INACTIVE旁边的箭头，您将看到可能的显示选项卡。一个常用的显示选项卡是SCALARS选项卡。此选项卡可以显示随时间变化的任何标量值。我们经常使用SCALARS显示来查看损失和准确率训练曲线。让我们看看如何在您的PyTorch代码中保存标量值以供TensorBoard使用。
- en: Note
  id: totrans-408
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The  PyTorch  integration  with  TensorBoard  was  originally  implemented  by
     an  open  source  project  called  TensorBoardX.  Since  then,  TensorBoard  support
     has  been  integrated into the PyTorch project as the `torch.utils.tensorboard`
     package  and  it’s  actively  maintained  by  the  PyTorch  development  team.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch与TensorBoard的集成最初是由一个名为TensorBoardX的开源项目实现的。自那时起，TensorBoard支持已集成到PyTorch项目中，作为`torch.utils.tensorboard`包，并由PyTorch开发团队积极维护。
- en: 'First let’s import PyTorch’s TensorBoard interface and set up PyTorch for use
    with TensorBoard, as shown in the following code:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们导入PyTorch的TensorBoard接口，并设置PyTorch以便与TensorBoard一起使用，如下所示的代码：
- en: '[PRE10]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO1-1)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO1-1)'
- en: The writer will output to the *./runs/* directory by default.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，写入器将输出到*./runs/*目录。
- en: 'We simply import the `SummaryWriter` class from the PyTorch `tensorboard` package
    and instantiate a `SummaryWriter` object. To write data to TensorBoard, all we
    need to do is call methods from the `SummaryWriter` object. To save our loss values
    while our model is training, we use the `add_scalar()` method, as shown in the
    following code:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需从PyTorch的`tensorboard`包中导入`SummaryWriter`类，并实例化一个`SummaryWriter`对象。要将数据写入TensorBoard，我们只需要调用`SummaryWriter`对象的方法。在模型训练时保存我们的损失数值，我们使用`add_scalar()`方法，如下面的代码所示：
- en: '[PRE11]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO2-1)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO2-1)'
- en: Log `loss.item()` as an event to `tensorboard`.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 将`loss.item()`作为事件记录到`tensorboard`。
- en: This is just an example training loop. You can assume the `model` has already
    been defined and the `trainloader` has been created. Not only does the code print
    the loss every epoch, but it also logs it to a `tensorboard` event. We can either
    refresh the TensorBoard application in the previous cell or create another cell
    altogether using the `%tensorboard` command.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个示例训练循环。您可以假设`model`已经被定义，`trainloader`已经被创建。代码不仅在每个epoch打印损失，还将其记录到`tensorboard`事件中。我们可以刷新之前单元格中的TensorBoard应用程序，或者使用`%tensorboard`命令创建另一个单元格。
- en: Learning Curves with SCALARS
  id: totrans-419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SCALARS查看学习曲线
- en: TensorBoard provides the ability to plot one or more scalar values over time.
    This is useful in deep learning development to display metrics as your model trains.
    By viewing metrics like loss or accuracy it’s easy to see if your model’s training
    is stable and continues to improve.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard提供了绘制一个或多个标量值随时间变化的能力。在深度学习开发中，这对于显示模型训练时的指标非常有用。通过查看损失或准确率等指标，您可以轻松地看到您的模型训练是否稳定并持续改进。
- en: '[Figure 8-2](#fig_0802) shows an example display of learning curves using TensorBoard.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-2](#fig_0802)展示了使用TensorBoard显示学习曲线的示例。'
- en: You can interact with the display by sliding the smoothing factor, and you can
    also see the curve at each epoch by mousing over the plots. TensorBoard allows
    you to apply smoothing to iron out instabilities and show the overall progress.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过滑动平滑因子与显示进行交互，也可以通过将鼠标悬停在绘图上查看每个epoch的曲线。TensorBoard允许您应用平滑处理以消除不稳定性并显示整体进展。
- en: '![“Visualizing Learning Curves with TensorBoard”](Images/ptpr_0802.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![“使用TensorBoard可视化学习曲线”](Images/ptpr_0802.png)'
- en: Figure 8-2\. TensorBoard learning curves
  id: totrans-424
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. TensorBoard学习曲线
- en: Model Architectures with GRAPHS
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GRAPHS查看模型架构
- en: 'Another useful feature of TensorBoard is visualizing your deep learning model
    using graphs. To save a graph to the event file, we will use the `add_graph()`
    method, as shown in the following code:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard的另一个有用功能是使用图形可视化您的深度学习模型。要将图形保存到事件文件中，我们将使用`add_graph()`方法，如下面的代码所示：
- en: '[PRE12]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this code we instantiate a VGG16 model and write the model to an event file.
    We can display the model graph by either refreshing an existing TensorBoard cell
    or creating a new one. [Figure 8-3](#fig_0803) shows the graph visualization tool
    in TensorBoard.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们实例化了一个VGG16模型，并将模型写入事件文件。我们可以通过刷新现有的TensorBoard单元格或创建一个新的单元格来显示模型图。[图8-3](#fig_0803)展示了TensorBoard中的图形可视化工具。
- en: '![“Visualizing Model Graphs with TensorBoard”](Images/ptpr_0803.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![“使用TensorBoard可视化模型图”](Images/ptpr_0803.png)'
- en: Figure 8-3\. TensorBoard model graph
  id: totrans-430
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. TensorBoard模型图
- en: The graph is interactive. You can click on each module and expand it to view
    the underlying modules. This tool is useful for understanding existing models
    and verifying that your model graphs match their intended designs.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 该图是交互式的。您可以单击每个模块并展开以查看底层模块。这个工具对于理解现有模型并验证您的模型图是否符合其预期设计非常有用。
- en: Data with IMAGES, TEXT, and PROJECTOR
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用图像、文本和投影仪的数据
- en: You can also use TensorBoard to view different types of data, such as images,
    text, and 3D embeddings. In these cases, you would use the `add_image()`, `add_text()`,
    and `add_projection()` methods, respectively, to write data to the event file.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用TensorBoard查看不同类型的数据，例如图像、文本和3D嵌入。在这些情况下，您将分别使用`add_image()`、`add_text()`和`add_projection()`方法将数据写入事件文件。
- en: '[Figure 8-4](#fig_0804) shows a batch of image data from the Fashion-MNIST
    dataset.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-4](#fig_0804)显示了来自Fashion-MNIST数据集的一批图像数据。'
- en: By examining batches of image data, you can verify that the data looks as expected
    or identify errors in your data or results. TensorBoard also provides the ability
    to listen to audio data, display text data, and view 3D projections of multidimensional
    data or data embeddings.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查图像数据的批次，您可以验证数据是否符合预期，或者识别数据或结果中的错误。TensorBoard还提供了监听音频数据、显示文本数据以及查看多维数据或数据嵌入的3D投影的能力。
- en: '![“Visualizing Image Data with TensorBoard”](Images/ptpr_0804.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![“使用TensorBoard可视化图像数据”](Images/ptpr_0804.png)'
- en: Figure 8-4\. TensorBoard image display
  id: totrans-437
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-4\. TensorBoard图像显示
- en: Weight Distributions with DISTRIBUTIONS and HISTOGRAMS
  id: totrans-438
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用DISTRIBUTIONS和HISTOGRAMS查看权重分布
- en: Another useful feature of TensorBoard is the ability to display distributions
    and histograms. This allows you to view large amounts of data to verify expected
    behavior or identify issues.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard的另一个有用功能是显示分布和直方图。这使您可以查看大量数据以验证预期行为或识别问题。
- en: One common task in model development is making sure you avoid the *vanishing
    gradient problem*. Vanishing gradients occur when the model weights become zero
    or close to zero. When this occurs the neurons essentially die off and can no
    longer be updated.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发中的一个常见任务是确保避免*梯度消失问题*。当模型权重变为零或接近零时，梯度消失就会发生。当这种情况发生时，神经元基本上会死亡，无法再更新。
- en: If we visualize the distribution of our weights, it’s easy to see when a large
    portion of the weight values have reached zero.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们可视化我们的权重分布，很容易看到大部分权重值已经达到零。
- en: '[Figure 8-5](#fig_0805) shows the DISTRIBUTIONS tab in TensorBoard. Here we
    can examine the distributions of our weight values.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-5](#fig_0805)展示了TensorBoard中的DISTRIBUTIONS选项卡。在这里，我们可以检查我们的权重值的分布。'
- en: As you see in [Figure 8-5](#fig_0805), TensorBoard can display distributions
    in 3D so it’s easy to see how the distributions change over time or over each
    epoch.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[图8-5](#fig_0805)中所见，TensorBoard可以以3D显示分布，因此很容易看到分布随时间或每个时期如何变化。
- en: '![“Weight Distributions with TensorBoard”](Images/ptpr_0805.png)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![“使用TensorBoard的权重分布”](Images/ptpr_0805.png)'
- en: Figure 8-5\. TensorBoard weight distributions
  id: totrans-445
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-5\. TensorBoard权重分布
- en: Hyperparameters with HPARAMS
  id: totrans-446
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有HPARAMS的超参数
- en: When running deep learning experiments, it’s easy to lose track of the different
    hyperparameter sets used to try a hypothesis. TensorBoard provides a way to keep
    track of the hyperparameter values during each experiment and tabularizes the
    values and their results.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行深度学习实验时，很容易迷失不同超参数集的跟踪，以尝试假设。TensorBoard提供了一种在每次实验期间跟踪超参数值并将值及其结果制表的方法。
- en: '[Figure 8-6](#fig_0806) displays an example of how we track experiments and
    their corresponding hyperparameters and results.'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-6](#fig_0806)显示了我们如何跟踪实验及其相应的超参数和结果的示例。'
- en: In the HPARAMS tab, you can view the results in table view, parallel coordinates
    view, or scatter plot matrix view. Each experiment is identified by its session
    group name, hyperparameters such as dropout percentage and optimizer algorithm,
    and the resulting metric, such as accuracy. The HPARAMS tables help you keep track
    of your experiments and results.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 在HPARAMS选项卡中，您可以以表格视图、平行坐标视图或散点图矩阵视图查看结果。每个实验由其会话组名称、超参数（如丢失百分比和优化器算法）以及结果指标（如准确性）标识。HPARAMS表格可帮助您跟踪实验和结果。
- en: 'When you’re finished writing data to TensorBoard event files, you should use
    the `close()` method, as shown here:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成向TensorBoard事件文件写入数据时，应使用`close()`方法，如下所示：
- en: '[PRE13]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will call the destructor function and release any memory that was used
    for the summary writer.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 这将调用析构函数并释放用于摘要写入器的任何内存。
- en: '![“Tracking Hyperparameters in TensorBoard”](Images/ptpr_0806.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![“在TensorBoard中跟踪超参数”](Images/ptpr_0806.png)'
- en: Figure 8-6\. TensorBoard hyperparameter tracking
  id: totrans-454
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-6\. TensorBoard超参数跟踪
- en: The TensorBoard API
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorBoard API
- en: The PyTorch TensorBoard API is pretty simple. It’s included as part of the `torch.utils`
    package as `torch.utils.tensorboard`. [Table 8-20](#table_tensorboard_api) shows
    a comprehensive list of functions used to interface PyTorch to TensorBoard.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch TensorBoard API非常简单。它作为`torch.utils.tensorboard`的一部分包含在`torch.utils`包中。[表8-20](#table_tensorboard_api)显示了用于将PyTorch与TensorBoard接口的函数的全面列表。
- en: Table 8-20\. PyTorch TensorBoard API
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-20\. PyTorch TensorBoard API
- en: '| Method | Description |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 描述 |'
- en: '| --- | --- |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `SummaryWriter(`*`log_dir=None, comment='''', purge_step=None, max_queue=10,
    flush_secs=120, filename_suffix=''''`*`)` | Creates a `SummaryWriter` object |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| `SummaryWriter(`*`log_dir=None, comment='''', purge_step=None, max_queue=10,
    flush_secs=120, filename_suffix=''''`*`)` | 创建`SummaryWriter`对象 |'
- en: '| `flush()` | Flushes the event file to disk; makes sure that all pending events
    have been written to disk |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| `flush()` | 将事件文件刷新到磁盘；确保所有待处理事件都已写入磁盘 |'
- en: '| `close()` | Frees the `SummaryWriter` object and closes event files |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| `close()` | 释放`SummaryWriter`对象并关闭事件文件 |'
- en: '| `add_scalar(`*`tag, scalar_value, global_step=None, walltime=None`*`)` |
    Writes a scalar to the event file |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| `add_scalar(`*`tag, scalar_value, global_step=None, walltime=None`*`)` |
    将标量写入事件文件 |'
- en: '| `add_scalars(`*`main_tag, tag_scalar_dict, global_step=None, walltime=None`*`)`
    | Writes multiple scalars to the event file to display multiple scalars on the
    same plot |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| `add_scalars(`*`main_tag, tag_scalar_dict, global_step=None, walltime=None`*`)`
    | 将多个标量写入事件文件以在同一图中显示多个标量 |'
- en: '| `add_custom_scalars(`*`layout`*`)` | Creates a special chart by collecting
    chart tags in scalars |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| `add_custom_scalars(`*`layout`*`)` | 通过收集标量中的图表标签创建特殊图表 |'
- en: '| `add_histogram(`*`tag, values, global_step=None, bins=tensorflow, walltime=None,
    max_bins=None`*`)` | Writes data for a histogram display |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| `add_histogram(`*`tag, values, global_step=None, bins=tensorflow, walltime=None,
    max_bins=None`*`)` | 为直方图显示写入数据 |'
- en: '| `add_image(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=CHW`*`)`
    | Writes image data |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| `add_image(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=CHW`*`)`
    | 写入图像数据 |'
- en: '| `add_images(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=NCHW`*`)`
    | Writes multiple images to the same display |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| `add_images(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=NCHW`*`)`
    | 将多个图像写入同一显示 |'
- en: '| `add_figure(`*`tag, figure, global_step=None, close=True, walltime=None`*`)`
    | Writes a `matplotlib`-type plot as an image |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| `add_figure(`*`tag, figure, global_step=None, close=True, walltime=None`*`)`
    | 将`matplotlib`类型的图绘制为图像 |'
- en: '| `add_video(`*`tag, vid_tensor, global_step=None, fps=4, walltime=None``)`*
    | Writes a video |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| `add_video(`*`tag, vid_tensor, global_step=None, fps=4, walltime=None``)`*
    | 写入视频 |'
- en: '| `add_audio(`*`tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None`*`)`
    | Writes an audio file to the event summary |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| `add_audio(`*`tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None`*`)`
    | 将音频文件写入事件摘要 |'
- en: '| `add_text(`*`tag, text_string, global_step=None, walltime=None`*`)` | Writes
    text data to summary |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| `add_text(`*`tag, text_string, global_step=None, walltime=None`*`)` | 将文本数据写入摘要
    |'
- en: '| `add_graph(`*`model, input_to_model=None, verbose=False`*`)` | Writes a model
    graph or computational graph to summary |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| `add_graph(`*`model, input_to_model=None, verbose=False`*`)` | 将模型图或计算图写入摘要
    |'
- en: '| `add_embedding(`*`mat, metadata=None, label_img=None, global_step=None, tag=default,
    metadata_header=None`*`)` | Writes embedding projector data tto summary |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| `add_embedding(`*`mat, metadata=None, label_img=None, global_step=None, tag=default,
    metadata_header=None`*`)` | 将嵌入投影仪数据写入摘要 |'
- en: '| `add_pr_curve(`*`tag, labels, predictions, global_step=None, num_thresholds=127,
    weights=None, walltime=None`*`)` | Writes the precision/recall curve under different
    thresholds |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| `add_pr_curve(`*`tag, labels, predictions, global_step=None, num_thresholds=127,
    weights=None, walltime=None`*`)` | 在不同阈值下写入精度/召回率曲线 |'
- en: '| `add_mesh(`*`tag, vertices, colors=None, faces=None, config_dict=None, global_step=None,
    walltime=None`*`)` | Adds meshes or 3D point clouds to TensorBoard |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| `add_mesh(`*`tag, vertices, colors=None, faces=None, config_dict=None, global_step=None,
    walltime=None`*`)` | 将网格或3D点云添加到TensorBoard |'
- en: '| `add_hparams(`*`hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None`*`)`
    | Adds a set of hyperparameters for comparison in TensorBoard |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '`add_hparams(`*`hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None`*`)`：向TensorBoard中添加一组超参数以进行比较。'
- en: As shown in [Table 8-20](#table_tensorboard_api), the API is simple. You can
    use the `SummaryWriter()`, `flush()`, and `close()` methods to manage the writer
    object and use the other functions to add data to the TensorBoard event file.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 如[表8-20](#table_tensorboard_api)所示，API很简单。您可以使用`SummaryWriter()`、`flush()`和`close()`方法来管理写入对象，并使用其他函数向TensorBoard事件文件添加数据。
- en: For more details on the TensorBoard PyTorch API, visit the [TensorBoard API
    documentation](https://pytorch.tips/pytorch-tensorboard). For more details on
    using the TensorBoard application itself, visit the [TensorBoard documentation](https://pytorch.tips/tensorboard).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 有关TensorBoard PyTorch API的更多详细信息，请访问TensorBoard API文档。有关如何使用TensorBoard应用程序本身的更多详细信息，请访问TensorBoard文档。
- en: TensorBoard solves one major challenge with developing deep learning models
    in PyTorch by providing a visualization tool. Another major challenge is keeping
    up with the latest research and state-of-the art solutions. Researchers often
    need to reproduce the results and leverage the code for benchmarking their own
    designs. In the next section we explore Papers with Code, a resource you can use
    to solve this problem.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard通过提供可视化工具解决了在PyTorch中开发深度学习模型时的一个主要挑战。另一个主要挑战是跟上最新研究和最先进的解决方案。研究人员经常需要重现结果并利用代码来对比自己的设计。在接下来的部分中，我们将探讨Papers
    with Code，这是一个您可以使用的资源来解决这个问题。
- en: Papers with Code
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Papers with Code
- en: Papers with Code (PwC) is a website that organizes access to machine learning
    research papers and their corresponding code, which is often written in PyTorch.
    PwC allows you to easily reproduce experiments and extend current research, and
    the website allows you to find the best-performing research papers for a given
    machine learning topic. For example, want to find the best image classification
    models and their code? Just click on the Image Classification tile and you’ll
    see a summary of the research area as well as benchmarks and links to corresponding
    papers and code on GitHub. [Figure 8-7](#fig_0807) shows an example listing for
    Image Classification.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: Papers with Code（PwC）是一个网站，它整理了机器学习研究论文及其相应的代码，这些代码通常是用PyTorch编写的。PwC允许您轻松重现实验并扩展当前研究，该网站还允许您找到给定机器学习主题的表现最佳的研究论文。例如，想要找到最佳的图像分类模型及其代码吗？只需点击图像分类瓷砖，您将看到研究领域的摘要以及GitHub上相应论文和代码的基准和链接。图8-7展示了图像分类的示例列表。
- en: '![“Papers With Code Image Classification Listing”](Images/ptpr_0807.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: “Papers With Code Image Classification Listing”图片
- en: Figure 8-7\. Papers with Code
  id: totrans-484
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7. Papers with Code
- en: PwC is not an exclusive PyTorch project; however, most of the code provided
    on PwC uses PyTorch. It may be able to help you build awareness of the current
    state-of-the-art research and solve your problems in deep learning and AI. Explore
    more at the [PwC website](https://pytorch.tips/pwc).
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: PwC并不是一个专门的PyTorch项目；然而，PwC提供的大多数代码都使用PyTorch。它可能有助于您了解当前最先进的研究并解决您在深度学习和人工智能方面的问题。在PwC网站上探索更多。
- en: Additional PyTorch Resources
  id: totrans-486
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外的PyTorch资源
- en: After reading this book, you should have a good understanding of PyTorch and
    its features. However, there are always new aspects to explore and practice. In
    this section, I’ll provide a list of additional resources that you can check out
    to learn more and grow your skills with PyTorch.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完这本书后，您应该对PyTorch及其功能有很好的理解。然而，总是有新的方面可以探索和实践。在本节中，我将提供一些额外资源的列表，您可以查看以了解更多信息，并提升您在PyTorch中的技能。
- en: Tutorials
  id: totrans-488
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 教程
- en: The [PyTorch website](https://pytorch.tips/pytorch) provides an extensive set
    of documentation and tutorials. If you’re looking for more code examples, this
    resource is a good place to start. [Figure 8-8](#fig_0808) shows the [PyTorch
    Tutorials website](https://pytorch.tips/tutorials), where you can select tags
    to help you find tutorials that interest you.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch网站提供了大量的文档和教程。如果您正在寻找更多的代码示例，这个资源是一个很好的起点。图8-8展示了PyTorch教程网站，您可以选择标签来帮助您找到感兴趣的教程。
- en: '![“PyTorch Tutorials Website”](Images/ptpr_0808.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
  zh: “PyTorch教程网站”图片
- en: Figure 8-8\. PyTorch Tutorials
  id: totrans-491
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-8. PyTorch教程
- en: The site includes a 60-min blitz, PyTorch recipes, tutorials, and a PyTorch
    Cheat Sheet. Most of the code and tutorials are available on GitHub, and can be
    run in VS Code, Jupyter Notebook, and Colab.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 该网站包括一个60分钟的闪电战、PyTorch食谱、教程和PyTorch备忘单。大多数代码和教程都可以在GitHub上找到，并且可以在VS Code、Jupyter
    Notebook和Colab中运行。
- en: The 60-min Blitz is a good place to start, refresh your skills, or review the
    basics of PyTorch. PyTorch recipes are bite-sized, actionable examples of how
    to use specific PyTorch features. PyTorch tutorials are slightly longer than recipes
    and are composed of multiple steps to achieve or demonstrate an outcome.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 60分钟闪电战是一个很好的起点，可以帮助您恢复技能或复习PyTorch的基础知识。PyTorch食谱是关于如何使用特定PyTorch功能的简短、可操作的示例。PyTorch教程比食谱稍长，由多个步骤组成，以实现或演示一个结果。
- en: 'Currently, you can find tutorials related to the following topics:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，您可以找到与以下主题相关的教程：
- en: Audio
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频
- en: Best Practice
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳实践
- en: C++
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++
- en: CUDA
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA
- en: Extending PyTorch
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展PyTorch
- en: FX
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FX
- en: Frontend APIs
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前端API
- en: Getting Started
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入门
- en: Image/Video
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像/视频
- en: Interpretability
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可解释性
- en: Memory Format
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存格式
- en: Mobile
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动
- en: Model Optimization
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型优化
- en: Parallel and Distributed Training
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行和分布式训练
- en: Production
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产
- en: Profiling
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析
- en: Quantization
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化
- en: Reinforcement Learning
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: TensorBoard
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorBoard
- en: Text
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本
- en: TorchScript
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TorchScript
- en: The PyTorch team is continually adding new resources and this list is certainly
    subject to change. For more information and the latest tutorials, visit the PyTorch
    Tutorials website.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch团队不断添加新资源，这个列表肯定会发生变化。有关更多信息和最新教程，请访问PyTorch教程网站。
- en: Books
  id: totrans-517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 书籍
- en: Tutorials are a great for learning, but perhaps you’d prefer to read more about
    PyTorch and gain different perspectives from multiple authors. [Table 8-21](#table_pytorch_books)
    provides a list of other books related to PyTorch.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 教程是学习的好方法，但也许您更喜欢阅读有关PyTorch的更多信息，并从多位作者的不同视角获得不同观点。[表8-21](#table_pytorch_books)提供了与PyTorch相关的其他书籍列表。
- en: Table 8-21\. PyTorch books
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-21\. PyTorch书籍
- en: '| Book | Publisher, year | Summary |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 出版商，年份 | 摘要 |'
- en: '| --- | --- | --- |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| *Cloud Native Machine Learning* by Carl Osipov | Manning, 2021 | Learn how
    to deploy PyTorch models on AWS |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| *云原生机器学习* by Carl Osipov | Manning, 2021 | 学习如何在AWS上部署PyTorch模型 |'
- en: '| *Deep Learning for Coders with fastai and PyTorch* by Jeremy Howard and Sylvain
    Gugger | O’Reilly, 2020 | Learn how to build AI applications without a PhD |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| *使用fastai和PyTorch进行编码人员的深度学习* by Jeremy Howard和Sylvain Gugger | O’Reilly,
    2020 | 学习如何在没有博士学位的情况下构建人工智能应用程序 |'
- en: '| *Deep Learning with PyTorch* by Eli Stevens et al. | Manning, 2019 | Learn
    how to build, train, and tune NNs using Python tools |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch进行深度学习* by Eli Stevens等 | Manning, 2019 | 学习如何使用Python工具构建、训练和调整神经网络
    |'
- en: '| *Deep Learning with PyTorch* by Vishnu Subramanian | Packt, 2018 | Learn
    how to build NN models using PyTorch |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch进行深度学习* by Vishnu Subramanian | Packt, 2018 | 学习如何使用PyTorch构建神经网络模型
    |'
- en: '| *Hands-On Generative Adversarial Networks with PyTorch 1.x* by John Hany
    and Greg Walters | Packt, 2019 | Learn how to implement next-generation NNs to
    build powerful GAN models using Python |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch 1.x进行实用生成对抗网络* by John Hany和Greg Walters | Packt, 2019 | 学习如何使用Python实现下一代神经网络，构建强大的GAN模型
    |'
- en: '| *Hands-On Natural Language Processing with PyTorch 1.x* by Thomas Dop | Packt,
    2020 | Learn how to build smart, AI-driven linguistic applications using deep
    learning and NLP techniques |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| *Hands-On Natural Language Processing with PyTorch 1.x* by Thomas Dop | Packt,
    2020 | 学习如何利用深度学习和自然语言处理技术构建智能的人工智能驱动的语言应用程序 |'
- en: '| *Hands-On Neural Networks with PyTorch 1.0* by Vihar Kurama | Packt, 2019
    | Learn how to implement deep learning architectures in PyTorch |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch 1.0进行实用神经网络* by Vihar Kurama | Packt, 2019 | 学习如何在PyTorch中实现深度学习架构
    |'
- en: '| *Natural Language Processing with PyTorch* by Delip Rao and Brian McMahan
    | O’Reilly, 2019 | Learn how to build intelligent language applications using
    deep learning |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch进行自然语言处理* by Delip Rao和Brian McMahan | O’Reilly, 2019 | 学习如何利用深度学习构建智能语言应用程序
    |'
- en: '| *Practical Deep Learning with PyTorch* by Nihkil Ketkar | Apress, 2020 |
    Learn how to optimize GANs with Python |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| *使用PyTorch进行实用深度学习* by Nihkil Ketkar | Apress, 2020 | 学习如何使用Python优化GAN |'
- en: '| *Programming PyTorch for Deep Learning* by Ian Pointer | O’Reilly, 2019 |
    Learn how to create and deploy deep learning applications |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| *为深度学习编程PyTorch* by Ian Pointer | O’Reilly, 2019 | 学习如何创建和部署深度学习应用程序 |'
- en: '| *PyTorch Artificial Intelligence Fundamentals* by Jibin Mathew | Packt, 2020
    | Learn how to design, build, and deploy your own AI models with PyTorch 1.x |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| *PyTorch人工智能基础* by Jibin Mathew | Packt, 2020 | 学习如何设计、构建和部署自己的PyTorch 1.x
    AI模型 |'
- en: '| *PyTorch Recipes* by Pradeepta Mishra | Apress, 2019 | Learn how to solve
    problems in PyTorch |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| *PyTorch食谱* by Pradeepta Mishra | Apress, 2019 | 学习如何在PyTorch中解决问题 |'
- en: Online Courses and Live Training
  id: totrans-534
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线课程和现场培训
- en: If you prefer online video courses and live training workshops, there are options
    available for you to expand your PyTorch knowledge and skills. You can continue
    learning from me and other online instructors at PyTorch Academy, Udemy, Coursera,
    Udacity, Skillshare, DataCamp, Pluralsight, edX, O’Reilly Learning, and LinkedIn
    Learning. Some courses are free while others require a fee or a subscription.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更喜欢在线视频课程和现场培训研讨会，您可以选择扩展您的PyTorch知识和技能的选项。您可以继续从PyTorch Academy、Udemy、Coursera、Udacity、Skillshare、DataCamp、Pluralsight、edX、O’Reilly
    Learning和LinkedIn Learning等在线讲师那里学习。一些课程是免费的，而其他课程需要付费或订阅。
- en: '[Table 8-22](#table_pytorch_courses) lists a selection of online courses on
    PyTorch available at the time of writing.'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-22](#table_pytorch_courses)列出了撰写时可用的PyTorch在线课程的选择。'
- en: Table 8-22\. PyTorch courses
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-22\. PyTorch课程
- en: '| Course | Instructor | Platform |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| 课程 | 讲师 | 平台 |'
- en: '| --- | --- | --- |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Getting Started with PyTorch Development | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| 开始使用PyTorch开发 | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
- en: '| PyTorch Fundamentals | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch基础 | Joe Papa | [PyTorch Academy](https://pytorchacademy.com) |'
- en: '| Advanced PyTorch | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
  zh: '| 高级PyTorch | Joe Papa | [PyTorch Academy](https://pytorchacademy.com) |'
- en: '| Introduction to Deep Learning with PyTorch | Ismail Elezi | [DataCamp](https://www.datacamp.com/courses/deep-learning-with-pytorch)
    |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: '| 使用PyTorch进行深度学习入门 | Ismail Elezi | [DataCamp](https://www.datacamp.com/courses/deep-learning-with-pytorch)
    |'
- en: '| Foundations of PyTorch | Janani Ravi | [Pluralsight](https://www.pluralsight.com/courses/foundations-pytorch)
    |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch基础 | Janani Ravi | [Pluralsight](https://www.pluralsight.com/courses/foundations-pytorch)
    |'
- en: '| Deep Neural Networks with PyTorch | IBM | [Coursera](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)
    |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '| 使用PyTorch的深度神经网络 | IBM | [Coursera](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)
    |'
- en: '| PyTorch Basics for Machine Learning | IBM | [edX](https://www.edx.org/course/pytorch-basics-for-machine-learning)
    |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| 用于机器学习的PyTorch基础 | IBM | [edX](https://www.edx.org/course/pytorch-basics-for-machine-learning)
    |'
- en: '| Intro to Deep Learning with PyTorch | Facebook AI | [Udacity](https://www.udacity.com/course/deep-learning-pytorch%E2%80%94ud188)
    |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 使用PyTorch进行深度学习入门 | Facebook AI | [Udacity](https://www.udacity.com/course/deep-learning-pytorch%E2%80%94ud188)
    |'
- en: '| PyTorch: Deep Learning and Artificial Intelligence | Lazy Programmer | [Udemy](https://www.udemy.com/course/pytorch-deep-learning/)
    |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch：深度学习和人工智能 | 懒惰的程序员 | [Udemy](https://www.udemy.com/course/pytorch-deep-learning/)
    |'
- en: '| PyTorch for Deep Learning and Computer Vision | Rayan Slim et al. | [Udemy](https://www.udemy.com/course/pytorch-for-deep-learning-and-computer-vision)
    |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 用于深度学习和计算机视觉的PyTorch | Rayan Slim等 | [Udemy](https://www.udemy.com/course/pytorch-for-deep-learning-and-computer-vision)
    |'
- en: '| PyTorch for Beginners | Dan We | [Skillshare](https://www.skillshare.com/classes/Pytorch-for-beginners-how-machine-learning-with-pytorch-really-works/1042152565)
    |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch入门 | Dan We | [Skillshare](https://www.skillshare.com/classes/Pytorch-for-beginners-how-machine-learning-with-pytorch-really-works/1042152565)
    |'
- en: '| PyTorch Essential Training: Deep Learning | Jonathan Fernandes | [LinkedIn
    Learning](https://www.linkedin.com/learning/pytorch-essential-training-deep-learning)
    |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch基础培训：深度学习 | Jonathan Fernandes | [LinkedIn Learning](https://www.linkedin.com/learning/pytorch-essential-training-deep-learning)
    |'
- en: '| Introduction to Deep Learning Using PyTorch | Goku Mohandas and Alfredo Canziani
    | [O’Reilly Learning](https://learning.oreilly.com/videos/introduction-to-deep/9781491989944/)
    |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| 使用PyTorch介绍深度学习 | Goku Mohandas和Alfredo Canziani | [O’Reilly Learning](https://learning.oreilly.com/videos/introduction-to-deep/9781491989944/)
    |'
- en: This chapter has provided resources for expanding your learning, research, and
    development with PyTorch. You can use this material as a quick reference for the
    numerous packages within the PyTorch project and the PyTorch Ecosystem. When you
    are looking to expand your skills and knowledge, you can return to this chapter
    to get ideas on other training materials available to you.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了扩展您学习、研究和开发PyTorch的资源。您可以将这些材料作为PyTorch项目和PyTorch生态系统中众多软件包的快速参考。当您希望扩展您的技能和知识时，可以返回本章，获取其他培训材料的想法。
- en: Congratulations on completing the book! You’ve come a long way, getting to grips
    with tensors, understanding the model development process, and exploring reference
    designs using PyTorch. In addition, you’ve learned how to customize PyTorch, create
    your own features, accelerate training, optimize your models, and deploy your
    NNs to the cloud and edge devices. Finally, we explored the PyTorch Ecosystem,
    investigated key packages like Torchvision, Torchtext, and TensorBoard, and learned
    about additional ways to expand your knowledge with tutorials, books, and online
    courses.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成了这本书！您已经走了很长一段路，掌握了张量，理解了模型开发过程，并探索了使用PyTorch的参考设计。此外，您还学会了如何定制PyTorch，创建自己的特性，加速训练，优化模型，并将您的神经网络部署到云端和边缘设备。最后，我们探索了PyTorch生态系统，调查了关键软件包如Torchvision、Torchtext和TensorBoard，并了解了通过教程、书籍和在线课程扩展知识的其他方法。
- en: No matter what projects you tackle in the future, I hope you’ll be able to return
    to this book again and again. I also hope you continue to expand your skills and
    master PyTorch’s capabilities to develop innovative new deep learning tools and
    systems. Don’t let your new knowledge and skills dwindle away. Go build something
    interesting, and make a difference in the world!
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您将来要处理什么项目，我希望您能一次又一次地返回这本书。我也希望您继续扩展您的技能，并掌握PyTorch的能力，开发创新的新深度学习工具和系统。不要让您的新知识和技能消失。去构建一些有趣的东西，在世界上产生影响！
- en: Let me know what you create! I hope to see you in one of my courses at [PyTorch
    Academy](https://pytorchacademy.com) and feel free to reach out to me via email
    ([jpapa@joepapa.ai](mailto:jpapa@joepapa.ai)), Twitter (@JoePapaAI), or LinkedIn
    (@MrJoePapa).
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 让我知道您创造了什么！我希望在[PyTorch Academy](https://pytorchacademy.com)的课程中见到您，并随时通过电子邮件（[jpapa@joepapa.ai](mailto:jpapa@joepapa.ai)）、Twitter（@JoePapaAI）或LinkedIn（@MrJoePapa）联系我。
