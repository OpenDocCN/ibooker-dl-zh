- en: 1 What is generative AI and why PyTorch?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 什么是生成式AI，为什么是PyTorch？
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Generative AI vs. nongenerative AI
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI与非生成式AI的比较
- en: Why PyTorch is ideal for deep learning and generative AI
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么PyTorch是深度学习和生成式AI的理想选择
- en: The concept of Generative Adversarial Networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络的概念
- en: The benefits of the attention mechanism and Transformers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力机制和Transformers的好处
- en: Advantages of creating generative AI models from scratch
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头创建生成式AI模型的优势
- en: Generative AI has significantly affected the global landscape, capturing widespread
    attention and becoming a focal point since the advent of ChatGPT in November 2022\.
    This technological advancement has revolutionized numerous aspects of everyday
    life, ushering in a new era in technology and inspiring a host of startups to
    explore the extensive possibilities offered by various generative models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI自2022年11月ChatGPT问世以来，对全球格局产生了重大影响，引起了广泛关注，并成为焦点。这项技术进步彻底改变了日常生活的许多方面，迎来了技术新时代，并激发了许多初创公司探索各种生成模型提供的广泛可能性。
- en: Consider the advancements made by Midjourney, a pioneering company, which now
    creates high-resolution, realistic images from brief text inputs. Similarly, Freshworks,
    a software company, has accelerated application development dramatically, reducing
    the time required from an average of 10 weeks to mere days, a feat achieved through
    the capabilities of ChatGPT (see the *Forbes* article “10 Amazing Real-World Examples
    of How Companies Are Using ChatGPT in 2023,” by Bernard Barr, 2023, [https://mng.bz/Bgx0](https://mng.bz/Bgx0)).
    To add a case in point, elements of this very introduction have been enhanced
    by generative AI, demonstrating its ability to refine content to be more engaging.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下Midjourney这家先驱公司取得的进步，它现在可以从简短的文字输入中创建高分辨率、逼真的图像。同样，软件公司Freshworks显著加速了应用程序的开发，将平均所需时间从10周缩短到仅仅几天，这是通过ChatGPT的能力实现的（参见*Forbes*文章“2023年公司如何使用ChatGPT的10个惊人的真实世界例子”，作者Bernard
    Barr，2023年，[https://mng.bz/Bgx0](https://mng.bz/Bgx0)）。为了举例说明，这篇引言的一些内容已经通过生成式AI得到了增强，展示了其精炼内容以使其更具吸引力的能力。
- en: NOTE What better way to explain generative AI than letting generative AI do
    itself? I asked ChatGPT to rewrite an early draft of this introduction in a “more
    engaging manner” before finalizing it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项：有什么比让生成式AI自己解释生成式AI更好的方法呢？在最终确定之前，我让ChatGPT重新撰写了这篇引言的早期草稿，以“更具吸引力”的方式呈现。
- en: The repercussions of this technological advancement extend far beyond these
    examples. Industries are experiencing significant disruption due to the advanced
    capabilities of generative AI. This technology now produces essays comparable
    to those written by humans, composes music reminiscent of classical compositions,
    and rapidly generates complex legal documents, tasks that typically require considerable
    human effort and time. Following the release of ChatGPT, CheggMate, an educational
    platform, witnessed a significant decrease in its stock value. Furthermore, the
    Writers Guild of America, during a recent strike, reached a consensus to put guardrails
    around AI’s encroachment on scriptwriting and editing (see the *WIRED* article
    “Hollywood Writers Reached an AI Deal That Will Rewrite History,” by Will Bedingfield,
    2023, [https://mng.bz/1ajj](https://mng.bz/1ajj)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术进步的影响远远超出了这些例子。由于生成式AI的先进能力，各行业正经历着重大的颠覆。这项技术现在可以创作出与人类写作相当的文章，创作出令人联想到古典作品的音乐，并快速生成复杂的法律文件，这些任务通常需要大量的人类努力和时间。ChatGPT发布后，教育平台CheggMate的股价出现了显著下降。此外，美国编剧工会最近的一次罢工中，达成了一致意见，要为AI在剧本写作和编辑方面的侵犯设定界限（参见*Wired*文章“好莱坞编剧达成AI协议，将改写历史”，作者Will
    Bedingfield，2023年，[https://mng.bz/1ajj](https://mng.bz/1ajj)）。
- en: NOTE CheggMate charges college students to have their questions answered by
    human specialists. Many of these jobs can now be done by ChatGPT or similar tools
    at a fraction of the costs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项：CheggMate向大学生收费，让他们的问题由人类专家回答。现在，许多这些工作可以通过ChatGPT或类似工具以极低成本完成。
- en: 'This raises several questions: What is generative AI, and how does it differ
    from other AI technologies? Why is it causing such widespread disruption across
    various sectors? What is the underlying mechanism of generative AI, and why is
    it important to understand?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了一系列问题：什么是生成式AI，它与其他AI技术有何不同？为什么它在各个行业引起了如此广泛的颠覆？生成式AI的潜在机制是什么，为什么了解它很重要？
- en: 'This book offers an in-depth exploration of generative AI, a groundbreaking
    technology reshaping numerous industries through its efficient and rapid content
    creation capabilities. Specifically, you’ll learn to use state-of-the-art generative
    models to create various forms of content: shapes, numbers, images, text, and
    audio. Further, instead of treating these models as black boxes, you’ll learn
    to create them from scratch so that you have a deep understanding of the inner
    workings of generative AI. In the words of physicist Richard Feynman, “What I
    cannot create, I do not understand.”'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本书深入探讨了生成式人工智能，这是一种通过从现有数据中学习模式来创建新内容（如文本、图像或音乐）的人工智能类型。它与专注于区分不同数据实例之间的差异并学习类别之间边界的判别模型不同。图1.1展示了这两种建模方法之间的差异。例如，当面对包含狗和猫的图像数组时，判别模型通过捕捉区分两者的几个关键特征（例如，猫有小的鼻子和尖耳朵）来确定每张图像描绘的是狗还是猫。如图表的上半部分所示，判别模型将数据作为输入，并产生不同标签的概率，我们用Prob(狗)和Prob(猫)表示。然后我们可以根据最高的预测概率对输入进行标记。
- en: All these models are based on deep neural networks, and you’ll use Python and
    PyTorch to build, train, and use these models. We chose Python for its user-friendly
    syntax, cross-platform compatibility, and wide community support. We also chose
    PyTorch over other frameworks like TensorFlow for its ease of use and adaptability
    to various model architectures. Python is widely regarded as the primary tool
    for machine learning (ML), and PyTorch has become increasingly popular in the
    field of AI. Therefore, using Python and PyTorch allows you to follow the new
    developments in generative AI. Because PyTorch allows for graphics processing
    unit (GPU) training acceleration, you’ll train these models in a matter of minutes
    or hours and witness generative AI in action!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些模型都是基于深度神经网络，你将使用Python和PyTorch来构建、训练和使用这些模型。我们选择Python是因为其用户友好的语法、跨平台兼容性和广泛的社区支持。我们还选择了PyTorch而不是TensorFlow等其他框架，因为它易于使用并且能够适应各种模型架构。Python被广泛认为是机器学习（ML）的主要工具，PyTorch在人工智能领域也越来越受欢迎。因此，使用Python和PyTorch可以使你跟上生成式人工智能的新发展。因为PyTorch允许使用图形处理单元（GPU）进行训练加速，所以你可以在几分钟或几小时内训练这些模型，并见证生成式人工智能的实际应用！
- en: 1.1 Introducing generative AI and PyTorch
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 介绍生成式人工智能和PyTorch
- en: 'This section explains what generative AI is and how it’s different from its
    nongenerative counterparts: discriminative models. Generative AI is a category
    of technologies with the remarkable capacity to produce diverse forms of new content,
    including text, images, audio, video, source code, and intricate patterns. Generative
    AI crafts entirely new worlds of novel and innovative content; ChatGPT is a notable
    example. In contrast, discriminative modeling predominantly concerns itself with
    the task of recognizing and categorizing pre-existing content.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了什么是生成式人工智能以及它与非生成式人工智能（如判别模型）的不同之处。生成式人工智能是一类具有非凡能力，能够产生各种形式的新内容的技术，包括文本、图像、音频、视频、源代码和复杂模式。生成式人工智能能够创造全新的内容世界；ChatGPT是一个显著的例子。相比之下，判别建模主要关注的是识别和分类现有内容的工作。
- en: 1.1.1 What is generative AI?
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 什么是生成式人工智能？
- en: Generative AI is a type of artificial intelligence that creates new content,
    such as text, images, or music, by learning patterns from existing data. It differs
    from discriminative models, which specialize in discerning disparities among distinct
    data instances and learning the boundary between classes. Figure 1.1 illustrates
    the difference between these two modeling methods. For instance, when confronted
    with an array of images featuring dogs and cats, a discriminative model determines
    whether each image portrays a dog or a cat by capturing a few key features that
    distinguish one from the other (e.g., cats have small noses and pointy ears).
    As the top half of the figure shows, a discriminative model takes data as inputs
    and produces probabilities of different labels, which we denote by Prob(dog) and
    Prob(cat). We can then label the inputs based on the highest predicted probabilities.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能是一种通过从现有数据中学习模式来创建新内容（如文本、图像或音乐）的人工智能类型。它与专注于区分不同数据实例之间的差异并学习类别之间边界的判别模型不同。图1.1展示了这两种建模方法之间的差异。例如，当面对包含狗和猫的图像数组时，判别模型通过捕捉区分两者的几个关键特征（例如，猫有小的鼻子和尖耳朵）来确定每张图像描绘的是狗还是猫。如图表的上半部分所示，判别模型将数据作为输入，并产生不同标签的概率，我们用Prob(狗)和Prob(猫)表示。然后我们可以根据最高的预测概率对输入进行标记。
- en: '![](../../OEBPS/Images/CH01_F01_Liu.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F01_Liu.png)'
- en: Figure 1.1 A comparison of generative models versus discriminative models. A
    discriminative model (top half of the figure) takes data as inputs and produces
    probabilities of different labels, which we denote by Prob(dog) and Prob(cat).
    In contrast, a generative model (bottom half) acquires an in-depth understanding
    of the defining characteristics of these images to synthesize new images representing
    dogs and cats.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 生成模型与判别模型的比较。判别模型（图的上半部分）将数据作为输入，并产生不同标签的概率，我们用Prob(dog)和Prob(cat)表示。相反，生成模型（图的下半部分）通过深入了解这些图像的显著特征来合成代表狗和猫的新图像。
- en: In contrast, generative models exhibit a unique ability to generate novel instances
    of data. In the context of our dog and cat example, a generative model acquires
    an in-depth understanding of the defining characteristics of these images to synthesize
    new images representing dogs and cats. As the bottom half of figure 1.1 shows,
    a generative model takes task descriptions (such as varying values in a latent
    space that result in different characteristics in the generated image, which we
    will discuss in detail in chapters 4 to 6) as inputs and produces entirely new
    images of dogs and cats.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，生成模型展现出生成数据新实例的独特能力。在我们的狗和猫示例中，生成模型通过深入了解这些图像的显著特征来合成代表狗和猫的新图像。如图1.1的下半部分所示，生成模型将任务描述（例如，在潜在空间中变化的值导致生成的图像具有不同的特征，我们将在第4章到第6章中详细讨论）作为输入，并产生狗和猫的全新图像。
- en: From a statistical perspective, when presented with data examples with features
    X, which describe the input and various corresponding labels Y, discriminative
    models undertake the responsibility of predicting conditional probabilities, specifically
    the probability prob(Y|X). Conversely, generative models attempt to learn the
    joint probability distribution of the input features X and the target variable
    Y, denoted as prob (X, Y). Armed with this knowledge, they sample from the distribution
    to conjure fresh instances of X.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从统计学的角度来看，当面对具有特征X的数据示例，这些特征描述了输入和相应的各种标签Y时，判别模型承担预测条件概率的责任，具体来说是预测Y|X的概率。相反，生成模型试图学习输入特征X和目标变量Y的联合概率分布，表示为prob(X,
    Y)。凭借这种知识，它们从分布中采样，以产生X的新实例。
- en: 'There are different types of generative models depending on the specific forms
    of content you want to create. In this book, we focus primarily on two prominent
    technologies: Generative Adversarial Networks (GANs) and Transformers (although
    we’ll also cover variational autoencoders and diffusion models). The word “adversarial”
    in GANs refers to the fact that the two neural networks compete against each other
    in a zero-sum game framework: the generative network tries to create data instances
    indistinguishable from real samples, while the discriminative network tries to
    identify the generated samples from real ones. The competition between the two
    networks leads to the improvement of both, eventually enabling the generator to
    create highly realistic data. Transformers are deep neural networks that can efficiently
    solve sequence-to-sequence prediction tasks, and we’ll explain them in more detail
    later in this chapter.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你想要创建的具体内容形式，存在不同类型的生成模型。在这本书中，我们主要关注两种突出的技术：生成对抗网络（GANs）和转换器（虽然我们也会涵盖变分自编码器和扩散模型）。在GANs中的“对抗”一词指的是两个神经网络在零和博弈框架中相互竞争的事实：生成网络试图创建与真实样本不可区分的数据实例，而判别网络则试图从真实样本中识别生成的样本。两个网络之间的竞争导致两者都得到改进，最终使生成器能够创建高度逼真的数据。转换器是能够高效解决序列到序列预测任务的深度神经网络，我们将在本章后面更详细地解释它们。
- en: GANs, celebrated for their ease of implementation and versatility, empower individuals
    with even rudimentary knowledge of deep learning to construct their generative
    models from the ground up. These versatile models can give rise to a plethora
    of creations, from geometric shapes and intricate patterns, as exemplified in
    chapter 3 of this book, to high-quality color images like human faces, which you’ll
    learn to generate in chapter 4\. Furthermore, GANs exhibit the ability to transform
    image content, seamlessly morphing a human face image with blond hair into one
    with black hair, a phenomenon discussed in chapter 6\. Notably, they extend their
    creative prowess to the field of music generation, producing realistic-sounding
    musical compositions, as demonstrated in chapter 13.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GANs因其易于实现和多功能性而备受赞誉，使连对深度学习只有初步了解的人也能从头开始构建他们的生成模型。这些多才多艺的模型可以产生各种各样的创作，从本书第3章中展示的几何形状和复杂图案，到第4章中将学习生成的高质量彩色图像，如人类面孔。此外，GANs还表现出转换图像内容的能力，无缝地将金发人类面孔图像转变为黑发人类面孔图像，这在第6章中进行了讨论。值得注意的是，它们将它们的创造力扩展到音乐生成领域，产生听起来逼真的音乐作品，如第13章中所示。
- en: In contrast to shape, number, or image generation, the art of text generation
    poses formidable challenges, chiefly due to the sequential nature of textual information,
    where the order and arrangement of individual characters and words hold significant
    meaning. To confront this complexity, we turn to Transformers, deep neural networks
    designed to proficiently address sequence-to-sequence prediction tasks. Unlike
    their predecessors, such as recurrent neural networks (RNNs) or convolutional
    neural networks (CNNs), Transformers excel in capturing intricate, long-range
    dependencies inherent in both input and output sequences. Notably, their capacity
    for parallel training (a distributed training method in which a model is trained
    on multiple devices simultaneously) has substantially reduced training times,
    making it possible for us to train Transformers on vast amounts of data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与形状、数量或图像生成相比，文本生成的艺术面临巨大的挑战，这主要归因于文本信息的序列性质，其中单个字符和单词的顺序和排列具有重大意义。为了应对这种复杂性，我们转向Transformer，这是一种专为高效处理序列到序列预测任务而设计的深度神经网络。与它们的
    predecessors，如循环神经网络（RNN）或卷积神经网络（CNN）不同，Transformer在捕捉输入和输出序列中固有的复杂、长距离依赖关系方面表现出色。值得注意的是，它们并行训练的能力（一种在多个设备上同时训练模型的多设备训练方法）大大减少了训练时间，使我们能够在大量数据上训练Transformer。
- en: The revolutionary architecture of Transformers underpins the emergence of large
    language models (LLMs; deep neural networks with a massive number of parameters
    and trained on large datasets), including ChatGPT, BERT, DALL-E, and T5\. This
    transformative architecture serves as the bedrock of the recent surge in AI advancement,
    ushered in by the introduction of ChatGPT and other generative pretrained Transformer
    (GPT) models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer的革命性架构是大型语言模型（LLMs；具有大量参数并在大型数据集上训练的深度神经网络）的出现的基础，包括ChatGPT、BERT、DALL-E和T5。这种变革性的架构是近年来AI进步激增的基石，ChatGPT和其他生成预训练Transformer（GPT）模型的引入开启了这一进步。
- en: 'In the subsequent sections, we dive into the comprehensive inner workings of
    these two pioneering technologies: their underlying mechanisms and the myriad
    possibilities they unlock.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入了解这两种开创性技术的全面内部工作原理：它们的底层机制和它们解锁的众多可能性。
- en: 1.1.2 The Python programming language
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 Python编程语言
- en: I assume you have a working knowledge of Python. To follow the content in the
    book, you need to know the Python basics such as functions, classes, lists, dictionaries,
    and so on. If not, there are plenty of free resources online to get you started.
    Follow the instructions in appendix A to install Python. After that, create a
    virtual environment for this book and install Jupyter Notebook as the computing
    environment for projects in this book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设您已经具备Python的基本知识。为了跟随书中的内容，您需要了解Python的基础知识，例如函数、类、列表、字典等。如果您还没有，网上有大量的免费资源可以帮助您入门。按照附录A中的说明安装Python。之后，为本书创建一个虚拟环境，并安装Jupyter
    Notebook作为本书项目中计算环境。
- en: Python has established itself as the leading programming language globally since
    the latter part of 2018, as documented by *The Economist* (see the article “Python
    Is Becoming the World’s Most Popular Coding Language” by the Data Team at *The
    Economist,* 2018, [https://mng.bz/2gj0](https://mng.bz/2gj0)). Python is not only
    free for everyone to use but also allows other users to create and tweak libraries.
    Python has a massive community-driven ecosystem, so you can easily find resources
    and assistance from fellow Python enthusiasts. Plus, Python programmers love to
    share their code, so instead of reinventing the wheel, you can import premade
    libraries and share your own with the Python community.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自2018年后期以来，Python已经成为全球领先的编程语言，正如《经济学人》杂志所记录的（参见《经济学人》数据团队撰写的文章“Python Is Becoming
    the World’s Most Popular Coding Language”，2018年，[https://mng.bz/2gj0](https://mng.bz/2gj0)）。Python不仅对每个人都是免费的，还允许其他用户创建和调整库。Python有一个庞大的社区驱动的生态系统，因此你可以轻松找到来自其他Python爱好者的资源和帮助。此外，Python程序员喜欢分享他们的代码，所以你不必重新发明轮子，你可以导入现成的库，并与Python社区分享你的代码。
- en: No matter if you’re on Windows, Mac, or Linux, Python’s got you covered. It’s
    a cross-platform language, although the process of installing software and libraries
    might vary a bit depending on your operating system—but don’t worry; I’ll show
    you how to do it in appendix A. Once everything’s set up, Python code behaves
    the same across different systems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是在Windows、Mac还是Linux上，Python都能满足你的需求。它是一种跨平台语言，尽管安装软件和库的过程可能因操作系统而异——但不用担心；我会在附录A中向你展示如何操作。一旦一切准备就绪，Python代码在不同系统上表现一致。
- en: Python is an expressive language that’s suitable for general application development.
    Its syntax is easy to grasp, making it straightforward for AI enthusiasts to understand
    and work with. If you run into any problems with the Python libraries mentioned
    in this book, you can search Python forums or visit sites like Stack Overflow
    ([https://stackoverflow.com/questions/tagged/python](https://stackoverflow.com/questions/tagged/python))
    for answers. And if all else fails, don’t hesitate to reach out to me for assistance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种适合通用应用开发的表达性语言。它的语法易于理解，使得AI爱好者能够轻松理解和操作。如果你在这本书中提到的Python库遇到任何问题，你可以在Python论坛上搜索或访问像Stack
    Overflow([https://stackoverflow.com/questions/tagged/python](https://stackoverflow.com/questions/tagged/python))这样的网站寻找答案。如果所有其他方法都失败了，请不要犹豫，向我寻求帮助。
- en: Lastly, Python offers a large collection of libraries that make creating generative
    models easy (relative to other languages such as C++ or R). In this journey, we’ll
    exclusively use PyTorch as our AI framework, and I’ll explain why we pick it over
    competitors like TensorFlow shortly.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Python提供了一大批库，使得创建生成模型变得容易（相对于C++或R等其他语言）。在这个旅程中，我们将独家使用PyTorch作为我们的AI框架，我将在稍后解释为什么我们选择它而不是像TensorFlow这样的竞争对手。
- en: 1.1.3 Using PyTorch as our AI framework
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.3 使用PyTorch作为我们的AI框架
- en: Now that we have settled on using Python as the programming language for this
    book, we’ll choose a suitable AI framework for generative modeling. The two most
    popular AI frameworks in Python are PyTorch and TensorFlow. In this book, we use
    PyTorch over TensorFlow for its ease of use, and I strongly encourage you to do
    the same.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经决定将Python作为本书的编程语言，我们将选择一个适合生成建模的AI框架。在Python中，最受欢迎的两个AI框架是PyTorch和TensorFlow。在这本书中，我们选择PyTorch而不是TensorFlow，因为它易于使用，并且我强烈建议你也这样做。
- en: PyTorch is an open-source ML library developed by Meta’s AI Research lab. Built
    on the Python programming language and the Torch library, PyTorch aims to offer
    a flexible and intuitive platform for creating and training deep learning models.
    Torch, the predecessor of PyTorch, was an ML library for building deep neural
    networks in C with a Lua wrapper, but its development was discontinued. PyTorch
    was designed to meet the needs of researchers and developers by providing a more
    user-friendly and adaptable framework for deep learning projects.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是由Meta的AI研究实验室开发的开源ML库。它建立在Python编程语言和Torch库的基础上，旨在提供一个灵活且直观的平台，用于创建和训练深度学习模型。Torch是PyTorch的前身，是一个用C语言构建深度神经网络并带有Lua包装器的ML库，但它的开发已经停止。PyTorch旨在通过提供一个更用户友好和适应性强的框架来满足研究人员和开发者的需求。
- en: A computational graph is a fundamental concept in deep learning that plays a
    crucial role in the efficient computation of complex mathematical operations,
    especially those involving multidimensional arrays or tensors. A computational
    graph is a directed graph where the nodes represent mathematical operations, and
    the edges represent data that flow between these operations. One of the key uses
    of computational graphs is the calculation of partial derivatives when implementing
    backpropagation and gradient descent algorithms. The graph structure allows for
    the efficient calculation of gradients required to update the model parameters
    during training. PyTorch creates and modifies the graph on the fly, which is called
    a dynamic computational graph. This makes it more adaptable to varying model architectures
    and simplifies debugging. Further, just like TensorFlow, PyTorch provides accelerated
    computation through GPU training, which can significantly reduce training time
    compared to central processing unit (CPU) training.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图是深度学习中的一个基本概念，在高效计算复杂数学运算中扮演着至关重要的角色，尤其是涉及多维数组或张量的运算。计算图是一种有向图，其中的节点代表数学运算，而边则代表在这些运算之间流动的数据。计算图的关键用途之一是在实现反向传播和梯度下降算法时计算偏导数。图结构允许高效地计算在训练过程中更新模型参数所需的梯度。PyTorch能够动态创建和修改图，这被称为动态计算图。这使得它能够更好地适应不断变化的结构模型，并简化了调试过程。此外，就像TensorFlow一样，PyTorch通过GPU训练提供加速计算，与中央处理器（CPU）训练相比，可以显著减少训练时间。
- en: PyTorch’s design aligns well with the Python programming language. Its syntax
    is concise and easy to understand, making it accessible to both newcomers and
    experienced developers. Researchers and developers alike appreciate PyTorch for
    its flexibility. It empowers them to experiment with novel ideas quickly, thanks
    to its dynamic computational graph and simple interface. This flexibility is crucial
    in the rapidly evolving fields of generative AI. PyTorch also has a rapidly growing
    community that actively contributes to its development. This results in an extensive
    ecosystem of libraries, tools, and resources for developers.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的设计与Python编程语言相得益彰。其语法简洁易懂，使得新手和经验丰富的开发者都能轻松上手。研究人员和开发者都欣赏PyTorch的灵活性。它使他们能够快速实验新想法，这得益于其动态计算图和简单的接口。这种灵活性在快速发展的生成人工智能领域至关重要。PyTorch还拥有一个快速发展的社区，积极为其发展做出贡献。这导致了一个庞大的生态系统，包括库、工具和资源，为开发者提供支持。
- en: PyTorch excels in transfer learning, a technique where pretrained models designed
    for a general task are fine-tuned for specific tasks. Researchers and practitioners
    can easily utilize pretrained models, saving time and computational resources.
    This feature is especially important in the age of pretrained LLMs and allows
    us to adopt LLMs for downstream tasks such as classification, text summarization,
    and text generation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch在迁移学习方面表现出色，这是一种将针对通用任务设计的预训练模型微调以适应特定任务的技术。研究人员和实践者可以轻松利用预训练模型，节省时间和计算资源。这一特性在预训练大型语言模型（LLMs）的时代尤为重要，它使我们能够将LLMs应用于下游任务，如分类、文本摘要和文本生成。
- en: PyTorch is compatible with other Python libraries, such as NumPy and Matplotlib.
    This interoperability allows data scientists and engineers to seamlessly integrate
    PyTorch into their existing workflows, enhancing productivity. PyTorch is also
    known for its commitment to community-driven development. It evolves rapidly,
    with regular updates and enhancements based on real-world usage and user feedback,
    ensuring that it remains at the cutting edge of AI research and development.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch与其它Python库兼容，如NumPy和Matplotlib。这种互操作性允许数据科学家和工程师无缝地将PyTorch集成到现有的工作流程中，提高生产力。PyTorch还以其对社区驱动开发的承诺而闻名。它发展迅速，定期根据实际使用和用户反馈进行更新和改进，确保其始终处于人工智能研究和开发的前沿。
- en: Appendix A provides detailed instructions on how to install PyTorch on your
    computer. Follow the instructions to install PyTorch in the virtual environment
    for this book. In case you don’t have a Compute Unified Device Architecture (CUDA)-enabled
    GPU installed on your computer, all programs in this book are compatible with
    CPU training as well. Better yet, I’ll provide the trained models on the book’s
    GitHub repository [https://github.com/markhliu/DGAI](https://github.com/markhliu/DGAI)
    so you can see the trained models in action (in case the trained model is too
    large, I’ll provide them on my personal website [https://gattonweb.uky.edu/faculty/lium/](https://gattonweb.uky.edu/faculty/lium/)).
    In chapter 2, you’ll dive deep into PyTorch. You’ll first learn the data structure
    in PyTorch, Tensor, which holds numbers and matrices and provides functions to
    conduct operations. You’ll then learn to perform an end-to-end deep learning project
    using PyTorch. Specifically, you’ll create a neural network in PyTorch and use
    clothing item images and the corresponding labels to train the network. Once done,
    you use the trained model to classify clothing items into 10 different label types.
    The project will get you ready to use PyTorch to build and train various generative
    models in later chapters.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 附录A提供了如何在您的计算机上安装PyTorch的详细说明。按照说明在本书的虚拟环境中安装PyTorch。如果您计算机上没有安装支持Compute Unified
    Device Architecture (CUDA)的GPU，本书中的所有程序也兼容CPU训练。更好的是，我将在本书的GitHub仓库[https://github.com/markhliu/DGAI](https://github.com/markhliu/DGAI)上提供训练好的模型，以便您可以看到训练好的模型在实际中的应用（如果训练模型太大，我将在我的个人网站上提供[https://gattonweb.uky.edu/faculty/lium/](https://gattonweb.uky.edu/faculty/lium/))）。在第二章中，您将深入探索PyTorch。您首先将学习PyTorch中的数据结构，Tensor，它包含数字和矩阵，并提供执行操作的功能。然后，您将学习如何使用PyTorch执行端到端的深度学习项目。具体来说，您将在PyTorch中创建一个神经网络，并使用服装物品图像及其相应的标签来训练网络。完成之后，您将使用训练好的模型将服装物品分类到10种不同的标签类型中。这个项目将使您为在后续章节中使用PyTorch构建和训练各种生成模型做好准备。
- en: 1.2 GANs
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 GANs
- en: This section first provides a high-level overview of how GANs work. We then
    use the generation of anime face images as an example to show you the inner workings
    of GANs. Finally, we’ll discuss the practical uses of GANs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本节首先概述GANs的工作原理。然后，我们以生成动漫人脸图像为例，向您展示GANs的内部工作原理。最后，我们将讨论GANs的实际应用。
- en: 1.2.1 A high-level overview of GANs
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 GANs的高级概述
- en: GANs represent a category of generative models initially proposed by Ian Goodfellow
    and his collaborators in 2014 (“Generative Adversarial Nets,” [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)).
    GANs have become extremely popular in recent years because they are easy to build
    and train, and they can generate a wide variety of content. As you’ll see from
    the illustrating example in the next subsection, GANs employ a dual-network architecture
    comprising a generative model tasked with capturing the underlying data distribution
    to generate content and a discriminative model that serves to estimate the likelihood
    that a given sample originates from the authentic training dataset (considered
    as “real”) rather than being a product of the generative model (considered as
    “fake”). The primary objective of the model is to produce new data instances that
    closely resemble those in the training dataset. The nature of the data generated
    by GANs is contingent upon the composition of the training dataset. For example,
    if the training data consists of grayscale images of clothing items, the synthesized
    images will closely resemble such clothing items. Conversely, if the training
    dataset comprises color images of human faces, the generated images will also
    resemble human faces.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: GANs代表一类生成模型，最初由Ian Goodfellow及其合作者于2014年提出（“Generative Adversarial Nets,” [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)）。近年来，GANs因其易于构建和训练，并且能够生成各种内容而变得极为流行。您将从下一小节中的说明示例中看到，GANs采用一个双网络架构，包括一个生成模型，其任务是捕捉潜在的数据分布以生成内容，以及一个判别模型，其作用是估计给定样本是否来自真实的训练数据集（被认为是“真实”）而不是生成模型的产物（被认为是“虚假”）。模型的主要目标是产生与训练数据集中的数据实例非常相似的新数据实例。GANs生成数据的性质取决于训练数据集的组成。例如，如果训练数据由服装物品的灰度图像组成，合成的图像将非常类似于这样的服装物品。相反，如果训练数据集包含人类面部彩色图像，生成的图像也将类似于人类面部。
- en: Take a look at figure 1.2—the architecture of our GAN and its components. To
    train the model, both real samples from the training dataset (as shown at the
    top of figure 1.2) and fake samples created by the generator (left) are presented
    to the discriminator (middle). The principal aim of the generator is to create
    data instances that are virtually indistinguishable from the examples found within
    the training dataset. Conversely, the discriminator strives to distinguish fake
    samples generated by the generator from real samples. These two networks engage
    in a continual competitive process similar to a cat-and-mouse game, trying to
    outperform each other iteratively.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下图1.2——我们GAN的架构及其组件。为了训练模型，我们将真实样本（如图1.2顶部所示）和生成器创建的虚假样本（左侧）都展示给判别器（中间）。生成器的主要目的是创建与训练数据集中找到的示例几乎无法区分的数据实例。相反，判别器努力区分生成器生成的虚假样本和真实样本。这两个网络进行着一种持续的竞争过程，类似于猫捉老鼠的游戏，试图迭代地超越对方。
- en: '![](../../OEBPS/Images/CH01_F02_Liu.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F02_Liu.png)'
- en: Figure 1.2 GANs architecture and its components. GANs employ a dual-network
    architecture comprising a generative model (left) tasked with capturing the underlying
    data distribution and a discriminative model (center) that serves to estimate
    the likelihood that a given sample originates from the authentic training dataset
    (considered as “real”) rather than being a product of the generative model (considered
    as “fake”).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 GAN架构及其组件。GAN采用双网络架构，包括一个生成模型（左侧），其任务是捕捉潜在的数据分布，以及一个判别模型（中间），其目的是估计一个给定的样本是来自真实的训练数据集（被认为是“真实”）而不是生成模型的产物（被认为是“虚假”）的可能性。
- en: 'The training process of the GAN model involves multiple iterations. In each
    iteration, the generator takes some form of task description (step 1) and uses
    it to create fake images (step 2). The fake images, along with real images from
    the training set, are presented to the discriminator (step 3). The discriminator
    tries to classify each sample as either real or fake. It then compares the classification
    with the actual labels, the ground truth (step 4). Both the discriminator and
    the generator receive feedback (step 5) from the classification and improve their
    capabilities: while the discriminator adapts its ability to identify fake samples,
    the generator learns to enhance its capacity to generate convincing samples to
    fool the discriminator. As training advances, an equilibrium is reached when neither
    network can further improve. At this point, the generator becomes capable of producing
    data instances that are practically indistinguishable from real samples.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: GAN模型的训练过程涉及多个迭代。在每个迭代中，生成器接受某种形式的任务描述（步骤1）并使用它来创建虚假图像（步骤2）。虚假图像以及来自训练集的真实图像被展示给判别器（步骤3）。判别器试图将每个样本分类为真实或虚假。然后，它将分类与实际标签、真实情况（步骤4）进行比较。判别器和生成器都从分类中接收反馈（步骤5），并提高它们的能力：判别器适应其识别虚假样本的能力，而生成器学习提高其生成能够欺骗判别器的令人信服样本的能力。随着训练的进行，当两个网络都无法进一步改进时，达到平衡。此时，生成器能够产生与真实样本几乎无法区分的数据实例。
- en: To understand exactly how GANs work, let’s look at an illustrating example.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确切了解GAN是如何工作的，让我们来看一个说明性例子。
- en: '1.2.2 An illustrating example: Generating anime faces'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 一个说明性例子：生成动漫面孔
- en: 'Picture this: you’re a passionate anime enthusiast, and you’re on a thrilling
    quest to create your very own anime faces using a powerful tool known as a deep
    convolutional GAN (or DCGAN for short; don’t worry, we’ll dive deeper into this
    in chapter 4).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：你是一个热衷的动漫爱好者，你正在使用一种称为深度卷积GAN（简称DCGAN）的强大工具进行一次激动人心的探索，以创建你自己的动漫面孔。别担心，我们将在第4章中深入探讨这一点。
- en: If you look at the top middle of figure 1.2, you’ll spot a picture that reads
    “Real Image.” We’ll use 63,632 colorful images of anime faces as our training
    dataset. And if you flip to figure 1.3, you’ll see 32 examples from our training
    set. These special images play a crucial role as they form half of the inputs
    to our discriminator network.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你观察图1.2的顶部中间部分，你会看到一个写着“实像”的图片。我们将使用63,632张动漫面孔的彩色图片作为我们的训练数据集。如果你翻到图1.3，你会看到我们训练集中的32个示例。这些特殊图片在形成我们判别网络一半输入方面起着至关重要的作用。
- en: '![](../../OEBPS/Images/CH01_F03_Liu.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F03_Liu.png)'
- en: Figure 1.3 Examples from the anime faces training dataset
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 动漫面孔训练数据集示例
- en: The left of figure 1.2 is the generator network. To generate different images
    every time, the generator takes as input a vector Z from the latent space. We
    could think of this vector as a “task description.” During training, we draw different
    Z vectors from the latent space, so the network generates different images every
    time. These fake images are the other half of the inputs to the discriminator
    network.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2的左侧是生成器网络。为了每次生成不同的图像，生成器从潜在空间中输入一个向量Z。我们可以将这个向量视为“任务描述”。在训练过程中，我们从潜在空间中抽取不同的Z向量，因此网络每次都会生成不同的图像。这些假图像是鉴别器网络输入的一半。
- en: NOTE By altering the values in the vector Z, we generate different outputs.
    In chapter 5, you’ll learn how to select the vector Z to generate images with
    certain characteristics (e.g., male or female features).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：通过改变向量Z的值，我们可以生成不同的输出。在第5章，你将学习如何选择向量Z来生成具有特定特征（例如，男性或女性特征）的图像。
- en: 'But here’s the twist: before we teach our two networks the art of creation
    and detection, the images produced by the generator are, well, gibberish! They
    look nothing like the realistic anime faces you see in figure 1.3\. In fact, they
    resemble nothing more than static on a TV screen (you’ll witness this firsthand
    in chapter 4).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有个转折：在我们教我们的两个网络创作和检测的艺术之前，生成器产生的图像，嗯，简直是胡言乱语！它们看起来根本不像图1.3中你看到的那些逼真的动漫面孔。事实上，它们看起来就像电视屏幕上的静态画面（你将在第4章亲自见证这一点）。
- en: We train the model for multiple iterations. In each iteration, we present a
    group of images created by the generator, along with a group of anime face images
    from our training set to the discriminator. We ask the discriminator to predict
    whether each image is created by the generator (fake) or from the training set
    (real).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模型进行了多次迭代训练。在每次迭代中，我们向鉴别器展示一组由生成器创建的图像，以及一组来自我们的训练集的动漫面孔图像。我们要求鉴别器预测每张图像是由生成器（伪造）还是来自训练集（真实）创建的。
- en: 'You may wonder: How do the discriminator and the generator learn during each
    iteration of training? Once the predictions are made, the discriminator doesn’t
    just sit back; it learns from its prediction blunders for each image. With this
    newfound knowledge, it fine-tunes its parameters, shaping itself to make better
    predictions in the next round. The generator isn’t idle either. It takes notes
    from its image generation process and the discriminator’s prediction outcomes.
    With that knowledge in hand, it adjusts its own network parameters, striving to
    create increasingly lifelike images in the next iteration. The goal? To reduce
    the odds of the discriminator sniffing out its fakes.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想：鉴别器和生成器在每次训练迭代中是如何学习的？一旦做出预测，鉴别器不会坐以待毙；它会从每个图像的预测错误中学习。有了这种新获得的知识，它调整自己的参数，以在下一轮中做出更好的预测。生成器也不是闲着的。它从自己的图像生成过程和鉴别器的预测结果中汲取经验。有了这些知识在手，它调整自己的网络参数，力求在下一轮迭代中创造越来越逼真的图像。目标？降低鉴别器发现其伪造品的几率。
- en: As we journey through these iterations, a remarkable transformation takes place.
    The generator network evolves, producing anime faces that grow more and more realistic,
    akin to those in our training collection. Meanwhile, the discriminator network
    hones its skills, becoming a seasoned detective when it comes to spotting fakes.
    It’s a captivating dance between creation and detection.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们穿越这些迭代，一个显著的变化发生了。生成器网络在进化，产生的动漫面孔越来越逼真，类似于我们的训练集合中的那些。同时，鉴别器网络也在磨练自己的技能，成为在识别伪造品方面的老练侦探。这是创作与检测之间的一场迷人的舞蹈。
- en: Gradually, a magical moment arrives. An equilibrium, or perfect balance, is
    achieved. The images created by the generator become so astonishingly real that
    they are indistinguishable from the genuine anime faces in our training archives.
    At this point, the discriminator is so confused that it assigns a 50% chance of
    authenticity to every image, whether it’s from our training set or was crafted
    by the generator.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 渐渐地，一个神奇的时刻到来了。达到了一种平衡，或者说是一种完美的平衡。生成器创造的图像变得如此逼真，以至于它们与我们在训练档案中的真实动漫面孔无法区分。在这个时候，鉴别器如此困惑，以至于它将每个图像的真实性赋予50%的机会，无论它是来自我们的训练集还是由生成器制作的。
- en: 'Finally, behold some examples of the artwork of the generator, as shown in
    figure 1.4: they do look indistinguishable from those in our training set.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请看一些生成器艺术作品的例子，如图1.4所示：它们看起来确实与我们的训练集中的那些无法区分。
- en: '![](../../OEBPS/Images/CH01_F04_Liu.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F04_Liu.png)'
- en: Figure 1.4 Generated anime face images by the trained generator in DCGAN
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 DCGAN训练好的生成器生成的动漫人脸图像
- en: 1.2.3 Why should you care about GANs?
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 你为什么应该关注GANs？
- en: 'GANs are easy to implement and versatile: you’ll learn to generate geometric
    shapes, intricate patterns, high-resolution images, and realistic-sounding music
    in this book alone.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: GANs易于实现且用途广泛：仅在本书中，你将学会生成几何形状、复杂图案、高分辨率图像和听起来逼真的音乐。
- en: The practical use of GANs doesn’t stop at generating realistic data. GANs can
    also translate attributes in one image domain to another. As you’ll see in chapter
    6, you can train a CycleGAN (a type of generative model in the GAN family) to
    convert blond hair to black hair in human face images. The same trained model
    can also convert black hair to blond hair. Figure 1.5 shows four rows of images.
    The first row is the original images with blond hair. The trained CycleGAN converts
    them to images with black hair (second row). The last two rows are the original
    images with black hair and the converted image with blond hair, respectively.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: GANs的实用用途不仅限于生成逼真的数据。GANs还可以将一个图像域的属性转换到另一个域。正如你在第6章中将会看到的，你可以训练一个CycleGAN（GAN家族中的一种生成模型）将人脸图像中的金色头发转换为黑色头发。同样的训练模型也可以将黑色头发转换为金色头发。图1.5显示了四行图像。第一行是带有金色头发的原始图像。训练好的CycleGAN将它们转换为带有黑色头发的图像（第二行）。最后两行是带有黑色头发的原始图像和分别转换为金色头发的转换图像。
- en: '![](../../OEBPS/Images/CH01_F05_Liu.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH01_F05_Liu.png)'
- en: Figure 1.5 Changing hair color with CycleGAN. If we feed images with blond hair
    (first row) to a trained CycleGAN model, the model converts blond hair to black
    hair in these images (second row). The same trained model can also convert black
    hair (third row) to blond hair (bottom row).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 使用CycleGAN改变发色。如果我们将带有金色头发的图像（第一行）输入到一个训练好的CycleGAN模型中，该模型将这些图像中的金色头发转换为黑色头发（第二行）。同样的训练模型也可以将黑色头发（第三行）转换为金色头发（底部行）。
- en: 'Think about all the amazing skills you’ll pick up from training GANs—they’re
    not just cool; they’re super practical too! Let’s say you run an online clothing
    store with a “Make to Order” strategy (which allows users to customize their purchases
    before manufacturing). Your website showcases tons of unique designs for customers
    to pick from, but here’s the catch: you only make the clothes once someone places
    an order. Creating high-quality images of these clothes can be quite expensive
    since you have to produce the items and then photograph them.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 想想你在训练GANs时会掌握的所有令人惊叹的技能——它们不仅酷炫，而且超级实用！假设你经营一家采用“按需定制”策略的在线服装店（这允许用户在制造前定制他们的购买）。你的网站展示了大量独特的款式供客户选择，但这里有个问题：你只有在有人下单时才会制作衣服。由于你必须制作商品并拍照，制作这些衣服的高质量图像可能相当昂贵。
- en: GANs to the rescue! You don’t need a massive collection of manufactured clothing
    items and their images; instead, you can use something like CycleGAN to transform
    features from one set of images into another, creating a whole new array of styles.
    This is just one nifty way to use GANs. The possibilities are endless because
    these models are super versatile and can handle all sorts of data—making them
    a game-changer for practical applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: GANs来拯救！你不需要大量的制造服装物品及其图像；相反，你可以使用类似CycleGAN的东西将一组图像的特征转换到另一组，从而创建一系列全新的风格。这只是使用GANs的一种巧妙方式。可能性是无限的，因为这些模型非常灵活，可以处理各种类型的数据——使它们在实用应用中成为变革者。
- en: 1.3 Transformers
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 变换器
- en: 'Transformers are deep neural networks that excel at sequence-to-sequence prediction
    problems, such as taking an input sentence and predicting the most likely next
    words. This section introduces you to the key innovation in Transformers: the
    self-attention mechanism. We’ll then discuss the Transformer architecture and
    different types of Transformers. Finally, we’ll discuss some recent developments
    in Transformers, such as multimodal models (Transformers whose inputs include
    not only text but also other data types such as audio and images) and pretrained
    LLMs (models trained on large textual data that can perform various downstream
    tasks).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器是擅长序列到序列预测问题的深度神经网络，例如，输入一个句子并预测最可能的下一个单词。本节将向您介绍Transformers的关键创新：自注意力机制。然后我们将讨论Transformer架构和不同类型的Transformers。最后，我们将讨论Transformers的一些最新发展，如多模态模型（输入不仅包括文本，还包括其他数据类型，如音频和图像的Transformers）和预训练的LLMs（在大规模文本数据上训练的模型，可以执行各种下游任务）。
- en: Before the Transformer architecture was invented in 2017 by a group of Google
    researchers (Vaswani et al., “Attention Is All You Need,” [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)),
    natural language processing (NLP) and other sequence-to-sequence prediction tasks
    were primarily handled by RNNs. However, RNNs struggle with retaining information
    about earlier elements in a sequence, which hampers their ability to capture long-term
    dependencies. Even advanced RNN variants like long short-term memory (LSTM) networks,
    which can handle longer-range dependencies, fall short when it comes to extremely
    long-range dependencies.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在2017年由一组谷歌研究人员（Vaswani等人，“Attention Is All You Need”，[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)）发明
    Transformer 架构之前，自然语言处理（NLP）和其他序列到序列预测任务主要是由循环神经网络（RNNs）处理的。然而，RNNs 在保留序列中早期元素的信息方面存在困难，这阻碍了它们捕捉长期依赖关系的能力。即使是像长短期记忆（LSTM）网络这样的高级RNN变体，虽然可以处理较长的依赖关系，但在处理极长范围依赖关系时也显得不足。
- en: More importantly, RNNs (including LSTMs) process inputs sequentially, which
    means these models process one element at a time, in sequence, instead of looking
    at the entire sequence simultaneously. The fact that RNNs conduct computation
    along the symbol positions of the input and output sequences prevents parallel
    training, which makes training slow. This, in turn, makes it impossible to train
    the models on huge datasets.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，RNNs（包括LSTMs）按顺序处理输入，这意味着这些模型一次处理一个元素，按顺序处理，而不是同时查看整个序列。RNNs沿着输入和输出序列的符号位置进行计算的事实阻止了并行训练，这使得训练速度变慢。这反过来又使得在大型数据集上训练模型成为不可能。
- en: The key innovation of Transformers is the self-attention mechanism, which excels
    at capturing long-term dependencies in a sequence. Further, since the inputs are
    not handled sequentially in the model, Transformers can be trained in parallel,
    which greatly reduces the training time. More importantly, parallel training makes
    it possible to train Transformers on large amounts of data, which makes LLMs intelligent
    and knowledgeable (based on their ability to process and generate human-like text,
    understand context, and perform a variety of language tasks). This has led to
    the rise of LLMs such as ChatGPT and the recent AI boom.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers 的关键创新是自注意力机制，它擅长捕捉序列中的长期依赖关系。此外，由于模型中对输入的处理不是按顺序进行的，因此 Transformers
    可以并行训练，这大大减少了训练时间。更重要的是，并行训练使得在大量数据上训练 Transformers 成为可能，这使得大型语言模型（LLMs）变得智能和知识渊博（基于它们处理和生成类似人类文本、理解上下文以及执行各种语言任务的能力）。这导致了
    ChatGPT 等LLMs 的兴起以及最近的AI繁荣。
- en: 1.3.1 The attention mechanism
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 注意力机制
- en: The attention mechanism assigns weights on how an element is related to all
    elements in a sequence (including the element itself). The higher the weight,
    the more closely the two elements are related. These weights are learned from
    large sets of training data in the training process. Therefore, a trained LLM
    such as ChatGPT can figure out the relationship between any two words in a sentence,
    hence making sense of the human language.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制为序列中一个元素与序列中所有元素（包括该元素本身）的关系分配权重。权重越高，两个元素之间的关系越紧密。这些权重是在训练过程中从大量训练数据中学习得到的。因此，经过训练的LLM，如ChatGPT，可以找出句子中任意两个单词之间的关系，从而理解人类语言。
- en: 'You may wonder: How does the attention mechanism assign scores to elements
    in a sequence to capture the long-term dependencies? The attention weights are
    calculated by first passing the inputs through three neural network layers to
    obtain query Q, key K, and value V (which we’ll explain in detail in chapter 9).
    The method of using query, key, and value to calculate attention comes from retrieval
    systems. For example, you may go to a public library to search for a book. You
    can type in, say, “machine learning in finance” in the library’s search engine.
    In this case, the query Q is “machine learning in finance.” The keys K are the
    book titles, book descriptions, and so on. The library’s retrieval system will
    recommend a list of books (values V) based on the similarities between the query
    and the keys. Naturally, books with the phrases “machine learning” or “finance”
    or both in titles or descriptions come up on top while books with neither phrase
    in the title or description will show up at the bottom of the list because these
    books will be assigned a low matching score.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想：注意力机制是如何为序列中的元素分配分数以捕获长期依赖关系的？首先通过三个神经网络层处理输入以获得查询 Q、键 K 和值 V（我们将在第 9
    章中详细解释）。使用查询、键和值来计算注意力的方法来自检索系统。例如，你可能会去公共图书馆查找一本书。你可以在图书馆的搜索引擎中输入，比如，“金融领域的机器学习”。在这种情况下，查询
    Q 是“金融领域的机器学习”。键 K 是书名、书籍描述等。图书馆的检索系统将根据查询和键之间的相似性推荐一系列书籍（值 V）。自然地，标题或描述中包含“机器学习”或“金融”或两者都的书籍会出现在列表的顶部，而标题或描述中都不包含这两个短语的书籍会出现在列表的底部，因为这些书籍会被分配一个较低的匹配分数。
- en: In chapters 9 and 10, you’ll learn the details of the attention mechanism—better
    yet, you’ll implement the attention mechanism from scratch to build and train
    a Transformer to successfully translate English to French.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 9 章和第 10 章中，你将了解注意力机制的细节——更好的是，你将从头开始实现注意力机制以构建和训练一个 Transformer，以成功地将英语翻译成法语。
- en: 1.3.2 The Transformer architecture
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 Transformer 架构
- en: Transformers were first proposed when designing models for machine language
    translation (e.g., English to German or English to French). Figure 1.6 is a diagram
    of the Transformer architecture. The left side is the encoder, and the right side
    is the decoder. In chapters 9 and 10, you’ll learn to construct a Transformer
    from scratch to train the model to translate English to French, and we’ll explain
    figure 1.6 in greater detail then.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 首次在为机器语言翻译（例如，英语到德语或英语到法语）设计模型时被提出。图 1.6 是 Transformer 架构的示意图。左侧是编码器，右侧是解码器。在第
    9 章和第 10 章中，你将学习从头开始构建 Transformer 以训练模型将英语翻译成法语，那时我们将更详细地解释图 1.6。
- en: The encoder in the Transformer “learns” the meaning of the input sequence (e.g.,
    the English phrase “How are you?”) and converts it into vectors that represent
    this meaning before passing the vectors to the decoder. The decoder constructs
    the output (e.g., the French translation of an English phrase) by predicting one
    word at a time, based on previous words in the sequence and the output from the
    encoder. The trained model can translate common English phrases into French.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 中的编码器“学习”输入序列（例如，英语短语“你好吗？”）的含义，并将其转换为表示这种含义的向量，然后再将这些向量传递给解码器。解码器通过逐个预测序列中的单词，基于序列中的先前单词和编码器的输出来构建输出（例如，英语短语的法语翻译）。经过训练的模型可以将常见的英语短语翻译成法语。
- en: 'There are three types of Transformers: encoder-only Transformers, decoder-only
    Transformers, and encoder-decoder Transformers. An encoder-only Transformer has
    no decoder and is capable of converting a sequence into an abstract representation
    for various downstream tasks such as sentiment analysis, named entity recognition,
    and text generation. For example, BERT is an encoder-only Transformer. A decoder-only
    Transformer has only a decoder but no encoder, and it’s well suited for text generation,
    language modeling, and creative writing. GPT-2 (the predecessor of ChatGPT) and
    ChatGPT are both decoder-only Transformers. In chapter 11, you’ll learn to create
    GPT-2 from scratch and then extract the trained model weights from Hugging Face
    (an AI community that hosts and collaborates on ML models, datasets, and applications).
    You’ll load the weights to your GPT-2 model and start generating coherent text.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器有三种类型：仅编码器 Transformer、仅解码器 Transformer 和编码器-解码器 Transformer。仅编码器 Transformer
    没有解码器，能够将序列转换为用于各种下游任务（如情感分析、命名实体识别和文本生成）的抽象表示。例如，BERT 就是一个仅编码器 Transformer。仅解码器
    Transformer 只有解码器但没有编码器，非常适合文本生成、语言建模和创意写作。GPT-2（ChatGPT 的前身）和 ChatGPT 都是仅解码器
    Transformer。在第 11 章中，你将学习从头开始创建 GPT-2，然后从 Hugging Face（一个托管和协作机器学习模型、数据集和应用的 AI
    社区）中提取训练好的模型权重。你将把权重加载到你的 GPT-2 模型中，并开始生成连贯的文本。
- en: '![](../../OEBPS/Images/CH01_F06_Liu.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F06_Liu.png)'
- en: Figure 1.6 The Transformer architecture. The encoder in the Transformer (left
    side of the diagram) learns the meaning of the input sequence (e.g., the English
    phrase “How are you?”) and converts it into an abstract representation that captures
    its meaning before passing it to the decoder (right side of the diagram). The
    decoder constructs the output (e.g., the French translation of the English phrase)
    by predicting one word at a time, based on previous words in the sequence and
    the abstract representation from the encoder.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 Transformer 架构。Transformer 中的编码器（图示的左侧）学习输入序列（例如，英语短语“你好吗？”）的含义，并将其转换为捕获其含义的抽象表示，然后再传递给解码器（图示的右侧）。解码器通过逐个预测单词，基于序列中的先前单词和编码器提供的抽象表示来构建输出（例如，英语短语的法语翻译）。
- en: Encoder-decoder Transformers are needed for complicated tasks such as multimodal
    models that can handle text-to-image generation or speech recognition. Encoder-decoder
    Transformers combine the strengths of both encoders and decoders. Encoders are
    efficient in processing and understanding input data, while decoders excel in
    generating output. This combination allows the model to effectively understand
    complex inputs (like text or speech) and generate intricate outputs (like images
    or transcribed text).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂任务，如能够处理文本到图像生成或语音识别的多模态模型，需要编码器-解码器 Transformer。编码器-解码器 Transformer 结合了编码器和解码器的优点。编码器在处理和理解输入数据方面效率高，而解码器在生成输出方面表现卓越。这种组合使得模型能够有效地理解复杂的输入（如文本或语音）并生成复杂的输出（如图像或转录文本）。
- en: 1.3.3 Multimodal Transformers and pretrained LLMs
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 多模态 Transformer 和预训练的 LLM
- en: 'Recent developments in generative AI give rise to various multimodal models:
    Transformers that can use not only text but also other data types, such as audio
    and images, as inputs. Text-to-image Transformers are one such example. DALL-E
    2, Imagen, and Stable Diffusion are all text-to-image models, and they have garnered
    much media attention due to their ability to generate high-resolution images from
    textual prompts. Text-to-image Transformers incorporate the principles of diffusion
    models, which involve a series of transformations to gradually increase the complexity
    of data. Therefore, we first need to understand diffusion models before we discuss
    text-to-image Transformers.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 最近的进展催生了各种多模态模型：这些模型不仅可以使用文本，还可以使用其他数据类型作为输入，例如音频和图像。文本到图像 Transformer
    就是这样的一个例子。DALL-E 2、Imagen 和 Stable Diffusion 都是文本到图像模型，它们因其能够从文本提示中生成高分辨率图像的能力而受到媒体广泛关注。文本到图像
    Transformer 结合了扩散模型的原则，涉及一系列转换来逐步增加数据的复杂性。因此，在讨论文本到图像 Transformer 之前，我们首先需要了解扩散模型。
- en: Imagine you want to generate high-resolution flower images by using a diffusion-based
    model. You’ll first obtain a training set of high-quality flower images. You then
    ask the model to gradually add noise to the flower images (the so-called diffusion
    process) until they become completely random noise. You then train the model to
    progressively remove noise from these noisy images to generate new data samples.
    The diffusion process is illustrated in figure 1.7\. The left column contains
    four original flower images. As we move to the right, some noise is added to the
    images in each step, until at the right column, the four images are pure random
    noise.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你想要通过使用基于扩散的模型生成高分辨率的鲜花图像。首先，你需要获取一组高质量的鲜花图像作为训练集。然后，你让模型逐渐向鲜花图像中添加噪声（所谓的扩散过程），直到它们变成完全随机的噪声。接着，训练模型从这些噪声图像中逐步去除噪声，以生成新的数据样本。扩散过程在图1.7中展示。左侧列包含四张原始的鲜花图像。随着我们向右移动，每一步都会向图像中添加一些噪声，直到右侧列，四张图像变成了纯随机噪声。
- en: '![](../../OEBPS/Images/CH01_F07_Liu.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F07_Liu.png)'
- en: Figure 1.7 The diffusion model adds more and more noise to the images and learns
    to reconstruct them. The left column contains four original flower images. As
    we move to the right, some noise is added to the images in each time step, until
    at the right column, the four images are pure random noise. We then use these
    images to train a diffusion-based model to progressively remove noise from noisy
    images to generate new data samples.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 扩散模型向图像中添加越来越多的噪声，并学习重建它们。左侧列包含四张原始的鲜花图像。随着我们向右移动，每个时间步都会向图像中添加一些噪声，直到右侧列，四张图像变成了纯随机噪声。然后，我们使用这些图像来训练一个基于扩散的模型，逐步从噪声图像中去除噪声，以生成新的数据样本。
- en: 'You may be wondering: How are text-to-image Transformers related to diffusion
    models? Text-to-image Transformers take a text prompt as input and generate images
    that correspond to that textual description. The text prompt serves as a form
    of conditioning, and the model uses a series of neural network layers to transform
    that textual description into an image. Like diffusion models, text-to-image Transformers
    use a hierarchical architecture with multiple layers, each progressively adding
    more detail to the generated image. The core concept of iteratively refining the
    output is similar in both diffusion models and text-to-image Transformers, as
    we’ll explain in chapter 15.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道：文本到图像的Transformer与扩散模型有何关联？文本到图像的Transformer接受一个文本提示作为输入，并生成与该文本描述相对应的图像。文本提示作为一种条件，模型使用一系列神经网络层将文本描述转换为图像。与扩散模型一样，文本到图像的Transformer使用具有多个层的分层架构，每个层逐步向生成的图像添加更多细节。迭代优化输出的核心概念在扩散模型和文本到图像的Transformer中是相似的，我们将在第15章中解释这一点。
- en: Diffusion models have now become more popular due to their ability to provide
    stable training and generate high-quality images, and they have outperformed other
    generative models such as GANs and variational autoencoders. In chapter 15, you’ll
    first learn to train a simple diffusion model using the Oxford Flower dataset.
    You’ll also learn the basic idea behind multimodal Transformers and write a Python
    program to ask OpenAI’s DALL-E 2 to generate images through a text prompt. For
    example, when I entered “an astronaut in a space suit riding a unicorn” as the
    prompt, DALL-E 2 generated the image shown in figure 1.8\.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于扩散模型能够提供稳定的训练并生成高质量的图像，它们现在变得越来越受欢迎，并且已经超越了其他生成模型，如GANs和变分自编码器。在第15章中，你将首先学习使用牛津鲜花数据集训练一个简单的扩散模型。你还将学习多模态Transformer背后的基本思想，并编写一个Python程序，通过文本提示请求OpenAI的DALL-E
    2生成图像。例如，当我输入“一个宇航员穿着太空服骑独角兽”作为提示时，DALL-E 2生成了图1.8所示的图像。
- en: '![](../../OEBPS/Images/CH01_F08_Liu.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F08_Liu.png)'
- en: Figure 1.8 Image generated by DALL-E 2 with text prompt “an astronaut in a space
    suit riding a unicorn”
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 通过文本提示“一个宇航员穿着太空服骑独角兽”生成的DALL-E 2图像
- en: In chapter 16, you’ll learn how to access pretrained LLMs such as ChatGPT, GPT4,
    and DALL-E 2\. These models are trained on large textual data and have learned
    general knowledge from the data. Hence, they can perform various downstream tasks
    such as text generation, sentiment analysis, question answering, and named entity
    recognition. Since pretrained LLMs were trained on information a few months ago,
    they cannot provide information on events and developments in the last one or
    two months, let alone real-time information such as weather conditions, flight
    status, or stock prices. We’ll use LangChain (a Python library designed for building
    applications with LLMs, providing tools for prompt management, LLM chaining, and
    output parsing) to chain together LLMs with the Wolfram Alpha and Wikipedia APIs
    to create a know-it-all personal assistant.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在第16章中，你将学习如何访问预训练的大型语言模型（LLM），例如ChatGPT、GPT4和DALL-E 2。这些模型在大量文本数据上进行了训练，并从数据中学习了通用知识。因此，它们可以执行各种下游任务，如文本生成、情感分析、问答和命名实体识别。由于预训练的LLM是在几个月前训练的，它们无法提供过去一两个月内的事件和发展的信息，更不用说实时信息，如天气状况、航班状态或股价。我们将使用LangChain（一个用于构建LLM应用的Python库，提供提示管理、LLM链式调用和输出解析的工具）将LLM与Wolfram
    Alpha和Wikipedia API链式调用，以创建一个无所不知的个人助理。
- en: 1.4 Why build generative models from scratch?
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 为什么需要从头开始构建生成模型？
- en: 'The goal of this book is to show you how to build and train all generative
    models from scratch. This way, you’ll have a thorough understanding of the inner
    workings of these models and can make better use of them. Creating something from
    scratch is the best way to understand it. You’ll accomplish this goal for GANs:
    all models, including DCGAN and CycleGAN, are built from the ground up and trained
    using well-curated data in the public domain.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是向你展示如何从头开始构建和训练所有生成模型。这样，你将彻底理解这些模型的内部运作，并能更好地利用它们。从头开始创造是理解它的最佳方式。你将为GANs实现这一目标：所有模型，包括DCGAN和CycleGAN，都是从头开始构建并使用公共领域精心整理的数据进行训练的。
- en: For Transformers, you’ll build and train all models from scratch except for
    LLMs. This exception is due to the vast amount of data and the supercomputing
    facilities needed to train certain LLMs. However, you’ll make serious progress
    in this direction. Specifically, you’ll implement in chapters 9 and 10 the original
    groundbreaking 2017 paper “Attention Is All You Need” line by line with English-to-French
    translation as an example (the same Transformer can be trained on other datasets
    such as Chinese to English or English to German translations). You’ll also build
    a small-size decoder-only Transformer and train it using several of Ernest Hemingway’s
    novels, including *The Old Man and the Sea*. The trained model can generate text
    in Hemingway style. ChatGPT and GPT-4 are too large and complicated to build and
    train from scratch for our purposes, but you’ll peek into their predecessor, GPT-2,
    and learn to build it from scratch. You’ll also extract the trained weights from
    Hugging Face and load them up to the GPT-2 model you built and start to generate
    realistic text that can pass as human-written.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Transformers，你将从头开始构建和训练所有模型，除了LLM。这个例外是由于训练某些LLM需要大量的数据和超级计算设施。然而，你将在这一方向上取得重大进展。具体来说，你将在第9章和第10章中逐行实现2017年那篇开创性的论文“Attention
    Is All You Need”，并以英语到法语的翻译为例（相同的Transformer可以训练其他数据集，如中文到英语或英语到德语的翻译）。你还将构建一个仅包含解码器的小型Transformer，并使用欧内斯特·海明威的多部小说，包括《老人与海》进行训练。训练后的模型可以生成海明威风格的文本。ChatGPT和GPT-4对于我们的目的来说太大太复杂，无法从头开始构建和训练，但你将一窥其前身GPT-2，并学习如何从头开始构建它。你还将从Hugging
    Face提取训练好的权重，并将它们加载到你构建的GPT-2模型中，开始生成可以以人类写作方式通过的文字。
- en: In this sense, the book is taking a more fundamental approach than most books.
    Instead of treating generative AI models as a black box, readers have a chance
    to look under the hood and examine in detail the inner workings of these models.
    The goal is for you to have a deeper understanding of generative models. This,
    in turn, can potentially help you build better and more responsible generative
    AI for the following reasons.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种意义上，本书采用了比大多数书籍更基础的方法。本书不是将生成AI模型视为黑盒，读者有机会揭开盖子，详细检查这些模型的内部运作机制。目标是让你对生成模型有更深入的理解。这反过来又可能帮助你构建更好、更负责任的生成AI，以下是一些原因。
- en: First, having a deep understanding of the architecture of generative models
    helps readers make better practical uses of these models. For example, in chapter
    5, you’ll learn how to select characteristics in generated images such as male
    or female features and with or without eyeglasses. By building a conditional GAN
    from the ground up, you understand that certain features of the generated images
    are determined by the random noise vector, Z, in the latent space. Therefore,
    you can choose different values of Z as inputs to the trained model to generate
    the desired characteristics (such as male or female features). This type of attribute
    selection is hard to do without understanding the design of the model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，对生成模型架构的深入了解有助于读者更好地实际应用这些模型。例如，在第5章中，你将学习如何选择生成图像中的特征，如性别特征和是否戴眼镜。通过从头构建条件GAN，你理解生成图像的某些特征是由潜在空间中的随机噪声向量Z决定的。因此，你可以选择不同的Z值作为训练模型的输入，以生成所需的特征（如性别特征）。这种属性选择如果不了解模型的设计是难以实现的。
- en: For Transformers, knowing the architecture (and what encoders and decoders do)
    gives you the ability to create and train Transformers to generate the types of
    content you are interested in (say, Jane Austin–style novels or Mozart-style music).
    This understanding also helps you with pretrained LLMs. For example, while it
    is hard to train GPT-2 from scratch with its 1.5 billion parameters, you can add
    an additional layer to the model and fine-tune it for other downstream tasks such
    as text classification, sentiment analysis, and question-answering.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Transformer，了解其架构（以及编码器和解码器的作用）使你能够创建和训练Transformer以生成你感兴趣的内容类型（例如，简·奥斯汀风格的小说或莫扎特风格的音乐）。这种理解也有助于你使用预训练的LLM。例如，虽然从头开始训练具有15亿参数的GPT-2很困难，但你可以在模型中添加一个额外的层，并对其进行微调以完成其他下游任务，如文本分类、情感分析和问答。
- en: 'Second, a deep understanding of generative AI helps readers have an unbiased
    assessment of the dangers of AI. While the extraordinary powers of generative
    AI have benefitted us in our daily lives and work, it also has the potential to
    create great harm. Elon Musk went so far as saying that “there’s some chance that
    it goes wrong and destroys humanity” (see the article by Julia Mueller in *The
    Hill*, 2023, “Musk: There’s a Chance AI ‘Goes Wrong and Destroys Humanity,’” [https://mng.bz/Aaxz](https://mng.bz/Aaxz)).
    More and more people in academics and in the tech industry are worried about the
    dangers posed by AI in general and generative AI in particular. Generative AI,
    especially LLMs, can lead to unintended consequences, as many pioneers in the
    tech profession have warned (see, e.g., Stuart Russell, 2023, “How to Stop Runaway
    AI,” [https://mng.bz/ZVzP](https://mng.bz/ZVzP)). It’s not a coincidence that
    merely five months after the release of ChatGPT, many tech industry experts and
    entrepreneurs, including Steve Wozniak, Tristan Harris, Yoshua Bengio, and Sam
    Altman, signed an open letter calling for a pause in training any AI system that’s
    more powerful than GPT-4 for at least six months (see the article by Connie Loizos
    in *TechCrunch*, “1,100+ Notable Signatories Just Signed an Open Letter Asking
    ‘All AI Labs to Immediately Pause for at Least 6 Months,’” [https://mng.bz/RNEK](https://mng.bz/RNEK)).
    A thorough understanding of the architecture of generative models helps us provide
    a deep and unbiased evaluation of the benefits and potential dangers of AI.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，对生成式AI的深入了解有助于读者对AI的危险性进行无偏评估。虽然生成式AI的非凡能力在我们的日常生活和工作中带来了好处，但它也有可能造成巨大的危害。埃隆·马斯克甚至表示，“有一些可能性，它可能会出错并毁灭人类”（参见《The
    Hill》2023年的文章，“Musk: There’s a Chance AI ‘Goes Wrong and Destroys Humanity’”，[https://mng.bz/Aaxz](https://mng.bz/Aaxz)）。越来越多的学术界和科技行业的人士担心AI（尤其是生成式AI）带来的危险。生成式AI，尤其是LLM，可能导致意想不到的后果，正如许多科技行业的先驱所警告的那样（例如，参见Stuart
    Russell，2023年的文章，“How to Stop Runaway AI”，[https://mng.bz/ZVzP](https://mng.bz/ZVzP)）。ChatGPT发布仅仅五个月后，包括史蒂夫·沃兹尼亚克、特里斯坦·哈里斯、约书亚·本吉奥和山姆·奥特曼在内的许多科技行业专家和企业家签署了一封公开信，呼吁至少暂停六个月训练任何比GPT-4更强大的AI系统（参见《TechCrunch》的文章，“1,100+
    Notable Signatories Just Signed an Open Letter Asking ‘All AI Labs to Immediately
    Pause for at Least 6 Months’”，[https://mng.bz/RNEK](https://mng.bz/RNEK)）。对生成模型架构的深入了解有助于我们提供对AI的益处和潜在危险的深入和无偏评估。'
- en: Summary
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI is a type of technology with the capacity to produce diverse forms
    of new content, including texts, images, code, music, audio, and video.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI是一种具有产生各种形式新内容的能力的技术，包括文本、图像、代码、音乐、音频和视频。
- en: Discriminative models specialize in assigning labels while generative models
    generate new instances of data.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别性模型擅长于分配标签，而生成性模型则生成新的数据实例。
- en: PyTorch, with its dynamic computational graphs and the ability for GPU training,
    is well suited for deep learning and generative modeling.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch凭借其动态计算图和GPU训练的能力，非常适合深度学习和生成建模。
- en: 'GANs are a type of generative modeling method consisting of two neural networks:
    a generator and a discriminator. The goal of the generator is to create realistic
    data samples to maximize the chance that the discriminator thinks they are real.
    The goal of the discriminator is to correctly identify fake samples from real
    ones.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs（生成对抗网络）是一种由两个神经网络组成的生成建模方法：一个生成器和一个人工智能判别器。生成器的目标是创建逼真的数据样本，以最大化判别器认为这些样本是真实样本的概率。判别器的目标是正确识别出真实样本中的假样本。
- en: Transformers are deep neural networks that use the attention mechanism to identify
    long-term dependencies among elements in a sequence. The original Transformer
    has an encoder and a decoder. When it’s used for English-to-French translation,
    for example, the encoder converts the English sentence into an abstract representation
    before passing it to the decoder. The decoder generates the French translation
    one word at a time, based on the encoder’s output and the previously generated
    words.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变换器是一种使用注意力机制来识别序列中元素之间长期依赖的深度神经网络。原始的变换器包括编码器和解码器。例如，当用于英语到法语翻译时，编码器将英语句子转换成抽象表示，然后传递给解码器。解码器根据编码器的输出和之前生成的单词，逐词生成法语翻译。
