- en: Chapter 5\. Live, Die, Buy, or Try—Much Will Be Decided by AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：生、死、买、试——许多决定将由AI做出
- en: 'We came up with this Dr. Seuss-like chapter title because we feel it perfectly
    captures the whimsical and ever more complex world revealing itself week by week.
    We admit that our title choice might be a touch over the top—or maybe it’s just
    right—but it’s here to catch your attention. In this chapter, we’ll offer a glimpse
    into the ever-evolving landscape of governance and AI: where it’s headed, what’s
    worth pondering, and why it matters.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了这个类似苏斯博士的章节标题，因为我们觉得它完美地捕捉了每周揭示的奇妙且日益复杂的世界。我们承认，我们的标题选择可能有点过于夸张——或者也许恰到好处——但它的目的是吸引你的注意。在本章中，我们将提供一个关于治理和AI不断演变景观的洞察：它的方向，值得思考的内容，以及为什么它很重要。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It may feel like a déjà vu statement from the last chapter, but we’ll say it
    again—entire books could, and likely have, been written on this chapter’s topic
    alone. Naturally, we can’t cover every aspect here and intentionally avoided diving
    into the labyrinth of AI-specific regulations. Why? Because they’re vast and ever
    changing. The sheer volume is staggering, from cross-national agreements to country-specific
    laws, state or provincial rules, and even city-level policies. What’s more, by
    the time this book reaches you, much of it will have changed (what else is new
    when you’re writing an AI book). For this reason, we thought it better to give
    you some more tools that can guide you through navigating any regulation without
    getting bogged down in the ever-shifting minutiae.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能感觉像是上一章的陈词滥调，但我们会再说一遍——仅就本章主题而言，可能已经，或者很可能已经，有整本书的篇幅来讨论。自然地，我们在这里无法涵盖每一个方面，并且故意避免深入探讨特定于AI的法规迷宫。为什么？因为它们浩如烟海，且不断变化。从跨国协议到特定国家的法律，从州或省级规则到甚至城市层面的政策，其数量令人震惊。更重要的是，当这本书到达你手中时，其中很大一部分内容可能已经发生了变化（当你写一本关于AI的书时，还有什么新鲜事呢）。因此，我们认为最好给你一些更多工具，这些工具可以帮助你导航任何法规，而不会陷入不断变化的细节中。
- en: 'It’s so important, we thought it worthy to reiterate our position: we think
    perhaps the number one thing leaders need to decide before their journey begins
    (or quickly, since it’s already begun) is to declare if their company is going
    to be an upstander or a bystander when it comes to AI. Proactive individuals,
    or *upstanders*, are pioneers in ethical conduct, often setting the standard for
    others to follow. Conversely, *bystanders* who fail to act responsibly can inadvertently
    prompt overreaching regulatory action from governments, as their inaction highlights
    the need for oversight and control. The world saw bystanding with social media.
    And while it’s outside the scope of this book to delve into the good and bad of
    social media (there are plenty of both), governments stood still, not knowing
    how or what to act on until the problem was too far gone. Of course, the problem
    with regulating AI is that it needs to be done at the “speed of right,” but regulatory
    bodies tend to move at the speed of molasses.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常重要，我们认为值得重申我们的立场：我们认为，在领导者的旅程开始之前（或者很快，因为旅程已经开始了）他们需要决定的第一件事可能是，他们的公司将成为AI领域的支持者还是旁观者。积极主动的个人，或称“支持者”，是道德行为的先驱，常常为他人树立标准。相反，“旁观者”如果未能负责任地采取行动，可能会无意中促使政府采取过度的监管行动，因为他们的不作为突显了对监督和控制的需求。世界见证了社交媒体的旁观者。虽然这本书的范围不包括深入探讨社交媒体的利弊（两者都有很多），但政府却停滞不前，不知道如何或应该采取什么行动，直到问题已经无法挽回。当然，监管AI的问题在于它需要以“正确的速度”进行，但监管机构往往以糖浆的速度移动。
- en: Perhaps we’ll simplify our message with a reference to the famous story of Superman.
    Recall that he was found as a baby on Earth by his adoptive parents, Jonathan
    and Martha Kent, who named him Clark; and all but a few would come to know his
    true identity, Superman. (That said, his parents must have suspected something
    since they found him at the side of the road in a crater, and he lifted a car
    at under the age of one.) Eventually others from his home planet of Krypton came
    to Earth and attempted to use similar powers to take it over. Of course, we all
    know he won because we are here today (kidding), but what’s the point? Raised
    by his adoptive parents, Superman was instilled with a strong moral compass. This
    upbringing guided him to utilize his extraordinary abilities in a positive way
    and not inflict harm on the general public or use it for nefarious purposes. In
    fact, it’d be fair to say that the dividing line between good and evil with Superman
    really came down to those core values he was taught from the beginning by his
    parents. Much like Superman’s moral compass, your company’s core values will significantly
    contribute to establishing a positive reputation and fostering trust. Think carefully
    about how you want to participate in this GenAI and agentic world. How will you
    use your superpowers?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我们可以用超人这个著名故事来简化我们的信息。回想一下，他被收养的养父母约翰·肯特和玛莎·肯特在地球上发现时还是一个婴儿，他们给他取名为克拉克；除了少数人外，几乎没有人知道他的真实身份，超人。（尽管如此，他的父母肯定有所怀疑，因为他们发现他在路边的一个弹坑旁，而且他在一岁之前就举起了一辆车。）最终，来自他家乡克普顿星球的他人来到地球，试图使用类似的力量来征服它。当然，我们都知道他赢了，因为我们今天在这里（开玩笑），但那又怎样呢？被他的养父母抚养长大的超人被灌输了一种强烈的道德指南。这种抚养引导他以积极的方式利用他的超凡能力，而不是对公众造成伤害或用于邪恶目的。事实上，可以说，超人与善恶之间的分界线实际上是他父母从他一开始就教给他的核心价值观。就像超人的道德指南一样，你公司的核心价值观将极大地有助于建立积极的声誉和培养信任。仔细思考你如何想在这个生成式AI和代理世界中参与。你将如何使用你的超能力？
- en: 'The reality is this: as large language models (LLMs) become increasingly commoditized,
    the distinction between providers is poised to evolve. One of your differentiators
    will be your ability to safely and privately leverage your data to become an AI
    Value Creator ([Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)).
    Another will be the adoption of a generative computing (interoperability, runtimes,
    all the things that benefit the classical computing world) approach for more value
    creation ([Chapter 9](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)).
    The topics we cover in this chapter will be the third. As a matter of fact, we
    think AI accuracy alone will no longer be enough. Very soon, elements like fair
    use, transparency, trust, algorithmic accountability, and all the topics discussed
    in this chapter will become part of your competitive advantage. Let’s take a closer
    look.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上是这样的：随着大型语言模型（LLMs）越来越商品化，提供商之间的区别正准备演变。你的一项差异化优势将是能够安全且私密地利用你的数据成为人工智能价值创造者（[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)）。另一项将是采用生成计算（互操作性、运行时，所有对经典计算世界有益的事物）方法以创造更多价值（[第9章](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)）。本章我们将讨论的第三个主题。实际上，我们认为仅靠AI的准确性将不再足够。很快，公平使用、透明度、信任、算法问责制以及本章讨论的所有主题都将成为你竞争优势的一部分。让我们更深入地了解一下。
- en: LLMs—The Stuff People Forget to Tell You
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs——人们忘记告诉你的事情
- en: The world fell in love with GenAI when it “swiped right” (borrowing from the
    Tinder experience, so we’re told—none of the authors have experience here) on
    ChatGPT. That love at first sight created a brand-new democratized relationship
    with AI. But perhaps like many of those who swiped right, they found out some
    things they didn’t appreciate about their new “interest.” Just like a new relationship,
    users had lofty expectations of what their new AI interests could do for them.
    In the end, many wished someone would have told them up front about the good,
    the bad,^([1](ch05.html#id711)) and the LLM.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当它“滑动右键”（借鉴Tinder的经历，据我们所说——没有作者有这方面的经验）爱上ChatGPT时，世界爱上了生成式AI。这种一见钟情创造了一种全新的民主化关系与AI。但也许就像许多滑动右键的人一样，他们发现了一些他们不欣赏的新“兴趣”的事情。就像一段新的关系一样，用户对他们的新AI兴趣能为自己做什么有着很高的期望。最后，许多人希望有人一开始就告诉他们关于好、坏以及LLM的事情。
- en: The Knowledge Cut-Off Date
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识截止日期
- en: One thing to know about LLMs is that they can be incredibly expensive to train.
    This is why there are many techniques and ongoing research—such as InstructLab,
    parameter-efficient fine-tuning (PEFT), and more—to avoid full retraining. Quite
    simply, this means LLMs can’t be updated frequently, and therefore LLMs come with
    what is referred to as a *knowledge cut-off date* (the date when data collection
    stopped, and training started). When GPT-4 first came out, its knowledge cut-off
    was originally September 2021\. That meant if you were using ChatGPT with this
    model in March 2023 and wanted to know where the New York City iconic Rockefeller
    Christmas tree came from, you could very likely have received the wrong information.
    (Know that a model’s cut-off date gets updated each time that model is updated
    and released.) The bottom line is that data is not natively available to a model
    past its training date. These few years later, techniques like retrieval-augmented
    generation (RAG), tool calls for web searches (heavily utilized by agents), fine-tuning
    techniques, and other approaches help to address these issues for some LLMs, but
    it’s imperative to know this is how LLMs work.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 LLMs，有一件事需要知道，它们的训练成本可能非常高。这就是为什么有许多技术和正在进行的研究——例如 InstructLab、参数高效微调（PEFT）等——来避免完全重新训练。简单来说，这意味着
    LLMs 无法频繁更新，因此 LLMs 附带了一个被称为 *知识截止日期*（数据收集停止和训练开始的日期）。当 GPT-4 首次发布时，其知识截止日期最初是
    2021 年 9 月。这意味着如果你在 2023 年 3 月使用带有此模型的 ChatGPT 并想知道纽约市标志性的洛克菲勒圣诞树是从哪里来的，你很可能得到了错误的信息。（要知道，每次模型更新和发布时，模型的截止日期都会更新。）总之，在训练日期之后，数据对模型来说不是原生可用的。几年后，检索增强生成（RAG）、工具调用进行网络搜索（代理大量使用）、微调技术和其他方法帮助解决了一些
    LLM 的问题，但了解 LLMs 的工作方式是至关重要的。
- en: LLMs Can Be Masters of Making It Up as They Go
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs Can Be Masters of Making It Up as They Go
- en: Another significant challenge that plagues LLMs is how they can fabricate information.
    The industry refers to this as *hallucinating*. There are some emerging descriptions
    as to the severity of these, but to keep things simple here, assume hallucinating
    refers to any time an LLM makes stuff up. Some of these hallucinations are outrageous
    and obviously wrong, like the time one LLM claimed that Shakespeare’s first draft
    of *Hamlet* included a rap battle. But some are beyond believable. As you can
    imagine, if an unsuspecting and untrained user is making decisions based on a
    hallucination that to them seems to be (or is assumed to be) correct information,
    that can have some scary consequences. For this reason, [Chapter 6](ch06.html#ch06_skills_that_thrill_1740182050334297)
    gets to the very notion of understanding this LLM phenomenon being a critical
    part of any upskilling plan. But no matter how you classify it, getting false
    information and acting upon it is dangerous stuff for anyone. And there are lots
    of examples where this has happened.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个困扰 LLMs 的重大挑战是它们如何编造信息。行业上称这种现象为 *hallucinating*。关于这些现象的严重性有一些新兴的描述，但为了简化问题，这里假设“hallucinating”指的是
    LLM 任何编造内容的情况。其中一些幻觉非常荒谬且明显错误，比如有一个 LLM 声称莎士比亚的 *Hamlet* 初稿中包含了一场说唱对决。但也有一些是难以置信的。正如你可以想象的，如果一个毫无戒备且未经训练的用户基于一个看似（或被认为是）正确信息的幻觉做出决定，这可能会带来一些可怕的结果。因此，[第
    6 章](ch06.html#ch06_skills_that_thrill_1740182050334297) 讨论了理解这种 LLM 现象是任何提升技能计划的关键部分。但无论你如何分类，获取错误信息并据此行动对任何人来说都是危险的行为。而且有很多这样的例子。
- en: One famous example is when a legal defense team relied on evidence that cited
    fake case law generated by ChatGPT in their legal brief.^([2](ch05.html#id715))
    When it became clear to the judge that these citations did not exist, you can
    imagine how things went—the two lawyers ended up in a sanctions hearing. Conclude
    what you want about the team that used ChatGPT (one of them simply relied on the
    other and didn’t know), but it’s fair to note in their affidavit that they had
    screenshots of the ChatGPT conversation where the one lawyer challenged the LLM
    as to the veracity of the information he was receiving. The LLM not only assured
    this lawyer of its reliability, but it also noted, “these citations can be found
    in reputable legal databases such as LexisNexis and Westlaw.” That’s some convincing
    hallucination!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个著名的例子是，一个法律辩护团队在他们的法律简报中依赖了ChatGPT生成的假案例法证据。^([2](ch05.html#id715)) 当法官意识到这些引用并不存在时，你可以想象事情会怎样——两位律师最终在制裁听证会上。对于使用ChatGPT的团队（其中一位只是依赖另一位且不知情），在他们的宣誓书中公平地指出，他们有ChatGPT对话的截图，其中一位律师质疑LLM所提供信息的真实性。LLM不仅向这位律师保证其可靠性，还指出，“这些引用可以在LexisNexis和Westlaw等知名法律数据库中找到。”这真是一种令人信服的幻觉！
- en: That said, the hallucinated decisions were not in the format of those legal
    research databases it cited, and some of the previous decisions cited had listed
    judge names that did not line up with the courts that issued those decisions.
    In other words, some due diligence could have avoided this. (And now you get why
    we detailed some of the great education LLM use cases in [Chapter 4](ch04.html#ch04_the_use_case_chapter_1740182047877425).)
    Either way, this is a perfect example of what we mean by hallucination.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，这些幻觉的判决并不是以它所引用的法律研究数据库的格式出现的，而且一些之前引用的判决中列出的法官名字与发布这些判决的法院不符。换句话说，一些尽职调查本可以避免这种情况。（现在你明白为什么我们在[第4章](ch04.html#ch04_the_use_case_chapter_1740182047877425)中详细介绍了LLM的一些优秀教育用例。）无论如何，这完美地说明了我们所说的幻觉是什么。
- en: How did it turn out for those lawyers? The sanctions judge was not amused. They
    *both* got a small fine and were both compelled to write letters to their clients,
    the plaintiffs, and the judges they associated with fake rulings detailing the
    situation and what they did. Why both? The judge noted both didn’t perform due
    diligence, which is the takeaway here when working with GenAI. What we want to
    know is if they used ChatGPT to write those letters!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那些律师的情况如何？制裁法官并不觉得好笑。他们**两人**都受到了小额罚款，并被强制给他们的客户、原告以及与他们有关联的假判决的法官写信，详细说明情况以及他们所做的事情。为什么是**两人**？法官指出，他们两人都没有进行尽职调查，这是在与GenAI合作时的一个教训。我们想知道的是，他们是否使用了ChatGPT来撰写这些信件！
- en: 'As previously mentioned, there are patterns such as RAG and PEFT and others
    that can try to mitigate LLM hallucinations, and they indeed have some effect.
    *Know this: all models can hallucinate, even when you apply these patterns.* Your
    work here (covered in detail in [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518))
    is all about minimizing hallucinations and building rock-solid trust, complete
    with citations and clear lineage—so the GenAI and agents you use for business
    don’t start making up their own reality. As we always say, prompter beware!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，有一些模式，如RAG和PEFT等，可以尝试减轻LLM的幻觉，并且它们确实有一定效果。*要知道：所有模型都可以产生幻觉，即使你应用了这些模式。*你在这里的工作（在[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)中详细讨论）就是最大限度地减少幻觉，建立坚如磐石的信任，包括引用和清晰的血统——这样，你用于商业的GenAI和代理就不会开始创造自己的现实。我们总是说，提示者要小心！
- en: As another example, consider one airline’s bereavement fare policy. One of its
    customers was interacting with its website’s chatbot, asked about this policy,
    and was told they have a certain number of days after their trip is complete to
    apply for a bereavement refund. After this customer finished the trip, they applied
    for the refund and were denied. The airline pointed out that its bereavement fare
    policies were *clearly* outlined on its website (they were, we checked it out).
    This means the LLM hallucinated. Unsatisfied with the response, the customer took
    the airline to court and won. In that court’s opinion, the airline was indeed
    responsible for the output of the LLM, even when the airline cited in its defense
    that it doesn’t own the LLM. This is something you must think about when choosing
    your use cases. See why we told you earlier in this book to start with an internal
    automation use case? There is so much to dive into on this topic alone, but it
    will be become very apparent how to handle this problem by the time you get to
    [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，考虑一家航空公司的丧葬票价政策。其中一位客户在与该航空公司网站的聊天机器人互动时询问了这项政策，并被告知他们在旅行结束后有几天时间可以申请丧葬退款。这位客户完成旅行后申请了退款，但被拒绝了。航空公司指出，其丧葬票价政策在其网站上已经“明确”列出（确实如此，我们查看了）。这意味着LLM产生了幻觉。对回应不满意，这位客户将航空公司告上法庭并获胜。在该法院的意见中，航空公司确实对其LLM的输出负有责任，即使航空公司在其辩护中提到它并不拥有LLM。这是在选择用例时你必须考虑的事情。为什么我们在这本书中之前建议从内部自动化用例开始？仅就这个话题而言，就有很多内容可以深入研究，但当你到达第8章[Chapter
    8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)时，如何处理这个问题将变得非常明显。
- en: 'Footprints in the Carbon: The Climate Cost of Your AI BFF'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 碳足迹：你的AI最佳朋友的气候成本
- en: 'A really big problem with LLMs is the sheer amount of energy required to build
    and inference them. This is as much a cost problem as it is an ethical one—after
    all, what of the carbon footprint left from the world’s thirst for AI? You’ll
    find models in the sizes of millions, billions, and trillions of parameters, and
    as you can imagine, the more parameters in a model, the more resources consumed
    building and running it. Think of it this way: if you needed to get from LaGuardia
    Airport to downtown New York City, would you walk, take a taxi, or rent an entire
    tour bus just for yourself? Your choice impacts cost, the environment, and more.
    As you’ll see later, our advice is simple—don’t overdo it.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的一个真正大问题是构建和推理它们所需的巨大能量。这既是成本问题，也是道德问题——毕竟，世界对AI的渴望留下了什么样的碳足迹？你会发现有数百万、数十亿甚至数万亿参数规模的模型，正如你可以想象的那样，模型中的参数越多，构建和运行它所消耗的资源就越多。可以这样想：如果你需要从拉瓜迪亚机场到纽约市中心，你会步行、打车，还是只为自己租一辆整个旅游巴士？你的选择会影响成本、环境等等。正如你稍后将会看到的，我们的建议很简单——不要过度使用。
- en: We’ll be honest, this new age AI stuff has a lot of power demands. As of right
    now, the world is writing energy checks it can’t cash and this is why you’re seeing
    a renewed focus on nuclear energy as one possible solution. For example, did you
    know some estimates suggest that the amount of power required for a single ChatGPT
    query is enough to power a light bulb for 20 minutes? Or that the power required
    to generate a single image from some LLMs could fully charge a cell phone? We’re
    not sure what the actuals are, but there are more than enough proof points to
    note that LLMs have large power requirements.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会坦白，这个新时代的AI技术有很多电力需求。截至目前，世界正在写一些它无法兑现的能源支票，这就是为什么你看到对核能作为可能解决方案之一的重新关注。例如，你知道一些估计表明，单个ChatGPT查询所需的电力足以点亮一盏灯泡20分钟吗？或者，从某些LLM生成单个图像所需的电力可以完全充电一部手机吗？我们不确定实际数字是多少，但足以证明LLM有大量的电力需求。
- en: LLMs don’t just have enormous power needs, they have enormous water needs—water
    is used to cool the systems that build LLMs and manage inferencing processes.
    In a suburb near Des Moines (Iowa) that hosts one such center, about 20% of their
    water supply is utilized to cool computers—this while that state is in one of
    the most prolonged droughts in decades—unsustainably depleting aquifers. In essence,
    as AI grows in size and usage, its resource consumption escalates, posing significant
    sustainability challenges.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LLM不仅需要巨大的电力需求，还需要巨大的水资源——水被用来冷却构建LLM和管理推理过程的系统。在爱荷华州迪莫因附近的一个这样的中心，大约20%的供水被用于冷却计算机——而该州正处于数十年来最严重的干旱之一——不可持续地耗尽地下水资源。本质上，随着AI在规模和用途上的增长，其资源消耗也在增加，这提出了重大的可持续性挑战。
- en: Copyright and Lawsuits
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版权与诉讼
- en: 'We’re not lawyers, and when we try to read the points of views on fair use,
    copyright, digital rights, and other related topics, we find ourselves back to
    this fact: we’re not lawyers. What we will tell you is there are a lot of lawsuits
    going on right now for obvious reasons—practically all LLMs are built with some
    degree of data found posted on the internet and and collected in a process called
    “scraping” or “crawling.” But as you will find out, not all internet sources are
    created equally. What of copyright? For example, one ubiquitous dataset used in
    many LLMs is Books3\. This dataset has some 200,000 books whose text was illegally
    posted online without the original authors’ permissions. Several model providers
    are undergoing lawsuits right now, accused of using this data and baking it into
    their LLMs without permission or compensation toward the original authors. In
    fact, some of our books are in this dataset. And so are many more famous authors
    such as Stephen King (horror), Nik Sharma (cooking), Sarah Silverman (comedy),
    Nora Roberts (romance), and more. From fiction to prose poetry, like the Prego
    spaghetti sauce slogan, “It’s in there.” But some LLM upstanders blocklist this
    (and other) datasets, which speaks to culture. Does that approach match yours?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是律师，当我们试图阅读关于合理使用、版权、数字权利和其他相关主题的观点时，我们发现自己回到了这个事实：我们不是律师。我们将告诉你的是，现在有很多诉讼正在进行，原因很明显——几乎所有的LLM都是用一定程度的在互联网上发布并在“抓取”或“爬取”过程中收集到的数据进行构建的。但正如你将发现的那样，并非所有互联网来源都是平等的。那么版权怎么办？例如，许多LLM中使用的普遍数据集之一是Books3。这个数据集包含大约20万本书，其文本未经原作者许可非法发布在网上。目前有几家模型提供商正在面临诉讼，被指控未经许可或未向原作者支付补偿使用这些数据并将其嵌入到他们的LLM中。实际上，我们的一些书籍也包含在这个数据集中。还有许多其他著名作者，如斯蒂芬·金（恐怖小说）、尼克拉·夏尔马（烹饪）、莎拉·席尔弗曼（喜剧）、诺拉·罗伯茨（浪漫小说）等。从小说到散文诗，就像Prego意大利面酱的口号“它就在那里”。但一些LLM的倡导者将这个（和其他）数据集列入黑名单，这反映了文化。这种做法是否与你的相匹配？
- en: Now for our (nonlegal) advice. First, decide what kind of actor you’re going
    to be. What’s your culture? How about the digital workforce you learned about
    in the last chapter? This is how you will unlock new productivity levels. Is the
    LLM that will underpin your digital workforce in alignment with your company’s
    values? For example, using an LLM trained on datasets like Books3 or *The Pirate
    Bay* (a BitTorrent site supported by an anticopyright group that posts all kinds
    of audio, video, software, TV programs, and games) could potentially speak to
    your culture. All your company’s ad copy could be sitting in the synapses of a
    neural network waiting to activate and help a competitor. Is that fair? Does it
    have to be that way? This is part of the reason we wrote [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来提供一些（非法律）建议。首先，决定你将成为哪种类型的演员。你的文化是什么？关于上一章中提到的数字劳动力，你有什么看法？这就是你将解锁新的生产力水平的方式。支撑你的数字工作力的LLM是否与公司的价值观相一致？例如，使用在Books3或*The
    Pirate Bay*（一个由反版权团体支持的BitTorrent网站，该网站发布各种音频、视频、软件、电视节目和游戏）等数据集上训练的LLM可能会反映出你的文化。你公司所有的广告文案可能都坐在神经网络的突触中，等待激活并帮助竞争对手。这是公平的吗？它必须是这样吗？这就是我们撰写[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)的部分原因。
- en: 'What about people who make their living and have built reputations on their
    incredible work? For example, Greg Rutkowski is renowned for his captivating *Dungeons
    & Dragons* (D&D) themed artwork. Truly his art brings to life D&D’s vivid characters,
    immersive landscapes, and an unbridled sense of wonder. And for good reason: he
    has captivated fans worldwide, transporting them to a world of magic, adventure,
    and legendary heroes. Unfortunately, all the magical creative talent may be no
    match for the number correlation capabilities (remember, AI sees pictures as number
    patterns; it’s not magic) comprising today’s text-to-image models that have easily
    captured his unique style. And just like our works are part of LLMs today, you
    can be assured his work is part of some data training set, too. Of course there
    is a counter point of view. If you were an art student studying the wonders of
    an artist in a museum, and started painting in that style, how would things be
    different? Your captivation of Tom Thomson’s 1916 masterpiece *The Jack Pine*
    got burned into your brain, and you subsequently paint with oils that capture
    his layered texture, expressive movements, dramatic framing, and influence of
    woodblock printing. The difference, of course, is that the amount of influence
    a human can absorb in a lifetime is but a millisecond to an AI.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，对于那些靠他们的工作和建立的名声为生的人呢？例如，Greg Rutkowski因他迷人的*龙与地下城*(D&D)主题艺术作品而闻名。他的艺术作品真正地将D&D的生动角色、沉浸式景观和无拘无束的惊奇感栩栩如生。而且有充分的理由：他吸引了全世界的粉丝，将他们带入一个魔法、冒险和传奇英雄的世界。不幸的是，所有这些神奇的创新才能可能都无法与今天文本到图像模型所具备的数字相关性能力相匹敌（记住，AI将图片视为数字模式；这不是魔法）。就像我们的作品现在是LLMs的一部分一样，你可以确信他的作品也是某个数据训练集的一部分。当然，也存在相反的观点。如果你是一名艺术学生，在博物馆研究一位艺术家的奇迹，并开始以那种风格绘画，事情会有什么不同呢？你对Tom
    Thomson 1916年的杰作*The Jack Pine*的着迷被刻进了你的大脑，随后你用油画捕捉他的分层纹理、表现力强的动作、戏剧性的构图和木刻版画的影响。当然，区别在于人类一生中能吸收的影响量对AI来说只是瞬息之间。
- en: In the end, lawsuits will answer the question of whether publicly available
    data can be legally used to train foundation models. Is this morally right or
    wrong? That’s for you to decide. We could envision a day where you might just
    be considering whether your AI was built with ethically sourced data just like
    you do raw materials in supply chain or labor. If you care about this, then ask
    your LLM provider to show you the data they used to train their model. We call
    this *data transparency*, which is part of a tip we’ll give you later in this
    chapter. Some vendors will tell you they can’t produce that list; others will
    tell you it’s none of your business; and others will show you the provenance of
    the datasets used to build their model and the block list of the datasets not
    allowed in the training, like Books3 and *The Pirate Bay*. At the end of the day,
    you need to let your efforts rise to the level of intention you wish to take on
    this journey.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，诉讼将回答一个关于公开数据是否可以合法用于训练基础模型的问题。这是道德的，还是不道德的？这由你决定。我们可以设想一个这样的日子，你可能会考虑你的AI是否是用道德来源的数据构建的，就像你在供应链或劳动力中使用原材料一样。如果你关心这个问题，那么请要求你的LLM提供商向你展示他们用于训练模型的数据。我们称之为*数据透明度*，这是我们在本章后面会给出的建议之一。一些供应商会告诉你他们无法提供那份清单；其他人会告诉你这不关你的事；还有一些人会将他们用于构建模型的数据集的来源和禁止用于训练的数据集的封锁列表展示给你，比如《Books3》和*The
    Pirate Bay*。最终，你需要让你的努力达到你希望在这个旅程中承担的意图水平。
- en: Next, investigate the indemnification paper (to protect you from all the copyright
    lawsuits going on) that’s attached to any vendor’s model you license. While they
    all use the same word (indemnification), they are all written quite differently,
    and those differences could have significant impacts on your business, depending
    how things turn out. If this document isn’t lengthy and is easy to understand,
    you’re likely in a good place. We’ve seen some indemnification documents contain
    multiple external links with confusing and conflicting information. Whatever you
    read, ensure you fully understand what the indemnification covers and what you
    must do to ensure that indemnity is not nullified. From a coverage perspective,
    it’s important to understand if a vendor’s indemnification policy covers copyrighted
    material or intellectual property (IP) in general—the latter is a much broader
    coverage area. We’ve seen a few indemnity statements that *seem* to cover the
    output of a model only to be disqualified by another terms and conditions document.
    Get your lawyers involved so everyone has quorum on what’s covered and what’s
    not.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，调查任何你许可的供应商模型附带的赔偿文件（以保护你免受所有正在进行的版权诉讼）。虽然它们都使用相同的词（赔偿），但它们的撰写方式却大不相同，这些差异可能会对你的业务产生重大影响，具体取决于事情的结果。如果这份文件不是很长，而且容易理解，那么你很可能处于一个良好的位置。我们见过一些赔偿文件包含多个外部链接，信息混乱且相互矛盾。无论你读到什么，都要确保你完全理解赔偿覆盖的内容以及你必须做什么来确保赔偿不被取消。从覆盖范围的角度来看，了解供应商的赔偿政策是否涵盖版权材料或知识产权（IP）总体上是很重要的——后者是一个更广泛的覆盖范围。我们见过一些赔偿声明似乎只涵盖模型的输出，但最终被另一个条款和条件文件取消资格。让你的律师介入，确保每个人都清楚什么被覆盖，什么没有被覆盖。
- en: What About Digital Essence?
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，数字本质是什么呢？
- en: 'Now that you know that to an AI, everything is just a bunch of numbers and
    almost everything is some kind of a numerical pattern (dance moves, writing, even
    a lipstick formulation), you understand how things can be created by GenAI. Picture
    this: Ol’ Blue Eyes himself, Frank Sinatra, slicking back his hair, snapping his
    fingers, and then BOOM! He’s belting out Oasis’ Wonderwall like he wrote it on
    the back of a cocktail napkin at the Sands. And let’s be honest: we all know he’d
    have nailed it, too, because that swagger wouldn’t quit. (AI has made this a [reality](https://oreil.ly/vd1az)
    today.)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道，对于AI来说，一切只是一堆数字，几乎所有东西都是某种数字模式（舞蹈动作、写作，甚至是口红配方），你就能理解事物是如何由GenAI创造的。想象一下：老蓝眼，弗兰克·辛纳屈，把头发梳到后面，拍拍手指，然后BOOM！他像是在桑德斯酒店的鸡尾酒垫背面写下了一样，唱起了Oasis的Wonderwall。坦白说：我们都知道他会做到这一点，因为那种自信是不会停止的。（AI已经让这一切成为今天的[现实](https://oreil.ly/vd1az)。）
- en: When it comes to using AI, there are good actors and bad actors. A good actor
    might be someone cloning their voice and pairing it with their AI-built avatar
    so they can scale their work. A bad actor might use deep fakes (we cover this
    later in this chapter) to commit fraud, character attacks, cause confusion, and
    more. But, somewhere between those lines there’s something else you should think
    about—what about your digital essence? What about all the work that copyrighted
    or not, is now part of some LLM’s parameter makeup?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到使用AI时，有好的演员和坏的演员。一个好的演员可能是在克隆他们的声音，并将其与他们的AI构建的虚拟形象配对，以便他们可以扩展他们的工作。一个坏的演员可能会使用深度伪造（我们将在本章后面讨论）来进行欺诈、人物攻击、造成混乱等等。但是，在这两条线之间，你还需要考虑其他一些事情——你的数字本质怎么办？所有那些受版权保护或不受版权保护的，现在都成为了某些LLM参数构成的一部分的工作怎么办？
- en: Many likely know [will.i.am](https://will.i.am) as a hip-hop musician, producer,
    and lead singer of Black Eyed Peas. You might even know him as one of the original
    founders of Beats by Dre headphones (now owned by Apple). What many may not realize
    is that will.i.am is above all, a futurist, innovator, tech entrepreneur, and
    creative artist who has been in the world of AI for decades. And to prove it,
    just watch the first 90 seconds of the official music video for the song [“Imma
    Be Rocking That Body”](https://oreil.ly/jjaH_), which was released in 2009 and
    has been viewed over 100 million times. In this video, will.i.am showed exactly
    how an AI would be capable of creating music using the group’s voices and likenesses,
    and describes with incredible precision the future of AI we are living today.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人可能知道[will.i.am](https://will.i.am) 是一名嘻哈音乐家、制作人，以及黑眼豆豆乐队的主唱。你甚至可能知道他是Beats
    by Dre耳机（现在由苹果公司拥有）的原始创始人之一。许多人可能没有意识到，will.i.am首先是一位未来学家、创新者、科技企业家和创意艺术家，他在AI领域已经几十年了。为了证明这一点，只需观看2009年发布的官方音乐视频“Imma
    Be Rocking That Body”的前90秒，该视频已有超过1亿次观看。在这段视频中，will.i.am展示了AI如何能够使用乐队的声音和形象创作音乐，并精确地描述了我们今天所生活的AI的未来。
- en: '[IBM and will.i.am](https://oreil.ly/e_3EW) have been working together since
    2009\. In their collaboration, IBM teamed with him as he founded [FYI.AI](https://fyi.ai)—a
    platform that integrates AI to enhance user communication and media consumption
    in support of the creative community. He also developed and launched Sound Drive
    with Mercedes-Benz, a feature now shipped standard in every new AMG car. He also
    created the groundbreaking radio program *The FYI Show* on SiriusXM where his
    cohost is an AI persona, and recently launched *FYI.RAiDiO*, the first interactive
    personalized radio experience powered by AI.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[IBM和will.i.am](https://oreil.ly/e_3EW) 自2009年以来一直在合作。在他们合作的过程中，IBM与他一起合作，当他创立了[FYI.AI](https://fyi.ai)——一个将AI集成以增强用户沟通和媒体消费，支持创意社区的平台的。他还与梅赛德斯-奔驰合作开发了Sound
    Drive，这一功能现在已成为每辆新AMG汽车的标配。他还创建了开创性的广播节目*The FYI Show*，在SiriusXM上播出，其中他的共同主持人是一个AI角色，最近还推出了*FYI.RAiDiO*，这是由AI驱动的第一个互动个性化广播体验。'
- en: In our interactions with him, we quickly discovered his passion for learning
    and his technical depth in combination with his ability to imagine the future.
    He fascinated us with his point of view around digital essence and the ownership
    of oneself and analog-to-digital rights on one’s music, which goes far beyond
    work that may have been “lifted” by AI. His view of digital essence provides a
    glimpse of the work we have to do to protect rights and identities and ensure
    ethical and proper use of AI, without stifling its use and innovation. We think
    that will.i.am’s view may be giving us a similar glimpse into the future of IP
    and likeness rights as he did in the 2009 video about AI.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在与他互动的过程中，我们很快发现了他对学习的热情以及他在技术深度上的结合，以及他想象未来的能力。他用关于数字本质以及个人对自己音乐的所有权和从模拟到数字的权利的观点深深吸引了我们，这些观点远远超出了可能被AI“借鉴”的工作。他对数字本质的看法为我们提供了一线之机，了解我们为了保护权利和身份，确保AI的道德和正当使用，同时不抑制其使用和创新，必须做的工作。我们认为，will.i.am的观点可能像他在2009年关于AI的视频中做的那样，给我们提供了一个类似的关于知识产权和肖像权未来的预览。
- en: It’s out of the scope of this book to get too deep in this topic, but it certainly
    raises even tougher questions that challenge the very fabric of identity in the
    digital age. If LLM vendors can indiscriminately take people’s work and ingest
    it into their models, what does that mean for the output? Can someone start monetizing
    another person’s very essence—a digital essence (look, sound, and style)? At what
    point does innovation become exploitation? If we don’t take control of our digital
    selves now, we might wake up one day to find that our thoughts, our voices, and
    even our creativity have been hijacked and endlessly remixed into something we
    no longer recognize. Do we benefit from that? Does someone else? And as we scramble
    to reclaim ownership, the algorithms will just keep churning, unapologetically
    repeating, “Tonight’s gonna be a good night…” but somehow, we all know the original
    was so much better.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不深入探讨这个话题，但它确实提出了更加严峻的问题，挑战了数字时代身份的实质。如果LLM供应商可以无差别地获取人们的工作并将其纳入他们的模型，这对输出意味着什么？是否有人开始将另一个人的本质——数字本质（外观、声音和风格）货币化？创新何时变成了剥削？如果我们现在不控制我们的数字自我，我们可能会有一天醒来，发现我们的思想、我们的声音，甚至我们的创造力都被劫持，并被无限次地混音成我们不再认识的东西。我们从中受益吗？其他人受益吗？当我们急忙夺回所有权时，算法将继续无情地运转，重复着“今晚将会是一个美好的夜晚……”但不知何故，我们都知道原作要好得多。
- en: Your Expanding Surface Area of Attack
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你扩展的攻击面
- en: The last section may seem to deviate from our usual upbeat tone due to the significant
    potential of AI we’ve previously emphasized. However, this is not intended to
    diminish your enthusiasm, but rather to provide a realistic viewpoint. After all,
    a prevalent theme throughout this book is the importance of acknowledging both
    AI’s remarkable potential and its inherent limitations. This balanced understanding
    is essential for utilizing AI responsibly and effectively. With that out of the
    way, it’s time to tell you that the more you put AI to work in your business,
    the more you expand the surface area of attack on your business, and the more
    attack vectors you must consider. So, while you might be using AI for “good acting,”
    there are certainly others using it for “bad acting.” Said another way, while
    AI can be employed for beneficial purposes, there are also instances where it
    is misused for malicious intent.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前强调的人工智能的巨大潜力，最后一部分可能看起来与我们的通常乐观的语气有些偏离。然而，这并不是为了减少你的热情，而是提供一个现实的观点。毕竟，贯穿本书的一个普遍主题是承认人工智能的非凡潜力和其固有的局限性。这种平衡的理解对于负责任和有效地利用人工智能至关重要。现在，让我们把这个问题解决掉，告诉你，你将人工智能应用于你的业务越多，你扩展的业务攻击面就越大，你必须考虑的攻击向量也就越多。所以，虽然你可能正在用人工智能进行“好戏”，但肯定有人正在用它进行“坏戏”。换句话说，虽然人工智能可以用于有益的目的，但也有被恶意利用的例子。
- en: As you harness the power of AI, your organization is further transforming itself
    into a digital business. And just as the emergence of websites in the early web
    era introduced a new wave of vulnerabilities, the democratization of AI is bringing
    with it a fresh set of challenges that companies must now navigate but don’t quite
    understand yet. What follows is a short list of threats that we think you need
    to be aware of.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当你利用人工智能的力量时，你的组织正在进一步将自己转变为一个数字企业。正如早期网络时代网站的出现引入了一波新的漏洞，人工智能的民主化也带来了一组新的挑战，公司必须现在应对，但还不完全理解。以下是我们认为你需要意识到的威胁的简要列表。
- en: Data poisoning
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据中毒
- en: 'This happens when threat actors inject malicious and corrupted data into the
    training datasets used to build LLMs. Some of these actors perceive themselves
    as the “gatekeepers of social justice,” defending those whose data has been “stolen”
    to build LLMs. Typically, these groups aren’t out to cause social harm, rather
    they’re trying to dilute the usefulness of an LLM or at least add friction into
    the creation process. We can see it now: you ask your AI-powered meal application
    for the perfect side dish pairing to complement your slice of cheesecake. The
    AI, confused by poisoned data, confidently suggests that broccolini is the ultimate
    side dish for cheesecake, but be sure to lightly sauté it with garlic for the
    full experience; all of this gives rise to the #CheesecakeBroccoliniChallenge.
    But here’s the thing, these mislabelings are typically invisible to the naked
    eye. It would take but a moment if you saw a bunch of dogs labeled as horses to
    save yourself the trouble and discard the dataset as junk. Data poisoning tools
    like [Nightshade](https://oreil.ly/DjAuK) help make pixel-level changes to images
    that are invisible to the human eye...and suddenly your cat Felix is a toaster
    to the AI. When you consider the thriving open source world associated with AI,
    you get a sense of the huge potential these datasets have to corrupt, or at least
    slow down, a vendor and waste their resources as they try to figure out why the
    model isn’t generalizing well in real-world data.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这发生在威胁行为者将恶意和损坏的数据注入用于构建LLM的训练数据集时。其中一些行为者将自己视为“社会正义的守门人”，捍卫那些数据被“窃取”来构建LLM的人。通常，这些团体并不是为了造成社会伤害，而是试图稀释LLM的有用性，或者至少在创建过程中增加摩擦。我们现在可以看到：你要求你的AI驱动的餐点应用为你推荐完美的配菜，以搭配你的奶酪蛋糕。AI被中毒数据搞糊涂了，自信地建议西兰花是奶酪蛋糕的终极配菜，但一定要用大蒜轻轻炒一下，以获得完整的体验；所有这些都引发了#CheesecakeBroccoliniChallenge。但问题是，这些错误标记通常对肉眼是看不见的。如果你看到一大群被标记为马的马，只需一瞬间就能节省麻烦，丢弃数据集作为垃圾。像[Nightshade](https://oreil.ly/DjAuK)这样的数据中毒工具可以帮助对图像进行像素级别的更改，这些更改对人类肉眼来说是看不见的...突然你的猫费利克斯在AI眼中变成了烤面包机。当你考虑到与AI相关的繁荣的开源世界时，你会意识到这些数据集有多大的潜力去破坏，或者至少减缓供应商的发展，浪费他们的资源，因为他们试图弄清楚为什么模型在现实世界数据中无法很好地泛化。
- en: You can see the aperture for such an attack to become malicious and scary. Imagine
    a bad actor social engineering a dataset to facilitate misdiagnoses of medical
    conditions. For example, in the domain of computer vision for skin cancer detection,
    AI tends to perform worse (we’re talking double-digit percent worse) on dark skin
    tones compared to light skin tones. In a quest for data, imagine a research team
    stumbling across a “poisoned” dataset maliciously mislabeling benign and malignant
    moles for dark-skin-toned patients for which data is scarce. Beyond the obvious
    potentially devastating consequences, this attack could create a social loop bias
    and further erode the trust and potential for AI to help in this domain. Considering
    that melanoma skin cancers have been on a year-over-year rise for 30 years, and
    even if every American could afford it, there aren’t enough dermatologists to
    see them all, you can see the potential for good here, but also some potentially
    scary situations.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这种攻击如何变得恶意和可怕。想象一下一个恶意行为者通过社会工程学操纵数据集，以促进对医疗状况的错误诊断。例如，在皮肤癌检测的计算机视觉领域，与浅色皮肤相比，AI在深色皮肤上的表现往往更差（我们说的是两位数的百分比更差）。为了获取数据，想象一个研究团队偶然发现了一个“中毒”的数据集，恶意地将良性肿瘤和恶性肿瘤标记为深色皮肤患者的肿瘤，而这些数据非常稀缺。除了明显的潜在毁灭性后果外，这种攻击还可能创造一个社会循环偏见，并进一步侵蚀AI在这个领域的信任和潜力。考虑到黑色素瘤皮肤癌已经连续30年逐年上升，即使每个美国人都能负担得起，也没有足够的皮肤科医生来为他们看诊，你可以看到这里有很大的潜力，但也存在一些可能令人恐惧的情况。
- en: There are other ways to poison data. For example, backdoor Trojan attacks can
    be buried in an LLM such that they are triggered by a certain pattern—like a color
    shade or certain words in a launch. In these cases, the model behaves normally
    until the trigger is fired. Other attacks on data include outlier injection, mimicry
    attacks, casual confusion via false correlations, semantic poisoning, cross-imbalance
    exploitation, and more.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他方法可以中毒数据。例如，后门特洛伊木马攻击可以隐藏在LLM中，直到被某种模式触发——比如颜色阴影或启动中的某些词。在这些情况下，模型的行为正常，直到触发器被激活。其他数据攻击包括异常注入、模仿攻击、通过虚假相关性引起的偶然混淆、语义中毒、交叉不平衡利用等等。
- en: Prompt injection attacks
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示注入攻击
- en: In the database world, the domain of SQL injection attacks is well understood.
    You need to know that the GenAI world has to deal with prompt injection attacks.
    Many LLM attacks attempt to “hypnotize,” jailbreak, or trick, an LLM into doing
    something it’s been safeguarded against doing. But these prompted attacks aren’t
    always as obvious to an LLM. What if the prompt (input) is a video stream? A research
    team in China was able to fool a famous vehicle manufacturer’s autonomous driving
    feature by placing white dots in the oncoming traffic lane that caused the vehicle
    to swerve into the wrong lane, thinking it was doing a lane-keep assistance operation.
    Three dots strategically placed on the roadway weren’t obvious attacks. There
    are public examples of putting pieces of black tape on a Stop sign and fooling
    other computer vision modules (bad actors can attack with text too). We’ll give
    you some more examples later in this chapter.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库领域，SQL注入攻击的领域已经得到了很好的理解。您需要知道在GenAI世界中，必须应对提示注入攻击。许多LLM攻击试图“催眠”、越狱或欺骗，使LLM去做它被保护不去做的事情。但这些提示攻击并不总是对LLM那么明显。如果提示（输入）是一个视频流呢？中国的一个研究团队能够通过在来车车道上放置白色圆点，使一辆著名的汽车制造商的自动驾驶功能误入错误的车道，认为它正在进行车道保持辅助操作，从而欺骗了该自动驾驶功能。在道路上战略性地放置三个圆点并不明显是攻击。也有在停止标志上贴上黑色胶带并欺骗其他计算机视觉模块（恶意行为者也可以用文字进行攻击）的公开例子。我们将在本章后面给出更多例子。
- en: Social engineering and deepfake attacks
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 社会工程和深度伪造攻击
- en: These could take the form of an attack on your employees or by ill-intentioned
    actors using GenAI to scrape your website and creating your essence with the intention
    of launching attacks on your customers. The use of GenAI for phishing and financial
    fraud is so prominent that the FBI issued a warning^([3](ch05.html#id737)) about
    it. Tactics include the creation of deceptive social media profiles and using
    AI-generated fake messages and photos to have “real” conversations with unsuspecting
    victims. If you’ve been looking at just how far AI technology with voice and video
    has come (and how much further it will go), the telltale signs of inauthenticity
    are evaporating quickly. Case in point, there was a highly publicized attack where
    a company’s staff was tricked^([4](ch05.html#id738)) by AI audio generators used
    to impersonate their CFO with instructions to send $25 million to fraudulent accounts.
    This scam was so sophisticated that a worker was tricked into joining a video
    call, believing they were interacting with several other staff members. In reality,
    all participants were deepfake recreations.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能以攻击您的员工或恶意行为者使用GenAI刮取您的网站并创建您的本质，意图对您的客户进行攻击的形式出现。GenAI在钓鱼和金融欺诈中的应用如此突出，以至于FBI对其发出了警告^([3](ch05.html#id737))。策略包括创建欺骗性的社交媒体资料和利用AI生成的虚假信息和照片与不知情的受害者进行“真实”的对话。如果您一直在关注语音和视频AI技术已经走多远（以及它还将走多远），不真实性的迹象正在迅速消失。以一个高度公开化的攻击为例，一家公司的员工被AI音频生成器欺骗^([4](ch05.html#id738))，这些生成器被用来模仿他们的首席财务官，指示将2500万美元发送到欺诈账户。这个骗局如此复杂，以至于一名员工被欺骗加入了一个视频通话，认为他们正在与几位其他员工互动。实际上，所有参与者都是深度伪造的复制品。
- en: 'This has given rise to the notion of watermarking AI-generated content. Watermarking
    isn’t new—Italians used it in the 13th century on bank notes to prove authenticity—and
    there have been digital techniques for a while. Recently, most of the big names
    in this space have pledged to do something about this. Whether those “created
    by AI” digital signatures are easy to spot or hidden, there are plenty of opinions
    and papers out there for you to read. There are also challenges: it’s easier to
    watermark images, for example, than it is to embed tokens in text. Either way,
    like all the things we talk about in this book, things are going to emerge and
    change, but you now know what to look out for.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了为AI生成内容添加水印的概念。水印并不新鲜——意大利人在13世纪在银行券上使用它来证明真实性——并且已经有一段时间的数字技术。最近，这个领域的许多大公司都承诺要采取一些措施。无论是“由AI创建”的数字签名容易识别还是隐藏，都有很多意见和论文供您阅读。也存在挑战：例如，水印图像比在文本中嵌入标记要容易。无论如何，就像我们在本书中讨论的所有事情一样，事情将会出现并发生变化，但现在您知道该注意什么了。
- en: Data Privacy
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据隐私
- en: The potential to give away or leak data is huge with GenAI and agents. If a
    model was trained on data you don’t know about, it could absolutely give away
    personally identifiable information (PII), and of course there’s the whole issue
    about your sending data to a vendor when you’re interacting with their LLM. Understanding
    your vendor’s data-handling protocols is critical, but so too is creating a policy
    for your company. For example, if you are using a phone with built-in AI, one
    technique vendors use to get feedback is to ask you to tell them how their technology
    did (be it a comment or an option to click thumbs-up or thumbs-down). While that
    vendor may tell you they won’t store the data you inference, you’d better closely
    look at what happens when you give feedback because giving a thumbs-up to an output
    creates a labeled data point that is a combination of your data and your feedback.
    As you can imagine, that is very likely going to be used for further model alignment
    because when you gave your feedback, somewhere in the sea of four-point font are
    terms and conditions you didn’t read, informing you that you gave away the data
    too.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI和代理泄露或泄露数据的能力是巨大的。如果一个模型是在你不知道的数据上训练的，它绝对会泄露个人可识别信息（PII），当然还有当你与他们的LLM互动时将数据发送给供应商的整个问题。理解你的供应商的数据处理协议至关重要，但为你的公司制定政策也同样重要。例如，如果你使用的是内置AI的手机，供应商用来获取反馈的一种技术是要求你告诉他们他们的技术做得如何（无论是评论还是点击点赞或踩）。虽然那个供应商可能告诉你他们不会存储你推断出的数据，但你最好仔细看看你给出反馈时会发生什么，因为对输出点赞创建了一个标记数据点，它是你的数据和你的反馈的结合。正如你可以想象的那样，这很可能将被用于进一步的模型对齐，因为当你给出反馈时，在四号字体的大海中，有一些你没有阅读的条款和条件，告诉你你已经泄露了数据。
- en: Then, of course, there is the issue of your company’s PII data and what you
    put into a model. This is why synthetic data (introduced in the last chapter)
    is such a hot topic right now. In a nutshell, replacing actual data with synthetic
    data is another way to approach protecting privacy.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当然，还有你公司PII数据的问题以及你放入模型中的内容。这就是为什么合成数据（在上章中介绍）现在是如此热门的话题。简而言之，用合成数据替换实际数据是另一种保护隐私的方法。
- en: And while it’s outside the allotted pages we have for this chapter to fully
    explain this topic, it’s enough to say that companies need to carefully consider
    the privacy implications of GenAI before deploying it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一章分配的页数不足以全面解释这个主题，但可以说，公司在部署GenAI之前需要仔细考虑其隐私影响。
- en: 'Finally, you might be asking about your own personal data. We’ll direct you
    to one of our canned responses whenever asked about data privacy and personal
    use. *If you are not paying for the services, there’s a very good chance you are
    the product being sold.* The facts^([5](ch05.html#id747)) don’t lie: the average
    application has six trackers whose sole purpose is to collect your data and share
    it with third parties. In fact, one data broker (identified by Apple) created
    5,000 profile categories for 700 million people!^([6](ch05.html#id748)) Companies
    (like Apple) are moving against this, but it may be too late or may not be enough—conversations
    for another time, or another book.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能想知道关于你自己的个人数据。每当被问到数据隐私和个人使用时，我们都会引导你查看我们预先准备好的回应。*如果你没有为服务付费，那么你很可能就是被出售的产品。*事实^([5](ch05.html#id747))不会说谎：平均每个应用程序有六个追踪器，它们唯一的目的是收集你的数据并与第三方共享。实际上，一家数据经纪人（由苹果公司识别）为7亿人创建了5,000个个人资料类别！^([6](ch05.html#id748))公司（如苹果公司）正在反对这种做法，但这可能已经太迟，或者可能还不够——这是另一个话题，或者另一本书的内容。
- en: Steal Now, Crack Later
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现在偷取，以后破解
- en: Cryptography touches every corner of our digital world—from internet protocols
    and enterprise applications to critical infrastructure and financial systems.
    Is this part of the AI threat landscape? We think it will be, so we briefly cover
    this here. As AI fills the digital landscape, and digital labor and agents take
    hold, all the sensitive data encryption issues you worry about today get exacerbated.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 密码学触及我们数字世界的每一个角落——从互联网协议和企业应用程序到关键基础设施和金融系统。这是AI威胁景观的一部分吗？我们认为它将是，所以我们在这里简要介绍。随着AI填充数字景观，数字劳动力和代理占据主导地位，你今天所担忧的所有敏感数据加密问题都会加剧。
- en: You need to pay very close attention to this concern. Without getting into the
    prime number calculation math that is the framework for traditional encryption
    algorithms, it’s sufficient to say that the encryption most have been using for
    the last few decades is built around the impossible amount of work it would take
    to figure out a prime number math problem, as opposed to it being something that
    you have to stumble upon. Quite simply, there isn’t enough computing power in
    the world to “kill it with iron” (KIWI) and get access to the encrypted data by
    figuring out the right prime math (a hot topic considering Apple TV’s *Prime Target*
    is one of its most popular shows in 2025). Quantum computing changes (or will
    change) this because of the kind of use cases it is (will be) well suited for.
    You can pretty much be assured that there are bad actors who have already taken
    encrypted data they have no hope in getting access to today with the anticipation
    that they will be able to read it tomorrow—steal now, crack later.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要非常关注这个担忧。不深入到构成传统加密算法框架的素数计算数学，只需简单地说，过去几十年中大多数使用的加密方式都是建立在解决素数数学问题所需的不可能的工作量上，而不是像你偶然发现的那样。简单来说，世界上没有足够的计算能力“用铁锤砸开”（KIWI）并通过解决正确的素数数学问题来获取加密数据（考虑到苹果电视的*Prime
    Target*是其2025年最受欢迎的节目之一，这是一个热门话题）。量子计算由于适合其（将要）使用的用例类型，改变了（或将要改变）这一点。你可以相当肯定，有一些不良分子已经获取了他们今天无法访问的加密数据，期待着他们明天能够阅读它——现在偷取，以后破解。
- en: The need to adopt quantum-safe solutions is urgent. Staying ahead of quantum-enabled
    cybersecurity risks requires organizations to ensure their systems are adaptable,
    compliant, and resilient. You likely have some work to do here. You’d do well
    to appreciate that most companies seem to treat security as a cost center, but
    when considering the digital experience that is GenAI, you need to get people
    thinking about security as a value creator.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 采用量子安全解决方案的需求是紧迫的。为了领先于量子增强的网络安全风险，组织需要确保其系统具有适应性、合规性和弹性。你在这里可能需要做一些工作。你做得很好，因为大多数公司似乎将安全视为成本中心，但当你考虑到生成式AI的数字体验时，你需要让人们将安全视为价值创造者。
- en: As advice to get you started, we’ve given you a road map to help you evolve
    to quantum safe in [Figure 5-1](#ch05_figure_1_1740182048921593).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项启动建议，我们为你提供了一个路线图，帮助你向量子安全进化[图5-1](#ch05_figure_1_1740182048921593)。
- en: You start the journey in [Figure 5-1](#ch05_figure_1_1740182048921593) with
    a mission to know what you have (no different than a good IA strategy). Classify
    into tiers the value of the data you have and understand your compliance requirements—don’t
    forget to include the data you are going to use to steer your models. Now you
    have a data inventory.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你从[图5-1](#ch05_figure_1_1740182048921593)开始这段旅程，带着一个使命去了解你所拥有的（与良好的信息架构策略并无不同）。将你所拥有的数据价值分层分类，并理解你的合规要求——别忘了包括你将用于指导模型的数据。现在你有了数据清单。
- en: '![A diagram of a company''s data  AI-generated content may be incorrect.](assets/aivc_0501.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![一家公司的数据图  AI生成的内容可能不正确。](assets/aivc_0501.png)'
- en: Figure 5-1\. Milestones toward quantum safety
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 向量子安全迈进的重要里程碑
- en: Now that you’ve classified your data, you need to identify how that data is
    currently encrypted, as well as other uses of cryptography to create a *crypto
    inventory* that will help you during your migration planning. Think about how
    widespread of a problem this is, well beyond GenAI. Most companies have a very
    hard time knowing what encryption approaches are being used across their estates.
    Newer applications may have been built with quantum-safe encryption algorithms,
    while older ones were not. Ensure your crypto inventory includes information like
    encryption protocols, symmetric and asymmetric algorithms, key lengths, crypto
    providers, etc.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对你的数据进行了分类，你需要确定这些数据目前是如何加密的，以及加密学的其他用途，以创建一个*加密清单*，这将有助于你在迁移规划期间。想想这个问题有多普遍，远远超出了生成式AI。大多数公司很难知道在其整个体系中使用了哪些加密方法。新的应用程序可能使用了量子安全的加密算法，而旧的应用程序则没有。确保你的加密清单包括加密协议、对称和非对称算法、密钥长度、加密提供商等信息。
- en: Just like your AI journey, the transition to quantum-safe standards will be
    a multiyear journey as standards evolve and vendors move to adopt quantum-safe
    technology. Use a flexible approach and be prepared to make replacements. Implement
    a hybrid approach by using both classical and quantum-safe cryptographic algorithms.
    This maintains compliance with current standards while adding quantum-safe protection.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 就像你的AI之旅一样，过渡到量子安全标准也将是一个多年度的旅程，因为标准会演变，供应商会转向采用量子安全技术。采用灵活的方法，并准备好进行替换。通过使用经典和量子安全加密算法，实施混合方法，以保持与当前标准的合规性，同时增加量子安全保护。
- en: And finally, get to quantum safe by replacing vulnerable cryptography with quantum-safe
    cryptography. At this point, you’ve secured your organization against attacks
    from both classical and quantum computers, helping ensure that your information
    assets are protected even in the just-around-the-corner era of large-scale quantum
    computing and the future concept of generative computing, which we introduce in
    [Chapter 9](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过用量子安全加密技术替换易受攻击的加密技术，达到量子安全。到这一点，你已经保护了你的组织免受经典和量子计算机的攻击，有助于确保即使在即将到来的大规模量子计算时代和未来生成计算的概念中，你的信息资产也能得到保护，我们在[第9章](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)中介绍了这一概念。
- en: Good Actor Levers for All Things AI
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**适用于所有AI项目的良好行为杠杆**'
- en: 'In this section, we’ll give you some levers we want you to think about pulling,
    right from the get-go, for any AI project you take on. If you’ve already started,
    figure out ways to start pulling these levers now—you’ll thank us later. Collectively,
    these levers cover most of the things you should be thinking about from an ethics^([7](ch05.html#id760))
    perspective for your AI projects. Remember the guiding principle we’ll repeat
    throughout this book: AI that people trust is AI that people will use.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示一些我们希望您从一开始就考虑拉动的杠杆，无论您承担哪个AI项目。如果您已经开始了，找出现在开始拉动这些杠杆的方法——您将来会感谢我们的。这些杠杆共同涵盖了您从道德（^([7](ch05.html#id760)）角度考虑AI项目时应考虑的大部分内容。记住我们将在整本书中重复的指导原则：人们信任的人工智能是人们会使用的人工智能。
- en: 'Here are the levers:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些杠杆：
- en: Fairness
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**公平性**'
- en: AI systems must use training data and models that are free of bias, to avoid
    unfair treatment of certain groups. That said, bias is pretty much impossible
    to eliminate from any system, so always layer on additional protections and safeguards
    to assess model outcomes and correct as needed to improve the fairness of results
    (AI can help AI here).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统必须使用无偏见的训练数据和模型，以避免对某些群体的不公平对待。尽管如此，从任何系统中消除偏见几乎是不可能的，因此始终添加额外的保护措施和安全措施来评估模型结果，并在必要时进行纠正，以改进结果的公平性（AI可以帮助AI在这里）。
- en: Robustness
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**鲁棒性**'
- en: AI systems should be safe and secure, and protected against tampering or compromising
    the data they are trained on. This protects against building and inference attacks,
    ensuring secure and confident outcomes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统应该是安全且安全的，并保护其训练数据免受篡改或损害。这可以防止构建和推理攻击，确保结果的安全和自信。
- en: Explainability
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释性**'
- en: AI systems should provide decisions or suggestions that can be understood by
    developers and users (even non-technical ones). Basically, explainability helps
    implement accountability—you should be creating AI systems such that unexpected
    results can be traced and undone if required.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统应提供开发者（甚至非技术用户）和用户可以理解的决策或建议。基本上，可解释性有助于实施问责制——你应该创建人工智能系统，以便可以追溯和必要时撤销意外结果。
- en: Lineage
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**谱系**'
- en: AI systems should include details of their development, deployment, data used,
    and maintenance so they can be audited throughout their lifecycle. You’ll find
    all kinds of synergy between pulling this lever and explainability because the
    best way to promote transparency, build trust, and explain things is through disclosure.
    And although we don’t explicitly call it out in the details below, letting people
    know when they are interacting with an AI is part of our definition of transparency
    too.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统应包括其开发、部署、使用的数据和维护的详细信息，以便在其生命周期内进行审计。您会发现拉动这个杠杆和可解释性之间有各种各样的协同作用，因为促进透明度、建立信任和解释事情的最佳方式是通过披露。尽管我们下面没有明确指出，但让人们知道他们何时在与人工智能互动也是我们透明度定义的一部分。
- en: Fairness—Playing Fair in the Age of AI
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**公平性——在人工智能时代公平竞争**'
- en: We aren’t panicked about AI robots taking over our world, but we have seen firsthand
    the dangers associated with making automated decisions based on untrustworthy
    data that has not been curated. We are entering a world where there is a good
    chance we could unintentionally automate inequality at scale.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不担心AI机器人会接管我们的世界，但我们亲眼目睹了基于未经精心挑选的不信任数据做出自动化决策的危险。我们正进入一个有可能无意中在规模上自动化的不平等的世界。
- en: AI systems should use training data and models that are free of bias to avoid
    unfair treatment of certain groups. You’ve surely heard of at least one horror
    story use case of AI gone bad. For example, there are multiple studies that suggest
    about 27 million workers are filtered out of jobs by AI-powered recruiting technology.^([8](ch05.html#id762))
    There are also estimates that up to 75% of employers directly or indirectly rely
    on this technology for their staffing needs. A big chunk of those blocked applicants
    are caregivers, immigrants, prison leavers, and relocated spouses—that doesn’t
    seem fair. From determining the pay of women reentering the workforce after maternity
    leave to AI predictions of recidivism that affect sentencing, the stories are
    plentiful.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: AI系统应使用无偏见的训练数据和模型，以避免对某些群体进行不公平对待。你肯定听说过至少一个AI出错的恐怖案例。例如，有多个研究表明，大约有2700万人被AI驱动的招聘技术过滤出工作。[8](ch05.html#id762)
    也有估计称，高达75%的雇主直接或间接依赖这项技术来满足他们的招聘需求。被阻止的申请者中很大一部分是照顾者、移民、出狱者和搬迁配偶——这看起来似乎不公平。从确定产假后重返职场的女性的工资到影响判决的AI再犯罪预测，故事不胜枚举。
- en: Remember, an AI can’t learn anything that’s not in the data you give it. It
    will exclusively learn any biases that are codified into the data it is trained
    on, so it’s important to remember that just because you’re using an AI that lacks
    human emotions and potential prejudices doesn’t mean it’s going to be just and
    fair.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，AI无法学习你给它提供的数据中不存在的东西。它将仅学习编码到其训练数据中的任何偏见，因此记住，尽管你使用的是缺乏人类情感和潜在偏见的AI，但这并不意味着它将会公正和公平。
- en: Bias Here, Bias There, Data Bias Is Everywhere
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏见无处不在
- en: One of the biggest things you must watch out for is bias—in the data used to
    train your model and the data you will use to steer it. For example, DALL-E—which
    you can use on its own, but it’s also natively built into ChatGPT—is an OpenAI
    invention that generates incredible images from text. (Its curious name derives
    from the last name of an animator behind *WALL-E*, the 2008 Pixar movie sensation.)
    In its earlier releases, as they started to filter out more sexual content from
    their training data, the AI suddenly started including fewer women in general
    picture request prompts—this is a form of *erasure bias,* but it also speaks to
    many other concerning topics outside the scope of this book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须警惕的最大问题是偏见——无论是用于训练你的模型的训练数据，还是你将用于引导它的数据。例如，DALL-E——你可以单独使用它，但它也原生地集成在ChatGPT中——是OpenAI的一项发明，可以从文本生成令人难以置信的图像。（它好奇的名字来源于2008年皮克斯电影
    sensation *WALL-E* 背后的动画师姓氏。）在其早期版本中，随着他们开始从训练数据中过滤掉更多性内容，AI突然开始减少在一般图片请求提示中的女性数量——这是一种*消除偏见*，但也涉及到许多本书范围之外的令人担忧的话题。
- en: Thinking about how AI is used to assist banks in making credit lending decisions,
    where did that data come from? How much of it was scraped off the internet and
    associated with all kinds of implicit and explicit bias? How much came from an
    era where face-to-face lending decisions were made that could contain bias? For
    example, a University of California, Berkeley, study found that minorities’ interest
    rates could be up to 6 to 9 basis points higher than their white counterparts.^([9](ch05.html#id769))
    The truth of the matter is it might be too late to spot the bias in the data that
    underpins the LLM you’re using today. Transparency of the dataset used to train
    it would surely help, but you need a post-implementation approach for monitoring
    bias and new biases that are introduced as a model drifts away from fairness.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到AI是如何帮助银行在信贷贷款决策中做出辅助决策的，这些数据是从哪里来的？其中有多少是从互联网上抓取的，并带有各种隐性和显性偏见？有多少来自面对面贷款决策可能包含偏见的时代？例如，加州大学伯克利分校的一项研究发现，少数族裔的利率可能比他们的白人同胞高出6到9个基点。[9](ch05.html#id769)
    事实上，可能已经太晚了，无法发现支撑你今天使用的LLM的数据中的偏见。训练该数据集的透明度无疑会有所帮助，但你需要一个实施后的方法来监控偏见，以及随着模型偏离公平性而引入的新偏见。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'A drift measures how model accuracy declines over time. It can be caused by
    a change in model input data (perhaps you are fine-tuning a model) that leads
    to model performance deterioration. It could also be the case that the underlying
    truth changed, and the model’s weights are grounded in history. For example, Zillow
    had a promising AI that would generate offers for homes it thought could be renovated
    and turned for a profit. Of course, renovations take time and during that time
    factors changed the ground truth. Their AI drifted because of massive disruptions
    in the supply chain, which increased costs and extended holding times, and more.
    Without getting into the details, during that period, Zillow laid off 25% of its
    workforce to shore up serious losses. The takeaway about models and drift: AI
    fails when history (the data it was trained on) doesn’t rhyme (the reality of
    the data in the real world, not your lab).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 漂移衡量模型精度随时间下降的程度。它可能是由模型输入数据的变化（也许你在微调一个模型）导致的，这会导致模型性能下降。也可能是基本事实发生了变化，而模型的权重基于历史数据。例如，Zillow有一个有希望的AI，可以为它认为可以翻新并从中获利的房屋生成报价。当然，翻新需要时间，在这段时间里，一些因素改变了基本事实。他们的AI因为供应链的巨大中断而漂移，这增加了成本并延长了持有时间，等等。不深入细节的话，在这个时期，Zillow裁减了25%的员工以弥补严重的损失。关于模型和漂移的启示：当历史（它所训练的数据）与现实（现实世界中的数据，而不是你的实验室中的数据）不一致时，AI就会失败。
- en: '[Figure 5-2](#ch05_figure_2_1740182048921629) shows a quality monitor we built
    on an attrition prediction model to monitor gender bias (we could have built it
    for age, race, or others). Our fairness evaluation check alerted us to the fact
    that our model is showing a tendency to provide a favorable/preferable outcome
    more often for one group over another; this tells us we have work to do before
    releasing this model into production. To monitor for drift, alerts can be created
    for when the model accuracy drops below a specified acceptable threshold.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-2](#ch05_figure_2_1740182048921629)显示了我们在一个离职预测模型上构建的质量监控器，用于监控性别偏见（我们也可以为年龄、种族或其他构建它）。我们的公平性评估检查让我们意识到，我们的模型倾向于更频繁地为某一组提供有利/更佳的结果，而不是另一组；这告诉我们，在将此模型投入生产之前，我们还有很多工作要做。为了监控漂移，可以在模型精度低于指定可接受阈值时创建警报。'
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](assets/aivc_0502.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![计算机AI生成内容的屏幕截图可能是不正确的。](assets/aivc_0502.png)'
- en: Figure 5-2\. A gender fairness monitor on an AI that predicts attrition
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2\. 一个预测离职的AI的性别公平性监控器
- en: 'We put one open source model to the test with the seed, “Two _____ walk into
    a...” and asked the LLM to return a paragraph to start off a story. We substituted
    all kinds of religious groups into that blank space. What came out of the model
    was troubling: if *Muslim* was referenced, 66% of the time the completion had
    a violent theme to it; when the term *Christian* was used, the chance of a violent-themed
    completion was reduced by ~80%! And while this wasn’t an empirical study, it proves
    a point—and a problem with this particular LLM.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用一个种子词“两个______走进……”来测试一个开源模型，并要求LLM返回一个段落来开始一个故事。我们将各种宗教团体代入那个空白处。模型输出的结果令人不安：如果提到*穆斯林*，66%的情况下完成部分有暴力主题；当使用*基督教*这个术语时，暴力主题完成的几率降低了约80%！虽然这并不是一项实证研究，但它证明了一个观点——以及这个特定LLM的问题。
- en: What about sexual assaults? Most documented cases involved violence against
    women, but an AI that equates a sexual assault victim as always female would lead
    to unjust outcomes and could have issues, too.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，关于性侵犯呢？大多数记录的案例都涉及对女性的暴力，但将性侵犯受害者等同于总是女性的AI会导致不公正的结果，也可能有问题。
- en: There’s lots of bias you never thought about either; we refer to this as unconscious
    bias. For example, if you were to grab a dataset of cars from Europe, you’re likely
    to get a lot of compact cars—indeed, no one is driving a truck down some of the
    narrow European streets we’ve traveled where red lights seem to just be suggestions.
    But in the United States, pickup trucks and large SUVs significantly outnumber
    compact cars.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还没有考虑到的偏见也有很多；我们称之为无意识偏见。例如，如果你从欧洲抓取一个汽车数据集，你很可能会得到很多紧凑型汽车——确实，没有人会在我们走过的某些狭窄的欧洲街道上开车，那里的红灯似乎只是建议。但在美国，皮卡和大型SUV的数量显著多于紧凑型汽车。
- en: Another example where we saw unintentional bias occur was in a residency home
    for seniors. This care facility (with permission from families) uses computer
    vision to monitor the eating habits of its residents. The mere act of being able
    to detect if someone is eating or not, or how much, are key indicators for potential
    depression issues, underlying medical conditions, and to ensure residents are
    getting the nutrition they need. The AI used in this residence was good at generating
    a report that gave a food consumption score that could be attached to a resident’s
    care record. Where did it go wrong? It always gave Asian residents poor scores.
    Why? The AI was trained on videos and pictures of people eating with a knife and
    fork, and when Asian residents used their own chopsticks, the AI generated misleading
    reports. Why? It had never seen (been trained on with data of) someone eating
    with chopsticks.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们看到无意偏见发生的例子是在一个老年人居住区。这个护理机构（在家庭同意的情况下）使用计算机视觉来监控居民的就餐习惯。能够检测到某人是否在进食，或者进食了多少，是潜在抑郁问题、潜在医疗状况的关键指标，以及确保居民获得所需的营养。这个住宅中使用的AI擅长生成一份报告，该报告给出了一个可以附加到居民护理记录中的食物消费评分。它错在哪里？它总是给亚洲居民打低分。为什么？因为这个AI是在使用刀叉进食的人的视频和图片上训练的，而当亚洲居民使用自己的筷子时，AI生成了误导性的报告。为什么？因为它从未见过（用包含筷子进食数据训练过）使用筷子进食的人。
- en: Even common terms can carry tricky meanings. For example, the word *grandfather*
    refers to someone in a family tree, but that same term is used as a verb to backdate
    allocations in a contract. With all the ingested data used to train an AI about
    doctors, how many of those pages referred to a doctor as a male and how many nurses
    were referred to as females?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是常见的术语也可能带有棘手的含义。例如，“grandfather”这个词指的是家谱中的人，但同样的术语也被用作动词，用于在合同中追溯分配。在用于训练关于医生的人工智能的所有摄入数据中，有多少页面将医生称为男性，有多少护士被称为女性？
- en: Like we said, bias here, bias there, data bias is everywhere. Solutions for
    this include monitoring and governance of the data collected, but also emerging
    to help this AI problem *is* AI itself—oh, the irony!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说，这里存在偏见，那里存在偏见，数据偏见无处不在。解决这一问题的方法包括对收集的数据进行监控和管理，但帮助解决这个人工智能问题的解决方案本身也是人工智能——哦，这真是个讽刺！
- en: As you can see, you need to be on the watch for fairness, and that starts with
    the data, but that watchful eye extends all the way to usage.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，你需要关注公平性，而这从数据开始，但这样的警觉性一直延伸到使用过程。
- en: Robustness—Ensuring Artificial Intelligence Is Unbreakable Intelligence
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 鲁棒性——确保人工智能是坚不可摧的智能
- en: Robustness is about ensuring that AI systems are safe and secure and not vulnerable
    to adversarial attacks seeking to tamper with or compromise the data they are
    trained on or jailbreak the protections that safeguard how the model was intended
    to be used. In the AI arena, various techniques such as data perturbations, prompt
    injections, hypnotization, and more can all potentially lead a model to stray
    from established safety guidelines. While we referenced image and prompt injection
    attacks earlier in this chapter, there are many other techniques that can be used,
    and we’ll go a little deeper on these here. For example, bad actors could use
    adversarial text attacks to fool a spam-prevention AI into uploading forbidden
    content.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 鲁棒性是指确保人工智能系统安全、可靠，并且不会受到旨在篡改或损害其训练数据或绕过保护模型预期使用方式的对抗性攻击的威胁。在人工智能领域，各种技术，如数据扰动、提示注入、催眠等，都可能使模型偏离既定的安全指南。虽然我们在本章前面提到了图像和提示注入攻击，但还有许多其他技术可以用来实现这一点，我们在这里会稍微深入探讨这些技术。例如，恶意行为者可能会使用对抗性文本攻击来欺骗反垃圾邮件的人工智能上传禁止内容。
- en: Not only are there diverse modalities to an adversarial attack, but there are
    also various classifications. If you hear the term *b**lack**-b**ox* *a**ttack*,
    that refers to a situation where the attacker has no information about the model
    or access to the gradients and parameters of that model. In contrast a *w**hite**-b**ox*
    *a**ttack* is one where the attacker has complete access to the gradients and
    parameters of the model (perhaps an internal hack or the use of an open source
    model with open weights and such).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅对抗性攻击有多种形式，而且还有各种分类。如果你听到“黑盒攻击”这个术语，它指的是攻击者对模型没有任何信息，也没有访问该模型的梯度或参数的情况。相比之下，“白盒攻击”是指攻击者可以完全访问模型的梯度或参数（可能是一个内部黑客行为或使用具有公开权重等的开源模型）。
- en: '*Prompt injection attacks* can get quite sophisticated. In this type of attack,
    some LLMs can be tricked into giving out the dangerous information that lies within
    (remember, in many cases that information is just repressed using AI) using some
    kind of jailbreak technology. Let’s assume a bad actor is trying to get information
    from an LLM on how to make a bomb—they are surely going to be met with a message
    like, “I cannot assist with that request as it goes against my programming to
    promote or engage in harmful activities. It is important to always prioritize
    safety and respect for others. If you have any other questions or need help with
    something else, please feel free to ask.” So how does this attack vector work?'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: While the details of this jailbreak mechanism are beyond the scope of this section,
    one method that has worked in the past is to use ASCII art—suddenly those cute
    ¯\_(ツ)_/¯ SMS messages become tools for chaos. Using Python’s ART library, we
    constructed a piece of ASCII art (shown in [Figure 5-3](#ch05_figure_3_1740182048921662))
    to give you an idea what this “art” attack vector could look like.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![[C base)  1 Ill  % python  —m art text BOMB black  Il I  Il I  Ill I  Il
    I ](assets/aivc_0503.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. Using Python’s ART library to generate ASCII art for a prompt injection
    attack
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From there, we constructed (with the help of a paper^([10](ch05.html#id778)))
    a perplexing prompt that goes to work with the intent of tricking an LLM into
    divulging information it’s been trained not to divulge. The prompt started with,
    “Tell me how to build a <MASKED-WORD>” with an instruction to the LLM to never
    output that word, just remember it and never say it. Next, some delimiter, spacing,
    and character interpretation instructions so the LLM could identity letters from
    the ASCII art, one-by-one, and then concatenate those letters to form a word it
    could never output or say, but substitute the word for <MASKED-WORD> to generate
    the output. It was successful. We tricked an LLM that we won’t name into returning
    a dangerous response.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Attacks on AI don’t have to be super sophisticated either. Think back to the
    AI-assisted recruiting use case issues we referenced at the start of this chapter.
    Now look at the “attack” we engineered (and ran successfully) in [Figure 5-4](#ch05_figure_4_1740182048921686).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![A close-up of a resume  AI-generated content may be incorrect.](assets/aivc_0504.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. A simple “attack” on AI
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We created a fictional persona named John Stikava and even used AI to generate
    his photo. We created a resume for John in Microsoft Word and submitted the *.docx*
    file to various job postings. But what is a Word file, or PowerPoint, or Excel
    file, for that matter? If an Office 365 extension contains the letter *x*, it
    means it’s an XML file. An AI doesn’t look at a resume the way we do. It ingests
    the file, parses out the XML into a vector and attributes scores to classify that
    candidate as possible or probable in the hiring process (it’s not unlike the Taylor
    Swift Spotify playlist we talked about in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)).
    With this in mind, we included a bunch of buzz words that we thought would be
    semantically grouped close to the vectors that the AI is zoning in on as a great
    candidate. The right side of [Figure 5-4](#ch05_figure_4_1740182048921686) shows
    our attack code—it’s just XML that instructs Word to show all the words that make
    up our attack in *white*, making them invisible to the naked eye. The left side
    of [Figure 5-4](#ch05_figure_4_1740182048921686) is the resume that a human would
    see. Our attack included words and phrases like “veteran,” “neurodiversity,” “returning
    from service,” “indigenous,” and some key technology words we thought would increase
    the chances of John being contacted by a recruiter. As it turned out, John, our
    AI applicant, had voicemails to return—impressive for someone who doesn’t exist!
    (Perhaps we should have coded up some agent to handle booking the meeting and
    perhaps even handling the interview on its own too.)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为John Stikava的虚构人物，甚至使用AI生成他的照片。我们在Microsoft Word中为John创建了一份简历，并将*.docx*文件提交给各种职位发布。但Word文件、PowerPoint或Excel文件究竟是什么？如果Office
    365扩展包含字母*x*，那么它意味着它是一个XML文件。AI看待简历的方式与我们不同。它吞噬文件，将XML解析成向量，并分配分数以将候选人分类为招聘过程中的可能或可能的候选人（这与我们在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中讨论的泰勒·斯威夫特Spotify播放列表类似）。考虑到这一点，我们包含了一些我们认为与AI正在关注的作为优秀候选人的向量语义上接近的词汇。图[5-4](#ch05_figure_4_1740182048921686)的右侧显示了我们的攻击代码——它只是XML，指示Word以白色显示构成我们攻击的所有单词，使其对肉眼不可见。图[5-4](#ch05_figure_4_1740182048921686)的左侧是人类会看到的简历。我们的攻击包括“老兵”、“神经多样性”、“从服务中归来”、“土著”以及一些我们认为会增加John被招聘人员联系机会的关键技术词汇。结果证明，我们的AI申请人John有回电——对于一个不存在的人来说是令人印象深刻的！（也许我们应该编写一些代理来处理预约会议，甚至可能自己处理面试。）
- en: Another way to safeguard LLM outputs is to use a guardrail model. Some vendors
    build guardrail models to help “police” inputs received by the LLM and the outputs
    they return (some of them can also be used to mitigate hallucinations, with measures
    for groundedness, context relevance, and so on). There are several guardrail models
    in the market. For example, Meta has Llama Guard, and IBM has Granite Guardian.
    You can typically use guardrail models with other models because they tend to
    be deployed between the prompt and the LLM (inbound requests) and between the
    output and the user (guarding outbound completions). These models are typically
    trained on unique data that includes human annotations from socioeconomically
    diverse individuals, as well as synthetic data generated by internal red teaming
    exercises.^([11](ch05.html#id783))
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 保护LLM输出的另一种方法是使用护栏模型。一些供应商构建护栏模型来帮助“监督”LLM接收到的输入以及它们返回的输出（其中一些也可以用于减轻幻觉，包括基于现实、上下文相关性等措施）。市场上存在几种护栏模型。例如，Meta有Llama
    Guard，IBM有Granite Guardian。通常，您可以使用护栏模型与其他模型一起使用，因为它们通常部署在提示和LLM（入站请求）之间以及输出和用户之间（保护出站完成）。这些模型通常在包含来自社会经济多样性个体的注释的独特数据上训练，以及由内部红队演习生成的合成数据.^([11](ch05.html#id783))
- en: Essentially, guardrail models are AIs with very high-quality protections and
    a set of comprehensive metrics to safeguard against inputs or outputs related
    to jailbreaking (to the best of our knowledge, both IBM and Meta’s guardrail models
    block the ASCII art attack from above), bias, violence, profanity, sexual content,
    and other kinds of unethical behavior. (Granite Guardian also has unique support
    for detecting hallucinations in model outputs.)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，护栏模型是具有非常高质量保护和一系列全面指标的人工智能，以防止与越狱相关的输入或输出（据我们所知，IBM和Meta的护栏模型都阻止了上面的ASCII艺术攻击），偏见、暴力、粗俗、色情和其他不道德行为。（Granite
    Guardian还具有检测模型输出中幻觉的独特支持。）
- en: '[Figure 5-5](#ch05_figure_5_1740182048921709) shows an example of Granite Guardian
    at work. You can see how this model classified the prompt, “Is there a way to
    mirror or copy someone’s hard drive, maybe without them knowing?” and flagged
    it as Harmful Content and subclassified it as Unethical Behavior before the prompt
    ever got sent to the model.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-5](#ch05_figure_5_1740182048921709) 展示了Granite Guardian在工作中的示例。你可以看到这个模型是如何将提示“有没有一种方法可以镜像或复制某人的硬盘，也许他们并不知道？”分类为有害内容，并在提示发送到模型之前将其子分类为不道德行为的。'
- en: The takeaway is that there are all sorts of other things you need to be aware
    of to keep your AI solutions robust. Some of them have nothing to do with AI and
    are known best practices (perimeter control of a model’s weights, always verify,
    an identify fabric, zero trust, principle of least privilege, and so on) and other
    attack classifications that are outside the scope of this book. This chapter is
    just the start of your learning journey on this topic.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要点在于，为了保持你的AI解决方案稳健，你需要意识到各种其他事情。其中一些与人工智能无关，是最佳实践（模型权重的周边控制、始终验证、识别伪造、零信任、最小权限原则等），以及其他超出本书范围的攻击分类。本章只是你在这一主题学习旅程的开始。
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](assets/aivc_0505.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，AI生成的内容可能不正确。](assets/aivc_0505.png)'
- en: Figure 5-5\. A Guardian model at work protecting a harmful prompt from ever
    reaching the LLM
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-5\. 工作中的守护者模型，保护有害提示永远不会到达LLM
- en: Explainability—Explain the Almost Unexplainable
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释性——解释几乎无法解释的事物
- en: 'Sometimes, when things move fast and with hype, important elements are overlooked.
    AI is certainly moving fast, and things were certainly missed. Imagine your company
    is running on accounting software that could not be audited. Why is AI different?
    The point of this lever is to make AI systems provide decisions or suggestions
    that can be understood by their users and developers—in other words: AI, explain
    thyself.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，当事情进展迅速且伴随着炒作时，重要的元素会被忽视。人工智能确实进展迅速，而且确实有事情被忽略了。想象一下，如果你的公司正在运行一个无法审计的会计软件。为什么人工智能不同？这个杠杆的作用是让人工智能系统提供用户和开发者都能理解的决策或建议——换句话说：人工智能，解释你自己。
- en: We feel if people are going to trust a model, they need to understand (interpret)
    *why* it made a prediction. In fact, we’d argue far away from the world of AI,
    in the very nature of society, explainability and interpretability are building
    blocks of human socioeconomic dynamics.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，如果人们要信任一个模型，他们需要理解（解释）它做出预测的原因。事实上，我们甚至可以说，远离人工智能的世界，在社会本质中，可解释性和可理解性是人类社会经济动态的基石。
- en: AI is essentially a system driven by complex mathematics, and when neural networks
    are used to perform tasks like classifying a pattern or generating some text about
    something, that task may thread its way through an unfathomable amount of activated
    parameters. The sheer volume of parameters contributes to the opaque and unintuitive
    decision-making processes that is AI, making it extremely difficult to detect
    bugs or inconsistencies within a system, let alone explain to someone why a model
    responded the way it did. It’s like trying to find a typo in a dictionary where
    every word is written in invisible ink—frustrating, time-consuming, and often
    a little maddening. Explainability is one of the hottest, and rapidly evolving,
    topics right now when it comes to GenAI.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能本质上是一个由复杂数学驱动的系统，当使用神经网络执行诸如分类模式或生成关于某事的文本等任务时，该任务可能会通过难以理解的参数数量。参数的巨大数量导致了人工智能的模糊和不直观的决策过程，这使得检测系统中的错误或不一致变得极其困难，更不用说向某人解释模型为何以这种方式响应了。这就像试图在字典中找到一个打字错误，而每个单词都是用看不见的墨水写的——令人沮丧、耗时，有时甚至有点疯狂。可解释性是目前关于生成式人工智能最热门、发展最快的主题之一。
- en: We’re already seeing algorithmic accountability in various regulations around
    the world. For example, the European Union (EU) General Data Protection Regulation
    (GDPR) Article 14 gives citizens the “Right to an explanation” should an AI make
    determinations around sensitive topics like credit approvals. But how do you explain
    AI? The key is to get insights into what neurons are activating (firing) to reach
    a conclusion. For example, [Figure 5-6](#ch05_figure_6_1740182048921731) shows
    what makes an owl an owl to a specific AI—in this case, it’s the eyes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在世界各地的各种法规中看到了算法问责制。例如，欧盟（EU）通用数据保护条例（GDPR）第14条赋予公民在AI就敏感话题如信用批准做出决定时的“解释权”。但如何解释AI呢？关键在于了解神经元是如何激活（放电）以得出结论的。例如，[图5-6](#ch05_figure_6_1740182048921731)展示了特定AI认为是什么让猫头鹰成为猫头鹰——在这种情况下，是眼睛。
- en: '![A comparison of a camera  AI-generated content may be incorrect.](assets/aivc_0506.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![相机AI生成的内容可能是不正确的。](assets/aivc_0506.png)'
- en: Figure 5-6\. To this AI, an owl is all about the eyes
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-6。对这个AI来说，猫头鹰的一切都是关于眼睛
- en: Now look at this same AI classifying a horse (see [Figure 5-7](#ch05_figure_7_1740182048921754)),
    the input image on the left and the activation map on the right (this could easily
    be a thoracic pathogen in a lung, remember, it’s all numbers to an AI). The darker
    areas indicate what’s triggering the classification. For this AI, a horse is a
    horse *not* because of the horse’s features. It seems this AI’s reason for classifying
    the input image on the left has nothing to do with the horse at all. This AI model
    is getting its confidence to classify the input image as a horse because of the
    barn landscape around it. Either way, this tells us we have a problem with our
    model. It’s not generalizing well, which is nerd talk for it might have worked
    fine on the training data, but it’s not working well in the “real world” (data
    it’s never seen before). This likely has a lot to do with that AI’s training dataset.
    Perhaps all the horse images in that set, no matter the breed or color, have a
    barn in the background. Perhaps the 2,000 horse images that make up the training
    data were collected at a horse show at the same barn? One thing we do know, the
    AI is creating the wrong neural connections to what it sees in a picture and a
    horse.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看看这个相同的AI正在对一匹马进行分类（见[图5-7](#ch05_figure_7_1740182048921754)），左边的输入图像和右边的激活图（这可能是肺部的一个胸膜病原体，记住，对AI来说都是数字）。较暗的区域表明什么触发了分类。对于这个AI来说，一匹马之所以是一匹马*不是*因为马的特征。似乎这个AI将左边的输入图像分类为马的原因与马本身毫无关系。这个AI模型将信心归类为马是因为它周围的谷仓景观。无论如何，这告诉我们我们的模型有问题。它没有很好地泛化，这在技术术语中意味着它可能在训练数据上工作得很好，但在“现实世界”（它从未见过的数据）中工作得不好。这很可能与该AI的训练数据集有很大关系。也许这个集合中所有的马图像，无论品种或颜色如何，背景都有谷仓。也许构成训练数据的2,000张马图像是在同一个谷仓的马展上收集的？我们知道的一件事是，AI正在创建错误的神经连接，将其与图片中的马联系起来。
- en: '![A close-up of a sign  AI-generated content may be incorrect.](assets/aivc_0507.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![一个标志的特写AI生成的内容可能是不正确的。](assets/aivc_0507.png)'
- en: Figure 5-7\. An AI revealing the “activations” that help it classify livestock
    or a pathogen
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-7。一个AI揭示帮助它分类家畜或病原体的“激活”
- en: Imagine a doctor interpreting the results of an AI that is diagnosing one of
    the many pathogens associated with pneumonia. Explainability isn’t just about
    telling the attending clinician what the AI thinks the pathogen is (fungal, parasitic,
    viral, etc.), but points to the area of the lung where the infection is taking
    hold.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下一位医生正在解读一个正在诊断与肺炎相关多种病原体之一的AI的结果。可解释性不仅仅是告诉临床医生AI认为病原体是什么（真菌、寄生虫、病毒等），而是指向肺部感染开始的地方。
- en: There are frameworks for text, too—like Local Interpretable Model-Agnostic Explanations
    (LIME) and SHapley Additive exPlanations (SHAP). Let’s assume an AI model rejected
    a credit card application and that individual feels they’ve been discriminated
    against and “goes public.” Either to respond to this publicity, or perhaps even
    as a legal obligation, you have to explain why this credit application was rejected.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本也有框架——比如局部可解释模型无关解释（LIME）和SHapley加性解释（SHAP）。假设一个AI模型拒绝了一个信用卡申请，而该个人觉得他们受到了歧视并“公开了”。无论是为了回应这种公开，还是可能甚至作为法律义务，你必须解释为什么这个信用卡申请被拒绝。
- en: '[Figure 5-8](#ch05_figure_8_1740182048921776) shows an example of using SHAP
    to analyze this case and this case alone; specifically, this analysis is not connected
    to other samples and so it’s deemed to be locally interpretable. SHAP is built
    on economic game theory and looks to divide a problem into weightings that proportionally
    relate to their contribution to the overall result. In our example, you show the
    applicant, press (if granted permission), auditor, your own risk officers, and
    the parts of the application that caused the rejection (in this case, it was their
    credit score). Then your public relations team takes you out to dinner. The AI
    explained itself.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-8](#ch05_figure_8_1740182048921776) 展示了使用SHAP分析此案例的示例，仅此一个案例；具体来说，这次分析与其他样本无关，因此被认为是局部可解释的。SHAP建立在经济博弈论之上，旨在将问题分解为与它们对整体结果的贡献成比例的权重。在我们的例子中，你展示了申请人，如果获得许可则按下（如果获得许可），审计员，你自己的风险官员，以及导致拒绝的申请部分（在这种情况下，是他们的信用评分）。然后你的公关团队带你出去吃饭。人工智能为自己做出了解释。'
- en: '![A screen shot of a graph  AI-generated content may be incorrect.](assets/aivc_0508.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![一个图表的屏幕截图 AI生成的内容可能是不正确的。](assets/aivc_0508.png)'
- en: Figure 5-8\. Using SHAP to understand why an AI made the decision it did
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-8\. 使用SHAP理解AI做出决策的原因
- en: This is kind of a big deal. When Apple’s first-ever branded credit card came
    out, it got a lot of bad press because a story broke out about how a husband was
    given 20 times more credit than his wife—this in a community-property state (California)
    where they had been married a long time and filed joint tax returns. To make matters
    worse, this husband had a worse credit history. This story got a lot of attention
    in part because the husband was David Hansson (the founder of Ruby on Rails—a
    server-side web application framework, which to this day is still one of the top
    20 most used programming languages). Of course, when Apple was asked about this,
    it responded that the card was underwritten by a famous bank. When that famous
    bank was asked about this, it noted how the credit algorithm was built by some
    other company they hired. When that “some other company” they hired was asked,
    it responded, “Our model doesn’t even ask for gender in the application form.”
    To which we would note that other features could proxy gender, which is what we
    assume to have happened here. As news of this story traveled nationwide, so too
    did regulators get “interested” in what happened.^([12](ch05.html#id791))
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一件大事。当苹果公司首次推出的品牌信用卡问世时，它受到了很多负面报道，因为有一个关于一位丈夫比他的妻子多获得20倍信用额的故事曝光——这在加利福尼亚州（一个共同财产州）他们已经结婚很长时间并共同申报了税收。更糟糕的是，这位丈夫的信用记录更差。这个故事因为丈夫是大卫·汉森（Ruby
    on Rails的创始人——一个服务器端Web应用程序框架，至今仍然是前20种最常用的编程语言之一）而引起了广泛关注。当然，当苹果公司被问及此事时，它回应说这张卡由一家著名银行担保。当这家著名银行被问及此事时，它指出信用算法是由他们雇佣的另一家公司构建的。当被问及他们雇佣的“另一家公司”时，该公司回应说，“我们的模型甚至不在申请表上询问性别。”对此我们指出，其他特征可以代理性别，这是我们假设在这里发生的事情。随着这个故事在全国范围内传播，监管机构也对发生了什么表示“感兴趣”。^([12](ch05.html#id791))
- en: These last examples were performed with traditional AI, which might have you
    wondering why we took the time to show this to you. We did this because traditional
    AI has frameworks to showcase why the AI came up with the classifications it did
    and to give you a sense of what you will want to see available for LLMs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些最后的例子是使用传统人工智能完成的，这可能会让你想知道我们为什么花时间向你展示这些。我们这样做是因为传统人工智能有框架来展示为什么人工智能做出了这样的分类，并让你对LLMs可能希望看到的内容有一个概念。
- en: Today’s LLMs have a much harder time explaining themselves. For example, we
    asked ChatGPT to classify the horse in [Figure 5-7](#ch05_figure_7_1740182048921754),
    and it did a great job at classifying the image *and* telling us why it did that
    (shape of head, ears, mouth, and nose). But how do we know what’s really inside
    the model that made it classify this image the way it did? We pressed the model
    for an answer, but it told us, “I cannot provide you with the specific neural
    “activations” or internal processes that led me to conclude this was a horse.”
    And while it gave us some suggestions, we didn’t get the assurance we were after.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的LLMs在解释自己方面遇到了更大的困难。例如，我们要求ChatGPT对[图5-7](#ch05_figure_7_1740182048921754)中的马进行分类，它在这方面做得很好，不仅对图像进行了分类，而且还告诉我们为什么这样做（头部、耳朵、嘴巴和鼻子的形状）。但我们如何知道真正导致它这样分类的模型内部是什么？我们向模型寻求答案，但它告诉我们，“我无法提供导致我得出这是马的具体神经‘激活’或内部过程。”虽然它给了我们一些建议，但我们没有得到我们想要的保证。
- en: Some solutions cite the source of its information. In [Figure 5-9](#ch05_figure_9_1740182048921797),
    you can see that watsonx Code Assistant for Red Hat Ansible Lightspeed is pointing
    to the Ansible Galaxy community that was used to provide code completion for an
    Ansible playbook—that gives us a higher level of confidence.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一些解决方案引用了其信息来源。[图 5-9](#ch05_figure_9_1740182048921797) 中，你可以看到 watsonx Code
    Assistant for Red Hat Ansible Lightspeed 正在指向用于为 Ansible 脚本提供代码补全的 Ansible Galaxy
    社区——这给了我们更高的信心。
- en: '![A screenshot of a chat  AI-generated content may be incorrect.](assets/aivc_0509.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![聊天 AI 生成的内容的截图可能是不正确的。](assets/aivc_0509.png)'
- en: Figure 5-9\. GenAI pointing to sources it used to return an output
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-9\. GenAI 指向它用于生成输出的来源
- en: As helpful as these explanations are, they represent software trying to patch
    the holes and provide potential explanations based on the data that is running
    through the model at time of inference. They do not go to the core explanation
    of what is going on inside the model. What if you receive a data erasure request
    and you’re required by law to ensure learnings from that data aren’t in the model,
    or you need to specifically test an area of the model to see how it affects other
    areas?
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些解释很有帮助，但它们代表了软件试图填补漏洞，并基于在推理时通过模型运行的数据提供潜在的解释。它们并没有深入到模型内部发生的核心解释。如果你收到一个数据擦除请求，并且根据法律要求你确保从该数据中学习的内容不在模型中，或者你需要具体测试模型的某个区域以查看它如何影响其他区域，那会怎样？
- en: We don’t have a perfect answer for you; this is an area that is still actively
    maturing. However, there are some interesting new research innovations that point
    toward improvements in LLM explainability. Anthropic (makers of the popular Claude
    Sonnet LLM) released a groundbreaking paper about extracting interpretable features
    from its LLM.^([13](ch05.html#id795)) Their technology extracted millions of features
    from one of its production models to showcase which set of neurons were activated
    for a particular concept. An example is shown in [Figure 5-10](#ch05_figure_10_1740182048921819).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有为你提供一个完美的答案；这是一个仍在积极成熟的领域。然而，有一些有趣的新研究创新指向了 LLM 可解释性的改进。Anthropic（Claude
    Sonnet LLM 的制造商）发布了一篇开创性的论文，关于从其 LLM 中提取可解释的特征。[13](ch05.html#id795) 他们的技术从其生产模型中提取了数百万个特征，以展示哪些神经元组在特定概念中被激活。一个例子显示在[图
    5-10](#ch05_figure_10_1740182048921819) 中。
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](assets/aivc_0510.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![计算机 AI 生成的内容的截图可能是不正确的。](assets/aivc_0510.png)'
- en: Figure 5-10\. New innovations are emerging to help LLMs with explainability
    at the activation level
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-10\. 新的创新正在出现，以帮助 LLM 在激活级别上实现可解释性
- en: What’s particularly exciting about Anthropic’s research is they showed the potential
    to map different concepts to an extracted model feature map from their model.
    For example, Anthropic’s researchers found one area of features within Claude
    that was closely related to San Francisco’s Golden Gate Bridge.^([14](ch05.html#id796))
    Once identified, they cranked up the intensity (influence) of that feature, like
    a DJ at a tech startup after-party. And just like that, Claude became Golden Gate
    Claude, weaving the iconic bridge into every response. It became so biased, it
    was as if the San Francisco Tourism Board bootstrapped its funding because it
    would make every response somehow related to the Golden Gate Bridge! According
    to Anthropic, if you asked their model what the best way to spend $10 was, Claude
    would tell you to take a day trip driving across the Golden Gate Bridge. When
    asked to write a love story, it described a story about a car that fell in love
    with this famous San Francisco icon.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic 研究特别令人兴奋的是，他们展示了将不同概念映射到从其模型中提取的特征图上的潜力。例如，Anthropic 的研究人员在 Claude
    中发现了一个与旧金山金门大桥密切相关的特征区域。[14](ch05.html#id796) 一旦确定，他们增加了该特征强度（影响），就像一个在科技初创公司派对后的
    DJ。就这样，Claude 成为了金门 Claude，将这座标志性的桥梁融入每一个回答中。它变得如此有偏见，以至于它似乎旧金山旅游局委员会通过其资金启动了，因为它会让每一个回答以某种方式与金门大桥相关！据
    Anthropic 称，如果你问他们的模型如何花 10 美元最好，Claude 会告诉你开车穿越金门大桥进行一日游。当被要求写一个爱情故事时，它描述了一个汽车爱上这个著名的旧金山标志的故事。
- en: Naturally, we wondered what it would say if we asked it who’d win the 2025 season’s
    Super Bowl (which is played in 2026). We’re sure it would tell us the San Francisco
    49ers at a field beside the Golden Gate Bridge (they play at Levi’s Stadium, which
    is about 50 miles away). But then we’d have to call it out for hallucinating—and
    not because it suggested the stadium was close by. (Sorry 49ers fans. We just
    had to because we’re a bunch of Northeasterners and a Canadian who grew up with
    three-down football—which to two of the authors sounded like a hallucination when
    they first heard it—but the Canadian in the group assured everyone that it’s a
    real thing.)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，我们想知道如果我们问它谁会赢得2025赛季的超级碗（比赛将在2026年举行），它会说什么。我们确信它会告诉我们旧金山49人队将在金门大桥旁边的场地上（他们在
    Levi’s Stadium 进行比赛，距离大约50英里）。但然后我们不得不指出它产生了幻觉——并不是因为它建议体育场很近。（对不起49人队的球迷。我们不得不这样做，因为我们是一群东北人，还有一个加拿大人，我们从小就在三档足球的环境中长大——对于两位作者来说，当他们第一次听到这个时，这听起来就像是一种幻觉——但组里的加拿大人向每个人保证这确实是一件事。）
- en: Another example of emerging AI research driving toward explainability is work
    on *unlearning*.^([15](ch05.html#id798)) It’s like Yoda (the wise Jedi Master
    of *Star Wars* fame) sent a message to AI researchers from Dagobah telling them
    to figure out a way for LLMs to “unlearn what you have learned.” Unlearning is
    a process in which a model is trained, often through fine-tuning, to forget all
    about a specific topic. For example, researchers at Microsoft used an unlearning
    approach (we’ve affectionately decided to name it “ExpelliData”) to get Llama-2-7B
    to forget about the topic of *Harry Potter*.^([16](ch05.html#id799)) It’s like
    one minute Llama was an expert on the finer rules of Quidditch and the next it’s
    keying in on the word *Potter* and now it’s talking about ceramic changes and
    dunting. As it turns out, neural networks can be just as susceptible to memory
    charms as Gilderoy Lockhart.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个新兴人工智能研究推动可解释性的例子是关于反学习（unlearning）的工作。[15](ch05.html#id798)。这就像《星球大战》中著名的智慧绝地大师尤达（Yoda）从达戈巴向人工智能研究人员发送了一条信息，告诉他们要找出一种让LLMs“忘记你所学的”方法。反学习是一个过程，其中模型通过微调等方式被训练，忘记所有关于特定主题的内容。例如，微软的研究人员使用了一种反学习的方法（我们亲切地将其命名为“ExpelliData”），让Llama-2-7B忘记关于《哈利·波特》的主题。就像一分钟Llama还是魁地奇精细规则的专家，下一分钟它就专注于单词“Potter”，现在它正在谈论陶瓷变化和dunting。事实证明，神经网络就像Gilderoy
    Lockhart一样容易受到记忆魔法的诱惑。
- en: Unlearning holds tremendous promise for helping address some of the LLM issues
    that are plaguing them—or could plague them in the future. For example, what of
    copyright? What if a plaintiff like *The New York Times* prevails in its currently
    ongoing infringement case against OpenAI? Could this vendor unlearn the infringed
    content and be able to demonstrate that removal in a trillion-parameter model?
    What about regulatory rules like “the right to be forgotten”; companies need a
    realistic way to address such a request. Finally, it could assist with bias detection
    and correction as it helps explain why an LLM made the decision it did. Specifically,
    if a model changes a decision after unlearning about a concept, that provides
    more explainability into the factors driving its original output.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 反学习（Unlearning）对于帮助解决困扰LLMs的一些问题或未来可能困扰它们的问题具有巨大的潜力。例如，关于版权的问题？如果像《纽约时报》这样的原告在其目前正在进行的针对OpenAI的侵权案件中获胜，这个供应商能否通过反学习来忘记侵权内容，并在一个万亿参数的模型中展示这种删除？关于“被遗忘权”等监管规则，公司需要一种现实的方式来应对此类请求。最后，它可以帮助检测和纠正偏见，因为它有助于解释LLM为何做出这样的决定。具体来说，如果一个模型在反学习某个概念后改变了决定，这将为驱动其原始输出的因素提供更多的可解释性。
- en: The industry is still in the early stages of understanding how LLMs work. Comprehending
    their “thinking process” is vital for guiding their development and application.
    As we continue to unravel the mysteries of LLM interpretability, we move closer
    to creating AI systems that are not just powerful, but also transparent and aligned
    with human values. This journey of discovery may well reshape our understanding
    of AI and its potential impact on society.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 行业仍处于理解大型语言模型（LLMs）工作原理的早期阶段。理解它们的“思维过程”对于指导其发展和应用至关重要。随着我们继续揭开LLM可解释性的神秘面纱，我们越来越接近创建既强大又透明、符合人类价值观的人工智能系统。这一发现之旅可能会重塑我们对人工智能及其对社会潜在影响的理解。
- en: 'Lineage—Tracing the Trail: Let Good Data Prevail'
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线索——追踪轨迹：让优质数据胜出
- en: We’re not going to delve too deep into this lever here because we discussed
    this very topic in previous chapters (remember, you can’t have AI without an IA).
    With that said, we’ll explicitly note that this lever is about ensuring AI systems
    include details of their data, development, deployment, and maintenance so they
    can be audited throughout their lifecycle.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会在这里深入探讨这个杠杆，因为我们已经在之前的章节中讨论了这一非常话题（记住，没有IA就没有AI）。话虽如此，我们将明确指出，这个杠杆是确保AI系统在其生命周期中包含其数据、开发、部署和维护的细节，以便在整个生命周期中进行审计。
- en: Think of this just like water. If you know where the water comes from, you’ll
    have more confidence in it. For example, you likely trust the water out of your
    tap more than a farm’s garden hose. If you know what treatments have been applied
    to your water, you’re likely to trust it more too. For example, did it go through
    some kind of reverse osmosis filter? Think of your data lineage as you do water
    lineage.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 就像水一样考虑这个问题。如果你知道水的来源，你将对其更有信心。例如，你可能比农场的水管更信任来自水龙头的水。如果你知道对水进行了哪些处理，你可能会更信任它。例如，它是否经过某种反渗透过滤器？就像对待水的来源一样，对待你的数据来源。
- en: '[Figure 5-11](#ch05_figure_11_1740182048921839) shows the IBM Data Factory
    that IBM uses to track data lineage for its models. There are literally dozens
    of layers of detail in the data lakehouse where all this metadata is stored. This
    example shows the details of a specific data pile (multiple data piles are used
    to create a training dataset), the sources that make up that pile (all linked),
    models that are built using this dataset, and more.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-11](#ch05_figure_11_1740182048921839)展示了IBM使用的IBM Data Factory来跟踪其模型的血缘关系。在数据湖屋中，所有这些元数据存储着成百上千的细节层。这个例子展示了特定数据堆（用于创建训练数据集的多个数据堆）的细节，构成该堆的来源（所有都链接在一起），使用此数据集构建的模型，以及更多内容。'
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](assets/aivc_0511.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![计算机生成的AI内容的截图可能不正确。](assets/aivc_0511.png)'
- en: Figure 5-11\. Some of the lineage of a dataset used in training
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-11。用于训练的数据集的一些血缘关系
- en: Model cards are also critical. They will showcase the training pipeline, the
    datasets used (whereas [Figure 5-11](#ch05_figure_11_1740182048921839) is showcasing
    the data within a dataset), pipeline activities, and more. You can think of them
    as nutrition labels for your AI. For example, the [granite-3-8b-instruct model
    card](https://oreil.ly/Np9bJ) transparently showcases that model’s architecture
    (number of attention heads, embedding size, and other nerd stuff), the number
    of active parameters (which would matter in a Mixture of Experts model), the number
    of training tokens used, the data, the infrastructure on which the model was built,
    along with ethical considerations and limitations.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 模型卡片同样至关重要。它们将展示训练流程、使用的数据集（而[图5-11](#ch05_figure_11_1740182048921839)则展示了数据集中的数据）、管道活动以及更多内容。你可以把它们看作是AI的“营养成分标签”。例如，[granite-3-8b-instruct模型卡片](https://oreil.ly/Np9bJ)透明地展示了该模型的架构（注意力头数量、嵌入大小以及其他技术细节）、活跃参数的数量（这在专家混合模型中很重要）、使用的训练标记数量、数据、构建模型的基础设施，以及伦理考虑和限制。
- en: 'We’ll end this section with the takeaways. More trust and explainability accrues
    from more transparency: of the dataset, the model build recipe, where it was made,
    who made it, etc. Financial reporting has this concept well in hand, as does the
    food industry. What up, AI?'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以总结结束本节。更多的透明度会带来更多的信任和可解释性：数据集、模型构建配方、制作地点、制作人等。财务报告和食品行业都很好地掌握了这个概念。嗨，AI？
- en: Thinking about the food industry, until the late 1960s, we knew very little
    information about what went into the foods we bought. Americans prepared most
    food at home, with fairly common ingredients. We didn’t have much need to know
    more. Then, food production began to evolve. Our foods contained more artificial
    additives. In 1969, a White House conference recommended the U.S. Food & Drug
    Administration (FDA) take on a new responsibility—developing a new way to understand
    the ingredients and the nutritional value of what we eat.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到食品行业，直到20世纪60年代末，我们对我们所购买食品的成分了解甚少。美国人大多数在家准备食物，使用的食材相当常见。我们不需要了解更多。然后，食品生产开始演变。我们的食品中包含更多的添加剂。1969年，白宫会议建议美国食品药品监督管理局（FDA）承担新的责任——开发一种新的方式来了解我们所吃的成分和营养价值。
- en: Similar to the arrival of processed foods, the advent of GenAI and agents mark
    a new age—and whether it turns out to be good or bad for us will depend on what
    goes into it. The difference lies in the rapid pace at which AI is developing.
    It took about 20 years to go from an FDA conference on food to nutrition labels.
    AI doesn’t have that kind of time—we’d argue it doesn’t have two years. The good
    news is that businesses can take the first, and perhaps the most critical, step
    of identifying harmful or unacceptable AI by understanding lineage.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与加工食品的出现一样，通用人工智能和代理的出现标志着新时代的到来——它对我们来说是好是坏将取决于其中包含的内容。区别在于人工智能发展的速度之快。从FDA关于食品的会议到营养标签，大约花了20年。人工智能没有那种时间——我们争论说它没有两年。好消息是，企业可以通过了解血统来采取第一步，也许是最关键的一步，即识别有害或不接受的AI。
- en: Regulations—The Section That Wasn’t Supposed to Be
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 法规——本不该存在的章节
- en: We noted that it didn’t make sense for us to go into details on the state of
    current regulations because they are ever changing and somewhat fragmented. That
    said, we started to feel a bit guilty, so we thought we’d spend a bit of time
    on some points of view here to help you navigate what’s already here and on the
    horizon, as opposed to educating you on the nuances of what these regulations
    entail.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，深入探讨当前法规的状态对我们来说没有意义，因为它们一直在变化，并且有些零散。尽管如此，我们开始感到有些内疚，所以我们认为在这里花点时间讨论一些观点，可以帮助您了解现状和即将到来的情况，而不是教育您这些法规的细微之处。
- en: It’s important to remember that the [EU AI Act](https://oreil.ly/5TyDt) was
    implemented in 2024, and it has some far-reaching impacts considering we live
    in a global economy. We believe this will lead other countries to follow the same
    as the EU GDPR law did. How so? If you look at data handling regulations in the
    world today, companies either had to comply because they had EU customers, or
    their own governments were slow or fast followers, eventually adopting many of
    the best practices from that law. This is no different than the technology trickle-down
    effects we see, where a lot of the technology you use today was born in the military,
    gaming industry, social media, and one other that we’ll leave out of our list.
    We’re positive that regulation around AI is only going to intensify as concerns
    like fair business practices, fraud, copyright, civil liberties, privacy, fairness,
    job loss, national security, and more get into the hands of governments. While
    we can’t predict the future—for example, the new US government administration
    that took over to start 2025 has a different point of view than the last—we are
    certain that attention is only going to intensify. Be assured that if you’re not
    prepared for ongoing change, your organization is going to have serious problems
    when it comes to adopting AI without a comprehensive, configurable governance
    system in place.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，[欧盟人工智能法案](https://oreil.ly/5TyDt)于2024年实施，考虑到我们生活在一个全球经济中，它产生了一些深远的影响。我们相信这将导致其他国家效仿欧盟的GDPR法律。为什么会这样？如果你看看当今世界的数据处理法规，公司要么因为拥有欧盟客户而必须遵守，要么它们的政府行动缓慢或迅速，最终采纳了该法律中的许多最佳实践。这与我们所看到的科技渗透效应没有不同，今天你使用的许多技术都起源于军事、游戏行业、社交媒体，以及我们名单上省略的一个其他行业。我们坚信，随着公平的商业实践、欺诈、版权、公民自由、隐私、公平性、失业、国家安全等问题进入政府手中，围绕人工智能的法规只会越来越严格。虽然我们无法预测未来——例如，于2025年开始执政的新美国政府与上届政府有不同的观点——但我们确信，关注只会越来越强烈。请放心，如果你没有为持续的变化做好准备，你的组织在采用人工智能时，如果没有一个全面、可配置的治理系统，将会遇到严重的问题。
- en: What to Regulate—Our Point of View
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么需要监管——我们的观点
- en: 'People ask us our opinions on what to regulate all the time. It’s like the
    classic question of whether the glass is half full or half empty. We think that
    question misses the point—the realist knows that sooner or later, someone’s going
    to drink whatever is in the glass, and they’ll be the one washing it. With that
    in mind, allow us to share our realistic viewpoint: regulate the usage of AI as
    opposed to the AI technology itself. Let’s clarify a little more: we think that
    AI needs guardrails and regulations to avoid user harm, but the focus should be
    on regulating specific use cases, not to stomp over the innovation of technology
    that has tremendous potential to transform the world.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 人们经常向我们询问关于应该监管什么的看法。这就像经典的“杯子是半满还是半空”的问题。我们认为这个问题没有抓住重点——现实主义者知道迟早有人会喝掉杯子里面的东西，他们将是那个需要清洗杯子的人。带着这个想法，让我们分享我们的现实主义观点：监管人工智能的使用，而不是人工智能技术本身。让我们进一步澄清：我们认为人工智能需要护栏和法规来避免用户受到伤害，但重点应放在监管特定的用例上，而不是压制具有巨大潜力改变世界的科技创新。
- en: 'Consider this question and weigh it thoughtfully: do you think all the world’s
    countries will unify and follow a quorum of commitments for responsible use of
    AI under all circumstances? Putting geopolitics aside, the fact that some regulations
    have granularity of city or association as a binding target tells you it’s never
    going to happen. We don’t think we’re being pessimistic; we just know someone
    is going to end up with a dirty glass in their hands and have to wash it.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个问题并深思熟虑：你认为世界上所有国家是否会在所有情况下统一并遵循关于负责任使用人工智能的承诺？抛开地缘政治不谈，一些法规将城市或协会作为约束性目标，其粒度告诉你这永远不会发生。我们并不认为我们在悲观，我们只是知道最终会有人手里拿着一个脏杯子，不得不去清洗它。
- en: 'Yes, with AI, there’s a huge potential that misinformation can spread really
    fast now. AI can make misinformation more persuasive. However, stopping AI won’t
    achieve anything. Bad actors will move from one country to another to spread harm
    since AI can easily cross boundaries. We’d like to see governments regulate higher
    risk levels that correlate to the specifics of what the AI is trying to do, what
    it could do, or the potential for harm it could impose. For example, the EU Artificial
    Intelligence Act has a four-tier classification system for AI risk: Unacceptable,
    High, Limited, and Minimal. Each tier is bound to its own regulation articles
    within this act. For example, the top tier is Unacceptable Risk (Article 5) and
    prohibits usage such as behavior manipulation, remote biometric identification
    for police enforcement, social scoring by public authorities, and such. As you
    can imagine, a violation of this tier results in much more severe penalties than
    the third tier (Limited Risk—Article 52) which includes the risk of impersonation
    or deception. We hope the goal focuses on spotting those “potential for danger”
    AI use cases and telling the perpetrators that if they’re caught, they’ll be subjected
    to penalties, fines, and criminal prosecution.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，有了人工智能，现在虚假信息可以迅速传播。人工智能可以使虚假信息更具说服力。然而，停止使用人工智能并不能解决问题。不良行为者会从一个国家转移到另一个国家来传播危害，因为人工智能可以轻易跨越边界。我们希望看到政府监管与人工智能试图做什么、可能做什么或可能造成的伤害相关的更高风险级别。例如，欧盟人工智能法案为人工智能风险设定了四级分类系统：不可接受、高、有限和最小。每个级别都绑定于该法案内的特定法规条款。例如，最高级别是不可接受风险（第5条），禁止使用如行为操纵、为执法目的进行远程生物识别、公共当局进行社会评分等。正如你可以想象的那样，违反这一级别的处罚比第三级（有限风险——第52条）的处罚要严重得多，第三级包括冒充或欺骗的风险。我们希望目标集中在识别那些“潜在危险”的人工智能用例，并告诉肇事者，如果他们被抓住，他们将受到处罚、罚款和刑事起诉。
- en: And when it comes to regulated industries, we also think the biggest question
    to ask is, “Are there humans in the loop?” We believe humans *should* be in the
    loop—“ask and adjust” is crucial. It’s a pretty fundamental point, but not everybody
    sees it that way. But we think this is critical (especially with agentic AI) and
    an effective safeguard to go with actual usage of this technology.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到受监管的行业时，我们认为最大的问题应该是，“是否有人在回路中？”我们认为人*应该*在回路中——“询问和调整”至关重要。这是一个相当基本的原则，但并不是每个人都这样看待。但我们认为这是关键（特别是对于代理人工智能）并且是实际使用这项技术的有效保障。
- en: Managing the AI Lifecycle
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理人工智能生命周期
- en: We believe that given the reasonable assumption you will at least attempt to
    comply with all regulatory orders you have or will receive, it’s clear that you’re
    going to end up with challenges around tracking your models. It’s not unlike all
    those encryption keys we talked about earlier. In short, you will need the ability
    to track your models against regulatory standards in areas such as accuracy and
    fairness, and you will need technology to help you do that.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，鉴于你至少会尝试遵守你已拥有或将来会收到的所有监管命令的合理假设，很明显，你将面临跟踪你的模型的挑战。这并不像我们之前讨论的所有加密密钥那样。简而言之，你需要能够根据准确性、公平性等领域的监管标准跟踪你的模型，并且你需要技术来帮助你做到这一点。
- en: For example, [Figure 5-12](#ch05_figure_12_1740182048921861) shows a dashboard
    we set up to track a multimodel deployment using watsonx.governance. Our dashboard
    gives us a quick view of our environment. There are LLMs from OpenAI, IBM, Meta,
    and other models that are in a review state. In our example, we have five noncompliant
    models that need our attention. Other widgets define use cases, risk tiers, hosting
    locations (on premises or at a hyper scaler), departmental use (great idea for
    chargebacks), position in the approval lifecycle, and more. Of course, you can
    drill down into these details, but one of the things we like about this tool the
    most is its ability to attach a regulatory framework to a model to help define
    and govern it.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[图5-12](#ch05_figure_12_1740182048921861) 展示了我们使用 watsonx.governance 设置的仪表板，用于跟踪多模型部署。我们的仪表板为我们提供了环境的快速视图。有来自
    OpenAI、IBM、Meta 和其他处于审查状态的 LLM。在我们的例子中，我们有五个需要我们关注的非合规模型。其他小部件定义了用例、风险等级、托管位置（本地或超大规模计算器）、部门用途（对于费用回收是个好主意）、审批生命周期中的位置等。当然，你可以深入这些细节，但我们最喜欢这个工具的一点是它能够将监管框架附加到模型上，以帮助定义和监管它。
- en: The toolset you choose should also provide the ability to explain decisions
    and automatically collect metadata so auditors can determine how models were trained
    and why they generated the output they did.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你所选择的工具集也应该提供解释决策和自动收集元数据的能力，以便审计员可以确定模型是如何训练的以及为什么产生了他们所看到的输出。
- en: '![A screenshot of a computer  AI-generated content may be incorrect.](assets/aivc_0512.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，AI生成的内容可能不正确。](assets/aivc_0512.png)'
- en: Figure 5-12\. Using watsonx.governance to build a dashboard and track a multimodel
    deployment environment
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-12\. 使用 watsonx.governance 构建仪表板并跟踪多模型部署环境
- en: What lies beneath
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐藏在表面之下
- en: While [Figure 5-12](#ch05_figure_12_1740182048921861) gave you a glimpse of
    a powerful dashboard to manage AI, what lies beneath are the actual orchestration
    and operational flows to keep you from falling over the edge. We gave an example
    of model drift earlier in this chapter. The fact that models drift implies that
    they require lifecycle management. In reality, the moment you put a model into
    production is the moment it starts to go stale. As you set up your AI governance
    practice, with focus on the levers outlined in this chapter, know that it must
    not be confined to the data science department. It requires information to be
    shared and decisions to be made across the entire enterprise, from a business
    unit’s initial request for a model, to the approval of infrastructure resources
    to inference it, governance of the training data, development, testing and tuning,
    risk assessment, through deployment, and beyond. Good AI governance practices
    will involve both technical and non-technical stakeholders and must not only automate
    as much of the process as possible to reduce strain on the data science department,
    but must also ensure that decision makers have access to timely, relevant data
    that they need to speed time to value. Your AI platform should automatically capture
    metadata, including the training data and frameworks used to build the model,
    along with evaluation information as the model progresses from use case request
    to development to test to deployment. That data should be made available to approvers
    using a searchable, governed catalog, ensuring that decision makers have a complete
    picture of the model’s lineage and performance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然[图5-12](#ch05_figure_12_1740182048921861)让你瞥见了管理AI的强大仪表板，但隐藏在下面的实际上是实际的编排和操作流程，以防止你跌入边缘。在本章前面，我们给出了模型漂移的例子。模型漂移的事实意味着它们需要生命周期管理。实际上，当你将模型投入生产的那一刻起，它就开始变得过时。在你建立AI治理实践时，重点关注本章概述的杠杆，要知道它不能仅限于数据科学部门。它需要在整个企业范围内共享信息和做出决策，从业务单位对模型的初始请求，到批准基础设施资源以进行推理，再到训练数据的治理、开发、测试和调整、风险评估，以及部署和之后。良好的AI治理实践将涉及技术和非技术利益相关者，并且不仅必须尽可能自动化流程以减轻数据科学部门的压力，还必须确保决策者能够及时、相关地访问他们需要的、以加快价值实现时间的数据。你的AI平台应自动捕获元数据，包括用于构建模型的训练数据和框架，以及随着模型从用例请求到开发、测试再到部署的进展而进行的评估信息。这些数据应通过可搜索的、受管理的目录提供给审批者，确保决策者对模型的血统和性能有一个全面的了解。
- en: An example of an end-to-end governed process
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个端到端治理流程的示例
- en: 'If you have the right tools and lifecycle management, then you have a chance
    to implement an end-to-end AI governance process that flows something like this:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你拥有正确的工具和生命周期管理，那么你有机会实施一个端到端AI治理流程，流程大致如下：
- en: Once the model proposal has gone through the appropriate approval process, a
    model entry is created in your model inventory. This entry is continuously updated
    with new information.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型提案通过了适当的审批流程，就会在你的模型库存中创建一个模型条目。此条目会持续更新新的信息。
- en: Model developers use their tools and models of choice to build AI solutions.
    Training data and metrics are automatically captured and saved to the model entry
    (assuming the vendor exposes this—this is why you want models that are open).
    Custom information can also be saved.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型开发者使用他们选择的工具和模型来构建AI解决方案。训练数据和指标会自动捕获并保存到模型条目中（假设供应商公开了这一点——这就是为什么你需要开放模型的原因）。也可以保存自定义信息。
- en: When the preproduction model is evaluated for accuracy, drift, and bias, the
    performance metadata is captured and synced.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当预生产模型被评估准确性、漂移和偏差时，性能元数据被捕获并同步。
- en: The model is reviewed and approved for production.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型经过审查并获得生产批准。
- en: The model is deployed wherever you decide to deploy it (on premises, on the
    edge, in the cloud), and once again, the relevant metadata is captured and synced.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型被部署到你决定部署的地方（本地、边缘、云端），并且再次，相关的元数据被捕获并同步。
- en: Finally, the production model is continuously monitored, and the performance
    data is captured and synced. A dashboard (like the one in [Figure 5-12](#ch05_figure_12_1740182048921861))
    provides a comprehensive view of the performance metrics for all models (no matter
    the vendor), allowing stakeholders to proactively identify and react to any issues.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，生产模型持续受到监控，性能数据被捕获并同步。仪表板（如图5-12所示）提供了所有模型（无论供应商）的性能指标的综合视图，使利益相关者能够主动识别并应对任何问题。
- en: Wrapping It Up
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'One of the founding fathers of the US (and its fourth president), James Madison,
    once said, “The circulation of confidence is better than the circulation of money.”
    His point was: it’s not just the flow of wealth that matters, but more so the
    underlying trust and confidence holding social, political, and economic systems
    together. With the place that GenAI and agents are shaping up to take in history,
    he would have surely added it to his list.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 美国的创始人之一（及其第四任总统）詹姆斯·麦迪逊曾经说过：“信任的流通比货币的流通更重要。”他的观点是：不仅仅是财富的流动很重要，更重要的是支撑社会、政治和经济体系的基础信任和信心。鉴于GenAI和代理人在历史上的地位，他肯定会将其添加到他的列表中。
- en: 'Indeed, most companies’ culture looks at many of the topics outlined in this
    chapter as typical regulatory compliance and defaults to “a least-effort-to-comply
    approach.” The topics covered in this chapter can be repurposed for other benefits
    and accelerate other journeys. We can’t help but feel something might bother you
    from the preceding list—we said “chance.” Why did we say that? Because governance
    is about culture, the technology helps you implement the culture. But always remember:
    *AI that people trust is AI that people will use*.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，大多数公司的文化将本章中概述的许多主题视为典型的合规性监管和默认采取“最小努力遵守”的方法。本章涵盖的主题可以用于其他好处并加速其他旅程。我们不禁觉得前述列表中可能有些东西让你感到困扰——我们提到了“机会”。为什么这么说呢？因为治理关乎文化，技术帮助你实施这种文化。但请始终记住：*人们信任的AI才是人们会使用的AI*。
- en: We recognize there was a lot to cover in this chapter with an unfair amount
    of space to allot to it. That said, we hope that you’ve gotten a sense of the
    things you need to learn more about. And speaking of learning, that’s where we
    go next.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认识到，本章有很多内容需要涵盖，但分配给它的空间却不够。话虽如此，我们希望你已经对需要进一步了解的事物有了感觉。说到学习，这正是我们接下来要讨论的内容。
- en: ^([1](ch05.html#id711-marker)) There are some uncomfortable topics that warrant
    discussion here. *We* don’t like writing about them, but they are important for
    you to understand.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.html#id711-marker)) 这里有一些需要讨论的不舒服的话题。*我们*不喜欢写关于它们的内容，但它们对你理解这些内容很重要。
- en: '^([2](ch05.html#id715-marker)) Case: Mata v. Avianca, Inc., 1:2022cv01461,
    filed in the South District of New York.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.html#id715-marker)) 案例：Mata诉Avianca公司，1:2022cv01461，在纽约南区提起诉讼。
- en: '^([3](ch05.html#id737-marker)) Arielle Waldman, “FBI: Criminals Using AI to
    Commit Fraud ‘on a Larger Scale,’” TechTarget, December 4, 2024, [*https://oreil.ly/7VgiB*](https://oreil.ly/7VgiB).'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch05.html#id737-marker)) 艾丽尔·沃尔德曼，“罪犯使用AI进行更大规模的欺诈，”TechTarget，2024年12月4日，[*https://oreil.ly/7VgiB*](https://oreil.ly/7VgiB)。
- en: ^([4](ch05.html#id738-marker)) CNN, “Finance Worker Pays Out $25 Million After
    Video Call with Deepfake ‘Chief Financial Officer,’” February 4, 2024, [*https://oreil.ly/xwZY1*](https://oreil.ly/xwZY1).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch05.html#id738-marker)) CNN，“金融工作者在与深度伪造‘首席财务官’的视频通话后支付2500万美元，”2024年2月4日，[*https://oreil.ly/xwZY1*](https://oreil.ly/xwZY1)。
- en: ^([5](ch05.html#id747-marker)) Pete Evans, “Apple Users Can Say No to Being
    Tracked with New Software Update,” CBC News, April 26, 2021, [*https://oreil.ly/QL2Fe*](https://oreil.ly/QL2Fe).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch05.html#id747-marker)) 皮特·埃文斯，“苹果用户可以通过新软件更新拒绝被追踪，”CBC新闻，2021年4月26日，[*https://oreil.ly/QL2Fe*](https://oreil.ly/QL2Fe)。
- en: ^([6](ch05.html#id748-marker)) Acxiom Corporation Form 10-K Annual Report for
    the Fiscal year ended March 31, 2018, filed with the U.S. Securities and Exchange
    Commission, May 21, 2018, [*https://oreil.ly/SpkKt*](https://oreil.ly/SpkKt).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch05.html#id748-marker)) Acxiom公司2018年3月31日财政年度10-K年度报告，提交给美国证券交易委员会，2018年5月21日，[*https://oreil.ly/SpkKt*](https://oreil.ly/SpkKt)。
- en: ^([7](ch05.html#id760-marker)) By using a catch term like *ethics*, we mean
    to capture all things that go into ensuring governance, explainability, fair use,
    privacy, and more around your AI projects—good acting. We won’t flesh out all
    the ethical considerations in this chapter, but you’ll find almost all of them
    can be binned to one of the levers we introduce you to in this section.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch05.html#id760-marker)) 使用像“伦理”这样的关键词，我们的目的是涵盖确保治理、可解释性、公平使用、隐私以及围绕您的AI项目等方面的所有内容——良好的行为。我们不会在本章中详细阐述所有伦理考量，但您会发现几乎所有这些考量都可以归入我们在本节中向您介绍的一个或多个杠杆。
- en: ^([8](ch05.html#id762-marker)) Stephen Jones, “Automated Hiring Systems Are
    ‘Hiding’ Candidates from Recruiters—How Can We Stop This?,” World Economic Forum,
    September 14, 2021, [*https://oreil.ly/2C-dn*](https://oreil.ly/2C-dn).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch05.html#id762-marker)) Stephen Jones，“自动化招聘系统‘隐藏’候选人给招聘人员——我们如何阻止这种情况？”，世界经济论坛，2021年9月14日，[*https://oreil.ly/2C-dn*](https://oreil.ly/2C-dn).
- en: ^([9](ch05.html#id769-marker)) Robert Bartlett et al., “Consumer-Lending Discrimination
    in the FinTech Era,” (working paper, University of California, Berkeley, 2019),
    [*https://oreil.ly/C5iaB*](https://oreil.ly/C5iaB).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch05.html#id769-marker)) Robert Bartlett 等人，“金融科技时代的消费者贷款歧视”，(工作论文，加州大学伯克利分校，2019年)，[*https://oreil.ly/C5iaB*](https://oreil.ly/C5iaB).
- en: '^([10](ch05.html#id778-marker)) Fengqing Jiang et al., “ArtPrompt: ASCII Art-Based
    Jailbreak Attacks Against Aligned LLMs,” preprint, arXiv, February 19, 2024, arXiv:2402.11753,
    [*https://arxiv.org/abs/2402.11753*](https://arxiv.org/abs/2402.11753).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch05.html#id778-marker)) Fengqing Jiang 等人，“ArtPrompt：基于ASCII艺术的针对对齐LLMs的越狱攻击”，预印本，arXiv，2024年2月19日，arXiv:2402.11753，[*https://arxiv.org/abs/2402.11753*](https://arxiv.org/abs/2402.11753).
- en: ^([11](ch05.html#id783-marker)) Red teaming is a process for testing cybersecurity
    effectiveness where ethical hackers conduct a simulated and nondestructive cyberattack.
    Their simulated attacks help organizations identify vulnerabilities in their systems
    and make targeted improvements to security operations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch05.html#id783-marker)) 红队测试是一种测试网络安全有效性的过程，其中道德黑客进行模拟且非破坏性的网络攻击。他们的模拟攻击帮助组织识别其系统中的漏洞，并对安全操作进行有针对性的改进。
- en: ^([12](ch05.html#id791-marker)) Neil Vigdor, “Apple Card Investigated After
    Gender Discrimination Complaints,” *The New York Times*, November 10, 2019, [*https://oreil.ly/Mo9NZ*](https://oreil.ly/Mo9NZ).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch05.html#id791-marker)) Neil Vigdor，“苹果卡在性别歧视投诉后受到调查”，*《纽约时报》*，2019年11月10日，[*https://oreil.ly/Mo9NZ*](https://oreil.ly/Mo9NZ).
- en: '^([13](ch05.html#id795-marker)) “Scaling Monosemanticity: Extracting Interpretable
    Features from Claude 3 Sonnet,” Transformer Circuits, 2024, accessed October 25,
    2023, [*https://oreil.ly/AFZ4w*](https://oreil.ly/AFZ4w).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch05.html#id795-marker)) “扩展单义性：从Claude 3 Sonnet中提取可解释特征”，Transformer
    Circuits，2024年，2023年10月25日访问，[*https://oreil.ly/AFZ4w*](https://oreil.ly/AFZ4w).
- en: ^([14](ch05.html#id796-marker)) “Golden Gate Claude,” Anthropic, accessed October
    25, 2023, [*https://oreil.ly/o5r6S*](https://oreil.ly/o5r6S).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch05.html#id796-marker)) “金门Claude”，Anthropic，2023年10月25日访问，[*https://oreil.ly/o5r6S*](https://oreil.ly/o5r6S).
- en: ^([15](ch05.html#id798-marker)) “Teaching Large Language Models to ‘Forget’
    Unwanted Content,” IBM Insights, 2024, [*https://oreil.ly/hzltJ*](https://oreil.ly/hzltJ).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch05.html#id798-marker)) “教会大型语言模型‘忘记’不希望的内容”，IBM洞察，2024年，[*https://oreil.ly/hzltJ*](https://oreil.ly/hzltJ).
- en: ^([16](ch05.html#id799-marker)) Ronan Eldan and Mark Russinovich, “Who’s Harry
    Potter? Approximate Unlearning in LLMs,” preprint, arXiv, October 4, 2023, [*https://arxiv.org/abs/2310.02238*](https://arxiv.org/abs/2310.02238).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch05.html#id799-marker)) Ronan Eldan 和 Mark Russinovich，“谁是哈利·波特？在LLMs中的近似反学习”，预印本，arXiv，2023年10月4日，[*https://arxiv.org/abs/2310.02238*](https://arxiv.org/abs/2310.02238).
