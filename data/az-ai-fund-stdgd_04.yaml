- en: Chapter 4\. Fundamental Principles of Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：机器学习的基本原则
- en: In the AI-900 exam, about 20%–25% of the material covers the core principles
    of ML on Microsoft Azure. This includes foundational techniques like regression
    analysis, classification, and clustering. Each of these techniques offers a unique
    approach to problem solving. They allow you to select the right method based on
    the data type and the predictions you need to make. In this chapter, we’re going
    to dig into these must-know concepts and services. Understanding these ideas will
    help you tackle questions on the AI-900 exam, so you’ll know not only what these
    services are but also how they work and why they matter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI-900考试中，大约20%–25%的内容涵盖了在Microsoft Azure上机器学习的核心原则。这包括回归分析、分类和聚类等基础技术。每种技术都提供了一种独特的问题解决方法。它们允许你根据数据类型和需要做出的预测选择合适的方法。在本章中，我们将深入研究这些必须了解的概念和服务。理解这些想法将帮助你在AI-900考试中应对问题，这样你不仅会知道这些服务是什么，还会了解它们是如何工作的以及为什么它们很重要。
- en: What Is Machine Learning?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: ML, which is a branch of AI, allows systems to perform tasks like data analysis
    without needing explicit instructions. Instead, it processes large amounts of
    historical data, identifies patterns, and makes predictions based on those patterns.
    For instance, you can use ML to classify images, numbers, or documents and make
    predictions from them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML），作为人工智能的一个分支，允许系统在没有明确指令的情况下执行数据分析和类似任务。相反，它处理大量的历史数据，识别模式，并根据这些模式进行预测。例如，你可以使用机器学习对图像、数字或文档进行分类，并从中做出预测。
- en: Let’s say you work for a financial services organization looking to differentiate
    between fraudulent and genuine transactions. With ML, the system would learn to
    identify patterns from known examples and then apply that knowledge to predict
    whether a new transaction is genuine.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你为一家金融服务机构工作，该机构试图区分欺诈交易和真实交易。使用机器学习，系统将学会从已知示例中识别模式，然后将这些知识应用于预测新交易是否真实。
- en: ML is essential for modern businesses because it helps automate data collection,
    classification, and analysis. This speeds up decision making and drives growth.
    It improves processes like customer experience and resource management, enabling
    businesses to solve problems faster.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习对于现代企业至关重要，因为它有助于自动化数据收集、分类和分析。这加快了决策过程并推动了增长。它改善了客户体验和资源管理等流程，使企业能够更快地解决问题。
- en: Although the terms *artificial intelligence* (*AI*) and *machine learning* (*ML*)
    are often used interchangeably, they aren’t the same. AI is a broader concept
    that includes anything from voice assistants to self-driving cars. ML, however,
    focuses on specific tasks, such as predicting equipment maintenance schedules
    or classifying documents.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管术语*人工智能*（*AI*）和*机器学习*（*ML*）经常被互换使用，但它们并不相同。人工智能是一个更广泛的概念，包括从语音助手到自动驾驶汽车的一切。然而，机器学习专注于特定的任务，例如预测设备维护计划或对文档进行分类。
- en: 'Take manufacturing, for example. ML can help with the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以制造业为例。机器学习可以帮助以下方面：
- en: Predictive maintenance
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性维护
- en: Identify potential equipment failures before they occur, reducing downtime and
    repair costs
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在设备发生故障之前识别潜在的设备故障，减少停机时间和维修成本
- en: Quality control
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 质量控制
- en: Monitor production lines to detect defects and ensure consistent product quality
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 监控生产线以检测缺陷并确保产品质量的一致性
- en: Product design optimization
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 产品设计优化
- en: Refine designs, such as improving the abrasiveness of sandpaper by analyzing
    small changes in size and shape
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 优化设计，例如通过分析尺寸和形状的微小变化来提高砂纸的磨削性
- en: Supply chain management
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 供应链管理
- en: Predict demand, identify bottlenecks, and streamline logistics to improve efficiency
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 预测需求，识别瓶颈，并优化物流以提高效率
- en: The ML Model Workflow
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型工作流程
- en: At its core, an *ML model* is simply a software application that takes one or
    more input values and calculates an output value. The process of figuring out
    how to make that calculation is called *training*. Once the model is trained,
    you can use it to make predictions. This is a process known as *inferencing*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，一个*机器学习模型*只是一个软件应用，它接受一个或多个输入值并计算一个输出值。确定如何进行这种计算的过程称为*训练*。一旦模型经过训练，你就可以用它来进行预测。这个过程被称为*推理*。
- en: Let’s take a closer look at the main steps of an ML system, which you can see
    in [Figure 4-1](#i04_chapter4_figure_1_1742068262037129). This is a very basic
    example. Keep in mind that the algorithms can be quite complex. But for our purposes,
    we just want to get a sense of the workflow.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看机器学习系统的主要步骤，您可以在[图4-1](#i04_chapter4_figure_1_1742068262037129)中看到。这是一个非常基础的例子。请记住，算法可能相当复杂。但就我们的目的而言，我们只想对工作流程有一个大致的了解。
- en: '![](assets/aaif_0401.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0401.png)'
- en: Figure 4-1\. The basic workflow of an ML model
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1\. 机器学习模型的基本工作流程
- en: Let’s take a look at each of these steps in more detail.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些步骤中的每一个。
- en: 'Step 1: Train the Model'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：训练模型
- en: 'The process of training an ML model begins with past data, which is referred
    to as the *training data* or *dataset*. Each data point in the training dataset
    is made up of two essential components:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 训练机器学习模型的过程从过去的数据开始，这些数据被称为*训练数据*或*数据集*。训练数据集中的每个数据点由两个基本组成部分组成：
- en: Features
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 特征
- en: The characteristics or attributes you observe in each data point
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你在每个数据点观察到的特征或属性
- en: Labels
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 标签
- en: The outcome or result you want the model to predict
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模型需要预测的结果或结果
- en: A dataset in table form is organized into rows and columns, as you would see
    in a spreadsheet or database. Each row represents an individual record or entry,
    and each column contains specific attributes or features of the data. This structure
    allows for easy comparison and analysis of data across multiple entries by syncing
    similar information in a consistent format. [Table 4-1](#i04_chapter4_table_1_1742068262048473)
    shows an example of a table for a dataset for customer feedback and return requests.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以表格形式组织成行和列，就像你在电子表格或数据库中看到的那样。每一行代表一个单独的记录或条目，每一列包含数据的特定属性或特征。这种结构允许通过以一致格式同步相似信息，轻松比较和分析多个条目之间的数据。[表4-1](#i04_chapter4_table_1_1742068262048473)展示了客户反馈和退货请求数据集的示例。
- en: Table 4-1\. Sample dataset showing customer feedback and return requests
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-1\. 显示客户反馈和退货请求的样本数据集
- en: '| Customer_ID | Purchase_Date | Product_Category | Rating | Feedback_Comment
    | Return_Requested |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 客户_ID | 购买日期 | 产品类别 | 评分 | 反馈评论 | 退货请求 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 001 | 2024-10-01 | Electronics | 5 | “Great product, fast delivery!” | No
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 001 | 2024-10-01 | 电子产品 | 5 | “产品优秀，快速配送！” | 否 |'
- en: '| 002 | 2024-10-05 | Apparel | 2 | “Size did not match description.” | Yes
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 002 | 2024-10-05 | 服装 | 2 | “尺寸与描述不符。” | 是 |'
- en: '| 003 | 2024-10-07 | Home Goods | 4 | “Quality is good, but color is off.”
    | No |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 003 | 2024-10-07 | 家居用品 | 4 | “质量不错，但颜色不对。” | 否 |'
- en: '| 004 | 2024-10-10 | Electronics | 1 | “Item arrived damaged.” | Yes |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 004 | 2024-10-10 | 电子产品 | 1 | “商品损坏到达。” | 是 |'
- en: '| 005 | 2024-10-12 | Beauty | 3 | “Average product, packaging was poor.” |
    No |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 005 | 2024-10-12 | 美容 | 3 | “产品一般，包装很差。” | 否 |'
- en: Data is often messy and incomplete. These imperfections can distort results,
    lead to inaccuracies, and complicate decision making.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常杂乱无章且不完整。这些不完美之处可能会扭曲结果，导致不准确，并使决策复杂化。
- en: 'For example, a common issue is missing data. While removing incomplete information
    is a straightforward approach, it can lead to unintended distortions, particularly
    when the missing data is not randomly distributed. Instead, consider alternative
    methods to handle missing data effectively:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个常见问题是数据缺失。虽然删除不完整信息是一种直接的方法，但它可能导致意外的扭曲，尤其是在缺失数据不是随机分布的情况下。相反，考虑其他有效处理缺失数据的方法：
- en: Mean/median imputation
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 均值/中位数插补
- en: Replace missing values with the average (mean) or the middle value (median)
    of the dataset to maintain consistency
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 用数据集的平均值（均值）或中间值（中位数）替换缺失值以保持一致性
- en: Predictive imputation
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性插补
- en: Leverage statistical models to predict and fill in missing values based on patterns
    in the available data, providing a more accurate estimate
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 利用统计模型根据可用数据中的模式预测和填充缺失值，提供更准确的估计
- en: 'Another common challenge in data analysis is dealing with outliers. *Outliers*
    are extreme data points that differ significantly from other observations. They
    can distort results or obscure important patterns. Properly managing outliers
    is essential for improving the accuracy and reliability of your findings. Consider
    the following approaches:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析中另一个常见的挑战是处理异常值。*异常值*是与其他观察值显著不同的极端数据点。它们可能会扭曲结果或掩盖重要的模式。正确管理异常值对于提高你发现结果的准确性和可靠性至关重要。考虑以下方法：
- en: Removal
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 移除
- en: Exclude outliers from the dataset if they are identified as errors or are irrelevant
    to the analysis
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果识别出异常值是错误或与分析无关，则从数据集中排除它们
- en: Transformation
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 转换
- en: Use mathematical techniques, such as logarithmic or square root transformations,
    to minimize the influence of outliers without removing them entirely
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数学技术，例如对数或平方根转换，以最小化异常值的影响，而无需完全删除它们
- en: Investigation
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 调查
- en: Examine outliers closely to determine whether they provide valuable insights
    or are the result of data-entry mistakes
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细检查异常值，以确定它们是否提供了有价值的见解，或者是否是数据输入错误的结果
- en: 'Data may also have duplications. For this, you can consider these options:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也可能存在重复。为此，你可以考虑以下选项：
- en: Deduplication algorithms
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 去重算法
- en: Use tools or scripts to identify and merge duplicate data
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用工具或脚本来识别和合并重复数据
- en: Unique identifiers
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一标识符
- en: Ensure that each record has a unique key to prevent duplication at the entry
    point
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 确保每条记录都有一个唯一键，以防止在输入点出现重复
- en: Quality control
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 质量控制
- en: Regularly audit data to detect and resolve duplicates
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 定期审计数据以检测和解决重复问题
- en: 'Then there is the problem with inconsistent data formats. You can use the following
    techniques to address this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后还有不一致的数据格式问题。你可以使用以下技术来解决这个问题：
- en: Data normalization
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Convert data to a standard format (e.g., ISO 8601 for dates)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据转换为标准格式（例如，ISO 8601日期格式）
- en: Validation rules
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 验证规则
- en: Implement automated checks during data entry to enforce consistent formatting
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据输入期间实施自动化检查，以强制执行一致的格式
- en: Preprocessing pipelines
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理管道
- en: Develop extract, transform, and load (ETL) processes to clean and standardize
    data before analysis
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 开发提取、转换和加载（ETL）过程，在分析之前清理和标准化数据
- en: Once you have improved the quality of the dataset—a process known as *data preparation*—you
    can then look at training. One way to think of this is in terms of basic algebra.
    The features are represented by *x*, and there are often several of them, forming
    a vector (an array of values). The label is represented by *y*, which is the prediction
    or result the model tries to output.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提高了数据集的质量——这个过程被称为*数据准备*——你就可以开始进行训练。一种思考方式是基本代数。特征由*x*表示，通常有几个特征，形成一个向量（值的数组）。标签由*y*表示，这是模型试图输出的预测或结果。
- en: For example, let’s say you’re building a model that predicts the price of a
    house based on its characteristics. The features (*x*) might include the number
    of bedrooms, square footage, and location. The label (*y*) would be the house’s
    sale price. The model is trained to learn how these features relate to the price
    and can then predict the price of a new house based on similar characteristics.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在构建一个基于房屋特征的模型来预测房价。特征（*x*）可能包括卧室数量、面积和位置。标签（*y*）将是房屋的销售价格。该模型经过训练，学习这些特征与价格之间的关系，然后可以根据类似特征预测新房屋的价格。
- en: 'Another example could be a model designed to predict whether an email is spam.
    The features (*x*) could be things like the presence of certain keywords, the
    sender’s address, and the time the email was sent. The label (*y*) would be a
    binary outcome: 1 if the email is spam, 0 if it’s not. Over time, the model learns
    to recognize patterns in the features that indicate whether an email is spam or
    legitimate.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子可能是一个旨在预测电子邮件是否为垃圾邮件的模型。特征（*x*）可能包括某些关键词的存在、发件人的地址以及发送电子邮件的时间。标签（*y*）将是一个二元结果：如果电子邮件是垃圾邮件，则为1，如果不是，则为0。随着时间的推移，模型会学会识别特征中的模式，这些模式表明电子邮件是垃圾邮件还是合法的。
- en: 'Step 2: Apply the Algorithm'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步：应用算法
- en: 'When you’re working with an ML model, you need an algorithm to figure out the
    relationship between the features and the label. The goal is to find a way to
    take the features (*x*) and use them to predict the label (*y*). The basic idea
    is to fit a function to your data. In other words, the algorithm looks for a pattern
    that can calculate *y* based on *x*. For our example, this is what it looks like:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当你与机器学习模型一起工作时，你需要一个算法来找出特征和标签之间的关系。目标是找到一种方法来使用特征（*x*）来预测标签（*y*）。基本思想是将一个函数拟合到你的数据上。换句话说，算法寻找一个模式，可以根据*x*计算*y*。对于我们的例子，它看起来是这样的：
- en: '*y* = f(*x*)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* = f(*x*)'
- en: Once the algorithm has done its job, it gives you a model. This model is essentially
    a function that performs the calculation. In this chapter, we’ll see various examples
    of this, like linear regression.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦算法完成了其工作，它就会给你一个模型。这个模型本质上是一个执行计算的函数。在本章中，我们将看到各种示例，例如线性回归。
- en: 'Step 3: Use Inferencing'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步：使用推理
- en: Once the training phase is done, you can use the trained model to make predictions,
    a process called *inferencing*. The model now works like a software program that
    contains the function learned during training. You provide it with a set of feature
    values, and it gives you a prediction for the label.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成训练阶段，你可以使用训练好的模型进行预测，这个过程称为*推理*。现在，模型就像一个包含训练期间学习到的函数的软件程序。你提供一组特征值，它为你提供一个标签的预测。
- en: Since this output is a prediction generated by the function rather than an actual
    observed value, it’s typically written as *ŷ*, pronounced “y-hat.” This is a useful
    way to show that the result is an estimate based on what the model has learned,
    not a guaranteed outcome.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个输出是由函数生成的预测值，而不是实际观察到的值，通常写作 *ŷ*，发音为“y-hat。”这是一种有用的方式来表明结果是基于模型学习到的估计，而不是一个保证的结果。
- en: Types of ML
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习类型
- en: 'There are several types of ML, each designed for different kinds of problems.
    At the highest level, ML is divided into two main types: *supervised learning*,
    which has labeled data, and *unsupervised learning*, where the data does not have
    labels. These two categories help determine how the model learns from the data
    and what kind of tasks it can perform. Under the umbrellas of supervised and unsupervised
    learning, there are other types of ML. [Figure 4-2](#i04_chapter4_figure_2_1742068262037163)
    shows the hierarchy.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有几种类型，每种类型都针对不同的问题设计。在最高层次上，机器学习分为两种主要类型：*监督学习*，它有标记的数据，和*无监督学习*，其中数据没有标签。这两个类别有助于确定模型如何从数据中学习以及它可以执行的任务类型。在监督学习和无监督学习的范畴下，还有其他类型的机器学习。[图4-2](#i04_chapter4_figure_2_1742068262037163)显示了层次结构。
- en: '![](assets/aaif_0402.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aaif_0402.png)'
- en: Figure 4-2\. The categories of ML
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-2\. 机器学习的类别
- en: In the next few sections, we’ll look at the approaches for supervised learning
    and then follow this up by looking at unsupervised learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将探讨监督学习的方法，然后接着探讨无监督学习。
- en: Regression Analysis
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析
- en: '*Regression analysis* is a statistical method used to predict a numerical outcome
    based on one or more known factors, or variables. It helps you understand the
    relationship between these variables and the result you’re trying to predict.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归分析*是一种统计方法，用于根据一个或多个已知因素或变量预测数值结果。它帮助你理解这些变量与你要预测的结果之间的关系。'
- en: For example, let’s say you want to predict how much of a new product will sell
    based on factors like advertising spend, the season, and market trends. Regression
    analysis allows you to analyze these factors and estimate how they affect sales
    so that you can forecast future performance based on current data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想根据广告支出、季节和市场趋势等因素预测新产品将卖出多少。回归分析允许你分析这些因素，并估计它们如何影响销售，以便你可以根据当前数据预测未来的表现。
- en: 'Here’s how you would approach it:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以这样来处理：
- en: Split the data
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 分割数据
- en: 'Begin by dividing your data into three subsets: a training set, a validation
    set, and a testing set. The training set is used to develop the model, the validation
    set helps fine-tune the model’s parameters, and the testing set is reserved for
    assessing the model’s performance on new, unseen data.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 首先将你的数据分为三个子集：训练集、验证集和测试集。训练集用于开发模型，验证集帮助微调模型的参数，测试集则保留用于评估模型在新、未见过的数据上的性能。
- en: Train the model
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型
- en: Using the training data, apply an algorithm to identify relationships between
    key variables, such as the advertising budget, seasonality, and market trends,
    and their impact on sales. The model searches for patterns, such as whether increased
    ad spending leads to higher sales or if certain times of the year naturally see
    better sales performance.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练数据，应用算法来识别关键变量（如广告预算、季节性和市场趋势）及其对销售的影响之间的关系。模型寻找模式，例如增加广告支出是否会导致更高的销售，或者是否某些年份的自然销售表现更好。
- en: Fine-tune the model
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 微调模型
- en: With the validation set, optimize the model’s parameters or hyperparameters
    to enhance its predictive accuracy. This step helps ensure that the model generalizes
    well and avoids overfitting to the training data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用验证集，优化模型的参数或超参数以提高其预测准确性。这一步骤有助于确保模型具有良好的泛化能力，并避免过度拟合训练数据。
- en: Test the model
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 测试模型
- en: Evaluate the performance of the fine-tuned model using the testing set. In this
    stage, the model generates sales predictions based on input variables (e.g., advertising
    budget, season, market trends) and compares these predictions to actual sales
    data to measure accuracy.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试集评估微调模型的性能。在这个阶段，模型根据输入变量（例如，广告预算、季节、市场趋势）生成销售预测，并将这些预测与实际销售数据进行比较，以衡量准确性。
- en: Evaluate the model
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型
- en: Assess the accuracy of the model’s predictions using relevant metrics, such
    as mean absolute error (MAE), root mean square error (RMSE), or *R*², which we’ll
    learn about later in this chapter. If the model’s performance falls short of expectations,
    refine the process by revisiting earlier steps, such as trying a different algorithm,
    adjusting parameters, or including new features.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相关的指标，如平均绝对误差（MAE）、均方根误差（RMSE）或*R*²（我们将在本章后面了解）来评估模型预测的准确性。如果模型的性能低于预期，通过重新访问早期步骤来改进过程，例如尝试不同的算法、调整参数或包括新特征。
- en: Iterate and improve
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代和改进
- en: Using the insights gained from the evaluation, iterate on the model to improve
    its performance. This iterative process might include collecting additional data
    or exploring alternative modeling techniques to boost accuracy.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用评估中获得的见解，对模型进行迭代以改进其性能。这个迭代过程可能包括收集更多数据或探索替代建模技术以提高准确性。
- en: 'Example: Ticket Sales'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：票务销售
- en: Let’s take a look at a more detailed example to better understand how regression
    analysis works. For this example, we won’t cover every step outlined in the previous
    section. When it comes to the exam, such in-depth detail about regression analysis
    isn’t necessary. Instead, we’ll focus on the main phases.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个更详细的例子，以更好地理解回归分析是如何工作的。对于这个例子，我们不会涵盖上一节中概述的每个步骤。在考试中，关于回归分析这样的深入细节是不必要的。相反，我们将专注于主要阶段。
- en: In our example, we’ll predict a numeric label (*y*) based on a single feature
    (*x*). While most real-world applications involve multiple features, starting
    with just one keeps things simple and allows us to focus on the core idea.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将根据单个特征（*x*）预测一个数值标签（*y*）。虽然大多数实际应用涉及多个特征，但仅从单个特征开始可以使事情保持简单，并允许我们专注于核心思想。
- en: Let’s consider the example of predicting concert ticket prices based on the
    popularity of the performing artist. Here, the popularity score is derived from
    survey data collected from fans, representing a value on a scale from 1 to 100\.
    This score serves as our feature while the ticket price for the artist’s concert
    is the label we aim to predict. To build this prediction model, we’ll use historical
    data that pairs popularity scores (*x*) with their corresponding ticket prices
    (*y*) from past concerts, as shown in [Table 4-2](#i04_chapter4_table_2_1742068262048550).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个基于表演艺术家人气预测音乐会票价示例。在这里，人气分数是从粉丝收集的调查数据中得出的，代表1到100的尺度上的一个值。这个分数作为我们的特征，而艺术家音乐会的票价是我们想要预测的标签。为了构建这个预测模型，我们将使用历史数据，这些数据将人气分数（*x*）与过去音乐会的相应票价（*y*）配对，如[表4-2](#i04_chapter4_table_2_1742068262048550)所示。
- en: Table 4-2\. Comparing an artist’s popularity with the concert ticket price
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-2\. 比较艺术家的知名度和音乐会票价
- en: '| Artist popularity (*x*) | Ticket price (*y*) |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 艺术家人气 (*x*) | 票价 (*y*) |'
- en: '| --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 35 | $45 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 35 | $45 |'
- en: '| 40 | $60 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 40 | $60 |'
- en: '| 45 | $55 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 45 | $55 |'
- en: '| 50 | $75 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 50 | $75 |'
- en: '| 55 | $65 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 55 | $65 |'
- en: '| 60 | $85 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 60 | $85 |'
- en: '| 65 | $100 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 65 | $100 |'
- en: '| 70 | $105 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 70 | $105 |'
- en: '| 75 | $115 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 75 | $115 |'
- en: '| 80 | $135 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 80 | $135 |'
- en: '| 85 | $140 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 85 | $140 |'
- en: '| 90 | $170 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 90 | $170 |'
- en: Next, we’ll split the data and use a portion of it to train the model. In this
    case, the data was split randomly to ensure a balanced representation of the dataset.
    [Table 4-3](#i04_chapter4_table_3_1742068262048585) shows the subset of data selected
    for training.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将分割数据并使用其中一部分来训练模型。在这种情况下，数据被随机分割以确保数据集的平衡表示。[表4-3](#i04_chapter4_table_3_1742068262048585)显示了用于训练的数据子集。
- en: Table 4-3\. The subset of data for the training of the model
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-3\. 模型训练的数据子集
- en: '| Artist popularity (*x*) | Ticket price (*y*) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 艺术家人气 (*x*) | 票价 (*y*) |'
- en: '| --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 40 | $60 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 40 | $60 |'
- en: '| 50 | $75 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 50 | $75 |'
- en: '| 60 | $85 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 60 | $85 |'
- en: '| 70 | $105 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 70 | $105 |'
- en: '| 75 | $115 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 75 | $115 |'
- en: '| 80 | $135 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 80 | $135 |'
- en: 'While random splitting is a common approach, there are other methods that can
    be used based on the scenario:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然随机分割是一种常见的方法，但根据场景还可以使用其他方法：
- en: Stratified splitting
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 分层分割
- en: Ensures that specific proportions of key features (like popularity ranges) are
    maintained in both training and testing sets
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在训练集和测试集中保持关键特征（如流行度范围）的特定比例
- en: Time-based splitting
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基于时间的分割
- en: Used when the data has a chronological order, such as time-series data, where
    older data is used for training and newer data for testing
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据具有时间顺序时使用，例如时间序列数据，其中较旧的数据用于训练，较新的数据用于测试
- en: K-fold cross-validation
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: K 折交叉验证
- en: Splits the data into multiple folds, where each subset takes a turn as the test
    set while the others are used for training
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分成多个折，其中每个子集轮流作为测试集，而其他数据用于训练
- en: To get a better understanding of how the popularity scores (*x*) and ticket
    prices (*y*) relate to each other, we can plot these values as points on a graph.
    You can see this in [Figure 4-3](#i04_chapter4_figure_3_1742068262037187). By
    plotting these points, you can start to see the relationship between the two—typically,
    as the popularity increases, so does the ticket price.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解流行度得分（*x*）和票价（*y*）之间的关系，我们可以在图上绘制这些值作为点。您可以在[图 4-3](#i04_chapter4_figure_3_1742068262037187)中看到这一点。通过绘制这些点，您可以看到两者之间的关系——通常，随着流行度的增加，票价也会增加。
- en: '![](assets/aaif_0403.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0403.png)'
- en: Figure 4-3\. This scatter plot illustrates the relationship between artist popularity
    and ticket prices
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 该散点图说明了艺术家流行度与票价之间的关系
- en: With the training dataset, we’re ready to apply an algorithm that can model
    the relationship between artist popularity and ticket price. We’ll use the linear
    regression formula, which essentially finds the best-fit line through the points
    that minimizes the distance between the line and the actual data points. This
    line represents a function where the slope tells you how much the ticket price
    will increase with each increase in the artist’s popularity. This is shown in
    [Figure 4-4](#i04_chapter4_figure_4_1742068262037209).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练数据集，我们准备应用一个可以建模艺术家流行度与票价之间关系的算法。我们将使用线性回归公式，该公式本质上是通过最小化线与实际数据点之间的距离来找到最佳拟合线的点。这条线代表一个函数，其斜率告诉你随着艺术家流行度的增加，票价将增加多少。这可以在[图
    4-4](#i04_chapter4_figure_4_1742068262037209)中看到。
- en: '![](assets/aaif_0404.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0404.png)'
- en: Figure 4-4\. The scatter plot with the linear regression line added for our
    training dataset
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 为我们的训练数据集添加了线性回归线的散点图
- en: Let’s say an artist has a popularity score of 77\. By applying the equation
    derived from the linear regression line, we can estimate the corresponding ticket
    price. In this case, the price would be something like $120 based on the trend
    we’ve established.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个艺术家的流行度得分为 77。通过应用从线性回归线推导出的方程，我们可以估计相应的票价。在这种情况下，价格将类似于我们建立的趋势中的 $120。
- en: The next step is to evaluate the accuracy of this regression model. Using the
    testing dataset, we can predict the ticket prices for each artist’s popularity
    score, shown in [Table 4-4](#i04_chapter4_table_4_1742068262048610).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是评估这个回归模型的准确性。使用测试数据集，我们可以预测每个艺术家流行度得分对应的票价，如[表 4-4](#i04_chapter4_table_4_1742068262048610)所示。
- en: Table 4-4\. The predicted ticket price
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-4\. 预测票价
- en: '| Artist popularity (*x*) | Actual ticket price (*y*) | Predicted ticket price
    (ŷ) |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 艺术家流行度 (*x*) | 实际票价 (*y*) | 预测票价 (ŷ) |'
- en: '| --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 35 | $45 | $50 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 35 | $45 | $50 |'
- en: '| 45 | $55 | $60 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 45 | $55 | $60 |'
- en: '| 55 | $65 | $70 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 55 | $65 | $70 |'
- en: '| 65 | $100 | $85 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 65 | $100 | $85 |'
- en: '| 80 | $135 | $120 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 80 | $135 | $120 |'
- en: '| 90 | $170 | $140 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 90 | $170 | $140 |'
- en: We can then plot these values on a chart, which you can see in [Figure 4-5](#i04_chapter4_figure_5_1742068262037231).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以在图表上绘制这些值，您可以在[图 4-5](#i04_chapter4_figure_5_1742068262037231)中看到。
- en: '![](assets/aaif_0405.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0405.png)'
- en: Figure 4-5\. The original dataset shown with actual and predicted ticket prices
    for the test data
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 显示了测试数据中实际和预测票价的原始数据集
- en: The original data points capture the historical trend while the test data highlights
    how closely the model’s predictions align with actual ticket prices. The chart
    makes it easy to visualize where the model performed well and where deviations
    occurred, particularly by comparing the actual and predicted ticket prices across
    different levels of artist popularity.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据点捕捉了历史趋势，而测试数据突出了模型的预测与实际票价之间的紧密程度。图表使得可视化模型表现良好的地方和出现偏差的地方变得容易，尤其是在比较不同艺术家流行度水平下的实际和预测票价时。
- en: In this case, the model performed fairly well. For midrange popularity scores,
    the predicted values are close to the actual values, indicating minimal error.
    However, at the lower (35) and higher (90) ends of the popularity scale, the model’s
    predictions underestimate the actual ticket prices. While the performance is promising,
    the noticeable deviations at these extremes suggest the model could benefit from
    additional fine-tuning to improve accuracy, especially for edge cases.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型表现相当不错。对于中等受欢迎程度的评分，预测值接近实际值，表明误差最小。然而，在受欢迎程度评分的较低端（35）和较高端（90），模型的预测低估了实际票价。虽然表现有希望，但这些极端情况下的明显偏差表明模型可能需要额外的微调来提高准确性，特别是对于边缘情况。
- en: Evaluation Metrics for Regression Models
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归模型的评估指标
- en: When it comes to measuring how well your regression model performs, there are
    a few handy metrics based on the differences between your predicted values and
    the actual ones.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到衡量你的回归模型表现如何时，有一些基于你的预测值和实际值之间差异的便捷指标。
- en: Mean absolute error
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平均绝对误差
- en: 'Imagine you’re predicting how many pizzas a group of friends will eat at a
    party. *Mean absolute error (MAE)* helps you figure out, on average, how far off
    your predictions were—whether you guessed too high or too low. For instance, if
    you predicted four pizzas but your friends ate seven, you missed by three. MAE
    ignores whether the difference is positive or negative, so it treats both -3 and
    +3 as a difference of 3\. If your absolute errors for a set of predictions were
    1, 2, 3, and 4 pizzas, the MAE would simply be the average of those numbers: 2.5
    pizzas.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在预测一群朋友在派对上会吃多少披萨。*平均绝对误差（MAE）* 帮助你了解，平均而言，你的预测偏差有多大——是预测过高还是过低。例如，如果你预测了四块披萨，但你的朋友们吃了七块，你差了三块。MAE
    忽略差异是正数还是负数，因此将 -3 和 +3 都视为 3 的差异。如果你的预测误差为 1、2、3 和 4 块披萨，那么 MAE 将是这些数字的平均值：2.5
    块披萨。
- en: Mean squared error
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方误差
- en: 'Sometimes, you want to give more weight to bigger errors. After all, consistently
    being off by one pizza isn’t as bad as being wildly off by five. That’s where
    *mean squared error (MSE)* comes in. Instead of just taking the differences as
    they are, you square each error (making bigger mistakes stand out), and then average
    those squared values. In our pizza example, if your errors were 1, 2, 3, and 4,
    squaring them gives you 1, 4, 9, and 16\. The MSE would then be the average of
    these squared errors: 7.5.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能想要给更大的误差赋予更多的权重。毕竟，一直差一块披萨并不像差五块那么糟糕。这就是 *均方误差（MSE）* 发挥作用的地方。不是简单地取误差值，而是将每个误差平方（使更大的错误更加突出），然后平均这些平方值。在我们的披萨例子中，如果你的误差是
    1、2、3 和 4，那么平方它们会得到 1、4、9 和 16。那么 MSE 将是这些平方误差的平均值：7.5。
- en: Root mean squared error
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方根误差
- en: While MSE is useful, those squared numbers don’t match up with the original
    quantities you were measuring, so they can feel a little abstract. If you want
    the error back in terms of pizzas (or whatever you’re predicting), you can take
    the square root of the MSE. That’s called the *root mean squared error (RMSE)*.
    In this case, the square root of 7.5 is about 2.74, meaning your average error
    is around 2.74 pizzas.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 MSE 很有用，但这些平方数与你要测量的原始数量不匹配，所以它们可能感觉有点抽象。如果你想用披萨（或你预测的任何东西）来表示误差，你可以取 MSE
    的平方根。这被称为 *均方根误差（RMSE）*。在这种情况下，7.5 的平方根大约是 2.74，这意味着你的平均误差大约是 2.74 块披萨。
- en: Coefficient of determination
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定系数
- en: What if you want to understand how well your model explains the variation in
    your data? Enter *R*², also called the *coefficient of determination*. This metric
    tells you how much of the difference between actual and predicted values your
    model accounts for.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解你的模型如何解释数据中的变化，那么请进入 *R*²，也称为 *确定系数*。这个指标告诉你你的模型解释了实际值和预测值之间差异的多少。
- en: For example, if you’re trying to predict how many cupcakes a bakery sells each
    day, *R*² tells you how much your model can explain. If your *R*² value is 0.85,
    that means your model explains 85% of the variation in cupcake sales—the rest
    might be due to some unexpected cupcake-related event, like a new bakery opening
    next door. *R*² ranges from 0 to 1, and the closer it is to 1, the better your
    model fits the data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你试图预测面包店每天卖出多少纸杯蛋糕，*R*² 会告诉你你的模型可以解释多少。如果你的 *R*² 值是 0.85，这意味着你的模型解释了纸杯蛋糕销售的
    85% 的变化——其余的可能是一些意外的纸杯蛋糕相关事件，比如隔壁新开了一家面包店。*R*² 的范围从 0 到 1，越接近 1，你的模型越适合数据。
- en: 'All of these metrics are certainly helpful. But in real-world scenarios, ML
    isn’t a one-shot deal. Data scientists typically train models over and over, tweaking
    different aspects to improve performance. Here’s what they adjust:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些指标当然很有帮助。但在现实世界的场景中，机器学习不是一次性的交易。数据科学家通常会反复训练模型，调整不同的方面以提高性能。以下是他们会调整的内容：
- en: Feature selection and preparation
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择和准备
- en: You can choose which factors or features to include in the model and how to
    tweak them for better results. For instance, maybe you realize that cupcake sales
    don’t depend just on weather but also on nearby events.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在模型中包含哪些因素或特征，以及如何调整它们以获得更好的结果。例如，您可能意识到纸杯蛋糕的销售不仅仅取决于天气，还取决于附近的活动。
- en: Algorithm selection
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 算法选择
- en: There’s more than one way to predict the number of cupcakes sold. While one
    algorithm might focus on simple linear relationships, another might use more complex
    patterns.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 预测销售的纸杯蛋糕数量的方法不止一种。虽然一个算法可能专注于简单的线性关系，另一个算法可能使用更复杂的模式。
- en: Algorithm parameters
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 算法参数
- en: These are the settings you adjust to fine-tune your algorithm. Think of them
    like the dials on an oven. If your cupcakes are coming out undercooked, you tweak
    the temperature (or in ML, the *hyperparameters*) to get better results.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是您调整以微调算法的设置。想象一下，它们就像烤箱上的旋钮。如果您的纸杯蛋糕没有烤熟，您会调整温度（或者在机器学习中，调整*超参数*）以获得更好的结果。
- en: After several rounds of this iterative process, you’ll settle on the version
    of the model that performs best for your specific problem.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几轮这样的迭代过程后，您将确定最适合您特定问题的模型版本。
- en: Let’s sum up what we have learned about regression analysis in [Table 4-5](#i04_chapter4_table_5_1742068262048633).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下我们在[表4-5](#i04_chapter4_table_5_1742068262048633)中学到的关于回归分析的内容。
- en: Table 4-5\. Key concepts in regression analysis
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-5\. 回归分析中的关键概念
- en: '| Factors | Description |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 因素 | 描述 |'
- en: '| --- | --- |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Purpose | To predict a numeric outcome label based on one or more predictor
    features by identifying patterns in historical data |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 目的 | 通过识别历史数据中的模式，根据一个或多个预测特征预测数值结果标签 |'
- en: '| Process |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 流程 |'
- en: Split data into training and testing sets.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集。
- en: Train the model to identify relationships.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型以识别关系。
- en: Test the model to make predictions.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试模型进行预测。
- en: Evaluate model accuracy and refine if needed.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型准确度并在必要时进行细化。
- en: '|'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Training the model | Uses an algorithm, such as linear regression, to analyze
    patterns in the training data, establishing a predictive relationship between
    the independent and dependent variables |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 训练模型 | 使用算法（如线性回归）分析训练数据中的模式，建立自变量和因变量之间的预测关系 |'
- en: '| Evaluation metrics |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 评估指标 |'
- en: 'MAE: Measures average prediction error without considering direction (over/underestimate)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MAE：衡量平均预测误差，不考虑方向（高估/低估）
- en: 'MSE: Emphasizes larger errors by squaring them'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MSE：通过平方来强调较大的误差
- en: 'RMSE: Provide the error in original measurement units'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RMSE：提供原始测量单位的误差
- en: 'R² (coefficient of determination): Indicates the model’s explanatory power,
    with values closer to 1 suggesting a better fit'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²（确定系数）：表示模型的解释力，值越接近1表示拟合度越好
- en: '|'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Classification
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: '*Classification* in ML is a supervised learning task where the goal is to predict
    the category or class to which a given data point belongs. It involves training
    a model on labeled data where the label is categorical, such as “yes” or “no.”
    The model learns the relationship between input features and output classes, enabling
    it to assign new, unseen data points to one of the predefined categories.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的**分类**是一个监督学习任务，其目标是预测给定数据点所属的类别或类别。它涉及在标记数据上训练模型，其中标签是分类的，例如“是”或“否”。模型学习输入特征与输出类别之间的关系，使其能够将新的、未见过的数据点分配到预定义的类别之一。
- en: There are various types of classification techniques. In the next few sections,
    we’ll take a look at binary and multiclass classification.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种类型的分类技术。在接下来的几节中，我们将探讨二分类和多分类。
- en: Binary Classification
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元分类
- en: '*Binary classification* is one of the most common types of classification tasks.
    At its core, it’s about predicting one of two possible outcomes. When you feed
    your model data, the goal is to get it to categorize new information into one
    of two buckets, often labeled as 0 and 1\. For example, if you’re building a model
    to predict whether an email is spam or not, binary classification is your go-to
    technique. Each email gets analyzed, and the model spits out a prediction: “spam”
    or “not spam.”'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**二元分类**是分类任务中最常见的一种类型。其核心是预测两种可能的结果之一。当你向模型提供数据时，目标是让它将新的信息分类到两个桶中的一个，通常标记为0和1。例如，如果你正在构建一个预测电子邮件是否为垃圾邮件的模型，二元分类是你的首选技术。每封电子邮件都会被分析，模型会给出预测：“垃圾邮件”或“非垃圾邮件”。'
- en: What makes binary classification different from something like regression is
    that you aren’t predicting a continuous value, like a temperature or a sales figure.
    Instead, you’re focused on making a choice between two discrete options. The model
    looks at the features of the data you provide, such as email content, and it uses
    that to assign a probability. Based on this probability, it then makes a final
    classification.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使二元分类与回归等不同之处在于，你并不是在预测一个连续值，如温度或销售额。相反，你专注于在两个离散选项之间做出选择。模型会查看你提供的数据的特征，如电子邮件内容，并使用这些信息分配一个概率。基于这个概率，然后做出最终的分类。
- en: 'Let’s walk through a simple example to show how binary classification works.
    Imagine we want to predict whether a person will default on a loan using one feature:
    their credit score (*x*). Our goal is to classify them into one of two categories:
    either they default (*y* = 1) or they don’t (*y* = 0). The model will learn from
    the data in [Table 4-6](#i04_chapter4_table_6_1742068262048658) to make predictions.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来展示二元分类是如何工作的。想象一下，我们想要使用一个特征来预测一个人是否会违约贷款：他们的信用分数（*x*）。我们的目标是将他们分类到两个类别之一：要么他们违约（*y*
    = 1），要么他们不违约（*y* = 0）。模型将从[表4-6](#i04_chapter4_table_6_1742068262048658)中的数据中学习以做出预测。
- en: Table 4-6\. Defaults based on credit scores
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-6\. 根据信用分数的违约情况
- en: '| Credit score (*x*) | Default? (*y*) |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 信用分数 (*x*) | 是否违约? (*y*) |'
- en: '| --- | --- |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 580 | 1 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 580 | 1 |'
- en: '| 720 | 0 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 720 | 0 |'
- en: '| 610 | 1 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 610 | 1 |'
- en: '| 750 | 0 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 750 | 0 |'
- en: '| 590 | 1 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 590 | 1 |'
- en: '| 800 | 0 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 800 | 0 |'
- en: Based on the patterns in the training data, the model will eventually predict
    whether someone is likely to default or not. As you can see, it’s about using
    past information to make a binary choice. In our example, people with a credit
    score of 610 or lower are predicted to default while anyone with a score of 720
    or higher is predicted not to default.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 根据训练数据中的模式，模型最终将预测某人是否可能违约。如您所见，这是关于使用过去的信息来做出二元选择。在我们的例子中，信用分数为610或以下的人被预测为会违约，而任何信用分数为720或更高的人被预测为不会违约。
- en: To train our model, we’ll use an algorithm that analyzes the training data and
    fits it to a function that calculates the probability of a person defaulting on
    a loan. For example, if the model predicts a probability of 0.8 for default, that
    means there’s an 80% chance the person will default and a 20% chance they won’t.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的模型，我们将使用一个分析训练数据并将其拟合到计算贷款违约概率的函数的算法。例如，如果模型预测违约概率为0.8，这意味着有80%的可能性该人将违约，有20%的可能性他们不会违约。
- en: There are several algorithms that handle binary classification, but *logistic
    regression* is a common choice. Logistic regression gives us an S-shaped curve,
    called a *sigmoid function*, that assigns values between 0 and 1 based on the
    input data. This is shown in [Figure 4-6](#i04_chapter4_figure_6_1742068262037256).
    Even though its name includes *regression*, the logistic regression algorithm
    is used for classification because it models the probability of different outcomes.
    This is a common topic for the exam.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 处理二元分类的算法有好几种，但**逻辑回归**是一个常见的选择。逻辑回归为我们提供了一个S形曲线，称为**sigmoid函数**，根据输入数据分配介于0和1之间的值。这如图[图4-6](#i04_chapter4_figure_6_1742068262037256)所示。尽管其名称中包含**回归**，但逻辑回归算法用于分类，因为它模型化了不同结果的可能性。这是考试的一个常见主题。
- en: '![](assets/aaif_0406.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aaif_0406.png)'
- en: Figure 4-6\. A sigmoid function showing the probability of loan default based
    on credit scores, with a threshold of 0.5 determining default (y = 1) or no default
    (y = 0)
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-6\. 一个sigmoid函数，显示了基于信用分数的贷款违约概率，阈值为0.5决定违约（y = 1）或未违约（y = 0）
- en: 'In this case, the curve shows the probability that someone will default (*y*
    = 1) based on their credit score (*x*). Mathematically, the model’s function can
    be represented like this:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，曲线显示了根据信用评分(*x*)某人违约(*y* = 1)的概率。从数学上讲，模型的函数可以表示如下：
- en: f(*x*) = P(*y* = 1 | *x*)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: f(*x*) = P(*y* = 1 | *x*)
- en: Note that for the exam, you will not have to memorize equations. They are used
    in this book as a way to better help you understand the concepts.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于考试，你不需要记住方程式。它们在这本书中作为帮助你更好地理解概念的一种方式被使用。
- en: For some people in the training data, we already know they defaulted (*y* =
    1), so the probability for them is 1.0\. For others who didn’t default, the probability
    is 0.0\. The sigmoid curve visually shows how the likelihood of default changes
    as credit scores increase.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练数据中的一些人，我们已知他们已经违约(*y* = 1)，因此他们的概率是1.0。对于其他人，他们没有违约，概率是0.0。双曲正切曲线直观地显示了违约可能性如何随着信用评分的增加而变化。
- en: In [Figure 4-6](#i04_chapter4_figure_6_1742068262037256), the dashed line at
    0.5 serves as the threshold for our model’s predictions. When the calculated probability
    is at or above 0.5, the model predicts that the person will default (*y* = 1).
    If the probability falls below 0.5, the prediction is that they won’t default
    (*y* = 0). For instance, if someone has a credit score of 580, and the model assigns
    a 0.9 probability of default, that’s well above the threshold, meaning the model
    would predict this person is likely to default.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图4-6](#i04_chapter4_figure_6_1742068262037256)中，0.5的虚线作为我们模型预测的阈值。当计算出的概率达到或超过0.5时，模型预测该人将违约(*y*
    = 1)。如果概率低于0.5，预测结果是他们不会违约(*y* = 0)。例如，如果某人的信用评分为580，并且模型分配了0.9的违约概率，这远远高于阈值，意味着模型会预测这个人很可能违约。
- en: Just like with regression models, when you train a binary classification model,
    it’s essential to hold back a set of data to validate how well the model performs.
    Let’s say we kept the credit score data in [Table 4-7](#i04_chapter4_table_7_1742068262048681)
    aside to validate our model predicting loan defaults.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 就像回归模型一样，当你训练一个二元分类模型时，保留一部分数据来验证模型的表现是非常重要的。比如说，我们将[表4-7](#i04_chapter4_table_7_1742068262048681)中的信用评分数据留出以验证我们预测贷款违约的模型。
- en: Table 4-7\. Data used to validate the predictions for loan defaults
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-7\. 验证贷款违约预测所使用的数据
- en: '| Credit score (*x*) | Default? (*y*) |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 信用评分(*x*) | 是否违约(*y*) |'
- en: '| --- | --- |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 62 | 0 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 62 | 0 |'
- en: '| 108 | 1 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 108 | 1 |'
- en: '| 113 | 1 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 113 | 1 |'
- en: '| 70 | 0 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 70 | 0 |'
- en: '| 88 | 1 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 88 | 1 |'
- en: '| 91 | 1 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 91 | 1 |'
- en: We can apply the logistic function we trained earlier to these values, which
    you can see in [Figure 4-7](#i04_chapter4_figure_7_1742068262037277).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将之前训练的逻辑函数应用于这些值，如图[图4-7](#i04_chapter4_figure_7_1742068262037277)所示。
- en: '![](assets/aaif_0407.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0407.png)'
- en: Figure 4-7\. A sigmoid function used to evaluate a binary classification model
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-7\. 用于评估二元分类模型的双曲正切函数
- en: Based on whether the calculated probability is above or below the threshold
    (usually 0.5), the model will predict either a default (1) or no default (0) for
    each credit score. We can then compare the predicted defaults (ŷ) to the actual
    defaults (*y*), as shown in [Table 4-8](#i04_chapter4_table_8_1742068262048704).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 根据计算出的概率是否高于或低于阈值（通常是0.5），模型将为每个信用评分预测违约（1）或无违约（0）。然后我们可以将预测的违约（ŷ）与实际违约（*y*）进行比较，如图[表4-8](#i04_chapter4_table_8_1742068262048704)所示。
- en: Table 4-8\. Comparing the predicted defaults to the actual defaults
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-8\. 比较预测违约与实际违约
- en: '| Credit score (*x*) | Actual default (*y*) | Predicted default (*ŷ*) |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 信用评分(*x*) | 实际违约(*y*) | 预测违约(*ŷ*) |'
- en: '| --- | --- | --- |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 62 | 0 | 0 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 62 | 0 | 0 |'
- en: '| 108 | 1 | 1 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 108 | 1 | 1 |'
- en: '| 113 | 1 | 1 |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 113 | 1 | 1 |'
- en: '| 70 | 0 | 0 |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 70 | 0 | 0 |'
- en: '| 88 | 1 | 0 |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 88 | 1 | 0 |'
- en: '| 91 | 1 | 1 |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 91 | 1 | 1 |'
- en: This comparison helps us see where the model is getting it right and where it
    might need improvement.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这种比较有助于我们了解模型在哪些地方做得正确，在哪些地方可能需要改进。
- en: Evaluation Metrics for Binary Classification
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元分类评估指标
- en: The first step in calculating evaluation metrics for a binary classification
    model is usually to create a *confusion matrix* of the number of correct and incorrect
    predictions for each possible class label, as you can see in [Table 4-9](#i04_chapter4_table_9_1742068262048724).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 计算二元分类模型评估指标的第一步通常是创建一个包含每个可能类别标签的正确和错误预测数量的*混淆矩阵*，正如你在[表4-9](#i04_chapter4_table_9_1742068262048724)中看到的。
- en: Table 4-9\. Confusion matrix
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-9\. 混淆矩阵
- en: '|   | Positive | Negative |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|   | 正面 | 负面 |'
- en: '| --- | --- | --- |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Positive** | 30 | 45 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| **正类** | 30 | 45 |'
- en: '| **Negative** | 20 | 19 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| **负类** | 20 | 19 |'
- en: The rows represent the actual values, labeled as “positive” or “negative,” while
    the columns show the predicted values. For example, the model predicted the positive
    class correctly 30 times, which is displayed as the true positive count. However,
    it also made 45 incorrect predictions where it classified negatives as positives.
    Similarly, there are 20 instances of false negatives and 19 true negatives. This
    distribution helps evaluate the accuracy and types of errors in the model’s predictions.
    One way to express the different possibilities for the confusion matrix is shown
    in [Table 4-10](#i04_chapter4_table_10_1742068262048744).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 行代表实际值，标记为“正类”或“负类”，而列显示预测值。例如，模型正确预测了30次正类，这显示为真阳性计数。然而，它还做出了45次错误的预测，将负类错误地分类为正类。同样，有20个假阴性实例和19个真阴性实例。这种分布有助于评估模型预测的准确性和错误类型。表示混淆矩阵不同可能性的方法之一显示在[表
    4-10](#i04_chapter4_table_10_1742068262048744)中。
- en: Table 4-10\. Confusion matrix with descriptions
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-10\. 带描述的混淆矩阵
- en: '|   | Positive | Negative |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|   | 正类 | 负类 |'
- en: '| --- | --- | --- |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Positive** | True positive | False positive |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| **正类** | 真阳性 | 假阳性 |'
- en: '| **Negative** | False negative | True negative |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| **负类** | 假阴性 | 真阴性 |'
- en: 'The rows and columns follow the same arrangement, but each cell now includes
    a label: true positive, false positive, false negative, and true negative. These
    labels offer a clearer understanding of the relationship between predicted and
    actual outcomes:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 行和列遵循相同的排列，但现在每个单元格都包含一个标签：真阳性、假阳性、假阴性和真阴性。这些标签提供了对预测结果和实际结果之间关系的更清晰理解：
- en: True positive (TP)
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性 (TP)
- en: The model predicted the positive class, and the actual class was also positive.
    This is a correct prediction for the positive class.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测了正类，实际类别也是正类。这是正类的正确预测。
- en: False positive (FP)
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性 (FP)
- en: The model predicted the positive class, but the actual class was negative. This
    is an incorrect prediction, often referred to as a *type I error*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测了正类，但实际类别是负类。这是一个错误的预测，通常被称为*第一类错误*。
- en: False negative (FN)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 假阴性 (FN)
- en: The model predicted the negative class, but the actual class was positive. This
    is another incorrect prediction, known as a *type II error*.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测了负类，但实际类别是正类。这是另一种错误的预测，被称为*第二类错误*。
- en: True negative (TN)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 真阴性 (TN)
- en: The model predicted the negative class, and the actual class was also negative.
    This is a correct prediction for the negative class.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测了负类，实际类别也是负类。这是负类的正确预测。
- en: 'Calling this a *confusion matrix* is certainly apt: it can be tough to understand
    this. Yet the confusion matrix is likely to be on the exam. This is why it’s a
    good idea to memorize the four outcomes.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 将其称为*混淆矩阵*确实很恰当：理解这一点可能有些困难。然而，混淆矩阵很可能会出现在考试中。这就是为什么记住这四种结果是个好主意。
- en: Let’s now take a look at other common evaluation metrics.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看其他常见的评估指标。
- en: Accuracy
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准确率
- en: 'One basic metric derived from the confusion matrix is *accuracy*, which is
    simply the proportion of correct predictions out of the total. It’s calculated
    as:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵衍生出的一个基本指标是*准确率*，它只是正确预测占总预测的比例。它计算如下：
- en: Accuracy = (TN + TP) ÷ (TN + FN + FP + TP)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率 = (TN + TP) ÷ (TN + FN + FP + TP)
- en: 'For our credit score example, the calculation is:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的信用评分示例，计算如下：
- en: (2 + 3) ÷ (2 + 1 + 0 + 3) = 5 ÷ 6 = 0.83
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: (2 + 3) ÷ (2 + 1 + 0 + 3) = 5 ÷ 6 = 0.83
- en: This means our model correctly predicted loan defaults 83% of the time. While
    accuracy seems like a good measure, it can be misleading if the data is imbalanced.
    For instance, if only a small percentage of people default, a model could predict
    no default for everyone and still achieve high accuracy, but it wouldn’t truly
    capture the patterns in the ​data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们的模型在预测贷款违约时正确率达到了83%。虽然准确率看起来是一个很好的指标，但如果数据不平衡，它可能会产生误导。例如，如果只有一小部分人违约，模型可以预测所有人都不会违约，并仍然达到高准确率，但它不会真正捕捉到数据中的模式。
- en: Recall
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 召回率
- en: '*Recall* measures how well the model identifies positive cases (people who
    defaulted on a loan). It’s calculated as:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率*衡量模型识别正类（贷款违约的人）的能力。它计算如下：'
- en: Recall = TP ÷ (TP + FN)
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率 = TP ÷ (TP + FN)
- en: 'For our example, the calculation is:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，计算如下：
- en: 3 ÷ (3 + 1) = 3 ÷ 4 = 0.75
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 3 ÷ (3 + 1) = 3 ÷ 4 = 0.75
- en: So our model correctly identified 75% of those who defaulted.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的模型正确地识别了75%的违约者。
- en: Precision
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精确率
- en: '*Precision* tells us how accurate the positive predictions are—that is, how
    many of the predicted defaults were actual defaults. It’s calculated as:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度*告诉我们正预测的准确性——也就是说，预测的违约中有多少是实际违约。它是这样计算的：'
- en: Precision = TP ÷ (TP + FP)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度 = TP ÷ (TP + FP)
- en: 'In our case, the calculation is:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这个例子中，计算公式是：
- en: 3 ÷ (3 + 0) = 3 ÷ 3 = 1.0
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 3 ÷ (3 + 0) = 3 ÷ 3 = 1.0
- en: This means that every time the model predicted a default, it was correct 100%
    of the time.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每次模型预测违约时，它都是 100% 正确的。
- en: F1 score
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F1 分数
- en: The *F1 score* provides a harmonic mean between precision and recall, which
    is a type of average that emphasizes the smaller values in a dataset. The harmonic
    mean is calculated as the reciprocal of the average of the reciprocals of the
    values, ensuring that both precision and recall are given equal weight. Unlike
    accuracy, which can be misleading when dealing with imbalanced datasets, the F1
    score takes both false positives and false negatives into account, offering a
    more nuanced view of a model’s effectiveness.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '*F1 分数*提供了精确度和召回率之间的调和平均数，这是一种强调数据集中较小值的平均数类型。调和平均数是通过计算值的倒数平均数的倒数来计算的，确保精确度和召回率都得到同等重视。与处理不平衡数据集时可能具有误导性的准确度不同，F1
    分数考虑了假正例和假负例，为模型的有效性提供了一个更细致的视角。'
- en: 'The formula is:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 公式是：
- en: F1 score = 2 × Precision × Recall ÷ Precision + Recall
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数 = 2 × 精确度 × 召回率 ÷ 精确度 + 召回率
- en: 'For our example, the calculation is:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的例子，计算公式是：
- en: 2 × 1.0 × 0.75 ÷ 1.0 + 0.75 = 1.5 ÷ 1.75 = 0.86
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 2 × 1.0 × 0.75 ÷ 1.0 + 0.75 = 1.5 ÷ 1.75 = 0.86
- en: The resulting F1 score of 0.86 indicates that the model achieves a good balance
    between precision and recall, performing effectively in correctly identifying
    positive cases while minimizing false positives and false negatives.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的 F1 分数为 0.86，表明模型在精确度和召回率之间取得了良好的平衡，在正确识别正例的同时，最大限度地减少了误报和漏报。
- en: Area under the curve
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 曲线下面积
- en: Another way to think about recall is to call it the *true positive rate (TPR)*,
    which shows how well the model identifies positive cases (defaults, in our example).
    On the flip side, we also have the *false positive rate (FPR)*, which measures
    how often the model incorrectly predicts a default when there wasn’t one. The
    FPR is calculated as FP ÷ (FP + TN). In our case, since there were no false positives,
    the FPR is 0 ÷ 2 = 0.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考召回率的方式是将其称为 *真正例率 (TPR)*，它显示了模型识别正例（在我们的例子中是违约）的能力。另一方面，我们还有 *假正例率 (FPR)*，它衡量模型在实际上没有违约的情况下错误预测违约的频率。FPR
    是通过 FP ÷ (FP + TN) 计算得出的。在我们的例子中，由于没有假正例，FPR 是 0 ÷ 2 = 0。
- en: Now, if we adjust the threshold for predicting a default (for instance, moving
    it higher or lower than 0.5), that would change the balance of positive and negative
    predictions, which means both the TPR and FPR would shift. A common way to visualize
    this is by plotting a *receiver operating characteristic (ROC) curve*, which compares
    the TPR and FPR across all possible threshold values. [Figure 4-8](#i04_chapter4_figure_8_1742068262037296)
    illustrates this.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们调整预测违约的阈值（例如，将其移动到 0.5 以上或以下），这将改变正负预测的平衡，这意味着 TPR 和 FPR 都会发生变化。一种常见的可视化方法是绘制
    *接收者操作特征 (ROC) 曲线*，它比较了所有可能阈值下的 TPR 和 FPR。[图 4-8](#i04_chapter4_figure_8_1742068262037296)
    展示了这一点。
- en: '![](assets/aaif_0408.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0408.png)'
- en: Figure 4-8\. ROC plots the true positive and false positive rates
  id: totrans-293
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-8\. ROC 绘制了真正例和假正例率
- en: The perfect ROC curve would shoot straight up along the TPR axis and then run
    across the top, giving it an area under the curve (AUC) of 1.0, as shown in [Figure 4-8](#i04_chapter4_figure_8_1742068262037296).
    This means that the model makes perfect predictions. A completely random model
    would follow a diagonal line, with an AUC of 0.5—basically just guessing. For
    our credit score example, let’s assume we generated the ROC curve and the AUC
    is 0.875\. This tells us that the model is much better than guessing and performs
    well in predicting loan defaults.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 完美的 ROC 曲线将直接沿着 TPR 轴向上延伸，然后穿过顶部，使其曲线下面积 (AUC) 为 1.0，如图 [图 4-8](#i04_chapter4_figure_8_1742068262037296)
    所示。这意味着模型做出了完美的预测。一个完全随机的模型将遵循对角线，AUC 为 0.5——基本上就是猜测。对于我们的信用评分示例，假设我们生成了 ROC 曲线和
    AUC 为 0.875。这告诉我们，模型比猜测要好得多，并且在预测贷款违约方面表现良好。
- en: '[Table 4-11](#i04_chapter4_table_11_1742068262048765) sums up what we have
    learned about binary classification.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 4-11](#i04_chapter4_table_11_1742068262048765) 总结了我们关于二元分类所学的知识。'
- en: Table 4-11\. Key concepts in binary classification
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-11\. 二元分类中的关键概念
- en: '| Factors | Definition |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 因素 | 定义 |'
- en: '| --- | --- |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Purpose | To categorize data into one of two distinct classes, often labeled
    as 0 and 1, such as predicting “spam” versus “not spam” or “default” versus “no
    default” |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 目的 | 将数据分类到两个不同的类别之一，通常标记为0和1，例如预测“垃圾邮件”与“非垃圾邮件”或“违约”与“无违约” |'
- en: '| Process |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 流程 |'
- en: Split data into training and testing sets.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集。
- en: Train the model to classify based on patterns in the data.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型以根据数据中的模式进行分类。
- en: Test and validate model accuracy on new data.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新数据上测试和验证模型准确性。
- en: '|'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Training the model | Commonly uses logistic regression to fit a function
    that estimates the probability of an outcome between 0 and 1, applying a threshold
    (e.g., 0.5) to classify results |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 训练模型 | 通常使用逻辑回归来拟合一个估计结果在0到1之间的概率的函数，应用一个阈值（例如，0.5）来分类结果 |'
- en: '| Evaluation metrics |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 评估指标 |'
- en: 'Accuracy: Overall correct predictions divided by total predictions'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率：总体正确预测除以总预测数
- en: 'Confusion matrix: A table that summarizes the performance of a classification
    model by displaying the counts of TPs, FPs, TNs, and FNs.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵：一个表格，通过显示TPs、FPs、TNs和FNs的数量来总结分类模型的性能。
- en: 'Recall: TPR assessing how well the model identifies positive cases'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率：TPR评估模型识别正例的能力
- en: 'Precision: Accuracy of positive predictions'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率：正预测的准确性
- en: 'F1 score: Harmonic mean of precision and recall for balanced evaluation'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1分数：精确率和召回率的调和平均值，用于平衡评估
- en: 'AUC: Measures the model’s ability to distinguish between classes across all
    thresholds, with 1.0 indicating a perfect classifier'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AUC：衡量模型在所有阈值下区分类别的能力，1.0表示完美的分类器
- en: '|'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Multiclass Classification
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类
- en: When you’re working with *multiclass classification*, you’re figuring out which
    category, out of several, best fits a specific observation. This is based on calculating
    the likelihood of various outcomes. It allows a model to predict which option
    is most likely for a given case.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 当你进行 *多类分类* 时，你正在确定几个类别中哪一个最适合特定的观察结果。这是基于计算各种结果的可能性。它允许模型预测在给定情况下哪个选项最有可能。
- en: 'Let’s use a group of flowers as an example. For each flower, we’ve measured
    the petal length (*x*), and we’re trying to predict the flower type (*y*), which
    could be one of the following:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 以下以一组花朵为例。对于每一朵花，我们已经测量了花瓣长度 (*x*)，并试图预测花朵类型 (*y*)，这可能是以下之一：
- en: 0 = rose
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 = 玫瑰
- en: 1 = daisy
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 = 雏菊
- en: 2 = tulip
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 = 郁金香
- en: Of course, in a real-world scenario, you’d usually have more than just one feature
    (*x*) to work with. But for simplicity, we’re sticking to a single feature here.
    The data is in [Table 4-12](#i04_chapter4_table_12_1742068262048789).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在现实世界的场景中，你通常会处理不止一个特征 (*x*)。但为了简单起见，我们在这里坚持使用单个特征。数据在[表4-12](#i04_chapter4_table_12_1742068262048789)中。
- en: Table 4-12\. The relationship between petal length and flower type
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-12\. 花瓣长度与花朵类型之间的关系
- en: '| Petal length (*x*) | Flower type (*y*) |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣长度 (*x*) | 花朵类型 (*y*) |'
- en: '| --- | --- |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 167 | 0 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 167 | 0 |'
- en: '| 172 | 0 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 172 | 0 |'
- en: '| 225 | 2 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 225 | 2 |'
- en: '| 197 | 1 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 197 | 1 |'
- en: '| 189 | 1 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 189 | 1 |'
- en: '| 232 | 2 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 232 | 2 |'
- en: '| 158 | 0 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 158 | 0 |'
- en: 'To train our model, we need to select an algorithm, and we have two main options
    to choose from: one-vs-rest (OVR) and multinomial.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的模型，我们需要选择一个算法，我们有两种主要选项可供选择：一对余（OVR）和多项式。
- en: One-vs-rest algorithms
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一对余算法
- en: 'With OVR, the idea is to build a separate binary classification model for each
    class. Each model decides whether a given observation belongs to its specific
    class. Using our flower example, this method would create three models:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OVR，想法是为每个类别构建一个独立的二元分类模型。每个模型决定一个给定的观察结果是否属于其特定的类别。以我们的花朵为例，这种方法将创建三个模型：
- en: Model 1
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 1
- en: Determines if a flower is a rose (class 0)
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 确定花朵是否为玫瑰（类别0）
- en: Model 2
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 2
- en: Determines if a flower is a daisy (class 1)
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 确定花朵是否为雏菊（类别1）
- en: Model 3
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 3
- en: Determines if a flower is a tulip (class 2)
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 确定花朵是否为郁金香（类别2）
- en: Each model calculates a probability between 0 and 1\. The class with the highest
    probability is selected as the prediction.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型计算一个介于0和1之间的概率。具有最高概率的类别被选为预测。
- en: Multinomial algorithms
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多项式算法
- en: A multinomial algorithm generates a single function that produces a probability
    distribution for all the classes at once. Instead of having multiple models, it
    gives you a vector with probabilities for each class, and the total of these probabilities
    always equals 1.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式算法生成一个函数，该函数一次产生所有类别的概率分布。它不是拥有多个模型，而是给你一个包含每个类别的概率向量的向量，这些概率的总和始终等于1。
- en: 'For example, you might get an output like this:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能会得到这样的输出：
- en: '[0.2, 0.3, 0.5]'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '[0.2, 0.3, 0.5]'
- en: This means there’s a 20% chance the flower is a rose, a 30% chance it’s a daisy,
    and a 50% chance it’s a tulip. Since 0.5 is the highest, the model predicts tulip.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着有 20% 的可能性这朵花是玫瑰，30% 的可能性是菊花，50% 的可能性是郁金香。由于 0.5 是最高的，模型预测郁金香。
- en: No matter which algorithm you go with, the model uses these probabilities to
    predict the most likely class for any observation.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪种算法，模型都会使用这些概率来预测任何观察结果的最可能类别。
- en: Evaluation of a Multiclass Classification Model
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类模型评估
- en: You can measure the performance of a multiclass classifier by calculating binary
    metrics for each individual class or by using aggregate metrics that consider
    all classes together. [Table 4-13](#i04_chapter4_table_13_1742068262048811) shows
    the evaluation for our flower example.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过计算每个单独类别的二进制指标或使用考虑所有类别的聚合指标来衡量多类分类器的性能。[表 4-13](#i04_chapter4_table_13_1742068262048811)
    显示了我们花朵示例的评估。
- en: Table 4-13\. Measuring the performance of a multiclass classifier
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-13\. 评估多类分类器的性能
- en: '| Petal length (*x*) | Actual flower (*y*) | Predicted flower (ŷ) |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣长度 (*x*) | 实际花朵 (*y*) | 预测花朵 (ŷ) |'
- en: '| --- | --- | --- |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 165 | 0 | 0 |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 165 | 0 | 0 |'
- en: '| 171 | 0 | 0 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 171 | 0 | 0 |'
- en: '| 205 | 1 | 1 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 205 | 1 | 1 |'
- en: '| 195 | 1 | 1 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 195 | 1 | 1 |'
- en: '| 183 | 1 | 1 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 183 | 1 | 1 |'
- en: '| 221 | 2 | 2 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 221 | 2 | 2 |'
- en: '| 214 | 2 | 2 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 214 | 2 | 2 |'
- en: The confusion matrix for a multiclass classifier works similarly to the confusion
    matrix for a binary one, but instead of two classes, it captures predictions across
    multiple classes. This shows the number of predictions for each combination of
    actual and predicted class labels. [Figure 4-9](#i04_chapter4_figure_10_1742068262037358)
    displays the confusion matrix.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类器的混淆矩阵与二类分类器的混淆矩阵工作原理类似，但它不是捕捉两个类别的预测，而是捕捉多个类别的预测。这显示了实际和预测类别标签组合的预测数量。[图
    4-9](#i04_chapter4_figure_10_1742068262037358) 显示了混淆矩阵。
- en: '![](assets/aaif_0409.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0409.png)'
- en: Figure 4-9\. Confusion matrix showing the actual and predicted flower classes
  id: totrans-361
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. 实际和预测的花类混淆矩阵
- en: From this confusion matrix, we can figure out the key metrics for each flower
    class, listed in [Table 4-14](#i04_chapter4_table_14_1742068262048835).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个混淆矩阵中，我们可以找出每个花朵类别的关键指标，列在[表 4-14](#i04_chapter4_table_14_1742068262048835)
    中。
- en: Table 4-14\. Confusion matrix for the key metrics for each flower class
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-14\. 每个花朵类别的关键指标混淆矩阵
- en: '| Class | TP | TN | FP | FN | Accuracy | Recall | Precision | F1 score |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | TP | TN | FP | FN | 准确率 | 召回率 | 精确率 | F1 分数 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 2 | 5 | 0 | 0 | 1.0 | 1.0 | 1.0 | 1.0 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 2 | 5 | 0 | 0 | 1.0 | 1.0 | 1.0 | 1.0 |'
- en: '| 1 | 2 | 4 | 1 | 0 | 0.86 | 1.0 | 0.67 | 0.8 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 4 | 1 | 0 | 0.86 | 1.0 | 0.67 | 0.8 |'
- en: '| 2 | 2 | 4 | 0 | 1 | 0.86 | 0.67 | 1.0 | 0.8 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2 | 4 | 0 | 1 | 0.86 | 0.67 | 1.0 | 0.8 |'
- en: 'To get the overall accuracy, recall, and precision for the model, we sum the
    values for TPs, TNs, FPs, and FNs:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得模型的总体准确率、召回率和精确率，我们将 TP、TN、FP 和 FN 的值相加：
- en: Overall accuracy = (13 + 6) ÷ (13 + 6 + 1 + 1) = 0.90
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 总体准确率 = (13 + 6) ÷ (13 + 6 + 1 + 1) = 0.90
- en: Overall recall = 6 ÷ (6 + 1) = 0.86
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 总体召回率 = 6 ÷ (6 + 1) = 0.86
- en: Overall precision = 6 ÷ (6 + 1) = 0.86
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 总体精确率 = 6 ÷ (6 + 1) = 0.86
- en: 'Finally, the overall F1 score is calculated using the overall recall and precision
    values:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用总体召回率和精确率值计算总体 F1 分数：
- en: Overall F1 score = (2 × 0.86 × 0.86) ÷ (0.86 + 0.86) = 0.86
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 总体 F1 分数 = (2 × 0.86 × 0.86) ÷ (0.86 + 0.86) = 0.86
- en: These metrics help us understand how well our flower classifier is performing
    across all  classes.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标帮助我们了解我们的花朵分类器在所有类别上的表现如何。
- en: Let’s sum up what we have learned about multiclass classification in [Table 4-15](#i04_chapter4_table_15_1742068262048858).
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下关于多类分类我们在[表 4-15](#i04_chapter4_table_15_1742068262048858)中学到的内容。
- en: Table 4-15\. Key concepts in multiclass classification
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-15\. 多类分类中的关键概念
- en: '| Factors | Description |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| 因素 | 描述 |'
- en: '| --- | --- |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Purpose | To categorize data into one of multiple possible classes by estimating
    the likelihood of each class for a given observation, such as predicting flower
    types based on features like petal length |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 目的 | 通过估计给定观察结果（如根据花瓣长度等特征预测花朵类型）的每个类别的可能性，将数据分类到多个可能的类别之一 |'
- en: '| Process |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 处理过程 |'
- en: Select and train a model using either OVR or multinomial algorithms.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 OVR 或多项式算法中选择和训练模型。
- en: Predict the class based on the highest probability output.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据最高概率输出预测类别。
- en: Evaluate accuracy and refine the model as needed.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据需要评估准确度并改进模型。
- en: '|'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Modeling techniques |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 建模技术 |'
- en: 'OVR: Builds a binary classifier for each class to predict if a given observation
    belongs to that class'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OVR：为每个类别构建一个二元分类器来预测给定的观察值是否属于该类别
- en: 'Multinomial: Uses a single model that outputs probabilities for all classes
    simultaneously, with the highest probability indicating the predicted class'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式：使用单个模型同时输出所有类别的概率，最高概率表示预测的类别
- en: '|'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Evaluation metrics |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 评估指标 |'
- en: 'Confusion matrix: Visualizes correct and incorrect predictions across all classes'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵：可视化所有类别的正确和错误预测
- en: 'Accuracy, recall, precision, and F1 score: Calculated per class and as an aggregate
    to gauge overall performance'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、召回率、精确率和F1分数：按类别和汇总计算，以评估整体性能
- en: '|'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Clustering
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: '*Clustering* is an ML technique used to organize data into groups, or clusters,
    based on the similarity of their features. It falls under the category of unsupervised
    learning because it does not rely on prelabeled data to identify these groups.
    Instead, the algorithm analyzes the data’s features and assigns each data point
    to a cluster based on shared characteristics. In essence, the clusters act as
    labels generated by the model after analyzing the inherent structure of the data.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '*聚类*是一种机器学习技术，用于根据数据的特征相似性将数据组织成组或聚类。它属于无监督学习类别，因为它不依赖于预先标记的数据来识别这些组。相反，算法分析数据的特征，并根据共享特征将每个数据点分配到聚类中。本质上，聚类是模型在分析数据的内在结构后生成的标签。'
- en: Clustering is particularly useful in scenarios where you need to uncover hidden
    patterns or groupings within data. For example, it can help in market segmentation,
    where customers are grouped based on purchasing behavior, or in biology, where
    genes with similar functions are grouped together. It’s also valuable for anomaly
    detection, such as identifying unusual transactions in fraud detection, or in
    image segmentation to group pixels into distinct regions.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类在需要揭示数据中的隐藏模式或分组的情况下特别有用。例如，它可以帮助市场细分，根据购买行为将客户分组，或在生物学中，将具有相似功能的基因分组在一起。它对于异常检测也很有价值，例如在欺诈检测中识别不寻常的交易，或在图像分割中将像素分组到不同的区域。
- en: 'Let’s take a look at a more detailed example. Suppose you’re a marine biologist
    studying a group of fish. Instead of focusing on identifying the species, you’re
    only interested in grouping the fish based on two characteristics: the length
    of the fish and the number of fins. The data is in [Table 4-16](#i04_chapter4_table_16_1742068262048881).'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个更详细的例子。假设你是一位海洋生物学家，正在研究一群鱼。你只对根据鱼的长度和鳍数这两个特征对鱼进行分组感兴趣，而不是专注于识别物种。数据在[表4-16](#i04_chapter4_table_16_1742068262048881)中。
- en: Table 4-16\. Grouping of fish based on similarities in length and fin count
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-16\. 基于长度和鳍数相似性的鱼分组
- en: '| Length (*x*1) | Fins (*x*2) |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 长度 (*x*1) | 尾鳍 (*x*2) |'
- en: '| --- | --- |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 10 | 3 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 3 |'
- en: '| 12 | 4 |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 4 |'
- en: '| 15 | 2 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 2 |'
- en: '| 15 | 2 |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 2 |'
- en: '| 16 | 5 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 16 | 5 |'
- en: '| 18 | 6 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 18 | 6 |'
- en: '| 20 | 2 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 2 |'
- en: '| 22 | 5 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 22 | 5 |'
- en: '| 24 | 6 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 24 | 6 |'
- en: In this case, the goal is to cluster fish with similar lengths and fin counts
    together, not to classify them into any specific species.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，目标是把具有相似长度和鳍数的鱼聚在一起，而不是将它们分类到任何特定的物种中。
- en: There are several ways to approach clustering. One of the most popular methods
    is called *k-means clustering*.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以处理聚类。最流行的方法之一被称为*k-均值聚类*。
- en: Let’s see how to do this. First, you turn your data into vectors, which means
    assigning each data point a coordinate in a space. If you have two features, like
    the length of a fish (*x*1) and the number of fins (*x*2), these become two coordinates—[x1,
    x2]—that can be plotted on a two-dimensional graph.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何做这件事。首先，你需要将你的数据转换成向量，这意味着为每个数据点在空间中分配一个坐标。如果你有两个特征，比如鱼的长度 (*x*1) 和鳍的数量
    (*x*2)，这些就变成了两个坐标——[x1, x2]——可以在二维图上绘制。
- en: Next, you decide how many clusters you want. Let’s say you choose three clusters
    (*k* = 3). You randomly place three points on the graph to represent the centers
    of your clusters, called *centroids*. Then, each fish is assigned to the centroid
    it is closest to. The centroid itself is recalculated to be the average of the
    data points (fish) assigned to it.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你决定你想要多少个聚类。假设你选择了三个聚类（*k* = 3）。你随机在图上放置三个点来代表你聚类的中心，称为*质心*。然后，每条鱼被分配到最近的质心。质心本身被重新计算为分配给它的数据点（鱼）的平均值。
- en: 'This process repeats: as the centroids move, some fish may become closer to
    a different centroid, so the assignments change. This back-and-forth of reassigning
    fish to clusters and adjusting the centroids continues until the groups become
    stable. You can see this in [Figure 4-10](#i04_chapter4_figure_11_1742068262037379).'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程会重复：随着质心的移动，一些鱼可能离不同的质心更近，因此分配会改变。将鱼重新分配到簇和调整质心的这种来回过程会一直持续到组变得稳定。您可以在[图
    4-10](#i04_chapter4_figure_11_1742068262037379)中看到这一点。
- en: '![](assets/aaif_0410.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0410.png)'
- en: Figure 4-10\. The clusters of fish grouped by length and number of fins
  id: totrans-416
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. 按长度和鳍的数量分组的鱼簇
- en: 'Since there’s no known label to which to compare the cluster assignments, the
    effectiveness of a clustering model is judged by how well the clusters are distinct
    from one another. You can use several metrics to measure how well the clusters
    are separated:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有已知的标签可以与簇分配进行比较，因此聚类模型的有效性是通过簇之间的分离程度来评估的。您可以使用几个指标来衡量簇的分离程度：
- en: Average distance to cluster center
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 平均到簇中心的距离
- en: Measures how close, on average, each point in the cluster is to the centroid
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量簇中每个点到质心的平均距离
- en: Average distance to other centers
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 到其他中心的平均距离
- en: Looks at how close, on average, each point in the cluster is to the centroids
    of other clusters
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 看看簇中的每个点平均距离其他簇的质心有多近
- en: Maximum distance to cluster center
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 到簇中心的最大距离
- en: Finds the farthest point from the centroid within the cluster
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在簇内找到离质心最远的点
- en: Silhouette score
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓分数
- en: A number between -1 and 1 that shows how well separated the clusters are (with
    1 indicating the best separation)
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 一个介于 -1 和 1 之间的数字，表示簇之间的分离程度（1 表示最佳分离）
- en: Deep Learning
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习
- en: DL is a more sophisticated type of ML that tries to mimic how our brains learn.
    At its core, DL relies on what’s called an *artificial neural network*, which
    behaves similarly to how biological neurons work by using mathematical functions.
    These artificial neural networks consist of multiple layers of neurons, which
    creates a structure that processes data through increasingly complex layers. This
    is why the method is called “deep” learning, and the resulting models are known
    as *deep neural networks (DNNs)*. You can apply DL to various tasks, such as predicting
    outcomes (regression), classifying data, and even more complex problems like understanding
    language or recognizing images.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是一种更复杂的机器学习类型，试图模仿我们大脑的学习方式。在其核心，深度学习依赖于所谓的 *人工神经网络*，它通过使用数学函数的行为类似于生物神经元的工作方式。这些人工神经网络由多个神经元层组成，创建了一个通过越来越复杂的层处理数据的结构。这就是为什么这种方法被称为“深度”学习，而由此产生的模型被称为
    *深度神经网络 (DNNs)*。您可以将深度学习应用于各种任务，例如预测结果（回归）、分类数据，甚至更复杂的问题，如理解语言或识别图像。
- en: Like other forms of ML, DL involves training a model to predict an output based
    on one or more inputs. The model’s job is to figure out a function that connects
    these inputs to the correct outputs. This function is built up across the neural
    network layers, with each layer handling a part of the process. During training,
    the model repeatedly adjusts its internal parameters (called *weights*) to minimize
    how far its predictions are from the correct values. Over time, the model fine-tunes
    these weights to improve accuracy and make better predictions.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他机器学习形式一样，深度学习涉及训练一个模型，根据一个或多个输入预测输出。模型的工作是找出一个函数，将这些输入与正确的输出联系起来。这个函数是通过神经网络层构建起来的，每一层处理过程的一部分。在训练过程中，模型反复调整其内部参数（称为
    *权重*），以最小化其预测与正确值之间的差距。随着时间的推移，模型微调这些权重以提高准确性和做出更好的预测。
- en: 'Let’s break down how a neural network works by looking at an example that classifies
    three different types of fruit: apples, oranges, and bananas. In this case, the
    input data (*x*) is a vector of measurements for these features. Let’s say we
    measure:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过查看一个将三种不同类型的果实（苹果、橙子和香蕉）进行分类的例子来分解神经网络的工作原理。在这种情况下，输入数据 (*x*) 是这些特征的测量值的向量。假设我们测量：
- en: The fruit’s weight
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水果的重量
- en: The color’s hue value
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色的色调值
- en: The curvature of the fruit
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水果的曲率
- en: 'So *x* is a vector with three values:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 *x* 是一个包含三个值的向量：
- en: '*x* = [x1, x2, x3]'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '*x* = [x1, x2, x3]'
- en: 'Now, the label (*y*) is the fruit’s type, which could be one of the three:
    apple, orange, or banana. Since this is a classification problem, the neural network
    will predict probabilities for each class. So *y* will be a vector representing
    the probabilities for each fruit: [P(apple|x), P(orange|x), P(banana|x)].'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，标签（*y*）是水果的类型，可能是以下三种之一：苹果、橙子或香蕉。由于这是一个分类问题，神经网络将预测每个类的概率。因此，*y*将是一个表示每个水果概率的向量：[P(apple|x),
    P(orange|x), P(banana|x)]。
- en: 'Here’s how the network makes a prediction:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 这是网络做出预测的方式：
- en: The feature data for a fruit, like [180g, 0.8, 0.3], is fed into the input layer
    of the neural network.
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 水果的特征数据，如[180g, 0.8, 0.3]，被输入到神经网络的输入层。
- en: Each neuron in the input layer takes the feature values, multiplies them by
    their assigned weights, and passes the result through an activation function.
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入层中的每个神经元都接受特征值，将它们乘以分配的权重，并通过激活函数传递结果。
- en: The neurons in each layer are connected to neurons in the next layer, forming
    a fully connected network where the results are fed forward through the network’s
    layers.
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每一层的神经元都与下一层的神经元相连，形成一个完全连接的网络，其中结果通过网络的层向前传递。
- en: The output layer generates a vector of probabilities—for example, [0.2, 0.7,
    0.1]—which represents the likelihood of the fruit being an apple, orange, or banana.
    Since 0.7 is the highest value, the network predicts the fruit is an orange.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出层生成一个概率向量——例如，[0.2, 0.7, 0.1]——这代表了水果是苹果、橙子或香蕉的可能性。由于0.7是最高值，网络预测该水果是橙子。
- en: '[Figure 4-11](#i04_chapter4_figure_12_1742068262037397) shows a graphical representation
    of a deep learning network.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-11](#i04_chapter4_figure_12_1742068262037397)展示了深度学习网络的图形表示。'
- en: '![](assets/aaif_0411.png)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aaif_0411.png)'
- en: Figure 4-11\. A deep learning network
  id: totrans-443
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-11\. 深度学习网络
- en: 'The magic of neural networks lies in adjusting the weights during training
    to make better predictions. Initially, these weights are random, but through a
    process called *backpropagation*, the network refines them to improve accuracy.
    Here’s a high-level view of the training process:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的魅力在于在训练过程中调整权重以做出更好的预测。最初，这些权重是随机的，但通过称为*反向传播*的过程，网络将它们细化以提高准确性。以下是训练过程的概述：
- en: Define your training data—basically, a set of known fruit types with their corresponding
    measurements.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义您的训练数据——基本上，一组已知的水果类型及其相应的测量值。
- en: The data is passed through the neural network, and the output is compared to
    the actual labels using a loss function. A loss function is a mathematical formula
    that quantifies the difference between the predicted output and the true labels.
    For example, if the network predicts [0.3, 0.1, 0.6] for a banana, but the true
    label is [0, 0, 1], the loss function calculates the discrepancy between these
    values. This difference, or loss, serves as a signal for the model to adjust its
    parameters and improve its predictions. The ultimate goal is to minimize this
    loss to enhance the network’s accuracy.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据通过神经网络传递，并使用损失函数将输出与实际标签进行比较。损失函数是一个数学公式，它量化了预测输出和真实标签之间的差异。例如，如果网络预测香蕉的值为[0.3,
    0.1, 0.6]，但真实标签是[0, 0, 1]，则损失函数计算这些值之间的差异。这种差异，或损失，作为模型调整其参数并改进其预测的信号。最终目标是最大限度地减少这种损失以提高网络的准确性。
- en: The network calculates how much each weight contributed to the loss and uses
    this information to adjust the weights.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络计算每个权重对损失的贡献程度，并使用这些信息来调整权重。
- en: This process is repeated over many cycles (called *epochs*) until the loss is
    minimized and the model is accurate enough.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程在许多周期（称为*epoch*）中重复，直到损失最小化并且模型足够准确。
- en: This training typically happens in batches of data, using powerful hardware
    like GPUs to handle the heavy computation involved. Over time, the network becomes
    good at identifying whether the fruit is an apple, orange, or banana.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 这种训练通常以数据批次的形式进行，使用如GPU等强大的硬件来处理涉及的重计算。随着时间的推移，网络变得擅长识别水果是苹果、橙子还是香蕉。
- en: For the AI-900 exam, you may see questions that ask about the differences between
    ML and DL. [Table 4-17](#i04_chapter4_table_17_1742068262048902) lays out these
    key differences to help you get a solid grasp of each.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI-900考试，您可能会看到关于机器学习和深度学习之间区别的问题。[表4-17](#i04_chapter4_table_17_1742068262048902)概述了这些关键区别，以帮助您牢固掌握每个概念。
- en: Table 4-17\. Key differences between ML and DL
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-17\. 机器学习和深度学习的关键区别
- en: '| Factor | Machine learning | Deep learning |'
  id: totrans-452
  prefs: []
  type: TYPE_TB
  zh: '| 因素 | 机器学习 | 深度学习 |'
- en: '| --- | --- | --- |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Complexity | Less | More |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '| 复杂性 | 较少 | 较多 |'
- en: '| Data requirements | Performs well with structured, smaller datasets | Requires
    large volumes of data to achieve accuracy |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| 数据要求 | 在结构化、较小的数据集上表现良好 | 需要大量数据才能达到准确性 |'
- en: '| Training time | Faster | Longer |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 训练时间 | 更快 | 更长 |'
- en: '| Hardware requirements | Can run on standard CPUs | Often requires GPUs |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 硬件要求 | 可在标准 CPU 上运行 | 通常需要 GPU |'
- en: '| Interpretability | Easier | More difficult |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 更容易 | 更困难 |'
- en: Conclusion
  id: totrans-459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we’ve explored the core concepts of ML, diving into essential
    techniques like regression, classification, and clustering. Each of these approaches
    offers unique ways to uncover patterns in data and make accurate predictions.
    They also empower you to tackle real-world challenges head-on.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了机器学习的核心概念，深入探讨了回归、分类和聚类等基本技术。每种方法都提供了独特的发现数据模式并做出准确预测的方法。它们还使你能够直面现实世界的挑战。
- en: Quiz
  id: totrans-461
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验
- en: To check your answers, please refer to the [“Chapter 4 Answer Key”](app02.html#answers_chapter_4_sample_questions_1745932457451742).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查你的答案，请参阅[“第 4 章答案键”](app02.html#answers_chapter_4_sample_questions_1745932457451742)。
- en: What is the primary purpose of regression analysis in machine learning (ML)?
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习（ML）中回归分析的主要目的是什么？
- en: To categorize data into distinct classes
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分类到不同的类别
- en: To cluster similar data points
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相似数据点聚类在一起
- en: To predict a numerical outcome based on variables
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据变量预测数值结果
- en: To analyze images and videos
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析图像和视频
- en: Which of the following is an example of supervised learning?
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项是监督学习的例子？
- en: K-means clustering
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: K-means 聚类
- en: Predicting house prices based on features
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据特征预测房价
- en: Segmenting customers based on purchase history
  id: totrans-471
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据购买历史对客户进行细分
- en: Identifying anomalies in financial transactions
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别金融交易中的异常
- en: In binary classification, which algorithm is commonly used to predict probabilities
    between two classes?
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在二元分类中，哪种算法通常用于预测两个类别之间的概率？
- en: Linear regression
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Logistic regression
  id: totrans-475
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Decision trees
  id: totrans-476
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树
- en: K-means
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: K-means
- en: What does the F1 score represent in model evaluation?
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F1 分数在模型评估中代表什么？
- en: The model’s ability to distinguish between classes
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型区分类别的能力
- en: The average of errors in predictions
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测误差的平均值
- en: A balance between precision and recall
  id: totrans-481
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精确度和召回率的平衡
- en: The total accuracy of the model
  id: totrans-482
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的总准确率
- en: Which step in the ML workflow involves using the model to generate predictions?
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习工作流程中的哪个步骤涉及使用模型进行预测？
- en: Training
  id: totrans-484
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练
- en: Inferencing
  id: totrans-485
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推理
- en: Validation
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证
- en: Data preparation
  id: totrans-487
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备
- en: What type of learning is K-means clustering associated with?
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: K-means 聚类与哪种学习类型相关联？
- en: Supervised
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监督
- en: Semisupervised
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 半监督
- en: Reinforcement
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化
- en: Unsupervised
  id: totrans-492
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无监督
- en: What metric measures how well a regression model explains the variation in data?
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个指标衡量回归模型解释数据变化的好坏？
- en: Mean squared error (MSE)
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均方误差 (MSE)
- en: Coefficient of determination (*R*²)
  id: totrans-495
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定系数 (*R*²)
- en: Root mean squared error (RMSE)
  id: totrans-496
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根均方误差 (RMSE)
- en: Mean absolute error (MAE)
  id: totrans-497
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均值绝对误差 (MAE)
- en: Which approach is used to address missing data by estimating based on patterns
    in available data?
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种方法通过根据可用数据中的模式进行估计来解决缺失数据？
- en: Mean imputation
  id: totrans-499
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均值插补
- en: Predictive imputation
  id: totrans-500
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测性插补
- en: Removal of incomplete data
  id: totrans-501
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除不完整数据
- en: Data normalization
  id: totrans-502
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据归一化
- en: What is the primary goal of classification in ML?
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习中分类的主要目标是什么？
- en: To identify hidden patterns in unlabeled data
  id: totrans-504
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别未标记数据中的隐藏模式
- en: To predict numerical outcomes
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测数值结果
- en: To assign data points to predefined categories
  id: totrans-506
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据点分配到预定义的类别
- en: To generate new content
  id: totrans-507
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成新内容
- en: Which ML technique is suitable for grouping similar data points without labels?
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种机器学习技术适合对无标签的相似数据点进行分组？
- en: Regression
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归
- en: Classification
  id: totrans-510
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类
- en: Clustering
  id: totrans-511
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类
- en: Deep learning (DL)
  id: totrans-512
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习 (DL)
