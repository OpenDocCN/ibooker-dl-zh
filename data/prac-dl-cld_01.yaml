- en: Chapter 1\. Exploring the Landscape of Artificial Intelligence
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 探索人工智能的领域
- en: 'Following are the words from Dr. May Carson’s ([Figure 1-1](part0003.html#drdot_may_carson))
    seminal paper on the changing role of artificial intelligence (AI) in human life
    in the twenty-first century:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Dr. May Carson（[图1-1](part0003.html#drdot_may_carson)）关于人工智能（AI）在21世纪人类生活中角色变化的重要论文中的话：
- en: Artificial Intelligence has often been termed as the electricity of the 21st
    century. Today, artificial intelligent programs will have the power to drive all
    forms of industry (including health), design medical devices and build new types
    of products and services, including robots and automobiles. As AI is advancing,
    organizations are already working to ensure those artificial intelligence programs
    can do their job and, importantly, avoid mistakes or dangerous accidents. Organizations
    need AI, but they also recognize that not everything they can do with AI is a
    good idea.
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能经常被称为21世纪的电力。今天，人工智能程序将有能力推动各种行业（包括医疗），设计医疗设备并构建新型产品和服务，包括机器人和汽车。随着AI的发展，组织已经在努力确保这些人工智能程序能够胜任工作，并且重要的是，避免错误或危险事故。组织需要AI，但他们也意识到并非所有可以用AI做的事情都是一个好主意。
- en: ''
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We have had extensive studies of what it takes to operate artificial intelligence
    using these techniques and policies. The main conclusion is that the amount of
    money spent on AI programs per person, per year versus the amount used to research,
    build and produce them is roughly equal. That seems obvious, but it’s not entirely
    true.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们对使用这些技术和政策操作人工智能所需的资金进行了广泛研究。主要结论是，每年每人在AI项目上花费的资金与用于研究、构建和生产这些项目的资金大致相等。这似乎是显而易见的，但并非完全如此。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: First, AI systems need support and maintenance to help with their functions.
    In order to be truly reliable, they need people to have the skills to run them
    and to help them perform some of their tasks. It’s essential that AI organizations
    provide workers to do the complex tasks needed by those services. It’s also important
    to understand the people who are doing those jobs, especially once AI is more
    complex than humans. For example, people will most often work in jobs requiring
    advanced knowledge but are not necessarily skilled in working with systems that
    need to be built and maintained.
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先，AI系统需要支持和维护来帮助它们的功能。为了真正可靠，他们需要人们具备运行它们和帮助他们执行一些任务的技能。AI组织提供工作人员来执行这些服务所需的复杂任务是至关重要的。了解从事这些工作的人员也很重要，尤其是当AI比人类更复杂时。例如，人们通常会从事需要高级知识的工作，但不一定擅长处理需要构建和维护的系统。
- en: '![Dr. May Carson](../images/00247.jpeg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Dr. May Carson](../images/00247.jpeg)'
- en: Figure 1-1\. Dr. May Carson
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1. Dr. May Carson
- en: An Apology
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致歉
- en: We now have to come clean and admit that everything in this chapter up to now
    was entirely fake. Literally everything! All of the text (other than the first
    italicized sentence, which was written by us as a seed) was generated using the
    GPT-2 model (built by Adam King) on the website *[TalkToTransformer.com](http://TalkToTransformer.com)*.
    The name of the author was generated using the “Nado Name Generator” on the website
    *[Onitools.moe](http://Onitools.moe)*. At least the picture of the author must
    be real, right? Nope, the picture was generated from the website *[ThisPersonDoesNotExist.com](http://ThisPersonDoesNotExist.com)*
    which shows us new pictures of nonexistent people each time we reload the page
    using the magic of Generative Adversarial Networks (GANs).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须坦白承认，本章直到现在为止的所有内容都是完全虚假的。真的是一切！所有的文本（除了第一个斜体句子，这是我们写的种子）都是使用GPT-2模型（由Adam
    King构建）在网站*[TalkToTransformer.com](http://TalkToTransformer.com)*上生成的。作者的名字是使用网站*[Onitools.moe](http://Onitools.moe)*上的“Nado
    Name Generator”生成的。至少作者的照片必须是真实的，对吧？不，这张照片是从网站*[ThisPersonDoesNotExist.com](http://ThisPersonDoesNotExist.com)*生成的，该网站利用生成对抗网络（GANs）的魔法每次重新加载页面时向我们展示不存在的人的新图片。
- en: Although we feel ambivalent, to say the least, about starting this entire book
    on a dishonest note, we thought it was important to showcase the state-of-the-art
    of AI when you, our reader, least expected it. It is, frankly, mind-boggling and
    amazing and terrifying at the same time to see what AI is already capable of.
    The fact that it can create sentences out of thin air that are more intelligent
    and eloquent than some world leaders is...let’s just say big league.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们对以不诚实的方式开始整本书感到矛盾，但我们认为展示AI的最新技术是重要的，当您，我们的读者，最不期望时。看到AI已经能够创造出比一些世界领导人更聪明和雄辩的句子，这实在是令人难以置信、惊人和可怕的。它能够凭空创造出句子，这让我们不禁要说，这是大联盟。
- en: That being said, one thing AI can’t appropriate from us just yet is the ability
    to be fun. We’re hoping that those first three fake paragraphs will be the driest
    in this entire book. After all, we don’t want to be known as “the authors more
    boring than a machine.”
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，AI目前还无法从我们这里获得的一件事是有趣的能力。我们希望这本书中前三段虚假的段落将是整本书中最枯燥的部分。毕竟，我们不想被称为“比机器更无聊的作者”。
- en: The Real Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真正的介绍
- en: Recall that time you saw a magic show during which a trick dazzled you enough
    to think, “How the heck did they do that?!” Have you ever wondered the same about
    an AI application that made the news? In this book, we want to equip you with
    the knowledge and tools to not only deconstruct but also build a similar one.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得你看过的一个魔术表演，其中一个把戏让你眼花缭乱，让你想，“他们到底是怎么做到的？！”你是否曾经对一则AI应用程序登上新闻感到好奇？在这本书中，我们希望为您提供知识和工具，不仅可以解构，还可以构建类似的应用程序。
- en: 'Through accessible, step-by-step explanations, we dissect real-world applications
    that use AI and showcase how you would go about creating them on a wide variety
    of platforms—from the cloud to the browser to smartphones to edge AI devices,
    and finally landing on the ultimate challenge currently in AI: autonomous cars.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过易于理解的逐步解释，我们剖析了使用人工智能的真实应用程序，并展示了您如何在各种平台上创建这些应用程序——从云端到浏览器，再到智能手机，再到边缘人工智能设备，最终着眼于当前人工智能领域的最终挑战：自动驾驶汽车。
- en: In most chapters, we begin with a motivating problem and then build an end-to-end
    solution one step at a time. In the earlier portions of the book, we develop the
    necessary skills to build the brains of the AI. But that’s only half the battle.
    The true value of building AI is in creating usable applications. And we’re not
    talking about toy prototypes here. We want you to construct software that can
    be used in the real world by real people for improving their lives. Hence, the
    word “Practical” in the book title. To that effect, we discuss various options
    that are available to us and choose the appropriate options based on performance,
    energy consumption, scalability, reliability, and privacy trade-offs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数章节中，我们从一个激励性问题开始，然后一步一步地构建一个端到端的解决方案。在本书的前部分，我们培养了构建人工智能大脑所需的技能。但这只是一半的战斗。构建人工智能的真正价值在于创建可用的应用程序。我们不是在谈论玩具原型。我们希望您构建的软件可以在现实世界中被真实的人们使用，以改善他们的生活。因此，书名中有“实用”一词。为此，我们讨论了我们可以选择的各种选项，并根据性能、能耗、可扩展性、可靠性和隐私权的权衡选择适当的选项。
- en: In this first chapter, we take a step back to appreciate this moment in AI history.
    We explore the meaning of AI, specifically in the context of deep learning and
    the sequence of events that led to deep learning becoming one of the most groundbreaking
    areas of technological progress in the early twenty-first century. We also examine
    the core components underlying a complete deep learning solution, to set us up
    for the subsequent chapters in which we actually get our hands dirty.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这第一章中，我们退后一步，欣赏人工智能历史上的这一时刻。我们探讨人工智能的含义，特别是在深度学习的背景下以及导致深度学习成为21世纪初最具突破性技术进步领域之一的事件序列。我们还研究了构成完整深度学习解决方案的核心组件，为我们做好准备，以便在随后的章节中实际动手。
- en: So our journey begins here, with a very fundamental question.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的旅程从这里开始，从一个非常基本的问题开始。
- en: What Is AI?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是人工智能？
- en: 'Throughout this book, we use the terms “artificial intelligence,” “machine
    learning,” and “deep learning” frequently, sometimes interchangeably. But in the
    strictest technical terms, they mean different things. Here’s a synopsis of each
    (see also [Figure 1-2](part0003.html#the_relationship_between_aicomma_machine)):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们经常使用“人工智能”、“机器学习”和“深度学习”这些术语，有时可以互换使用。但从严格的技术角度来看，它们有不同的含义。以下是每个术语的概要（也可参见[图1-2](part0003.html#the_relationship_between_aicomma_machine)）。
- en: AI
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能
- en: This gives machines the capabilities to mimic human behavior. IBM’s Deep Blue
    is a recognizable example of AI.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得机器具备模仿人类行为的能力。IBM的深蓝是人工智能的一个著名例子。
- en: Machine learning
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习
- en: This is the branch of AI in which machines use statistical techniques to learn
    from previous information and experiences. The goal is for the machine to take
    action in the future based on learning observations from the past. If you watched
    IBM’s Watson take on Ken Jennings and Brad Rutter on *Jeopardy!*, you saw machine
    learning in action. More relatably, the next time a spam email doesn’t reach your
    inbox, you can thank machine learning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是人工智能的一个分支，其中机器使用统计技术从以前的信息和经验中学习。目标是让机器根据过去的学习观察来未来采取行动。如果您看过IBM的沃森在*危险边缘*上与肯·詹宁斯和布拉德·拉特对决，您就看到了机器学习的实际应用。更具相关性的是，下次垃圾邮件没有进入您的收件箱时，您可以感谢机器学习。
- en: Deep learning
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习
- en: This is a subfield of machine learning in which deep, multilayered neural networks
    are used to make predictions, especially excelling in computer vision, speech
    recognition, natural language understanding, and so on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习的一个子领域，其中使用深度、多层神经网络进行预测，特别擅长计算机视觉、语音识别、自然语言理解等领域。
- en: '![The relationship between AI, machine learning, and deep learning](../images/00160.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能、机器学习和深度学习之间的关系](../images/00160.jpeg)'
- en: Figure 1-2\. The relationship between AI, machine learning, and deep learning
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2。人工智能、机器学习和深度学习之间的关系
- en: Throughout this book, we primarily focus on deep learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们主要关注深度学习。
- en: Motivating Examples
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激励性例子
- en: 'Let’s cut to the chase. What compelled us to write this book? Why did you spend
    your hard-earned money^([1](part0003.html#ch01fn1)) buying this book? Our motivation
    was simple: to get more people involved in the world of AI. The fact that you’re
    reading this book means that our job is already halfway done.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直奔主题。是什么促使我们写这本书？为什么您要花自己辛苦挣来的钱购买这本书？我们的动机很简单：让更多的人参与到人工智能的世界中。您正在阅读这本书意味着我们的工作已经完成了一半。
- en: 'However, to really pique your interest, let’s take a look at some stellar examples
    that demonstrate what AI is already capable of doing:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了真正激起您的兴趣，让我们看一些出色的例子，展示人工智能已经能够做到什么：
- en: '“DeepMind’s AI agents conquer human pros at StarCraft II”: *The Verge*, 2019'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “DeepMind的AI代理在《星际争霸II》中征服人类专家”：*The Verge*，2019
- en: '“AI-Generated Art Sells for Nearly Half a Million Dollars at Christie’s”: *AdWeek*,
    2018'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “由AI生成的艺术品在佳士得拍卖会上以近50万美元售出”：*AdWeek*，2018
- en: '“AI Beats Radiologists in Detecting Lung Cancer”: *American Journal of Managed
    Care*, 2019'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “AI在检测肺癌方面击败放射科医生”：*美国管理护理杂志*，2019
- en: '“Boston Dynamics Atlas Robot Can Do Parkour”: *ExtremeTech*, 2018'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “波士顿动力的Atlas机器人可以做跑酷”：*ExtremeTech*，2018
- en: '“Facebook, Carnegie Mellon build first AI that beats pros in 6-player poker”:
    *ai.facebook.com*, 2019'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Facebook，卡内基梅隆大学首次打败6名扑克专家的AI”：*ai.facebook.com*，2019
- en: '“Blind users can now explore photos by touch with Microsoft’s Seeing AI”: *TechCrunch*,
    2019'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “盲人现在可以通过微软的Seeing AI触摸探索照片”：*TechCrunch*，2019
- en: '“IBM’s Watson supercomputer defeats humans in final Jeopardy match”: *VentureBeat*,
    2011'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “IBM的沃森超级计算机在最后的《危险边缘》比赛中击败人类”：*VentureBeat*，2011
- en: '“Google’s ML-Jam challenges musicians to improvise and collaborate with AI”:
    *VentureBeat*, 2019'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “谷歌的ML-Jam挑战音乐家即兴演奏并与人工智能合作”：*VentureBeat*，2019
- en: '“Mastering the Game of Go without Human Knowledge”: *Nature*, 2017'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “无需人类知识即可掌握围棋游戏”：*Nature*，2017
- en: '“Chinese AI Beats Doctors in Diagnosing Brain Tumors”: *Popular Mechanics*,
    2018'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “中国人工智能在诊断脑瘤方面击败医生”：*Popular Mechanics*，2018
- en: '“Two new planets discovered using artificial intelligence”: *Phys.org*, 2019'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “使用人工智能发现了两颗新行星”：*Phys.org*，2019
- en: '“Nvidia’s latest AI software turns rough doodles into realistic landscapes”:
    *The Verge*, 2019'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “英伟达最新的人工智能软件将粗糙的涂鸦转化为逼真的风景”：*The Verge*，2019
- en: These applications of AI serve as our North Star. The level of these achievements
    is the equivalent of a gold-medal-winning Olympic performance. However, applications
    solving a host of problems in the real world is the equivalent of completing a
    5K race. Developing these applications doesn’t require years of training, yet
    doing so provides the developer immense satisfaction when crossing the finish
    line. We are here to coach you through that 5K.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些人工智能的应用是我们的北极星。这些成就的水平相当于获得金牌的奥运表现。然而，在现实世界中解决一系列问题的应用相当于完成一场5K比赛。开发这些应用并不需要多年的训练，但当开发者跨过终点线时，会获得巨大的满足感。我们在这里指导你完成这场5K比赛。
- en: Throughout this book, we intentionally prioritize breadth. The field of AI is
    changing so quickly that we can only hope to equip you with the proper mindset
    and array of tools. In addition to tackling individual problems, we will look
    at how different, seemingly unrelated problems have fundamental overlaps that
    we can use to our advantage. As an example, sound recognition uses Convolutional
    Neural Networks (CNNs), which are also the basis for modern computer vision. We
    touch upon practical aspects of multiple areas so you will be able to go from
    0 to 80 quickly to tackle real-world problems. If we’ve generated enough interest
    that you decide you then want to go from 80 to 95, we’d consider our goal achieved.
    As the oft-used phrase goes, we want to “democratize AI.”
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们有意地优先考虑广度。人工智能领域的变化如此之快，以至于我们只能希望为您提供正确的思维方式和一系列工具。除了解决个别问题外，我们还将探讨不同的、看似无关的问题之间的基本重叠，这些重叠可以为我们所用。例如，声音识别使用卷积神经网络（CNNs），这也是现代计算机视觉的基础。我们涉及多个领域的实际方面，因此您将能够迅速从0到80，解决现实世界中的问题。如果我们引起了足够的兴趣，让您决定从80到95，我们将认为我们的目标已经实现。正如常用的短语所说，我们希望“民主化人工智能”。
- en: 'It’s important to note that much of the progress in AI happened in just the
    past few years—it’s difficult to overstate that. To illustrate how far we’ve come
    along, take this example: five years ago, you needed a Ph.D. just to get your
    foot in the door of the industry. Five years later, you don’t even need a Ph.D.
    to write an entire book on the subject. (Seriously, check our profiles!)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，人工智能领域的许多进展都是在过去几年中取得的——这一点很难言之过早。为了说明我们已经取得了多大的进步，举个例子：五年前，你需要一个博士学位才能进入这个行业。五年后，你甚至不需要博士学位就能写一本关于这个主题的整本书。（真的，查看我们的个人资料吧！）
- en: Although modern applications of deep learning seem pretty amazing, they did
    not get there all on their own. They stood on the shoulders of many giants of
    the industry who have been pushing the limits for decades. Indeed, we can’t fully
    appreciate the significance of this time without looking at the entire history.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现代深度学习的应用似乎非常惊人，但它们并不是靠自己就能达到这一点的。它们站在许多行业巨头的肩膀上，这些人已经在推动行业的极限数十年了。事实上，我们不能完全欣赏这个时代的重要性，而不看整个历史。
- en: A Brief History of AI
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能简史
- en: 'Let’s go back in time a little bit: our whole universe was in a hot dense state.
    Then nearly 14 billion years ago expansion started, wait...okay, we don’t have
    to go back that far (but now we have the song stuck in your head for the rest
    of the day, right?). It was really just 70 years ago when the first seeds of AI
    were planted. Alan Turing, in his 1950 paper, “Computing Machinery and Intelligence,”
    first asked the question “Can machines think?” This really gets into a larger
    philosophical debate of sentience and what it means to be human. Does it mean
    to possess the ability to compose a concerto and know that you’ve composed it?
    Turing found that framework rather restrictive and instead proposed a test: if
    a human cannot distinguish a machine from another human, does it really matter?
    An AI that can mimic a human is, in essence, human.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到过去一点：我们整个宇宙都处于一个炽热而密集的状态。然后大约在140亿年前开始膨胀，等等...好吧，我们不必回溯那么久（但现在你一整天都会被这首歌困扰，对吧？）。其实，70年前才种下了人工智能的第一颗种子。艾伦·图灵在他1950年的论文《计算机器械与智能》中首次提出了“机器能思考吗？”这实际上涉及到了更大的哲学辩论，即意识和成为人类的含义。拥有创作协奏曲的能力并知道你已经创作了它，这是什么意思？图灵发现这种框架相当狭隘，而提出了一个测试：如果一个人无法区分机器和另一个人，那真的重要吗？一个能够模仿人类的人工智能本质上就是人类。
- en: Exciting Beginnings
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令人兴奋的开端
- en: The term “artificial intelligence” was coined by John McCarthy in 1956 at the
    Dartmouth Summer Research Project. Physical computers weren’t even really a thing
    back then, so it’s remarkable that they were able to discuss futuristic areas
    such as language simulation, self-improving learning machines, abstractions on
    sensory data, and more. Much of it was theoretical, of course. This was the first
    time that AI became a field of research rather than a single project.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: “人工智能”这个术语是由约翰·麦卡锡在1956年的达特茅斯暑期研究项目中创造的。当时实际的计算机甚至并不是真正存在的东西，所以令人惊讶的是，他们能够讨论诸如语言模拟、自我改进的学习机器、对感官数据的抽象等未来领域。当然，其中很多是理论性的。这是人工智能第一次成为一个研究领域而不是一个单一项目。
- en: 'The paper “Perceptron: A Perceiving and Recognizing Automaton” in 1957 by Frank
    Rosenblatt laid the foundation for deep neural networks. He postulated that it
    should be feasible to construct an electronic or electromechanical system that
    will learn to recognize similarities between patterns of optical, electrical,
    or tonal information. This system would function similar to the human brain. Rather
    than using a rule-based model (which was standard for the algorithms at the time),
    he proposed using statistical models to make predictions.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 1957年，弗兰克·罗森布拉特在他的论文“感知器：一个感知和识别的自动机”中奠定了深度神经网络的基础。他假设应该可以构建一个电子或电机系统，学会识别光学、电气或音调信息的模式相似性。这个系统将类似于人类大脑。他提出使用统计模型进行预测，而不是使用基于规则的模型（当时算法的标准）。
- en: Note
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Throughout this book, we repeat the phrase *neural network*. What is a neural
    network? It is a simplified model of the human brain. Much like the brain, it
    has *neurons* that activate when encountering something familiar. The different
    neurons are connected via connections (corresponding to synapses in our brain)
    that help information flow from one neuron to another.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们反复提到*神经网络*这个词组。什么是神经网络？它是人类大脑的简化模型。就像大脑一样，它有*神经元*，当遇到熟悉的东西时会被激活。不同的神经元通过连接（对应我们大脑中的突触）相连，帮助信息从一个神经元流向另一个神经元。
- en: 'In [Figure 1-3](part0003.html#an_example_of_a_perceptron), we can see an example
    of the simplest neural network: a perceptron. Mathematically, the perceptron can
    be expressed as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图1-3](part0003.html#an_example_of_a_perceptron)中，我们可以看到最简单的神经网络的一个示例：感知器。从数学上讲，感知器可以表示如下：
- en: '*output = f(x[1], x[2], x[3]) = x[1] w[1] + x[2] w[2] + x[3] w[3] + b*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出 = f(x[1], x[2], x[3]) = x[1] w[1] + x[2] w[2] + x[3] w[3] + b*'
- en: '![An example of a perceptron](../images/00270.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![感知器的示例](../images/00270.jpeg)'
- en: Figure 1-3\. An example of a perceptron
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3。感知器的示例
- en: In 1965, Ivakhnenko and Lapa published the first working neural network in their
    paper “Group Method of Data Handling—A Rival Method of Stochastic Approximation.”
    There is some controversy in this area, but Ivakhnenko is regarded by some as
    the father of deep learning.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 1965年，伊瓦赫涅科和拉帕在他们的论文“数据处理的群方法——随机逼近的竞争方法”中发表了第一个工作的神经网络。在这个领域存在一些争议，但伊瓦赫涅科被一些人认为是深度学习之父。
- en: Around this time, bold predictions were made about what machines would be capable
    of doing. Machine translation, speech recognition, and more would be performed
    better than humans. Governments around the world were excited and began opening
    up their wallets to fund these projects. This gold rush started in the late 1950s
    and was alive and well into the mid-1970s.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时候，人们对机器能够做到什么做出了大胆的预测。机器翻译、语音识别等将比人类表现更好。世界各国政府兴奋起来，开始敞开钱包资助这些项目。这场淘金热始于20世纪50年代末，并一直持续到20世纪70年代中期。
- en: The Cold and Dark Days
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寒冷黑暗的日子
- en: With millions of dollars invested, the first systems were put into practice.
    It turned out that a lot of the original prophecies were unrealistic. Speech recognition
    worked only if it was spoken in a certain way, and even then, only for a limited
    set of words. Language translation turned out to be heavily erroneous and much
    more expensive than what it would cost a human to do. Perceptrons (essentially
    single-layer neural networks) quickly hit a cap for making reliable predictions.
    This limited their usefulness for most problems in the real world. This is because
    they are linear functions, whereas problems in the real world often require a
    nonlinear classifier for accurate predictions. Imagine trying to fit a line to
    a curve!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 投入了数百万美元后，第一个系统被投入实践。结果发现，很多最初的预言是不现实的。语音识别只有在特定方式下才有效，即使如此，也只适用于有限的一组词汇。语言翻译结果错误严重，成本远远超过人类的成本。感知器（本质上是单层神经网络）很快达到了可靠预测的上限。这限制了它们在现实世界中大多数问题中的实用性。这是因为它们是线性函数，而现实世界中的问题通常需要非线性分类器进行准确预测。想象一下试图将一条直线拟合到一条曲线上！
- en: So what happens when you over-promise and under-deliver? You lose funding. The
    Defense Advanced Research Project Agency, commonly known as DARPA (yeah, those
    people; the ones who built the ARPANET, which later became the internet), funded
    a lot of the original projects in the United States. However, the lack of results
    over nearly two decades increasingly frustrated the agency. It was easier to land
    a man on the moon than to get a usable speech recognizer!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么当你过度承诺而未能兑现时会发生什么？你会失去资金。国防高级研究计划局，通常称为DARPA（是的，那些人；建立了ARPANET，后来成为互联网的人），资助了美国的许多最初项目。然而，近20年来缺乏结果越来越让这个机构感到沮丧。登上月球比获得可用的语音识别器更容易！
- en: Similarly, across the pond, the Lighthill Report was published in 1974, which
    said, “The general-purpose robot is a mirage.” Imagine being a Brit in 1974 watching
    the bigwigs in computer science debating on the BBC as to whether AI is a waste
    of resources. As a consequence, AI research was decimated in the United Kingdom
    and subsequently across the world, destroying many careers in the process. This
    phase of lost faith in AI lasted about two decades and came to be known as the
    “AI Winter.” If only Ned Stark had been around back then to warn them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在大西洋的另一边，1974年发表了莱特希尔报告，其中说：“通用机器人是一个幻觉。”想象一下，作为1974年的英国人，看着计算机科学的权威在BBC上辩论人工智能是否是资源浪费。结果，人工智能研究在英国遭到破坏，随后在全世界范围内也受到影响，摧毁了许多职业生涯。这种对人工智能失去信心的阶段持续了大约两十年，被称为“人工智能寒冬”。如果当时能有尼德·史塔克在场警告他们就好了。
- en: A Glimmer of Hope
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一线希望
- en: 'Even during those freezing days, there was some groundbreaking work done in
    this field. Sure, perceptrons—being linear functions—had limited capabilities.
    How could one fix that? By chaining them in a network, such that the output of
    one (or more) perceptron is the input to one (or more) perceptron. In other words,
    a multilayer neural network, as illustrated in [Figure 1-4](part0003.html#an_example_multilayer_neural_network_lef).
    The higher the number of layers, the more the nonlinearity it would learn, resulting
    in better predictions. There is just one issue: how does one train it? Enter Geoffrey
    Hinton and friends. They published a technique called *backpropagation* in 1986
    in the paper “Learning representations by back-propagating errors.” How does it
    work? Make a prediction, see how far off the prediction is from reality, and propagate
    back the magnitude of the error into the network so it can learn to fix it. You
    repeat this process until the error becomes insignificant. A simple yet powerful
    concept. We use the term backpropagation repeatedly throughout this book.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在那些寒冷的日子里，这个领域也做了一些开创性的工作。当然，感知器——作为线性函数——具有有限的能力。如何解决这个问题？通过将它们链接在一个网络中，使得一个（或多个）感知器的输出是另一个（或多个）感知器的输入。换句话说，一个多层神经网络，如[图1-4](part0003.html#an_example_multilayer_neural_network_lef)所示。层数越多，学习的非线性就越多，从而产生更好的预测。只有一个问题：如何训练它？乔治·希尔顿和他的朋友们登场了。他们在1986年的论文“通过反向传播错误学习表示”中发表了一种称为*反向传播*的技术。它是如何工作的？做出预测，看看预测与现实有多大偏差，然后将错误的大小传播回网络，以便学会修正它。重复这个过程，直到错误变得微不足道。一个简单而强大的概念。我们在本书中反复使用反向传播这个术语。
- en: '![An example multilayer neural network (image credit)](../images/00121.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![一个多层神经网络的示例（图片来源）](../images/00121.jpeg)'
- en: Figure 1-4\. An example multilayer neural network ([image source](https://oreil.ly/Jn-T6))
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4。一个多层神经网络的示例（[图片来源](https://oreil.ly/Jn-T6)）
- en: In 1989, George Cybenko provided the first proof of the *Universal Approximation
    Theorem*, which states that a neural network with a single hidden layer is theoretically
    capable of modeling any problem. This was remarkable because it meant that neural
    networks could (at least in theory) outdo any machine learning approach. Heck,
    it could even mimic the human brain. But all of this was only on paper. The size
    of this network would quickly pose limitations in the real world. This could be
    overcome somewhat by using multiple hidden layers and training the network with…wait
    for it…backpropagation!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 1989年，乔治·赛本科提供了*通用逼近定理*的第一个证明，该定理指出具有单个隐藏层的神经网络在理论上能够模拟任何问题。这是令人瞩目的，因为这意味着神经网络可以（至少在理论上）超越任何机器学习方法。它甚至可以模仿人类大脑。但所有这些都只是纸上谈兵。这个网络的规模很快就会在现实世界中限制。通过使用多个隐藏层并使用...等待...反向传播来训练网络，这个问题可以在一定程度上得到解决！
- en: On the more practical side of things, a team at Carnegie Mellon University built
    the first-ever autonomous vehicle, NavLab 1, in 1986 ([Figure 1-5](part0003.html#the_autonomous_navlab_1_from_1986_in_all)).
    It initially used a single-layer neural network to control the angle of the steering
    wheel. This eventually led to NavLab 5 in 1995\. During a demonstration, a car
    drove all but 50 of the 2,850-mile journey from Pittsburgh to San Diego on its
    own. NavLab got its driver’s license before many Tesla engineers were even born!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在更实际的一面，卡内基梅隆大学的一个团队于1986年建造了第一辆自主车辆NavLab 1（[图1-5](part0003.html#the_autonomous_navlab_1_from_1986_in_all)）。最初，它使用单层神经网络来控制方向盘的角度。这最终导致了1995年的NavLab
    5。在一次演示中，一辆汽车独自驾驶了从匹兹堡到圣迭戈的2850英里旅程中的所有路程，只剩下50英里。NavLab在许多特斯拉工程师出生之前就获得了驾驶执照！
- en: '![The autonomous NavLab 1 from 1986 in all its glory (image source)](../images/00116.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![1986年的自主NavLab 1的全貌（图片来源）](../images/00116.jpeg)'
- en: Figure 1-5\. The autonomous NavLab 1 from 1986 in all its glory ([image source](https://oreil.ly/b2Bnn))
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5。1986年的自主NavLab 1的全貌（[图片来源](https://oreil.ly/b2Bnn)）
- en: Another standout example from the 1980s was at the United States Postal Service
    (USPS). The service needed to sort postal mail automatically according to the
    postal codes (ZIP codes) they were addressed to. Because a lot of the mail has
    always been handwritten, optical character recognition (OCR) could not be used.
    To solve this problem, Yann LeCun et al. used handwritten data from the National
    Institute of Standards and Technology (NIST) to demonstrate that neural networks
    were capable of recognizing these handwritten digits in their paper “Backpropagation
    Applied to Handwritten Zip Code Recognition.” The agency’s network, LeNet, became
    what the USPS used for decades to automatically scan and sort the mail. This was
    remarkable because it was the first convolutional neural network that really worked
    in the wild. Eventually, in the 1990s, banks would use an evolved version of the
    model called LeNet-5 to read handwritten numbers on checks. This laid the foundation
    for modern computer vision.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 上世纪80年代的另一个突出例子是美国邮政服务（USPS）。该服务需要根据邮政编码（邮政编码）自动对邮件进行分类。由于许多邮件一直是手写的，因此无法使用光学字符识别（OCR）。为了解决这个问题，杨立昆等人使用了来自国家标准技术研究所（NIST）的手写数据，以证明神经网络能够识别这些手写数字，他们在论文“应用于手写邮政编码识别的反向传播”中使用了这些手写数据。该机构的网络LeNet成为USPS几十年来用于自动扫描和分类邮件的工具。这是令人瞩目的，因为这是第一个真正在野外工作的卷积神经网络。最终，在1990年代，银行将使用该模型的演变版本LeNet-5来读取支票上的手写数字。这为现代计算机视觉奠定了基础。
- en: Note
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Those of you who have read about the MNIST dataset might have already noticed
    a connection to the NIST mention we just made. That is because the MNIST dataset
    essentially consists of a subset of images from the original NIST dataset that
    had some modifications (the “M” in “MNIST”) applied to them to ease the train
    and test process for the neural network. Modifications, some of which you can
    see in [Figure 1-6](part0003.html#a_sample_of_handwritten_digits_from_the), included
    resizing them to 28 x 28 pixels, centering the digit in that area, antialiasing,
    and so on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 那些已经了解MNIST数据集的人可能已经注意到我们刚刚提到的NIST的联系。这是因为MNIST数据集本质上包含了原始NIST数据集中的一部分图像，对它们进行了一些修改（“MNIST”中的“M”），以便为神经网络的训练和测试过程提供便利。修改包括将它们调整为28
    x 28像素，将数字居中在该区域，抗锯齿等。
- en: '![A sample of handwritten digits from the MNIST dataset](../images/00196.jpeg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST数据集中手写数字的样本](../images/00196.jpeg)'
- en: Figure 1-6\. A sample of handwritten digits from the MNIST dataset
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6。MNIST数据集中手写数字的样本
- en: A few others kept their research going, including Jürgen Schmidhuber, who proposed
    networks like the Long Short-Term Memory (LSTM) with promising applications for
    text and speech.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一些人继续他们的研究，包括尤尔根·施密德胡伯，他提出了像长短期记忆（LSTM）这样的网络，具有文本和语音的有前途的应用。
- en: At that point, even though the theories were becoming sufficiently advanced,
    results could not be demonstrated in practice. The main reason was that it was
    too computationally expensive for the hardware back then and scaling them for
    larger tasks was a challenge. Even if by some miracle the hardware was available,
    the data to realize its full potential was certainly not easy to come by. After
    all, the internet was still in its dial-up phase. Support Vector Machines (SVMs),
    a machine learning technique introduced for classification problems in 1995, were
    faster and provided reasonably good results on smaller amounts of data, and thus
    had become the norm.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在那时，尽管理论已经足够先进，但实际上无法证明结果。主要原因是当时的硬件计算成本太高，将它们扩展到更大的任务是一个挑战。即使通过某种奇迹硬件是可用的，要实现其全部潜力的数据肯定不容易获得。毕竟，互联网仍处于拨号阶段。支持向量机（SVM），一种用于分类问题的机器学习技术在1995年引入，速度更快，在较小量的数据上提供了相当不错的结果，因此已经成为常态。
- en: As a result, AI and deep learning’s reputation was poor. Graduate students were
    warned against doing deep learning research because this is the field “where smart
    scientists would see their careers end.” People and companies working in the field
    would use alternative words like informatics, cognitive systems, intelligent agents,
    machine learning, and others to dissociate themselves from the AI name. It’s a
    bit like when the U.S. Department of War was rebranded as the Department of Defense
    to be more palatable to the people.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，人工智能和深度学习的声誉很差。研究生被警告不要进行深度学习研究，因为这是“聪明的科学家的职业终结的领域”。在该领域工作的人和公司会使用替代词，如信息学、认知系统、智能代理、机器学习等，以与人工智能名称区分开来。这有点像美国战争部被重新品牌为国防部，以使人们更容易接受。
- en: How Deep Learning Became a Thing
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习如何成为一种事物
- en: Luckily for us, the 2000s brought high-speed internet, smartphone cameras, video
    games, and photo-sharing sites like Flickr and Creative Commons (bringing the
    ability to legally reuse other people’s photos). People in massive numbers were
    able to quickly take photos with a device in their pockets and then instantly
    upload. The data lake was filling up, and gradually there were ample opportunities
    to take a dip. The 14 million-image ImageNet dataset was born from this happy
    confluence and some tremendous work by (then Princeton’s) Fei-Fei Li and company.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，2000年代带来了高速互联网、智能手机摄像头、视频游戏以及像Flickr和知识共享这样的照片分享网站（带来了合法重用他人照片的能力）。大量的人们能够迅速用口袋里的设备拍照，然后立即上传。数据湖正在填满，逐渐有了足够的机会去尝试。这个快乐的交汇产生了1400万张图像的ImageNet数据集，并得益于（当时的普林斯顿大学）李飞飞等人的一些巨大工作。
- en: During the same decade, PC and console gaming became really serious. Gamers
    demanded better and better graphics from their video games. This, in turn, pushed
    Graphics Processing Unit (GPU) manufacturers such as NVIDIA to keep improving
    their hardware. The key thing to remember here is that GPUs are damn good at matrix
    operations. Why is that the case? Because the math demands it! In computer graphics,
    common tasks such as moving objects, rotating them, changing their shape, adjusting
    their lighting, and so on all use matrix operations. And GPUs specialize in doing
    them. And you know what else needs a lot of matrix calculations? Neural networks.
    It’s one big happy coincidence.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个十年里，个人电脑和游戏机游戏变得非常严肃。玩家们要求他们的视频游戏拥有越来越好的图形。这反过来促使了图形处理单元（GPU）制造商，如NVIDIA不断改进他们的硬件。这里要记住的关键一点是，GPU在矩阵运算方面非常出色。为什么会这样？因为数学需要！在计算机图形学中，常见的任务，如移动对象、旋转对象、改变形状、调整光照等都使用矩阵运算。而GPU专门擅长执行这些任务。你知道还有什么需要大量矩阵计算吗？神经网络。这是一个巧合。
- en: With ImageNet ready, the annual ImageNet Large Scale Visual Recognition Challenge
    (ILSVRC) was set up in 2010 to openly challenge researchers to come up with better
    techniques for classifying this data. A subset of 1,000 categories consisting
    of approximately 1.2 million images was available to push the boundaries of research.
    The state-of-the-art computer-vision techniques like Scale-Invariant Feature Transform
    (SIFT) + SVM yielded a 28% (in 2010) and a 25% (2011) top-5 error rate (i.e.,
    if one of the top five guesses ranked by probability matches, it’s considered
    accurate).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有了ImageNet准备好后，2010年设立了年度ImageNet大规模视觉识别挑战赛（ILSVRC），公开挑战研究人员提出更好的分类这些数据的技术。提供了一个包含大约120万张图像的1,000个类别的子集，以推动研究的边界。像尺度不变特征变换（SIFT）+
    SVM这样的最新计算机视觉技术在2010年产生了28%（2010年）和25%（2011年）的前五错误率（即，如果按概率排名的前五个猜测之一匹配，则被认为是准确的）。
- en: And then came 2012, with an entry on the leaderboard that nearly halved the
    error rate down to 16%. Alex Krizhevsky, Ilya Sutskever (who eventually founded
    OpenAI), and Geoffrey Hinton from the University of Toronto submitted that entry.
    Aptly called AlexNet, it was a CNN that was inspired by LeNet-5\. Even at just
    eight layers, AlexNet had a massive 60 million parameters and 650,000 neurons,
    resulting in a 240 MB model. It was trained over one week using two NVIDIA GPUs.
    This single event took everyone by surprise, proving the potential of CNNs that
    snowballed into the modern deep learning era.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后到了2012年，排行榜上的一个条目将错误率几乎减少到16%。来自多伦多大学的Alex Krizhevsky，Ilya Sutskever（最终创立了OpenAI）和Geoffrey
    Hinton提交了该条目。AlexNet恰如其名，受到LeNet-5的启发。即使只有八层，AlexNet拥有庞大的6000万参数和65万个神经元，导致一个240
    MB的模型。它使用两个NVIDIA GPU在一周内训练。这一事件让所有人都感到惊讶，证明了CNN的潜力，这导致了现代深度学习时代的发展。
- en: '[Figure 1-7](part0003.html#evolution_of_winning_entries_at_imagenet) quantifies
    the progress that CNNs have made in the past decade. We saw a 40% year-on-year
    decrease in classification error rate among ImageNet LSVRC–winning entries since
    the arrival of deep learning in 2012\. As CNNs grew deeper, the error continued
    to decrease.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-7](part0003.html#evolution_of_winning_entries_at_imagenet)量化了CNN在过去十年中取得的进展。自2012年深度学习出现以来，我们看到ImageNet
    LSVRC获奖作品的分类错误率每年减少40%。随着CNN变得更深，错误率继续下降。'
- en: '![Evolution of winning entries at ImageNet LSVRC](../images/00264.jpeg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![ImageNet LSVRC获奖作品的演变](../images/00264.jpeg)'
- en: Figure 1-7\. Evolution of winning entries at ImageNet LSVRC
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7\. ImageNet LSVRC获奖作品的演变
- en: Keep in mind we are vastly simplifying the history of AI, and we are surely
    glossing over some of the details. Essentially, it was a confluence of data, GPUs,
    and better techniques that led to this modern era of deep learning. And the progress
    kept expanding further into newer territories. As [Table 1-1](part0003.html#a_highlight_reel_of_the_modern_deep_lear)
    highlights, what was in the realm of science fiction is already a reality.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们正在大大简化AI的历史，并且肯定忽略了一些细节。基本上，这是数据、GPU和更好技术的融合导致了这个现代深度学习时代。进展不断扩展到新的领域。正如[表1-1](part0003.html#a_highlight_reel_of_the_modern_deep_lear)所强调的，科幻小说中的东西已经成为现实。
- en: Table 1-1\. A highlight reel of the modern deep learning era
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-1\. 现代深度学习时代的精华片段
- en: '| 2012 | Neural network from Google Brain team starts recognizing cats after
    watching YouTube videos |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 2012 | 来自Google Brain团队的神经网络开始观看YouTube视频后识别猫 |'
- en: '| 2013 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 2013 |'
- en: Researchers begin tinkering with deep learning on a variety of tasks
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究人员开始在各种任务上尝试深度学习
- en: word2vec brings context to words and phrases, getting one step closer to understanding
    meanings
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: word2vec为单词和短语带来上下文，使理解含义更接近一步
- en: Error rate for speech recognition went down 25%
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别的错误率下降了25%
- en: '|'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2014 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 2014 |'
- en: GANs invented
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs被发明
- en: Skype translates speech in real time
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Skype实时翻译语音
- en: Eugene Goostman, a chatbot, passes the Turing Test
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人Eugene Goostman通过图灵测试
- en: Sequence-to-sequence learning with neural networks invented
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络进行序列到序列学习
- en: Image captioning translates images to sentences
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像字幕将图像翻译成句子
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2015 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 2015 |'
- en: Microsoft ResNet beats humans in image accuracy, trains 1,000-layer network
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软ResNet在图像准确性上击败人类，训练1000层网络
- en: Baidu’s Deep Speech 2 does end-to-end speech recognition
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 百度的Deep Speech 2进行端到端语音识别
- en: Gmail launches Smart Reply
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gmail推出智能回复
- en: YOLO (You Only Look Once) does object detection in real time
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YOLO（You Only Look Once）实时进行目标检测
- en: Visual Question Answering allows asking questions based on images
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉问答允许根据图像提出问题
- en: '|'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2016 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 2016 |'
- en: AlphaGo wins against professional human Go players
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlphaGo击败专业人类围棋选手
- en: Google WaveNets help generate realistic audio
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google WaveNets帮助生成逼真的音频
- en: Microsoft achieves human parity in conversational speech recognition
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软在对话语音识别中实现了与人类的平等
- en: '|'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2017 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 2017 |'
- en: AlphaGo Zero learns to play Go itself in 3 days
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlphaGo Zero在3天内学会自己下围棋
- en: Capsule Nets fix flaws in CNNs
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 胶囊网络修复CNN中的缺陷
- en: Tensor Processing Units (TPUs) introduced
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入张量处理单元（TPUs）
- en: California allows sale of autonomous cars
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚州允许出售自动驾驶汽车
- en: Pix2Pix allows generating images from sketches
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pix2Pix允许从草图生成图像
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2018 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2018 |'
- en: AI designs AI better than humans with Neural Architecture Search
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI设计比人类更好的AI，使用神经结构搜索
- en: Google Duplex demo makes restaurant reservations on our behalf
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Duplex演示代表我们预订餐厅
- en: Deepfakes swap one face for another in videos
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deepfakes在视频中交换一个面孔
- en: Google’s BERT succeeds humans in language understanding tasks
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google的BERT在语言理解任务中成功超越人类
- en: DawnBench and MLPerf established to benchmark AI training
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DawnBench和MLPerf建立用于基准测试AI训练
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2019 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 2019 |'
- en: OpenAI Five crushes Dota2 world champions
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI Five击败Dota2世界冠军
- en: StyleGan generates photorealistic images
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StyleGan生成逼真的图像
- en: OpenAI GPT-2 generates realistic text passages
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI GPT-2生成逼真的文本段落
- en: Fujitsu trains ImageNet in 75 seconds
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 富士通在75秒内训练ImageNet
- en: Microsoft invests $1 billion in OpenAI
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软向OpenAI投资10亿美元
- en: AI by the Allen Institute passes 12th-grade science test with 80% score
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 艾伦研究所的AI通过12年级科学考试，得分80%
- en: '|'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Hopefully, you now have a historical context of AI and deep learning and have
    an understanding of why this moment in time is significant. It’s important to
    recognize the rapid rate at which progress is happening in this area. But as we
    have seen so far, this was not always the case.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 希望现在您对AI和深度学习有了历史背景，并了解为什么这一时刻如此重要。重要的是要认识到在这一领域进展迅速的速度。但正如我们迄今所见，情况并非总是如此。
- en: The original estimate for achieving real-world computer vision was “one summer”
    back in the 1960s, according to two of the field’s pioneers. They were off by
    only half a century! It’s not easy being a futurist. A study by Alexander Wissner-Gross
    observed that it took 18 years on average between when an algorithm was proposed
    and the time it led to a breakthrough. On the other hand, that gap was a mere
    three years on average between when a dataset was made available and the breakthrough
    it helped achieve! Look at any of the breakthroughs in the past decade. The dataset
    that enabled that breakthrough was very likely made available just a few years
    prior.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 根据该领域的两位先驱，实现真实世界的计算机视觉的最初估计是在20世纪60年代的“一个夏天”。他们只差了半个世纪！成为未来学家并不容易。亚历山大·维斯纳-格罗斯的一项研究发现，算法提出和取得突破之间的平均时间约为18年。另一方面，数据集提供和帮助实现突破之间的平均时间仅为三年！看看过去十年的任何突破。实现该突破的数据集很可能在几年前才被提供。
- en: Data was clearly the limiting factor. This shows the crucial role that a good
    dataset can play for deep learning. However, data is not the only factor. Let’s
    look at the other pillars that make up the foundation of the perfect deep learning
    solution.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 数据显然是限制因素。这显示了一个好数据集对深度学习可以发挥的关键作用。然而，数据并不是唯一的因素。让我们看看构成完美深度学习解决方案基础的其他支柱。
- en: Recipe for the Perfect Deep Learning Solution
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完美深度学习解决方案的配方
- en: Before Gordon Ramsay starts cooking, he ensures he has all of the ingredients
    ready to go. The same goes for solving a problem using deep learning ([Figure 1-8](part0003.html#ingredients_for_the_perfect_deep_learnin)).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在Gordon Ramsay开始烹饪之前，他确保所有的配料都准备就绪。解决问题时使用深度学习也是如此（[图1-8](part0003.html#ingredients_for_the_perfect_deep_learnin)）。
- en: '![Ingredients for the perfect deep learning solution](../images/00098.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![完美深度学习解决方案的成分](../images/00098.jpeg)'
- en: Figure 1-8\. Ingredients for the perfect deep learning solution
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。完美深度学习解决方案的成分
- en: And here’s your deep learning *mise en place*!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你的深度学习*准备好了！
- en: '[PRE0]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let’s look into each of these in a little more detail.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些内容。
- en: Datasets
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: Just like Pac-Man is hungry for dots, deep learning is hungry for data—lots
    and lots of data. It needs this amount of data to spot meaningful patterns that
    can help make robust predictions. Traditional machine learning was the norm in
    the 1980s and 1990s because it would function even with few hundreds to thousands
    of examples. In contrast, Deep Neural Networks (DNNs), when built from scratch,
    would need orders more data for typical prediction tasks. The upside here is far
    better predictions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 就像吃豆子的吃豆人渴望数据一样，深度学习也渴望数据——大量的数据。它需要这么多数据来发现有意义的模式，从而帮助做出稳健的预测。传统机器学习在20世纪80年代和90年代是主流，因为即使只有几百到几千个示例，它也可以正常运行。相比之下，从头开始构建的深度神经网络（DNNs）通常需要更多的数据来完成典型的预测任务。这里的好处是预测更准确。
- en: In this century, we are having a data explosion with quintillions of bytes of
    data being created every single day—images, text, videos, sensor data, and more.
    But to make effective use of this data, we need labels. To build a sentiment classifier
    to know whether an Amazon review is positive or negative, we need thousands of
    sentences and an assigned emotion for each. To train a face segmentation system
    for a Snapchat lens, we need the precise location of eyes, lips, nose, and so
    forth on thousands of images. To train a self-driving car, we need video segments
    labeled with the human driver’s reactions on controls such as the brakes, accelerator,
    steering wheel, and so forth. These labels act as teachers to our AI and are far
    more valuable than unlabeled data alone.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本世纪，我们每天都会产生数量巨大的数据——图像、文本、视频、传感器数据等等，但要有效利用这些数据，我们需要标签。要构建一个情感分类器，以了解亚马逊评论是积极的还是消极的，我们需要成千上万的句子，并为每个句子分配一个情感。要训练一个用于Snapchat镜头的面部分割系统，我们需要在成千上万的图像上准确标记眼睛、嘴唇、鼻子等位置。要训练一辆自动驾驶汽车，我们需要用人类驾驶员对控制设备的反应标记视频片段，例如刹车、油门、方向盘等。这些标签对我们的人工智能起着教师的作用，比仅有未标记数据更有价值。
- en: Getting labels can be pricey. It’s no wonder that there is an entire industry
    around crowdsourcing labeling tasks among thousands of workers. Each label might
    cost from a few cents to dollars, depending on the time spent by the workers to
    assign it. For example, during the development of the Microsoft COCO (Common Objects
    in Context) dataset, it took roughly three seconds to label the name of each object
    in an image, approximately 30 seconds to place a bounding box around each object,
    and 79 seconds to draw the outlines for each object. Repeat that hundreds of thousands
    of times and you can begin to fathom the costs around some of the larger datasets.
    Some labeling companies like Appen and Scale AI are already valued at more than
    a billion dollars each.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 获取标签可能会很昂贵。难怪有成千上万的工人在众包标注任务周围形成了一个整个行业。每个标签的成本可能从几分钱到几美元不等，取决于工人分配标签所花费的时间。例如，在开发微软COCO（上下文中的常见对象）数据集期间，大约需要三秒来标记图像中每个对象的名称，大约需要30秒来在每个对象周围放置一个边界框，以及79秒来为每个对象绘制轮廓。重复这个过程数十万次，你就能开始估算一些更大数据集的成本。一些标注公司，如Appen和Scale
    AI，已经价值超过十亿美元。
- en: 'We might not have a million dollars in our bank account. But luckily for us,
    two good things happened in this deep learning revolution:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的银行账户可能没有一百万美元。但幸运的是，在这次深度学习革命中发生了两件好事：
- en: Gigantic labeled datasets have been generously made public by major companies
    and universities.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型标记数据集已经被主要公司和大学慷慨地公开。
- en: A technique called *transfer learning,* which allows us to tune our models to
    datasets with even hundreds of examples—as long as our model was originally trained
    on a larger dataset similar to our current set. We use this repeatedly in the
    book, including in [Chapter 5](part0007.html#6LJU3-13fa565533764549a6f0ab7f11eed62b)
    where we experiment and prove even a few tens of examples can get us decent performance
    with this technique. Transfer learning busts the myth that big data is necessary
    for training a good model. Welcome to the world of *tiny data*!
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种称为 *迁移学习* 的技术，允许我们将模型调整到具有数百个示例的数据集上，只要我们的模型最初是在类似于我们当前集合的更大数据集上进行训练的。我们在本书中反复使用这种技术，包括在[第
    5 章](part0007.html#6LJU3-13fa565533764549a6f0ab7f11eed62b)中，我们进行实验并证明即使有几十个示例，也可以通过这种技术获得良好的性能。迁移学习打破了训练良好模型需要大数据的神话。欢迎来到
    *微小数据* 的世界！
- en: '[Table 1-2](part0003.html#a_diverse_range_of_public_datasets) showcases some
    of the popular datasets out there today for a variety of deep learning tasks.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[表格 1-2](part0003.html#a_diverse_range_of_public_datasets) 展示了当今一些流行的数据集，用于各种深度学习任务。'
- en: Table 1-2\. A diverse range of public datasets
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1-2. 多样的公共数据集
- en: '| **Data type** | **Name** | **Details** |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| **数据类型** | **名称** | **详情** |'
- en: '| --- | --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Image | Open Images V4(from Google) |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | 开放图像 V4（来自谷歌） |'
- en: Nine million images in 19,700 categories
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 19700 个类别中的九百万张图像
- en: 1.74 Million images with 600 categories (bounding boxes)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有 600 个类别的 174 万张图像（带有边界框）
- en: '|'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|   | Microsoft COCO |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|   | Microsoft COCO |'
- en: 330,000 images with 80 object categories
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有 80 个对象类别的 33 万张图像
- en: Contains bounding boxes, segmentation, and five captions per image
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含边界框、分割和每张图像五个标题
- en: '|'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Video | YouTube-8M |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 视频 | YouTube-8M |'
- en: 6.1 million videos, 3,862 classes, 2.6 billion audio-visual features
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 610 万个视频，3862 个类别，26 亿个视听特征
- en: 3.0 labels/video
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3.0 标签/视频
- en: 1.53 TB of randomly sampled videos
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1.53 TB 的随机抽样视频
- en: '|'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Video, images | BDD100K(from UC Berkeley) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 视频、图像 | BDD100K（来自加州大学伯克利分校） |'
- en: 100,000 driving videos over 1,100 hours
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超过 1100 小时的 10 万个驾驶视频
- en: 100,000 images with bounding boxes for 10 categories
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有 10 个类别的边界框的 10 万张图像
- en: 100,000 images with lane markings
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有车道标记的 10 万张图像
- en: 100,000 images with drivable-area segmentation
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有可驾驶区域分割的 10 万张图像
- en: 10,000 images with pixel-level instance segmentation
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有像素级实例分割的 1 万张图像
- en: '|'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Waymo Open Dataset | 3,000 driving scenes totaling 16.7 hours of video data,
    600,000 frames, approximately 25 million 3D bounding boxes, and 22 million 2D
    bounding boxes |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Waymo 开放数据集 | 总计 3,000 个驾驶场景，16.7 小时的视频数据，60 万帧，约 2500 万个 3D 边界框和 2200 万个
    2D 边界框 |'
- en: '| Text | SQuAD | 150,000 Question and Answer snippets from Wikipedia |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | SQuAD | 来自维基百科的 15 万个问题和答案片段 |'
- en: '|   | Yelp Reviews | Five million Yelp reviews |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|   | Yelp 评论 | 五百万条 Yelp 评论 |'
- en: '| Satellite data | Landsat Data | Several million satellite images (100 nautical
    mile width and height), along with eight spectral bands (15- to 60-meter spatial
    resolution) |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 卫星数据 | Landsat 数据 | 数百万卫星图像（100 海里宽度和高度），以及八个光谱波段（15 到 60 米的空间分辨率） |'
- en: '| Audio | Google AudioSet | 2,084,320 10-second sound clips from YouTube with
    632 categories |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 音频 | Google AudioSet | 来自 YouTube 的 2,084,320 个 10 秒音频片段，包含 632 个类别 |'
- en: '| LibriSpeech | 1,000 hours of read English speech |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| LibriSpeech | 1000 小时的英语朗读语音 |'
- en: Model Architecture
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型架构
- en: At a high level, a model is just a function. It takes in one or more inputs
    and gives an output. The input might be in the form of text, images, audio, video,
    and more. The output is a prediction. A good model is one whose predictions reliably
    match the expected reality. The model’s accuracy on a dataset is a major determining
    factor as to whether it’s suitable for use in a real-world application. For many
    people, this is all they really need to know about deep learning models. But it’s
    when we peek into the inner workings of a model that it becomes really interesting
    ([Figure 1-9](part0003.html#a_black_box_view_of_a_deep_learning_mode)).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，模型只是一个函数。它接受一个或多个输入并给出一个输出。输入可以是文本、图像、音频、视频等形式。输出是一个预测。一个好的模型是那些预测可靠地匹配预期现实的模型。模型在数据集上的准确性是决定其是否适用于实际应用的主要因素。对于许多人来说，这就是他们真正需要了解的关于深度学习模型的全部。但当我们窥探模型的内部工作时，它变得真正有趣（[图
    1-9](part0003.html#a_black_box_view_of_a_deep_learning_mode)）。
- en: '![A black box view of a deep learning model](../images/00077.jpeg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![一个深度学习模型的黑盒视图](../images/00077.jpeg)'
- en: Figure 1-9\. A black box view of a deep learning model
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-9. 一个深度学习模型的黑盒视图
- en: Inside the model is a graph that consists of nodes and edges. Nodes represent
    mathematical operations, whereas edges represent how the data flows from one node
    to another. In other words, if the output of one node can become the input to
    one or more nodes, the connections between those nodes are represented by edges.
    The structure of this graph determines the potential for accuracy, its speed,
    how much resources it consumes (memory, compute, and energy), and the type of
    input it’s capable of processing.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 模型内部是一个由节点和边组成的图。节点代表数学运算，而边代表数据如何从一个节点流向另一个节点。换句话说，如果一个节点的输出可以成为一个或多个节点的输入，那么这些节点之间的连接由边表示。这个图的结构决定了准确性的潜力、速度、它消耗的资源（内存、计算和能量）以及它能够处理的输入类型。
- en: The layout of the nodes and edges is known as the *architecture* of the model.
    Essentially, it’s a blueprint. Now, the blueprint is only half the picture. We
    still need the actual building. Training is the process that utilizes this blueprint
    to construct that building. We train a model by repeatedly 1) feeding it input
    data, 2) getting outputs from it, 3) monitoring how far these predictions are
    from the expected reality (i.e., the labels associated with the data), and then,
    4) propagating the magnitude of error back to the model so that it can progressively
    learn to correct itself. This training process is performed iteratively until
    we are satisfied with the accuracy of the predictions.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 节点和边的布局被称为模型的*架构*。本质上，它是一个蓝图。现在，蓝图只是一部分。我们仍然需要实际的建筑。训练是利用这个蓝图来构建那座建筑的过程。我们通过反复进行以下步骤来训练模型：1）输入数据，2）从中获取输出，3）监视这些预测与预期现实（即与数据相关联的标签）之间的差距，然后，4）将错误的大小传播回模型，以便它逐渐学会自我纠正。这个训练过程是迭代进行的，直到我们对预测的准确性感到满意。
- en: The result from this training is a set of numbers (also known as weights) that
    is assigned to each of the nodes. These weights are necessary parameters for the
    nodes in the graph to operate on the input given to them. Before the training
    begins, we usually assign random numbers as weights. The goal of the training
    process is essentially to gradually tune the values of each set of these weights
    until they, in conjunction with their corresponding nodes, produce satisfactory
    predictions.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这种训练的结果是一组数字（也称为权重），分配给每个节点。这些权重是图中的节点在给定的输入上操作所必需的参数。在训练开始之前，我们通常将随机数分配为权重。训练过程的目标基本上是逐渐调整每组这些权重的值，直到它们与相应的节点一起产生令人满意的预测。
- en: 'To understand weights a little better, let’s examine the following dataset
    with two inputs and one output:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解权重，让我们来看下面的数据集，其中有两个输入和一个输出：
- en: Table 1-3\. Example dataset
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-3.示例数据集
- en: '| **input[1]** | **input[2]** | **output** |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|**input[1]**|**input[2]**|**output**|'
- en: '| --- | --- | --- |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|---|---|---|'
- en: '| 1 | 6 | 20 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|1|6|20|'
- en: '| 2 | 5 | 19 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|2|5|19|'
- en: '| 3 | 4 | 18 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|3|4|18|'
- en: '| 4 | 3 | 17 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|4|3|17|'
- en: '| 5 | 2 | 16 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|5|2|16|'
- en: '| 6 | 1 | 15 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|6|1|15|'
- en: 'Using linear algebra (or guesswork in our minds), we can deduce that the equation
    governing this dataset is:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性代数（或我们头脑中的猜测），我们可以推断控制这个数据集的方程是：
- en: '*output = f(input[1], input[2]*) = 2 x *input[1]* + 3 x *input[2]*'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*output = f(input[1], input[2])* = 2 x *input[1]* + 3 x *input[2]*'
- en: In this case, the weights for this mathematical operation are 2 and 3\. A deep
    neural network has millions of such weight parameters.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，这个数学运算的权重是2和3。一个深度神经网络有数百万个这样的权重参数。
- en: Depending on the types of nodes used, different themes of model architectures
    will be better suited for different kinds of input data. For example, CNNs are
    used for image and audio, whereas Recurrent Neural Networks (RNNs) and LSTM are
    often used in text processing.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 根据使用的节点类型不同，不同主题的模型架构将更适合不同类型的输入数据。例如，CNNs用于图像和音频，而循环神经网络（RNNs）和LSTM通常用于文本处理。
- en: In general, training one of these models from scratch can take a pretty significant
    amount of time, potentially weeks. Luckily for us, many researchers have already
    done the difficult work of training them on a generic dataset (like ImageNet)
    and have made them available for everyone to use. What’s even better is that we
    can take these available models and tune them to our specific dataset. This process
    is called transfer learning and accounts for the vast majority of needs by practitioners.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，从头开始训练这些模型可能需要相当长的时间，可能需要几周。幸运的是，许多研究人员已经完成了在通用数据集（如ImageNet）上训练它们的艰苦工作，并使它们可供所有人使用。更好的是，我们可以拿这些可用的模型并将它们调整到我们的特定数据集。这个过程称为迁移学习，占了从业者绝大多数需求。
- en: 'Compared to training from scratch, transfer learning provides a two-fold advantage:
    significantly reduced training time a (few minutes to hours instead of weeks),
    and it can work with a substantially smaller dataset (hundreds to thousands of
    data samples instead of millions). [Table 1-4](part0003.html#example_model_architectures_over_the_yea)
    shows some famous examples of model architectures.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 与从头开始训练相比，迁移学习提供了双重优势：显著减少的训练时间（几分钟到几小时，而不是几周），并且可以使用大大较小的数据集（数百到数千个数据样本，而不是数百万个）。[表1-4](part0003.html#example_model_architectures_over_the_yea)显示了一些著名的模型架构示例。
- en: Table 1-4\. Example model architectures over the years
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-4.多年来的示例模型架构
- en: '| **Task** | **Example model architectures** |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|**任务**|**示例模型架构**|'
- en: '| --- | --- |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|---|---|'
- en: '| Image classification | ResNet-152 (2015), MobileNet (2017) |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|图像分类|ResNet-152（2015年），MobileNet（2017年）|'
- en: '| Text classification | BERT (2018), XLNet (2019) |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|文本分类|BERT（2018年），XLNet（2019年）|'
- en: '| Image segmentation | U-Net (2015), DeepLabV3 (2018) |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|图像分割|U-Net（2015年），DeepLabV3（2018年）|'
- en: '| Image translation | Pix2Pix (2017) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|图像翻译|Pix2Pix（2017年）|'
- en: '| Object detection | YOLO9000 (2016), Mask R-CNN (2017) |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|目标检测|YOLO9000（2016年），Mask R-CNN（2017年）|'
- en: '| Speech generation | WaveNet (2016) |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|语音生成|WaveNet（2016年）|'
- en: Each one of the models from [Table 1-4](part0003.html#example_model_architectures_over_the_yea)
    has a published accuracy metric on reference datasets (e.g., ImageNet for classification,
    MS COCO for detection). Additionally, these architectures have their own characteristic
    resource requirements (model size in megabytes, computation requirements in floating-point
    operations, or FLOPS).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[表1-4](part0003.html#example_model_architectures_over_the_yea)中的每个模型都在参考数据集（例如，分类的ImageNet，检测的MS
    COCO）上有一个已发布的准确度指标。此外，这些架构有它们自己的特征资源需求（以兆字节为单位的模型大小，以浮点运算为单位的计算需求，或FLOPS）。'
- en: We explore transfer learning in-depth in the upcoming chapters. Now, let’s look
    at the kinds of deep learning frameworks and services that are available to us.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节深入探讨迁移学习。现在，让我们看看我们可以使用的深度学习框架和服务。
- en: Note
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: 'When Kaiming He et al. came up with the 152-layer ResNet architecture in 2015—a
    feat of its day considering the previous largest GoogLeNet model consisted of
    22 layers—there was just one question on everyone’s mind: “Why not 153 layers?”
    The reason, as it turns out, was that Kaiming ran out of GPU memory!'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当Kaiming He等人在2015年提出了152层的ResNet架构时——考虑到之前最大的GoogLeNet模型由22层组成，这是当时的壮举——每个人心中只有一个问题：“为什么不是153层？”原来，原因是Kaiming的GPU内存用完了！
- en: Frameworks
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 框架
- en: There are several deep learning libraries out there that help us train our models.
    Additionally, there are frameworks that specialize in using those trained models
    to make predictions (or *inference*), optimizing for where the application resides.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个深度学习库可以帮助我们训练模型。此外，还有专门用于使用这些训练模型进行预测（或*推理*）的框架，优化应用程序所在的位置。
- en: Historically, as is the case with software generally, many libraries have come
    and gone—Torch (2002), Theano (2007), Caffe (2013), Microsoft Cognitive Toolkit
    (2015), Caffe2 (2017)—and the landscape has been evolving rapidly. Learnings from
    each have made the other libraries easier to pick up, driven interest, and improved
    productivity for beginners and experts alike. [Table 1-5](part0003.html#popular_deep_learning_frameworks)
    looks at some of the popular ones.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，就像通常的软件一样，许多库已经出现并消失了——Torch（2002年）、Theano（2007年）、Caffe（2013年）、Microsoft
    Cognitive Toolkit（2015年）、Caffe2（2017年）——并且这个领域一直在迅速发展。从每个库中学到的东西使其他库更容易上手，引起了兴趣，并提高了初学者和专家的生产力。[表1-5](part0003.html#popular_deep_learning_frameworks)看一些流行的框架。
- en: Table 1-5\. Popular deep learning frameworks
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-5. 流行的深度学习框架
- en: '| **Framework** | **Best suited for** | **Typical target platform** |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| **框架** | **最适用于** | **典型目标平台** |'
- en: '| --- | --- | --- |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| TensorFlow (including Keras) | Training | Desktops, servers |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow（包括Keras）| 训练 | 台式机、服务器 |'
- en: '| PyTorch | Training | Desktops, servers |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch | 训练 | 台式机、服务器 |'
- en: '| MXNet | Training | Desktops, servers |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| MXNet | 训练 | 台式机、服务器 |'
- en: '| TensorFlow Serving | Inference | Servers |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow Serving | 推理 | 服务器 |'
- en: '| TensorFlow Lite | Inference | Mobile and embedded devices |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow Lite | 推理 | 移动和嵌入式设备 |'
- en: '| TensorFlow.js | Inference | Browsers |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow.js | 推理 | 浏览器 |'
- en: '| ml5.js | Inference | Browsers |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| ml5.js | 推理 | 浏览器 |'
- en: '| Core ML | Inference | Apple devices |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Core ML | 推理 | 苹果设备 |'
- en: '| Xnor AI2GO | Inference | Embedded devices |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| Xnor AI2GO | 推理 | 嵌入式设备 |'
- en: TensorFlow
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TensorFlow
- en: In 2011, Google Brain developed the DNN library DistBelief for internal research
    and engineering. It helped train Inception (2014’s winning entry to the ImageNet
    Large Scale Visual Recognition Challenge) as well as helped improve the quality
    of speech recognition within Google products. Heavily tied into Google’s infrastructure,
    it was not easy to configure and to share code with external machine learning
    enthusiasts. Realizing the limitations, Google began working on a second-generation
    distributed machine learning framework, which promised to be general-purpose,
    scalable, highly performant, and portable to many hardware platforms. And the
    best part, it was open source. Google called it TensorFlow and announced its release
    on November 2015.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 2011年，Google Brain开发了用于内部研究和工程的DNN库DistBelief。它帮助训练了Inception（2014年ImageNet大规模视觉识别挑战的获奖作品），并帮助提高了Google产品中语音识别的质量。与Google的基础设施紧密联系，它不容易配置和与外部机器学习爱好者共享代码。意识到这些限制，Google开始研发第二代分布式机器学习框架，承诺是通用、可扩展、高性能且可移植到许多硬件平台。而且最重要的是，它是开源的。Google称之为TensorFlow，并于2015年11月宣布发布。
- en: TensorFlow delivered on a lot of these aforementioned promises, developing an
    end-to-end ecosystem from development to deployment, and it gained a massive following
    in the process. With more than 100,000 stars on GitHub, it shows no signs of stopping.
    However, as adoption gained, users of the library rightly criticized it for not
    being easy enough to use. As the joke went, TensorFlow was a library by Google
    engineers, of Google engineers, for Google engineers, and if you were smart enough
    to use TensorFlow, you were smart enough to get hired there.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow实现了许多前述承诺，从开发到部署形成了一个端到端的生态系统，并在这个过程中获得了大量的追随者。在GitHub上拥有超过10万颗星星，显示出没有停止的迹象。然而，随着采用的增加，该库的用户
    rightly 批评它使用起来不够简单。正如笑话所说，TensorFlow是由Google工程师制作的库，为Google工程师制作的库，如果你足够聪明使用TensorFlow，你就足够聪明被雇佣在那里。
- en: But Google was not alone here. Let’s be honest. Even as late as 2015, it was
    a given that working with deep learning libraries would inevitably be an unpleasant
    experience. Forget even working on these; installing some of these frameworks
    made people want to pull their hair out. (Caffe users out there—does this ring
    a bell?)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 但Google并不孤单。说实话，即使到2015年，使用深度学习库仍然是一种令人不愉快的经历。甚至忘记使用这些库，安装其中一些框架就让人想拔头发。（Caffe的用户们，这是不是让你们想起了什么？）
- en: Keras
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Keras
- en: As an answer to the hardships faced by deep learning practitioners, François
    Chollet released the open source framework Keras in March 2015, and the world
    hasn’t been the same since. This solution suddenly made deep learning accessible
    to beginners. Keras provided an intuitive and easy-to-use interface for coding,
    which would then use other deep learning libraries as the backend computational
    framework. Starting with Theano as its first backend, Keras encouraged rapid prototyping
    and reduced the number of lines of code. Eventually, this abstraction expanded
    to other frameworks including Cognitive Toolkit, MXNet, PlaidML, and, yes, TensorFlow.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 作为深度学习从业者面临困难的答案，François Chollet于2015年3月发布了开源框架Keras，自那以后世界就变了。这个解决方案突然使深度学习对初学者变得可访问。Keras提供了一个直观且易于使用的编码界面，然后使用其他深度学习库作为后端计算框架。从其第一个后端Theano开始，Keras鼓励快速原型设计并减少代码行数。最终，这种抽象扩展到其他框架，包括Cognitive
    Toolkit、MXNet、PlaidML，以及TensorFlow。
- en: PyTorch
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch
- en: In parallel, PyTorch started at Facebook early in 2016, where engineers had
    the benefit of observing TensorFlow’s limitations. PyTorch supported native Python
    constructs and Python debugging right off the bat, making it flexible and easier
    to use, quickly becoming a favorite among AI researchers. It is the second-largest
    end-to-end deep learning system. Facebook additionally built Caffe2 to take PyTorch
    models and deploy them to production to serve more than a billion users. Whereas
    PyTorch drove research, Caffe2 was primarily used in production. In 2018, Caffe2
    was absorbed into PyTorch to make a full framework.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，PyTorch在2016年初在Facebook开始，工程师们有幸观察到TensorFlow的局限性。PyTorch从一开始就支持本地Python构造和Python调试，使其灵活且易于使用，很快成为AI研究人员的最爱。它是第二大端到端深度学习系统。Facebook另外构建了Caffe2，用于将PyTorch模型部署到生产环境，为超过十亿用户提供服务。PyTorch推动了研究，而Caffe2主要用于生产。2018年，Caffe2被吸收到PyTorch中，形成一个完整的框架。
- en: A continuously evolving landscape
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个不断发展的领域
- en: Had this story ended with the ease of Keras and PyTorch, this book would not
    have the word “TensorFlow” in the subtitle. The TensorFlow team recognized that
    if it truly wanted to broaden the tool’s reach and democratize AI, it needed to
    make the tool easier. So it was welcome news when Keras was officially included
    as part of TensorFlow, offering the best of both worlds. This allowed developers
    to use Keras for defining the model and training it, and core TensorFlow for its
    high-performance data pipeline, including distributed training and ecosystem to
    deploy. It was a match made in heaven! And to top it all, TensorFlow 2.0 (released
    in 2019) included support for native Python constructs and eager execution, as
    we saw in PyTorch.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个故事以Keras和PyTorch的便利结束，这本书的副标题就不会有“TensorFlow”这个词了。TensorFlow团队意识到，如果真的想要扩大工具的影响力并使AI民主化，就需要让工具更容易使用。因此，当Keras正式作为TensorFlow的一部分包含在内时，这是一个好消息，提供了两全其美的选择。这使开发人员可以使用Keras定义模型和训练模型，使用核心TensorFlow进行高性能数据管道，包括分布式训练和部署生态系统。这是天作之合！最重要的是，TensorFlow
    2.0（2019年发布）包括对本地Python构造和急切执行的支持，正如我们在PyTorch中看到的那样。
- en: With so many competing frameworks available, the question of portability inevitability
    arises. Imagine a new research paper published with the state-of-the-art model
    being made public in PyTorch. If we didn’t work in PyTorch, we would be locked
    out of the research and would have to reimplement and train it. Developers like
    to be able to share models freely and not be restricted to a specific ecosystem.
    Organically, many developers wrote libraries to convert model formats from one
    library to another. It was a simple solution, except that it led to a combinatorial
    explosion of conversion tools that lacked official support and sufficient quality
    due to the sheer number of them. To address this issue, the Open Neural Network
    Exchange (ONNX) was championed by Microsoft and Facebook, along with major players
    in the industry. ONNX provided a specification for a common model format that
    was readable and writable by a number of popular libraries officially. Additionally,
    it provided converters for libraries that did not natively support this format.
    This allowed developers to train in one framework and do inferences in a different
    framework.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这么多竞争框架可用，可移植性的问题不可避免地出现。想象一下，一篇新的研究论文以PyTorch公开发布的最先进模型。如果我们不在PyTorch中工作，我们将无法参与研究，必须重新实现和训练。开发人员喜欢能够自由共享模型，而不受限于特定的生态系统。许多开发人员自然地编写了库，将模型格式从一个库转换为另一个库。这是一个简单的解决方案，但由于转换工具的数量庞大，缺乏官方支持和足够的质量，导致了组合爆炸。为了解决这个问题，微软和Facebook等行业主要参与者发起了开放神经网络交换（ONNX）。ONNX提供了一个通用模型格式的规范，可以被多个流行库官方读写。此外，它为不支持此格式的库提供了转换器。这使开发人员可以在一个框架中进行训练，然后在另一个框架中进行推断。
- en: Apart from these frameworks, there are several Graphical User Interface (GUI)
    systems that make code-free training possible. Using transfer learning, they generate
    trained models quickly in several formats useful for inference. With point-and-click
    interfaces, even your grandma can now train a neural network!
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些框架外，还有几个图形用户界面（GUI）系统，可以实现无代码训练。使用迁移学习，它们可以快速生成多种格式的训练模型，用于推断。即使是您的祖母也可以通过点按界面快速训练神经网络！
- en: Table 1-6\. Popular GUI-based model training tools
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-6.流行的基于GUI的模型训练工具
- en: '| **Service** | **Platform** |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| **服务** | **平台** |'
- en: '| --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Microsoft CustomVision.AI | Web-based |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 微软CustomVision.AI | 基于Web |'
- en: '| Google AutoML | Web-based |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| Google AutoML | 基于Web |'
- en: '| Clarifai | Web-based |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Clarifai | 基于Web |'
- en: '| IBM Visual Recognition | Web-based |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| IBM视觉识别 | 基于Web |'
- en: '| Apple Create ML | macOS |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 苹果Create ML | macOS |'
- en: '| NVIDIA DIGITS | Desktop |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA DIGITS | 桌面 |'
- en: '| Runway ML | Desktop |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| Runway ML | 桌面 |'
- en: So why did we choose TensorFlow and Keras as the primary frameworks for this
    book? Considering the sheer amount of material available, including documentation,
    Stack Overflow answers, online courses, the vast community of contributors, platform
    and device support, industry adoption, and, yes, open jobs available (approximately
    three times as many TensorFlow-related roles compared to PyTorch in the United
    States), TensorFlow and Keras currently dominate the landscape when it comes to
    frameworks. It made sense for us to select this combination. That said, the techniques
    discussed in the book are generalizable to other libraries, as well. Picking up
    a new framework shouldn’t take you too long. So, if you really want to move to
    a company that uses PyTorch exclusively, don’t hesitate to apply there.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么我们选择TensorFlow和Keras作为本书的主要框架？考虑到可用的材料数量，包括文档、Stack Overflow答案、在线课程、庞大的贡献者社区、平台和设备支持、行业采用以及可用的工作岗位（在美国，与PyTorch相比，大约有三倍的TensorFlow相关角色），当涉及到框架时，TensorFlow和Keras目前主导着这个领域。对我们来说选择这种组合是有道理的。也就是说，本书讨论的技术也适用于其他库。学习一个新的框架不应该花费太长时间。因此，如果您真的想要加入一个专门使用PyTorch的公司，不要犹豫去申请。
- en: Hardware
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件
- en: In 1848, when James W. Marshall discovered gold in California, the news spread
    like wildfire across the United States. Hundreds of thousands of people stormed
    to the state to begin mining for riches. This was known as the *California Gold
    Rush*. Early movers were able to extract a decent chunk, but the latecomers were
    not nearly as lucky. But the rush did not stop for many years. Can you guess who
    made the most money throughout this period? The shovel makers!
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 1848年，当詹姆斯·W·马歇尔在加利福尼亚州发现金矿时，这一消息迅速传遍美国。成千上万的人涌向该州开始挖掘财富。这被称为*加利福尼亚淘金热*。早期行动者能够挖掘出一大笔财富，但后来者则没有那么幸运。但淘金热多年来并未停止。你能猜到在这段时间内谁赚了最多钱吗？铲子制造商！
- en: Cloud and hardware companies are the shovel makers of the twenty-first century.
    Don’t believe us? Look at the stock performance of Microsoft and NVIDIA in the
    past decade. The only difference between 1849 and now is the mind-bogglingly large
    amount of shovel choices available to us.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 云和硬件公司是21世纪的铲子制造商。不相信？看看过去十年微软和英伟达的股票表现。1849年和现在唯一的区别是我们可供选择的铲子数量之多令人难以置信。
- en: Given the variety of hardware available, it is important to make the correct
    choices for the constraints imposed by resource, latency, budget, privacy, and
    legal requirements of the application.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于可用的硬件种类繁多，重要的是根据应用程序的资源、延迟、预算、隐私和法律要求来做出正确的选择。
- en: Depending on how your application interacts with the user, the inference phase
    usually has a user waiting at the other end for a response. This imposes restrictions
    on the type of hardware that can be used as well as the location of the hardware.
    For example, a Snapchat lens cannot run on the cloud due to the network latency
    issues. Additionally, it needs to run in close to real time to provide a good
    user experience (UX), thus setting a minimum requirement on the number of frames
    processed per second (typically >15 fps). On the other hand, a photo uploaded
    to an image library such as Google Photos does not need immediate image categorization
    done on it. A few seconds or few minutes of latency is acceptable.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的应用程序与用户的交互方式，推理阶段通常有用户在另一端等待响应。这对可以使用的硬件类型以及硬件的位置施加了限制。例如，由于网络延迟问题，Snapchat镜头无法在云端运行。此外，它需要在接近实时的情况下运行，以提供良好的用户体验（UX），因此对每秒处理的帧数设置了最低要求（通常>15
    fps）。另一方面，上传到图像库（如Google照片）的照片不需要立即进行图像分类。几秒钟或几分钟的延迟是可以接受的。
- en: Going to the other extreme, training takes a lot more time; anywhere between
    minutes to hours to days. Depending on our training scenario, the real value of
    better hardware is enabling faster experimentation and more iterations. For anything
    more serious than basic neural networks, better hardware can make a mountain of
    difference. Typically, GPUs would speed things up by 10 to 15 times compared to
    CPUs, and at a much higher performance per watt, reducing the wait time for our
    experiment to finish from a week to a few hours. This can be the difference in
    watching a documentary about the Grand Canyon (two hours) versus actually making
    the trip to visit the Grand Canyon (four days).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 走向另一个极端，培训需要更多的时间；从几分钟到几小时到几天不等。根据我们的培训场景，更好的硬件的真正价值在于能够加快实验速度和增加迭代次数。对于比基本神经网络更严肃的事情，更好的硬件可以产生巨大的差异。通常情况下，与CPU相比，GPU的速度会提高10到15倍，并且性能每瓦更高，将实验完成的等待时间从一周减少到几个小时。这可能是观看大峡谷纪录片（两小时）与实际前往大峡谷旅行（四天）之间的区别。
- en: 'Following are a few fundamental hardware categories to choose from and how
    they are typically characterized (see also [Figure 1-10](part0003.html#comparison_of_different_types_of_hardwar)):'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是几个基本的硬件类别可供选择以及它们通常的特征（另请参见[图1-10](part0003.html#comparison_of_different_types_of_hardwar)）：
- en: Central Processing Unit (CPU)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 中央处理器（CPU）
- en: Cheap, flexible, slow. For example, Intel Core i9-9900K.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 便宜、灵活、慢。例如，英特尔酷睿i9-9900K。
- en: GPU
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图形处理器（GPU）
- en: High throughput, great for batching to utilize parallel processing, expensive.
    For example, NVIDIA GeForce RTX 2080 Ti.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 高吞吐量，非常适合批处理以利用并行处理，价格昂贵。例如，英伟达GeForce RTX 2080 Ti。
- en: Field-Programmable Gate Array (FPGA)
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现场可编程门阵列（FPGA）
- en: Fast, low power, reprogrammable for custom solutions, expensive. Known companies
    include Xilinx, Lattice Semiconductor, Altera (Intel). Because of the ability
    to run in seconds and configurability to any AI model, Microsoft Bing runs the
    majority of its AI on FPGAs.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 快速、低功耗、可重新编程以适应定制解决方案，价格昂贵。知名公司包括赛灵思、Lattice Semiconductor、Altera（英特尔）。由于能够在几秒钟内运行并可配置到任何AI模型，微软必应将大部分AI运行在FPGA上。
- en: Application-Specific Integrated Circuit (ASIC)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 专用集成电路（ASIC）
- en: 'Custom-made chip. Extremely expensive to design, but inexpensive when built
    for scale. Just like in the pharmaceutical industry, the first item costs the
    most due to the R&D effort that goes into designing and making it. Producing massive
    quantities is rather inexpensive. Specific examples include the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 定制芯片。设计成本极高，但在大规模生产时成本低廉。就像在制药行业一样，第一件物品的成本最高，因为设计和制造所需的研发工作。大规模生产相对廉价。具体示例包括以下内容：
- en: Tensor Processing Unit (TPU)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 张量处理单元（TPU）
- en: ASIC specializing in operations for neural networks, available on Google Cloud
    only.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 专门用于神经网络操作的ASIC，仅在Google Cloud上提供。
- en: Edge TPU
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘TPU
- en: Smaller than a US penny, accelerates inference on the edge.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 小于美国一分硬币大小，加速边缘推理。
- en: Neural Processing Unit (NPU)
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 神经处理单元（NPU）
- en: Often used by smartphone manufacturers, this is a dedicated chip for accelerating
    neural network inference.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 通常由智能手机制造商使用，这是一种专用芯片，用于加速神经网络推理。
- en: '![Comparison of different types of hardware relative to flexibility, performance,
    and cost](../images/00092.jpeg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![相对于灵活性、性能和成本的不同类型硬件的比较](../images/00092.jpeg)'
- en: Figure 1-10\. Comparison of different types of hardware relative to flexibility,
    performance, and cost
  id: totrans-282
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。相对于灵活性、性能和成本的不同类型硬件的比较
- en: 'Let’s look at a few scenarios for which each one would be used:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每种情况下会使用哪些方案：
- en: Getting started with training → CPU
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始训练→CPU
- en: Training large networks → GPUs and TPUs
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练大型网络→GPU和TPU
- en: Inference on smartphones → Mobile CPU, GPU, Digital Signal Processor (DSP),
    NPU
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能手机推断→移动CPU、GPU、数字信号处理器（DSP）、NPU
- en: Wearables (e.g., smart glasses, smartwatches) → Edge TPU, NPUs
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可穿戴设备（例如智能眼镜、智能手表）→Edge TPU、NPU
- en: Embedded AI projects (e.g., flood surveying drone, autonomous wheelchair) →
    Accelerators like Google Coral, Intel Movidius with Raspberry Pi, or GPUs like
    NVIDIA Jetson Nano, all the way down to $15 microcontrollers (MCUs) for wake word
    detection in smart speakers
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入式AI项目（例如洪水调查无人机、自动轮椅）→加速器如谷歌Coral、英特尔Movidius与树莓派，或像NVIDIA Jetson Nano这样的GPU，一直到用于智能音箱唤醒词检测的15美元微控制器（MCU）
- en: As we go through the book, we will closely explore many of these.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们阅读本书，我们将仔细探讨其中许多内容。
- en: Responsible AI
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负责任的AI
- en: So far, we have explored the power and the potential of AI. It shows great promise
    to enhance our abilities, to make us more productive, to give us superpowers.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了AI的力量和潜力。它展现了极大的潜力，可以增强我们的能力，使我们更加高效，赋予我们超能力。
- en: But with great power comes great responsibility.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 但伟大的力量伴随着伟大的责任。
- en: As much as AI can help humanity, it also has equal potential to harm us when
    not designed with thought and care (either intentionally or unintentionally).
    The AI is not to blame; rather, it’s the AI’s designers.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AI可以帮助人类，但当设计得不经过深思熟虑时（无论是有意还是无意），它也有同等的潜力伤害我们。AI本身不应受责备；而是AI的设计者。
- en: Consider some real incidents that made the news in the past few years.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一些过去几年在新闻中曝光的真实事件。
- en: '“____ can allegedly determine whether you’re a terrorist just by analyzing
    your face” ([Figure 1-11](part0003.html#startup_claiming_to_classify_people_base)):
    *Computer World*, 2016'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____据称可以通过分析你的面部判断你是否是恐怖分子”（[图1-11](part0003.html#startup_claiming_to_classify_people_base)）：《计算机世界》，2016年
- en: '“AI is sending people to jail—and getting it wrong”: *MIT Tech Review*, 2019'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “AI正在错误地将人们送进监狱”：《麻省理工科技评论》，2019年
- en: '“____ supercomputer recommended ‘unsafe and incorrect’ cancer treatments, internal
    documents show”: *STAT News*, 2018'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____超级计算机推荐‘不安全和不正确’的癌症治疗方法，内部文件显示”：《STAT新闻》，2018年
- en: '“____ built an AI tool to hire people but had to shut it down because it was
    discriminating against women”: *Business Insider*, 2018'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____开发了一个用于招聘人才的AI工具，但不得不关闭它，因为它歧视女性”：《商业内幕》，2018年
- en: '“____ AI study: Major object recognition systems favor people with more money”:
    *VentureBeat*, 2019'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____AI研究：主要物体识别系统偏向于拥有更多金钱的人”：《风险投资者》，2019年
- en: '“____ labeled black people ‘gorillas’” *USA Today*, 2015\. “Two years later,
    ____ solves ‘racist algorithm’ problem by purging ‘gorilla’ label from image classifier”:
    *Boing Boing*, 2018'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____将黑人标记为‘大猩猩’”：《今日美国》，2015年。“两年后，____通过从图像分类器中清除‘大猩猩’标签解决了‘种族主义算法’问题”：《Boing
    Boing》，2018年
- en: '“____ silences its new A.I. bot Tay, after Twitter users teach it racism”:
    *TechCrunch*, 2016'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____在Twitter用户教会它种族主义后，让其新的AI机器人Tay保持沉默”：《科技博客》，2016年
- en: '“AI Mistakes Bus-Side Ad for Famous CEO, Charges Her With Jaywalking”: *Caixin
    Global*, 2018'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “AI误将公交车侧面广告误认为著名CEO，指控其违章横穿马路”：《财新全球》，2018年
- en: '“____ to drop Pentagon AI contract after employee objections to the ‘business
    of war’”: *Washington Post*, 2018'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “____因员工反对‘战争生意’而决定放弃五角大楼的AI合同”：《华盛顿邮报》，2018年
- en: '“Self-driving ____ death car ‘spotted pedestrian six seconds before mowing
    down and killing her’”: *The Sun*, 2018'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “自动驾驶____致命车辆‘在撞倒并杀死行人前六秒发现了她’”：《太阳报》，2018年
- en: '![Startup claiming to classify people based on their facial structure](../images/00324.jpeg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![声称根据面部结构对人进行分类的初创公司](../images/00324.jpeg)'
- en: Figure 1-11\. Startup claiming to classify people based on their facial structure
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11。声称根据面部结构对人进行分类的初创公司
- en: Can you fill in the blanks here? We’ll give you some options—Amazon, Microsoft,
    Google, IBM, and Uber. Go ahead and fill them out. We’ll wait.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 你能在这里填上空白吗？我们给你一些选项——亚马逊、微软、谷歌、IBM和优步。继续填写。我们会等待。
- en: There’s a reason we kept them blank. It’s to recognize that it’s not a problem
    belonging to a specific individual or a company. This is everyone’s problem. And
    although these things happened in the past, and might not reflect the current
    state, we can learn from them and try not to make the same mistakes. The silver
    lining here is that everyone learned from these mistakes.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将它们留空是有原因的。这是为了认识到这不是属于特定个人或公司的问题。这是每个人的问题。尽管这些事情发生在过去，可能不反映当前状态，但我们可以从中学习，尽量避免犯同样的错误。这里的一线希望是每个人都从这些错误中学到了东西。
- en: We, as developers, designers, architects, and leaders of AI, have the responsibility
    to think beyond just the technical problem at face value. Following are just a
    handful of topics that are relevant to any problem we solve (AI or otherwise).
    They must not take a backseat.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 作为AI的开发者、设计师、架构师和领导者，我们有责任超越表面上的技术问题。以下是一些与我们解决的任何问题（无论是AI还是其他问题）相关的主题。它们不应该被忽视。
- en: Bias
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏见
- en: Often in our everyday work, we bring in our own biases, knowingly or unknowingly.
    This is the result of a multitude of factors including our environment, upbringing,
    cultural norms, and even our inherent nature. After all, AI and the datasets that
    power them were not created in a vacuum—they were created by human beings with
    their own biases. Computers don’t magically create bias on their own, they reflect
    and amplify existing ones.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们日常工作中，我们常常带入自己的偏见，有意或无意。这是多种因素的结果，包括我们的环境、成长背景、文化规范，甚至我们固有的天性。毕竟，AI和驱动它们的数据集并非在真空中创造出来的——它们是由带有自己偏见的人类创造的。计算机不会自己神奇地产生偏见，它们反映和放大现有的偏见。
- en: Take the example from the early days of the YouTube app when the developers
    noticed that roughly 10% of uploaded videos were upside-down. Maybe if that number
    had been lower, say 1%, it could have been brushed off as user error. But 10%
    was too high a number to be ignored. Do you know who happens to make up 10% of
    the population? Left-handed people! These users were holding their phones in the
    opposite orientation as their right-handed peers. But the engineers at YouTube
    had not accounted for that case during the development and testing of their mobile
    app, so YouTube uploaded videos to its server in the same orientation for both
    left-handed and right-handed users.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 以YouTube应用程序早期的一个例子为例，开发人员注意到大约10%的上传视频是颠倒的。也许如果这个数字更低，比如1%，可能会被视为用户错误。但10%的数字太高了，不能被忽视。你知道谁恰好占人口的10%吗？左撇子！这些用户将手机保持在与右撇子同向相反的方向。但YouTube的工程师在开发和测试移动应用程序时没有考虑到这种情况，因此YouTube将上传的视频以相同的方向上传到服务器，供左撇子和右撇子用户使用。
- en: This problem could have been caught much earlier if the developers had even
    a single left-handed person on the team. This simple example demonstrates the
    importance of diversity. Handedness is just one small attribute that defines an
    individual. Numerous other factors, often outside their control, often come into
    play. Factors such as gender, skin tone, economic status, disability, country
    of origin, speech patterns, or even something as trivial as hair length can determine
    life-changing outcomes for someone, including how an algorithm treats them.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果开发人员团队中有一个左撇子，这个问题本可以更早被发现。这个简单的例子展示了多样性的重要性。左右利手只是定义个体的一个小属性。许多其他因素，通常超出他们的控制，经常起作用。诸如性别、肤色、经济地位、残疾、出生国家、语音模式，甚至像头发长度这样微不足道的事情，都可能决定某人的改变生活结果，包括算法如何对待他们。
- en: 'Google’s [machine learning glossary](https://oreil.ly/ySfNv) lists several
    forms of bias that can affect a machine learning pipeline. The following are just
    some of them:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的[机器学习词汇表](https://oreil.ly/ySfNv)列出了可能影响机器学习流程的几种偏见形式。以下只是其中一些：
- en: Selection bias
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 选择偏见
- en: The dataset is not representative of the distribution of the real-world problem
    and is skewed toward a subset of categories. For example, in many virtual assistants
    and smart home speakers, some spoken accents are overrepresented, whereas other
    accents have no data at all in the training dataset, resulting in a poor UX for
    large chunks of the world’s population.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集不代表真实世界问题的分布，并偏向于某些类别的子集。例如，在许多虚拟助手和智能家居扬声器中，一些口音被过度代表，而其他口音在训练数据集中根本没有数据，导致世界大部分人口的用户体验不佳。
- en: Selection bias can also happen because of co-occurrence of concepts. For example,
    Google Translate, when used to translate the sentences “She is a doctor. He is
    a nurse” into a gender-neutral language such as Turkish and then back, switches
    the genders, as demonstrated in [Figure 1-12](part0003.html#google_translate_reflecting_the_underlyi).
    This is likely because the dataset contains a large sample of co-occurrences of
    male pronouns and the word “doctor,” and female pronouns and the word “nurse.”
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 选择偏见也可能是因为概念的共同出现。例如，当使用谷歌翻译将句子“她是医生。他是护士”翻译成土耳其等性别中立语言，然后再翻译回来时，性别会发生变化，如[图1-12](part0003.html#google_translate_reflecting_the_underlyi)所示。这可能是因为数据集包含了大量的男性代词和“医生”一词的共同出现，以及女性代词和“护士”一词的共同出现。
- en: '![Google Translate reflecting the underlying bias in data (as of September
    2019)](../images/00013.jpeg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![谷歌翻译反映了数据中的潜在偏见（截至2019年9月）](../images/00013.jpeg)'
- en: Figure 1-12\. Google Translate reflecting the underlying bias in data (as of
    September 2019)
  id: totrans-319
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-12。谷歌翻译反映了数据中的潜在偏见（截至2019年9月）
- en: Implicit bias
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 隐性偏见
- en: This type of bias creeps in because of implicit assumptions that we all make
    when we see something. Consider the highlighted portion in [Figure 1-13](part0003.html#zebra_sofa_by_glen_edelson_left_parenthe).
    Anyone shown it might assume with a high amount of certainty that those stripes
    belong to a zebra. In fact, given how much ImageNet-trained networks are biased
    toward textures,^([2](part0003.html#idm45475775799448)) most of them will classify
    the full image as a zebra. Except that we know that the image is of a sofa upholstered
    in a zebra-like fabric.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏见是因为我们在看到某事时都会做出的隐性假设。考虑[图1-13](part0003.html#zebra_sofa_by_glen_edelson_left_parenthe)中的突出部分。任何看到它的人都可能非常肯定地认为那些条纹属于斑马。事实上，考虑到ImageNet训练的网络对纹理有多么偏向，大多数网络都会将整个图像分类为斑马。除了我们知道这张图片是用斑马样式的织物装饰的沙发。
- en: '![Zebra sofa by Glen Edelson (image source)](../images/00134.jpeg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![Glen Edelson的斑马沙发（图片来源）](../images/00134.jpeg)'
- en: Figure 1-13\. Zebra sofa by Glen Edelson ([image source](https://oreil.ly/Xg4MP))
  id: totrans-323
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。Glen Edelson的斑马沙发（[图片来源](https://oreil.ly/Xg4MP)）
- en: Reporting bias
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 报告偏见
- en: Sometimes the loudest voices in the room are the most extreme ones and dominate
    the conversation. One good look at Twitter might make it seem as if the world
    is ending, whereas most people are busy leading mundane lives. Unfortunately,
    boring does not sell.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，房间里最响亮的声音是最极端的声音，并主导了对话。看一眼Twitter可能会让人觉得世界正在末日，而大多数人都在忙于过着平凡的生活。不幸的是，无聊是卖不动的。
- en: In-group/out-group bias
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 内外群体偏见
- en: An annotator from East Asia might look at a picture of the Statue of Liberty
    and give it tags like “America” or “United States,” whereas someone from the US
    might look at the same picture and assign more granular tags such as “New York”
    or “Liberty Island.” It’s human nature to see one’s own groups with nuance while
    seeing other groups as more homogenous, and that reflects in our datasets, as
    well.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 来自东亚的注释员可能会看到自由女神像的照片，并给予“美国”或“美利坚合众国”等标签，而来自美国的人可能会看同一张照片，并分配更细致的标签，如“纽约”或“自由岛”。人类天性是看待自己的群体时会有细微差别，而看待其他群体时会更加同质化，这也反映在我们的数据集中。
- en: Accountability and Explainability
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问责和可解释性
- en: Imagine, in the late 1800s, Mr. Karl Benz told you that he invented this four-wheeled
    device that could transport you quicker than anything else in existence. Except
    he had no idea how it worked. All he knew was that it consumed a highly flammable
    liquid that exploded several times inside it to propel it forward. What caused
    it to move? What caused it to stop? What stopped it from burning the person sitting
    inside it? He had no answers. If this was the origin story of the car, you’d probably
    not want to get into that contraption.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，在19世纪末，卡尔·本茨先生告诉你，他发明了这种四轮设备，可以比任何其他东西更快地将你运送。除了他不知道它是如何工作的。他只知道它消耗了一种高度易燃的液体，在内部爆炸了几次以推动它前进。是什么让它移动？是什么让它停下来？是什么阻止它燃烧坐在里面的人？他没有答案。如果这是汽车的起源故事，你可能不想进入那个装置。
- en: This is precisely what is happening with AI right now. Previously, with traditional
    machine learning, data scientists had to manually pick features (predictive variables)
    from data, from which a machine learning model then would learn. This manual selection
    process, although cumbersome and restrictive, gave them more control and insight
    into how the prediction came about. However, with deep learning, these features
    are automatically selected. Data scientists are able to build models by providing
    lots of data, and these models somehow end up making predictions reliably—most
    of the time. But the data scientist doesn’t know exactly how the model works,
    what features it learned, under what circumstances the model works, and, more
    importantly, the circumstances under which it doesn’t work. This approach might
    be acceptable when Netflix is recommending TV shows to us based on what we’ve
    already watched (although we’re fairly certain they have the line `recommendations.append("Stranger
    Things")` in their code somewhere). But AI does a lot more than just recommend
    movies these days. Police and judicial systems are beginning to rely on algorithms
    to decide whether someone poses a risk to society and whether they should be detained
    before their trial. The lives and freedoms of many people are at stake. We simply
    must not outsource important decision making to an unaccountable black box. Thankfully,
    there’s momentum to change that with investments in *Explainable AI*, wherein
    the model would be able to not just provide predictions but also account for the
    factors that caused it to make a certain prediction, and reveal areas of limitations.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是目前人工智能正在发生的事情。以前，传统机器学习中，数据科学家必须手动从数据中选择特征（预测变量），然后机器学习模型会学习这些特征。尽管这种手动选择过程虽然繁琐和受限，但给了他们更多的控制和洞察力，以了解预测是如何产生的。然而，使用深度学习，这些特征是自动选择的。数据科学家可以通过提供大量数据来构建模型，这些模型在大多数情况下会可靠地进行预测。但数据科学家并不知道模型是如何工作的，它学习了哪些特征，在什么情况下模型有效，更重要的是，在什么情况下模型无法工作。当Netflix基于我们已经观看的内容向我们推荐电视节目时，这种方法可能是可以接受的（尽管我们相当肯定他们的代码中的某处有`recommendations.append("Stranger
    Things")`）。但是如今人工智能所做的远不止推荐电影。警察和司法系统开始依赖算法来决定某人是否对社会构成风险，以及他们是否应该在审判前被拘留。许多人的生命和自由岌岌可危。我们绝对不能将重要的决策外包给一个不负责任的黑匣子。幸运的是，有改变的势头，投资于*可解释人工智能*，其中模型不仅能够提供预测，还能解释导致其做出某种预测的因素，并揭示限制的领域。
- en: Additionally, cities (such as New York) are beginning to make their algorithms
    accountable to the public by recognizing that the public has a right to know what
    algorithms they use for vital decision making and how they work, allowing reviews
    and audits by experts, improving expertise in government agencies to better evaluate
    each system they add, and by providing mechanisms to dispute a decision made by
    an algorithm.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些城市（如纽约）开始让他们的算法对公众负责，承认公众有权知道他们用于重要决策的算法以及它们的工作原理，允许专家进行审查和审计，提高政府机构的专业知识以更好地评估他们添加的每个系统，并提供争议决定的机制，这些决定是由算法做出的。
- en: Reproducibility
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可重复性
- en: Research performed in the scientific field gains wide acceptance by the community
    only when it’s reproducible; that is, anyone studying the research should be able
    to replicate the conditions of the test and obtain the same results. Unless we
    can reproduce a model’s past results, we cannot hold it accountable when using
    it in the future. In the absence of reproducibility, research is vulnerable to
    *p-hacking*—tweaking the parameters of an experiment until the desired results
    are obtained. It’s vital for researchers to extensively document their experimental
    conditions, including the dataset(s), benchmarks, and algorithms, and declare
    the hypothesis they will be testing prior to performing an experiment. Trust in
    institutions is at an all-time low and research that is not grounded in reality,
    yet sensationalized by the media, can erode that trust even more. Traditionally,
    replicating a research paper was considered a dark art because many implementation
    details are left out. The uplifting news is that researchers are now gradually
    beginning to use publicly available benchmarks (as opposed to their privately
    constructed datasets) and open sourcing the code they used for their research.
    Members of the community can piggyback on this code, prove it works, and make
    it better, thereby leading to newer innovations rapidly.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 科学领域的研究只有在可重复时才会得到社区的广泛认可；也就是说，任何研究者都应该能够复制测试条件并获得相同的结果。除非我们能够重现模型的过去结果，否则在将来使用它时无法追究责任。在没有可重复性的情况下，研究容易受到*p-hacking*的影响——调整实验参数直到获得期望的结果。研究人员有必要广泛记录他们的实验条件，包括数据集、基准和算法，并在进行实验之前声明他们将要测试的假设。对机构的信任达到历史最低点，而那些不基于现实但被媒体夸大的研究可能会进一步侵蚀这种信任。传统上，复制研究论文被认为是一种黑暗的艺术，因为许多实现细节被省略。令人振奋的消息是，研究人员现在逐渐开始使用公开可用的基准（而不是他们私下构建的数据集）并开源他们用于研究的代码。社区成员可以借助这些代码，证明它有效，并使其更好，从而迅速导致新的创新。
- en: Robustness
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳健性
- en: There’s an entire area of research on one-pixel attacks on CNNs. Essentially,
    the objective is to find and modify a single pixel in an image to make a CNN predict
    something entirely different. For example, changing a single pixel in a picture
    of an apple might result in a CNN classifying it as a dog. A lot of other factors
    can influence predictions, such as noise, lighting conditions, camera angle, and
    more that would not have affected a human’s ability to make a similar call. This
    is particularly relevant for self-driving cars, where it would be possible for
    a bad actor on a street to modify the input the car sees in order to manipulate
    it into doing bad things. In fact, Tencent’s Keen Security Lab was able to exploit
    a vulnerability in Tesla’s AutoPilot by strategically placing small stickers on
    the road, which led it to change lanes and drive into the oncoming lane. Robust
    AI that is capable of withstanding noise, slight deviations, and intentional manipulation
    is necessary if we are to be able to trust it.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个关于对CNN进行一像素攻击的研究领域。基本上，目标是找到并修改图像中的一个像素，使CNN预测完全不同的东西。例如，在一个苹果图片中改变一个像素可能导致CNN将其分类为狗。许多其他因素可以影响预测，如噪音、光照条件、摄像头角度等，这些因素不会影响人类做出类似判断的能力。这对于自动驾驶汽车尤为重要，因为街上的坏人可能会修改汽车看到的输入，以操纵它做坏事。事实上，腾讯的Keen
    Security Lab能够利用特斯拉AutoPilot的漏洞，通过在路上策略性地放置小贴纸，导致汽车变道并驶入对向车道。如果我们要信任AI，那么必须具备能够抵御噪音、轻微偏差和故意操纵的强大AI。
- en: Privacy
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私
- en: In the pursuit of building better and better AI, businesses need to collect
    lots of data. Unfortunately, sometimes they overstep their bounds and collect
    information overzealously beyond what is necessary for the task at hand. A business
    might believe that it is using the data it collects only for good. But what if
    it is acquired by a company that does not have the same ethical boundaries for
    data use? The consumer’s information could be used for purposes beyond the originally
    intended goals. Additionally, all that data collected in one place makes it an
    attractive target for hackers, who steal personal information and sell it on the
    black market to criminal enterprises. Moreover, governments are already overreaching
    in an attempt to track each and every individual.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求构建更好的人工智能的过程中，企业需要收集大量数据。不幸的是，有时它们会越过界限，过度热衷于收集超出当前任务所需的信息。一个企业可能认为它只是为了善良目的使用收集的数据。但如果被一家对数据使用没有相同道德底线的公司收购呢？消费者的信息可能被用于超出最初目标的目的。此外，所有这些数据集中在一个地方使其成为黑客的目标，他们窃取个人信息并将其出售给犯罪企业。此外，政府已经在试图追踪每个个人时越界。
- en: All of this is at odds to the universally recognized human right of privacy.
    What consumers desire is having transparency into what data is being collected
    about them, who has access to it, how it’s being used, and mechanisms to opt out
    of the data collection process, as well to delete data that was already collected
    on them.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都与普遍认可的隐私人权相悖。消费者希望能够透明地了解有关他们的数据收集情况，谁可以访问这些数据，数据如何被使用，以及退出数据收集过程的机制，以及删除已经收集的数据。
- en: As developers, we want to be aware of all the data we are collecting, and ask
    ourselves whether a piece of data is even necessary to be collected in the first
    place. To minimize the data we collect, we could implement privacy-aware machine
    learning techniques such as Federated Learning (used in Google Keyboard) that
    allow us to train networks on the users’ devices without having to send any of
    the Personally Identifiable Information (PII) to a server.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发者，我们希望意识到我们正在收集的所有数据，并问自己是否有必要收集某个数据。为了最小化我们收集的数据，我们可以实施隐私感知的机器学习技术，如联邦学习（在谷歌键盘中使用），这使我们能够在用户设备上训练网络，而无需将任何个人身份信息发送到服务器。
- en: It turns out that in many of the aforementioned headlines at the beginning of
    this section, it was the bad PR fallout that brought mainstream awareness of these
    topics, introduced accountability, and caused an industry-wide shift in mindset
    to prevent repeats in the future. We must continue to hold ourselves, academics,
    industry leaders, and politicians accountable at every misstep and act swiftly
    to fix the wrongs. Every decision we make and every action we take has the potential
    to set a precedent for decades to come. As AI becomes ubiquitous, we need to come
    together to ask the tough questions and find answers for them if we want to minimize
    the potential harm while reaping the maximum benefits.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，在本节开头提到的许多标题中，是糟糕的公关后果引起了这些话题的主流意识，引入了问责制，并导致了整个行业思维的转变，以防止未来的重复发生。我们必须继续要求自己、学者、行业领袖和政客在每一次失误时负责，并迅速采取措施纠正错误。我们做出的每个决定和采取的每个行动都有可能为未来几十年树立先例。随着人工智能的普及，我们需要共同努力提出艰难的问题，并为这些问题找到答案，以便在最大程度上减少潜在的危害。
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter explored the landscape of the exciting world of AI and deep learning.
    We traced the timeline of AI from its humble origins, periods of great promise,
    through the dark AI winters, and up to its present-day resurgence. Along the way,
    we answered the question of why it’s different this time. We then looked at the
    necessary ingredients to build a deep learning solution, including datasets, model
    architectures, frameworks, and hardware. This sets us up for further exploration
    in the upcoming chapters. We hope you enjoy the rest of the book. It’s time to
    dig in!
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了令人兴奋的人工智能和深度学习世界的格局。我们追溯了人工智能的时间线，从其谦逊的起源，伟大的希望时期，到黑暗的人工智能冬季，再到如今的复苏。在这个过程中，我们回答了为什么这一次不同的问题。然后，我们看了构建深度学习解决方案所需的必要要素，包括数据集、模型架构、框架和硬件。这为我们在接下来的章节中进一步探索做好了准备。希望您喜欢本书的其余部分。现在是深入研究的时候了！
- en: Frequently Asked Questions
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见问题
- en: I’m just getting started. Do I need to spend a lot of money on buying powerful
    hardware?
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我刚刚开始。我需要花很多钱购买强大的硬件吗？
- en: Luckily for you, you can get started even with your web browser. All of our
    scripts are available online, and can be run on free GPUs courtesy of the kind
    people at Google Colab ([Figure 1-14](part0003.html#screenshot_of_a_notebook_on_github_runni)),
    who are generously making powerful GPUs available for free (up to 12 hours at
    a time). This should get you started. As you become better at it by performing
    more experiments (especially in a professional capacity or on large datasets),
    you might want to get a GPU either by renting one on the cloud (Microsoft Azure,
    Amazon Web Services (AWS), Google Cloud Platform (GCP), and others) or purchasing
    the hardware. Watch out for those electricity bills, though!
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 幸运的是，您甚至可以通过网络浏览器开始。我们所有的脚本都可以在线获取，并且可以在Google Colab提供的免费GPU上运行（感谢慷慨的Google
    Colab团队，他们免费提供强大的GPU（每次最多12小时）。这应该让您开始。随着您通过执行更多实验（尤其是在专业环境或大型数据集上）变得更加熟练，您可能希望通过在云上租用（Microsoft
    Azure、Amazon Web Services（AWS）、Google Cloud Platform（GCP）等）或购买硬件来获得GPU。不过要注意那些电费账单！
- en: '![Screenshot of a notebook on GitHub running on Colab inside Chrome](../images/00278.jpeg)'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在Colab中运行的GitHub笔记本的屏幕截图](../images/00278.jpeg)'
- en: Figure 1-14\. Screenshot of a notebook on GitHub running on Colab inside Chrome
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-14。在Colab中运行的GitHub笔记本的屏幕截图
- en: Colab is great, but I already have a powerful computer that I purchased for
    playing <insert name of video game>. How should I set up my environment?
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Colab很棒，但我已经有一台为玩<插入视频游戏名称>而购买的强大计算机。我应该如何设置我的环境？
- en: 'The ideal setup involves Linux, but Windows and macOS work, too. For most chapters,
    you need the following:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理想的设置涉及Linux，但Windows和macOS也可以。对于大多数章节，您需要以下内容：
- en: Python 3 and PIP
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3和PIP
- en: '`tensorflow` or `tensorflow-gpu` PIP package (version 2 or greater)'
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow`或`tensorflow-gpu` PIP包（版本2或更高）'
- en: Pillow
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pillow
- en: We like keeping things clean and self-contained, so we recommend using Python
    virtual environments. You should use the virtual environment whenever you install
    a package or run a script or a notebook.
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们喜欢保持事情整洁和自包含，因此我们建议使用Python虚拟环境。每当您安装软件包或运行脚本或笔记本时，都应该使用虚拟环境。
- en: If you do not have a GPU, you are done with the setup.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您没有GPU，您的设置就完成了。
- en: 'If you have an NVIDIA GPU, you would want to install the appropriate drivers,
    then CUDA, then cuDNN, then `tensorflow-gpu` package. If you’re using Ubuntu,
    there’s an easier solution than installing these packages manually, which can
    be tedious and error prone even for the best of us: simply install the entire
    environment with just one line using [Lambda Stack](https://oreil.ly/93oon).'
  id: totrans-355
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您有NVIDIA GPU，您需要安装适当的驱动程序，然后安装CUDA，然后安装cuDNN，然后安装`tensorflow-gpu`软件包。如果您使用Ubuntu，有一个比手动安装这些软件包更简单的解决方案，即使用[Lambda
    Stack](https://oreil.ly/93oon)一行代码安装整个环境。
- en: Alternatively, you could install all of your packages using Anaconda Distribution,
    which works equally well for Windows, Mac, and Linux.
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，您可以使用Anaconda Distribution安装所有软件包，这对Windows、Mac和Linux同样有效。
- en: Where will I find the code used in this book?
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在哪里可以找到本书中使用的代码？
- en: You’ll find ready-to-run examples at [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai).
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以在[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)找到可直接运行的示例。
- en: What are the minimal prerequisites to be able to read this book?
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读本书的最低先决条件是什么？
- en: A Ph.D. in areas including Calculus, Statistical Analysis, Variational Autoencoders,
    Operations Research, and so on...are definitely *not* necessary to be able to
    read this book (had you a little nervous, didn’t we?). Some basic coding skills,
    familiarity with Python, a healthy amount of curiosity, and a sense of humor should
    go a long way in the process of absorbing the material. Although a beginner-level
    understanding of mobile development (with Swift and/or Kotlin) will help, we’ve
    designed the examples to be self-sufficient and easy enough to be deployed by
    someone who has never written a mobile app previously.
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 博士学位包括微积分、统计分析、变分自动编码器、运筹学等领域...绝对*不*是必需的，才能阅读这本书（让您有点紧张，是吧？）。一些基本的编码技能、熟悉Python、健康的好奇心和幽默感应该会在吸收材料的过程中大有裨益。尽管初级水平的移动开发理解（使用Swift和/或Kotlin）会有所帮助，但我们设计的示例是自给自足且足够简单，可以由以前从未编写过移动应用的人部署。
- en: What frameworks will we be using?
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用哪些框架？
- en: Keras + TensorFlow for training. And chapter by chapter, we explore different
    inference frameworks.
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Keras + TensorFlow用于训练。逐章探讨不同的推理框架。
- en: Will I be an expert when I finish this book?
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我读完这本书后会成为专家吗？
- en: If you follow along, you’ll have the know-how on a wide variety of topics all
    the way from training to inference, to maximizing performance. Even though this
    book primarily focuses on computer vision, you can bring the same know-how to
    other areas such as text, audio, and so on and get up to speed very quickly.
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您跟着学习，您将掌握从训练到推理再到性能最大化等各种主题的知识。尽管这本书主要关注计算机视觉，您也可以将相同的知识应用到其他领域，如文本、音频等，并且能够迅速上手。
- en: Who is the cat from earlier in the chapter?
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章前面的猫是谁？
- en: That is Meher’s cat, Vader. He will be making multiple cameos throughout this
    book. And don’t worry, he has already signed a model release form.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 那是Meher的猫，Vader。他将在本书中多次客串。不用担心，他已经签署了模特释放表。
- en: Can I contact you?
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我可以联系您吗？
- en: Sure. Drop us an email at [PracticalDLBook@gmail.com](mailto:PracticalDLBook@gmail.com)
    with any questions, corrections, or whatever, or tweet to us [@PracticalDLBook](https://www.twitter.com/PracticalDLBook).
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当然。如果有任何问题、更正或其他问题，请给我们发送电子邮件至[PracticalDLBook@gmail.com](mailto:PracticalDLBook@gmail.com)，或在Twitter上@PracticalDLBook发推文。
- en: ^([1](part0003.html#ch01fn1-marker)) If you’re reading a pirated copy, consider
    us disappointed in you.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在阅读盗版副本，请考虑我们对您感到失望。
- en: ^([2](part0003.html#idm45475775799448-marker)) [Robert Geirhos et al.](https://arxiv.org/pdf/1811.12231.pdf)
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](part0003.html#idm45475775799448-marker)) [Robert Geirhos等人](https://arxiv.org/pdf/1811.12231.pdf)
