# 附录 C. AI 治理与 MLOps 的整合

将 AI 治理整合到 MLOps Stack Canvas（图 C-1）中，使团队能够积极识别和减轻与偏见、公平性、隐私和安全相关的风险，同时支持遵守相关法规和标准。这种集成方法提高了模型质量，促进了可靠的预测，并加强了负责任的 AI 开发。它与技术能力同步扩展，鼓励跨职能协作，并促进审计和问责制。

在本附录中，我们将回顾 MLOps Stack Canvas 的组件（在第二章中介绍）并将框架扩展到包含关键的 AI 治理概念。

![图片](img/taie_c001.png)

###### 图 C-1. MLOps Stack Canvas 框架

# 价值主张

除了为 MLOps 平台制定一般的价值主张和数据治理目标外，还应考虑 AI 治理如何有助于 ML 项目的整体价值。例如：

+   添加一个“合规要求”部分，概述适用的法规和标准（例如，欧盟 AI 法案、GDPR、特定行业的 AI 法规）。

+   包含与欧盟 AI 法案类别（不可接受、高风险、有限风险或低风险）一致的“风险分类”组件，以评估 AI 系统的潜在风险和预期收益。

+   添加一个“伦理影响评估”部分，以评估 AI 系统的潜在社会和伦理影响，并确保项目符合组织的 AI 伦理原则。

+   包含一个利益相关者分析组件，以确定所有受系统影响的各方，特别关注弱势或边缘化群体。

# 数据来源和数据版本控制

在 MLOps 过程中考虑数据来源时，您还需要考虑 AI 治理。为此，您应该：

+   确保数据来源符合伦理指南和法律法规。

+   包含数据质量和偏见评估协议，以识别和减轻训练数据中的潜在偏见。

+   包含一个数据伦理审查流程，以评估数据收集和使用的伦理影响。

# 数据分析和实验管理

在开发数据分析和管理实验流程的同时，保持对 AI 治理的关注，整合伦理指南以防止偏见：

+   使用实验管理工具记录所有实验细节，确保模型开发中的透明度和问责制。

+   在实验中包含公平性指标和偏见分析。

+   记录决策过程和理由。

+   对分析脚本和笔记本实施版本控制，以确保实验的可重复性。

+   实施可解释 AI（XAI）技术，以确保模型的可解释性。

+   包含道德实验文档要求以创建审计跟踪。

+   将实验设计和结果纳入道德审查流程。

# 特征存储和工作流程

在特征存储和工作流程组件中维护 AI 治理需要确保数据隐私和安全的政策。标准化特征工程工作流程，使其可重复和透明，记录所有转换及其预期目的。此外：

+   添加特征重要性分析以支持透明度、可解释性和潜在道德影响的识别。

+   实施特征偏差检测和缓解策略。

+   包含隐私保护的特征工程技术。

+   添加特征文档和审计性及治理要求。

# CI/CT/CD：机器学习管道编排

此部分画布非常适合嵌入治理自动化。要将 AI 治理集成到持续集成、测试和部署过程中，从一开始就使这些工作流程与道德、法律和组织标准保持一致：

+   在 CI/CD 管道的关键阶段集成道德审查检查点，例如在模型训练和部署之前和之后。例如，一家医疗保健公司可能在训练后包括一个审查检查点，以评估模型预测是否符合关于种族或性别偏差的道德标准。

+   确保代码更改和模型版本之间的可追溯性。

+   在每次训练管道之后实施自动模型卡片生成，以记录模型限制、潜在偏差和预期用例。

+   使用带有人工监督的逐步推出策略以最小化风险。

+   添加模型鲁棒性和安全性测试，包括对抗性测试和输入扰动。可以使用 CleverHans 或对抗鲁棒性工具箱等框架来增强模型对操纵和攻击的抵抗力。

+   进行部署前的道德影响评估，并将模型公平性和偏差测试作为 CI/CD 测试套件的一部分。可以将 IBM 的 AI 公平 360 或 Google 的 What-If 工具集成到测试阶段，以自动检测和报告模型预测中的偏差。

+   自动化数据处理和模型行为的合规性检查。在 CI/CD 管道中实施自动化合规性检查。例如，包括自动化脚本来验证在数据用于训练或测试之前，数据匿名化和脱敏技术是否正确应用，并支持遵守欧盟 AI 法案、GDPR 和 HIPAA 等法规。

+   在持续部署过程中包含治理审批门。在部署模型之前，添加验证步骤，让利益相关者（如伦理学家、法律顾问和目标社区代表）可以根据道德考虑审查和批准模型。

# 模型注册和模型版本控制

为了确保模型版本与数据版本和治理政策保持一致，在模型注册表中包含道德元数据和治理信息。以下实践是推荐的：

+   建立模型部署的审批流程。

+   维护模型变更和审批的审计轨迹。

+   实施模型血统和来源以记录每个模型的整个生命周期和责任个人。

+   包含模型风险评估文档。

# 模型部署

在模型部署中维持 AI 治理需要几个关键行动：

+   在实施金丝雀发布和 A/B 测试时，需考虑道德因素。

+   确保关键决策过程中有人工参与。为高风险 AI 系统提供人工监督机制。

+   进行部署后的道德关注监控。

+   添加渐进式发布策略，以仔细监控已部署的模型。

# 预测服务

为了在 MLOps Stack Canvas 的预测服务部分保持 AI 治理的焦点，整合以下步骤：

+   为用户提供争议或上诉决策的机制，并收集用户反馈以识别潜在问题或偏见。实施速率限制和滥用预防控制。

+   应用道德输入验证以防止滥用或偏见输入。

+   实时监控模型输出以确保公平性。

+   维护所有预测的 comprehensive 审计日志。

+   为最终用户和审计员提供模型可解释性接口。

# 模型、数据和应用程序监控

为了在画布的模型、数据和应用程序监控组件中维持 AI 治理：

+   建立持续的公平性和偏见监控。

+   设置道德违规或意外模型行为的警报。

+   监控数据漂移和概念漂移，关注其道德影响。

+   实施自动检测可能影响公平性或性能的变动。

+   配置自动警报以标记治理违规行为。

# 元数据管理

元数据管理是 AI 治理的关键方面，在第三章中进行了深入探讨。目前，以下是一些关键实践，可纳入您的 MLOps 流程中：

+   维护 AI 治理实践和政策 comprehensive 的文档，并实施适当的版本控制。

+   建立模型、数据和治理决策之间的可追溯性。

+   维护 AI 系统和其治理状态的清单。

+   包含与法规遵从性相关的元数据（例如，欧盟 AI 法案，GDPR）。

+   为关键模型决策添加可追溯性。

+   收集与模型可解释性和可解释性相关的元数据。

通过将人工智能治理概念纳入 MLOps Stack Canvas，您创建了一个全面的框架，该框架不仅解决了机器学习操作的技术方面，而且还确保了人工智能开发与部署的道德、负责任和透明。这个改进的画布促进了整个 ML 项目生命周期中人工智能系统的信任、问责制和可持续发展。

# 将数据与人工智能治理集成到 MLOps 中

在欧盟人工智能法案的背景下，一个新兴趋势是数据与人工智能治理正日益与 MLOps 紧密相连。一个有希望的发展是将 MLOps 平台与内部审计和风险管理系统的集成，以增强治理流程。这有助于组织确保人工智能模型在其整个生命周期中符合监管要求和组织政策。表 C-1 总结了应在 MLOps 技术堆栈中纳入的数据和人工智能治理流程。

表 C-1。数据与人工智能治理集成到 MLOps 流程的总结

| MLOps 堆栈画布组件 | 数据治理 | 人工智能治理 |
| --- | --- | --- |
| 价值主张 |

+   合规性要求

|

+   人工智能法规合规性要求

+   伦理人工智能价值观

|

| 数据源和数据版本控制 |
| --- |

+   数据目录

+   数据访问控制

+   数据溯源和来源

+   数据隐私和安全

|

+   偏差评估

+   数据伦理审查流程

|

| 数据分析和实验管理 |
| --- |

+   数据隐私和安全

+   数据访问控制

+   数据处理监控

|

+   公平性指标和偏差分析

+   实验可重复性

+   可解释人工智能（XAI）技术

+   实验文档

+   实验的伦理审查

|

| 特征存储和工作流程 |
| --- |

+   特征版本控制

+   带有元数据的特征编目

+   特征存储的访问控制

+   特征溯源和特征来源

+   特征文档

|

+   对潜在偏差和非歧视的特征评估

+   特征文档

+   隐私保护的特征工程

+   特征重要性分析

|

| CI/CT/CD：ML 管道编排 |
| --- |

+   数据操作（DataOps）

+   自动化数据概要分析

+   自动化异常检测机制

+   CI/CD 管道中的治理检查

+   数据的自动化合规性检查

+   CI/CD 管道中的数据安全

+   CI/CD 管道中的数据质量检查和验证

+   敏感数据保护

+   CI/CT 工作流程中的数据漂移检测和警报

|

+   代码更改与模型版本之间的可追溯性

+   文档（为透明度生成模型卡片）

+   部署前的伦理影响评估

+   在人类监督下的逐步推出策略

+   自动化合规性检查

+   模型公平性和偏差测试

+   治理审批门

|

| 模型注册和模型版本控制 |
| --- |

+   模型注册表的访问控制和权限

+   与数据版本控制对齐的模型版本控制

+   模型的版本历史

|

+   伦理元数据

+   模型注册表中的治理信息

+   模型部署的审批工作流程

+   模型限制、潜在偏差和预期用例的文档记录

+   模型血缘跟踪

+   模型风险评估

+   模型审计跟踪

|

| 模型部署 |
| --- |

+   部署的模型遵守数据隐私和安全法规

|

+   带有道德考量的金丝雀发布和 A/B 测试

+   关键决策中的人机协作流程

+   负责任的人工智能清单（部署前验证）

+   部署后的道德价值观监控

|

| 预测服务 |
| --- |

+   输入数据验证

+   敏感输出保护

+   预测服务期间的数据隐私

+   预测服务期间的用数据监控和审计以确保合规

+   预测请求和响应的审计和日志记录

+   检测并警告预测质量、性能或公平性指标中的任何偏差

|

+   公平性和偏差的实时监控

+   预测解释

+   道德输入验证

+   预测审计日志

|

| 模型、数据和应用程序监控 |
| --- |

+   监控生产机器学习系统中的数据质量、偏差和漂移

+   调查和修复数据治理问题的流程

|

+   监控具有道德影响的（持续公平性和偏差监控）数据漂移和概念漂移

+   遵循道德关键绩效指标的性能监控

+   AI 治理违规警报

|

| 元数据管理 |
| --- |

+   数据分类和元数据架构

+   数据治理元数据（数据血缘、来源、合规检查、访问日志）

|

+   AI 系统和其治理状态的清单

+   AI 监管合规元数据

+   管理政策的版本控制

+   人工智能治理文档

+   模型、数据和治理决策之间的可追溯性

+   捕获模型目的、使用的数据、性能指标、合规检查和批准的元数据

|
