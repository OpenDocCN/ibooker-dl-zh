# 前言

欧盟的人工智能法案，自 2024 年 8 月起全面生效，标志着全球人工智能监管的一个分水岭。作为第一个全面的人工智能法律框架，其明确目的是：在欧盟内促进创新和发展，同时有效减轻人工智能系统带来的潜在风险。这项雄心勃勃的法规建立了一个统一的法律框架，该框架管理着欧盟范围内人工智能系统的开发、上市、投入使用和使用。

初看欧盟人工智能法案的复杂性，可能会让人认为这是一个仅属于法律团队和政策专家的任务。法案确实复杂，包含 113 篇文章，涉及高度技术性问题，辅以 13 个附件详细说明实施细节和 180 个序言（提供背景和解释的引入性陈述）。然而，正如欧盟人工智能法案的实践要求所揭示的，*实现并维持法案的合规性本质上是一个工程问题*。这是本书的核心信息。

运营欧盟人工智能法案合规性远不止法律解释。它需要建立角色、流程、结构和人工智能工程实践。例如，上市后的合规性直接需要实施机器学习操作（MLOps）实践，如监控和警报。成功实现欧盟人工智能法案合规性与理解人工智能系统的设计、开发和维护密切相关。

合规性不是在开发生命周期结束时应用的法律印章，而是一个必须从开始就融入人工智能系统核心的持续过程。法案基于“可信人工智能”的概念，要求系统在其整个生命周期中合法、道德且稳健。这需要将道德和合规方面直接嵌入到人工智能系统开发过程中。

本书作为您的指南，帮助您应对作为工程挑战的欧盟人工智能法案合规性。我们将探讨完成此任务所必需的各种实用方法和框架，包括：

人工智能工程

定义为将软件工程原则应用于人工智能系统的端到端生命周期，包括设计、开发、部署和维护。

CRISP-ML(Q)

此结构化的机器学习开发流程为在设计、开发和维护人工智能系统时考虑合规性提供了一个蓝图。它对人工智能生命周期中质量保证和持续风险管理的强调与欧盟人工智能法案的风险基础方法直接一致。CRISP-ML(Q)要求记录整个开发过程，包括风险管理措施，这对于满足法案的技术文档和透明度义务至关重要。

MLOps Stack Canvas

MLOps 堆栈画布是一个全面且实用的框架，旨在指导组织构建和管理其机器学习操作基础设施。画布围绕三个核心领域构建：数据与代码管理、模型管理和元数据管理。它提供了成功部署机器学习所需组件的整体视图。通过与 CRISP-ML(Q)流程模型对齐，画布确保了机器学习生命周期的每个阶段都得到解决，从数据来源和版本控制到模型部署和监控。它强调诸如可重复性、可靠性和效率等关键方面，帮助团队规划基础设施成本，选择合适的工具，并建立稳健的工作流程。作为战略和运营工具，MLOps 堆栈画布促进了组织内所有机器学习和人工智能项目利益相关者之间的清晰沟通。

SMACTR（范围界定、映射、工件收集、测试和反思）

作为一种内部审计框架，SMACTR 旨在指导在其整个生命周期中实施道德人工智能开发的实际操作。SMACTR 倡导一种主动和预防性的方法来促进人工智能开发。将审计流程嵌入到设计和开发阶段，使工程师能够在部署前预见并解决潜在风险，这与法案强调的风险缓解重点完美契合。SMACTR 在每个阶段生成详细文档的焦点对于满足法案对高风险人工智能系统技术文档的要求也是至关重要的。

CRISP-ML(Q)与人工智能工程之间的协同作用提供了一个强大的框架，用于解决欧盟人工智能法案的合规性问题。此外，将 SMACTR 与 CRISP-ML(Q)方法相结合，为负责任地开发人工智能系统提供了一个稳健且可审计的过程。这种组合允许在机器学习生命周期中主动地将合规性工程化，从数据收集到监控，而不是将其视为事后之想。

本书还探讨了这些工程原则如何应用于法案的风险分类——禁止、高风险、有限风险和低风险。虽然高风险系统面临最严格的要求，但第 50 条引入了透明度义务，适用于所有旨在直接与人类互动的人工智能系统，无论其风险水平如何。这些义务，如告知用户人工智能交互和标记合成内容，需要实际工程解决方案来主动遵守。将人工智能工程实践与 SMACTR 和 CRISP-ML(Q)对齐，为管理人工智能系统生命周期提供了结构化和自动化的方法，以实现透明度。

本书还讨论了通用人工智能（GPAI）和生成式人工智能（GenAI）带来的特定挑战，这些是法案中的后期但重要的补充。生成式人工智能操作（GenAIOps）的概念被引入，作为传统 MLOps 原则的扩展，以处理 GPAI 和生成式人工智能应用的独特复杂性。将人工智能工程原则应用于实施 GPAI 的透明度义务，以及整合 CRISP-ML(Q)、SMACTR 和 GenAIOps，对于导航这个不断发展的领域至关重要。

# 适合阅读本书的人群

本书旨在为人工智能工程师、MLOps 从业者、数据科学家、人工智能产品经理以及任何参与人工智能系统实际开发和部署的人士提供参考。它展示了通过应用稳健的方法、严格的文档编制以及持续整合伦理考量，人工智能团队可以构建既具有技术创新性，又符合可证明的合规性、值得信赖并符合社会期望的系统。我试图通过引入一个全面的框架和实用的清单，将人工智能工程实践与整个 CRISP-ML(Q)生命周期中的欧盟人工智能法案条款相一致，使本书尽可能具有可操作性。

如人工智能网像 Net 的创造者、被称为人工智能教母的 Fei-Fei Li 最近[指出](https://oreil.ly/_PUIb)：“现在比以往任何时候都更需要一个治理框架。”本书提供了实施此类框架的实用工程基础，使从业者能够通过经验验证、风险意识开发和协作实践构建符合欧盟人工智能法案严格要求的人工智能系统。法律设定了要求，但合规性是由工程实现的。

# 导航本书

本书旨在作为您的参考，指导通过人工智能工程实践和将其整合到人工智能生命周期中，从数据收集到监控，进行主动的欧盟人工智能法案合规。每个章节都是相对独立的，并适当引用了其他章节。章节组织如下：

+   第一章，“理解人工智能法规”，提供了对欧盟人工智能法案和建立值得信赖的人工智能系统的必要性的基础理解。它概述了构建此类系统所需的七个基本要求：人类代理和监督；技术稳健性和安全性；隐私和数据治理；透明度；多样性、非歧视和公平；社会和环境福祉；以及问责制。本章描述了法案的结构，包括定义、关键参与者、风险分类和实施时间表，并概述了这一重要监管框架。

+   第二章，“AI 工程：主动合规的催化剂”，解释了如何将 CRISP-ML(Q)与 AI 工程相结合，以帮助组织满足欧盟 AI 法案的合规要求。CRISP-ML(Q)通过不同的阶段（如数据准备和模型评估）引导 AI 生命周期，而 MLOps 原则，包括自动化、版本控制、测试和监控，为确保 AI 系统可靠、可重复和持续合规提供了运营基础。在本章中，您还将了解 MLOps Stack Canvas 作为定义必要技术基础设施的框架，涵盖数据、代码和模型管理，以支持主动合规工程。

+   第三章，“数据与 AI 治理及 AI 工程”，解释了在欧盟 AI 法案背景下数据治理和 AI 治理的关键作用。在本章中，您将了解这些治理概念如何实际集成到 AI 系统开发生命周期中，以确保可信和合规的 AI。

+   第四章，“AI 系统评估和针对不同风险级别的 AI 工程定制”，重点关注组织实现欧盟 AI 法案合规性的关键初始步骤。您将了解如何创建现有 AI 系统的清单以及如何确定其风险级别以确定适用的义务。本章还解释了组织可以承担的不同角色（提供者或部署者），这进一步定制了合规要求。

+   第五章，“高风险 AI 系统的 AI 工程”，提供了通过 AI 工程实践实施欧盟 AI 法案对高风险 AI 系统要求的全面指南。它分解了法案的关键条款（第 9 条至第 15 条），重点关注风险管理、数据治理、文档编制、记录保存、透明度、人工监督、准确性、鲁棒性和安全性等方面。您将了解如何将法案的法律要求映射到特定的质量属性，以及如何将它们集成到 CRISP-ML(Q)生命周期中。本章展示了文档和元数据管理对于证明合规性和确保高风险 AI 系统可信度的重要性。

+   第六章，“面向有限风险 AI 系统的 AI 工程”，重点介绍如何开发符合欧盟 AI 法案透明度要求的 AI 系统，这些要求与高风险系统所需的更严格的合规性评估不同。在这里，您将了解如何将 SMACTR 框架与 CRISP-ML(Q)生命周期集成。本章还突出了 AI 治理平台和多种技术工具在促进合规和负责任 AI 部署中的新兴作用。

+   第七章，“迈向可信赖的通用 AI 和生成 AI”，解释了法案如何旨在平衡 AI 创新与风险缓解，引入了 GPAI 和系统性风险等概念。它概述了生成 AI 系统的具体透明度义务，例如告知用户 AI 交互和标记合成内容，并详细说明了 GPAI 模型的法规，包括对提供商和部署者的文档和风险管理要求。您还将了解 GenAIOps，这是一个框架，通过将其与 CRISP-ML(Q)和 SMACTR 框架等既定方法集成，将透明度和合规性方面与 GenAI 开发和部署的操作化相结合。

# 本书使用的约定

###### 小贴士

此元素表示提示或建议。

###### 注意

此元素表示一般性说明。

###### 警告

此元素表示警告或注意事项。

# O’Reilly 在线学习

###### 注意

超过 40 年来，[*O’Reilly Media*](https://oreilly.com)一直提供技术和商业培训、知识和洞察力，以帮助公司成功。

我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。O’Reilly 的在线学习平台为您提供按需访问实时培训课程、深入的学习路径、交互式编码环境以及来自 O’Reilly 和 200 多家其他出版商的大量文本和视频。更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。

# 如何联系我们

请将有关本书的评论和问题寄给出版社：

+   O’Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   加州塞巴斯蒂波利斯 95472

+   800-889-8969（美国或加拿大）

+   707-827-7019（国际或本地）

+   707-829-0104（传真）

+   *support@oreilly.com*

+   [*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)

我们为这本书有一个网页，其中列出了勘误表、示例以及任何其他附加信息。您可以通过[*https://oreil.ly/AI-engineer-EU-AI-Act*](https://oreil.ly/AI-engineer-EU-AI-Act)访问此页面。

想了解有关我们的书籍和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。

在 LinkedIn 上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media).

在 YouTube 上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia).

# 致谢

将这本书带到生活中来是一个真正令人满足的经历。在整个写书过程中，我得到了许多人的支持——非常感谢所有帮助这本书成为现实的人！

我特别想向本书的技术审稿人表示衷心的感谢：Una Galyeva、Katharine Jarmul、Janna Lipenkova、Anil Sood 和 Debmalya Biswas。他们在阅读初稿并提供评论、建议和修正方面投入了宝贵的时间和精力，他们对提高本书的整体质量做出了重大贡献。

在整本书的生命周期中，O’Reilly 的每个人都与我们一起出色地工作，从 Nicole Butterfield 开始，她立刻看到了核心信息——欧盟人工智能法案合规性本质上是一个工程挑战——的潜力。Sara Hunter 与我紧密合作，塑造和编辑这本书，当我准备进入生产流程时，Kristen Brown 表现得非常出色。向整个 O’Reilly 团队表示衷心的感谢，包括校对员 Rachel Head、校对员 Kim Cofer、索引员 Ben Hurst、插图师 Kate Dullea 以及封面设计团队 Monica Kaamsvaag 和 Susan Brown。你们都是英雄！
