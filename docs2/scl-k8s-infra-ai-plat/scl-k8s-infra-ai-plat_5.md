# 第六章。总结与展望

在这份报告中，你了解了管理人工智能项目多层生命周期的内容（图 1-1 中的 AI 开发生命周期和图 3-1 中的 AI 模型生命周期），以及那些旨在实现每个阶段规模化的开源 Kubernetes 工具。你学习了如何利用开源工具成功地将生成式 AI 模型通过这些周期，标准化模型创建的过程，并允许你自信地部署和管理生产中的 AI 模型。

为了理解这些阶段如何相互作用，每个阶段应使用哪些开源工具，以及它们在实际中的样子，让我们来看一个示例项目。

# 个性化医疗聊天机器人

在这个例子中，让我们跟随一家大型健康保险公司的一个虚构生成式 AI 团队，它提出并构建了一个个性化的健康聊天机器人。在 AI 开发生命周期的第一阶段，项目被启动。

在*项目启动*阶段，生成式 AI 团队负责人与团队的工程总监、销售负责人、IT 负责人和研发总监会面，讨论由团队成员提出的一个项目想法。她提出一个个性化的聊天机器人，医疗订阅者可以通过它与个人健康、保险政策和医疗服务提供者互动来导航问题。她声称这可以减少客户代理在常见个性化任务上的时间；减少个人可识别信息（PII）和健康信息暴露给客户代理；并增加订阅者对其自身医疗保健的控制权，降低成本并提高满意度。

业务部门被她提出的案例说服了，但工程总监持怀疑态度。数据将如何得到保护？将使用哪些技术？我们如何部署这个系统并服务于所有客户？团队负责人向工程总监解释了这一点，她对她的回答感到满意。我们将在本章的剩余部分详细阐述她的计划。

一旦项目启动被开发和同意，下一个阶段，如图 图 1-1 所示，是 *数据准备*。我们的技术负责人团队开始收集数据以训练和个性化聊天机器人。团队选择了一个流行的 *基础模型*，它将微调以更好地访问非可识别的公司内部信息，然后将在推理时间使用用户个人信息，结合提示工程和检索增强生成 (RAG) 技术来进一步个性化单个聊天机器人会话。在这个阶段中，是 AI 模型生命周期从 图 3-1 的第一个阶段：*收集训练/微调数据*。团队从其医疗保健合作伙伴和内部系统构建数据摄取管道，*在线分析处理 (OLAP)* 数据库来存储这些数据，以及对象存储技术来存储额外的数据和视图。

接下来，生成式 AI 团队进入 AI 开发生命周期的 *模型实验* 阶段。这是一个迭代阶段，包括 AI 模型生命周期的以下阶段（图 3-1）：

+   开发训练/微调代码

+   执行训练/微调作业

+   评估训练好的模型

团队花费了几个月的时间来做这项工作，构建了初始模型训练代码框架，团队将在其上微调基础模型并测试 RAG 技术和不同的提示。团队致力于一个云无关的开源平台，以允许在许多环境中拥有更大的灵活性，因此选择使用 Kubernetes 来构建其基础设施。由于微调一个基础大型语言模型（LLM）的强度不如从头开始训练，团队选择使用 PyTorch 库在公司的数据小语料库上微调现有的较小基础模型。早期探索版本是在一个小型的 Jupyter 笔记本环境中创建的，但随着微调数据集、基础模型和微调模型规模的增加，团队转向了 [Kubeflow](https://www.kubeflow.org) 和 Kubeflow 训练操作员来在其 Kubernetes 集群上扩展微调过程。

随着团队对其微调模型的新版本进行训练和评估，管理训练集群变成了一个头疼的问题，因此团队决定投入时间寻找一个训练资源管理工具。此时，团队对 Kubernetes 已经更加熟悉，并希望确保在不过多抽象的情况下拥有足够的控制权。团队采用了 [Kueue](https://kueue.sigs.k8s.io) 来排队并优先处理资源密集型训练作业，确保最高优先级的作业首先运行。

然而，在项目早期，团队决定需要一款实验跟踪工具。团队知道在第一个候选模型准备好被推广到生产环境之前，他们需要频繁地重复微调/评估周期，并且需要一种方式来了解谁做了什么。由于团队之前选择了 Kubeflow 作为其首选平台，因此团队能够使用[Kubeflow Pipelines](https://oreil.ly/bjLBl)来构建可重复的训练作业，并使用 Kubeflow Model Registry 来跟踪训练模型。这允许数据科学团队能够跟踪微调模型工件、提示工件和模型评估指标，使得团队领导在决定何时将模型投入生产时生活更加轻松。

这一阶段的关键交付成果是生产就绪的模型工件和一个可重用的训练管道，它加速了这一阶段以及部署模型的定期重新训练。该管道本身使用 GitOps 原则（见第三章）和[Argo CD](https://oreil.ly/00FxF)进行干净地版本控制，以管理连续交付干净的生产管道版本，这些版本将被用于训练生产模型。

同时，生成式 AI 团队的工程师们正在与产品工程团队合作，设计和构建 API 和工件存储，这使得生成式 AI 团队能够自主部署新模型，而产品工程团队能够构建一个无需了解模型任何细节的聊天界面。这是模型开发生命周期中的*应用集成*阶段，对于较小的团队来说，这可能在训练出第一个生产就绪模型之后才会发生。

“最后”阶段（引号是因为这是一个循环、迭代的过程）是将模型投入*生产服务*。在图 3-1 中，这对应于*将模型推广到生产进行推理并监控所提供模型*（见第四章）。

当一个模型被推广到生产环境时，会建立一个系统来部署所选的工件，并在 API 后面提供服务。在生产运行期间，会监控指标以确保模型按预期运行，并且服务基础设施能够及时向用户返回结果。我们的生成式 AI 团队领导选择使用[KServe](https://oreil.ly/sZzWk)和[vLLM](https://docs.vllm.ai)运行时。她选择 KServe 是因为它与 Kubernetes 生态系统的紧密集成和活跃的开发者社区。她选择 vLLM 运行时是因为它是专门为大规模服务 LLM 而构建的，并且具有许多功能和优化，可以快速处理大量推理请求。这种组合还带来了模型上的标准 API，产品团队可以访问它以完成应用程序集成和金丝雀部署，逐步向少量用户推出和测试新模型版本。

在整个过程中，团队花了一些时间定义了多个指标，以跟踪生产模型。其中一些来自 vLLM，一些来自 KServe，一些是来自客户的客户反馈评分，还有一些是团队自己构建的。得益于与 KServe 的集成，团队的 MLOps 工程师正在使用[Prometheus](https://prometheus.io)来可视化和监控生产模型的指标，并立即对性能缓慢、流量激增、数据漂移和故障做出响应。

几次使用 Prometheus 帮助团队及早发现增长中的扩展问题，KServe 提供的金丝雀部署防止了问题影响超过少数用户。遵循 GitOps 最佳实践允许团队将问题基础设施版本回滚到之前已知的好版本，给团队成员时间诊断和修复任何发现的错误，然后再重新部署。

在早期测试期间，团队发现用户能够从聊天机器人那里获得不适当的答案，并且一些与聊天机器人的对话被认为是不礼貌的。团队中的机器学习工程师最近阅读了关于[TrustyAI Guardrails](https://oreil.ly/wOv-O)（见第五章）的内容，并开始了一个将护栏构建到 KServe 中的倡议。借助 Prometheus，团队能够监控不适当响应和交互的检测以及这些实例的客户反馈。使用护栏，团队能够将负面交互减少了惊人的 87%。

结果令人震惊：客户代理有更多时间提升技能并处理更复杂问题的客户，客户可以在会话界面中获取个性化信息，而无需打电话或等待真人代理，她的团队为整个组织的未来生成式 AI 计划制定了蓝图。

但团队的工作还没有完成，实际上直到该功能被淘汰或被另一种技术取代之前，工作都不会结束。因为模型是在整个组织的数据上微调的，所以它必须定期进行微调、评估和重新部署，以确保其拥有最新的信息。令人惊讶的是，这将是一项简单的任务，只需要一到两名数据科学家不到一周的时间就能完成。这一切都归功于生成式 AI 团队领导者的前瞻性思维，通过指导创建和使用带有 GitOps 的可重复使用训练管道、通过注册表进行模型版本跟踪、数据版本化以及使用可预测的数据存储。

# 未来技术展望

接下来，这个勇敢的生成式 AI 团队将有何作为？我们预计，在未来几个月内，AI 和 AI 平台创新将沿着三个广泛的维度发展：

+   模型架构、它们产生的功能以及创建它们所使用的工具和技术

+   支撑整体 MLOps 生命周期的工具之间的集成程度以及利用这些集成解决方案以更具成本效益的方式构建智能应用的能力

+   在推理优化方面的进一步创新，以减少响应延迟，包括量化技术、LoRA 适配器、动态批处理和推理工作负载调度技术

+   以确保 AI 的负责任和值得信赖的使用方式构建和维护 AI 赋能应用的能力

在第一个维度上，我们将继续看到，随着计算资源变得更加高效、更高效，并且更容易获得，最大的模型将变得更大。同时，我们还将看到针对组织自己的数据进行定制的小型模型的创新方法，以便在特定领域用例中以更低的成本产生高性能结果。通用 AI 将变得更加强大，特定用例的模型将更容易创建。利用这些创新的关键在于利用具有强大开源社区采用的框架和训练平台，以便在新技术的最前沿占据有利位置。

在第二个维度上，平台套件如 Kubeflow 将捆绑 AI 模型和开发生命周期中的工具，这将使数据科学家更容易以对他们越来越透明的方式使用每个组件。例如，用于训练模型的库将原生集成到实验跟踪和模型注册工具中，以便自动跟踪数据科学家的实验。此外，这些解决方案将附带工具，可以自动检测和响应模型训练和部署期间的硬件故障，从而降低开发和运行模型的整体成本。这些项目将通过更好地管理计算资源并在数据科学团队之间共享这些资源来提高和改善管理模型开发成本的能力。

管理计算资源是第三维度的主题。在这里，我们将看到通过持续研究新的量化技术（其中模型的权重和激活以较低精度的数据类型表示，从而减少内存使用）、高效利用[键值（KV）缓存](https://oreil.ly/MOnY_)、LoRA 适配器和动态批处理技术（根据批大小或经过的时间将硬件加速器的请求进行批处理），所有这些都在于更有效地使用如 GPU 这样的硬件加速器。我们还将开始看到在硬件加速器上调度和执行推理工作负载的全新创新，再次以提高现有加速器的效率。

在最后一个维度上，我们预计将看到更多资源（财务、人才等）、研究和工具被投入到生成式 AI 的道德和安全训练及使用中。从训练数据溯源和追踪到模型可解释性和安全工具，如护栏和幻觉检测，生成式 AI 极大地扩展了 LLMs 有害创建和使用的能力。由社区驱动的项目，如[TrustyAI](https://oreil.ly/PXDlY)和特别提到的 TrustyAI Guardrails，以及[Guardrails Hub](http://hub.guardrailsai.com)，已经使保护用户、个人身份信息（PII）和企业免受 LLMs 可能带来的各种直接和间接危害（如诉讼）变得比以往任何时候都容易。此外，我们预计还将出现更多关于道德收集和共享大型数据集的规范和工具，以保护隐私和知识产权。

# 关于作者

**Alex Corvin**是一位高级工程经理，负责在 Red Hat OpenShift AI（Red Hat 的旗舰 AI/ML 平台）中构建和执行数据科学家实验和模型训练的能力。Alex 负责创建和增强分布式训练和微调 AI 模型的功能，包括广泛的语言模型，使用 Ray 和 PyTorch 等工具。Alex 及其团队在多个突出的开源项目中做出了重大贡献，包括 Kubeflow Pipelines、Kueue、Kuberay、Feast 和 Kubeflow Training Operator。Alex 在 Ray Summit、DevConf、NVIDIA GTC、OpenShift Commons 等多个行业会议上发表过演讲。

**Taneem Ibrahim** 是一位高级工程经理，他的团队负责开发企业级 MLOps 产品 Red Hat OpenShift AI 的多个项目。作为产品工程工作的一部分，Taneem 及其团队参与了许多开源项目，如模型服务（KServe、ModelMesh、vLLM）、负责任的人工智能（TrustyAI、AIX360）以及模型注册（KubeFlow、ML Metadata）。Taneem 还与广泛的 AI 合作伙伴生态系统合作，以实现与 OpenShift AI 和 IBM watsonx.ai 的集成。Taneem 曾在许多行业活动中发表演讲，如 Ray Summit、Red Hat Summit 和 KubeCon。

**Kyle Stratis** 是一位拥有超过十年经验的软件工程师，在多个领域的 AI 开发生命周期中都有所涉猎，包括计算机视觉、医疗技术和社交媒体分析。除了是一位 O’Reilly 的作者外，他还是[Stratis Data Labs](https://stratisdatalabs.com)的创始人，这是一家 AI 和数据咨询公司，最近曾担任 Vizit Labs 的首席机器学习工程师，在那里他构建了 Vizit 的内部 AI 平台。
