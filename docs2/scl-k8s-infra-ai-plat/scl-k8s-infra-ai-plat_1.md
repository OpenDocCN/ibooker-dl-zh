# 第二章\. Kubernetes 上的模型开发

在本章中，我们将概述使用 Kubernetes 作为计算平台开发机器学习模型的现有技术和方法。虽然我们将关注与大型语言模型（LLMs）和生成式人工智能相关的特定技术，但我们讨论的许多技术也适用于传统的预测模型和其他架构。

从历史上看，模型需要大量数据准备来创建高质量、充分捕获问题域的标记数据集。创建这些数据集非常劳动密集且成本高昂。最近，计算能力的进步、改进的算法用于在计算资源之间分配训练，以及训练数据的广泛开放访问，所有这些都为构建无需大量数据整理的极其强大的通用模型铺平了道路。

通常，基础 LLMs 是通过在极其庞大、未标记的数据集上进行的自监督学习，一种无监督学习类型来创建的。对于 LLMs 来说，这导致了一个能够理解人类语言中的模式并预测给定输入后最可能输出的模型。这些基础模型在广泛的任务中表现出实用性，但从业者通常需要将这些预训练的基础模型适应到某些特定用例中。

有几种流行的技术用于适应这些基础模型，这些技术在预期的用例、实施难度和实施成本方面各不相同。总的来说，我们将把这些方法称为*模型定制技术*。

# LLM 定制技术概述

与生成式人工智能的许多领域一样，LLM 定制空间正在迅速发展，新技术被定期发明。一般来说，定制是通过以下一个或多个基本技术之一实现的：

+   通过不改变模型但仔细构建输入以获得期望的结果来定制现有模型的输出。这种方法包括*提示工程*和*检索增强生成*（RAG）。

+   将单个模型组合起来以实现比单个模型更理想的结果。这种方法的例子之一是[*混合代理*方法](https://oreil.ly/vw3kM)。

+   使用针对特定任务定制的精选数据重新训练现有模型。这被称为*微调*。

新颖的模型定制技术可能通过更有效地实现这些基本技术的新算法或通过创造性地结合这些技术来实现，例如在[*检索增强微调*（RAFT）](https://oreil.ly/feMXE)的情况下。

在本节的其余部分，我们将介绍两种最突出的模型定制方法（截至本文撰写时）：RAG 和微调。

## Retrieval-Augmented Generation

预训练基础模型的一个基本限制是，它们只拥有它们训练过的数据的“知识”。如果你询问一个模型关于它没有训练过的数据，它将无法给出所需的答案。RAG 是一种技术，通过在查询时将相关上下文数据作为输入传递给模型，从而扩展了现有模型的知识。

那么，RAG 是如何工作的呢？通常，当用户查询模型时，会查询数据库（通常是[向量数据库](https://oreil.ly/2L8-k)）以获取与输入查询相关的信息。RAG 系统解析结果，并使用类似[余弦相似度](https://oreil.ly/7uOIh)的算法来选择与查询最相关的结果。一旦选择了这些结果，它们就被添加到原始查询中作为上下文信息，并以“仅使用在此输入文档中找到的信息，为我回答这个问题”的格式发送给模型。图 2-1 展示了假设的 RAG 系统。

![图片](img/skia_0201.png)

###### 图 2-1\. 一个通用 RAG 系统的示意图，展示了用户、检索系统、向量数据库和模型之间的交互

所选的检索和排名算法对 RAG 系统的性能至关重要。如果系统没有检索到相关的上下文数据，模型将缺乏向用户提供所需答案所需的知识。

尽管 RAG 需要在用户和模型之间使用检索系统和额外的数据存储，但它具有许多优点。因为 RAG 在运行时补充了模型的知识，所以它需要将更少的知识烘焙到模型中，并开启了使用更小、更便宜的服务于用户的模型的可能性，同时允许用户即时整合快速变化的数据，如股票价格。RAG 还可以通过不需要长时间的重训练过程来减少使用 LLM 实现价值所需的时间。

另一方面，通过 RAG 提供给模型的知识是瞬时的，并且仅存在于单个查询中。你还得仔细设计输入提示，以获得你感兴趣的那种输出。然而，这种定制也有其局限性。如果你想使知识变化持久或完全自定义模型输出的格式，就需要重新训练基础模型。

## 模型微调

训练基础模型众所周知既昂贵又耗时，即使是最大的企业也无法承担。相反，我们可以利用一种称为微调的技术。通过微调，你可以创建一个针对特定领域任务、知识或所需输出格式的优质、标记的数据集。然后你可以使用该数据集在极短的时间内以及极少的训练数据下调整预训练模型。

微调后的模型将包含你希望的知识和行为，从而使你的生产架构避免 RAG 等技术所需的复杂性。然而，微调需要知道如何训练模型，以及收集足够大的训练数据集以影响模型所需的时间，以及进行训练本身可能的高计算成本。

存在许多技术可以优化微调的计算成本，例如参数高效的微调（PEFT）和低秩适应（LoRA）。这两种技术都是通过仅训练预训练模型权重和偏差的子集来工作的。

虽然这很复杂，但有许多工具和整个平台可以帮助训练和微调模型，例如 [InstructLab](https://instructlab.ai) 和 Hugging Face 的 [sft_trainer](https://oreil.ly/9f4mP)，其中许多都在开源 Kubernetes 生态系统中可用。

# 原生 Kubernetes 模型训练工具

虽然有许多训练工具和平台可用，但从基本层面来看，它们都提供了训练和微调模型所需的计算能力。在评估训练工具或平台时，应考虑以下要求：

+   与数据科学家或数据科学团队使用和熟悉的训练框架（分布式或其他）集成。

+   支持您团队希望使用的训练/微调算法。

+   访问硬件优化器，例如加速器（例如，GPU）、专用网络设备和具有多写能力的存储的专用存储提供商。

+   与数据科学家或数据科学团队已经使用的开发环境数据集成。一个能够有效抽象 Kubernetes 的工具是理想的，这样数据科学家或团队就不需要管理它。

在以下子节中，我们将探讨满足这些要求并且具有强大社区采用的开源工具。

## Ray

[Ray](https://oreil.ly/eu-Ll) 是一个框架，它使用户能够将他们的训练和微调过程从单机扩展到机器集群，并且可以通过 [KubeRay](https://oreil.ly/H7Xgz) 操作员在 Kubernetes 上原生运行。它通过 [Ray Train](https://oreil.ly/dLTwc) 与 PyTorch 和其他框架无缝集成，并对 [加速器](https://oreil.ly/TrRP-) 提供广泛的支持。它还附带一个仪表板，为最终用户提供关键监控信息。

###### 注意

[操作员](https://oreil.ly/-lPOg) 是 Kubernetes 的扩展，它通过使用自定义资源来自动化应用程序的生命周期来帮助管理 Kubernetes 应用程序。

Ray 的最大优势是数据科学家易于采用，即使他们对 Kubernetes 不太了解，但它与具有更“原始” Kubernetes 接口的选项相比，在管理 Ray 集群时会产生更高的开销。它也不总是适合极端大规模的训练作业。

## Kubeflow 训练操作符

[Kubeflow](https://www.kubeflow.org) 是一个由社区管理的开源生态系统，包含支持完整 AI 生命周期的 Kubernetes 组件。该生态系统的一部分，Kubeflow 训练操作符（KFTO）是一个 Kubernetes 原生操作符，允许用户使用 Kubernetes 进行大规模模型的分布式训练和微调。它的软件开发工具包（SDK）允许轻松集成到现有环境和代码中，并广泛支持 PyTorch 等常见框架。

KFTO 加速器支持与所选训练框架相关联，因此它支持训练框架和 Kubernetes 支持的任何内容，并且可以扩展到框架和 Kubernetes 能够扩展到的任何级别。与 Ray 不同，KFTO 是在底层 Kubernetes 对象之上的一个薄层，这引入了非常小的计算开销。然而，这也意味着更多的 Kubernetes 细节暴露给用户，这可能会让不需要了解这些细节的数据科学家和开发者感到困惑。

## 与 Kubernetes 的原生训练框架集成

大多数训练框架都有针对 Kubernetes 的特定工具，用于提供计算资源。例如，PyTorch 有一个通用的作业启动器称为 TorchX，它通过其调度器提供 Kubernetes 支持。虽然这种解决方案是最轻量级的，也是数据科学家最容易采用的，但它不太声明性，因此不太适合 MLOps 团队的管理。

另一个潜在的缺点是，这些工具是框架特定的，因此在大组织中使用不同框架的多个数据科学团队中，使用可能不会按比例扩展。这些原生集成最适合在实验阶段的小型数据科学团队。

###### 注意

通常，一旦模型经过训练或微调，你将想要评估其性能。当 Kubernetes 被用作训练平台时，数据科学家在 Kubernetes 外部使用的许多现有模型评估工具也可以使用。

# 管理训练的计算资源

虽然上一节中描述的工具允许你在许多计算资源上进行训练和微调，但这通常需要大量的和昂贵的硬件资源。企业必须特别注意在训练或微调过程中产生的成本。一个强大的管理系统应该能够做到以下几点：

+   促进作业队列的创建，以便在硬件可用时立即处理计算硬件的请求。

+   将资源配额分配给用户组，以限制特定组可以消耗的资源数量。

+   当个别组需要爆发并存在空闲资源时，在组之间共享资源配额。

+   管理资源请求的优先级和基于优先级的作业抢占。

+   在模型、作业和团队级别上提供资源管理的可审计性和报告。

+   允许 IT 团队集中管理所有这些功能，同时保持对用户透明。

目前在这个领域有两个主要的开源项目：[Kueue](https://oreil.ly/JZQ_0) 和 [Volcano](https://oreil.ly/cCQQJ)。这两个项目都是 Kubernetes 原生，并且拥有强大的社区支持。它们还支持管理各种类型的资源，如 Ray 集群、KFTO 作业和 PyTorch 训练作业。

虽然这些项目提供类似的功能，但它们确实有一些关键的区别。Kueue 是官方 Kubernetes 特别兴趣小组项目，因此得到了更广泛的 Kubernetes 社区的认可。它基于将功能委托给现有 Kubernetes 组件的设计原则，因此 Kueue 相对较轻量。

另一方面，Volcano 复制了一些现有的 Kubernetes 功能，这给它带来更多的开销，但允许它成为一个更全面、更好的集成解决方案。它也比 Kueue 更成熟，截至本文撰写时提供了更多的功能。

一旦数据科学团队有了模型和训练流程，准备将其发送到生产环境，就需要定期重新训练模型，同时跟踪进入每个新版本模型的数据集。在第三章中，我们将讨论定期重新训练、模型版本化和数据集版本化的必要性，以及帮助这些生产流程的工具。
