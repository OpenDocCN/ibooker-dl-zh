# 第一章. 深入探讨智能体记忆系统

智能体的“记忆”在本质上等同于数据、存储和检索。每当听到“内存管理”时，你正确地将其解释为“数据管理”。事实上，在软件工程的世界里，我们对数据管理有相当多的了解。那么，为什么我们还需要关于 AI 智能体内存管理的完整报告呢？答案是，虽然数据管理是一个理解的概念，但 AI 智能体对数据的“使用”在本质上与传统工具工程师之前遇到的一切都不同。

请记住，智能体是非确定性系统，它们被编程使用工具和约束，这些工具和约束通常引导它们——但仍然是非确定性的。对这些智能体来说，某些数据比其他数据更相关，所有数据都占用空间，所有智能体都有有限的容量——或者说上下文窗口——来处理这些数据。这一基本洞察塑造了我们设计、实施和管理智能体记忆系统的方方面面。

由于智能体使用数据的方式与传统软件程序有根本性的不同，因此记忆通常被用作人类认知的替代品。这种想法是，如果智能体使用信息以非确定性方式生成——比旧信息更重视新信息，考虑用户上下文和偏好，并动态适应新输入——那么记忆可能是智能体工作方式的适当类比。

这种在类似人类行为和根本不同的架构之间的张力定义了当前智能体记忆系统的状态。在本章中，我们将探讨行业如何通过短期记忆管理、长期持久化策略、新兴技术和诸如命名实体识别等增强技术来应对这些挑战。

# 理解智能体记忆系统

并非每个系统对智能体来说都是相同的，它们在未来肯定会发生变化——它们正在变化！这就是为什么关注特定架构远不如理解更高层次的概念重要。尽管智能体不是传统可编程的，但在内存管理方面，它们遵循经典计算机科学原理。

将智能体记忆类比为计算机中的 RAM。即使上下文窗口扩大，通常情况下，信息越适用、越简洁，查询越直接，结果就会越好。这不仅仅关乎效率；这是关于语言的基本性质以及处理这些信息的系统的本质。

由于代理系统有不同的架构，因此也有不同的内存分类。有些区分感觉记忆（如图像、音频和触觉反馈等信息摄入）、短期或工作记忆（对话历史的活跃记忆缓冲区）和长期记忆（与代理或用户的生活或工作相关的存储）。^(1) 另一些人专注于短期和长期记忆之间的划分，长期记忆的子类别包括情景记忆（特定过去事件）、程序记忆（情境工作知识和学习技能）和语义记忆（一般世界知识）。^(2) 这些思考很大程度上受到心理学领域的影响，心理学可以以类似的方式对人类记忆进行分类。这些区分有助于定制代理与人类、系统和甚至与其他代理的交互方式。特别是，它们影响记忆的存储和检索方式。

# 内存存储和表示

几乎所有的记忆都嵌入到对特定大型语言模型（LLMs）有意义的连续数字向量中，然后存储在向量数据库中。其中一些信息可以被认为是知识（嵌入的文档或工作上下文），而其他信息是传统意义上的记忆（用户偏好、持续指令或相关过去答案）。然后还有不需要保留的情景记忆，例如随机交互或似乎没有持久相关性的问题。

决定每种类型构成的过程是复杂性的开始。与明确定义模式和关系的传统数据库不同，代理记忆系统必须动态地做出这些决定，通常是在不完整信息的情况下。

# 非确定性系统的挑战

我们这些每天与代理打交道的人都知道这种挫败感：过去明确给出的指令在新会话中不再保留，或者更糟糕的是，在较长的会话中忽略了相同的指令。即使记忆被保留，这也并不意味着代理会按照你的预期行事。因为代理不是以传统方式可编程的，所以重复相同的任务可能会得到明显不同的结果。

考虑一个研究助理为同一个问题检索不同来源的情况。这种可变性也扩展到编码代理。毕竟，要求编码代理扫描和迭代改进大型遗留代码库的任务，比要求其从头开始构建新仓库要困难得多。指示代理在一个可能有许多搜索栏的系统中的“修改搜索栏”留下了很大的解释空间。代理为你检索的内容很大程度上取决于因素，如代理必须摄入的上下文大小、它们嵌入的复杂相互作用、它们的相似性指标以及你查询的具体措辞。

# 存储和检索：核心挑战

这需要反复强调，因为这是人工智能代理系统中内存管理最关键的一个方面：知识的保留是动态和随机的，不仅是在存储方面，在检索方面也是如此。

你如何决定应该存储什么？哪些指令足够全面以提供给系统？你是否存储一切？对话可能从几句话到几十页的文本不等，这取决于用户和用例。当存储空间紧张时，你如何清除系统？

有许多策略可以应对这些挑战。一些流行的方法包括：

重要性评分

基于近期、引用频率、用户参与度指标和关键词相关性计算内存重要性^(3)

级联内存系统

允许代理本身选择什么应该提升到长期存储，什么应该检索^(4)

智能压缩

使用专用模型将对话历史压缩为关键细节、事件和决策^(5)

向量存储卸载

将较旧的消息从短期记忆移动到向量存储中，通常伴随着摘要^(6)

工程师通常通过指示大型语言模型（LLM）尽可能地进行总结来压缩信息。但摘要与原文不同。根据定义，信息会有所损失。

# 检索的不精确性

检索使一切变得更加复杂。信息检索通常基于文本之间的相似性，由于语言的不精确性，检索也会变得模糊。经典的例子是*银行*：它可以是一个金融机构或河流的一个方面。

根据模型选择和嵌入，必须使用不同的算法：余弦相似度、欧几里得距离，甚至像词频-逆文档频率（TF-IDF）这样的旧方法。没有单一的方式来搜索和检索信息，速度和准确性之间有很多权衡。

我们在向量数据库空间中确实在进步——本地选项如 ChromaDB、Redis、带有 pgvector 的 PostgreSQL 和 Qdrant 存在，但仍有很大的改进空间。

# 管理上下文窗口限制

所有模型都包含包含用于生成答案的上下文信息的上下文窗口。管理这些限制有不同的方法。使用 FIFO（先进先出），在长时间对话中最早接收到的信息可能最不准确，这意味着最近的信息被优先考虑。

解决这一问题的策略包括智能修剪，其中模型会删除多余的信息。但这也带来了一些后果。考虑关于法律文本的摘要信息：你可能会得到法律论点和主题的大致轮廓，但会失去关键信息，比如否定或案例引用，这会完全改变内容。根据定义，摘要意味着失去细节并采取更高的抽象视角。

将其与 Gemini 2.5 中的更大上下文窗口进行比较，它可以处理数百万个标记。我们可以将更多信息放入模型，但相对于最后的信息，我们可能没有有效的召回能力。如果我们可以生活在一个模型具有完美召回能力的世界里，那将很棒，但变压器自注意力机制的架构要求随着上下文的增加而进行二次方处理。

类似于 FlashAttention 这样的算法试图解决这个问题，但更直接的方法可能是检索增强生成（RAG），它限制了文档的语料库并迫使大型语言模型返回有源信息，而不是在信息中填充多余的内容。

更为精细的方法——我相信它将变得更加流行——是语义缓存。如果我们通过处理传递内容的意义来保留信息检索系统随时间推移的相对上下文，会怎样？频繁检索到的信息得到优先处理。对于像内部大型语言模型或 RAG 这样的系统，其中许多用户与相同的信息语料库进行交流，可能更有效率和成本效益的是在语义上缓存这些信息。语义缓存并非没有缺点——它对于单次问题处理得非常好，但在多轮对话中会崩溃。这些方法将继续得到改进，但基本问题将保持不变：我们如何最有效地存储和检索我们所需的信息？

# 通过检查点实现持久性

检查点对于代理来说是一个关键步骤，尤其是那些参与多轮对话的代理。随着代理与用户或系统交互，它们会定期保存其内部状态（它们的记忆），以便在会话或长对话中持久化信息。不同的组织、产品和系统以不同的方式处理这个过程。关键洞察是，检查点不仅仅是保存状态——它是在动态、非确定性的代理交互世界中使状态可检索和可操作。

处理检查点的方式有很多，不同的团队使用不同的工具。例如，Redis 是一个流行的选择，因为它速度快，非常适合实时应用。一些配置使用 Redis 来保存会话线程或代理状态，这使得跨会话恢复上下文或在不同系统部分之间共享内存变得容易。像自动清理（生存时间）这样的功能有助于保持事物整洁，因此你不会陷入一大堆过时、无关的数据。7

基本上，检查点是为了确保代理不会失去位置，并且它们的记忆在不可预测的 AI 交互世界中既持久又实用。

1 Michael Lanham, 《AI Agents in Action》 (Manning Publications, 2024), 200.

^(2) Manvinder Singh 和 Andrew Brookins, “构建更智能的 AI 代理：使用 Redis 管理短期和长期内存,” Redis 博客, 2025 年 4 月 29 日, [*https://redis.io/blog/build-smarter-ai-agents-manage-short-term-and-long-term-memory-with-redis/*](https://redis.io/blog/build-smarter-ai-agents-manage-short-term-and-long-term-memory-with-redis/).

^(3) Singh 和 Brookins, “构建更智能的 AI 代理。”

^(4) “代理的内存,” LangChain 博客, 2024 年 10 月 19 日, [*https://blog.langchain.com/memory-for-agents*](https://blog.langchain.com/memory-for-agents).

^(5) “如何迁移到 LangGraph 内存,” LangChain 文档, [*https://python.langchain.com/docs/versions/migrating_memory*](https://python.langchain.com/docs/versions/migrating_memory).

^(6) Singh 和 Brookins, “构建更智能的 AI 代理。”

^(7) Brian Sam-Bodden, “LangGraph 与 Redis：使用内存和持久性构建更智能的 AI 代理,” Redis 博客, 2025 年 3 月 28 日, [*https://redis.io/blog/langgraph-redis-build-smarter-ai-agents-with-memory-persistence/*](https://redis.io/blog/langgraph-redis-build-smarter-ai-agents-with-memory-persistence/); Redis 官方文档, Redis, [*https://redis.io/docs/*](https://redis.io/docs/).
