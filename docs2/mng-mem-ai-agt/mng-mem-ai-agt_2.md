# 第二章：长期记忆：构建持久学习代理

对于代理系统中不同类型的记忆，没有单一、普遍的定义——每家公司似乎都有自己的看法。例如，Anthropic、OpenAI 和 Google 都使用略有不同的术语和方法。但更有趣的问题是：代理实际上是如何决定什么算作程序性、语义性或情景记忆的？或者换句话说：什么被视为短期、长期或情境记忆？

沿着这个思路，语义缓存可能发挥重要作用。有时，如果短期记忆被频繁访问，它们可以被提升为长期记忆。相反，很少使用的长期记忆可能会被总结，变得不那么详细，甚至可能完全从系统中删除。这些就是设计代理记忆时需要考虑的权衡和决策。最终，一切都取决于系统是如何构建来管理和保留信息的。由于几乎不可能编程代理来处理每个场景，我们依赖于约束和参数来指导哪些被视为情景记忆、语义记忆或程序记忆。

# 长期记忆类型

行业已经汇聚为三种主要的长期记忆类型，尽管实现方式差异很大：

情景记忆

存储特定的过去经验和事件，功能类似于人类的自传体记忆。公司通常通过在对话历史中实施 RAG 系统来实现这一点，提取相关的片段而不是保留完整的历史。1 常见的方法是使用少样本示例提示，其中代理从过去的序列中学习，关键事件、行动和结果以结构化格式记录。2

语义记忆

维护结构化事实知识——事实、定义、规则——通过知识库、符号人工智能或向量嵌入实现。LLM 从对话中提取信息，将其存储为用户或实体配置文件，这些配置文件被检索并插入到系统提示中，以影响未来的响应。

程序记忆

最少共同区域，但正在增长，它存储了用于自动任务执行的技能、规则和已学习的行为。这结合了 LLM 权重、代理代码和系统提示，一些代理通过“反思”或元提示来更新自己的提示。

代理人工智能领域正从对记忆的严格定义转向更灵活的混合方法，其中记忆可以根据使用模式和重要性评分在类型之间转换。正如 Redis 的首席执行官 Rowan Trollope 观察到的那样，这反映了人类记忆的巩固。正如我们的 REM 周期在我们睡觉时将信息从短期记忆压缩到长期记忆一样，目标是构建能够参与类似过程的代理。3

# 框架中的长期记忆

长期记忆的实际实现跨框架差异很大，每个框架都采取了不同的哲学方法来应对挑战：

LangGraph Stores

来自 LangChain 的创作者，LangChain 是一个用于 LLM 和代理开发的框架，该系统以具有唯一标识符的 JSON 文档形式在命名空间中组织内存，支持语义事实、用户偏好、情景示例和程序化系统提示。LangMem SDK 增加了从对话中提取信息、优化提示和维持持久记忆的工具。4

Mem0（Memory-Zero）

该框架从交互中提取关键事实并选择性地更新长期记忆。它不是存储完整的聊天历史，而是保持简洁的条目以减少内存使用并提高检索速度。用户可以添加基于图的扩展 Mem0g，以映射实体之间的关系以提供额外的上下文。5

Redis 语义缓存（LangCache）

该框架通过语义缓存解决了代理查询的重复性。其实施包括可配置的搜索标准、REST API 和用户特定的安全功能。在撰写本文时，LangCache 处于私有预览阶段，但很快应该对公众开放。6

ADK MemoryService（谷歌的代理开发套件）

该框架提供了一个 BaseMemoryService 接口，具有两个主要功能：将完成的会话添加到存储中并搜索存储的信息。开发者可以在基于 RAM 的关键字搜索（非持久）的 InMemoryService 和用于具有持久语义搜索的生产环境的 VertexAIMemoryBankService 之间进行选择。

# 高级内存管理的技术和解决方案

代理内存技术领域反映了根本性的紧张关系：需要复杂性和简单性、性能和灵活性、创新和可靠性。每个解决方案都代表了对代理如何记忆的不同哲学。

每个框架都反映了不同的优先级和哲学：

LangGraph

采用文档存储方法寻求简单性。易于集成和命名空间组织使其成为快速原型设计和标准代理工作流程的理想选择，尽管它缺乏专业解决方案的复杂性。

ADK MemoryService

提供企业级可靠性，具有清晰的接口和 Vertex AI 集成。其权衡是其限制在谷歌生态系统中——非常适合谷歌云部署，但不太适合多云架构。

向量数据库替代方案

每个都满足不同层次的需求。Pinecone 提供出色的托管服务，非常适合扩展。Weaviate 提供开源的混合搜索功能。Qdrant 专注于性能和高级过滤。Chroma 保持轻量级且对开发者友好。Pgvector 利用熟悉的后端工具，为已经投资于该生态系统的团队提供支持。Redis 通过添加 RediSearch 功能来索引和搜索，利用其作为缓存系统的普遍性。

选择向量数据库并不简单（图 2-1）。你需要 Redis 的原始性能吗？Mem0 的智能抽象？LangGraph 的简单性？ADK 的企业功能？你的答案将塑造你的代理记忆架构和整体系统设计。

![图示代理记忆架构，展示从使用命名实体识别进行输入处理，通过嵌入和评分，到使用余弦相似度从向量数据库检索，以实现高效的记忆存储和上下文检索的过程。](img/mmai_0201.png)

###### 图 2-1\. 评分和检索概述

# 使用命名实体识别增强记忆准确性

命名实体识别（NER）将自然语言的模糊世界转化为计算机和代理可以可靠地工作的结构化精确度。在代理记忆系统中，NER 不仅仅是一个锦上添花的特性；它正成为准确、可检索记忆的必要条件。

## NER 管道及其在记忆中的作用

NER 是一种帮助计算机从普通文本中挑选并标注重要事物——如人物、地点、组织或日期——的技术。将其视为一个代理读取句子并自动突出显示提到的名称、公司或地点的方式，将混乱的语言转化为结构化数据。

这对代理有什么意义呢？当代理能够可靠地识别和标注对话或文档中的实体时，它可以更有效地组织和检索信息。例如，代理可能会使用 NER 来跟踪会议中提到的人物，检索所有关于特定项目的先前讨论，或在不同对话中链接相关事实。这种结构化方法使记忆检索更加准确，并允许代理以更高的精度回答诸如“约翰对预算说了什么？”或“我们上次讨论巴黎是什么时候？”等问题。

现代 NER 系统非常准确，尤其是在针对对话 AI 进行微调时（^(7））。一些代理甚至更进一步，使用增强的 NER 管道将实体作为元数据存储，结合语义和基于实体的搜索，并维护实体之间的长期关系。这将模糊、无结构化的记忆转化为代理可以更容易推理和使用的东西。

NER 可以经历以下三个阶段：

实体提取

识别人物、地点、组织、日期和自定义实体，并为每个实体标记置信度分数，并在对话轮次之间链接实体

内存存储增强

将实体作为结构化元数据与嵌入一起存储，实现结合语义和基于实体的方法的混合搜索，并创建以实体为中心的记忆索引

检索改进

允许通过特定实体查询记忆，通过实体类型过滤结果，并维护实体关系随时间的变化

## 利用结构化数据提高记忆检索和准确性

命名实体识别（NER）不仅仅是关于标记单词——它是关于使内存搜索更智能和更精确。例如，如果你问一个智能体，“约翰对预算说了什么？”NER 让智能体过滤其记忆中的人（约翰）和主题（预算），而不仅仅是进行广泛的关键词搜索。这可以大大缩小搜索空间，并使答案更加相关.^(8)

除此之外，命名实体识别（NER）帮助智能体构建知识图谱——连接人、地点和事物，并跟踪它们随时间的关系。这减少了混淆（例如区分“苹果”公司与其水果“苹果”），并帮助智能体解决代词或模糊引用。

在实践中，许多生产系统已经使用命名实体识别（NER）来改善记忆：Redis Agent Memory Server、Mem0g 和 LangChain 都包括实体识别或实体记忆模块。随着该领域的发展，命名实体识别（NER）已经开始扩展，不仅处理文本，还处理图像和音频，并适应新的领域，而所需的训练最少。

命名实体识别（NER）的结构化数据将模糊、不清晰的记忆转化为智能体可以实际使用和推理的东西——使它们在现实场景中更加有用和准确。

# 摘要

在进入经济考虑之前，让我们回顾一下到目前为止我们关于记忆所学到的内容。

智能体记忆是处理、解释、动态存储和检索数据的过程。这个简单的陈述，开启了我们的探索之旅，对我们构建和思考 AI 智能体的方式有着深远的影响。在本章中，我们看到了这一理念如何塑造智能体记忆系统的方方面面——从我们从人类认知中汲取灵感的方式，到现实世界实施的具体细节。

真正的挑战不仅仅是技术性的：它关乎拥抱智能体所需的不可预测性和灵活性。智能体不仅仅是具有花哨界面的数据库；它们是动态的、自适应的系统，需要在即时记住、忘记和学习之间取得平衡。

如果有一个要点，那就是构建智能体记忆并不是关于将更多数据塞入更大的上下文窗口或追逐最新的数据库。这是关于设计能够智能管理信息的系统——知道保留什么，压缩什么，以及放弃什么。智能体记忆的未来将取决于我们如何让我们的智能体适应、优先排序并理解他们遇到的信息。

最后，记忆只是数据——但是当管理得当，它就变成了知识，当动态应用时，它就变成了智能。这就是智能体记忆系统的真正承诺：将原始数据转化为智能体和人类可以实际使用的东西，一次交互一次。

^(1) Cole Stryker， “什么是 AI 智能体记忆？” IBM，访问日期：2025 年 9 月 8 日，[*https://www.ibm.com/think/topics/ai-agent-memory*](https://www.ibm.com/think/topics/ai-agent-memory).

^(2) “记忆：智能体开发工具包，” Google ADK 文档，[*https://google.git.io/adk-docs/sessions/memory*](https://google.github.io/adk-docs/sessions/memory).

^(3) Rowan Trollope，个人访谈，2025 年 7 月 11 日。

^(4) “在 LangGraph 中启动长期记忆支持，” LangChain 博客，2024 年 10 月 8 日，[*https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/*](https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/); “LangGraph 记忆概念，” LangChain 文档，[*https://langchain-ai.github.io/langgraph/concepts/memory/*](https://langchain-ai.github.io/langgraph/concepts/memory/); “LangMem SDK for Agent Long-Term Memory，” LangChain 博客，2025 年 2 月 18 日，[*https://blog.langchain.com/langmem-sdk-launch/*](https://blog.langchain.com/langmem-sdk-launch/).

^(5) Prateek Chhikara，Dev Khant，Saket Aryan，Taranjeet Singh，和 Deshraj Yadav， “Mem0：使用可扩展的长期记忆构建生产就绪的 AI 智能体，” arXiv:2504.19413，2025。

^(6) Rowan Trollope， “介绍 LangCache 和向量集，高性能 AI 应用的简单解决方案，” Redis 博客，2025 年 4 月 8 日，[*https://redis.io/blog/spring-release-2025/*](https://redis.io/blog/spring-release-2025/); Jim Allen Wallace， “语义缓存：更快、更智能的 LLM 应用，” Redis 博客，2024 年 7 月 9 日，[*https://redis.io/blog/what-is-semantic-caching/*](https://redis.io/blog/what-is-semantic-caching/); Rowan Trollope，个人访谈，2025 年 7 月 11 日。

^(7) Imed Keraghel，Stanislas Morbieu，和 Mohamed Nadif， “命名实体识别的最新进展：全面调查和比较研究，” arXiv:2401.10825，2024。

^(8) “在智能体系统中的基于实体的记忆检索，” 在*AAAI 人工智能会议论文集*，2024 年。
