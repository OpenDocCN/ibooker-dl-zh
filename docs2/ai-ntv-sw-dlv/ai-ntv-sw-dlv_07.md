# 第七章\. 部署到生产

2012 年 8 月 1 日的[Knight Capital 事件](https://oreil.ly/pTAIv)是一个鲜明的例子，说明了软件部署失败可能带来的灾难性后果。那天，Knight Capital，当时美国最大的交易公司之一，对其自动化交易系统进行了大规模更新。由于多种因素的综合作用，包括有限的自动化、部署中的人为错误和糟糕的功能标志管理，过时的代码意外地被重新激活，导致系统在股票市场上[迅速发出错误订单](https://oreil.ly/efPYb)。

在仅仅 45 分钟内，有缺陷的算法执行了超过 400 万笔交易，导致公司损失了 4.6 亿美元。这一事件不仅几乎使 Knight Capital 破产，最终导致其被收购，还造成了重大的市场动荡。它强调了在高风险软件环境中实施稳健的部署实践、彻底的测试、治理和应急机制的关键重要性。

部署到生产可能是一项高风险的活动。虽然并非每个应用程序都是市场制造交易平台，但值得更新的应用程序都有依赖它们的人，任何改变都引入了风险。尽管我们可能更喜欢通过减少部署频率来避免这种风险，但我们面临着对更频繁变更的商业需求。此外，随着我们推迟并积累越来越多的变更到计划发布中，某些类型的风险会增加，这使得持续交付方法更有价值。

在前面的章节中，当我们导航软件交付流程时，我们找到了减轻最终部署到生产环境风险的策略。在第二章中，我们讨论了代码审查的重要性。在第三章中，我们探讨了如何使用早期扫描和单元测试来快速检测问题。第四章描述了额外的测试类型，以加固你的软件，并回顾了部署到测试环境中的最佳实践。通过使用一致的工具、管道步骤和部署策略，并通过参数化环境差异，我们使用我们的部署到测试环境的部署来检验我们的生产部署。在第五章中，我们深入探讨了安全问题，回顾了有助于保护我们生产部署的实践。

今天，人工智能正在改变组织对待生产部署的方式，以防止此类灾难。机器学习系统现在分析部署模式，在部署过程中检测异常，并以比传统监控更高的精度验证应用程序的健康状况。与基于规则的验证不同，后者依赖于预定义的阈值，人工智能系统可以学习每个应用程序独特的正常行为模式，并检测可能表明出现问题的微妙偏差。这些能力使团队能够更快地部署，同时矛盾地降低风险——这与传统的速度与安全权衡相反。

在本章中，除了介绍人工智能的变革性作用外，我们还将探讨治理生产部署的最佳实践和安全的部署策略，并讨论可观察性以验证生产部署的质量。我们将探讨现代人工智能驱动的部署工具如何通过智能验证而不是仅仅通过反应式监控来降低风险，以及人工智能系统如何同时评估多个信号以确定部署健康，捕捉可能被人类操作员忽略的问题。

# 治理生产部署

凯特资本事件是一个很好的提醒：部署存在缺陷的软件的后果可能是灾难性的财务毁灭。您的组织的信任和信誉也处于风险之中。对于组织来说，部署后修复缺陷的成本可能会飙升，远远超过在开发期间解决它们的费用。

为了有信心地部署，我们需要了解哪些代码发生了变化，以及是谁进行了这些更改。我们需要验证我们实施的代码审查流程是否已执行，并了解是谁进行了这些审查。对于引入的任何依赖项，我们希望了解它们，并知道它们是否符合我们的政策。我们希望了解它们是否经过了对已知缺陷的审查。我们需要确保我们要求的构建、扫描和测试流程针对所有代码更改都得到了执行。当然，我们还想确保扫描和测试的结果实际上符合我们通过的标准。最后，我们需要证据证明我们的开发流程本身仍然符合我们组织相关的框架和需求。

严格的代码审查、彻底和稳健的测试实践以及自动化、可重复的部署程序对于避免部署失败至关重要。然而，如果没有适当的治理和控制来确保我们遵守了我们的流程，我们所有的努力都可能变得无效。

人工智能开始改变部署治理，尽管大多数应用仍在出现。当前的 AI 系统主要专注于分析部署模式以识别风险因素和政策违规，而不是做出自主决策。这些系统可以同时处理比人类更多的部署变量，帮助识别代码更改、部署配置和历史事件之间的微妙相关性。组织开始利用这些见解来完善他们的治理框架，尽管对于最终批准决策，人类监督仍然是必不可少的。

###### 注意

部署治理仅仅是系统性地监督和控制软件部署过程，以确保我们定义的规则和政策得到执行。从根本上说，治理是关于降低变更风险。治理包括组织使用的政策、流程和工具，以确保软件部署以一致、受控、安全和合规的方式进行。治理的挑战在于平衡敏捷性和创新的需求与稳定性和风险管理的需求。

在接下来的几节中，我们将讨论部署治理的传统和现代方法。我们将研究如何自动化执行我们的治理政策，以提高我们的交付流程效率。我们将回顾支持我们的治理流程的工具和策略，最后，我们将探讨部署治理的未来。

## 部署治理的传统方法

部署治理的传统方法是为预 DevOps 世界构建的。在这个世界中，对生产的变更很少见、风险高，并由传统的运维团队执行。决策是集中的，涉及严格的过程。

信息技术基础设施库（ITIL）是一个广泛采用的框架，它描述了一种传统方法。ITIL 最初在 20 世纪 80 年代作为对标准化 IT 管理实践需求的回应而出现，从一系列最佳实践发展成为一个全面的框架。它包括几个与部署治理直接相关的流程和实践。

其中之一是变更管理流程，它定义了一种结构化的方法来管理所有对服务和基础设施的变更，包括部署。它规定了提出变更的正式文档，包括其目的、范围、影响和风险评估。变更顾问委员会（CAB）或类似的机构评估变更。变更请求根据其优点和潜在风险正式授权或拒绝。如果变更获得批准并执行，将进行实施后评估，以确保变更实现了其目标并确定任何经验教训。

发布管理流程同样正式，并规范了将发布计划、调度和控制纳入生产环境的流程。它与变更管理流程密切相关，旨在确保部署以受控和透明的方式进行。

CABs 是像 ITIL 定义的方法中典型的特征。CAB 是一个由个人组成的委员会，负责正式评估和批准或拒绝软件变更的提案。这个委员会可能包括负责协调变更请求审查和跟踪变更实施的变更经理，以及技术专家、业务利益相关者、安全专家、合规官员和其他人。目的是通过从多个角度彻底评估请求来降低风险。

此外，如果发生任何问题，CABs 确保了问责制。虽然一个高度运作的 CAB 将提供预期的监督，但最糟糕的情况是，CAB 由粗心大意的审查员组成，他们几乎不做评估就盖章批准。或者，CAB 可能名义上有效，但效率低下。电子邮件驱动的审批流程因被忽视的电子邮件、审批人不在办公室且未进行委托，以及审查会议被重新安排而变得缓慢。

研究表明，这些传统的 CAB 流程不仅效率低下，实际上与它们旨在确保的稳定性背道而驰。在他们的书《加速》中，Forsgren、Humble 和 Kim 在讨论他们对高绩效组织的里程碑式研究时解释说：“外部批准与领先时间、部署频率和恢复时间呈负相关，与变更失败率没有相关性。”换句话说，像 CAB 这样的外部机构批准实际上会减慢交付速度，而不会提高稳定性。

这是因为变更顾问委员会（CABs）将责任与知识分离；对变更理解最深的人并不是做出批准决定的人。虽然这些委员会看起来在尽职调查，但它们通常充当合规戏剧，当事情出错时，组织可以指向某人，而不是真正防止失败。它们提供的控制错觉甚至可能降低实施变更的人的警惕性，因为“变更顾问委员会批准了”成为逃避责任的保护伞。

当应用程序发布频率较低时，CAB 会议的支出以及其无效性和延迟是可以容忍的。随着发布频率的增加，CAB 的问题越来越明显。

## 现代部署治理方法

在前面的章节中，我们探讨了如何通过在每个阶段自动化步骤来简化开发流程，从而实现更快、更频繁的软件发布。现代部署治理方法同样专注于自动化那些成为发布软件不必要的障碍的手动步骤。

与依赖委员会和手动批准的部署决策相比，现代方法更倾向于自动化决策和部署。由于生产部署的风险非常高，这必须非常谨慎地进行。在本节中，我们将探讨如何实现这一点。

除了自动化之外，现代治理方法还利用当代策略和工具来管理合规性。我们将探讨如何使用审计日志简化合规性，以及如何使用像 Open Policy Agent (OPA)这样的工具来执行安全和监管标准。

### 自动化决策

使用现代 CI/CD 工具，我们可以赋予我们的管道自主部署决策的能力。如果我们能确保我们的管道能够充分执行治理政策以维护我们的标准，我们就可以通过减少或最小化手动批准来加速软件交付。

在您的交付过程中自动化部署决策，请考虑以下步骤：

1. 确定您的“通过”标准

明确制定促进构建的标准对于自动化部署流程至关重要，但这可能具有挑战性。我们合作的一家银行将其控制措施记录在一个三英寸厚的活页夹中，包含数百页的法规和政策。通常，决策者可能会同时依赖客观数据和主观判断。模糊性可能使得将人类决策转化为一系列严格、自动化的规则变得困难。例如，如果决策者认为问题风险较低且不太可能影响用户，他们可能会在少数测试失败的情况下提升构建。然而，将这种直觉转化为准确评估风险和用户影响的自动化规则可能很复杂。人工智能在将人类决策的模糊元素引入完全或主要自动化流程中发挥着越来越重要的作用。如果以这种方式使用，它应该需要解释其建议和见解。

2. 使用“质量网关”实现复杂标准以尽可能自动化更多控制措施

网关是 CI/CD 管道中的检查点，用于评估特定标准以确定构建是否应进入下一阶段。网关可以考虑到测试结果、基于静态分析结果的代码质量指标、代码覆盖率以及遵守编码标准、安全扫描结果和性能指标。其他工具允许您引入一个如果决策为“否”则失败的管道步骤，或者您可以根据您特定的标准设置条件执行。通常，最简单的方法是配置每一组测试，如果它不符合您的标准则失败。这样，如果任何步骤失败，整个管道就会停止，防止推广不达标的构建。

3. 在自动化细微决策时考虑历史结果

例如，安全倡议通常从对新的高优先级问题实行零容忍政策开始，但在团队解决现有问题期间则对此予以容忍。这需要考虑历史数据，而不仅仅是最近的结果。

4. 最后，标准化自动化

使用标准化或痛苦的手动合规性选择作为使用标准化工具的激励。与我们合作的银行团队可以选择通过认证，证明发布符合绑定的所有控制措施来部署到生产环境，或者使用他们标准化的自动化流程和工具。这成为了一个简单的选择。

### 建立强大的审计跟踪以自动化合规性

部署治理和合规性密切相关。有效的治理实践对于实现和维护符合各种监管标准和框架至关重要。

我们在第五章中回顾了几个框架，特别是与安全相关的框架。PCI DSS 是一个广泛应用的例子。它被用来确保所有接受、处理、存储或传输信用卡信息的公司都保持一个安全的环境。无论您处理的交易规模或数量如何，如果您的组织处理持卡人数据，那么您就受其要求约束。主要信用卡品牌（如 Visa、Mastercard 等）如果无法证明合规性，可能会处以罚款或限制您处理信用卡支付的能力。

虽然 PCI DSS 主要关注保护持卡人数据，但其中一些要求直接与软件开发和部署过程相关。这是为了确保处理这些数据的环境的整体安全性。例如，PCI DSS 要求您通过在发布到生产之前对自定义代码进行审查和解决常见的编码漏洞等措施来开发和维护安全系统和应用程序。PCI DSS 还包括测试要求，规定在任何重大基础设施或应用程序升级或修改之后进行内部和外部渗透测试。

一个强大而全面的审计跟踪对于展示合规性所需的做法至关重要。尽管您的组织可能不受 PCI DSS 要求的影响，但许多其他相关框架可能对您的开发和部署过程有类似的要求。

您的源代码控制和 CI/CD 系统在这里发挥着至关重要的作用，通过捕捉交付管道中每个动作的细粒度细节，从代码提交和构建到测试结果、部署和环境配置，以及相关的用户、时间戳和任何相关元数据。这包括记录用户操作、系统事件、工件跟踪、配置更改和外部集成。通过以结构化和可访问的格式存储这些信息，CI/CD 工具提供了一种灵活的审计跟踪，可以适应任何数量的安全和监管框架。

支持强大审计跟踪的工具允许您的组织在不为每个框架维护单独日志的情况下证明合规性。它还使您能够积极应对潜在的安全或合规性问题。

### 使用策略即代码进行管理

策略即代码（PaC）在自动化生产部署的同时保持强大的治理能力方面可以发挥重要作用。PaC 是一种将安全、合规性和运营策略定义为代码并管理的实践，允许自动执行。策略以声明性语言定义，可以像其他任何关键代码片段一样进行管理：在源代码控制中进行版本控制，允许跟踪、协作和必要的代码审查，以及回滚功能。

OPA 是一个流行的开源策略引擎，用于实现 PaC。使用 OPA，每次部署都会自动与您定义的策略进行评估，确保一致性的执行，而不会减慢您的交付流程。想象一下，您的部署策略要求所有容器镜像在达到生产之前都必须扫描关键漏洞。使用 OPA，您可以表达这种 PaC，并将其集成到您的管道中。现在，每次触发部署时，OPA 都会自动扫描镜像，如果镜像干净，则允许部署继续进行；如果发现漏洞，则停止部署。这消除了手动安全检查，并确保在无需人工干预的情况下，始终一致地遵守您的安全标准。

OPA 的多功能性不仅限于安全检查。您可以编码各种部署策略，例如强制执行金丝雀部署、要求对特定更改进行批准或验证资源配置。通过自动化这些检查，您可以获得信心，确保每次部署都符合您组织的标准和监管要求。这不仅加速了您的交付流程，还降低了人为错误和非合规的风险。

## 保护部署流程

严格控制你的治理机制有助于保护你的部署。在现代部署中，开发者赋权同样关键。在实践中，你需要在这两者之间找到平衡。虽然你希望让开发者能够调整他们的部署管道，但你还需要防范潜在的风险。恶意行为者可能会篡改或绕过你设置的治理机制，或者它们可能受到人为错误的破坏。或者，对部署的过度严格控制可能会成为高效部署的另一个障碍。

OPA 在这里也能提供帮助。使用 OPA，你对策略更新过程本身应用严格控制，确保对治理框架的任何更改都经过仔细审查并符合规定。通过在 OPA 中集中策略规则并将其应用于管道，你创建了一个关注点的分离。这使得个人开发者更难规避策略，因为他们需要修改中央 OPA 策略，这些策略可能受到更严格的访问控制、同行评审和审计跟踪的影响。

随着我们越来越多地依赖 AI 为我们生成管道，OPA 策略既为 AI 提供方向性输入，说明我们想要什么，又提供保护，确保 AI 的输出符合我们的标准。

在保护部署流程方面，另一个重要的控制措施是实施强大的 RBAC。如第二章中所述，RBAC 允许你细粒度地控制谁有权修改 CI/CD 平台内的管道和敏感配置设置。这确保只有授权人员才能更改你的部署流程，最大限度地降低恶意活动的风险。

通过结合这些方法，你可以集中执行策略，确保你的部署防篡改并得到有效监控。

## 部署治理的未来趋势

在软件开发的大多数领域，人工智能和机器学习将推动部署治理的重要未来趋势。例如，预测分析是数据分析的一个分支，它应用机器学习技术来分析历史数据以预测未来结果。应用于软件部署，预测分析可以用来识别模式和风险因素，以标记潜在问题。供应商正在创建仪表板，例如 Digital.ai 的“变更风险预测”，基于团队失败率和测试中发现的缺陷等趋势。今天，这些解决方案中的大多数都是在大范围内发现的相对简单的相关性。随着我们继续前进，期待模型提供更多见解是合理的，尤其是来自易于访问更大数据集的 DevOps 平台的模型。

您的团队能够在问题影响用户之前主动解决问题。AI 和 ML 可以用于实时自动执行治理政策，分析代码更改、配置和部署，以确保符合安全和操作标准。这些进步将使组织能够以更高的速度、信心和弹性交付软件。

## 调和传统与现代方法

在传统的治理方法中，ITIL 将标准变更定义为预先批准、低风险且程序定义良好的变更，允许以最小正式授权快速实施。通过使用现代 DevOps 实践，依靠质量门和现代政策执行，我们可以显著降低甚至复杂软件部署的风险。这种控制和可靠性水平使得这些部署可以被视为标准变更。本质上，现代 DevOps 实践内在的风险缓解与 ITIL 标准化、可预测的变更管理目标相一致，从而实现更快、更频繁的部署，而不会影响稳定性或合规性。

在“生产部署策略”中，我们将探讨如何使用渐进式部署进一步降低生产部署的风险。

# 生产部署策略

在第四章中，我们介绍了如何自动化我们的部署流程，现在我们已经探讨了如何通过部署治理实践来降低风险。接下来，我们将关注将我们的软件部署到生产环境的实际业务。在本节中，我们将探讨如何通过渐进式部署技术进一步降低风险。即使是最强大的治理和最谨慎的渐进式部署，我们的部署仍可能失败。我们必须准备好回滚策略，因此我们将探讨快速回滚的方法。最后，我们将探讨工具选择。选择现代工具可以帮助您使治理、渐进式部署和回滚变得简单。

## 传统的“大爆炸”部署

在我们探讨现代方法之前，我们可以提醒自己传统的做法——以及对于某些有状态应用程序的某些元素可能仍需要的元素。传统上，我们会将应用程序离线，升级应用程序每个组件的每个实例，然后重新启动应用程序。在快速验证后，我们会将其重新暴露给用户，并观察一段时间以确保其看起来健康，然后才认为部署成功。如果有问题，我们会将应用程序再次离线，并尽可能地将应用程序回滚到最佳状态——这通常是一个艰巨的挑战。

这种传统方法需要应用程序停机，引入了重大风险，并要求工程师投入大量关注。改进的机会很多。

## 使用渐进式交付策略

软件部署可能就像走钢丝一样——一步走错，后果可能非常严重。但是，渐进式部署策略为你提供了一个安全网。通过逐步推出更改并密切监控其影响，这些策略最小化了风险，并在出现问题时允许快速纠正方向。在本节中，我们将探讨包括滚动更新、蓝绿部署、金丝雀部署和功能标志使用在内的多种流行的部署策略。

### 部署滚动更新

滚动部署是一种非常常见的交付策略，通过逐步更新应用程序或服务，通过逐步用新版本的实例替换旧版本的实例来实现。这是以一种受控的方式进行，确保在更新过程中始终有一定数量的实例可用，以处理用户流量。

滚动部署具有独特的优势。它们最小化了中断时间，因为应用程序在整个更新过程中始终保持可访问性。重要的是，滚动部署降低了风险。通过增量更新实例，可以早期发现并解决新版本中可能存在的问题，限制其影响。并且这种部署可以根据特定的应用程序需求进行定制，允许对更新过程的速度和规模进行无限调整。

然而，实施和管理滚动部署可能比其他部署策略更复杂，尤其是对于大规模或分布式系统。也存在不一致性的可能性。在更新过程中，同时运行的两个不同版本的应用程序可能导致数据或用户体验的差异。此外，回滚正在进行的部署可能很复杂，并且需要额外的步骤来保护数据完整性。

实施选项众多。Kubernetes 通过其 Deployment 对象提供了内置的滚动更新支持。新版本的 Pod 逐渐创建，一旦新 Pod 就绪，旧 Pod 就会被终止。容器编排平台（例如，Docker Swarm，Nomad）提供了类似的滚动更新机制，允许逐步替换容器或服务。负载均衡器可以通过逐渐将流量从旧实例转移到新实例来实现滚动更新，新实例一旦可用。在某些情况下，滚动部署可能使用自定义脚本或自动化工具来实现，这些工具管理更新过程并监控应用程序的健康状况。

虽然滚动部署需要实施的努力，但它们为最小化应用程序更新期间的中断和风险提供了一个有价值的选项。

### 使用蓝绿部署

蓝绿部署是一种涉及维护两个相同环境的发布策略，通常被称为“蓝”和“绿”。在任何给定时间，这两个环境中的一个（通常是蓝）是活跃的，负责处理生产流量。

当你的应用程序的新版本准备好时，它被部署到非活动环境（绿色）。在绿色环境中进行测试和验证后，流量从蓝色环境切换到绿色环境，使新版本变为实时。与滚动部署随着时间的推移进行更新，不同流量将体验不同的服务版本不同，蓝绿通常具有硬切换。一个开关被翻转，流量或至少是新流量立即从旧环境转移到新环境。图 7-1 展示了部署更新前后的蓝绿环境。

![](img/ansd_0701.png)

###### 图 7-1\. 蓝绿部署涉及运行两个相同的环境，以实现无缝更新和回滚选项（在印刷书中，蓝色以深灰色显示，绿色以浅灰色显示）

之前的实时环境（现在是蓝色）可以用于下一次部署，作为备份以备回滚需要时使用，或者可以退役。

蓝绿策略提供独特的优势：

减少停机时间

在环境之间切换流量，最小化对用户的任何干扰并减少停机时间。

容易回滚

如果新部署存在问题，可以迅速将流量切换回之前的版本。

改进的测试

在上线之前，可以在类似生产的环境中测试新版本。

主要的缺点在于基础设施成本的增加，因为维护两个完全相同的独立环境可能会很昂贵。此外，蓝绿部署可能不适合具有复杂状态管理或数据库模式变更的应用程序，因为在不同环境之间同步数据可能具有挑战性。

更高级的蓝绿模型可以通过整合 IaCM（基础设施即代码管理）实践来克服大多数基础设施成本挑战。在稳态生产期间，只有一个实例存在。在部署开始时，部署会触发 IaCM 工具来配置一个新实例，因此蓝绿都存在。在过程结束时，多余的实例会被取消配置。因此，多余的基础设施只需在蓝绿部署期间存在。

### 使用金丝雀发布

金丝雀发布提供了一种类似于滚动更新的渐进式策略。应用程序的新版本被部署到一小部分用户或服务器。这个“金丝雀”组充当测试平台，允许你在将新版本提供给所有用户之前，在实际的生产环境中监控其性能和稳定性。

在典型的金丝雀部署中，只有一小部分流量（例如，5% 到 10%）可能会被导向新部署的版本。新版本的性能、稳定性和错误率会被密切监控并与现有版本进行比较。响应时间、CPU 使用率和错误日志等指标会被分析以识别任何潜在问题。如果新版本在金丝雀环境中表现良好，指向它的流量百分比会逐渐增加，允许更多用户访问。这个过程会持续到新版本完全取代旧版本。如果在金丝雀阶段检测到任何问题或性能下降，部署可以迅速回滚，最小化对用户的影响。

金丝雀部署可以通过简单的指标阈值来实现，但它们越来越多地利用 AI 或 ML 能力来确定新版本是否表现满意。传统上，金丝雀部署专注于性能基准，但我们预计未来它们将越来越多地利用业务指标，如果新版本的应用程序损害了业务，即使它没有崩溃，也会停止发布。

虽然金丝雀部署和滚动更新都旨在实现渐进和可控的软件发布，但它们在重点上有所不同。滚动更新旨在最小化服务基础设施中的停机时间和服务中断。金丝雀部署则专注于基于指标的决策，关于是否逐渐增加新版本的流量或回滚到上一个版本。

### 使用特性标志

特性标志提供了一种以渐进方式部署 *特性* 的策略。想象一下特性标志就像你代码中的隐藏开关，允许你在不部署新代码的情况下，为特定用户或群体开启或关闭特性。这让你能够细粒度地控制谁看到什么，实现 A/B 测试和定向发布。特性标志与其他渐进式部署策略类似，因为它们允许你在真实环境中监控性能并收集反馈，并使用这些信息来降低风险。然而，特性标志在不同的层面上运作；它们控制单个版本内的功能。其他渐进式策略则测试全新的版本。

特性标志除了降低部署风险之外，还有其他好处，我们将在第八章中再次讨论。

### 回滚

我们已经探索了几种渐进式部署策略，但你的选择是无穷无尽的。融合滚动更新、蓝绿部署、金丝雀发布和功能标志等元素的变体和混合方法都是可能的选择。这些策略的共同点是可控的发布，允许你在需要时停止部署并回滚到先前的版本。使用类似蓝绿部署的策略，这是一个简单的提议：你的先前的版本已经准备就绪。对于滚动更新或金丝雀部署，回滚过程就是从具有缺陷软件的节点中移除流量，然后系统地用先前的软件版本替换这些节点。

回滚不仅涉及重新部署先前的稳定软件版本，还包括其关联的配置、依赖项和数据。回滚到先前的状态可能和部署本身一样复杂，甚至更复杂。某些部署方法将促进可靠的回滚。例如，如果部署是幂等的，意味着它可以重复并产生相同、非破坏性的结果，那么重新部署先前的版本将等同于回滚。

测试回滚对于确保你可以无忧地回滚至关重要。仅仅有回滚机制是不够的；你需要定期验证其准备就绪状态。这涉及到模拟各种故障场景，然后执行回滚程序以确保它迅速可靠地恢复先前的稳定版本。彻底的回滚测试验证了应用程序、其数据和其依赖项是否正确回滚。根据应用程序及其数据存储机制，回滚可能需要数据恢复或迁移以确保数据一致性。定期测试程序以确保它们在所有场景中都能按预期工作。

在对回滚程序充满信心之后，你可以配置回滚以根据部署健康自动触发。验证部署健康是我们将在下一节中讨论的主题。而不是依赖人工干预，当预定义的阈值被突破时，系统会自动回滚到先前的稳定版本。这不仅减轻了运维团队的工作负担，还排除了人为错误，以最小化停机时间。

### 针对特定架构的特殊考虑

部署和回滚的复杂性根据软件架构的不同而有很大差异。单体架构，由于其紧密耦合的代码库，通常需要完整的部署和回滚，这会影响整个系统。另一方面，微服务提供了更细粒度的部署和回滚，针对单个服务。然而，这种相互关联性意味着必须仔细管理依赖关系，以确保服务之间的一致性。分布式单体架构结合了单体架构和微服务的特征，将微服务的部署复杂性结合到单体架构的相互依赖问题上。

数据库增加了另一层复杂性。当更新涉及对持久数据结构的破坏性更改时，需要像“扩展和收缩”这样的策略。这种策略涉及在现有数据库字段或表旁边添加新的数据库字段或表，部署更新后的应用程序以利用新的结构，并最终逐步淘汰旧字段。这种方法实施起来很复杂，但通常需要确保在支持渐进式部署策略和干净的回滚时保持数据完整性。

## 选择正确的工具

拥有渐进式部署策略和强大的回滚能力，您可以有信心地将代码部署到生产环境中。但为了真正释放这些策略的潜力，您需要拥有可用的正确工具。现代部署工具在提供无缝支持渐进式部署策略方面起着至关重要的作用。

在选择用于编排您的软件部署的工具时，重要的是要超越基础功能，并考虑特定工具与您的具体需求如何匹配。如果您计划在采用新的持续交付工具的同时过渡到自动化的部署决策，那么在事先了解所有影响您提升决策的因素将有助于您选择具有所需治理和门控能力的正确工具。此外，确保部署工具能够无缝集成到您的目标环境中，无论是云、本地服务器还是混合配置。同样重要的是，该工具能够处理您的特定应用程序类型和架构，包括任何复杂的数据库部署或协调的多服务发布。

除去基础设施和架构兼容性之外，部署工具应该包含对您首选的渐进式部署策略的原生支持，确保您能够轻松实现金丝雀发布、滚动更新或其他技术。强大的回滚机制应该是一个首要关注点，因为它们允许您在出现意外问题时快速回滚到先前的稳定版本。此外，考虑该工具是否与您现有的功能标志管理系统集成或提供自己的功能标志功能，这为您提供了对功能发布的细粒度控制。

# 验证生产部署

即使是最勤奋的治理也无法消除系统性地验证生产部署的稳健实践的需求。在本节中，我们将探讨可观察性的作用。我们将讨论现代化您的验证流程，并查看针对生产部署验证的具体测试策略。

## 部署的可观察性

验证您的部署从可观察性开始。[可观察性](https://oreil.ly/94AtC)简单地说是指通过检查系统的外部输出来理解系统内部状态的能力。可观察性让您从知道有问题到理解为什么有问题，这有助于更快地故障排除和更有效的根本原因分析。可观察性数据包括三个关键支柱：

指标

这些提供了系统性能的定量测量，例如响应时间、错误率和资源利用率。通过跟踪这些指标的趋势和异常，团队可以快速识别潜在问题并评估新部署的影响。

日志

日志提供了应用程序及其基础设施中发生的事件和错误的详细记录。分析日志数据有助于确定问题的根本原因，并理解导致问题的事件序列。

跟踪

跟踪提供系统内请求流量的可视化表示，突出瓶颈、延迟问题和不同服务之间的依赖关系。这有助于识别性能问题并优化应用程序架构。

## 现代化作战室

传统的部署验证通常类似于高风险的作战室场景，工程师监控仪表板和日志，随时准备在出现任何问题时手动干预。这个过程高度手动，依赖于对可观察性数据的解释。它也是被动的，团队通常只有在问题影响了用户之后才会匆忙解决问题。

这种方法不仅压力巨大且效率低下，而且容易出错和响应时间慢。此外，它往往导致验证程序不一致，并限制了了解问题根本原因的视野。

现代化部署验证涉及自动化这些手动任务和人类决策。不再依赖工程师监控仪表板和日志，自动化系统接管，持续分析遥测数据，并在检测到异常时触发警报。从被动监控到主动监控的转变减少了人类干预的需求，并加速了响应时间。

实现这种自动化的技巧是将您的部署工具与可观察性平台集成。集成形式取决于使用的工具。在一种方法中，您的 CI/CD 工具在部署进行时通知可观察性平台，提供一个“钩子”，可以用来触发回滚。然后，可观察性平台分析遥测数据并决定是否启动回滚，调用 CD 工具提供的钩子。

或者，像 Harness 这样的 CD 工具可以被配置为在部署过程中监视一个或多个可观察性工具的故障迹象。如果检测到问题，CD 工具可以自动触发其自身的回滚机制，停止部署并回滚到先前的稳定版本。这种部署和可观察性工具之间的紧密集成使得验证过程无缝且自动化，最小化停机时间并确保更快的反馈循环。

在任何情况下，行业都不再容忍中断，并寻求在应用程序失败之前检测到问题即将发生的迹象。因此，AI/ML 被用来分析多个数据源，以识别可能发生故障的异常。AI 异常检测已成为现代部署验证的核心组成部分。与传统监控不同，后者依赖于预定义的阈值，这些系统构建了正常应用程序行为在数百个指标上的统计模型，并能检测到复杂的多维异常，这些异常用静态规则定义是不可能的。这种能力在生产部署后的关键分钟内尤其有价值，否则微妙的性能问题可能直到它们升级为影响用户的重大事件才被发现。

部署验证系统将这些 AI 能力集成到自动化验证门中，在整个部署过程中提供持续评估，而不是点时间检查。当检测到异常时，这些系统可以自动暂停渐进式部署，甚至自动触发回滚过程。

## 测试生产部署

我们在第四章中详细讨论了测试。现在我们回到测试策略，特别是针对验证生产环境的策略。验证生产部署需要分层测试方法。

合成测试可以与分阶段或渐进式部署相结合。通过在生产环境中模拟典型用户交互和交易，合成测试运行通过场景来快速捕捉问题。这允许团队在早期解决问题，无论是通过回滚部署还是实施必要的修复。

超过初始部署阶段，在生产环境中持续测试对于确保长期稳定性和性能至关重要。合成测试继续发挥着重要作用，提供对关键用户旅程的持续监控，并识别任何回归或性能下降。我们在第六章中提到的混沌工程，通过故意向系统中注入故障来测试其弹性和恢复能力，将这一过程进一步推进。

持续测试的另一个重要方面是逐步功能披露。这涉及到逐步向用户子集推出新功能，允许团队在全面发布之前收集反馈并监控性能。像 A/B 测试这样的技术允许比较不同版本的功能，有助于确定最有效的实现方式。这种对功能发布的控制方法最小化了风险，并允许基于真实用户行为的数据驱动决策。通过结合合成测试、混沌工程和逐步功能披露，组织可以建立全面的测试策略，确保其生产部署的持续验证和改进。

# 摘要

随着人工智能继续改变生产部署，部署策略与功能管理之间的联系变得越来越重要。人工智能驱动的部署验证系统不仅监控整体应用程序健康；现在它们可以跟踪部署中单个功能的影响，提供细粒度的洞察，这些洞察既用于回滚决策，也用于未来的功能发布。这些系统创建了一个持续反馈循环，其中部署数据流入功能标志决策，而功能行为则影响部署策略。现代平台分析部署中的功能性能模式，以推荐哪些功能应通过功能标志逐步发布，哪些可以安全地传统部署。这种智能帮助团队平衡开发速度与运营稳定性，创造了一种更复杂的方法来管理生产环境中的部署和功能。在第八章中，我们将深入探讨功能管理。
