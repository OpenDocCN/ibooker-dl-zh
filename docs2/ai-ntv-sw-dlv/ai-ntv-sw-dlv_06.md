# 第六章. 混沌工程与服务可靠性

复杂的现代系统天生具有脆弱性。即使是看似微小的中断，或者一个单一的薄弱环节，也可能导致问题螺旋式地升级，产生灾难性的后果。

考虑以下场景：一个著名的电子商务平台在高峰销售活动期间（类似于黑色星期五）遭受了重大中断。随着流量的增加，平台的结账服务变得缓慢，最终导致完全失败。数千名客户无法完成购买，这不仅导致了即时的收入损失，还损害了声誉，削弱了信任和品牌忠诚度。事后分析发现，根本原因是结账服务与关键定价数据缓存之间的网络延迟。随着缓存响应在高流量压力下变慢，系统的重试机制变得不堪重负，导致一系列失败的请求最终使数据库过载。

这样的场景以及故障成本的上升导致了服务可靠性作为一个学科的出现，以及混沌工程（有时称为故障或故障注入测试）的实践。混沌工程的目标是提供对系统在异常（混沌）压力下如何行为的理解。这些实践日益普及，得益于新工具、技术和实践的发展。

混沌工程的术语可以追溯到 2010 年的 Netflix。该公司正在将其基础设施过渡到云端，这引入了新的复杂性，数百个微服务以不可预测的方式相互交互。为了测试他们系统的弹性，Netflix 工程师开发了 Chaos Monkey，这是一个旨在随机终止其生产环境中虚拟机实例的工具。这模拟了现实世界的故障，迫使工程师构建能够优雅地处理意外中断的系统。

使用“混沌”一词以及将猴子释放到生产环境中随机终止软件的形象确实会引发混乱。鉴于这些先入为主的观念，将混沌工程引入一个组织可能会遇到阻力。不止一位老板曾想过：“我们这里不是已经够混乱了吗？”

在本章中，我们将通过理解现代混沌工程作为一种严格的实验实施方法来反驳那些观念。作为一种方法，我们利用这种*可控*的破坏来测试我们系统的弹性。除了测试我们的当前状态外，混沌工程还给我们提供了一种强大的方法，以系统地提高弹性。

我们进行的实验使我们更深入地理解了软件在压力下的行为。这些知识使我们能够设计有针对性的改进。然后我们测试以验证它们在满足我们的目标方面的有效性。

我们还将介绍如何使用服务级别目标（SLOs）来设定我们的弹性目标。我们将探讨使用错误预算来允许在目标范围内接受一定程度的失败。我们将通过帮助验证我们的系统是否可以在其错误预算内运行并仍然达到目标，即使面临意外的中断，来了解混沌工程如何与这些机制协同工作。

在本章中，我们还将超越静态的混沌实验，了解一种更现代、更动态的方法，该方法涉及将混沌工程集成到我们的 CI/CD 管道中，使我们能够作为常规开发工作流程的一部分，持续评估和改进系统弹性。

在本章中，我们将探讨高级混沌工程工具如何利用 AI/ML 驱动的洞察力来推荐和指导这些实验的执行，从而实现更高效、更有效的弹性测试，同时降低风险。我们还将看到代理 AI、通用 AI 和 MCP 如何通过自动化实验设计、实现动态风险检测和提供智能修复来解决混沌工程中的关键可扩展性和精度挑战。这些技术将混沌工程从一种被动实践转变为一种主动、自我优化的系统弹性策略。

# 开始使用混沌工程

虽然许多混沌工程实验采用随机性（例如，随机选择一个服务器或服务进行关闭），但混沌工程的实践与实验室科学一样严谨。在本节中，我们将深入研究混沌工程的核心原则，并探讨在开展实验时降低造成服务中断风险的最佳实践。

## 混沌工程原理

Netflix 已经定义了一套核心原则，为探索你的系统在压力下的行为提供了一个有用的框架。一种结构化的方法确保你的混沌实验不仅是不规则事件，而且是结构化的调查，可以生成有价值的数据，你可以使用这些数据来推动系统弹性的改进。这些原则包括：

定义一个表征正常系统行为的“稳态”

可观察性在这里是关键。你必须拥有你需要的指标来理解指示你的系统健康且按预期运行的正常值范围。这可能包括请求延迟、错误率、吞吐量或特定于应用程序的指标。务必考虑可能影响你的指标的外部因素，例如一天中的时间、一周中的哪一天，或者可能引发流量激增的市场营销活动的存在。

将期望转化为假设

根据您对系统架构和依赖关系的理解，提出一个假设，即当引入特定故障时，系统应该如何行为。以您选择的标准来客观测试的方式构建您的假设。例如，“如果我们模拟 20%的流量增加，平均响应时间应该保持在三秒以下，错误率不应超过 0.5%。”

通过模拟现实世界事件来执行实验

使用混沌工程工具来自动化故障注入。模拟服务器崩溃或不可用、关键第三方服务的中断或用户请求的突然激增。

将结果与假设进行评估

将实验期间系统的行为与您建立的基线和假设的结果进行比较。指标是否保持在可接受的范围内？系统是否按预期恢复？是否观察到任何意外的副作用？如果系统偏离了预期的行为，调查其根本原因。根据实验的结果，完善您的假设，并调整系统设计或操作程序以提高弹性。

## 从小规模开始并扩展

故意模拟故障以关闭系统当然会带来风险。我们明知故犯地以这种方式承担风险，以验证我们定义的假设。降低风险的一个重要策略是从小规模的实验开始。

为了说明从小规模开始并扩展实验，让我们通过一个专注于测试电子商务系统中结账服务的示例来进行分析。这个服务是一个关键的微服务，负责处理用户购买。预期的结果是简单的：客户将商品添加到购物车，进入结账流程，并完成支付。客户期望获得流畅、快速和可靠的体验。

在幕后，这个简单的操作依赖于一系列复杂的过程。结账服务依赖于多个 API 和外部服务才能正常运行，包括库存系统、支付网关和缓存层（如 Redis）以快速检索重要数据，例如产品价格、折扣和可用性。结账服务从缓存中获取定价数据以快速访问。如果缓存速度慢或失败，结账服务应通过切换到另一个缓存实例或甚至到数据库作为备份来提供正确信息，尽管这可能会慢一些。

###### 备注

GenAI 可以将混沌工程从手动假设测试转变为自适应、自我优化的弹性验证系统。这种方法在关键电子商务工作流程（如结账服务）中尤其有价值，在这些工作流程中，平衡风险缓解与现实故障模拟至关重要。

开发人员通常配置重试逻辑、超时和断路器来处理网络问题或故障。让我们逐一看看：

重试逻辑

这确保了如果对缓存的请求失败或遇到网络问题，系统会在放弃之前自动尝试几次。这有助于处理暂时性的故障。例如，系统可能会在每次重试之间延迟 100 毫秒，最多重试三次。

超时

超时设置定义了服务在决定尝试失败之前应该等待响应多长时间。这防止了服务在缓存缓慢或无响应时无限期地挂起。系统可能被配置为每个缓存请求在 200 毫秒后超时。

断路器

断路器在经过一定数量的失败尝试后阻止进一步尝试调用失败的服务。如果缓存继续失败或太慢，断路器“跳闸”，并将流量路由到备用系统（例如，另一个缓存或数据库）。断路器可以在设定的时间后自动重置，以测试原始服务是否已恢复。例如，断路器可能被配置为在连续五次重试失败后跳闸。

我们将通过引入小的延迟来开始测试结账服务，以确保在扩展到引入更严重的问题（这将最终触发断路器）之前，重试逻辑和超时设置正在正常工作。如果一切顺利，我们预计系统将切换到备用数据源。这些是我们的步骤。

### 第 1 步：进行简单的延迟实验

我们从测试我们的重试逻辑开始。我们希望确保如果出现网络问题，例如高延迟或暂时性的连接丢失，系统是具有弹性的。我们的稳定状态是响应性服务，在可接受的时间限制内响应。

我们的假设是，如果在尝试访问缓存时网络出现显著的延迟，系统应该使用其重试逻辑和超时设置来优雅地处理问题，最终触发断路器以防止服务进一步退化。

我们通过在结账服务和缓存之间注入少量的网络延迟（例如，200 毫秒）来从小处开始。

我们观察重试逻辑是否启动，以及服务是否在可接受的时间限制内处理延迟，而不会对用户产生影响。我们继续监控系统是否继续按预期工作，在延迟延迟后从缓存中获取数据。

### 第 2 步：测试对更严重的网络问题的弹性

一旦我们使用小延迟测试了我们的重试逻辑，我们就可以增加实验的范围和强度，以模拟更重大的网络问题。这测试了我们的超时。我们增加网络延迟（例如，从 500 毫秒到 1 秒），以查看服务在更重负载或网络拥塞下的表现。我们测试重试逻辑如何处理延长的延迟。服务是否重试对缓存的调用，并且是否尊重超时设置？如果是这样，我们通过在设置的重试次数后使缓存 API 完全失败来增加问题的严重性。

### 第 3 步：验证断路器是否切换到备用

我们接下来设置实验条件以使缓存不可访问。在重试后，断路器机制应该被触发。当断路器跳闸时，检查服务将切换到备用数据源，例如位于不同数据中心（在这种情况下，我们的 Postgres 数据库）的另一个缓存实例。虽然 Postgres 数据库可能比缓存慢，但目标是保持服务运行，尽管性能略有下降。

通过使用强化学习动态调整故障注入参数，AI 代理可以使此过程更加简单。例如：

1.  从 200 毫秒的延迟开始，然后根据实时性能遥测自动扩展到 500 毫秒到 1 秒。

1.  最初将实验影响限制在交易量的 0.5%，仅在验证安全机制后扩大。

1.  通过历史成功模式分析优化跳闸阈值（例如，五次失败转为四次）。

您可以通过引入类似网络问题来进一步扩展实验，以测试故障转移的弹性，这些网络问题存在于检查服务和 Postgres 数据库之间，以查看系统在增加的故障条件下的适应情况。通过遵循此过程，我们逐渐增加实验的复杂性，以验证系统的弹性机制，而无需立即跳入重大中断。

重要的是要注意，弹性机制的初始设置通常基于有根据的猜测而不是精确数据。这也是通过混沌工程实验进行测试如此关键的原因之一。

在混沌实验中，注入网络延迟只是我们可以扩展的一个条件。我们将在本节稍后讨论其他条件。

## 从类似生产环境开始

另一个重要的最佳实践是在将实验移至生产之前在预生产环境中测试实验，以最小化混沌工程中的风险。这允许我们在不影响真实用户的情况下安全地进行实验。我们可以快速迭代、调整参数并观察结果，不受生产约束的限制。一旦在这些设置中确认系统弹性，我们就将实验提升到下一个环境，最终达到生产环境。每次提升都伴随着风险，因此我们谨慎行事。环境之间的配置漂移可能导致实验结果的不一致。在环境之间移动时保持“从小规模开始并扩展”的方法在遇到问题时至关重要。在预生产中对我们的实验进行彻底审查确保我们的实验设计良好且富有洞察力，没有意外的后果。

## 利用现代工具

我们在混沌实验中广泛研究了测试网络延迟的示例。还有许多其他类型的条件是重要的测试对象。现代工具（如 Harness 混沌工程、Chaos Monkey 和 LitmusChaos）通过提供广泛的预定义实验目录来帮助这里。现代工具通常会提供跨类别和常见故障模式的混沌工程实验，包括：

资源耗尽

CPU 资源耗尽

强制高 CPU 利用率以模拟进程消耗过多的处理能力。

内存耗尽

消耗所有可用内存以测试您的应用程序如何处理内存压力和潜在的内存不足错误。

磁盘 I/O 资源耗尽

生成大量的磁盘读写操作以模拟存储瓶颈。

网络带宽耗尽

满足网络带宽以测试您的应用程序在网络拥塞下的性能。

网络中断

网络延迟

在服务或外部依赖之间引入网络通信延迟。

数据包丢失

模拟网络数据包丢失以测试您的应用程序如何处理不可靠的连接。

网络分区

将您的网络部分隔离以模拟服务或可用区故障之间的连接问题。

DNS 故障

模拟 DNS 解析问题以测试您的应用程序如何处理 DNS 崩溃或错误的响应。

基础设施故障

节点故障

终止或关闭虚拟机或容器以模拟硬件故障。

Pod 故障（Kubernetes）

终止或驱逐 pods 以测试您的 Kubernetes 部署的自我修复能力。

可用区故障

模拟整个可用区故障以测试您的灾难恢复计划和跨区域部署。

推理层攻击

在机器学习模型服务期间模拟 GPU 内存耗尽。

应用层故障

服务故障

停止或崩溃应用程序中的特定服务以测试容错性和服务降级。

函数故障

在特定函数或方法中引入错误或异常以测试错误处理和恢复机制。

数据损坏

在数据库或存储系统中损坏数据，以测试您的数据完整性和恢复流程。

状态管理

时间旅行

操作系统时钟以模拟时间变化，测试您的应用程序如何处理时间敏感的操作或计划任务。

状态注入

将特定数据或状态注入您的应用程序以测试其在异常条件下的行为。使用生成式 AI 创建符合模式约束的合理损坏数据条目。

使用 AI 动态生成场景

架构建模

使用 AI 分析服务依赖关系（例如，Redis 缓存→支付网关→数据库），以创建与生产环境相似的故障链。

生成对抗网络

通过将 AI 模型相互对抗，创建新的故障模式，以发现未探索的漏洞组合。

我们尝试的实验类型越多，我们就能更多地了解我们系统中的弱点以及我们如何加强我们的弹性。

新的工具不仅能提供目录，还能分析您的系统架构，并提出针对性的实验，以揭示您特定设置中的潜在弱点。例如，对于使用微服务架构构建的软件，混沌工程工具可能会分析网络流量和依赖关系，以识别关键服务并建议针对这些服务的特定实验。现代工具还可能建议在服务之间的 API 调用中注入延迟或错误，以测试对通信中断的弹性。

对于使用 Kubernetes 部署的应用程序，该工具可以分析您的 Kubernetes 部署，并提出针对特定 Pod、部署或命名空间的实验建议，以测试副本扩展、资源限制和健康检查。像 Red Hat 的 Krkn 这样的工具使用 AI 来分析 Kubernetes Pod，以优先考虑网络密集型服务进行分区测试。在多区域部署的情况下，现代工具可能会分析您的多区域设置，并提出模拟区域故障或网络分区的实验建议，以测试您的灾难恢复计划以及您的应用程序切换到另一个区域的能力。

## 向他人学习

密切关注行业范围内的事件，尤其是那些影响具有相似技术堆栈的公司的事件，对于主动风险缓解至关重要。例如，2024 年 12 月 11 日 OpenAI 的故障，是一个鲜明的提醒，表明看似微小的部署可能会产生连锁反应。

在这种情况下，一家公司的新遥测服务压倒了其 Kubernetes 控制平面，引发了 DNS 故障，导致其 API、ChatGPT 和 Sora 平台瘫痪数小时。影响广泛且持久：数小时内，开发者和用户无法访问他们依赖的服务。工程师几分钟内就确定了根本原因，但面临一个主要障碍——没有访问 Kubernetes 控制平面，回滚或修复部署极为困难。

让我们看看几个有针对性的混沌工程实验，看看这些级联故障是如何可能被预防的。

### 实验 1：控制平面过载模拟

首先，我们设计一个实验来测试我们的 Kubernetes API 服务器的弹性。在这个实验中，我们会故意向 Kubernetes API 服务器发送大量读写操作，以模拟新遥测服务在生产环境中所做的操作。通过在一个具有类似生产规模的预演环境中运行这个测试，我们可以发现 API 服务器开始失败的确切阈值。这种早期检测将有助于更好的负载限制、改进的警报以及可能更安全的分阶段发布策略。

### 实验 2：DNS 故障测试

这个实验将涉及在 DNS 解析过程中引入延迟或故障——特别是针对负责服务发现的组件。运行这个实验有助于确认即使 DNS 被中断，基本服务也能继续运行。我们将发现我们的缓存、回退机制或替代路由策略是否足够。如果不充分，我们就会知道在真正的事故发生之前，需要在这些领域进行投资。

### 示例 3：破窗访问演习

最后这个实验（或演习）涉及模拟工程师在重负载下被锁出 Kubernetes API 的情况。通过练习紧急访问方法——比如拥有专门的备用通道或专用工具——团队可以在标准控制平面不可访问时快速回滚或禁用有问题的部署。如果这个演习事先进行过，团队就会知道如何在几分钟内确切地移除有缺陷的遥测服务，从而最小化停机时间。

# 服务级别目标和服务的弹性

我们看到混沌工程如何帮助我们揭示弱点并构建更具有弹性的系统。但“弹性”是如何定义的呢？我们如何衡量和跟踪我们的系统是否达到了我们的可靠性目标？这正是 SLOs（服务级别目标）和服务级别指标（SLIs）发挥作用的地方。它们共同为定义和衡量我们服务的可靠性提供了框架，为我们提供了一个清晰的目标，以及跟踪我们进步的方法。

SLOs 是我们为服务的可靠性设定的目标。SLIs 是我们用来衡量是否达到这些目标的特定指标。SLOs 通常以百分比时间或必须满足定义的 SLI 标准的请求数量来表示。例如，*99.9%的请求应该有低于 200 毫秒的延迟*。SLIs 是反映您服务性能的特定、可衡量的指标，从用户的角度来看。它们量化了可用性、延迟、错误率、吞吐量和其他相关因素。

从本质上讲，SLIs 是你要衡量的内容，而 SLOs 是为这些测量设定的目标。

## 建立可靠性目标

在制定可靠性目标时，必须确保它们与整体业务需求相一致。监控和可观察性解决方案提供了许多 SLI 指标，但重要的是要优先考虑那些准确反映客户体验的指标。目标是跟踪每个单独的服务，而是关注那些对客户体验至关重要的服务。

常见的 SLI 包括“四个黄金信号”：

请求延迟

处理用户请求所需的时间

吞吐量

每秒处理的请求数量

错误率

失败请求的百分比

饱和

系统的利用率百分比

仔细考虑如何在您的系统中实施这些指标。例如，在测量延迟（响应时间）时，您可以选择跟踪所有事务或专注于最重要的子集，例如登录、支付提交或添加购物车中的项目。再次强调，选择一个能够提供客户体验有意义表现的指标。

## 系统可靠性的共享所有权

在第一章中，我们介绍了 DevOps 作为结合软件开发（Dev）和 IT 运营（Ops）关注的实践。在确保系统可靠性方面，共享所有权和协作尤为重要。SLO（服务等级目标）是这种共享责任的绝佳例子。开发、运营和可靠性团队应共同努力定义 SLO。这种协作建立了对可接受系统性能的理解，并为每个人设定了一个共同的目标。SLO 然后作为指南，在平衡快速开发（速度）和稳定可靠系统需求之间做出决策。

通过这种共享理解，开发者可以优先考虑维护可靠性的功能，了解他们的工作如何影响整体系统性能。同时，运营团队获得了有效支持应用程序所需的环境。如果 SLO 被违反，它将触发活动，鼓励工程团队在发布新功能之前稳定服务。这有助于防止不稳定循环，并确保可靠性始终是首要任务。

一种协作方法，用于设计、优先排序和执行混沌工程实验本身，将团队聚集在一起。所有团队都从这些实验中获得见解，并从一起工作时解决故障中受益。

现代工具促进了这种系统可靠性的协作方法。监控平台、事件管理系统和通信工具提供了对系统性能和潜在问题的共享可见性。实时数据和自动警报使开发和运维团队能够快速响应事件。更重要的是，这些工具培养了一种主动解决问题的文化（如数据驱动的优先级排序、实时协作分类等），团队可以在问题影响用户之前识别并解决潜在问题。

# 错误预算及其在可靠性和创新中的作用

我们已经了解到混沌工程如何帮助我们主动发现系统弱点，以及 SLOs 和 SLIs 如何为我们定义可靠性目标并提供一个清晰的框架，以衡量我们的系统是否达到这些目标。[错误预算](https://oreil.ly/K0JqJ)提供了安全网。

错误预算代表了服务在满足其 SLOs 的同时可以容忍的最大不可靠性或停机时间。通过容忍快速创新过程中的小故障，错误预算承认完美是无法实现的，并帮助我们实现一个可接受的可靠性水平，平衡这两个相互竞争的优先级。

让我们通过回到我们的电子商务示例来看看这是如何工作的。想象一下，我们为小于 300 毫秒的网站登录设置了 99.9%的服务目标（SLO）。在一周内，这相当于 10.08 分钟的允许的最大 SLO 违规时间。这是我们错误预算。这会对我们产生什么影响？如果错误预算耗尽到零，我们将停止或减缓新软件的部署，并专注于稳定系统，同时我们的错误预算得到补充。不仅我们的错误预算状态影响我们的部署优先级，它还影响到混沌测试的优先级。

## 监控以提供混沌测试实验的信息

密切关注你的服务级别指标（SLIs）不仅能让你及时发现即时问题——它还能揭示你系统中潜在的不稳定因素。例如，如果你注意到你的系统不断逼近延迟限制，耗尽错误预算，那么你的系统可能在高流量场景下难以维持。这表明，这是一个很好的领域，可以集中进行混沌实验。通过模拟这些高流量、高延迟的情况，你可以看到你的系统在压力下的表现，并确保在高峰使用期间仍能满足其服务目标（SLOs）。

使用现代工具，你可以通过自动触发基于这些模式的混沌测试来自动化这个过程，这样你就可以在不费吹灰之力的情况下持续测试和改进你系统的弹性。现代平台可以使用人工智能将 SLI 趋势与混沌测试建议相关联，从而显著增加测试覆盖率。

## 混沌测试实验中错误预算的战略使用

错误预算不仅仅是偶尔失败的保障网；它们是管理风险的工具。以我们的电子商务网站为例，我们认为 10.08 分钟的错误预算是一种需要明智使用的资源。在本节中，我们将探讨如何积极使用这笔预算来开展混沌实验。

### 根据可用的错误预算优先考虑混沌实验

有效的混沌工程需要考虑你的可用错误预算。当你的错误预算健康时，你的运行时间就长。你有更多的自由进行激进的实验，模拟大规模故障或推动关键系统组件达到极限。这可能包括测试故障转移机制、注入网络延迟，甚至模拟核心服务的完全中断。

当你的错误预算减少时，转向关注规模较小、风险较低的实验至关重要。这些实验可能包括单独测试单个组件、模拟轻微的网络问题或验证最近更改的弹性。以这种方式优先考虑实验确保你可以在不危及整体系统稳定性的情况下继续学习和改进。

现代自动化工具可以帮助。通过实时分析你的错误预算，这些工具可以根据你的可用“失败空间”推荐适当的实验。这允许你在主动测试和服务可靠性之间保持平衡，确保你的混沌工程工作既具有洞察力又负责任。

### 通过利用增强人工智能的干跑和模拟来保护你的错误预算

模拟先行是另一种策略，以最小化混沌实验中意外后果的风险。这在面对日益减少的错误预算时尤为重要。使用人工智能增强的“干跑”混沌实验实践涉及在一个受控环境中模拟实验，使用系统模型或副本来评估它们在执行生产前的潜在影响，并使用人工智能修复代理在异常检测阈值超过预定义限制时回滚实验。通过事先识别潜在问题和细化实验参数，团队可以降低造成重大中断的可能性，这些中断可能会耗尽你的错误预算并造成重大破坏。

# 将混沌工程和 SLOs 集成到 CI/CD 管道中

可靠性问题主要是由变化引起的，无论是我们应用程序的变化还是您基础设施的变化。Google DevOps Research and Assessment (DORA) 定义了变更失败率（CFR）指标，这为我们提供了对挑战的另一种视角。CFR 描述了我们的变更，如新代码部署或基础设施更新，在生产中引入问题，需要热修复或回滚的频率。DORA 2024 年 DevOps 状态报告表明，80% 的受访团队的平均 CFR 为其发布版本的 20%。实际上，25% 的团队的平均 CFR 高达令人担忧的 40%。

此外，我们必须考虑修复每个变更失败所需的时间和成本。失败的部署恢复时间指标（取代类似的平均恢复时间 [MTTR] 指标）关注的是组织从故障中恢复的速度。这让我们对团队在这一方面的挑战有了感觉。虽然许多团队能够在一天内修复，但仍有 25% 的团队需要一周到一个月的时间来替换有缺陷的软件。

在前面的章节中，我们探讨了防止缺陷进入生产的策略。我们在交付管道的每个阶段进行测试，执行各种类型的测试。我们小心地管理我们的环境。我们使用 GitOps 等实践来防止配置漂移，并结合 IaC。我们在预生产和生产环境中进行混沌工程测试，以帮助我们找到系统中的弱点。尽管我们尽了最大努力，但偶尔需要快速修复的缺陷仍然是不可避免的。这就是持续弹性的作用所在。

正如持续集成和持续交付是关于使用自动化来构建、测试和部署我们的代码一样，持续弹性是通过将混沌工程实验添加到我们的 CI/CD 管道中来自动化我们的弹性实践。这样做意味着我们不仅测试功能，而且积极且持续地评估变化对我们系统稳定性的影响。使用 AI 代理进行 DevOps，混沌实验可以智能地集成到 CI/CD 管道中。

在“扩展您的混沌工程实践”中，我们将探讨如何通过将混沌工程实践纳入我们的交付管道并借助现代工具来扩展它。我们将探讨如何优先考虑添加到管道中的实验，以及确保您的管道中混沌实验安全和管理的最佳实践。

## 扩展您的混沌工程实践

组织开始混沌工程之旅的方式各不相同。通常，一个或两个团队会采用开源工具，并在组织的一个小范围内引入实验。一个组织可能会定期举办混沌工程“游戏日”。这些是全员参与、计划中的活动，团队会故意向系统中注入一系列故障以练习事件响应并识别受控环境中的弱点。这些活动通常不频繁，且对发现的问题的反应是反应性的。

在组织规模上实施持续弹性，选择合适的工具可能是一个关键问题。虽然开源和专有解决方案都提供了有价值的特性，但组织应仔细评估其需求。一些企业环境可能需要特定的功能，如高级安全控制、全面的审计跟踪和 RBAC——这些功能在开源解决方案中的可用性和成熟度可能有所不同。

这项挑战在一个每天处理超过十亿笔支付交易的主要金融科技公司中尤为明显。面对高峰需求期间交易失败的不断增加，它寻求一种解决方案来提高其支持 20 多个金融产品的复杂平台的可靠性。

公司选择现代混沌工程工具对于克服其混沌工程实践扩展的障碍至关重要。它选择的工具（在本例中为 Harness 混沌工程）包含了一个庞大的预构建实验库，简化了自动化和编排多个混沌实验的工作。此外，全面的分析和报告能力使公司能够快速了解其系统的弹性。

公司开始时专注于一个关键服务，该服务每天处理九百万笔支付请求。它确定了复杂基础设施中的容错目标，为弹性测试的受控推出奠定了基础。通过优先考虑在交付管道和生产环境中自动化混沌实验，它解决了交易失败的根本原因，并为持续弹性建立了基础。

通过其自动化的弹性测试平台，公司能够扩大其测试范围，以发现服务恢复中的漏洞，优化应用程序设计模式，并微调配置。结果是显著的：失败交易减少了 16 倍，MTTR 减少到 10 分钟，客户满意度提高了 10 倍。如果没有提供安全、模板、自动化和编排的现代工具，就不可能在短时间内将混沌工程推广到整个组织并取得这些成果。

## 将混沌工程实验和 SLO 添加到您的 CI/CD 管道中

为了巩固你的弹性策略，将 SLOs（服务水平目标）作为可靠性护栏整合到你的 CI/CD（持续集成/持续部署）管道中。将 SLOs 比作赛车上的刹车——在追求最大速度的同时，保持控制至关重要。开发团队，就像赛车手一样，追求快速部署，但如果没有稳健的 SLOs，他们可能会因为未经检查的更改而导致系统崩溃。通过监控关键指标，你可以自动阻止超过这些阈值或耗尽错误预算的部署。这种方法可以在不牺牲稳定性的情况下加速你的开发速度。

当将混沌工程实验添加到你的 CI/CD 管道时，请记住两个指导你进步的指标：弹性评分和弹性覆盖率。弹性评分简单地衡量你的服务在 QA 和生产中应用实验时的表现。弹性覆盖率，类似于代码覆盖率，评估还需要多少实验才能全面评估系统弹性，指导创建实际数量的测试。这两个指标共同提供了一个全面的弹性视图，使所有团队都能为持续弹性目标做出贡献并衡量进展。

首先，添加测试已知弹性条件的实验，确保每次新部署后你的弹性评分保持稳定。通过添加测试新条件的实验，逐步增加你的弹性覆盖率。如果增加弹性覆盖率意味着弹性评分降低，确定失败的混沌实验是否需要停止管道，或者是否可以并行采取行动。

接下来，添加针对目标部署平台变更的实验。例如，当升级底层平台如 Kubernetes 时，将混沌实验纳入你的 CI/CD 管道，以主动识别潜在弱点和兼容性问题。这有助于防止潜在问题在未来影响应用程序，并确保平台更新期间的平稳过渡。通过早期发现这些问题，你可以避免昂贵的意外事件并保持持续的弹性。

向管道中添加实验，以验证部署对先前生产事件和警报的响应。最后，添加实验以验证部署对目标基础设施配置更改的响应。这也是一个场景，其中之前通过弹性测试的情况将开始失败，因为目标环境通过更高的或更低的配置发生了变化。

当你投资于创建和微调你的实验时，就像对待任何其他软件一样对待它们：对它们进行版本控制，测试它们，并在存储库中管理它们的生命周期。这确保了你的混沌工程实践保持有效，并适应你系统中的变化。集中式存储库促进了协作和这些实验的共享，促进了团队间的一致性和最佳实践。

## 混沌工程的安全和治理

显然，混沌工程是一种强大的方法，但粗心实验可能会对系统的弹性和你对混沌工程计划的信任造成严重伤害。通过将其与你的安全和治理框架集成，你可以定义所需的护栏，以确保实验负责任地进行。

就像技术债务一样，弹性债务也可能积累在你的生产服务中。每一次警报、事件、热修复或临时解决方案——比如简单地向问题投入更多资源——都会增加这种债务。这些快速修复措施通常掩盖了潜在问题，并创造了一种虚假的稳定感。

现代混沌工程工具可以帮助你建立和执行政策来对抗这种问题。例如，我们可以设定一项政策，要求对与组件行为不当、网络问题、API 故障或意外负载相关的每个生产事件进行相应的混沌实验。这个实验，集成到你的 CI/CD 管道中，需要在特定时间内得到验证，比如说，在事件发生后的 60 天内。这样的政策不仅会强制执行解决弹性债务的纪律，还会鼓励开发者和 QA 团队优先修复生产代码，而不是推动可能进一步加剧问题的新的功能。

除了使用政策来管理弹性债务外，你还可以使用安全治理政策来防止未经授权的实验，限制对关键系统的访问，并限制按环境、时间窗口、人员或甚至故障类型进行测试。通过自动化监督并将这些政策集成到你的 CI/CD 管道中，你可以增加弹性覆盖率同时降低风险。

# 服务可靠性中 AI 原生混沌工程的未来

混沌工程的未来在服务可靠性实践中承诺了更高的复杂性和集成度。像 Harness 混沌工程和 Chaos Monkey 这样的工具不仅会自动化实验，还会利用 AI/ML 来预测它们的影响，分析系统在压力下的行为，并推荐最佳的缓解策略。这种智能自动化将最小化风险，使团队能够更有信心和效率地开展更复杂的实验。可观察性和跟踪技术的进步将提供对系统动态的更深入洞察，使更精确地识别漏洞和更快地从中断中恢复成为可能。

随着系统变得越来越复杂，分布式架构和微服务变得无处不在，混沌工程将在确保其弹性方面发挥关键作用。即使是基于大型语言模型的多智能体系统也可以通过混沌工程[得到增强](https://oreil.ly/g7tjd)。通过将混沌测试与人工智能分析（例如，[ChaosEater](https://oreil.ly/IKlJW)）和自动修复相结合，我们将能够更快、更精确地解决潜在故障，最小化停机时间并保持高水平的服务可靠性。

# 摘要

在本章中，我们探讨了混沌工程作为一种构建和验证系统弹性的系统方法。我们学习了如何负责任地设计和执行实验，利用服务等级目标（SLOs）和错误预算来平衡创新与稳定性。通过将混沌工程集成到持续集成/持续部署（CI/CD）管道中并利用现代工具，组织可以主动识别弱点，从失败中学习，并持续提高弹性。最终，混沌工程使我们能够创建更健壮的系统，以满足当今复杂数字世界的要求。有了这些原则，下一步就是将这些原则无缝地应用于您的部署流程中。让我们探讨如何在生产部署过程中确保稳定性。
