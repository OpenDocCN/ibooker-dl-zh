# 第十一章\. 使用 LLM 构建

在今天的 LLM（大型语言模型）世界中，最大的未解之谜之一是如何最好地将它们交到最终用户手中。在某种程度上，LLM 实际上比之前的计算界面更加直观。与传统的计算机应用程序相比，它们对拼写错误、口误和人类的一般不精确性更加宽容。另一方面，处理“稍微偏离”的输入的能力也带来了一种倾向，即有时会产生“稍微偏离”的结果——这与之前的任何计算倾向都大不相同。

事实上，计算机被设计成每次都能可靠地重复执行同一组指令并得到相同的结果。在过去的几十年里，这一可靠性原则已经渗透到人机界面（统称为 HCI、UX 和 UI）的设计中，以至于许多通常的结构最终在依赖于 LLM 的应用程序中变得不够好。

让我们举一个例子：Figma 是一个设计师使用的软件应用程序，用于创建网站、移动应用、书籍或杂志封面等设计的忠实呈现——列表可以继续下去。与几乎所有生产力软件（用于创建某种长篇内容的软件）一样，其界面是以下因素的组合：

+   一系列工具和预构建的*基本构建块*，在这种情况下是线条、形状、选择和绘图工具等等。

+   一个画布，用户在此处插入这些构建块并将它们组织成自己的创作：一个网站页面、一个移动应用屏幕等等。

这个界面建立在软件功能事先已知的前提之上，这在 Figma 的案例中确实是真实的。所有构建块和工具都是软件工程师事先编写的。因此，在界面设计时，它们就已经存在了。指出这一点听起来几乎有些荒谬，但同样的情况并不严格适用于大量使用 LLM 的软件。

看一下文字处理器（例如，Microsoft Word 或 Google Docs）。这是一个用于创建某种长篇文本内容的软件应用程序，例如博客文章、文章、书籍章节等等。我们可用的界面也是由以下熟悉的组合构成的：

+   一系列工具和预构建的*基本构建块*：在文字处理器的例子中，可用的基本构建块包括表格、列表、标题、图像占位符等等，而工具包括拼写检查、注释等等。

+   *画布*：在这种情况下，它字面上是一个空白页面，用户在此处输入文字，并可能包含上述提到的某些元素。

如果我们构建一个 LLM 原生文字处理器，这种情况会如何改变？本章探讨了三个可能的答案，这些答案广泛适用于任何 LLM 应用程序。对于我们所探讨的每个模式，我们将概述你需要实现它的关键概念。我们并不想暗示这些是唯一的，关于这个特定问题的尘埃可能还需要一段时间才会落定。

让我们逐一查看这些模式，从最容易添加到现有应用程序的模式开始。

# 交互式聊天机器人

这可能是向现有软件应用程序添加的最简单的改进。在最基本的概念上，这个想法只是将一个 AI 助手附加到应用现有的用户界面中——以供提出想法——而所有工作仍然在应用程序的现有用户界面中完成。这里的一个例子是 GitHub Copilot Chat，它可以在 VSCode 代码编辑器的侧边栏中使用。

将这种模式升级的一种方法是添加一些 AI 助手扩展和主应用程序之间的通信点。例如，在 VSCode 中，助手可以“看到”当前正在编辑的文件内容或用户选定的代码的任何部分。在另一个方向上，助手可以在该打开编辑器中插入或编辑文本，从而实现用户和 LLM 之间的一种基本形式的协作。

###### 备注

正如我们所描述的，流式聊天是目前 LLM 的典型应用。它几乎是应用开发者在其 LLM 之旅中学习的第一个要构建的内容，它几乎是公司向现有应用程序添加 LLM 时首先寻求的内容。也许这种情况会持续多年，但另一种可能的结局可能是流式聊天成为 LLM 时代的命令行——即，最接近直接编程访问的，成为一个利基界面，就像它对计算机所做的那样。

要构建最基础的聊天机器人，你应该使用以下组件：

一个聊天模型

它们的对话调整非常适合与用户的多次交互。有关对话调整的更多信息，请参阅序言。

对话历史

一个有用的聊天机器人需要能够“超越你好”。也就是说，如果聊天机器人无法记住之前的用户输入，那么与它进行有意义的对话将会非常困难，这隐含地指代了之前的消息。

要超越基础，你可能需要添加以下内容：

流式输出

目前最好的聊天机器人体验是将 LLM 的输出逐个 token（或更大的块，如句子或段落）直接流式传输到用户，这减轻了今天 LLM 固有的延迟。

工具调用

要使聊天机器人能够与应用程序的主画布和工具交互，你可以将它们暴露为模型可以决定调用的工具——例如，“获取选中文本”工具和“在文档末尾插入文本”工具。

人工参与式

一旦你给聊天机器人工具可以改变应用程序画布中的内容，你就需要将一些控制权交还给用户——例如，让用户在插入新文本之前确认，甚至编辑。

# 与 LLMs 的协作编辑

大多数生产力软件都内置了某种形式的协作编辑功能，我们可以将其归类为以下类别之一（或介于两者之间）：

保存和发送

这是最基本的版本，一次只能支持一个用户编辑文档，然后在“移交接力棒”给另一个用户（例如，通过电子邮件发送文件）并重复此过程，直到完成。最明显的例子是 Microsoft Office 应用程序套件：Excel、Word、PowerPoint。

版本控制

这是保存和发送的演变，支持多个编辑者同时在自己的文档上工作（并且不知道彼此的更改），通过提供工具在之后合并他们的工作：合并策略（如何合并无关的更改）和冲突解决（如何合并不兼容的更改）。今天最受欢迎的例子是 Git/GitHub，软件工程师用它来协作软件项目。

实时协作

这使得多个编辑者可以同时编辑同一份文档，同时看到彼此的更改。这可以说是软件支持的最自然形式的协作，这一点可以从 Google Docs 和 Google Sheets 在技术和非技术计算机用户中的流行程度得到证明。

这种 LLM 用户体验模式包括将 LLM 代理作为那些“用户”之一，为这个共享文档做出贡献。这可以采取多种形式，包括以下几种：

+   总是处于“副驾驶”状态，为你提供如何完成下一句的建议

+   一个异步的“草稿人”，你可以分配给，例如，去研究相关主题，然后稍后带回来可以融入最终文档的章节

要构建这个，你可能会需要以下内容：

共享状态

LLM 代理和人类用户在访问和理解文档状态方面应该处于同等地位——也就是说，他们能够解析文档的状态并产生对该状态的编辑，以兼容的格式。

任务管理器

生成有用的文档编辑将不可避免地是一个多步骤的过程，这可能需要时间，并且可能在半途中失败。这需要可靠的长运行作业调度和编排，包括排队、错误恢复和对运行任务的控制。

合并分支

用户在分配任务给 LLM 代理后将继续编辑文档，因此 LLM 的输出需要与用户的工作合并，要么由用户手动（类似于 Git）合并，要么自动（通过如 Google Docs 所使用的 CRDT 和操作转换（OT）等冲突解决算法）。

并发

人类用户和 LLM 代理同时处理同一件事情需要处理中断、取消、重新路由（这样做）和排队（这样做）的能力。

撤销/重做堆栈

这是在生产力软件中普遍存在的模式，不可避免地也需要在这里。用户可能会改变主意，想要回到文档的早期状态，LLM 应用需要能够跟随他们到那里。

中间输出

当输出逐渐进行并且一旦产生就分批到达时，合并用户和 LLM 的输出会变得容易得多，就像一个人逐句写一个 10 段落的页面一样。

# 环境计算

一个非常有用的 UX 模式是始终开启的背景软件，当发生需要你注意的“有趣”事件时，它会发出声音。你可以在今天找到很多这样的例子。以下是一些例子：

+   你可以在你的经纪应用中设置一个警报，当某些股票价格低于某个特定价格时通知你。

+   你可以要求谷歌在找到匹配某些搜索查询的新搜索结果时通知你。

+   你可以为你的计算机基础设施定义警报，当某些行为偏离常规模式时通知你。

在更广泛地部署这种模式时，主要障碍可能是提前找到一个可靠的*有趣*的定义，这个定义同时满足以下两点：

有用

当你认为应该通知你时，它会通知你。

实用性

大多数用户不会愿意花费大量时间预先创建无尽的规则来设置警报。

LLM 的推理能力可以解锁这种*环境计算*模式的新应用，这些应用同时更加有用（它们能识别出更多你感兴趣的内容）并且设置起来更加简单（它们的推理可以替代大部分或全部的手动规则设置）。

*协作*和*环境*之间的主要区别在于并发性：

协作

你和 LLM 通常（或有时）同时工作，并从对方的工作中汲取灵感。

环境

当你，用户，可能在做其他事情时，LLM（大型语言模型）会持续在后台进行某种工作。

构建这个系统，你需要：

触发器

LLM 代理需要从环境中接收（或定期轮询）新信息。这实际上是环境计算的动力：一个现有的周期性或连续的新信息来源，需要被处理。

长期记忆

没有咨询之前接收到的信息数据库，将无法检测到新的有趣事件。

反思（或学习）

理解什么是*有趣*的（什么值得人类输入）可能需要从每个已经发生的有兴趣的事件中学习。这通常被称为*反思步骤*，其中 LLM 更新其长期记忆，可能修改其检测未来有趣事件的内部“规则”。

总结输出

在后台工作的代理可能会产生比人类用户希望看到的多得多的输出。这要求代理架构被修改以生成工作摘要，并将新或值得注意的内容仅呈现给用户。

任务管理器

在后台持续运行 LLM 代理需要采用某种系统来管理工作，排队新的运行，并处理和从错误中恢复。

# 摘要

LLMs 有潜力改变我们构建软件的方式，甚至改变我们构建的软件本身。我们开发者现在可以利用的新能力来生成新内容，不仅将增强许多现有应用，还可以实现我们尚未梦想过的新事物。

这里没有捷径。您真的需要构建一些（s）crap 的东西，与用户沟通，然后重复这个过程，直到出现新的、意料之外的东西。

通过这一章以及整本书，我们试图向您提供我们认为可以帮助您利用 LLMs 构建独特优秀事物的知识。我们感谢您与我们一同踏上这段旅程，并祝您在事业和未来中一切顺利。
