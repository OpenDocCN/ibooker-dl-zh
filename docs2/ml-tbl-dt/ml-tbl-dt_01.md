# 1 理解表格数据

本章涵盖

+   表格数据是什么

+   为什么表格数据很重要

+   深度学习和非深度学习方法在处理表格数据之间的区别

+   人们对于使用深度学习处理表格数据的看法

+   区分表格数据与其他类型数据（如图像、声音或文本数据）的特征

表格数据是我们现代生活以及对于我们大多数人来说，是工作生活的重要组成部分。表格数据存在于电子表格中，如 CSV 文件，以及关系数据库的表中，它填充了分析和报告，还可以作为训练机器学习模型的燃料。在您的表格业务上训练的机器学习模型可以成功解决许多有用的问题，例如预测零售店的库存需求或预测市场商品的价格。

在本章中，我们介绍了为表格数据问题选择适当建模方法的过程。我们介绍了两种主要方法：深度学习和经典机器学习。然后，从数据的角度来看，我们探讨了在使用机器学习模型处理表格数据时，你面临的一些独特考虑因素。

## 1.1 什么是表格数据？

为了本书的目的，“表格数据”仅仅是按行和列组织的数据。一组表格数据可以被称为**表格数据集**或**表格**。一行中的所有条目都与一个共同的数据点或观察相关。每一行与其他行是独立的，并完全描述了特定条件。列代表该数据点的属性，它们通常被称为变量（一个更统计学的术语）或特征（一个更典型的机器学习术语）。列中的所有条目具有共同的数据类型，如整数、字符串或浮点数。表格中的列通常具有相同的类型。

考虑一个包含一组国家使用的货币信息的表格，如图 1.1 所示。

![](img/CH01_F01_Ryan2.png)

图 1.1 表格数据的示例

该表中的列包含不同类型的值：

+   国家、货币名称、货币符号和 ISO 4217 代码都是**分类列**，因为这些列的有效值来自一个有限且相对较小的值集。

+   货币昵称是自由文本列，因为它们可以包含一系列值或根本没有值，这取决于国家。

+   每美元单位是一个连续列，因为它包含实数值。

我们将在第二章中探讨更多关于表格数据特性的细节。

表格数据可以存在于各种物理格式中：

+   **独立文件**，包括 CSV 文件和电子表格文件，如 Excel 和 Google Sheets 文件。

+   **关系数据库中的表格**，例如

    +   开源数据库，如 Postgres ([`www.postgresql.org/`](https://www.postgresql.org/)) 和 MySQL ([`www.mysql.com/`](https://www.mysql.com/))

    +   原地供应商数据库，例如 SQL Server（[`mng.bz/MD2W`](https://mng.bz/MD2W)）和 Oracle（[`www.oracle.com/ca-en/database/`](https://www.oracle.com/ca-en/database/)）

    +   云原生数据库，例如 Google Cloud Spanner（[`cloud.google.com/spanner`](https://cloud.google.com/spanner)）、AWS Aurora（[`aws.amazon.com/rds/aurora/`](https://aws.amazon.com/rds/aurora/)）和 Snowflake（[`www.snowflake.com/`](https://www.snowflake.com/)）

注意：你可能已经听到“结构化数据”这个术语与“表格数据”交替使用。然而，这两个术语并不相同。例如，人们有时将具有一定结构但不是表格形式的数据（如嵌套 JSON）称为结构化数据。结构化数据还包括关系数据、时间序列数据、图数据和空间数据，这些数据中的任何一种也可能以表格形式表示。为了避免任何混淆，我们将在本书中仅使用“表格数据”这个术语。

既然我们已经确定了什么是表格数据，那么什么不是表格数据呢？这是一个重要的问题，因为表格数据与非表格数据之间的差异有助于解释本书回答的关键问题之一：是否存在应该使用深度学习处理表格数据的情况？以下是一些非表格数据的例子：

+   图片

+   视频

+   音频

+   文本

+   JSON 格式的传感器数据，例如由物联网设备生成

+   社交媒体流数据

你能想到所有这些非表格数据类型有什么共同点吗？如果你回答，“它们都已被非常成功地用于训练深度学习模型”，你就完全正确了。确实，在过去的 10 年里，一个又一个突破性的模型都是使用各种非表格数据集创建的。在本书中，我们将探讨为什么深度学习没有像对非表格数据那样在表格数据的世界中引起轰动，以及在什么情况下将深度学习应用于表格数据是有意义的。

## 1.2 世界运行在表格数据上

根据文章《结构化数据与非结构化数据》（[`mng.bz/5g7Z`](https://mng.bz/5g7Z)），世界上所有数字数据中高达 90%是非表格数据，并且每年非表格数据的比例都在增加。如果这是真的，那么为什么还要读一本关于将机器学习方法应用于表格数据的书呢？虽然可能只有世界上很小一部分数据是表格数据，但这一部分数据绝对是至关重要的。每个银行、每家保险公司、每个政府机构、每个零售商、每个制造商——它们的所有核心活动都是基于表格数据运行的。这种主导地位首先是因为其以行和列排列的表格格式使得表格数据易于输入、检索、管理和分析。其次，表格数据得到了许多商业软件和应用程序的支持，例如电子表格、数据库和商业智能工具。

除了它们的核心活动之外，这些组织还依赖于表格数据来监控他们的进展和发现问题。作为现代生活中的消费者、雇员和公民，你的日常活动会在数百甚至数千个表格中产生更新。

在过去的三年里，本书的一位作者有幸负责世界上最大的关系型数据库产品之一的全球支持功能。一周七天，一天 24 小时，这项工作揭示了依赖于表格数据的组织的广度和深度。它还揭示了当表格数据系统失败时会发生什么。整个大陆的购物者无法使用他们的信用卡，卡车在边境上排起了长队，货运列车停止运行，零售网站在黑色星期五崩溃，制造人工心脏的工厂也停止了运转。这并非夸张——世界运行在表格数据以及结构化数据上。

表格数据无处不在，并且至关重要。对我们中的许多人来说，我们的工作围绕着表格数据。正因为如此，了解如何有效地将机器学习（以及在适当的情况下，深度学习）应用于表格数据是一项非常有用的技能。在这本书中，你将学习解锁表格数据潜力的技术。

## 1.3 机器学习与深度学习比较

深度学习和经典机器学习方法都旨在将输入数据映射到预测。然而，它们采取不同的方法，因为深度学习方法被设计来模拟生物大脑的行为，而其他机器学习技术通常基于统计优化或相似度比较。然而，除了采取不同的方法之外，它们还暗示了一种深刻不同的利用数据的方式。

在经典机器学习方法中，特征转换和工程至关重要，因为无论你采用哪种模型，你都需要根据数据特征和数据的来源领域（这是商业数据吗？它代表任何社会、经济或物理现象？）对数据进行适当的转换。以下是特征工程在经典机器学习中如此重要的几个原因：

+   *相关信息提取*——并非所有原始数据对特定任务都同等相关。特征工程有助于识别和提取数据中最具信息量的方面，丢弃无关或噪声的部分。通过关注相关特征，模型可以专注于学习基本模式，从而实现更好的泛化并提高性能。

+   *数据表示*——不同的模型在数据表示方面有不同的要求。特征工程允许你将数据转换为适合模型假设和限制的合适格式。这一步骤保证了模型可以从数据中有效地学习并做出准确的预测。

+   *处理非线性*—在许多现实世界问题中，特征与目标变量之间的关系可能不是线性的。特征工程可以帮助转换数据以处理非线性，使线性模型更容易近似复杂关系。

+   *特定领域知识*—在某些情况下，领域专家可能对数据有宝贵的见解，这些见解可以用来构建相关的特征。引入领域知识可以显著提高模型在特定应用中的性能。

另一方面，深度学习方法依赖于*表示学习*，这是它们内部和自动将数据处理成有意义形式以解决手头问题的能力。深度学习模型的表示学习能力使它们能够将数据转换成更紧凑和有意义的形式，从而捕捉特定任务的相关特征和模式。实际上，在学习过程中，由于所有输入特征都以非线性方式与其他特征相互作用，深度学习模型能够自行发现数据中的复杂模式和依赖关系，这些模式和依赖关系可能无法通过手动特征工程显现出来，并且它们能够开发出从基本特征开始，逐步构建到更复杂和抽象的输入数据层次表示。

因此，经典机器学习主要侧重于彻底和有效的特征工程，而表格数据的深度学习模型则更多地关注神经元层级的排列架构以及单个神经元的特性。这种二分法构成了我们书籍的一个基本方面：接下来的章节不仅强调经典机器学习模型和深度学习模型之间的区别，而且还介绍了不同的方法来构建数据问题并基于这种区别找到解决方案。

虽然以这种方式简化术语可能不完全正统，但在整本书中，我们使用通用术语*机器学习*或*经典机器学习*来指代所有机器学习方法，除了神经网络，我们使用*深度学习*来指代基于神经网络的方法。

我们将介绍基于流行包（如）的基本和更高级的机器学习模型：

+   可在 Scikit-learn ([`scikit-learn.org/`](https://scikit-learn.org/)) 和 GPU 专用库（如 NVIDIA Rapids ([`developer.nvidia.com/rapids`](https://developer.nvidia.com/rapids))）中找到的基本机器学习模型：

    +   线性回归

    +   逻辑回归

    +   广义线性模型

+   Scikit-learn 中可用的基于树的某些方法包括

    +   弱预测器的 Bagging 集成

    +   随机森林

    +   极端随机树

+   基于直方图的梯度提升方法，包括

    +   XGBoost eXtreme Gradient Boosting ([`github.com/dmlc/xgboost`](https://github.com/dmlc/xgboost))

    +   微软的 LightGBM ([`github.com/Microsoft/LightGBM`](https://github.com/Microsoft/LightGBM))

    +   Scikit-learn 中的 HistGradientBoosting

对于深度学习，我们将介绍在 TensorFlow 或 PyTorch 深度学习框架中实现的、对表格数据有效的各种架构：

+   带有分类嵌入的浅层网络（直接使用可用的深度学习框架之一实现）

+   fastai 表格 ([`docs.fast.ai/tabular.model.html`](https://docs.fast.ai/tabular.model.html))

+   PyTorch 表格 ([`github.com/manujosephv/pytorch_tabular`](https://github.com/manujosephv/pytorch_tabular))

+   TabNet ([`arxiv.org/abs/1908.07442`](https://arxiv.org/abs/1908.07442))

+   SAINT ([`arxiv.org/abs/2106.01342`](https://arxiv.org/abs/2106.01342))

+   DeepTables ([`github.com/DataCanvasIO/deeptables`](https://github.com/DataCanvasIO/deeptables))

在我们探索这两种方法并建议何时使用每种方法来解决表格数据问题时，你将在这本书中看到机器学习和深度学习之间的这种区别。

## 1.4 表格数据有何不同？

我们知道，由于深度学习方法在解决涉及多种类型的数据问题时占主导地位，这些数据我们可能定义为“非表格”或“非结构化”，因为它们的特征、大小和模态的多样性，你无法在行/列数据模型中约束。深度学习成功解决的典型非结构化数据示例包括

+   音频

+   视频

+   图片

+   文本

在这里，与结构化表格数据问题相反，你没有任何接近典型矩阵形状的格式，而是不同文件或实例，以无序的方式包含大量信息。在深度学习革命改变非结构化数据建模方式之前，我们想要用于预测模型的非结构化数据必须通过仔细创建定义良好且具体的特征（称为特征工程）来转换成结构化数据格式。对于每种非结构化数据问题，研究人员和从业者花费了数年时间来找到从数据中提取的最佳特征，以供机器学习模型使用，并最终获得令人满意的预测结果。

由于它们的表示能力，深度学习模型可以处理所有必要的转换，将非结构化数据转换为可行的预测，以端到端的方式，直接从输入到解决方案。基于这个背景，你可能会预期深度学习模型在表格数据上会更加有效，但到目前为止并非如此。

实际上，有许多原因可以解释深度学习在处理表格数据问题时面临的挑战。第一个原因是学术研究和新技术的私人投资的实际方向。正如我们提到的，过去，研究人员花费时间和精力寻找将非结构化数据转换为结构化数据以适应当时机器学习范式的最佳方法。如今，同样的努力被用于推进深度学习，特别关注非结构化数据，因为它们在公共仓库中更容易获取，并且比表格数据“更统一”，因此带来了更多的研究成功。

图像库，如 ImageNet ([`image-net.org/index.php`](https://image-net.org/index.php)) 和开放文本语料库，如维基百科或 Common Crawl 的网页存档 ([`commoncrawl.org/`](https://commoncrawl.org/))，对学术研究人员和从业者来说都很容易获取，用于训练或改进他们的深度学习模型。至于表格数据，在公共开源数据仓库方面没有等效的。相反，表格数据分散在众多私有数据库中，每个数据库的变异性甚至比非结构化数据还要高，因为每个数据库都有自己的数据收集规则和特征结构。

除了开源的表格数据集通常更难找到这一事实之外，你还必须考虑第二个原因。开源的表格数据集通常规模较小，并且往往与企业和政府拥有的私有数据有很大不同。因此，数据的缺乏通常会导致神经网络性能不佳。此外，没有黄金法则可以用来衡量一个人的进步，因为使用特定类型的数据仅限于表格数据问题广泛领域中的特定问题。对于任何研究人员来说，从表格数据集或有限的选项中概括最佳实践，比使用普遍可用和接受的图像、音频或文本作为参考基准来做同样的事情要更具挑战性。

由于难以获取且包含的信息类型极其多样，表格数据集对深度学习解决方案提出了进一步的限制：你无法想到任何预训练的解决方案，因为你无法掌握所有类型的表格问题。一旦你为图像和文本问题开发了一个深度学习模型，你就可以将其公开，并期望其他学者或从业者稍作调整后，将其用于他们的问题。这在技术上被称为*迁移学习*，因为你可以成功地将在一个问题上训练的深度学习网络，以有限的额外建模努力，应用于另一个相似的任务。这种机会在近年来强烈推动了以预训练形式扩散深度学习模型。

总之，缺乏可推广的表格示例、表格数据类型的多样性以及学者对非结构化数据的更多关注，导致了机器学习和深度学习之间特征工程扮演着不同的角色：

+   在机器学习中，特征工程可以为表格数据提供比算法本身更强的预测能力，并且通常被认为更像是艺术而非科学。

+   在深度学习中，相反，学者和从业者往往过于依赖表示学习，让网络处理一切，而不是自己使用特征工程，并展示深度学习如何，在给定与机器学习算法相同的数据框架的情况下，以不同且有用的方式学习解决方案。

确实，正如最近的研究所证明的，表格数据特征，如冗余特征、偏斜分布和预测目标的非规律模式，对神经网络构成了挑战。我们将在第五章中更详细地讨论这一点，当具体处理梯度提升模型时。尽管如此，我们断言，机器学习和深度学习模型都是解决表格数据问题的可行方法，随着从业者和研究者在测试比今天更容易获得的表格数据上的架构和解决方案上投入更多努力，深度学习的重要性将会增长。

## 1.5 生成式 AI 和表格数据

生成式 AI——特别是大型语言模型（LLMs）——是各种与文本生产和处理相关的任务的得力助手。一般来说，LLMs 已被证明是某些范围内任务的突破性解决方案，例如

+   *生成*——生成文本，如下一个标记、完成短语所需的单词，甚至从指导提示生成文本

+   *提取*—命名实体识别、句子分割、关键词提取、主题建模、命名实体识别、语义关系提取

+   *分类*—语言、意图、情感、语义，甚至包括讽刺、反语、否定等棘手问题

+   文本的*转换*——翻译、校正、风格修改、释义、总结

+   *理解*——导致问答、推理、知识补全

许多这些任务可以扩展到数据科学家或数据工程师的工作。LLMs 可以在特征工程、编写函数和可视化指令（例如，使用 matplotlib 包的命令）等活动上支持用户，提供分析建议，帮助解释结果，并将它们综合性地呈现为图表和报告。LLMs 在表格数据中的一个显著的实际应用是自动化文本数据相关任务。当处理文本变量字段时，它们可以通过总结、分类和识别关键主题来构建新的特征。它们还可以开发用于在 Python 中处理相同文本的代码，例如，通过创建函数或确定文本处理的正确正则表达式。

除了支持用户和作为有用的助手外，大型语言模型（LLMs）还可以在分析中扮演更加直接和活跃的角色。最近 ChatGPT（高级数据分析 API）的应用也提供了直接的数据分析，以 CSV 格式呈现，随后是其他与数据相关的任务，包括总结、预处理、分析、可视化和报告生成。在每一步，该工具都可以提供执行并获得相同结果的 Python 代码，它为您运行代码并提供一些图表和表格形式的可视化。这与 TableGPT 或其他工具（如 MediTab）预期的功能相一致。TableGPT（[`arxiv.org/pdf/2307.08674.pdf`](https://arxiv.org/pdf/2307.08674.pdf)）是一个新的框架，它利用 LLMs 来增强人类与表格数据的交互。它使用户能够使用自然语言表达的命令与表格交互，并执行各种任务，如问答、数据处理、数据可视化和报告生成以及自动预测。相反，MediTab（[`arxiv.org/pdf/2305.12081.pdf`](https://arxiv.org/pdf/2305.12081.pdf)）通过整合表格样本、将域外数据与目标任务对齐以及扩展训练数据，专注于处理医学表格数据。面对基于文本数据的预测任务，它甚至展现了优于 XGBoost 等经典机器学习算法的性能。

通常来说，大型语言模型（LLMs）在表格数据的预测任务上并不提供可比的性能，正如 TABLET 基准测试（[`arxiv.org/pdf/2304.13188.pdf`](https://arxiv.org/pdf/2304.13188.pdf)）所示。在评估 LLMs 相对于全监督模型的表现时，该论文通过 4 次示例比较了 Flan-T5 11b 和 ChatGPT，与在整个数据集上训练的 XGBoost 进行了比较。当 XGBoost 模型应用于所有数据时，在预测任务上实现了平均 F1 分数为 0.94。相比之下，ChatGPT 的平均得分为 0.68，而 Flan-T5 11b 使用 F1 分数实现了 0.66。这一分析突出了在涉及具有多模态类型（文本和数字）的表格数据的 LLMs 预测任务中，仍有很大的改进空间，并且这些工具在执行指令方面继续表现出色，尤其是在处理文本输入和产生文本输出时。例如，llm-classifier（[`github.com/lamini-ai/llm-classifier`](https://github.com/lamini-ai/llm-classifier)）这样的工具因其能够使用已使用的 LLM 中包含的信息而令人惊讶，但它无法获取表格问题典型的许多额外信息。

总的来说，在处理表格数据时，生成式 AI 尚未成为解决方案，这不仅是因为性能原因，还因为其他关键方面，例如

+   *成本*—生成式 AI 模型通常需要大量的 GPU 资源，导致更高的运营成本。

+   *可扩展性*—生成式 AI 模型资源密集型的特性，尤其是它们对 GPU 的依赖，可能阻碍可扩展性。

+   *延迟和吞吐量*—较大的模型往往会增加每个请求的处理时间，影响延迟和吞吐量。

+   *偏差*—生成式 AI 模型可能会从它们训练的数据中继承偏差，可能加剧或放大现有偏差。

+   *灵活性*—将生成式 AI 模型适应定制任务通常需要大量的重新训练，这限制了它们的灵活性。

+   *决定论*—生成式 AI 模型的固有复杂性可能使其难以控制和预测其输出，从而影响决定论。

+   *可解释性*—生成式 AI 模型的复杂性可能阻碍可解释性，使得理解它们如何运作和产生结果变得困难。

承认生成式 AI 处理表格数据问题的现有局限性，我们将重点关注从表格数据中学习的核心经典机器学习和深度学习技术，以及如何正确和恰当地准备这些数据以进行分析。然而，我们也将留出一些空间来处理生成式 AI 工具，如 ChatGPT、Google Gemini 和为 Google Cloud 提供的 Gemini，因为我们认识到生成式 AI 在表格数据领域的变革力量。根据我们在该领域的经验，我们预计 LLM 或其他生成工具不会取代经典的机器学习算法或专门针对表格数据的深度学习架构，因为这些综合工具在性能和控制方面都提供了优势。相反，我们认识到 LLM 和其他生成 AI 模型如何支持并增强表格数据处理、分析和建模，帮助从业者在其表格数据项目中变得更加熟练和高效。

## 摘要

+   表格数据是有行和列组织的数据，例如 CSV 文件或关系型数据库表中的数据。

+   结构化数据有时被用作表格数据的同义词，但它是一个更广泛的概念，包括 JSON 格式的数据。

+   表格数据仅占全球所有数字数据的一小部分，但它对我们生活的影响是巨大的。

+   与其他类型的数据（例如图像、视频、文本、音频）相比，大多数工作围绕的数据类型是表格数据，因此学习如何高效地将机器学习/深度学习应用于表格数据是一项有用的技能，许多人可以将这项技能应用于他们的工作中。

+   在这本书中，我们简单地称不包括神经网络（从线性回归到梯度提升方法）的机器学习方法为*经典机器学习*或简称为*机器学习*，以区分它们与深度学习。

+   与其他类型的数据（例如图像、视频、文本、音频）的深度学习相比，表格数据的深度学习在学术研究者中得到的关注较少。

+   传统观点是使用类似于 XGBoost 的梯度提升方法来处理表格数据。

+   在社交媒体上，关于深度学习是否在解决涉及表格数据的问题中有一席之地，存在热烈的讨论。在这本书中，我们并不在这场辩论中站队。相反，我们试图客观地描述为什么你会选择机器学习或深度学习来解决特定的表格数据问题，以及每种方法的最佳实践。

+   表格数据具有一些其他类型数据（如图像、视频、文本）所不具备的独特特征。这些特征包括缺乏代表现实世界业务问题中表格数据集的大型开源数据集。

+   生成式 AI，尤其是大型语言模型（LLMs），显著影响了人们对 AI 的认知、在个人和组织中的传播以及应用。LLMs 可以帮助自动化与表格数据分析建模相关的各种任务，尤其是在涉及文本输入和输出的情况下。
