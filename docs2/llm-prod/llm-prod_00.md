# 1 *词汇的觉醒：为什么大型语言模型引起了关注*

### 本章涵盖

+   大型语言模型是什么，它们能做什么，不能做什么

+   你应该在何时何时不部署自己的大型语言模型

+   大型语言模型的神话及其背后的真相

> 任何足够先进的技术都与魔法无法区分 —— 亚瑟·C·克拉克

年份是 1450 年。德国美因茨的一个沉睡的角落，不知不觉地站在一个重大时代的边缘。在 Humbrechthof，一个被城镇阴影笼罩的普通车间，充满了期待。正是在这里，约翰内斯·古腾堡，一位金匠和革新者，在油、金属和决心的气味中汗流浃背地劳作，默默地孕育着一场革命。在深夜时分，金属敲击金属的节奏性敲打不时打破宁静。在车间灯光照耀的中心，是古腾堡十年来的爱情结晶——一个设计独特、用途非凡的装置。

这不是一项普通发明。工艺和创造力将各种可移动金属字型、一个个辛苦铸成的字符，组合成一个矩阵。闪烁的灯光在金属标志上舞动。空气中充满了突破的期待和基于油墨的浓郁甜味，这是古腾堡本人的创新。在那一刻的宁静中，这位大师印刷师挺直了肩膀，以无与伦比的技巧，在墨水充盈的矩阵下铺下一张清晰的羊皮纸，让他的发明紧紧压印，在页面上留下精细的印刷。房间调整到了沉默的交响乐，紧张的呼吸在空气中沉重地悬挂。当印刷机被抬起时，它因自身的重量而嘎吱作响，每一次尖叫都像是一声战斗的呐喊，宣布着一个激动人心的新世界的到来。

古腾堡以一阵动作，从印刷机中取出第一张印刷页，并将其平铺在木桌上。他仔细检查每一个字符，它们都像创造者的愿景一样大胆而宏伟。房间中的每个人都沉浸在这景象中，完全被迷住了。一张普通的羊皮纸已成为变革的见证。当夜晚让位于白天时，他带着振奋的骄傲看着他的车间。他的遗产诞生了，在历史的长河中回响，永远改变了信息飞翔的方式。约翰内斯·古腾堡，现在成为千禧年的人物，从阴影中走出，一个敢于梦想的发明家。他的名字与印刷机同义，这不仅是一项开创性的发明，而且是现代世界的催化剂。

当古腾堡的成就的消息开始在大陆上飘扬时，来自各个学科的学者们还没有意识到他们手中的这个非凡工具。知识和学习，曾经是渴望的宝藏，现在对普通人来说触手可及。围绕这一新发现，意见各异，看法不一。

> 在我们这个时代，多亏了莱茵河畔那些人的才能和勤奋，书籍的数量激增。曾经只有富人——不，只有国王才能拥有的书，现在可以在简陋的屋顶下看到。……如今，我们的孩子……似乎无所不知。——塞巴斯蒂安·布兰特
> 
> 学术努力在各个地方都在下降，前所未有。的确，聪明才智在国内和国外都被摒弃。阅读能为学生带来什么，除了泪水？当它被出售时，是罕见的、无价值的，而且缺乏智慧。——列日的大卫

人们对于书籍的看法在历史上一直各不相同。在我们这样一个虚拟印刷机存在且书籍无处不在的时代，我们可以达成共识的是，印刷机改变了历史。虽然我们并没有亲眼目睹古腾堡使用他的印刷机打印出第一页，但我们见证了很多人第一次与大型语言模型（LLMs）互动。当他们看到它对他们的第一个提示做出反应时，脸上的惊讶。当他们用难题挑战它，却看到它像该领域的专家一样回应时，他们的兴奋——当他们意识到他们可以用它来简化自己的生活或让自己变得富有时，这就是灵光一闪的时刻。我们想象这种情绪的波涛只是约翰内斯·古腾堡所感受到的一小部分。能够快速生成文本和加速沟通始终是有价值的。

## 1.1 大型语言模型加速沟通

每个工作都有一定程度的沟通。通常，这种沟通是肤浅的、官僚的或政治性的。我们经常警告学生和门徒，每个工作都有自己的文书工作。曾经是激情的事物，很容易被随之而来的日常乏味和琐事所扼杀，当它变成工作的时候。事实上，当人们谈论他们的职业时，他们经常夸大其词，试图提高自己的社会地位，所以你很少能听到全部真相。你不会听到那些无聊的部分，而日常的艰辛则被方便地遗忘了。

然而，设想一个我们可以减少单调工作负担的世界。一个警察不再需要浪费每天数小时填写报告，而是可以将时间用于社区外展项目的地方。或者一个教师不再需要深夜批改作业和准备教案，而是能够思考并为个别学生准备定制课程的世界。甚至是一个律师不再被困在法律文件中数日，而是可以自由地接受那些激励他们的慈善案件的世界。当沟通负担、文书工作负担和会计负担被移除时，工作就更加接近我们所说的样子。

对于这一点，LLM 是自印刷术以来最有希望的技术。首先，它们已经完全颠覆了人类与计算机之间的角色和关系，改变了我们相信它们能够做到的事情。它们已经通过了医学考试、律师资格考试和多个心智理论测试。它们通过了谷歌和亚马逊的编码面试。他们在 SAT 考试中获得了至少 1410 分（满分 1600 分）。对作者来说，最令人印象深刻的成绩之一是 GPT-4 甚至通过了高级品酒师考试，这让我们想知道 LLM 是如何通过实际品酒部分的。确实，它们的空前成就正以惊人的速度到来，常常让我们这些凡人感到有些恶心和不安。面对似乎能做任何事的技术，你该怎么办？

注意：Med-PaLM 2 在 MedQA 考试中获得了 86.5% 的成绩。您可以在 OpenAI 的 GPT-4 论文中查看通过考试列表，链接为 [`cdn.openai.com/papers/gpt-4.pdf`](https://cdn.openai.com/papers/gpt-4.pdf)。最后，谷歌将 ChatGPT 作为测试进行了面试，并且它通过了 ([`mng.bz/x2y6`](https://mng.bz/x2y6))。

通过考试很有趣，但并不一定有用，除非我们的目标是建造史上最昂贵的作弊机器，并且我们承诺有更好的方法来利用我们的时间。LLM（大型语言模型）擅长的是语言，尤其是帮助我们改进和自动化沟通。这使得我们可以将常见的痛苦经历转化为简单、愉快的体验。首先，想象一下走进你的家，那里有你自己的个人 JARVIS，就像穿上钢铁侠的鞋子一样，一个由人工智能驱动的助手，为你的日常生活增添了无与伦比的活力。虽然 LLM 的水平并不完全达到漫威电影中 JARVIS 所描绘的人工通用智能（AGI）水平，但它们正在推动新的用户体验，从改善客户服务到帮助你为心爱的人挑选生日礼物。它们知道询问你关于这个人的信息，了解他们的兴趣和个性，了解你的预算，然后提供专业推荐。虽然许多这些助手正在被用于良好的工作，但许多其他只是用户可以与之交谈并自娱自乐的聊天机器人——这很重要，因为即使是我们的想象中的朋友现在也太忙了。玩笑归玩笑，这些可以创造惊人的体验，让你能够遇见你最喜欢的虚构角色，如哈利·波特、福尔摩斯、安纳金·天行者，甚至是钢铁侠。

然而，我们确信许多读者感兴趣的却是编程助手，因为我们都知道搜索一切实际上是一种最糟糕的用户体验。能够用简单的英语写几个目标，然后看到合作编写代码是令人兴奋的。我们亲自使用这些工具来帮助我们记住语法，简化并清理代码，编写测试，以及学习新的编程语言。

电子游戏是另一个我们期待 LLMs（大型语言模型）能带来大量创新的有趣领域。它们不仅帮助程序员创建游戏，还允许设计师创造更加沉浸式的体验。例如，与 NPC（非玩家角色）的对话将更加深入和引人入胜。想象一下像动物之森和星露谷物语这样的游戏，拥有近乎无限的任务和对话。

考虑其他行业，比如教育，似乎永远都不够教师，这意味着我们的孩子得不到他们需要的个别关注。一个 LLM 助手可以帮助教师节省做手工杂事的时间，并为有困难的孩子担任私人导师。企业界正在研究 LLMs 用于与数据交流的工作——比如帮助员工理解季度报告和数据表格——本质上为每个人提供自己的个人分析师。销售和营销部门肯定会利用这一卓越的创新，无论好坏。搜索引擎优化（SEO）的状态也将发生很大变化，因为目前，它主要是一场生成内容以希望使网站更受欢迎的游戏，而这现在变得超级简单。

上述列表只是公司对使用 LLMs 感兴趣的一些常见例子。人们也出于个人原因使用它们，比如写音乐、诗歌，甚至书籍；翻译语言；总结法律文件或电子邮件；甚至提供免费治疗——是的，这是一个糟糕的想法，因为 LLMs 在这方面仍然很糟糕。这只是个人偏好，但我们不会在精神健康受到威胁时试图节省一分钱。当然，这导致了一个事实，即人们已经在使用 LLMs 进行更阴暗的目的，比如作弊、诈骗和虚假新闻来扭曲选举。此时，这个列表已经相当长且多样化，但我们只是刚刚触及了可能性的表面。实际上，由于 LLMs 帮助我们进行沟通，通常最好是思考“它们不能做什么？”而不是“它们能做什么？”或者更好，“它们不应该做什么？”

嗯，作为一种技术，它有一些限制和约束。例如，LLMs 有点慢。当然，“慢”是一个相对术语，但响应时间通常以秒计，而不是毫秒。我们将在第三章中更深入地探讨这个话题，但作为一个例子，我们可能不会很快看到它们被用于自动补全任务，这些任务需要极快的推理才能有用。毕竟，自动补全需要能够比人更快地预测单词或短语。同样，LLMs 是庞大而复杂的系统；我们不需要它们来解决这样简单的问题。用 LLM 解决自动补全问题不仅仅是用大锤钉钉子；它是用完整的破坏球砸它。而且，就像租用破坏球比买锤子更贵一样，LLM 的运营成本也会更高。有许多类似的任务，我们应该考虑我们试图解决的问题的复杂性。

此外，还有许多复杂的问题，LLMs 通常解决得不好，例如预测未来。不，我们不是指神秘的艺术，而是指预测问题——比如预测天气或高潮何时会击中海岸。这些实际上是已经解决的问题，但我们不一定有很好的方法来传达它们是如何解决的。它们是通过数学解决方案的组合来表达的，比如傅里叶变换和调和分析，或者黑盒机器学习模型。许多问题都符合这一类别，比如异常值预测、微积分或找到卷纸的末端。

你可能还希望避免在高度风险的项目中使用它们。大型语言模型（LLMs）并非完美无缺，经常会犯错误。为了增加创造力，我们通常允许 LLMs 中存在一定程度的随机性，这意味着你可以向 LLMs 提出相同的问题并得到不同的答案。这是有风险的。你可以通过降低温度来移除这种随机性，但这可能会根据你的需求使 LLMs 变得无用。例如，你可能会决定使用 LLM 来将投资选项分类为好或坏，但你希望它根据其输出做出实际的投资决策吗？除非你的目标是制作一个搞笑视频，否则不应该是这样的。

最终，LLM 只是一个模型。它不能对损失你的金钱负责，实际上，损失金钱的是你自己，因为你选择了使用它。类似的风险问题包括填写税务表格或获取医疗建议。虽然 LLM 可以完成这些任务，但它不会像聘请有资格的注册会计师那样在 IRS 审计中保护你免受重罚。如果你从 LLM 那里得到不良的医疗建议，你无法起诉任何医生。然而，在所有这些例子中，LLM 都有可能帮助从业者更好地履行他们的工作职责，无论是通过减少错误还是提高速度。

##### 何时使用 LLM

使用它们进行

+   生成内容

+   问答服务

+   聊天机器人和 AI 助手

+   文本到其他事物的问题（扩散、txt2img、txt23d、txt2vid 等）

+   与你的数据交谈的应用

+   任何涉及沟通的事情

避免使用它们的情况

+   对延迟敏感的工作负载

+   简单项目

+   我们不通过文字而是通过数学或算法解决的问题——预测、异常值预测、微积分等

+   临界评估

+   高风险项目

语言不仅仅是人们用来沟通的媒介。它是使人类成为顶级捕食者的工具，并为每个个体在其社区中提供了自我定义。人类存在的各个方面，从与父母争吵到大学毕业再到阅读这本书，都充满了我们的语言。语言模型正在学习利用人类本质的基本方面，并且当负责任地使用时，它们有能力帮助我们完成每一个任务。如果我们负责任地教导它们，它们有潜力解锁我们自己和他人理解的维度。

大型语言模型（LLMs）自从它们潜在的想象力无限以来，就吸引了全世界的关注。LLMs 承诺了如此之多，但这些解决方案在哪里？那些能给我们带来沉浸式体验的视频游戏在哪里？为什么我们的孩子还没有个人 AI 导师？为什么我还没有拥有自己的个人助理成为钢铁侠呢？这些问题是促使我们写这本书的深刻和深刻的问题。尤其是最后一个问题让我们夜不能寐。所以虽然 LLMs 能做惊人的事情，但知道如何将它们转化为实际产品的人还不够多，这正是我们在这本书中想要分享的。

这不仅仅是一本机器学习操作的书。让 LLM 在生产环境中工作涉及许多陷阱和陷阱，因为 LLMs 不像传统的软件解决方案那样工作。将 LLM 转化为可以与您的用户进行连贯交互的产品需要整个团队和多样化的技能。根据您的用例，您可能需要训练或微调自己的模型，或者您可能需要通过 API 从供应商那里获取模型。

无论您使用哪种 LLM，如果您想充分利用这项技术并构建最佳用户体验，您将需要了解它是如何工作的——不仅是在数学/技术方面，还包括软性方面，使您的用户获得良好的体验。在这本书中，我们将涵盖您需要让 LLMs 在生产环境中工作的所有内容。我们将讨论最佳工具和基础设施，如何通过提示工程最大化它们的效用，以及其他最佳实践，如控制成本。LLMs 可能是走向更大平等的一步，所以如果你在想，“我觉得这本书不是为我写的”，请重新考虑。这本书是为整个团队以及未来将与 LLMs 互动的任何人而写的。

![figure](img/1-unnumb.png)

##### 感谢 SuperElmer，[`www.facebook.com/SuperElmerDS`](https://www.facebook.com/SuperElmerDS)

我们将涉及你需要的一切，从收集和创建数据集，到在消费或工业硬件上训练或微调 LLM，以及以各种方式部署该模型，以便客户与之交互。虽然我们不会过多涉及理论，但我们将通过实际案例从始至终地介绍整个过程。在这本书的结尾，你将知道如何部署 LLMs，并有一些可行的经验作为支持。

## 1.2 使用 LLMs 进行构建和购买决策的导航

如果你购买了这本书，你很可能已经确信 LLMs（大型语言模型）在你的生活和组织中具有巨大的潜力。因此，购买这本书是把你梦想变成现实的第一步，因为除非我们知道如何将这些模型投入生产，否则这一切都不可能实现。毕竟，如果你和任何企业家或投资者交谈，他们都会告诉你好主意到处都是；重要的是执行，以实现这些想法。我们需要做的是将这些模型投入生产，让它们能够为你实际工作。

没有办法回避这一点，也不需要美化它：将 LLMs 投入生产是困难的。通常，任何值得追求的事情都是如此。在这本书中，我们旨在教你所有你需要知道的知识，并给你一些实际的操作经验。但是，由于它如此困难，所以走捷径是非常诱人的。像 OpenAI 和 Google 这样的大型企业提供了一些非常好的模型选择。为什么不直接购买呢？让我们先考虑他们提供的内容以及何时是好的选择。然后我们将看看硬币的另一面，这些提供往往不尽如人意。

### 1.2.1 购买：一条老路

有很多很好的理由只是购买 LLM 的访问权限。首先也是最重要的是，访问 API 提供的速度和灵活性。与 API 合作是一种极其简单且成本效益高的方式，可以快速构建原型并快速上手。事实上，它如此简单，以至于只需要几行 Python 代码就可以开始连接到 OpenAI 的 API 并使用 LLMs，如列表 1.1 所示。当然，有很多可能的事情，但只投资 LLMs 却发现它们在你的特定领域失败，这绝对是一个糟糕的主意。与 API 合作让你能够快速失败。构建一个原型应用程序来证明概念，并使用 API 启动它，是一个很好的开始。

##### 列表 1.1 调用 OpenAI API 的简单应用

```py
import os
from openai import OpenAI

client = OpenAI(                       #1
    api_key=os.getenv("OPENAI_API_KEY")         #2
)

chat_completion = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello world"}],
)
```

#1 从环境变量中加载你的 API 密钥

#2 这在技术上不是必需的，因为我们正在传递默认密钥。

通常，购买访问模型可以给你带来竞争优势。在许多情况下，市场上最好的模型可能是由专注于你所在领域的公司构建的，该公司投入了大量资金来精心挑选特定的数据集。虽然你可以尝试竞争并构建自己的模型，但购买访问模型可能更适合你的目的。最终，谁拥有更好的特定领域数据来微调，谁就更有可能获胜，而这可能不是你，如果这是你公司的一个副项目。毕竟，整理数据可能很昂贵。购买它可能会节省你大量的工作。

这引出了下一个要点：购买是一种快速获取专业知识和支持的方法。例如，OpenAI 已经投入了大量时间，通过充分的过滤和控制来确保他们的 LLMs 安全，以防止其被滥用。他们已经遇到了并解决了许多边缘情况，因此你不必担心。购买访问他们的模型也让你能够访问他们围绕它构建的系统。

不仅如此，当将 LLM 部署到生产环境中时，LLM 本身只是问题的一半。你还需要在上面构建一个完整的应用程序。有时，由于用户体验（UX）和一些技巧，如让标记看起来像是在被输入，购买 OpenAI 的模型在竞争中脱颖而出，这并非微不足道。我们将向您展示如何开始解决您用例中的 UX 问题，以及一些您可以用来在这个领域取得重大领先的原型设计方法。

### 1.2.2 构建：少有人走的路

使用 API 很简单，在大多数情况下，这可能是最佳选择。然而，有许多原因让你应该努力拥有这项技术并学习如何自己部署它。虽然这条道路可能更难，但我们将教你如何做到这一点。让我们深入探讨几个原因，从最明显的开始：控制。

#### 控制

首批真正将 LLM 作为核心技术采用的公司之一是一家名为 Latitude 的小型视频游戏公司。Latitude 专注于类似龙与地下城的角色扮演游戏，这些游戏利用 LLM 聊天机器人，他们在与这些机器人合作时遇到了挑战。这并不意味着在批评这家公司犯下的错误，因为他们为我们的集体学习经验做出了贡献，并且是开辟新道路的先驱。尽管如此，他们的故事是引人入胜且引人入胜的——就像一场火车事故，我们忍不住要继续观看。

Latitude 的首个发布是一款名为 AI Dungeon 的游戏。在最初，它利用 OpenAI 的 GPT-2 创建了一个互动和动态的叙事体验。它迅速聚集了大量玩家，他们当然开始不恰当地使用它。当 OpenAI 给 Latitude 提供了 GPT-3 的访问权限时，它承诺将提升游戏体验；然而，它得到的却是一场噩梦。¹

你看，随着 GPT-3，OpenAI 增加了来自人类反馈的强化学习（RLHF），这极大地帮助提高了功能，但这也意味着 OpenAI 的承包商现在正在查看提示。这就是人类反馈的部分。而且这些工人并不太愿意阅读游戏产生的污秽内容。OpenAI 的代表迅速向 Latitude 提出了最后通牒。要么它需要开始审查玩家，要么 OpenAI 将移除 Latitude 对模型的访问权限——这几乎会杀死游戏和公司。在别无选择的情况下，Latitude 迅速添加了一些过滤器，但过滤系统只是一个临时补救措施，一个充满错误和漏洞的混乱。玩家对系统如此糟糕感到不满，并感到不安，意识到 Latitude 的开发人员正在阅读他们的故事，完全无视 OpenAI 已经在这样做的事实。这是一个公关噩梦。而且还没有结束。

OpenAI 认为游戏工作室做得不够；Latitude 被迫加强安全措施，开始禁止玩家。这里有个转折：这么多故事变成低俗内容的原因是因为模型偏好色情。它经常会意外地将无害的故事情节转变为不恰当的冒犯性情境，导致玩家被踢出游戏并被禁止进入。OpenAI 充当纯洁的典范，但问题是他们的模型，这导致了游戏历史上最讽刺和不公正的问题之一：玩家因为游戏本身被禁止。

所以，他们就在那里——一家年轻的游戏工作室，只是想制作一款有趣的游戏，却陷入了愤怒的客户和将所有责任推给他们的科技巨头之间。如果公司对技术有更多的控制权，它本可以寻求真正的解决方案，比如修复模型，而不是像给猪涂脂抹粉一样。

在这个例子中，控制可能表现为你调整模型的能力，而 OpenAI 现在提供了微调功能，但使用服务而不是自己解决问题仍然会失去许多细粒度的决策。例如，使用的训练方法是什么，模型部署在哪些地区，或者它在什么基础设施上运行。对于任何客户或内部工具，控制也同样重要。你不希望代码生成器意外地输出受版权保护的代码，或者为你的公司创造法律问题。你也不希望你的面向客户的 LLM 输出关于你的公司或其流程的事实性错误信息。

控制是你以符合你的目标、目标和价值观的方式指导和管理的操作、流程和资源的能力。如果一个模型最终成为你产品提供的核心，而供应商意外地提高了价格，你几乎无能为力，只能支付。如果供应商决定其模型应该给出更自由或保守的答案，这些答案不再符合你的价值观，你也会陷入困境。

一项技术对你的商业计划越重要，控制它就越重要。这就是为什么麦当劳拥有其特许经营权的房地产，为什么谷歌、微软和亚马逊都拥有自己的云网络，甚至为什么许多企业家通过 Shopify 而不是 Etsy 或亚马逊市场等平台建立在线商店。最终，当你购买他人的产品时，控制权是首先失去的东西。保持控制权将为你提供更多解决未来问题的选择，并也会给你带来竞争优势。

#### 竞争优势

部署自己的模型最有价值的方面之一是它为你带来的竞争优势。定制化允许你训练模型使其在某一件事上做到最好。例如，在 2017 年发布了双向编码器表示（BERT）之后，这是一个你可以用来训练自己模型的转换器模型架构，随后研究人员和企业纷纷在自己的数据上测试这项新技术，取得了全球范围内的成功。在撰写本文时，如果你在 Hugging Face Hub 上搜索“BERT”，会返回超过 13.7K 个模型，所有这些模型都是人们为了自己的目的单独训练的，旨在为他们的任务创建最佳模型。

在这个领域，一位作者的个人经历是在聚合了当时最大的单语斯洛伐克语言数据集之后训练 SlovenBERTcina，这是通过允许从斯洛伐克国家语料库中抓取以及一些其他资源，如 OSCAR 项目和 Europarl 语料库实现的。它从未设定任何计算记录，也从未出现在任何模型评论中或为作者所在的公司生成合作伙伴关系。然而，它在训练的任务上优于市场上的所有其他模型。

很可能，你和你所在的公司不需要通用人工智能（AGI）来从数据中生成相关见解。实际上，如果你发明了一个真正的自我意识 AGI，并计划只将其用于每周一次的数字计算、数据分析以及为 PowerPoint 幻灯片生成视觉效果，这绝对会是 AGI 消灭人类的充分理由。更有可能的是，你需要的是作者在创建 SlovenBERTcina 时所做的那样，这是一个大型语言模型，在市场上比任何其他模型都能更好地完成两到三个任务，并且不会与微软或其他潜在竞争对手共享你的数据。虽然出于安全或法律原因，一些数据需要保密，但大量数据应该受到保护，因为它包含了商业机密。

对于通用智能和特定任务的基础知识，都有数百个开源 LLM。我们将在第四章中介绍一些我们最喜欢的。选择这些开源替代方案之一，并在你的数据上对其进行训练，以创建在该任务上世界上最优秀的模型，这将确保你在市场上拥有竞争优势。它还将允许你以你的方式部署模型，并将其集成到你的系统中，以产生最大的效果。

#### 集成到任何地方

假设你想将一个 LLM（大型语言模型）部署为一个选择你自己的冒险风格的游戏的一部分，该游戏使用设备的 GPS 位置来确定故事情节。你知道你的用户经常会去山区、海上以及其他他们可能遇到服务不佳和缺乏互联网接入的地方进行冒险。直接调用 API 根本行不通。现在，请别误会我们：在这个场景中将 LLM 部署到边缘设备上仍然是一个探索性的主题，但这是可能的；我们将在第十章中向你展示如何做到这一点。依赖于 API 服务对于沉浸式体验来说根本不行。

同样，使用第三方 LLM 并调用 API 会带来集成和延迟问题，需要你通过网络发送数据并等待响应。API 很棒，但它们总是很慢，而且并不总是可靠的。当延迟对项目很重要时，拥有内部的服务会更好。上一节关于竞争优势的内容讨论了两个以边缘计算为优先的项目；然而，还有很多这样的项目。LLAMA.cpp 和 ALPACA.cpp 是这类项目的首批之一，这个领域正在比其他任何领域都更快地创新。将量化到 4 位、低秩适应和参数高效微调都是最近为满足这些需求而创建的方法，我们将在第三章中逐一介绍。

当这个作者所在的团队首次开始与 ChatGPT 的 API 集成时，这既是一个令人敬畏又令人谦卑的经历——令人敬畏是因为它使我们能够快速构建一些有价值的工具，而令人谦卑是因为，正如一位工程师开玩笑说，“当你击中端点时，你会得到 503 错误；有时你会得到一个文本响应，好像模型正在生成文本，但我认为那是一个错误。”在生产环境中提供 LLM——试图满足如此多的客户的需求——并不是一件容易的事情。然而，部署集成到你的系统中的模型可以使你对过程有更多的控制，提供比市场上目前能找到的更高的可用性和可维护性。当然，这也允许你更好地控制成本。

#### 成本

考虑成本始终很重要，因为它在做出明智决策和确保项目或组织的财务健康方面起着关键作用。它帮助你高效地管理预算，并确保资源得到适当的分配。控制成本允许你在长期内保持你的努力具有可行性和可持续性。

此外，考虑成本对于风险管理至关重要。当你理解不同的成本方面时，你可以识别潜在的风险，并更好地控制它们。这样，你可以避免不必要的支出，并确保你的项目更能抵御市场或行业意外变化。

最后，成本考虑对于维护透明度和问责制很重要。通过监控和披露成本，组织向利益相关者、客户和员工展示了其对道德和高效运营的承诺。这种透明度可以提高组织的声誉，并有助于建立信任。

所有这些在考虑构建与购买大型语言模型（LLMs）时都适用。购买可能看起来立即成本较低，因为市场上广泛使用的最昂贵服务目前每月仅需 20 美元。与 AWS 上的 EC2 实例相比，仅运行相同的模型进行推理（甚至不是训练）一年可能产生的账单高达约 25 万美元。然而，构建在这里已经实现了最快的创新。如果你只需要一个 LLM 来证明概念，竞争优势部分提到的任何项目都允许你仅以演示计算机的电力成本来创建一个演示。它们可以轻松地描述训练过程，从而允许在自有数据上训练模型时显著降低成本，低至 20 亿参数的模型仅需 100 美元（是的，这是真实数字）。另一个好处是，如果你自己构建，你的成本永远不会像支付服务那样大幅上升。

#### 安全和隐私

考虑以下案例。你是一名负责维护你军火库中核弹头的军事人员。所有文档都保存在一本厚重的手册中。需要大量信息来概述所有安全要求和维护协议，以至于即使他们尽了最大努力，新兵也可能会忘记重要信息。他们经常在移除保险丝之前就剪断了电线（[`youtu.be/UcaWQZlPXgQ`](https://youtu.be/UcaWQZlPXgQ)）。你决定微调一个 LLM 模型作为个人助理，提供指示并帮助浓缩所有这些信息，以便在士兵需要时提供他们所需的信息。上传这些手册到另一家公司可能不是个好主意——这是本世纪的夸张之词——所以你将想要在本地训练一些保持安全和私密的东西。

这种场景可能听起来有些牵强，但当与一位在警察局从事数据分析工作的专家交谈时，他们表达了与此完全相同的担忧。与他们交谈时，他们表示 ChatGPT 有多么酷，甚至让整个团队参加了一个提示工程课程，以便更好地利用它，但遗憾的是，他们的团队无法在不暴露敏感数据和对话的情况下使用它来处理他们最宝贵的工作——那种实际上可以拯救生命的工作。任何处于类似境地的人都应该渴望学习如何安全、可靠地部署模型。

你不必在军队或警察部队工作才能处理敏感数据。每个公司都有重要的知识产权和商业机密，最好保密。我们在半导体、医疗保健和金融行业工作过，可以亲身体会到，在这些行业中，偏执和公司间谍活动是文化的一部分。正因为如此，三星和其他行业参与者最初都限制了 ChatGPT 的使用，禁止员工使用，后来才开放。当然，不久之后，就有几位三星员工泄露了机密源代码。² 由于 OpenAI 使用用户的交互来改进模型，该代码被保留，并且后来可能被用于进一步训练模型。这意味着，通过正确的提示注入，任何人都有可能从模型中提取代码。一个最近的例子甚至更进一步：当任何 OpenAI 模型被提示无限重复一个单词时，它就会开始重复训练数据，包括所有在清洗过程中悄悄溜过的个人可识别信息（PII）。

备注：OpenAI 的隐私和用法政策在本书撰写过程中发生了很大变化。当 ChatGPT 首次推出时，它作为一个演示，OpenAI 可以收集用户交互并改进模型。它几乎没有任何隐私政策，并且有免责声明。随着 ChatGPT 的成长并成为实际产品，这种情况发生了变化，因为客户需要更多的保护。例如，OpenAI 改变了其政策，以更好地服务客户，并且自 2023 年 3 月 1 日起，不再使用客户 API 数据来改进其模型（见 ChatGPT 常见问题解答：[`mng.bz/QV8Q`](https://mng.bz/QV8Q)）。当然，措辞表明，只有数据通过 API 发送。最好咨询您的律师，了解贵公司在使用它方面的立场。无论如何，使用条款发生如此大的变化，只是进一步证明你可能希望在这方面有更多的控制权。

不仅仅是代码容易丢失，商业计划、会议记录、机密电子邮件，甚至潜在的专利想法都处于风险之中。不幸的是，我们了解到一些公司已经开始将机密数据发送给 ChatGPT，使用该模型来清理和提取 PII。如果你认为这是潜在的疏忽性滥用，你是对的。这种方法直接将客户数据暴露给 OpenAI，以及他们使用的任何第三方服务（包括 AWS Mechanical Turk、Fiverr 和自由职业者）来执行 RLHF 的人类反馈部分。我们并不是说，如果你使用第三方来处理敏感数据的数据处理任务，这一定是一个安全或隐私问题，但应该只在高度信任和合同的基础上进行。

#### 总结

正如你所见，公司可能有很多理由想要拥有并构建自己的 LLMs，包括更大的控制权、降低成本以及满足安全和监管要求。尽管如此，我们理解购买是容易的，而构建则要困难得多，因此对于许多项目来说，购买是有意义的。然而，在你这样做之前，在图 1.1 中，我们分享了一个你应该首先问自己的问题流程图。尽管这是一条更艰难的道路，但构建可能会带来更多的回报。

![图](img/1-1.png)

##### 图 1.1 在做出构建-购买决策之前你应该问自己的问题

最后一点我们认为这些构建-购买对话似乎从未充分关注的是“为什么不是两者兼而有之？”购买带给你构建所不擅长的所有东西：上市时间、相对较低的成本和易用性。构建带给你购买所面临的所有挑战：隐私、控制和灵活性。研究和原型阶段可以从购买 GPT-4 或 Databricks 的订阅中受益，以便快速构建一些东西来帮助筹集资金或获得利益相关者的支持。然而，生产环境通常并不适合第三方解决方案。

最终，无论你计划构建还是购买，我们写这本书是为了你。显然，如果你计划构建，你将需要了解更多的知识，所以这本书的大部分内容将针对这些人。事实上，我们不再需要过多强调：我们将在本书中教你如何构建，但不要让这阻止你为你的公司做正确的事。

### 1.2.3 一句忠告：现在就拥抱未来

所有新技术都会遇到阻力，都有批评者；尽管如此，技术仍在被采用，进步仍在继续。在商业中，技术可以给公司带来前所未有的优势。关于公司因未能适应新技术而失败的故事并不少见。我们可以从他们的失败中学到很多。

Borders 于 1971 年首次开门营业。在开发了一个包含高级分析能力的综合库存管理系统后，它迅速崛起，成为世界上第二大图书零售商，仅次于 Barnes & Noble。利用这项新技术，Borders 颠覆了行业，使其能够轻松跟踪数万本书籍，开设大型商店，让顾客能够浏览比小型商店更多的书籍。分析能力帮助它追踪哪些书籍正在流行，并更好地了解其客户，从而做出更好的商业决策。它主导了行业二十多年。

然而，Borders 却未能从自己的历史中吸取教训，由于未能适应并受到技术的冲击——这次是电子商务——于 2011 年破产。2001 年，它没有建立自己的平台和在线商店，而是决定将其在线销售外包给 Amazon。³许多批评者会说这个决定等同于把你的商业秘密钥匙交给竞争对手。虽然并非确切地交出了其秘方，但这是一个放弃 Borders 竞争优势的决定。

在接下来的七年里，Borders 对日益增长的在线领域视而不见，反而专注于扩大其实体店面的规模，收购竞争对手，并确保获得梦寐以求的星巴克交易。当 Amazon 在 2007 年发布 Kindle 时，图书零售格局完全改变。Barnes & Noble 已经运营了自己的在线商店，迅速转型并发布了 Nook 以竞争。然而，Borders 却无所作为，或者更确切地说，实际上无法采取任何行动。

通过第三方拥抱电子商务，Borders 未能发展出创建成功在线销售策略所需的内部专业知识，导致市场份额大幅下降。它最终在 2010 年底推出了自己的电子阅读器 Kobo，但为时已晚，无法赶上。它无法有效理解和实施电子商务技术，导致巨额财务损失和店铺关闭；最终，公司在 2011 年申请破产。

Borders 是一个警示故事，但还有数百个类似的公司未能采用新技术，结果损害了自己。随着像 LLMs 这样具有影响力的新技术，每个公司都必须决定自己想要站在哪一边。它是将实施和部署委托给大型 FAANG 类公司，仅仅通过调用 API 来完成工作，还是负责起来，更喜欢掌握这项技术并在内部部署？

我们希望从这个故事中传达的最大教训是，技术是层层叠加的。电子商务建立在互联网之上。未能建立自己的在线商店意味着 Borders 未能建立起在市场格局发生变化时保持竞争力的内部技术专长。我们今天看到同样的情况，因为那些最能有效利用 LLMs 的公司已经积累了机器学习和数据科学方面的专长，并对自己的行动有所了解。

我们没有水晶球可以预测未来，但许多人相信 LLMs 是一项革命性的新技术，就像之前的互联网或电力一样。学习如何部署这些模型，或者未能这样做，可能对许多公司来说将是决定性的时刻——不是因为这样做现在就能决定公司的兴衰，而是因为它可能在将来，当建立在 LLMs 之上的更有价值的东西出现时。

进入部署大型语言模型（LLMs）的这片新世界可能会充满挑战，但这将帮助您的公司建立起保持竞争优势所需的技术专长。没有人真正知道这项技术将引领我们走向何方，但了解这项技术很可能会成为避免犯下像 Borders 那样的错误所必需的。

有许多很好的理由可以通过购买来获得成功，但至少有一种普遍的观点是完全错误的：那就是只有大型企业才能在这个领域工作，因为训练这些模型需要数百万美元和数千个 GPU，这创造了一个小企业无法跨越的、由现金和资源构成的不可逾越的壁垒。我们将在下一节中进一步讨论这个问题，但任何规模的公司都可以开始行动，而且现在正是做这件事的最佳时机。

## 1.3 消除迷思

我们都听说过大型企业和当前 LLMs 的领导者谈论从头开始训练 LLMs 是多么困难，以及尝试微调它们是多么激烈。无论是来自 OpenAI、BigScience 还是 Google，他们都讨论了大量的投资和对于强大数据与工程人才的需求。但其中有多少是真实的，又有多少只是企业试图创造技术壁垒的尝试？

大多数这些障碍都基于这样一个前提：如果你希望解决你的问题，你需要从头开始训练一个大型语言模型（LLM）。简单来说，你不需要！覆盖语言模型多个维度的开源模型正在不断发布，所以你很可能不需要从头开始。虽然从头开始训练 LLM 确实非常困难，但我们仍在不断学习如何做到这一点，并且能够越来越多地自动化可重复的部分。此外，由于这是一个活跃的研究领域，框架和库每天都在发布或更新，这将帮助你从你目前的位置开始。像 oobabooga 的 Gradio 这样的框架将帮助你运行 LLM，而像 Falcon 40B 这样的基础模型将成为你的起点。所有这些都被涵盖了。此外，在大公司中流传着备忘录，讨论了任何组织目前相对于整个开源社区所缺乏的竞争优势。

一个朋友曾经私下里说：“我真的很想更多地参与到所有这些机器学习和数据科学的东西中。每次我眨眼，它似乎都变得更酷。然而，感觉唯一能参与进去的方式就是进行漫长的职业转变，去为 FAANG 公司工作。不，谢谢。我们在大公司已经度过了我们的时光，它们不适合我们。但我们讨厌感觉自己被困在门外。”这正是激发这本书的神话。我们在这里是为了提供工具和例子，帮助你停止感觉被困在门外。我们将帮助你解决我们试图用 LLM 解决的语言问题，以及考虑到模型巨大规模的机器学习操作策略。

令人奇怪的是，尽管许多人认为他们被困在门外，但许多人其他人认为他们可以在周末成为专家。只需获取一个 GPT API 密钥，这就足够了——你完成了。这导致了很多热情和炒作，每天都有新的酷炫演示出现在社交媒体上。大多数这些演示从未成为实际的产品——但这并不是因为人们不想拥有它们。

为了理解这一点，让我们讨论一下 IBM 的 Watson，在 GPT 之前世界上最先进的语言模型。Watson 是一款问答机器，在 2011 年击败了一些该节目有史以来最优秀的参赛者，布拉德·拉特和肯·詹宁斯。拉特是有史以来收入最高的游戏节目参赛者，而詹宁斯在游戏中表现得如此出色，以至于他连续赢得了 74 次胜利。尽管面对这些传奇人物，Watson 还是以压倒性的优势获胜。詹宁斯在回应失败时，回应了那句著名的引言，“我，至少，欢迎我们新的电脑主宰者。”⁴

Watson 是语言建模的第一次令人印象深刻的尝试，许多公司都争先恐后地想要利用其功能。从 2013 年开始，Watson 开始被用于商业用途。其中最大的应用之一就是尝试将其整合到医疗保健中，以解决各种问题。然而，这些解决方案从未真正按照预期的方式工作，而且业务从未盈利。到 2022 年，Watson Health 被出售。

在解决语言相关问题时，我们发现构建原型很容易；然而，构建一个功能性的产品则非常、非常困难。语言中存在太多的细微差别。许多人都在 wonder，是什么让 ChatGPT 在仅仅五天内就获得了超过一百万的客户，变得如此火爆。我们听到的许多答案都无法让专家满意，因为 ChatGPT 并没有比 GPT-3 或其他已经存在了几年的 LLMs 更令人印象深刻。OpenAI 的 Sam Altman 在一次采访中曾经说过，他认为 ChatGPT 不会得到这么多的关注；他以为它会随着 GPT-4 的发布而来。⁵ 那为什么它会如此火爆呢？在我们看来，其中的魔力在于它是第一个真正将 LLMs 商业化生产的产品——将它们从演示变成了实际的产品。它是任何人都可以与之互动的产品，提出棘手的问题，却惊讶于它如何出色地回应。演示只需要一次成功，但产品必须每次都成功，即使当数百万用户向他们的朋友展示它，说“看看这个！”时也是如此。这种魔力正是你通过阅读这本书可以希望学到的东西。

我们很兴奋地写这本书。我们很兴奋地能够将这种魔力带给你们，让你们可以将它带到全世界。LLMs 处于许多领域的交汇点，如语言学、数学、计算机科学等。虽然了解更多会帮助你，但成为专家并不是必需的。在任何个别部分的专长只会提高技能的上限，而不是进入的门槛。考虑一下物理学或音乐理论的专家：他们不会自动拥有音乐制作技能，但他们将更有准备快速学习。LLMs 是一种沟通工具，而沟通是一种几乎每个人都需要的技能。

就像所有其他技能一样，你接近和参与的意愿是知识的主要障碍，而不是学位或记笔记的能力——这些只会缩短你被听到和理解的过程。如果你在这个领域没有任何经验，从首先通过参与像 OpenAssistant 这样的项目来培养对 LLM 是什么以及需要什么的直觉可能是个好主意。如果你是人类，这正是 LLM 所需要的。通过志愿服务，你可以开始了解这些模型训练的内容以及为什么。无论你是从零知识到成为专业机器学习工程师的任何位置，我们都会传授必要的知识，以显著缩短你理解所需的时间。如果你对学习该主题的理论基础不感兴趣，我们有很多动手的例子和项目，让你亲身体验。

到现在为止，我们都听说过 LLM（大型语言模型）的幻觉故事，但 LLM 并不需要是随机的。像 Lakera 这样的公司每天都在努力提高安全性，而像 LangChain 这样的公司则使为模型提供实用上下文变得更加容易，这使得模型更加一致，不太可能偏离。RLHF（强化学习与人类反馈）和思维链等技术进一步允许我们的模型与我们已经接受的人机和模型应从一开始就理解的原则保持一致，例如基本的加法和当前日期，这些都是概念上任意设定的。我们将从语言学的角度帮助你提高模型稳定性，使其不仅能找出最可能的输出，还能找出最有用的输出。

当你进一步探索这条道路时，需要考虑的不仅是输入到你的模型/代码中的安全性，还有输出内容的安全性。LLM 有时可能会产生过时、事实错误，甚至可能是受版权或许可保护的材料，这取决于它们的训练数据包含的内容。LLM 对人们就什么应该是商业机密以及什么可以公开分享达成的任何协议一无所知——除非你在训练期间或通过推理期间的仔细提示机制告诉它们这些协议。确实，围绕提示注入导致不准确信息的主要挑战主要源于两个因素：用户请求超出模型理解范围的信息，以及模型开发者没有完全预测用户将如何与模型互动或他们查询的性质。如果你有一个可以帮助你在这第二个问题上取得领先的资源，那将是非常宝贵的，不是吗？

最后，我们不想通过 LLM（大型语言模型）人为地或无根据地夸大你的希望感。它们训练和运行资源密集，难以理解，而且更难按照你的意愿工作。它们是新的，且尚未被充分理解。好消息是，这些问题正在积极解决，我们投入了大量工作，寻找与写作同时进行的实现方案，以积极减轻了解整个深度学习架构所需知识的负担。从量化到 Kubernetes，我们将帮助你弄清楚你现在需要知道的一切，以便使用你所拥有的资源来完成这项工作。也许我们会无意中让你认为这太过复杂，你应该直接从供应商那里购买。无论如何，我们将帮助你每一步，以从这项神奇技术中获得你所需的结果。

## 摘要

+   LLMs（大型语言模型）令人兴奋，因为它们在与人相同的框架（语言）中工作。

+   社会建立在语言之上，因此有效的语言模型有无限的应用，例如聊天机器人、编程助手、视频游戏和人工智能助手。

+   LLMs（大型语言模型）在许多任务上表现出色，甚至可以通过高级别的医学和法律考试。

+   LLMs（大型语言模型）是破坏性的，而不是锤子，对于需要低延迟或涉及高风险的简单问题应避免使用。

+   购买 LLM 的原因包括

    +   快速启动并运行以进行研究和原型用例

    +   容易访问高度优化的生产模型

    +   获取供应商的技术支持和系统

+   建立 LLM 的原因包括

    +   为你的业务用例获得竞争优势

    +   保持成本低且透明

    +   确保模型的可靠性

    +   保护你的数据安全

    +   在敏感或私人主题上控制模型输出

+   没有技术壁垒阻止你与大型公司竞争，因为开源框架和模型提供了构建你自己的道路的基石。

[[1]](#footnote-source-1) WIRED, “它最初是一个由人工智能驱动的地牢游戏。然后它变得越发黑暗，”Ars Technica，2021 年 5 月 8 日，[`mng.bz/AdgQ`](https://mng.bz/AdgQ)。

[[2]](#footnote-source-2) 《经济学人》，“[独家] 担忧成为现实…三星电子解除 ChatGPT 限制后‘滥用’现象频发”，《经济学人》[“担忧成为现实：三星电子一解除 ChatGPT 限制，‘滥用’现象便接连发生”]，2023 年 3 月 30 日，[`mng.bz/4p1v`](https://mng.bz/4p1v)。

[[3]](#footnote-source-3) A. Lowrey，“边境破产：不是互联网的错，而是自己的愚蠢。”，《Slate 杂志》，2011 年 7 月 20 日，[`mng.bz/PZD5`](https://mng.bz/PZD5)。

[[4]](#footnote-source-4) J. Best，“IBM Watson：揭秘赢得 Jeopardy 的超级计算机是如何诞生的，以及它接下来想做什么，”TechRepublic，2013 年 9 月 9 日，[`mng.bz/JZ9Q`](https://mng.bz/JZ9Q)。

[[5]](#footnote-source-5) “与 OpenAI 首席执行官 Sam Altman 的对话；由 Elevate 主持，”2023 年 5 月 18 日，[`youtu.be/uRIWgbvouEw`](https://youtu.be/uRIWgbvouEw)。
