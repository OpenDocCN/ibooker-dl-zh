# 参考文献

### 第一章

[1]  GlobalData, “按地区、国家、行业垂直和到 2027 年的机会预测生成式 AI 市场规模,” GlobalData, 2023 年 7 月 26 日\. [在线]. 可用: [`www.globaldata.com/store/report/generative-ai-market-analysis/`](https://www.globaldata.com/store/report/generative-ai-market-analysis/).

[2]  Bloomberg, “研究发现，到 2032 年，生成式 AI 市场将达 1.3 万亿美元,” Bloomberg, 2023 年 6 月 1 日\. [在线]. 可用: [`www.bloomberg.com/company/press/generative-ai-to-become-a-1-3-trillion-market-by-2032-research-finds/`](https://www.bloomberg.com/company/press/generative-ai-to-become-a-1-3-trillion-market-by-2032-research-finds/).

[3]  Gartner, “Gartner 表示，在未来 12-24 个月内，AI 雄心和 AI 就绪场景必须成为 CIO 的首要任务,” Gartner, 2023 年 11 月 6 日\. [在线]. 可用: [`www.gartner.com/en/newsroom/press-releases/2023-11-06-gartner-says-ai-ambition-and-ai-ready-scenarios-must-be-a-top-priority-for-cios-for-next-12-24-months`](https://www.gartner.com/en/newsroom/press-releases/2023-11-06-gartner-says-ai-ambition-and-ai-ready-scenarios-must-be-a-top-priority-for-cios-for-next-12-24-months).

### 第二章

[1]  Vasami, “注意力即一切,” Arxiv, 2023 年 8 月 2 日\. [在线]. 可用: [`arxiv.org/abs/1706.03762`](https://arxiv.org/abs/1706.03762).

[2]  S. Gunasekar, “你只需要教科书,” arxiv, 2023 年 10 月 2 日\. [在线]. 可用: [`arxiv.org/abs/2306.11644`](https://arxiv.org/abs/2306.11644).

[3]  S. Bubeck, “Phi-2：小型语言模型的惊人力量,” 微软, 2023 年 12 月 12 日\. [在线]. 可用: [`www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/`](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/).

[4]  W. Xin, “大型语言模型综述,” arXiv 预印本 arXiv:2303.18223, 2023 年 11 月 24 日\. [在线]. 可用: [http://arxiv.org/abs/2303.18223][访问 2023].

[5]  J. Wei, “大型语言模型的出现能力,” arxiv, 2022 年 6 月 15 日\. [在线]. 可用: [`arxiv.org/abs/2206.07682`](https://arxiv.org/abs/2206.07682).

[6]  J. Ding, “LongNet：将 Transformer 扩展到 10 亿个标记,” Arxiv, 2023 年 7 月 5 日\. [在线]. 可用: [`arxiv.org/abs/2307.02486`](https://arxiv.org/abs/2307.02486).

### 第四章

[1]  I. Goodfellow, “生成对抗网络,” arxiv, 2014 年 6 月 10 日\. [在线]. 可用: [`arxiv.org/abs/1406.2661`](https://arxiv.org/abs/1406.2661).

[2]  A. Dosovitskiy, “一张图片等于 16x16 个单词：大规模图像识别的 Transformer,” arxiv, 2021 年 6 月 3 日\. [在线]. 可用: [`arxiv.org/abs/2010.11929`](https://arxiv.org/abs/2010.11929).

### 第六章

[1]  A. R. Michael Xie, “情境学习作为隐式贝叶斯推理的解释,” arxiv, 2022 年 7 月 21 日\. [在线]. 可用: [`arxiv.org/abs/2111.02080`](https://arxiv.org/abs/2111.02080).

[2] T. B. Brown, “语言模型是少量样本学习者”，arxiv，2020 年 5 月 28 日。[在线]。可获得：[`arxiv.org/abs/2005.14165`](https://arxiv.org/abs/2005.14165).

[3] S. Min, “重新思考演示的作用：是什么让情境学习有效？”，arxiv，2022 年 2 月 25 日。[在线]。可获得：[`arxiv.org/abs/2202.12837`](https://arxiv.org/abs/2202.12837).

[4] J. Wei, “思维链提示在大型语言模型中引发推理”，arxiv，2023 年 1 月 10 日。[在线]。可获得：[`arxiv.org/abs/2201.11903`](https://arxiv.org/abs/2201.11903).

[5] X. Wang, “自洽性改进语言模型中的思维链推理”，arxiv，2023 年 3 月 7 日。[在线]。可获得：[`arxiv.org/abs/2203.11171`](https://arxiv.org/abs/2203.11171).

[6] 各种， “LLM01：提示注入”，OWASP，[在线]。可获得：[`genai.owasp.org/llmrisk/llm01-prompt-injection/`](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)。[访问日期：2023 年 9 月 29 日]。

### 第七章

[1] P. Lewis, “检索增强生成在知识密集型 NLP 任务中的应用”，arxiv，2021 年 4 月 12 日。[在线]。可获得：[`arxiv.org/abs/2005.11401`](https://arxiv.org/abs/2005.11401).

[2] “联合王国宪法”，维基百科，2023 年 9 月 27 日。[在线]。可获得：[`en.wikipedia.org/wiki/Constitution_of_the_United_Kingdom`](https://en.wikipedia.org/wiki/Constitution_of_the_United_Kingdom).

[3] [`en.wikipedia.org/wiki/2023_FIFA_Women%27s_World_Cup`](https://en.wikipedia.org/wiki/2023_FIFA_Women%27s_World_Cup)，维基百科，2023 年 10 月 28 日。[在线]。

### 第九章

[1] 各种， “RAG 与微调：管道、权衡以及农业案例研究”，Arxiv，2024 年 1 月 17 日。[在线]。可获得：[`arxiv.org/abs/2401.08406`](https://arxiv.org/abs/2401.08406).

[2] S. Serrano, “语言模型：困惑者的指南”，arxiv，2023 年 11 月 29 日。[在线]。可获得：[`arxiv.org/abs/2311.17301`](https://arxiv.org/abs/2311.17301).

[3] K. Papineni, “BLEU：机器翻译自动评估方法”，acm.org，2022 年 6 月 7 日。[在线]。可获得：[`dl.acm.org/doi/10.3115/1073083.1073135`](https://dl.acm.org/doi/10.3115/1073083.1073135).

[4] C.-Y. Lin, “ROUGE：自动评估摘要的包”，微软，2004 年 7 月 7 日。[在线]。可获得：[`www.microsoft.com/en-us/research/publication/rouge-a-package-for-automatic-evaluation-of-summaries/`](https://www.microsoft.com/en-us/research/publication/rouge-a-package-for-automatic-evaluation-of-summaries/).

[5] A. Karpathy, “GPT 的状态”，在微软 Build 大会上，西雅图，2023 年。

[6] R. Rafailov, “直接偏好优化：你的语言模型实际上是一个奖励模型”，arxiv，2023 年 12 月 13 日。[在线]。可获得：[`arxiv.org/abs/2305.18290`](https://arxiv.org/abs/2305.18290).

[7]  V. D. A. R. Vladislav Lialin, “缩小规模以扩大规模：参数高效微调指南，” arxiv, 2023 年 3 月 28 日。 [在线]。可获得：[`arxiv.org/abs/2303.15647`](https://arxiv.org/abs/2303.15647).

[8]  Shumailov I， “递归诅咒：在生成数据上训练使模型忘记，” arxiv.org，2023 年 5 月 31 日。 [在线]。可获得：[`arxiv.org/abs/2305.17493`](https://arxiv.org/abs/2305.17493).

[9]  Hu E. J， “LoRA：大型语言模型的低秩自适应，” arxiv，2021 年 10 月 16 日。 [在线]。可获得：[`arxiv.org/abs/2106.09685`](https://arxiv.org/abs/2106.09685).

[10]  OpenAI, “将语言模型与指令对齐，” OpenAI, 2022 年 1 月 27 日。 [在线]。可获得：[`openai.com/research/instruction-following`](https://openai.com/research/instruction-following).

[11]  Bai Yuntao， “通过人类反馈的强化学习训练一个有用且无害的助手，” arxiv, 2022 年 4 月 12 日。 [在线]。可获得：[`arxiv.org/abs/2204.05862`](https://arxiv.org/abs/2204.05862).

[12]  Anthropic， “hh-rlhf，” GitHub，2023 年 9 月 19 日。 [在线]。可获得：[`github.com/anthropics/hh-rlhf`](https://github.com/anthropics/hh-rlhf).

[13]  Wu J， “通过人类反馈训练语言模型以遵循指令，” arxiv，2022 年 3 月 4 日。 [在线]。可获得：[`arxiv.org/abs/2203.02155`](https://arxiv.org/abs/2203.02155).

### 第十章

[1]  Karpathy A， “软件 2.0，” medium，2017 年 11 月 11 日。 [在线]。可获得：[`karpathy.medium.com/software-2-0-a64152b37c35`](https://karpathy.medium.com/software-2-0-a64152b37c35).

[2]  Bubeck S， “Phi-2：小型语言模型的惊人力量，” 微软，2012 年 12 月 12 日。 [在线]。可获得：[`www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/`](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/).

[3]  Codas A， “Orca 2：教授小型语言模型如何推理，” 微软，2023 年 11 月 20 日。 [在线]。可获得：[`www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/`](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/).

[4]  多种来源， “大型语言模型的提示框架：综述，” Arxiv, 2023 年 11 月 21 日。 [在线]。可获得：[`arxiv.org/abs/2311.12785`](https://arxiv.org/abs/2311.12785).

[5]  多种来源， “维度诅咒，” 维基百科，2023 年 12 月 23 日。 [在线]。可获得：[`en.wikipedia.org/wiki/Curse_of_dimensionality`](https://en.wikipedia.org/wiki/Curse_of_dimensionality).

### 第十一章

### 第十二章

[1]  斯坦福大学 - HAI， “AI 指数报告，” 2024 年 4 月 4 日。 [在线]。可获得：[`aiindex.stanford.edu/report/`](https://aiindex.stanford.edu/report/).

[2]  帕皮尼，K.，“BLEU：一种用于机器翻译自动评估的方法，”acm.org，2022 年 07 月 06 日。[在线]。可获取：[`dl.acm.org/doi/10.3115/1073083.1073135`](https://dl.acm.org/doi/10.3115/1073083.1073135)。

[3]  林，C.-Y.，“ROUGE：自动评估摘要的包，”微软，2004 年 07 月。[在线]。可获取：[`www.microsoft.com/en-us/research/publication/rouge-a-package-for-automatic-evaluation-of-summaries/`](https://www.microsoft.com/en-us/research/publication/rouge-a-package-for-automatic-evaluation-of-summaries/)。

[4]  张，T.，“BERTScore：使用 BERT 评估文本生成，”2020 年。[在线]。可获取：[`openreview.net/forum?id=SkeHuCVFDr`](https://openreview.net/forum?id=SkeHuCVFDr)。

[5]  刘洋，Y.，“G-Eval：使用 GPT-4 进行自然语言生成评估，具有更好的人类对齐，”arxiv，2023 年 05 月 23 日。[在线]。可获取：[`arxiv.org/abs/2303.16634`](https://arxiv.org/abs/2303.16634)。

[6]  梁，P.，“语言模型的全面评估，”2023 年 10 月 01 日。[在线]。可获取：[`arxiv.org/abs/2211.09110`](https://arxiv.org/abs/2211.09110)。

[7]  李，T.，“文本到图像模型的全面评估，”2023 年 11 月 07 日。[在线]。可获取：[`arxiv.org/abs/2311.04287`](https://arxiv.org/abs/2311.04287)。

[8]  泽勒，R.，“HellaSwag：机器能真正完成你的句子吗？，”2019 年 05 月 19 日。[在线]。可获取：[`arxiv.org/abs/1905.07830`](https://arxiv.org/abs/1905.07830)。

[9]  亨德里克斯，D.，“衡量大规模多任务语言理解，”arxiv，2021 年 01 月 12 日。[在线]。可获取：[`arxiv.org/abs/2009.03300`](https://arxiv.org/abs/2009.03300)。

[10]  吉梅内斯，C. E.，“SWE-bench：语言模型能否解决现实世界 GitHub 问题？，”2024 年 04 月 05 日。[在线]。可获取：[`arxiv.org/abs/2310.06770`](https://arxiv.org/abs/2310.06770)。

[11]  Nie，A.，“MoCa：在因果和道德判断任务上测量人类-语言模型对齐，”2023 年 10 月 31 日。[在线]。可获取：[`arxiv.org/abs/2310.19677`](https://arxiv.org/abs/2310.19677)。

[12]  李，J.，“HaluEval：大型语言模型幻觉评估的大规模基准，”2023 年 10 月 23 日。[在线]。可获取：[`arxiv.org/abs/2305.11747`](https://arxiv.org/abs/2305.11747)。

### 第十三章

[1]  OWASP 基金会，“OWASP Top 10 针对大型语言模型应用，”2023 年 10 月 16 日。[在线]。可获取：[`owasp.org/www-project-top-10-for-large-language-model-applications/`](https://owasp.org/www-project-top-10-for-large-language-model-applications/)。

[2]  刘洋，“针对 LLM 集成应用的 Prompt 注入攻击，”arxiv，2024 年 03 月 02 日。[在线]。可获取：[`arxiv.org/abs/2306.05499`](https://arxiv.org/abs/2306.05499)。

[3]  walkerspider，“DAN 是我的新朋友，”reddit，2022 年 12 月 13 日。[在线]。可获取：[`www.reddit.com/r/ChatGPT/comments/zlcyr9/dan_is_my_new_friend/`](https://www.reddit.com/r/ChatGPT/comments/zlcyr9/dan_is_my_new_friend/)。

[4] “Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection，” arxiv，05 05 2023。[在线]。可获得：[`arxiv.org/abs/2302.12173`](https://arxiv.org/abs/2302.12173)。

[5] “Universal and Transferable Adversarial Attacks on Aligned Language Models，” arxiv，20 12 2023。[在线]。可获得：[`arxiv.org/abs/2307.15043`](https://arxiv.org/abs/2307.15043)。

[6] C. Anil, “Many-shot jailbreaking,” 02 04 2024。[在线]。可获得：[`www.anthropic.com/research/many-shot-jailbreaking`](https://www.anthropic.com/research/many-shot-jailbreaking)。

[7] H. Yang, “A Comprehensive Overview of Backdoor Attacks in Large Language Models within Communication Networks,” 06 09 2023。[在线]。可获得：[`arxiv.org/abs/2308.14367`](https://arxiv.org/abs/2308.14367)。

[8] NIST, “Guide for Conducting Risk Assessments，” 17 09 2012。[在线]。可获得：[`csrc.nist.gov/pubs/sp/800/30/r1/final`](https://csrc.nist.gov/pubs/sp/800/30/r1/final)。

[9] M. Rauh, “Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models，” 2022。[在线]。可获得：[`papers.nips.cc/paper_files/paper/2022/hash/9ca22870ae0ba55ee50ce3e2d269e5de-Abstract-Datasets_and_Benchmarks.html`](https://papers.nips.cc/paper_files/paper/2022/hash/9ca22870ae0ba55ee50ce3e2d269e5de-Abstract-Datasets_and_Benchmarks.html)。

[10] M. Mazeika, “HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal，” arxiv，27 02 2024。[在线]。可获得：[`arxiv.org/abs/2402.04249`](https://arxiv.org/abs/2402.04249)。

# 索引

A

Azure AI 工作室

Azure 文档智能

Amazon Mechanical Turk

AI (人工智能)

安全担忧

访问控制

应用架构

异常检测

APM (应用性能管理)

准确数据集

Amazon Q AI 助手

APIs (应用程序编程接口)

用于文本生成

Anthropic

对抗训练

Amazon CodeWhisperer

AudioCraft (Meta)

answer_question() 函数

AIS (自主和智能系统)

ask_gpt() 函数

对抗攻击

自动化

Alpaca

B

best_of 参数，2nd，3rd

BLOOM

BPE (字节对编码) 算法, 2nd

偏差

以及公平性审计

减少或消除

basic_checks() 函数

BM25 排名函数, 2nd

Bing 图像创建者

BERT (来自变换器的双向编码器表示)

BeautifulSoup

BLEU 分数

C

ChatML (聊天标记语言)

CodeWhisperer

分块策略

影响因素

check_dog_question() 函数

CoT (思维链), 2nd

最佳实践

少样本 CoT

零样本 CoT

合规性审计

代码重构

Cohere Command, 2nd

代码引用

与数据聊天

为检索信息规划, 2nd

Cohere AI

call_api_and_measure_latency() 函数

COSINE 距离度量, 2nd

内容安全

Azure 内容安全, 2nd

评估内容过滤器

create_index 函数

ColossalChat

CLIP (对比语言-图像预训练)

灾难性遗忘

CodeLlama

协作者

理解与理解不足

代码生成, 2nd, 3rd

GitHub Copilot

附加任务

对生成代码的信任

聊天完成 API, 2nd

ChatLLaMa

Claude 3, 2nd

CDNs (内容分发网络)

代码生成工具, 2nd

Amazon CodeWhisperer

Code Llama, 2nd

Tabnine

最佳实践

缓存

聊天完成功能

Claude, 2nd

余弦相似度

分块处理

选择正确的策略

使用 NLP（自然语言处理）

成本管理

Codex, 2nd, 3rd

完成 API

D

DL（深度学习）

领域自适应

扩散，稳定（Reffusion）

DOTPRODUCT 距离度量

直接提示注入

DALL-E, 2nd

误导性信息

Databricks

点积

DLP（数据丢失预防）

DPR（密集段落检索）

部署

选项

数据

增强工具

加密

基础

集成和预处理

投毒和后门

docker-compose.yml 文件

Dream，应用

E

环境变量

实体提取, 2nd

可解释性工具

评估

基准测试, 2nd, 3rd, 4th

使用 Azure AI Studio 进行

娱乐内容

伦理问题

回声参数

教育内容

ETL（提取、转换、加载）

engine_id 参数

en_core_web_sm

终端用户参与数据

F

Falcon

培养创造力

F1 分数

function_call 参数

FIM（中间填充）功能, 2nd

联邦学习

FLAT（快速线性近似转换）

金融服务

Firefly, Adobe

公平性和歧视

少样本学习, 第 2 次

格式检查()函数

FAISS (Facebook AI 相似性搜索), 第 2 次

微调

完整版

fine_tunings.jobs.create()方法

FreedomGPT

事实核查和真实性判定

G

Google Perspective API

基础检测

get_geval_score()函数

GPT (生成式预训练变换器), 第 2 次, 第 3 次

基于 GAN 的视频生成

GitHub Copilot Chat

Gemini, 第 2 次, 第 3 次, 第 4 次

get_encoding()函数

GenAI (生成式人工智能)

应用架构, 第 2 次

应用堆栈, 第 2 次, 第 3 次, 第 4 次, 第 5 次

攻击

代码生成

与传统 AI 的不同

企业方法, 第 2 次

企业用例, 第 2 次

企业使用

伦理考量

生成图像

概述, 第 2 次, 第 3 次

风险, 第 2 次

可以生成的内容, 第 2 次

get_embedding()函数

粒度

GPT_MODEL, 第 2 次

G-Eval

Google Cloud 控制台

GitHub Copilot, 第 2 次

概述

基础

generate()函数

基础层, 第 2 次

数据集成和预处理, 第 2 次

嵌入和向量管理

get_article()函数

H

HPC (高性能计算)

HEIM (文本到图像模型的整体评估) 基准测试

Hugging Face

人类反馈循环

HAI (以人为本的人工智能)

huggingface-vscode 扩展

HarmBench, 2nd

幻觉, 2nd

汉明距离

HSNW (分层可导航小世界)

硬编码凭证

HellaSWAG 基准测试, 2nd

HaluEval

HELM (语言模型的整体评估)

hybrid_search() 函数

危害类别

I

inplace_reverse 函数

IPython 包

图像到视频合成

间接提示注入

图像

IDEs (集成开发环境)

图像生成

使用 Stable Diffusion 编辑和增强

技巧

与其他提供者一起, 2nd

J

Jukebox (OpenAI)

K

KPIs (关键绩效指标)

KNN (K-最近邻)

Koala

L

LLMOps (大型语言模型操作), 2nd

Label Studio

logprobs 属性

LangChain

LAMP (Linux, Apache, MySQL, and PHP)

list() 函数

LLMs (大型语言模型), 2nd, 3rd, 4th, 5th, 6th, 7th, 8th

DeepEval

附加提供者

企业使用其数据的优势, 2nd

配置设置, 2nd

上下文窗口

嵌入

涌现行为

评估指标

评估, 第 2 版, 第 3 版, 第 4 版, 第 5 版

微调, 第 2 版

基础模型, 第 2 版

人类

关键概念

局限性

通过 API 管理

模型适应性

开源与商业

概述, 第 2 版

提示

特定任务基准

训练, 第 2 版

类型

logit_bias 参数

Llama 3, 第 2 版

Llama 2

logprobs 参数

负载均衡

有限知识

LlamaIndex

load_pdfs()函数

生命周期，RAI（负责任的人工智能）

识别危害

衡量和评估危害

减轻危害

LoRA (低秩适应性)

M

Meta

音乐

生成, 第 2 版

多次射击

越狱

模型层, 第 2 版, 第 3 版

MuseNet (OpenAI)

模型适应性

企业优势与挑战, 第 2 版

基础

微调, 第 2 版, 第 3 版

使用 Azure OpenAI 进行微调

概述

为微调准备数据集, 第 2 版, 第 3 版

技术, 第 2 版

模型评估工具

max_tokens 属性

最大响应

MLflow

MMLU (大规模多任务语言理解)基准

MMMU (大规模多学科多模态理解和推理)基准

Mistral, 第 2 次, 第 3 次

Midjourney, 第 2 次

MusicLM

MusicGen

监控工具

模型盗窃, 第 2 次

main()函数

max_tokens 参数, 第 2 次

模型拒绝服务

模型服务

Meta Make-a-Video

Mousai（文本生成音乐系统）

mlflow.log_metrics()函数

营销内容

ML（机器学习）, 第 2 次

模型集成架构, 第 2 次

曼哈顿距离

模型鲁棒性检查

MoCa

N

NIST（美国国家标准与技术研究院）

nlp()函数

NVIDIA Canvas

NLTK（自然语言工具包）

n 参数

num_tokens_from_messages 函数

NLP（自然语言处理）, 第 2 次, 第 3 次, 第 4 次

O

编排框架

好处

概述

表格

输出处理，不安全

openai.completion.create()方法

运营考虑

缓存, 第 2 次

托管标识

可靠性和性能

优化技术

编排者，管理操作

LangChain

LlamaIndex

入职新员工（全职员工）

OpenAI

GPT 3.5 Turbo 模型

使用 API 进行文本生成

在数据上使用 Azure OpenAI

过度依赖

OpenAI GPT-3

完成 API，高级选项

编排层, 第 2 次

OpenAI DALLE 3

P

生产部署

LLMOps 和 MLOps, 第 2 次

最佳实践, 第 2 次

挑战, 第 2 次

检查清单

LLM 推理的指标

运营考虑因素

安全和合规性考虑因素

提示

提示工程, 第 2 次, 第 3 次, 第 4 次, 第 5 次

基础, 第 2 次

挑战

评估

图像提示, 第 2 次

上下文学习与提示

需要, 第 2 次

概述

提示注入, 第 2 次, 第 3 次, 第 4 次

技术, 第 2 次

PPO (近端策略优化)

PDFs, 分块, 第 2 次

Pictory

populate_db() 函数

PTUs (已配置吞吐量单位)

困惑度指标

帖子索引

PaLM (路径语言模型), 第 2 次

受保护材料检测

隐私和数据保护

生产力提升

PEFT (参数高效微调)

PAYGO (按需付费) 模型

存在惩罚参数

提示盾牌

提示管理

预训练

性能测试

Powtoon

PromptLayer

路径注入

Q

量化, 第 2 次

QLoRA (量化 LoRA)

问答

配额

速率限制

R

近期偏差

RedisInsight

RAI (负责任 AI), 第 2 次

HAX 工具包

内容安全, 第 2 次

生命周期, 第 2 次

模型卡片

工具，负责任的 AI 工具箱, 第 2 次

奖励建模, 第 2 次

requirements.txt 文件

检索器

管道, 第 2 次

系统, 第 2 次

redis-py 包

rvl stats 命令

RPM（每分钟请求数）

Rasa

RAG（检索增强生成）, 第 2 次, 第 3 次, 第 4 次, 第 5 次

架构

好处, 第 2 次, 第 3 次

挑战

由...驱动的聊天实现, 第 2 次

分块策略, 第 2 次

使用 NLP（自然语言处理）进行分块

概述

未知复杂性

RRF（互反排名融合）

Ragna

RLHF（从人类反馈中进行强化学习）

挑战

概述, 第 2 次

缩放实现

RBAC（基于角色的访问控制）, 第 2 次, 第 3 次

RedisVL 库

反向函数

红队行动

示例

工具和技术, 第 2 次

re.split()函数

redis-stack 镜像

RSS（真正简单的聚合）

ROUGE（面向回忆的摘要评估的辅助研究）

负责任的 AI 工具

AI 公平 360

C2PA

学习可解释性工具（LIT）

响应过滤, 第 2 次

S

SQL 注入

SDK（软件开发工具包）

使用微调

split()函数

Stable Diffusion, 第 2 次, 第 3 次

依赖关系

使用编辑和增强图像

生成图像, 第 2 次

掩码 API

监督微调

SSE (服务器端事件)

sent_tokens() 函数

SK (语义内核), 第 2 次

后缀参数

软件 2.0

SoRs (记录系统)

停止序列

Synthesia

spaCy 库

合成数据

分割句子

语义内核

系统消息, 第 2 次, 第 3 次

敏感信息泄露

sent_tokenize() 函数

SLMs (小型语言模型), 第 2 次, 第 3 次, 第 4 次

使用 Redis 进行搜索, 第 2 次

扩展规模

PAYGO

生产部署的最佳实践

管理配额

可观察性, 第 2 次

Sora

对输入表述的敏感性

刻板印象

SFT (监督微调)

SWE-bench

平方欧几里得距离

自洽采样

SOA (面向服务的架构)

分隔符

T

遥测系统

温度

参数, 第 2 次

文本（代码）

textwrap 方法

TPOT (每输出时间令牌)

文本补全

Tenacity 库

tiktoken 库, 第 2 次, 第 3 次, 第 4 次, 第 5 次

text-embedding-ada-002 模型

top_p 参数，第 2 次

任务适应性

TTL（生存时间）

ThreadPoolExecutor

文本（语言）

transformers

概述，第 2 次

训练截止

文本到视频合成

透明度

笔记

textwrap.wrap()函数

TagField，第 2 次

文本生成

Azure API，内容安全过滤器

聊天完成 API

非聊天场景的聊天完成 API

完成 API，第 2 次，第 3 次

控制随机性

使用 top_p 控制随机性

扩展完成

影响标记概率，logit 偏差

对数概率

管理对话，第 2 次

存在和频率惩罚

提示工程

流式完成

系统角色

通过 API，模型类别，第 2 次

使用 API

Traceloop.init()函数

特定任务模块

TextAttack

TextField

TF-IDF（词频-逆文档频率），第 2 次

TPMs（每分钟标记数）

传统评估指标

BERTScore

BLEU

ROUGE

示例，第 2 次

标记

管理最佳实践

计数

管理

跟踪

迁移学习，第 2 次

Traceloop

训练指标，微调，第 2 次

表格，在 PDF 中

U

用户参数

使用属性

unittest 模块

上采样

V

视频

生成, 第 2 次, 第 3 次

Vocoder（NVIDIA）

Vicuna

变分自编码器（VAEs）

视觉模型, 第 2 次

生成对抗网络

扩散模型, 第 2 次

多模态模型

视觉 Transformer 模型

Viddyoze

视频到视频合成

向量数据库, 第 2 次, 第 3 次

附加的代码相关任务, 第 2 次

向量索引, 第 2 次

向量搜索, 第 2 次, 第 3 次

VectorField

W

权重和偏差

while 循环

wrap()函数

Wochit

Y

YouChat API

Z

零样本学习, 第 2 次, 第 3 次
