# 第十二章\. 人工智能服务分发

这项工作使用 AI 进行翻译。我们很高兴收到你的反馈和评论：translation-feedback@oreilly.com

在本章的最后一章，是时候完成你的 GenAI 解决方案并通过分发来实现。Go 将学习多种分发策略，作为分发的一部分，它将遵循最佳实践使用 Docker 来容器化其服务。

# 分发选项

现在你有一个正在运行的 GenAI 服务，你想要使其对你的用户可用。有哪些分发选项？有一些常见的分发策略你可以适应，以使你的应用程序对用户可用：

+   虚拟机（VM）

+   无服务器功能

+   管理应用程序平台

+   容器化

我们将更详细地分析每一个。

## 虚拟机上的分发

如果你打算使用你的本地服务器，或者更愿意将你的服务部署在同一硬件上，以获得高隔离性和安全性，你可以将你的 GenAI 服务部署在一个虚拟机（VM）中。

虚拟机是物理计算机的软件模拟，它运行操作系统（OS）和应用程序。它并不像笔记本电脑、智能手机或服务器这样的物理计算机。

虚拟机的 *宿主* 系统提供 CPU、内存和存储等资源，而一个名为 *虚拟机管理程序* 的软件层管理虚拟机，并将资源从宿主机分配到虚拟机。虚拟机管理程序分配给虚拟机的资源是操作系统和应用程序运行的 *虚拟硬件*。

虚拟机可以直接在宿主机的硬件上运行（裸金属）或在一个常规操作系统（即托管）上运行。因此，虚拟机内部安装的操作系统被称为 *客户操作系统*。

图 12-1 展示了虚拟化技术的系统架构。

![bgai 1201](img/bgai_1201.png)

###### 图 12-1\. 虚拟化系统架构

云服务提供商或你的数据中心可能由多个物理服务器组成，每个服务器都托管多个虚拟机，每个虚拟机都有自己的客户操作系统和托管的应用程序。为了在成本方面有效共享资源，这些虚拟机可以共享同一个物理存储单元，即使它们被完全隔离的环境所包含，如图 12-2 所示。

![bgai 1202](img/bgai_1202.png)

###### 图 12-2\. 数据中心中的虚拟机

使用虚拟机的优势在于，你可以直接访问客户操作系统、虚拟硬件资源和 GPU 驱动器。如果实施过程中出现问题，你可以通过*Secure Shell Transfer*（SSH）协议连接到虚拟机，检查应用程序日志、设置应用程序环境以及调试生产问题。

要在虚拟机上部署你的服务，只需在虚拟机上克隆代码仓库并安装启动应用程序所需的依赖项、软件包和驱动器即可。然而，推荐的方法是使用运行在虚拟机上的容器化平台，如 Docker，以实现持续部署和其他优势。你还应该确保适当地调整虚拟机的资源，以确保你的服务不会因为 CPU/GPU 核心、内存或磁盘空间而受限。

通过本地部署的虚拟机，你可以节省云托管或服务器租赁的成本，并可以完全保护你的应用环境，为少数用户提供一个隔离于公共互联网的网络环境。这些优势也可以通过云虚拟机获得，但需要额外的网络和资源配置配置。此外，你可以访问 GPU 硬件并配置满足你应用程序要求的驱动器。

请记住，使用虚拟机分布模型可能不太容易扩展，并且需要大量的维护工作。此外，虚拟机服务器通常每周 7 天，每天 24 小时运行，除非你根据需要自动化其启动和关闭，否则将产生持续的管理成本。你将负责应用安全补丁、操作系统更新、软件包更新以及网络配置。由于直接访问硬件资源，你还需要做出更多可能减缓你业务活动的决策，从而导致决策疲劳。

我的建议是，如果你没有打算在短期内扩展你的服务，或者你需要保持服务器成本较低并为一个用户群体提供一个隔离和安全的应用环境，那么请实施一个虚拟机。此外，确保你已经为实施、网络连接和虚拟机的配置计划了足够的时间。

## 分布式无服务器功能

除了虚拟机之外，你还可以将你的服务部署到云服务提供商提供的无服务器系统中。在无服务器计算中，你的代码会在响应于事件时执行，例如数据库的更改、存储中 blob 的更新、HTTP 请求或队列中添加的消息。这意味着你只为你的服务使用的请求或计算资源付费，而不是像持续运行的虚拟机那样为整个服务器付费。

当以下情况发生时，无服务器实现通常很有用：

+   你想要的是事件驱动的系统，而不是一个全天候、每周 7 天都在运行的虚拟机。

+   你想要使用一个在成本效率方面高度优化的无服务器架构来分发你的 API 服务。

+   你的服务需要执行批处理工作

+   你需要工作流自动化

“无服务器”这个术语并不意味着云函数不需要硬件资源来执行，而是说这些资源的管理是由云服务提供商负责。这让你可以专注于编写应用程序的代码，而无需担心服务器和操作系统的细节。

云服务提供商根据客户的需求实例化计算资源。通常会出现需求激增的情况，这需要提前创建额外的资源来处理高峰需求。然而，一旦需求减少，就会有多余的计算资源未被分配，这些资源需要关闭或与其他客户共享。

资源的创建和删除是一项计算密集型操作。在规模上，这些操作会给云服务提供商带来显著的成本。因此，云服务提供商更愿意尽可能保持这些资源活跃，并在现有客户之间分配，以最大化收入。

为了鼓励客户使用这些额外的计算，他们创建了云函数服务，你可以利用这些服务在额外的计算上运行你的后端服务（即无服务器）。幸运的是，存在像 Magnum 这样的包，它允许你将 FastAPI 服务打包成 AWS 云函数。你很快就会发现，FastAPI 服务也可以作为 Azure 云函数进行部署。

你必须记住，这些函数只分配了少量资源，并且有较短的超时时间。然而，你可以请求更长的超时时间和计算资源的分配，但这可能需要更多时间来接收这些分配，从而导致用户延迟更高。

###### 注意事项

如果你的业务逻辑消耗大量资源或需要超过几分钟的时间来执行，云函数可能不是适合你的部署选项。

然而，你可以将你的 FastAPI 服务分割成多个函数，每个函数处理一个公开的端点。这样，你可以将服务的一部分作为云函数进行部署，从而减少需要通过其他方法部署的 FastAPI 服务部分。

使用无服务器函数实现你的服务的主要优势是它们的可伸缩性：你可以根据需求伸缩你的应用程序，并且只需支付与预订专用虚拟机相比的一小部分成本。云服务提供商通常根据函数的执行次数和运行时来收费，通常提供慷慨的月度配额。这意味着如果你的函数执行速度快，并且同时用户数量适中，你可能会免费托管所有服务。

此外，云服务提供商还提供可以在本地安装的函数运行时，以便进行本地测试和开发，这样可以显著缩短开发迭代周期。

每个云服务提供商都有自己的无服务器函数部署方法。通常需要一个入口脚本，如*main.py*，它可以根据需要从其他模块导入依赖项。除了入口脚本之外，你还需要上传一个函数宿主的 JSON 配置文件以及*requirements.txt*文件，以便在部署到 Python 运行时安装必要的依赖项。

然后，你可以通过将所有必要的文件打包到一个压缩文件夹中或使用 CI/CD 管道（该管道与提供商进行身份验证并在你的云项目内部执行部署命令）来部署函数。

作为一个例子，我们来尝试部署一个简单且简单的 FastAPI 应用程序，该应用程序返回 LLM 的响应。项目结构如下：

```py
project/
│
├── host.json
├── main.py
├── app.py
└── requirements.txt
```

然后，你可以按照以下代码示例将 FastAPI 应用程序打包为[Azure 无服务器函数](https://oreil.ly/ZaOuF)。

你需要安装`azure-functions`包来执行 Azure 的无服务器函数的本地运行时，以便进行开发和测试：

```py
$ pip install azure-functions
```
