# 前言

自从 ChatGPT 等技术的发布以来，*生成式人工智能*（GenAI）正席卷全球。这种新型人工智能通过学习模仿其训练数据中的模式，能够在各种*模态*（如文本、音频、视频等）中创建内容。随着生成式 AI 能力的不断提高，许多企业正在投资现成的或定制的 AI 工具。这些工具需要可维护和可扩展的后端服务，以适应高需求。

人工智能的能力令人兴奋，因为它们打开了通往无限可能的大门，释放了新工具的潜力。在生成式人工智能出现之前，开发者必须编写脚本和训练优化模型来构建自动化和数据管道，以处理诸如文本语料库之类的非结构化数据。这个过程可能很繁琐，容易出错，并且仅适用于有限的用例。然而，随着大型语言模型（LLMs）等生成式 AI 模型的兴起，我们现在可以消化、比较和总结非结构化数据集和文档；重新措辞复杂的思想；并生成可视化和插图。

尽管大多数生成式模型，如 ChatGPT，在各自领域表现出色，你能想象当我们将它们连接到互联网、我们的数据库和其他服务时会有什么可能性吗？如果我们能够用自然语言“交谈”我们的服务，或者给他们一些图像、视频或音频，并让他们为我们做事，这将为创建新的可访问和自动化的应用程序打开无数机会。

聊天机器人并不是我们能够使用这种生成式模型创建的唯一应用程序。我们还能做更多的事情。我们可以创建后端服务代理，它们可以执行需要理解、逻辑推理和文本分析的各种复杂任务。

通过将我们的生成式模型连接到现有服务和互联网，我们正在为我们的 AI 服务提供额外的数据，以丰富他们对当前问题的理解。例如，一家公司可以使用开源的、定制的、微调的大型语言模型来解析采购订单、生成发票，并在向支付系统下单之前验证数据与客户数据库的一致性。这正是生成式模型大放异彩的地方。其他用例可能包括内容管理系统，可以帮助用户生成内容，以及可以建议图像、图标和用户界面（UI）组件以加快网站设计的网站构建器。

但有一个问题。大型语言模型和其他生成模型需要大量的处理能力和内存才能运行，目前尚不清楚开发者应该使用哪些部署模式和集成层来利用这些模型。构建生成式 AI 服务具有挑战性，因为你需要平衡可扩展性、安全性、性能和数据隐私。你还将希望拥有对服务进行监管、重新训练和优化以进行实时推理的能力。这些挑战对每个组织来说都不同，你构建生成式 AI 服务的方式将取决于你现有的软件系统和服务。

现有的资源和文档提供了开始训练自定义模型和微调大型语言模型所需的信息。然而，大多数开发者可能仍然会面临将这些新颖的生成模型作为现有软件系统和服务的部分进行打包和部署的挑战。

我写这本书的目的是通过理解构建和部署你自己的 AI 服务（使用如 FastAPI 网络框架等工具）的端到端过程，向你展示如何将 GenAI 投入生产。

# 目标和方法

本书的目标是帮助你探索将生成式 AI 作为服务与你的外部系统和应用程序集成时在开发、安全、测试和部署过程中面临的挑战。

本书侧重于在 FastAPI 中构建模块化、类型安全的生成式 AI 服务，并支持无缝的数据库模式处理和模型集成，以支持能够生成新数据的后端。

这些主题的重要性源于对构建能够适应变化需求、保持高性能并使用微服务模式高效扩展的灵活服务的日益增长的需求。

你还将学习如何通过从数据库、网络、外部系统和用户上传的文件等多种来源获取的上下文数据来丰富你的服务。

一些生成模型需要大量的处理能力和内存才能运行。你将探索如何在生产中处理这些模型，以及如何扩展你的服务以处理负载。你还将探索如何处理长时间运行的任务，如模型推理。

最后，我们将讨论身份验证概念、安全考虑、性能优化、测试和部署生产就绪的生成式 AI 服务。

# 先决条件

本书假设你对生成式 AI 没有先前的知识，并且不会要求你完全理解生成模型的工作原理。我将涵盖这些模型生成数据的直觉，但不会深入其背后的数学。然而，如果你想详细了解如何构建自己的生成式 AI 模型，我推荐 David Foster 的[*生成式深度学习*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)（O’Reilly，2024 年）。

由于这是一本针对生成式 AI 应用的 FastAPI 书籍，我假设您对这一 Web 框架有一定的熟悉度。如果您需要复习或想扩展对 FastAPI 特性的理解，我建议阅读 Bill Lubanovic 所著的[*FastAPI*](https://www.oreilly.com/library/view/fastapi/9781098135492/)（O'Reilly，2023）。然而，这不是跟随本书的必要条件。

此外，本书假设您对 Python、Docker 部署、Web 工作原理以及通过 HTTP 协议进行通信有一定的经验。

为了提高您的 Python 技能，我强烈推荐访问[realpython.org](https://realpython.org)，那里有关于更高级概念的优秀教程。官方[Docker 网站](https://www.docker.com)也提供了一个关于容器化和编写 Dockerfile 的优秀实用教程。

本书不会涵盖 Web 的基础知识，但我强烈推荐[MDN 的文档](https://oreil.ly/vvwzI)作为起点。

最后，本书不会要求您了解 Tensorflow 和 Keras 等深度学习框架。在相关的地方，您将介绍这些框架。相反，我们将主要使用托管在[Hugging Face 模型仓库](https://oreil.ly/vC0DA)上的预训练模型。

# 书籍结构

本书分为三个部分：

第一部分，“开发 AI 服务”

本部分涵盖了设置一个将支持您的 GenAI 服务的 FastAPI 项目的所有必要步骤。您将学习如何将各种生成模型集成到类型安全的 FastAPI 应用程序中，并公开端点以与之交互。

+   第一章，“引言”：本章讨论了 GenAI 在未来的重要性，并介绍了您将在本书中构建的实用项目。

+   第二章，“FastAPI 入门”：本章介绍了 FastAPI，这是一个用于构建 AI 服务的现代框架。您将了解其功能、限制以及与其他 Web 框架的比较。在本章结束时，您将能够开始创建 FastAPI 应用程序，逐步组织项目，并从 Flask 或 Django 等框架迁移。

+   第三章，“AI 集成与模型服务”：本章涵盖了将各种 GenAI 模型（包括语言、音频、视觉和 3D 模型）作为 FastAPI 服务使用应用程序生命周期进行集成和服务的全过程。我们将回顾各种模型服务的策略，如使用中间件预加载、外部化和监控模型。

+   第四章，“实现类型安全的 AI 服务”：本章介绍了类型安全的概念，以及 Python 的类型注解和 Pydantic 等数据验证工具如何帮助验证和序列化通过您的 AI 服务运行的数据。

第二部分，“与外部系统通信”

在本部分中，我们将集成我们的 AI 服务与外部系统，如数据库，并学习如何服务并发用户。我们还将实现模型输出的实时流。

+   第五章，“在 AI 工作负载中实现并发”：本章介绍了并发和并行性的概念，并比较了解决并发问题的不同策略。我们将回顾异步编程在处理长时间运行和阻塞任务中的作用，并回顾 Python 的全局解释器锁（GIL）在处理这些异步进程时的局限性。为了实践，我们将使用称为*检索增强生成*（RAG）的技术实现一个“与网络和文档交谈”的聊天机器人。最后，我们将介绍 FastAPI 的背景任务功能，用于处理长时间运行的操作。

+   第六章，“使用生成模型进行实时通信”：在本章中，我们将专注于实现使用生成模型进行实时客户端-服务器通信。作为其中的一部分，我们将通过实际示例比较各种机制，例如 WebSocket 和服务器流事件，当在生成模型之间传输数据时。

+   第七章，“将数据库集成到 AI 服务中”：本章提供了适用于 GenAI 服务的数据库技术的概述。我们将介绍在使用数据库时的一些最佳实践，例如使用经过实战检验的工具如 SQLAlchemy ORM 和 Alembic 来促进迁移。最后，我们将介绍 Prisma，这是一个即将推出的工具，用于生成一个完全类型化的数据库客户端，并自动处理迁移。

第三部分，“保护、优化、测试和部署 AI 服务”

在本部分中，我们专注于实现用户管理的身份验证层，以及安全和优化增强。然后，我们将转向测试，最后通过容器化部署我们的 AI 服务。

+   第八章，“身份验证和授权”：在本章中，我们将介绍为用户管理实现身份验证层，以保护、保护和限制对 AI 服务的访问。我们将回顾并实现各种身份验证策略，包括基本、基于令牌和 OAuth。然后，我们将介绍授权模型，包括基于角色的访问控制（RBAC），并解释 FastAPI 的依赖关系图在过程中的作用。这包括根据角色添加限制性权限，以便 AI 服务交互可以自动进行监管。

+   第九章，“保护 AI 服务”：本章提供了对生成解决方案常见攻击向量的概述。在这里，我们将重点转向在 AI 服务中实施各种安全措施，例如速率限制和防护栏，以保护免受有毒模型输出、常见攻击、滥用和误用的侵害。

+   第十章，“优化 AI 服务”：本章涵盖了各种性能优化技术，如批量处理、语义缓存和提示工程，以增强 AI 服务的质量和速度。

+   第十一章，“测试 AI 服务”：本章涵盖了测试 AI 服务的挑战和最佳实践。我们将回顾各种测试概念，包括测试阶段、边界和模拟，然后实现外部服务的模拟，保持测试环境隔离。最后，我们将介绍一种新颖的测试生成 AI 模型的方法，即使它们在测试运行中产生不同的输出。

+   第十二章，“AI 服务的部署”：本章涵盖了各种部署方法，包括使用虚拟机、云函数、托管应用服务和像 Docker 这样的容器化技术。然后我们将重点关注容器化概念，如存储和网络，以使用 Docker 部署我们的 AI 服务。

# 如何阅读本书

本书可以逐章阅读，也可以作为参考，您可以随时查阅任何章节。在每一章中，我在我们深入实际代码示例之前，都会解释概念并比较方法。因此，我建议您阅读每一章两次：一次是为了理解方法，然后再次回顾它们，使用本书附带的[代码仓库](https://github.com/Ali-Parandeh/building-generative-ai-services)亲自处理代码示例。

###### 小贴士

我坚信用日常类比、图表和故事来解释复杂的技术概念，任何人都能与之产生共鸣。这些通常在介绍新的复杂概念之后使用。注意像这样的提示部分，以帮助提高您对这些概念的理解。

最终，学习本书中的概念的最佳方法是亲自尝试开源生成模型，然后使用您自己的代码围绕它构建服务。最重要的是，我希望您发现这是一本有用且愉快的读物！

# 硬件和软件要求

运行生成模型通常是一个计算密集型任务，需要强大的 GPU。然而，我已经尽力提供使用小型开源生成模型的代码示例，这些模型不需要 GPU。

只有少数章节会有需要您访问 GPU 以处理并发操作或运行更重模型的代码示例。在这种情况下，我建议从任何云服务提供商那里租用具有 CUDA 启用的 NVIDIA GPU 的虚拟机，或者在一个具有至少 16 GB VRAM 的 CUDA 启用的 GPU 台式机上工作。

请参阅 NVIDIA 的 CUDA 安装说明，适用于[Windows](https://oreil.ly/fgwVk)或[Linux](https://oreil.ly/3rMv2)。

最后，要在 CUDA 启用的 NVIDIA GPU 上运行模型，您还需要安装为 CUDA 编译的`torch`包。

# 本书使用的约定

本书使用的排版约定：

*斜体*

指示新术语、URL、电子邮件地址、文件名和文件扩展名。

`常宽字体`

用于程序列表，以及段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。

*`常宽斜体`*

显示应替换为用户提供的值或由上下文确定的值的文本。

###### 提示

此元素表示提示或建议。

###### 注意

此元素表示一般性说明。

###### 警告

此元素表示警告或注意。

# 使用代码示例

本书附带了指导项目的代码仓库。此仓库可在[*https://github.com/Ali-Parandeh/building-generative-ai-services*](https://github.com/Ali-Parandeh/building-generative-ai-services)下载。您还可以在本书的配套网站上找到额外的资源、文章和支持材料[*https://buildinggenai.com*](https://buildinggenai.com)。

下载并克隆仓库后，您可以在本地执行安装。例如，如果您使用`conda`，您可以按照以下设置创建您的`genaiservice`环境：

```py
conda create -n genaiservice python=3.11
conda activate genaiservice
```

然后，您可以在新创建的 Python 环境中安装所有必要的依赖项：

```py
pip install -r requirements.txt
```

在各章节中散布着大约 170 多个代码示例。这些代码示例展示了如何使用 FastAPI Web 框架逐步构建一个生产就绪的生成式 AI 服务。我们将逐行分析代码，清晰的指示将展示代码如何实现支撑每个技术的理论。

代码仓库包含几个分支，这些分支将应用程序代码的状态映射到每个章节的开始和结束，作为示例，这些示例逐步构建在彼此之上。代码示例按分支而不是文件夹组织，以避免混乱，并为您提供干净的基础代码库进行工作。`main`分支包含书中结束时的应用程序代码最终状态。

在每个章节的开始，查看相关的`starter`分支，以跟随代码示例开发应用程序。例如，在第二章的开始，您可以查看`ch02-start`分支。如果您遇到困难或想查看每个章节结束时的仓库状态，您可以查看相应的`end`分支（即`ch02-end`），并将您的代码与仓库中的代码进行比较。

###### 注意

代码仓库在`main`分支的`README.md`文件中包含有关如何克隆仓库和切换分支的说明，如果您不熟悉 Git。

每个分支也将包含一个*README.md*文件，以指导您了解章节的实践元素。

在本书中，我将提供额外的任务和练习，以帮助您在指导项目中巩固对概念的理解。请注意这些部分以获取实施这些任务的说明。解决方案在代码存储库中提供。然而，我建议在查阅解决方案之前先尝试自己解决这些任务。请注意，对于给定的任务可能有多种解决方案。

如果您有技术问题或使用代码示例时遇到问题，请发送电子邮件到*support@oreilly.com*。

本书旨在帮助您完成工作。一般来说，如果本书提供了示例代码，您可以在您的程序和文档中使用它。除非您正在复制代码的很大一部分，否则您无需联系我们获取许可。例如，编写一个使用本书中几个代码块的程序不需要许可。通过引用本书并引用示例代码来回答问题不需要许可。将本书的大量示例代码纳入您产品的文档中需要许可。

我们感谢，但通常不需要归属。归属通常包括标题、作者、出版社和 ISBN。例如，“*Building Generative AI Services with FastAPI* by Alireza Parandeh (O’Reilly). Copyright 2025 Ali Parandeh, 978-1-098-16030-2。”

如果您认为您对代码示例的使用超出了合理使用或上述许可，请随时联系我们*permissions@oreilly.com*。

# O’Reilly 在线学习

###### 注意

超过 40 年来，[*O’Reilly Media*](https://oreilly.com)一直为科技公司提供技术和商业培训、知识和洞察力，以帮助公司成功。

我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。O’Reilly 的在线学习平台为您提供按需访问实时培训课程、深入的学习路径、交互式编码环境以及来自 O’Reilly 和 200 多家其他出版商的大量文本和视频。有关更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。

# 如何联系我们

请将有关本书的评论和问题提交给出版社：

+   O’Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   Sebastopol, CA 95472

+   800-889-8969（美国或加拿大）

+   707-827-7019（国际或本地）

+   707-829-0104（传真）

+   *support@oreilly.com*

+   [*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)

我们为本书有一个网页，其中列出了勘误表、示例和任何其他附加信息。您可以通过[*https://oreil.ly/building-gen-ai-fastAPI*](https://oreil.ly/building-gen-ai-fastAPI)访问此页面。

想了解我们书籍和课程的相关新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。

在 LinkedIn 上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)。

在 YouTube 上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)。

# 致谢

为我来说，撰写这本书是一次难以置信的经历和旅程。我要向我的家人表达最深切的感激，感谢他们在写作过程中的无条件支持。我特别想对我的妹妹 Tara Parandeh、我的父母 Mansoureh Tahabaz 和 Mohammadreza Parandeh 以及我的伴侣 Cherry Waller 表示特别的感谢。

我要感谢那些帮助营造支持性环境的亲朋好友、同事、合作者和 ADSP 团队。感谢 David Foster、Ross Witeszczak、Amy Bull、Zine Eddine、Joe Rowe、Jonathan Davies、Aneta Blazyczek、Giulia Scardovi、Maddy Clements、Sarah Davies、Evelina Kireilyte、Khaleel Syed、Rob Foster、Mai Do、Bogdan Bija、Nicholas Rawitscher Torres、Snehan Sighat 和 Leon Watson。

特别感谢我的导师，David Foster，他是《生成式深度学习》（O’Reilly 出版）的作者，他的书籍激励我撰写自己的书籍。在撰写过程中，他的书籍是我在生成式 AI 方面的学习和灵感来源。此外，我还要感谢那些在我职业生涯中扮演重要角色的亲密朋友：Lee Dalchow、Isaac Cleave 和 Rabah Tahraoui。

与 O’Reilly 合作是一次难以置信的经历。特别感谢我出色的编辑 Rita Fernando 和 Melissa Potter 在写作过程中的支持、热情和优秀的反馈。我无法想象更好的编辑了。感谢 Clare Laylock 在过程中准备早期发布章节并解决格式问题。看到这些章节在 O’Reilly 平台上，并收到读者的积极反馈，是写作过程中的一个重要动力。还要感谢 Nicole Butterfield 和 Amanda Quinn 在实现这本书和启动项目中的帮助。

最后，我要向我的技术审稿人 David Foster、Joe Rowe 和 Julien Brendel 表示衷心的感谢，他们仔细且详细地审阅了本书。每位审稿人提供了不同的视角，确保所有不一致、不准确和空白都得到了解决。没有他们的贡献，本书的质量将大打折扣。
