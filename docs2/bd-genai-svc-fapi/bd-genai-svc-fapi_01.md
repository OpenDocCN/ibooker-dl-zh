# 前言

这项工作是用 AI 翻译的。我们很高兴收到您的反馈和评论：translation-feedback@oreilly.com

*生成式人工智能*（GenAI）在 ChatGPT 等技术的发布后征服了世界。这种新型人工智能能够通过学习模仿训练数据模式，在多种*模式*（如文本、音频、视频等）中创建内容。随着生成式人工智能能力的增强，许多公司正在投资于现成的或定制的 AI 工具。这些工具需要可维护和可扩展的后端服务，能够适应高需求。

人工智能的能力令人兴奋，因为它打开了无限可能的大门，释放了新工具的潜力。在生成式人工智能之前，开发者需要编写脚本和训练优化模型以创建自动化和数据处理管道，用于处理非结构化数据，如文本语料库。这个过程可能很无聊，容易出错，并且仅适用于有限的用例。然而，随着生成式人工智能模型的出现，如大型语言模型（LLMs），我们现在可以消化、比较和总结非结构化数据集和文档，重新表述复杂想法，并生成视觉化和插图。

尽管大多数生成模型如 ChatGPT 在独立使用时都非常出色，你能想象当我们将它们连接到互联网、我们的数据库和其他服务时会产生哪些可能性吗？如果我们能用自然语言与我们的服务“交谈”，或者向他们提供图像、视频或音频，并让他们为我们做事，那么将打开许多创建可访问和自动化的新应用的机会。

聊天机器人并不是我们可以用这些生成模型创建的唯一应用。我们可以创建能够执行需要理解、逻辑推理和文本分析等复杂任务的售后服务代理。

将我们的生成模型连接到现有服务和互联网，为我们的人工智能服务提供更多数据，以丰富他们对问题的理解。例如，一家公司可以使用开源、内部和针对分析订单、生成发票以及在与支付系统下单之前验证客户数据库数据优化的 LLM。其他用例可能包括内容管理系统，可以帮助用户生成内容，以及网站构建者可以建议图像、图标和用户界面（UI）组件，以加快网站设计。

大型语言模型和其他生成模型需要大量的计算能力和内存才能运行，并且不清楚开发者应该使用哪些分布模型和集成级别来利用这些模型。构建 AI 生成服务是一项挑战，因为你需要在可扩展性、安全性、性能和数据隐私之间找到平衡。你还将希望有实时推断这些服务的能力，进行调节、重新培训和优化。这些挑战对每个组织来说都是不同的，你构建 AI 生成服务的方式将取决于你现有的系统和软件服务。

现有的资源和文档提供了开始训练定制模型和开发大型语言模型所需的信息。然而，大多数开发者可能仍然会遇到困难，将这些新的生成模型作为现有软件系统和服务的组成部分进行打包和分发。

本书的目标是向你展示如何通过理解构建和分发 AI 服务端到端流程来生产生成 AI，使用工具如 FastAPI 框架。

# 目标和方式

本书的目标是帮助你探索开发、安全、测试和实施 AI 生成服务作为与你的系统和外部应用集成的服务的挑战。

本书专注于在 FastAPI 中构建模块化和类型安全的 AI 生成服务，并提供对数据库模式管理和为能够生成新数据的后端模型集成的持续支持。

这些主题的重要性源于对构建能够适应不断变化的需求、保持高性能和高效扩展的微服务模型灵活服务的日益增长的需求。

你还将学会如何通过来自数据库、网络、外部系统和用户上传的文件等不同来源的数据来丰富你的服务过程。

一些生成模型需要大量的计算能力和内存才能运行。你将探索如何在生产中管理这些模型，以及如何扩展你的服务以处理负载。你还将了解如何管理长期活动，如模型推断。

最后，我们将讨论认证概念、安全考虑、性能优化、测试和实施准备投入生产的 AI 生成服务。

# 前提

本书不假设读者对生成式人工智能有先前的了解，也不要求读者完全理解生成模型的运作机制。我将讨论这些模型如何生成数据的基本直觉，但不会深入其基本数学。然而，如果你想详细了解如何构建自己的生成式人工智能模型，我建议阅读 David Foster 的[*生成式深度学习*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)（O'Reilly，2024）。

由于本书是关于 FastAPI 生成式人工智能应用的书籍，因此假设读者对这一框架有一定了解。如果你需要复习或想扩展对 FastAPI 功能的理解，我建议阅读 Bill Lubanovic 的[*FastAPI*](https://www.oreilly.com/library/view/fastapi/9781098135492/)（O'Reilly，2023）。然而，这并非阅读本书的必要条件。

此外，本书假设读者具备一定的 Python 经验，熟悉使用 Docker 进行部署，了解 Web 的运作方式以及通过 HTTP 协议进行通信。

为了提高你的 Python 知识，我建议访问[realpython.org](https://realpython.org)网站，以找到关于更高级概念的优秀教程。Docker 的[官方网站](https://www.docker.com)也提供了一个关于容器化和编写 Docker 文件的优秀实践教程。

在本书中，我不会涉及 Web 基础，但我强烈建议从[MDN 文档](https://oreil.ly/vvwzI)开始学习。

最后，本书不需要读者具备 TensorFlow 和 Keras 等深度学习框架的知识，这些框架将在需要时介绍。相反，我们将主要使用托管在[Hugging Face 模型库](https://oreil.ly/vC0DA)中的预训练模型。

# 本书结构

本书分为三个部分：

第一部分 "开发 AI 服务"

本部分涵盖了设置一个将支持你的生成式人工智能服务的 FastAPI 项目的所有必要步骤。你将学习如何将各种生成模型集成到一个类型安全的 FastAPI 应用程序中，并暴露端点以与之交互。

+   第一章 "引言": 本章讨论了生成式人工智能在未来中的重要性，并介绍了本书中你将实现的实际项目。

+   第二章 "开始使用 FastAPI": 本章介绍了 FastAPI，这是一个用于创建人工智能服务的现代框架，你将了解其特性、限制以及与其他 Web 框架的比较。到本章结束时，你将能够开始创建 FastAPI 应用程序，逐步组织项目，并从 Flask 或 Django 等框架迁移过来。

+   第三章，“人工智能与模型服务集成”：本章讨论了将各种 GenAI 模型（包括语言、音频、视觉和 3D 模型）作为 FastAPI 服务集成的整个过程，使用应用程序生命周期。将探讨各种模型服务策略，如预加载、外部化和使用中间件监控模型。

+   第四章，“从类型角度实现安全的 AI 服务”：本章介绍了类型安全的概念，以及 Python 类型注解和像 Pydantic 这样的数据验证工具如何帮助验证和序列化通过你的人工智能服务的数据。

第二部分，“与外部系统通信”

在这部分，我们将把我们的人工智能服务与外部系统如数据库集成，并学习如何服务同时在线的用户。我们还将实施模型结果的实时流式传输。

+   第五章，“在人工智能工作负载中获得一致性”：本章介绍了并发和并行性的概念，并比较了不同的策略来解决并发问题。我们将回顾异步编程在处理长期任务和阻塞任务中的作用，并检查 Python 的全局解释器锁（GIL）在异步进程管理中的限制。为了实践，我们将实现一个功能齐全的聊天机器人“与网络和你的文档对话”，使用一种称为*检索增强生成（RAG）*的技术。最后，我们将讨论 FastAPI 后台任务的功能，以处理长期操作。

+   第六章，“与生成模型实时通信”：在本章中，我们将专注于启用与生成模型的实时客户端-服务器通信，比较各种机制，如 WebSocket 和服务器流事件，以通过实际示例进行数据流式传输。

+   第七章，“在人工智能服务中集成数据库”：本章概述了适合 GenAI 服务的数据库技术，并说明了使用经过验证的工具（如 ORM SQLAlchemy 和 Alembic）与数据库一起工作的最佳实践，以简化迁移。最后，我们将介绍 Prisma，这是一个即将推出的工具，用于生成完全类型化的数据库客户端并自动管理迁移。

第三部分，“人工智能服务的保护、优化、测试和部署”

在这部分，我们将关注实现用户管理的认证级别，以及安全性和优化的改进。然后，我们将关注测试，最后通过容器化部署我们的 AI 服务。

+   第八章，"认证和授权": 在本章中，我们将讨论实现用户管理的认证级别，以保护并限制对 AI 服务的访问。我们将审查和实施各种认证策略，包括基本认证、基于令牌的认证和 OAuth。然后，我们将介绍授权模型，包括基于角色的访问控制（RBAC），并解释 FastAPI 依赖关系图在此过程中的作用。这包括根据角色添加限制性权限，以便自动调节与 AI 服务的交互。

+   第九章，"人工智能服务的安全部署": 本章概述了针对生成式解决方案最常见的攻击向量。在此，我们将关注在我们的 AI 服务中实施各种安全措施，如速率限制和护栏，以保护我们免受模型有毒输出的影响，以及常见的攻击、滥用和不正当使用。

+   第十章，"人工智能服务优化": 本章讨论了各种性能优化技术，如批量处理、语义缓存和提示工程，以提高 AI 服务的质量和速度。

+   第十一章，"AI 服务测试": 本章讨论了测试人工智能服务的挑战和最佳实践。我们将回顾各种测试概念，包括测试阶段、边界和模拟，然后实现外部服务的模拟，同时保持测试环境的隔离。最后，我们将介绍一种新的测试方法，用于测试生成性人工智能模型，即使它们在测试的不同执行中产生不同的输出。

+   第十二章，"AI 服务分布": 本章讨论了各种分布方法，包括虚拟机、云函数、管理应用服务和 Docker 等容器化技术。因此，我们将重点关注容器化概念，如存储和网络，以使用 Docker 来分布我们的 AI 服务。

# 如何阅读这本书

这本书可以一口气读完，也可以用作参考书，以便深入任何章节。在每一章中，我解释了概念，并在深入研究代码示例之前对比了方法。因此，我建议您阅读每一章两次：一次是为了理解方法，然后是使用附在书中的[代码仓库](https://github.com/Ali-Parandeh/building-generative-ai-services)复习代码示例。

###### 建议

我坚信，用类比、图表和日常故事解释复杂的技术概念是有效的，这些故事任何人都可以参考。通常，这些在介绍复杂新概念之后使用。寻找这样的建议部分，以增强您对概念的理解。

最终，学习本书中概念的最好方法是动手操作开源生成模型，然后使用您的代码围绕它构建服务。特别是，我希望您觉得它有用且阅读愉快！

# 硬件和软件要求

生成模型的执行通常是一项计算密集型活动，需要强大的 GPU。然而，我已经尽力提供使用小型开源生成模型示例的代码，这些模型不需要 GPU。

只有少数章节包含需要访问 GPU 以执行并发操作或运行更重模型的代码示例。在这种情况下，我建议您从任何云服务提供商那里租赁启用 CUDA 的 GPU 虚拟机，或者使用至少有 16GB VRAM 的启用 CUDA 的桌面计算机。

请参阅 NVIDIA CUDA 的安装说明，[Windows](https://oreil.ly/fgwVk) 或 [Linux](https://oreil.ly/3rMv2)。

最后，为了在兼容 CUDA 的 NVIDIA GPU 上执行模型，您需要安装为 CUDA 编译的`torch`包。

# 本书使用的约定

本书使用了以下排版约定：

*斜体*

表示新术语、URL、电子邮件地址、文件名和文件扩展名。

`常宽`

用于程序列表和段落内引用程序元素，如变量名或函数名、数据库、数据类型、环境变量、声明和关键字。

*`常宽斜体`*

显示需要用用户提供的值或上下文中确定的值替换的文本。

###### 建议

这个元素表示一个建议或提示。

###### 注意

这个元素表示一个一般性说明。

###### 警告

这个元素表示一个警告或注意事项。

# 使用代码示例

本书附带一个代码库，用于项目引导，可在 [*https://github.com/Ali-Parandeh/building-generative-ai-services.*](https://github.com/Ali-Parandeh/building-generative-ai-services) 下载。你可以在书的网站上找到其他资源、文章和支持材料，网址为 [*https://buildinggenai.com*](https://buildinggenai.com) [*.*](https://github.com/Ali-Parandeh/building-generative-ai-services)

在下载并克隆了代码库之后，你可以执行本地安装。例如，如果你使用 `conda`，你可以遵循以下设置来创建你的 `genaiservice` 环境：

```py
conda create -n genaiservice python=3.11
conda activate genaiservice
```

然后，你可以在刚刚创建的 Python 环境中安装所有必要的依赖项：

```py
pip install -r requirements.txt
```

在各个章节中分散着超过 170 个代码示例，这些示例展示了如何逐步构建一个准备就绪的生产级生成式 AI 服务，使用的是 FastAPI 框架。我们将逐步展示代码，并提供清晰的指示，说明代码如何实现每个技术背后的理论。

代码库包含多个分支，这些分支映射了应用代码在每个章节开始和结束时的状态，而示例则是以增量方式发展的。代码示例是按分支而不是按文件夹组织的，以避免混乱并提供一个干净的代码基础来工作。`main` 分支包含在书末应用代码的最终状态。

在每个章节的开始，请查阅相应的 `starter` 分支以在应用开发过程中跟随代码示例。例如，在 第二章 的开始，你可以查阅 `ch02-start` 分支。如果你在某个章节中遇到障碍或想查看每个章节结束时的代码库状态，你可以查阅相应的 `end` 分支（即 `ch02-end`），并将你的代码与代码库中的代码进行比较。

###### 注意

代码库在 `main` 分支的 *README.md* 文件中包含说明，指导如何克隆代码库以及如果你不熟悉 Git，如何更改分支。

每个分支都将包含一个 *README.md* 文件，以指导你了解章节的实践元素。

在本书的进程中，我将提供额外的任务和练习，以帮助你在项目引导过程中巩固对概念的理解。请注意这些部分，以获取实施这些任务的说明。解决方案包含在代码库中。然而，我建议你在查阅解决方案之前先尝试独立解决这些任务。请注意，对于特定任务可能存在许多解决方案。

如果你有一个技术问题或在使用代码示例时遇到问题，请发送电子邮件至 *support@oreilly.com.*

通常，如果本书附带示例代码，您可以在自己的程序和文档中使用它。除非您正在复制代码的显著部分，否则不需要联系我们获取授权。例如，编写一个使用本书不同部分代码的程序不需要授权。从 O'Reilly 的书籍中提取示例并销售或分发需要授权。引用本书并引用示例代码不需要授权。在您的产品文档中包含大量从本书提取的示例代码需要授权。

我们感谢，但通常不要求署名。署名通常包括标题、作者、出版社和 ISBN。例如，"*《使用 FastAPI 构建生成式 AI 服务》作者：阿里雷扎·帕尔安德（O'Reilly）。版权所有 2025 阿里·帕尔安德，978-1-098-16030-2"。

如果您认为您对示例代码的使用不属于公平使用或上述权限范围，请通过以下邮箱联系我们：*permissions@oreilly.com.*

# O'Reilly 在线培训

###### 注意

40 多年来，[*O'Reilly Media*](https://oreilly.com)为帮助企业成功提供技术知识和商业深入见解。

我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和技能。O'Reilly 的在线学习平台为您提供按需访问现场培训课程、深入的学习路径、交互式编码环境和 O'Reilly 及其超过 200 家其他出版商的丰富文本和视频资源。欲了解更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。

# 如何联系我们

我们邀请您将关于此书的评论和问题提交给出版社：

+   O'Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   加州塞巴斯蒂波尔 95472

+   800-889-8969（美国或加拿大）

+   707-827-7019（国际或本地）

+   707-829-0104（传真）

+   *support@oreilly.com*

+   [*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)

我们有一个专门为此书建立的网页，其中列出了错误、示例和所有附加信息。您可以通过以下链接访问此页面：[*https://oreil.ly/building-gen-ai-fastAPI.*](https://oreil.ly/building-gen-ai-fastAPI)

想了解我们的书籍和课程的信息和新闻，请访问我们的网站：[*https://oreilly.com.*](https://oreilly.com)

在 LinkedIn 上找到我们：[*https://linkedin.com/company/oreilly-media.*](https://linkedin.com/company/oreilly-media)

在 YouTube 上关注我们：[*https://youtube.com/oreillymedia.*](https://youtube.com/oreillymedia)

# 感谢

为我撰写这本书是一次不可思议的经历和旅程。我最深的感激之情要献给在我写作过程中给予无条件支持的我的家人。我想特别感谢我的妹妹塔拉·帕兰代赫；我的父母，曼苏雷·塔哈巴兹和穆罕默德·雷扎·帕兰代赫；以及我的伴侣，切瑞·沃勒。

我感谢那些帮助我营造有利环境的亲朋好友、同事、合作者和 ADSP 的员工。感谢大卫·福斯特、罗斯·维特谢茨卡、艾米·巴勒、津·艾丁、乔·罗、乔纳森·戴维斯、阿涅塔·布拉齐切克、朱莉亚·斯卡尔多维、马迪·克莱门茨、莎拉·戴维斯、伊夫琳娜·基雷伊利特、卡利尔·赛义德、罗布·福斯特、迈·多、博格丹·比亚、尼古拉斯·拉维茨切尔·托雷斯、斯内汉·西加特和莱昂·沃森。

尤其是我想感谢我的导师，大卫·福斯特，他是《生成深度学习》（O'Reilly 出版社）的作者，感谢他启发我撰写我的书籍。他的书籍在撰写过程中成为了我在生成式人工智能学习上的一个学习和灵感来源。此外，我还要感谢那些帮助塑造我职业生涯的亲密朋友：李·达尔乔、艾萨克·克利夫和拉巴·塔哈乌伊。

与 O'Reilly 合作是一次难以置信的经历。特别感谢我那两位了不起的编辑丽塔·费尔南多和梅丽莎·波特，感谢他们在写作过程中的支持、热情和出色的反馈。我无法想象更好的编辑了。感谢克莱尔·莱洛克，她提前准备了章节，并在格式处理过程中解决了问题。看到这些章节在 O'Reilly 平台上，并收到读者的积极反馈，这对我的写作是一个重要的激励。还要感谢妮可·巴特菲尔德和艾曼达·奎因，感谢他们在实现这本书和启动项目中的帮助。

最后，我要向我的技术审稿人表示深深的感谢，大卫·福斯特、乔·罗和朱利安·布伦德尔，感谢他们细致入微和详尽的审稿。每位审稿人都提供了不同的视角，以确保所有的不一致、不准确和疏漏都得到了处理。没有他们的贡献，这本书的质量将大打折扣。
