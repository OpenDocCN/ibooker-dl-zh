# 第七章\. 在人工智能服务中集成数据库

这项工作使用 AI 进行了翻译。我们很高兴收到您的反馈和评论：translation-feedback@oreilly.com

在本章中，您将把数据库集成到您当前的服务 API 中，以存储和检索用户交互。

这章假设您对数据库和 SQL（结构化查询语言）的使用有基本的经验，因此不会涵盖 SQL 编程和数据库工作流程的所有方面，而是会向您介绍高级数据库概念、开发工作流程以及将数据库集成到您的 FastAPI 应用程序中的最佳实践，这些应用程序与像 LLM（大型语言模型）这样的 GenAI 模型交互。

您将学习关系型数据库（SQL）与非关系型数据库（noSQL）在应用程序开发中的作用，并能够安全地选择适合您用例的正确数据库。然后，您将更好地了解关系型数据库的特点和相关工具，如对象关系映射器（ORM）和数据库迁移工具。最后，作为实际操作练习，您将使用 SQL 和 Alembic 将数据库集成到现有应用程序中，以存储和检索与 LLM 的对话。

在本章结束时，您将更有信心选择、配置和解决您在 GenAI 应用程序中遇到的数据库相关问题和挑战。

# 数据库的角色

当构建后端服务时，您通常需要一个数据库来维护应用程序状态和存储用户数据。在其他情况下，您的应用程序可能不需要数据库，您也不应该尝试添加数据库，因为任何与数据库的集成都可能显著增加您服务的复杂性。

在这里，有几种情况您可以放弃使用数据库：

1.  您的应用程序可以在每个新的用户会话启动时从新状态开始。

1.  从资源角度来看，应用程序数据的重新计算既简单又高效。

1.  应用程序数据足够小，可以存储。

1.  您的应用程序对由于服务器错误、重启或其他意外事件等原因导致的数据丢失具有容错性。

1.  不同的用户会话或应用程序实例不需要共享数据。

1.  您需要的数据可以直接从外部系统、GenAI 模型和其他应用程序 API 中提取，而不是从您的数据库中提取。

1.  用户愿意等待为每个新的会话或操作重新计算数据。

1.  你的服务要求允许你在磁盘上的文件、浏览器存储或外部云中保存数据，而不是在数据库中。使用这些替代方案，你的服务可以容忍数据存档和恢复不如数据库可靠和高效。

1.  你正在实现一个概念验证，必须尽量避免项目中的延迟或复杂性。

符合上述标准的一个应用示例是仅用于演示目的的 GenAI 图像生成器。

在这个例子中，你不需要记住任何生成的图像，并且你总是可以从一个新状态重新启动或使用应用程序。此外，应用程序不需要知道用户身份，也不需要在会话之间共享数据。此外，如果发生服务器错误，数据丢失的影响最小，因为你可以即时重新生成一个新的图像。

正如你所见，至少有一些情况下，你不需要数据库来构建你的 GenAI 服务。然而，你可能想知道何时真正需要数据库。

要理解何时需要数据库，你必须了解数据库的作用。简而言之，你可以使用它们以高效的方式存档、组织和处理数据，从而便于恢复、操作和分析。此外，数据库还具备诸如恢复/备份、并发访问管理、索引、缓存和基于角色的访问控制等基本功能，这使得它们成为任何显示、生成和消费数据的服务的不可或缺组成部分。

在下一节中，我们将详细探讨数据库的内部工作原理，特别是本章将集中讨论的关系型数据库。通过对数据库内部结构的深入了解，你可以设计出完全优化且适用于生产的 GenAI API。这样，你可以将最重的负载委托给专门为处理重任务而设计的数据库引擎。

# 数据库系统

现在你已经了解了何时使用数据库，让我们更深入地了解你可以使用的不同数据库及其工作原理。

你可以通过将数据库分为两大类来构建一个关于数据库的思维模型：关系型数据库（SQL）和非关系型数据库（NoSQL）。

SQL 与 NoSQL 的分类基于这样一个事实：关系型数据库使用 SQL 的各种方言作为主要的查询语言，而非关系型数据库通常配备有专用的查询语言。

对于数据库系统的这两类，可以采用一个心理模型来了解这些系统的结构。无论是 SQL 数据库还是 NoSQL 数据库，通常都由以下元素组成：

+   一个高级别的*服务器*，它托管整个数据库基础设施并消耗系统资源（CPU、RAM 和存储）。

+   服务器内的一个或多个*数据库*，作为包含相关数据的逻辑容器。

+   在数据库内部（根据数据库软件），一个或多个*schemata*，用于定义数据的完整结构和各种结构化对象，如索引、逻辑约束、触发器等。

+   在数据库内部（作为模式的一部分）创建的零个或多个*表*（SQL）或*集合*（NoSQL），将相关数据分组。

+   每个集合（如文档）或表（如行）内的零个或多个*元素*，代表特定的记录或实体。

图 7-1 展示了上述划分。

![bgai 0701](img/bgai_0701.png)

###### 图 7-1. 数据库系统划分

采用如图 7-1 所示的心理模型可以帮助你在不断增长的数据库系统种类中找到方向，因为你可以期待存在类似的基本机制。希望这种熟悉感能减少你在采用不同数据库系统时的学习曲线。

因此，我们简要回顾一下 SQL 和 NoSQL 数据库系统，以便更好地理解它们的用例、特性和在创建 API 和服务中的局限性。

为了帮助你建立关系型数据库和非关系型数据库的心理模型，请参阅图 7-2。

![bgai 0702](img/bgai_0702.png)

###### 图 7-2. 数据库类型

你也可以使用表 7-1 的总结作为本章将要讨论的数据库类型的参考。

表 7-1. 数据库对比

| 类型 | 数据模型 | 示例 | 用例 |
| --- | --- | --- | --- |
| 键值商店 | 键值对 | Redis, DynamoDB, Memcached | 缓存、会话管理 |
| 图形商店 | 节点和边 | Neo4j, Amazon Neptune, ArangoDB | 社交网络、推荐引擎、欺诈检测 |
| 文档存储 | 文档 | MongoDB, CouchDB, Amazon DocumentDB | 内容管理、电子商务、实时分析 |
| 向量商店 | 高维向量 | Pigna, Weaviate | 推荐系统、图像/文本搜索、ML 模型存储 |
| 宽列家族商店 | 行和列的表 | Apache Cassandra, HBase, ScyllaDB | 时间序列数据、实时分析、日志记录 |

现在你已经对所有的常见关系型和非关系型数据库有了全面的了解，你可以查看一个使用这些数据库的实时 GenAI 服务。

想象一下构建一个能够与知识库进行对话的 LLM 服务。这个知识库中的文档是相互关联的，因此你决定实现一个 RAG 图来捕获更丰富的上下文。为了实现 RAG 图，你需要将你的服务与一个图数据库集成。

现在，为了检索相关的文档片段，你也必须将它们插入到一个向量数据库中，作为这一部分，你还需要一个关系型数据库来监控使用情况并存储用户数据和对话历史。

由于用户可能会提出常见问题，你也决定提前生成不同的 LLM 输出并将其存储在缓存中。因此，你还将把一个键值存储库集成到你的服务中。

最后，你希望管理员能够控制系统的提示，并能够控制其版本。因此，你将内容管理系统添加到你的解决方案中作为提示的管理器。然而，由于提示模型可能会经常变化，你决定也集成一个文档数据库。

正如你所见，每种类型的数据库都在你的复杂 RAG 应用中解决特定的问题：一个存储后端和用户数据，另一个捕获文档之间的关系，一个存储文档的嵌入，另一个帮助存储灵活的提示模式，最后一个帮助你缓存返回的输出。

你可以在图 7-3 中看到应用程序架构的展示，以了解这些数据库如何一起工作以实现解决方案。

![bgai 0703](img/bgai_0703.png)

###### 图 7-3\. 各种类型数据库的联合使用

现在你已经了解了你的 GenAI 服务如何与不同的数据库集成，在下一节中，我们将专注于将关系型数据库添加到你的服务中。

# 项目：将用户与 LLM 的对话存储在关系型数据库中

在前一节中，我们讨论了数据库的基本概念，以将数据持久性添加到你的应用程序中。

在本节中，你将把一个关系型数据库集成到你的 GenAI 服务中，以便能够将用户与 LLM 的对话历史存储在数据库中。作为这项工作的一个部分，你还将学习到管理数据库模式更改和数据迁移的最佳实践、工具和开发流程。

对于此项目，我们将安装一个开源、免费且经过验证的关系型数据库 Postgres，许多公司都在使用它。为了开始，我们使用 `docker run` 命令下载并执行 Postgres 容器，如 Esempio 7-1 所示。

##### 示例 7-1\. 下载并执行 Postgres 数据库容器

```py
$ docker run -p 5432:5432  \  ![1](img/1.png) ![2](img/2.png)
	-e POSTGRES_USER=fastapi \
	-e POSTGRES_PASSWORD=mysecretpassword \
	-e POSTGRES_DB=backend_db \
	-e PGDATA=/var/lib/postgresql/data \ ![3](img/3.png)
    -v "$(pwd)"/dbstorage:/var/lib/postgresql/data \ ![4](img/4.png)
    postgres:latest ![1](img/1.png)
```

![1](img/#co_integrating_databases_into_ai_services_CO1-1)

从 Docker 注册表中下载并执行最新的关系型数据库 `postgres` 镜像。

![2](img/#co_integrating_databases_into_ai_services_CO1-2)

执行 `postgres` 镜像，然后暴露并映射容器的 `5432` 端口到主机上的相同端口。

![3](img/#co_integrating_databases_into_ai_services_CO1-3)

使用不同的环境变量执行容器，这些变量指定了数据库管理员的默认用户名和密码、数据库名以及 DBMS 数据在容器内的位置。

![4](img/#co_integrating_databases_into_ai_services_CO1-4)

在主机文件系统中，将 Postgres 数据库挂载到当前工作目录下的 `dbstorage` 文件夹中。

因此，我们安装 `sqlalchemy`、`alembic` 和 `psycopg3` 包：

```py
$ pip install alembic sqlalchemy psycopg3
```

```py`Questi pacchetti collaudati ti permettono di comunicare direttamente con il database relazionale Postgres tramite Python.`psycopg3` è un popolare adattatore di database PostgreSQL per Python, mentre SQLAlchemy è un toolkit SQL e un ORM che ti permette di eseguire query SQL sul tuo database in Python.    Infine, il pacchetto `alembic` è uno *strumento per la migrazione dei database* creato dagli sviluppatori di SQLAlchemy per essere utilizzato con SQLAlchemy. Il flusso di lavoro per la migrazione dei dati è simile al sistema di controllo delle versioni Git, ma per gli schemi del tuo database. Ti permette di gestire le modifiche e gli aggiornamenti dei tuoi schemi in modo da evitare qualsiasi corruzione dei dati, di tenere traccia delle modifiche nel tempo e di ripristinare qualsiasi modifica se necessario.    ## Definire i modelli ORM    Il primo passo per interrogare il database in Python è quello di definire i modelli ORM con le classi SQLAlchemy, come mostrato nell'Esempio 7-2. Puoi utilizzare gli schemi dei dati del diagramma ERD di cui alla Figura 8-4.    ###### Nota    Aggiungerai la tabella `user` nel prossimo capitolo quando implementerai i meccanismi di autenticazione e autorizzazione.    ##### Esempio 7-2\. Definizione dei modelli ORM del database    ``` # entities.py  from datetime import UTC, datetime from sqlalchemy import ForeignKey from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship  class Base(DeclarativeBase): ![1](img/1.png)     pass  class Conversation(Base): ![2](img/2.png)     __tablename__ = "conversations"      id: Mapped[int] = mapped_column(primary_key=True)     title: Mapped[str] = mapped_column() ![3](img/3.png)     model_type: Mapped[str] = mapped_column(index=True) ![4](img/4.png)     created_at: Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at: Mapped[datetime] = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC) ![5](img/5.png)     )      messages: Mapped[list["Message"]] = relationship(         "Message", back_populates="conversation", cascade="all, delete-orphan" ![6](img/6.png)     )   class Message(Base): ![7](img/7.png)     __tablename__ = "messages"      id: Mapped[int] = mapped_column(primary_key=True)     conversation_id: Mapped[int] = mapped_column(         ForeignKey("conversations.id", ondelete="CASCADE"), index=True ![6](img/6.png)     )     prompt_content: Mapped[str] = mapped_column()     response_content: Mapped[str] = mapped_column()     prompt_tokens: Mapped[int | None] = mapped_column()     response_tokens: Mapped[int | None] = mapped_column()     total_tokens: Mapped[int | None] = mapped_column()     is_success: Mapped[bool | None] = mapped_column()     status_code: Mapped[int | None] = mapped_column() ![8](img/8.png) ![9](img/9.png)     created_at: Mapped[datetime] = mapped_column(default=datetime.now(UTC))     updated_at: Mapped[datetime] = mapped_column(         default=datetime.now(UTC), onupdate=datetime.now(UTC)     )      conversation: Mapped["Conversation"] = relationship(         "Conversation", back_populates="messages"     ) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO2-1)      Dichiara una classe base dichiarativa per creare modelli SQLAlchemy per il suo motore ORM.      ![2](img/#co_integrating_databases_into_ai_services_CO2-2)      Crea il modello `Conversation` specificando le colonne della tabella, la chiave primaria e gli indici secondari.      ![3](img/#co_integrating_databases_into_ai_services_CO2-3)      Utilizza `mapped_column()` per derivare il tipo di colonna dal suggerimento di tipo dato a `Mapped`.      ![4](img/#co_integrating_databases_into_ai_services_CO2-4)      Indicizza il sito `model_type` se vuoi filtrare più velocemente le conversazioni per tipo di modello.      ![5](img/#co_integrating_databases_into_ai_services_CO2-5)      Specifica i valori predefiniti e le operazioni di aggiornamento per le colonne datetime.      ![6](img/#co_integrating_databases_into_ai_services_CO2-6)      Indica che tutti i messaggi orfani devono essere cancellati se una conversazione viene eliminata tramite un'operazione di `CASCADE DELETE`.      ![7](img/#co_integrating_databases_into_ai_services_CO2-7)      Crea il modello `Message` specificando le colonne della tabella, la chiave primaria, gli indici secondari, le relazioni della tabella e le chiavi esterne.      ![8](img/#co_integrating_databases_into_ai_services_CO2-9)      La tabella `messages` conterrà i prompt e le risposte del LLM, i token di utilizzo e i costi, oltre ai codici di stato e agli stati di successo.      ![9](img/#co_integrating_databases_into_ai_services_CO2-10)      Specifica `Mapped[int | None]` per dichiarare una tipizzazione opzionale in modo che la colonna permetta i valori di `NULL` (cioè `nullable=True`).      Una volta definiti i modelli di dati, puoi creare una connessione al database per creare ogni tabella con le configurazioni specificate. Per ottenere questo risultato, dovrai creare un *motore di database* e implementare la *gestione delle sessioni*.    ## Creazione di un motore di database e gestione delle sessioni    L'esempio 7-3 mostra a come creare un motore SQLAlchemy utilizzando la stringa di connessione al database Postgres. Una volta creato, puoi utilizzare il motore e la classe `Base` per creare tabelle per ciascuno dei tuoi modelli di dati.    ###### Avvertenze    Il metodo `create_all()` di SQLAlchemy nell'Esempio 7-3 può solo creare tabelle nel database ma non modificare le tabelle esistenti. Questo flusso di lavoro è utile solo se stai facendo dei prototipi e sei contento di reimpostare gli schemi del database con nuove tabelle a ogni esecuzione.    Per gli ambienti di produzione, dovresti utilizzare uno strumento di migrazione del database come `alembic` per aggiornare gli schemi del database ed evitare la perdita involontaria di dati. A breve scoprirai il flusso di lavoro della migrazione del database.    ##### Esempio 7-3\. Creare il motore del database SQLAlchemy    ``` # database.py  from sqlalchemy.ext.asyncio import create_async_engine from entities import Base  database_url = ( ![1](img/1.png)     "postgresql+psycopg://fastapi:mysecretpassword@localhost:5432/backend_db" ) engine = create_async_engine(database_url, echo=True) ![2](img/2.png)  async def init_db() -> None:     async with engine.begin() as conn:         await conn.run_sync(Base.metadata.drop_all)         await conn.run_sync(Base.metadata.create_all) ![3](img/3.png)  # main.py  from contextlib import asynccontextmanager from fastapi import FastAPI from database import engine, init_db  @asynccontextmanager async def lifespan(_: FastAPI):     await init_db()     # other startup operations within the lifespan     ...     yield     await engine.dispose() ![4](img/4.png)  app = FastAPI(lifespan=lifespan) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO3-1)      Per i database Postgres, la stringa di connessione viene definita utilizzando il seguente modello: `*<driver>*://*<username>*:*<password>*@*<origin>*/*<database>*`.      ![2](img/#co_integrating_databases_into_ai_services_CO3-2)      Crea un motore di database async utilizzando la stringa di connessione al database. Attiva il debug logging con `echo=True`.      ![3](img/#co_integrating_databases_into_ai_services_CO3-3)      Elimina tutte le tabelle esistenti e poi crea tutte le tabelle del database utilizzando i modelli SQLAlchemy definiti nell'Esempio 7-3.      ![4](img/#co_integrating_databases_into_ai_services_CO3-4)      Smaltisce il motore del database durante il processo di spegnimento del server. Qualsiasi codice dopo la parola chiave `yield` all'interno del gestore del contesto `lifespan` di FastAPI viene eseguito quando viene richiesto lo spegnimento del server.      ###### Avvertenze    Per chiarezza, le variabili d'ambiente e i segreti come le stringhe di connessione al database sono codificati in ogni esempio di codice.    Negli scenari di produzione, non codificare mai i segreti e le variabili d'ambiente. Sfrutta i file d'ambiente, i gestori di segreti e gli strumenti come Pydantic Settings per gestire i segreti e le variabili delle applicazioni.    Dopo aver creato il motore, puoi implementare una funzione di fabbrica per creare sessioni al database. La fabbrica di sessioni è un modello di progettazione che ti permette di aprire, interagire e chiudere le connessioni al database nei tuoi servizi.    Dal momento che puoi riutilizzare una sessione, puoi usare il sistema di iniezione delle dipendenze di FastAPI per memorizzare nella cache e riutilizzare le sessioni in ogni runtime di richiesta, come mostrato nell'Esempio 7-4.    ##### Esempio 7-4\. Creazione di una sessione di database Dipendenza FastAPI    ``` # database.py  from typing import Annotated from fastapi import Depends from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker from database import engine  async_session = async_sessionmaker(     bind=engine, class_=AsyncSession, autocommit=False, autoflush=False ![1](img/1.png) ) async def get_db_session(): ![2](img/2.png)     try:         async with async_session() as session: ![3](img/3.png)             yield session ![4](img/4.png)     except:         await session.rollback() ![5](img/5.png)         raise     finally:         await session.close() ![6](img/6.png)  DBSessionDep = Annotated[AsyncSession, Depends(get_db_session)] ![7](img/7.png) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO4-1)      Crea un factory di sessione di database asincrono legato al motore di database che hai creato in precedenza per connetterti in modo asincrono alla tua istanza di Postgres. Disabilita il commit automatico delle transazioni con `autocommit=false` e il flushing automatico delle modifiche al database con `autoflush=False`. Disabilitare entrambi i comportamenti ti offre un maggiore controllo, ti aiuta a prevenire aggiornamenti di dati non voluti e ti permette di implementare una gestione delle transazioni più robusta.      ![2](img/#co_integrating_databases_into_ai_services_CO4-2)      Definisci una funzione di dipendenza da riutilizzare e iniettare nella tua applicazione FastAPInelle funzioni delroute controller. Poiché la funzione utilizza la parola chiave `yield` all'interno di `async with`, è considerata un gestore di contesto async. FastAPI decorerà internamente `get_db_session` come gestore di contesto quando viene utilizzata comedipendenza.      ![3](img/#co_integrating_databases_into_ai_services_CO4-3)      Utilizza il factory di sessione del database per creare una sessione asincrona. Il gestore del contesto aiuta a gestire il ciclo di vita della sessione del database come l'apertura, l'interazione e la chiusura delle connessioni al database in ogni sessione.      ![4](img/#co_integrating_databases_into_ai_services_CO4-4)      Restituisce la sessione del database al chiamante della funzione `get_db_session`.      ![5](img/#co_integrating_databases_into_ai_services_CO4-5)      Se si verificano delle eccezioni, annulla la transazione e solleva nuovamente l'eccezione.      ![6](img/#co_integrating_databases_into_ai_services_CO4-6)      In ogni caso, chiudi la sessione del database alla fine per liberare le risorse che detiene.      ![7](img/#co_integrating_databases_into_ai_services_CO4-7)      Dichiara una dipendenza annotata della sessione del database che può essere riutilizzata da diversi controllori.      Ora che puoi creare una sessione del database da qualsiasi rotta FastAPI tramite dependency injection, implementiamo gli endpoint di creazione, lettura, aggiornamento e cancellazione (CRUD) per la risorsa conversazioni.    ## Implementare gli endpoint CRUD    Poiché FastAPI si affida a Pydantic per serializzare e convalidare i dati in entrata e in uscita, prima di implementare gli endpoint CRUD dovrai mappare le entità del database nei modelli di Pydantic. In questo modo eviterai di accoppiare strettamente lo schema dell'API con i modelli del database per darti la libertà e la flessibilità di sviluppare l'API e i database in modo indipendente l'uno dall'altro.    Puoi seguire l'Esempio 7-5 per definire i tuoi schemi CRUD.    ##### Esempio 7-5\. Dichiarazione degli schemi API di Pydantic per gli endpoint di conversazione    ``` # schemas.py  from datetime import datetime from pydantic import BaseModel, ConfigDict  class ConversationBase(BaseModel):     model_config = ConfigDict(from_attributes=True) ![1](img/1.png)      title: str     model_type: str  class ConversationCreate(ConversationBase): ![2](img/2.png)     pass  class ConversationUpdate(ConversationBase): ![2](img/2.png)     pass  class ConversationOut(ConversationBase): ![2](img/2.png)     id: int     created_at: datetime     updated_at: datetime ```py    ![1](img/#co_integrating_databases_into_ai_services_CO5-1)      Impostare il modello Pydantic per leggere e convalidare gli attributi di altri modelli come SQLAlchemy, che viene spesso utilizzato in Pydantic quando si lavora conmodelli di database.      ![2](img/#co_integrating_databases_into_ai_services_CO5-2)      Creare modelli Pydantic separati basati sul modello di base per diversi casi d'uso, come la creazione e l'aggiornamento dei record di conversazione o il recupero dei dati.      ###### Suggerimento    Dover dichiarare i modelli Pydantic e SQLAlchemy può sembrare una duplicazione del codice, ma ti permetterà di implementare il tuo livello di accesso ai dati nel modo che preferisci.    In alternativa, se vuoi evitare la duplicazione del codice, puoi utilizzare il pacchetto `sqlmodel`, che integra Pydantic con SQLAlchemy, eliminando gran parte della duplicazione del codice. Tuttavia, tieni presente che `sqlmodel` potrebbe non essere l'ideale per la produzione a causa della flessibilità limitata e del supporto per i casi d'uso avanzati con SQLAlchemy. Per questo motivo, potresti voler utilizzare modelli Pydantic e SQLAlchemy separati per applicazioni complesse.^(1)    Ora che hai i modelli SQLAlchemy e Pydantic, puoi iniziare a sviluppare gli endpoint delle API CRUD.    Nell'implementazione degli endpoint CRUD, dovresti cercare di sfruttare il più possibile le dipendenze FastAPI per ridurre i giri del database. Ad esempio, quando recuperi, aggiorni e cancelli dei record, devi verificare con il database l'esistenza di un record utilizzando il suo ID.    Puoi implementare una funzione di recupero dei record per utilizzare una dipendenza tra i tuoi endpoint get, update e delete, come mostrato nell'Esempio 7-6.    ###### Avvertenze    Tieni presente che FastAPI può memorizzare nella cache l'output della dipendenza `get_conversation` solo all'interno di una singola richiesta e non su più richieste.    ##### Esempio 7-6\. Implementazione di endpoint CRUD basati sulle risorse per la tabella `conversations`    ``` # main.py  from typing import Annotated from database import DBSessionDep from entities import Conversation from fastapi import Depends, FastAPI, HTTPException, status from schemas import ConversationCreate, ConversationOut, ConversationUpdate from sqlalchemy import select  ...  async def get_conversation(     conversation_id: int, session: DBSessionDep ![1](img/1.png) ) -> Conversation:     async with session.begin(): ![2](img/2.png)         result = await session.execute(             select(Conversation).where(Conversation.id == conversation_id)         )         conversation = result.scalars().first()     if not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation not found",         )     return conversation  GetConversationDep = Annotated[Conversation, Depends(get_conversation)]  @app.get("/conversations") async def list_conversations_controller(     session: DBSessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     async with session.begin():         result = await session.execute(             select(Conversation).offset(skip).limit(take) ![3](img/3.png)         )     return [         ConversationOut.model_validate(conversation)         for conversation in result.scalars().all()     ]  @app.get("/conversations/{id}") async def get_conversation_controller(     conversation: GetConversationDep, ) -> ConversationOut:     return ConversationOut.model_validate(conversation) ![4](img/4.png)  @app.post("/conversations", status_code=status.HTTP_201_CREATED) async def create_conversation_controller(     conversation: ConversationCreate, session: DBSessionDep ) -> ConversationOut:     new_conversation = Conversation(**conversation.model_dump())     async with session.begin():         session.add(new_conversation)         await session.commit() ![5](img/5.png)         await session.refresh(new_conversation)     return ConversationOut.model_validate(new_conversation)  @app.put("/conversations/{id}", status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     updated_conversation: ConversationUpdate,     conversation: GetConversationDep,     session: DBSessionDep, ) -> ConversationOut:     for key, value in updated_conversation.model_dump().items():         setattr(conversation, key, value)     async with session.begin():         await session.commit() ![5](img/5.png)         await session.refresh(conversation)     return ConversationOut.model_validate(conversation)  @app.delete("/conversations/{id}", status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation: GetConversationDep, session: DBSessionDep ) -> None:     async with session.begin():         await session.delete(conversation)         await session.commit() ![5](img/5.png) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO6-1)      Definisce una dipendenza per verificare se il record della conversazione esiste. Solleva un 404 `HTTPException` se il record non viene trovato; altrimenti, restituisce il record recuperato. Questa dipendenza può essere riutilizzata in diversi endpoint CRUD tramite dependency injection.      ![2](img/#co_integrating_databases_into_ai_services_CO6-2)      Inizia la sessione asincrona all'interno di un gestore di contesto asincrono durante ogni richiesta.      ![3](img/#co_integrating_databases_into_ai_services_CO6-3)      Quando si elencano i record, è più efficiente recuperare solo un sottoinsieme di record. Per impostazione predefinita, SQLAlchemy ORM restituisce un sottoinsieme dei record più recenti del database, ma puoi utilizzare i metodi concatenati `.offset(skip)` e `.limit(take)` per recuperare qualsiasi sottoinsieme di record.      ![4](img/#co_integrating_databases_into_ai_services_CO6-4)      Crea un modello Pydantic da un modello SQLAlchemy utilizzando `model_validate()`. Solleva un `ValidationError` se l'oggetto SQLAlchemy passato non può essere creato o non supera i controlli di validazione dei dati di Pydantic.      ![5](img/#co_integrating_databases_into_ai_services_CO6-5)      Per le operazioni che modificano un record (ad esempio, creazione, aggiornamento e cancellazione), esegui il commit della transazione e invia il record aggiornato al client, ad eccezione dell'operazione di cancellazione che deve restituire `None`.      Nota come la logica del controllore viene semplificata grazie a questo approccio di dependency injection.    Inoltre, presta attenzione ai codici di stato di successo che devi inviare al cliente. Le operazioni di recupero riuscite dovrebbero restituire 200, mentre le operazioni di creazione dei record restituiscono 201, gli aggiornamenti 202 e le cancellazioni 204.    Congratulazioni! Ora hai un'API RESTful basata su risorse che puoi utilizzare per eseguire operazioni CRUD sulla tua tabella `conversations`.    Ora che puoi implementare gli endpoint CRUD, rifattorizziamo gli esempi di codice esistenti per utilizzare il modello di progettazione di *repository e servizi* che hai imparato nel Capitolo 2. Con questo modello di progettazione, puoi astrarre le operazioni del database per ottenere una base di codice più modulare, manutenibile e testabile.    ## Pattern di progettazione di repository e servizi    Un*repository* *è un modello di progettazione che media la logica di business della tua applicazione e il livello di accesso al database, ad esempio tramite un ORM. Contiene diversi metodi per eseguire operazioni CRUD nel livello del database.*   *Nel Capitolo 2 hai visto per la prima volta la Figura 7-4, che mostrava la posizione dei repository all'interno dell'architettura applicativa a cipolla/strato quando si lavora con un database.  ![bgai 0704](img/bgai_0704.png)  ###### Figura 7-4\. Il modello di repository all'interno dell'architettura applicativa a cipolla/strato    Per implementare un pattern di repository, puoi utilizzare un'*interfaccia astratta*, che impone alcuni vincoli su come definire le classi specifiche del repository, come puoi vedere nell'Esempio 7-7.    ###### Nota    Se non hai mai usato le classi *astratte*, si tratta di classi che non possono essere istanziate da sole. Le classi astratte possono contenere metodi non implementati che le loro sottoclassi devono implementare.    Una classe concreta è una classe che eredita una classe astratta e implementa tutti i suoi metodi astratti.    ##### Esempio 7-7\. Implementazione dell'interfaccia astratta di un repository    ``` # repositories/interfaces.py  from abc import ABC, abstractmethod from typing import Any  class Repository(ABC): ![1](img/1.png)     @abstractmethod     async def list(self) -> list[Any]:         pass      @abstractmethod     async def get(self, uid: int) -> Any:         pass      @abstractmethod     async def create(self, record: Any) -> Any:         pass      @abstractmethod     async def update(self, uid: int, record: Any) -> Any:         pass      @abstractmethod     async def delete(self, uid: int) -> None:         pass ```py    ![1](img/#co_integrating_databases_into_ai_services_CO7-1)      Definisce l'interfaccia astratta `Repository` con diverse firme di metodi astratti relativi al CRUD che le sottoclassi devono implementare. Se un metodo astratto non è implementato in una sottoclasse concreta, verrà sollevato un`NotImplementedError`.      Ora che hai una classe `Repository`, puoi dichiarare delle sottoclassi per ciascuna delle tue tabelle per definire come devono essere eseguite le operazioni sul database seguendo i metodi basati sul CRUD. Ad esempio, per eseguire le operazioni CRUD sui record di conversazione nel database, puoi implementare una classe concreta `ConversationRepository`, come mostrato nell'Esempio 7-8.    ##### Esempio 7-8\. Implementazione del repository di conversazione utilizzando l'interfaccia del repository astratto    ``` # repositories/conversations.py  from entities import Conversation from repositories.interfaces import Repository from schemas import ConversationCreate, ConversationUpdate from sqlalchemy import select from sqlalchemy.ext.asyncio import AsyncSession  class ConversationRepository(Repository): ![1](img/1.png)     def __init__(self, session: AsyncSession) -> None:         self.session = session      async def list(self, skip: int, take: int) -> list[Conversation]:         async with self.session.begin():             result = await self.session.execute(                 select(Conversation).offset(skip).limit(take)             )         return [r for r in result.scalars().all()]      async def get(self, conversation_id: int) -> Conversation | None:         async with self.session.begin():             result = await self.session.execute(                 select(Conversation).where(Conversation.id == conversation_id)             )         return result.scalars().first()      async def create(self, conversation: ConversationCreate) -> Conversation:         new_conversation = Conversation(**conversation.model_dump())         async with self.session.begin():             self.session.add(new_conversation)             await self.session.commit()             await self.session.refresh(new_conversation)         return new_conversation      async def update(         self, conversation_id: int, updated_conversation: ConversationUpdate     ) -> Conversation | None:         conversation = await self.get(conversation_id)         if not conversation:             return None         for key, value in updated_conversation.model_dump().items():             setattr(conversation, key, value)         async with self.session.begin():             await self.session.commit()             await self.session.refresh(conversation)         return conversation      async def delete(self, conversation_id: int) -> None:         conversation = await self.get(conversation_id)         if not conversation:             return         async with self.session.begin():             await self.session.delete(conversation)             await self.session.commit() ```py    ![1](img/#co_integrating_databases_into_ai_services_CO8-1)      Eredita l'interfaccia astratta `Repository` e implementa tutti i suoi metodi rispettando le firme dei metodi.      Ora hai spostato la logica del database per le conversazioni all'interno di`ConversationRepository`. Questo significa che puoi importare questa classe nelle funzioni del controller della tua rotta e iniziare a usarla subito.    Torna al file `main.py` e rifattorizza i controllori di rotta in modo che utilizzino il file`ConversationRepository`, come mostrato nell'Esempio 7-9.    ##### Esempio 7-9\. Refactoring degli endpoint CRUD delle conversazioni per utilizzare lo schema del repository    ``` # routers/conversations.py  from typing import Annotated from fastapi import APIRouter, Depends, FastAPI, HTTPException, status ...  # Other imports from repositories import ConversationRepository  ...  # Other controllers and dependency implementations  router = APIRouter(prefix="/conversations") ![1](img/1.png)  async def get_conversation(     conversation_id: int, session: SessionDep ) -> Conversation:     conversation = await ConversationRepository(session).get(conversation_id) ![2](img/2.png)     if not conversation:         raise HTTPException(             status_code=status.HTTP_404_NOT_FOUND,             detail="Conversation not found",         )     return conversation  GetConversationDep = Annotated[Conversation, Depends(get_conversation)]  @router.get("") async def list_conversations_controller(     session: SessionDep, skip: int = 0, take: int = 100 ) -> list[ConversationOut]:     conversations = await ConversationRepository(session).list(skip, take)     return [ConversationOut.model_validate(c) for c in conversations]   @router.get("/{id}") async def get_conversation_controller(     conversation: GetConversationDep, ) -> ConversationOut:     return ConversationOut.model_validate(conversation) ![2](img/2.png)   @router.post("", status_code=status.HTTP_201_CREATED) async def create_conversation_controller(     conversation: ConversationCreate, session: SessionDep ) -> ConversationOut:     new_conversation = await ConversationRepository(session).create(         conversation     ) ![2](img/2.png)     return ConversationOut.model_validate(new_conversation)   @router.put("/{id}", status_code=status.HTTP_202_ACCEPTED) async def update_conversation_controller(     conversation: GetConversationDep,     updated_conversation: ConversationUpdate,     session: SessionDep, ) -> ConversationOut:     updated_conversation = await ConversationRepository(session).update( ![2](img/2.png)         conversation.id, updated_conversation     )     return ConversationOut.model_validate(updated_conversation)   @router.delete("/{id}", status_code=status.HTTP_204_NO_CONTENT) async def delete_conversation_controller(     conversation: GetConversationDep, session: SessionDep ) -> None:     await ConversationRepository(session).delete(conversation.id)   # main.py  from routers.conversations import router as conversations_router  app.include_router(conversations_router) ![1](img/1.png) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO9-1)      Posiziona le rotte CRUD di conversazione su un router API separato e includile nell'applicazione FastAPI per un design API modulare.      ![2](img/#co_integrating_databases_into_ai_services_CO9-2)      Refactoring delle rotte CRUD di conversazione per utilizzare lo schema del repository per rendere più leggibile l'implementazione del controller.      Hai notato come i tuoi route controller appaiono più puliti ora che la logica del database è stata astratta all'interno della classe `ConversationRepository`?    Un pattern di *servizio* è un'estensione del pattern di repository che incapsula la logica di business e le operazioni in un livello superiore. Queste operazioni di livello superiore spesso richiedono query più complesse e una sequenza di operazioni CRUD da eseguire per implementare la logica di business.    Ad esempio, puoi implementare un `ConversationService` per recuperare i messaggi relativi a una conversazione o a un utente specifico (vedi Esempio 7-10). Poiché estende un`ConversationRepository`, puoi comunque accedere ai metodi CRUD di accesso ai dati di livello inferiore come `list`, `get`, `create`, `update` e`delete`.    Ancora una volta puoi tornare ai tuoi controllori e sostituire i riferimenti al sito con i riferimenti al sito .`ConversationRepository` con quello di`ConversationService`. Inoltre, puoi utilizzare lo stesso servizio per aggiungere un nuovo endpoint per recuperare i messaggi all'interno di una singolaconversazione.    ##### Esempio 7-10\. Implementazione del pattern dei servizi di conversazione    ``` # services/conversations.py  from entities import Message from repositories.conversations import ConversationRepository from sqlalchemy import select  class ConversationService(ConversationRepository):     async def list_messages(self, conversation_id: int) -> list[Message]:         result = await self.session.execute(             select(Message).where(Message.conversation_id == conversation_id)         )         return [m for m in result.scalars().all()]  # routers/conversations.py  from database import DBSessionDep from entities import Message from fastapi import APIRouter from schemas import MessageOut from services.conversations import ConversationService  router = APIRouter(prefix="/conversations")  @router.get("/{conversation_id}/messages") ![1](img/1.png) async def list_conversation_messages_controller(     conversation: GetConversationDep,     session: DBSessionDep, ) -> list[Message]:     messages = await ConversationService(session).list_messages(conversation.id)     return [MessageOut.model_validate(m) for m in messages] ```py    ![1](img/#co_integrating_databases_into_ai_services_CO10-1)      Aggiungi un nuovo endpoint per elencare i messaggi di una conversazione utilizzando l'ID della conversazione.      Ora hai un'API RESTful perfettamente funzionante per interagire con i dati delle tue conversazioni seguendo i modelli di repository e di servizio.    ###### Suggerimento    Ora che hai una maggiore familiarità con il modello di repository e servizi, puoi provare a implementare gli endpoint CRUD per la tabella `messages`.    Quando utilizzi i modelli di repository e di servizio, fai attenzione a non accoppiare strettamente i tuoi servizi a specifiche implementazioni del repository e a non sovraccaricare i tuoi servizi con molte responsabilità. Mantieni i repository focalizzati sull'accesso e la manipolazione dei dati ed evita di inserire la logica di business.    Dovrai anche gestire correttamente le transazioni e le eccezioni del database, soprattutto quando si eseguono più operazioni correlate. Inoltre, considera le implicazioni sulle prestazioni delle tue query, come ad esempio l'inclusione di molte JOIN, e ottimizza le query dove è possibile.    È buona norma utilizzare convenzioni di denominazione coerenti per i metodi e le classi ed evitare di codificare le impostazioni di configurazione.    C'è un altro aspetto del flusso di lavoro dello sviluppo dei database che dobbiamo affrontare: la gestione di schemi di database in continua evoluzione, in particolare nei team collaborativi in cui più persone lavorano sullo stesso database sia in ambienti di sviluppo che di produzione.*````  ```py```*# Gestione delle modifiche agli schemi di database    Avrai notato che nell'Esempio 7-3 stai cancellando e ricreando le tabelle del database ogni volta che avvii il server FastAPI. Questo è accettabile per i flussi di lavoro di sviluppo durante la fase di prototipazione, ma non lo è affatto quando devi distribuire i tuoi servizi in produzione con utenti attivi. Non puoi resettare il database da zero ogni volta che aggiorni lo schema del database.    Inoltre, probabilmente avrai bisogno di un modo per ripristinare le modifiche se qualcosa si rompe o se decidi di fare un rollback di alcune funzionalità. Per ottenere questo risultato, puoi utilizzare uno strumento di migrazione del database come Alembic, progettato per funzionare perfettamente con l'ORM SQLAlchemy.    Alembic ti permette di controllare la versione degli schemi del tuo database nello stesso modo in cui strumenti come Git ti aiutano a controllare la versione del tuo codice. Sono estremamente utili quando lavori in un team con più ambienti applicativi e hai bisogno di tenere traccia delle modifiche o di ripristinare gli aggiornamenti se necessario.    Per iniziare, devi prima installare `alembic` tramite `pip` e poi inizializzarlo eseguendo l'Esempio 7-11 nella root del tuo progetto FastAPI.    ##### Esempio 7-11\. Inizializzazione di un ambiente Alembic    ``` $ alembic init ```py    Alembic creerà il suo ambiente all'interno della cartella `alembic` con diversi file e una cartella `versions`, come mostrato nell'Esempio 7-12.    ##### Esempio 7-12\. Ambiente Alembic nella directory principale del progetto    ``` project/     alembic.ini     alembic/         env.py ![1](img/1.png) README         script.py.mako         versions/ ![2](img/2.png) <migration .py files will appear here> ```py    ![1](img/#co_integrating_databases_into_ai_services_CO11-1)      Un file di ambiente per specificare lo schema di destinazione e le connessioni al database      ![2](img/#co_integrating_databases_into_ai_services_CO11-2)      Una directory per contenere i file *di migrazione*, che specificano le istruzioni su come aggiornare o ripristinare lo schema del database.      Una volta generato l'ambiente Alembic, apri e modifica il file *env.py* che si trova nella directory `alembic`, come mostrato nell'Esempio 7-13, in modo da ottenere l'accesso all'oggetto metadati SQLAlchemy che contiene le informazioni sullo schema di destinazione.    ##### Esempio 7-13\. Collegare l'ambiente Alembic con i modelli SQLAlchemy    ``` # alembic/env.py  from entities import Base from settings import AppSettings  settings = AppSettings() target_metadata = Base db_url = str(settings.pg_dsn)  ... ```py    Con Alembic collegato ai tuoi modelli SQLAlchemy, Alembic può ora generare automaticamente i file di migrazione confrontando lo schema attuale del tuo database con i tuoi modelli SQLAlchemy:    ``` $ alembic revision --autogenerate -m "Initial Migration" ```py   ```` Questo comando confronta i modelli SQLAlchemy definiti con lo schema del database esistente e genera automaticamente un file di migrazione SQL nella directory`alembic/versions` nella directory    Se apri il file di migrazione generato, dovresti vedere un contenuto del file simile all'Esempio 7-14.    ##### Esempio 7-14\. La migrazione iniziale di Alembic    ```py # alembic/versions/24c35f32b152.py  from datetime import UTC, datetime import sqlalchemy as sa from alembic import op  """ Revision ID: 2413cf32b712 Revises: Create Date: 2024-07-11 12:30:17.089406 """  # revision identifiers, used by Alembic. revision = "24c35f32b152" down_revision = None branch_labels = None  def upgrade():     op.create_table(         "conversations",         sa.Column("id", sa.BigInteger, primary_key=True),         sa.Column("title", sa.String, nullable=False),         sa.Column("model_type", sa.String, index=True, nullable=False),         sa.Column(             "created_at", sa.DateTime, default=datetime.now(UTC), nullable=False         ),         sa.Column(             "updated_at",             sa.DateTime,             default=datetime.now(UTC),             onupdate=datetime.now(UTC),             nullable=False,         ),     )      op.create_table(         "messages",         sa.Column("id", sa.BigInteger, primary_key=True),         sa.Column(             "conversation_id",             sa.BigInteger,             sa.ForeignKey("conversations.id", ondelete="CASCADE"),             index=True,             nullable=False,         ),         sa.Column("prompt_content", sa.Text, nullable=False),         sa.Column("response_content", sa.Text, nullable=False),         sa.Column("prompt_tokens", sa.Integer, nullable=True),         sa.Column("response_tokens", sa.Integer, nullable=True),         sa.Column("total_tokens", sa.Integer, nullable=True),         sa.Column("is_success", sa.Boolean, nullable=True),         sa.Column("status_code", sa.Integer, nullable=True),         sa.Column(             "created_at", sa.DateTime, default=datetime.now(UTC), nullable=False         ),         sa.Column(             "updated_at",             sa.DateTime,             default=datetime.now(UTC),             onupdate=datetime.now(UTC),             nullable=False,         ),     )  def downgrade():     op.drop_table("messages")     op.drop_table("conversations") ```    Ora che hai aggiornato il tuo primo file di migrazione, sei pronto per eseguirlo sul database:    ```py $ alembic upgrade head ```   ``Se hai bisogno di ripristinare l'operazione, puoi eseguire `alembic downgrade`.    Alembic genera l'SQL grezzo necessario per eseguire o ripristinare una migrazione e crea una tabella`alembic_versions` nel database. Utilizza questa tabella per tenere traccia delle migrazioni già applicate al database, in modo che eseguendo nuovamente il comando `alembic upgrade head` non vengano eseguite migrazioni duplicate.    Se in ogni caso gli schemi del database e la cronologia della migrazione si allontanano, puoi sempre rimuovere i file dalla directory `versions` e troncare la tabella`alembic_revision`. Poi reinizializza Alembic per iniziare con un ambiente nuovo e un database esistente.    ###### Avvertenze    Dopo aver migrato un database con un file di migrazione, assicurati di eseguire il commit in un repository Git. Evita di modificare nuovamente i file di migrazione dopo aver migrato un database, poiché Alembic salterà le migrazioni esistenti effettuando un controllo incrociato con la sua tabella di versioning.    Se un file di migrazione è già stato eseguito, non rileverà le modifiche al suo contenuto.    Per aggiornare lo schema del database, crea invece un nuovo file di migrazione.    Seguendo il flusso di lavoro sopra descritto, non solo potrai controllare la versione degli schemi del tuo database, ma potrai anche gestire le modifiche agli ambienti di produzione in base ai cambiamenti dei requisiti dell'applicazione.`` ```py`  ````` ```py`# Memorizzare i dati quando si lavora con gli stream in tempo reale    Ora dovresti essere in grado di implementare i tuoi endpoint CRUD per recuperare e modificare i record delle conversazioni e dei messaggi degli utenti nel tuo database.    Una domanda che rimane senza risposta è come gestire le transazioni all'interno degli endpoint di streaming dei dati, come ad esempio un LLM che trasmette gli output a un client.    Non puoi inviare i dati in streaming a un database relazionale tradizionale, perché garantire la conformità ACID con le transazioni in streaming sarà un'impresa ardua. Al contrario, vorrai eseguire le operazioni standard sul database non appena il server FastAPI restituisce una risposta al client. Questa sfida è esattamente ciò che un'attività in background di FastAPI può risolvere, come puoi vedere nell'Esempio 7-15.    ##### Esempio 7-15\. Memorizzazione del contenuto di un flusso di output LLM    ``` # main.py  from itertools import tee from database import DBSessionDep from entities import Message from fastapi import BackgroundTasks, Depends from fastapi.responses import StreamingResponse from repositories.conversations import Conversation from repositories.messages import MessageRepository from sqlalchemy.ext.asyncio import AsyncSession  async def store_message( ![1](img/1.png)     prompt_content: str,     response_content: str,     conversation_id: int,     session: AsyncSession, ) -> None:     message = Message(         conversation_id=conversation_id,         prompt_content=prompt_content,         response_content=response_content,     )     await MessageRepository(session).create(message)  @app.get("/text/generate/stream") async def stream_llm_controller(     prompt: str,     background_task: BackgroundTasks,     session: DBSessionDep,     conversation: Conversation = Depends(get_conversation), ![2](img/2.png) ) -> StreamingResponse:     # Invoke LLM and obtain the response stream     ...     stream_1, stream_2 = tee(response_stream) ![3](img/3.png)     background_task.add_task(         store_message, prompt, "".join(stream_1), conversation.id, session     ) ![4](img/4.png)     return StreamingResponse(stream_2) ```py    ![1](img/#co_integrating_databases_into_ai_services_CO12-1)      Crea una funzione per memorizzare un messaggio rispetto a una conversazione.      ![2](img/#co_integrating_databases_into_ai_services_CO12-2)      Controlla che il record della conversazione esista e lo recupera all'interno di una dipendenza.      ![3](img/#co_integrating_databases_into_ai_services_CO12-3)      Crea due copie separate del flusso LLM, una per il sito `StreamingResponse` e un'altra da elaborare in un'attività in background.      ![4](img/#co_integrating_databases_into_ai_services_CO12-4)      Crea un'attività in background per memorizzare il messaggio al termine di `StreamingResponse`.      Nell'Esempio 7-15, permetti a FastAPI di trasmettere completamente la risposta LLM al client.    Non importa se stai utilizzando un endpoint SSE o WebSocket. Una volta che la richiesta e la risposta sono state inviate in streaming, richiama un'attività in background passando il contenuto completo della risposta in streaming. All'interno dell'attività in background, puoi eseguire una funzione per memorizzare il messaggio dopo l'invio della richiesta, con il contenuto completo della risposta LLM.    Utilizzando lo stesso approccio, puoi anche generare un titolo per una conversazione in base al contenuto del primo messaggio. A tal fine, puoi invocare nuovamente il LLM con il contenuto del primo messaggio della conversazione, richiedendo un titolo appropriato per la conversazione. Una volta generato il titolo della conversazione, puoi creare il record della conversazione nel database, come mostrato nell'Esempio 7-16.    ##### Esempio 7-16\. Utilizzo del LLM per generare titoli di conversazione basati sul prompt iniziale dell'utente    ``` from entities import Conversation from openai import AsyncClient from repositories.conversations import ConversationRepository from sqlalchemy.ext.asyncio import AsyncSession  async_client = AsyncClient(...)  async def create_conversation(     initial_prompt: str, session: AsyncSession ) -> Conversation:     completion = await async_client.chat.completions.create(         messages=[             {                 "role": "system",                 "content": "Suggest a title for the conversation "                            "based on the user prompt",             },             {                 "role": "user",                 "content": initial_prompt,             },         ],         model="gpt-
