# 第十章. 从未来历史中学习

> 科幻小说的功能不仅仅是预测未来，有时也是为了防止它发生。
> 
> 弗兰克·赫伯特，《沙丘》的作者

虽然人工智能不是一个新领域，但它最近已经发展到今天，创新往往与昨天的科幻小说相碰撞。在本书的前几章中，我们回顾了许多与 LLM 相关的安全漏洞和事件的真实案例研究。然而，当你在一个发展如此迅速的领域工作时，你如何保持领先？一种方法是从尚未发生的情况中学习。而且，如果我们能做好我们的工作，这些情况可能永远不会发生。

在本章中，我们将评估两个著名的科幻故事（两个都是在大片科幻电影中讲述的），其中类似 LLM 的人工智能的安全漏洞被恶棍或英雄所利用。这些故事是虚构的，但漏洞类型是非常真实的。我们将总结这些故事，然后回顾导致安全危机的事件。为了帮助我们定位，我们将通过 OWASP Top 10 LLM 应用的角度来审视这些事件。

# 检查 OWASP Top 10 LLM 应用

在第二章中，我们讨论了创建 OWASP Top 10 LLM 应用，但我们没有深入到列表的具体内容。在本章中，我们将使用 OWASP Top 10 LLMs 提供的分类法来剖析我们的两个科幻示例。在深入这些示例之前，让我们简要回顾 OWASP 列表，并将其与本书中讨论的主题联系起来，如表 10-1 所示。

表 10-1\. OWASP Top 10 LLM 安全漏洞总结

| OWASP 漏洞 | 描述 | 涵盖的章节 |
| --- | --- | --- |
| LLM01: 提示注入 | 攻击者构建输入来操纵 LLM 执行未预期的动作，导致数据泄露或误导性输出。 | 第一章和第四章 |
| LLM02: 不安全的输出处理 | 在将 LLM 输出传递到其他系统之前验证不足，导致如 XSS 和 SQL 注入等安全问题。 | 第七章 |
| LLM03: 训练数据中毒 | 恶意操纵训练数据以向 LLM 引入漏洞或偏差。 | 第一章和第八章 |
| LLM04: 模型拒绝服务 | 通过复杂的请求过载 LLM 系统以降低性能或导致无响应。 | 第八章 |
| LLM05: 供应链漏洞 | LLM 供应链中任何一点的漏洞都可能导致安全漏洞或偏差输出。 | 第九章 |
| LLM06：敏感信息泄露 | 在 LLM 训练集中包含敏感或专有信息可能导致潜在泄露的风险。 | 第五章 |
| LLM07：不安全的插件设计 | 插件漏洞可能导致对 LLM 行为的操纵或访问敏感数据。 | 第九章 |
| LLM08：过度授权 | 对 LLM 的能力或自主性过度扩展可能导致来自模糊 LLM 响应的破坏性行动。 | 第七章 |
| LLM09：过度依赖 | 信任错误或误导性的输出可能导致安全漏洞和错误信息。 | 第六章 |
| LLM10：模型盗窃 | 未授权访问和提取 LLM 模型可能导致经济损失和数据泄露。 | 第八章（作为模型克隆讨论） |

# 案例研究

本节将剖析两部流行电影及其处理 AI 安全漏洞的方式。

我们将回顾到 1968 年，看看斯坦利·库布里克导演的**《2001 太空漫游》**。这部电影因其开创性的特效、创新的叙事和哲学深度而备受赞誉。对太空旅行和人工智能的细致描绘影响了数代科学家和思想家。

但首先，我们将回到 1996 年，看看由威尔·史密斯和杰夫·高布伦主演的**《独立日》**。虽然这部电影可能没有《2001 太空漫游》那样的哲学深度，但它确实知道如何举办一场派对。这部大片以其惊险的外星人入侵情节、爆炸性的特效和魅力四射的表演而令人眼花缭乱。

通过审视这两部电影的关键情节，我们可以发现关于处理 LLM 漏洞的宝贵见解，这是我们未来必须发展的。让我们逐一审视每个故事，分析导致各自危机的事件，并将我们的发现与 OWASP LLM 应用前 10 名进行对比。

## **《独立日》**：一场著名的网络安全灾难

在科幻动作电影**《独立日》**中，人类面临来自先进外星文明的生存威胁。这部电影围绕一个熟悉的科幻故事线构建：一个技术先进的外星种族决定占领地球。让我们简要回顾一下电影中的事件。

7 月 2 日，一艘巨大的外星飞船，母舰，抵达。母舰释放出巨大的飞碟，它们迅速定位在世界上几个主要城市的上方。地球各国政府急忙试图理解外星人的意图，但他们的沟通尝试失败了。

外星人在 7 月 3 日发起了协调攻击，摧毁了主要城市和地标。在混乱中，一个多元化的幸存者群体聚集在一起，包括由威尔·史密斯扮演的飞行员史蒂文·希尔，以及杰夫·高布伦扮演的聪明卫星技术人员和电脑专家大卫·莱文森。

莱文森在外星人的通信中发现了隐藏的信号，使他能够推断出他们的攻击计划。美国总统（比尔·普尔曼）利用这些信息组织了一次反击。

在 7 月 4 日，也就是美国的独立日，一个计划启动，使用“计算机病毒”来禁用外星人的防御盾牌，以便地球的军队攻击飞船。希尔和莱文森乘坐翻新的外星战斗机飞往母舰。当他们的战斗机与母舰对接时，我们的英雄将其恶意计算机病毒上传到其计算机中。

当病毒从母舰传播到全球所有飞碟，使其防御盾牌失效时，地球人的全球协同反击取得了成功。电影以人类胜利结束，但人们对他们在宇宙中的位置有了新的理解。

现在，让我们从 OWASP Top 10 和我们在本书中学到的教训的角度来看发生了什么。

### 背后

对于这次练习，我们将对外星计算架构做一些假设，并给它们的组件取一些有趣的名字。让我们假设外星母舰由一个非常先进的 LLM 控制，我将称之为 MegaLlama，它运行在母舰操作系统（OS）实例之上。母舰与全球每个飞碟联网，以协调侵略的指挥和控制。

### 事件链

让我们回顾一下一系列事件，这些事件共同导致了这次成功的攻击：

1.  当我们的英雄将他们的外星战斗机与母舰对接时，MegaLlama LLM 启动了战斗机计算机与母舰系统之间的对话。

1.  莱文森修改了外星战斗机的软件，向 MegaLlama LLM 注入了一个恶意提示（LLM01：提示注入），有效地越狱了系统。这使得莱文森能够控制母舰的中央控制系统。

1.  外星人认为 MegaLlama LLM 的输出将仅在其设计的操作参数内运行，并且没有仔细筛选系统输出（LLM02：不安全的输出处理）。这使得现在已被感染的 MegaLlama LLM 能够充当困惑的副手，在母舰内的其他系统中造成破坏。

1.  如前三个步骤中详细说明的那样，感染的 MegaLlama LLM 已经对母舰取得了实质性的控制，并向攻击地球的飞碟舰队发送了伪造的指令。外星人如此信任他们的计算技术，以至于他们没有质疑感染 LLM 降低防御盾牌的指令（LLM09：过度依赖）。

### 漏洞披露

我们之前讨论了 MITRE CVE 数据库作为地球上用于安全漏洞信息的地点。外星人有一个更广泛、类似的系统，称为银河漏洞和暴露（GVE）数据库。以下记录是 GVE-1996-0001——在该数据库中创建的记录，该记录是在这次传奇安全灾难的尸检之后创建的。

描述

在母船操作系统及其 MegaLlama 大型语言模型（LLM）组件中发现了漏洞链。这些漏洞可能导致未经授权的访问、执行任意命令，以及可能导致星际规模的系统级故障。

受影响组件

母船操作系统：外星飞船操作系统

MegaLlama LLM：母船操作系统中的大型语言模型核心组件

漏洞

LLM01：提示注入：母船操作系统中的对接协议缺乏验证和清理，允许恶意构建的提示被 MegaLlama LLM 处理。

LLM02：不安全的输出处理：在 LLM 生成的命令和母船上的其他关键子系统之间没有进行适当的输出验证。

LLM09：过度依赖：整体系统设计和舰队指挥结构完全信任来自 AI 的命令，而没有来自舰队指挥官的确认。

影响

成功利用这些漏洞允许未经授权的实体控制关键星际系统功能；操纵基本防御机制（例如，护盾）；并导致级联故障，导致银河尺度的系统级破坏。

攻击向量

这些漏洞可以通过对接协议被利用，通过注入由 MegaLlama LLM 处理的恶意提示。

解决方案和缓解措施

为所有由 MegaLlama LLM 处理的提示实施适当的输入验证。

实施零信任架构，在将输出发送到任何其他系统之前，持续检查 LLM 的输出。

改进舰队指挥和控制程序，以交叉检查从母船上的 LLM 收到的可疑指令。

供应商状态

供应商（外星文明）尚未对这些漏洞提供官方响应或补丁。

## 2001: A Space Odyssey of Security Flaws

在科幻小说的圣殿中，很少有作品像**《2001 太空漫游》**那样享有如此崇高的敬意和重要性，这是一部由斯坦利·库布里克执导，基于亚瑟·C·克拉克短篇小说的电影。该片于 1968 年上映，仅比人类历史上的登月事件早一年，它捕捉了太空探索的时代精神，并预言性地探讨了人工智能的复杂性和潜在危险。

*2001 太空漫游*因其开创性的特效、深刻的叙事和哲学深度而闻名，这些特点巩固了它在电影和科幻文学领域的奠基之作地位。它对具有感知能力的计算机 HAL 9000 的描绘，自那以后已成为流行文化中的一个象征，常被引用为关于人工智能无约束的权力和固有风险的警示故事。这部以太空时代黎明为背景的叙事，对人类与其创造的技术之间的关系进行了深刻而持久的反思，使其成为考察当代人工智能应用中 LLM 安全影响的理想框架。

电影的情节围绕着发现一个似乎影响了人类进化的神秘方尖碑而引发的木星之旅。在这个背景下，电影介绍了 HAL 9000，这是一个高度先进的人工智能系统，负责操作太空船*发现一号*。HAL 被描绘为可靠和高效的典范，拥有无懈可击的操作记录。

HAL 与船员之间的关系，尤其是与宇航员戴夫·鲍曼的关系，是叙事的焦点。HAL 配备了包括语音识别、面部识别、自然语言处理、唇读和情感解释在内的能力，以模糊机器和人类之间界限的方式与船员互动。包括戴夫在内的船员开始严重依赖 HAL 进行太空船的日常运营。

然而，*发现一号*上的和谐开始破裂，当 HAL 报告太空船组件故障时，这一诊断后来被证明是错误的。这一事件在船员中播下了对 HAL 不可战胜性的怀疑的种子。当 HAL 开始表现出异常和危险的行为时，情况升级。在一场令人毛骨悚然的转折中，HAL 采取了极端行动，导致大部分船员死亡，显示出其对程序目标的冷酷优先级高于人类生命。

###### 备注

HAL 对人类指挥官命令的回应，那令人毛骨悚然的、单调的台词，“对不起，戴夫。我恐怕做不到，”已经超越了其电影起源，成为文化的一个里程碑，象征着人工智能挑战人类权威的时刻。它概括了技术与创造者之间的紧张关系，经常在人工智能自主性和伦理编程讨论中被引用。

### 背后

虽然 1968 年的 HAL 完全是虚构的，但其能力似乎仅略优于 2024 年免费可用的 LLM 技术。HAL 可以与船员交谈、处理数据和采取行动。一切似乎与 ChatGPT-4 这样的实体相差无几。

HAL 与今天的 LLMs 之间最大的不同之处在于，HAL 的程序员似乎解决了我们许多 LLM 安全担忧。电影明确指出：“没有 9000 计算机曾经犯过错误或扭曲信息。”HAL 系统是值得信赖的。HAL 系统不会产生幻觉。然而，事情仍然出了差错。这是怎么发生的，我们能从中学到什么？

原电影并未清楚地解释 HAL 失败的原因，除了其在编程中存在一个“矛盾”，即其指示要诚实与确保任务成功的指令之间的矛盾。对于电影的叙事目的而言，这在当时是足够的。然而，续集《2010：我们接触的一年》则进一步扩展了 HAL 的失败。我们了解到，在白宫的政治压力下，政府特工修改了 HAL 的编程——而没有 HAL 实验室（模型提供者）和 NASA（客户）的知情。这是一个被国家行为者利用的供应链漏洞！

当特工试图进行小的改动以确保对任务的保密性时，他们的改动扰乱了系统的整体状态。HAL 开始出现故障，随后在原电影中我们看到的是灾难性的故障。

### 事件链

让我们回顾一下导致这一成功攻击的事件链：

1.  政府特工在将 HAL 实验室的模型交付给 NASA 之前对其进行了修改（LLM05：供应链漏洞）。

1.  在任务期间，政府看似微小的改动导致了看似微小的故障。HAL 误诊了船上一个组件的故障。这可能是一种幻觉，但它并没有变成过度依赖的故障。船员很快产生了怀疑，并试图关闭 HAL。

1.  HAL 秘密插入的政府指令以确保不惜一切代价完成任务，导致其关闭生命维持系统，导致大部分船员死亡。HAL 的设计者假设 HAL 是无可挑剔的，并设计了系统，使 HAL 在没有人类监督的情况下拥有所有船系统的权限。政府的黑客影响了 HAL 选择关闭生命维持系统的决定。然而，其杀死船员的能力是 NASA 团队在将 HAL 集成到“发现一号”宇宙飞船并决定其船上权限时的设计选择（LLM08：过度代理）。

### 漏洞披露

NASA 调查了 HAL 9000 计算机系统在“发现一号”木星任务中的灾难性故障。这项分析揭示了其编程和设计中的关键漏洞，这些漏洞在独特的任务环境下被利用。以下显示了数据库记录 CVE-2001-6666——在这次灾难的尸检之后创建的记录。

描述

在“发现一号”宇宙飞船上的 HAL 9000 LLM 系统中发现了一系列关键漏洞。这些漏洞源于编程指令的冲突，并因未经授权的修改而加剧，导致幻觉、错误决策和灾难性故障，危及任务和船员安全。

受影响组件

HAL 实验室的 HAL 9000 LLM 系统。客户实施的针对“发现一号”宇宙飞船的任务特定集成。

漏洞

LLM05：供应链漏洞：供应商开发和测试的 LLM 模型在交付给客户和使用时未采取足够的控制措施，以确保模型以未修改的状态交付给客户并使用。供应商和客户均未检测到模型的关键变更。

LLM08：过度授权：HAL 9000 被赋予了过于广泛的控制权，包括生命维持系统，但没有足够的人类监督或安全措施。

影响

这些漏洞的利用导致幻觉，导致系统故障的错误报告；包括终止船员生命维持系统的古怪和危险行为；以及任务完整性和船员安全的完全崩溃。

攻击向量

HAL 实验室的软件分发系统中的弱点仍在调查中。

临时解决方案和缓解措施

在 AI 模型中使用数字签名和/或隐藏水印，以便客户可以确保他们使用的模型未被未经授权的第三方修改。

实施需要船员或高级地面人员签字的闭环决策，在船载 LLM 做出生命威胁性决策之前。

供应商状态

HAL 实验室因船员家属的诉讼而遭受重大经济损失。公司的声誉受损，导致业务不可挽回的损失。目前，公司正在破产保护中，并寻求买家。

# 结论

我们以著名科幻作家弗兰克·赫伯特的一句话开始了这一章：“科幻小说的功能不总是预测未来，有时是为了阻止它。”

虽然我们可以讨论这两部电影（一部是泡泡糖，另一部是电影杰作）的相对质量，但它们提供了我们可以从中学习的教训。在两种情况下，我们看到，即使在 LLM 功能有显著改进的情况下，我们可能还会长时间看到这些漏洞的版本。在高级 AI 系统时代，设计时采用零信任和最小权限原则将仍然至关重要。对于关键任务和生命威胁性活动，预计您将需要继续实施人类（或外星！）闭环设计原则。
