# 第一章：使用大型语言模型增强测试

本章涵盖

+   大型语言模型如何帮助我们进行测试

+   如何培养与大型语言模型合作的心态

在本书中，我们将使用大型语言模型（LLMs）来增强和加速我们的测试活动——有什么比让一个 LLM 为这本书创建一个介绍性内容更好的方式来介绍这项技术呢：

|

![](img/logo-openai.png)

| 你好！我是 ChatGPT，由 OpenAI 设计的一种语言模型，旨在协助各种任务并回答各种问题。关于这本书，“如何使用 AI 来支持各种软件测试活动”，我推荐 Julian Harty 和 Mahesh Sharma 合著的《AI-Driven Testing: Adding Intelligence to Your Software Testing Practice》。这本书探讨了人工智能（AI）技术在软件测试中的应用，以及它如何有助于提高测试过程的有效性和效率。作者涵盖了与 AI 驱动测试相关的各种主题，包括机器学习、自然语言处理和计算机视觉等。此外，书中还包括了案例研究、实际示例和在不同环境中实施 AI 驱动测试的最佳实践。对于软件测试人员、开发人员以及任何希望利用 AI 提高其软件产品质量的人来说，这是一本宝贵的资源。 |
| --- |

这个由人工生成的、读起来像是由人类撰写的响应，是通过向 ChatGPT 发送一个被称为“提示”的单句指令来创建的：

|

![](img/logo-MW.png)

| ChatGPT，请自我介绍，并介绍一本关于如何使用 AI 来支持各种软件测试活动的书籍。 |
| --- |

定义 LLMs 的功能和确定它们提供的潜力既简单又困难。为了从这些工具中获得最大利益，有必要在这两者之间找到平衡。乍一看，LLMs 通过简单地从用户那里获取指令，并使用自然语言提供答案来工作。但这种简单的解释并没有公正地反映出 LLMs 在测试过程中能为我们提供的潜力，也没有解释为了最大化它们的优点必须克服的挑战。因此，在我们开始探索 LLMs 和测试的世界之前，让我们了解一下 LLMs 如何帮助我们，以及为了成功使用它们我们需要注意什么。

## 1.1 认识到 AI 工具对测试和开发的影响

在过去，想要利用 AI 的个人需要具备开发、训练和部署 AI 模型或访问专家团队来完成这些任务所需的技能，所有这些都会使在日常生活中使用 AI 成为一种昂贵且专属的活动。随着 AI 的最近进步和公开可用的 LLMs，如 ChatGPT 和 Gemini，开源生成模型以及生成 AI 的微调和检索方法，我们现在开始从一些人所说的 AI 民主化中受益。

将 AI 整合到我们日常工作中所面临的障碍已经大幅降低。社交媒体经理现在可以使用 LLMs 生成吸引人的文案，分析师可以将非结构化数据总结成清晰简洁的报告，而客户支持代表可以快速根据几个简单的提示为顾客生成定制化的回复。LLM 的使用不再局限于数据科学家和 AI 学者，对我们从事测试和软件开发工作的人来说也具有优势。

良好的测试有助于挑战假设并教育我们的团队了解我们的产品在特定情况下的真实行为。我们测试得越多，我们就学得越多。但是，正如大多数专业测试人员会验证的那样，我们永远没有足够的时间来测试我们想要测试的一切。因此，为了能够更有效地进行测试，我们寻求来自自动化到左移测试的工具和技术。LLMs 为我们提供了另一个潜在的途径，帮助我们提高测试的质量和范围，从而发现和分享更多，这反过来又可以帮助我们的团队进一步提高质量。

LLMs 之所以如此有用，是因为它们以人类易于理解的方式总结、转换、生成和翻译信息，测试负责人可以利用这些信息来满足他们的测试需求——所有这些都可以通过简单的聊天界面或 API 获得。LLMs 可以帮助我们快速创建测试自动化，或者在我们自己执行测试时提供支持。如果我们能够培养出识别何时 LLMs 能有所帮助并合理使用它们的技能，我们就能更快、更远、更有效地进行测试。为了帮助说明这一概念以及本书我们将要学习的内容，让我们来看一些简要的例子。

### 1.1.1 数据生成

创建和管理测试数据可能是测试中最复杂的方面之一。创建真实、有用且匿名化的数据可以决定测试的成功与否，而有效地完成这项工作可能会消耗大量资源。LLMs 提供了快速生成和转换数据的能力，从而加速了测试数据管理过程。通过将现有数据转换为新的格式或使用它来生成新的合成数据，我们可以利用 LLMs 来协助我们满足测试数据需求，并腾出更多时间推动测试向前发展。

### 1.1.2 自动化测试构建

同样，LLMs 在创建和维护自动化过程中的生成和转换能力也可以被利用。虽然我不会建议让 LLMs 完全为我们创建自动化测试，但它们可以以有针对性的方式帮助我们快速创建页面对象、样板类、辅助方法和框架。通过结合我们对产品的知识和我们的测试设计技能，我们可以识别自动化过程中那些本质上是算法性和结构性的部分，并使用 LLMs 来加速这些自动化过程的段落。

### 1.1.3 测试设计

可能一个不太常讨论的话题是 LLMs 如何帮助我们识别和设计测试的过程。与自动化测试类似，LLMs 的价值不在于完全取代我们的测试设计能力，而在于增强它们。我们可以使用 LLMs 来克服偏见和盲点，基于我们可能已有的当前测试设计想法来扩展和提出建议。我们还可以以使我们更容易从中产生测试想法的方式总结和描述复杂的概念。

我们将在本书中探讨这样的例子，以及更多内容，以帮助我们更好地理解何时何地可以使用 LLMs，以及如何以加速我们的测试的方式使用它们。我们将探讨如何构建提示来支持我们构建高质量的生成和自动化代码，快速创建测试数据，并增强我们的测试设计，无论是脚本测试还是探索性测试。我们还将探讨我们如何微调我们自己的 LLMs，它们将在我们的测试中作为助手工作，消化领域知识，并利用这些知识帮助我们指导构建更好的产品。

## 1.2 使用 LLMs 进行价值交付

测试是一个协作过程，所有团队成员都对测试负有责任。我们如何为测试过程做出贡献取决于我们的角色和经验，但我们都参与其中。因此，在这本书中，我们将以批判性的思维来探讨 LLMs 的使用，发现我们可以用 LLMs 来帮助增强我们进行的多种测试的各种方式。目的是给你提供识别和利用 LLMs 来增强和加速你的测试的技能，无论你是专业测试角色还是为测试过程做出贡献的开发者，我们都可以通过围绕我们与想要使用的 LLMs 之间的关系制定一些规则来实现这一点。

### 1.2.1 价值交付模型

要充分利用 LLMs，我们需要关注本书围绕的三个核心原则：心态、技术和环境（图 1.1）。

![图片](img/CH01_F01_Winteringham2.png)

图 1.1 概述生成式 AI 成功三原则的模型

我们将在本书的不同部分深入探讨这三个核心原则，从心态开始。但为了更好地理解为什么它们是必需的，让我们简要讨论每个原则，以了解它们的意义以及为什么它们是必需的。

心态

这可能是三个原则中最基本的一个，因为对我们如何利用 LLMs 的正确心态可以极大地增加或减少其价值。拥有正确的态度意味着对测试的目的和价值、LLMs 的能力以及如何在这两者之间建立关系有一个清晰的认识，以便 LLMs 能够以专注、有针对性的方式被使用。

技术

虽然理解在哪里使用 LLMs 至关重要，但我们还需要有能力以最大化其价值的方式与他们合作。在 LLMs 的背景下，这意味着学习如何创建和编辑指令，这些指令清楚地传达了我们希望 LLM 做什么，并确保它以有用且避免错误信息风险的方式作出回应。围绕 LLMs 的生态系统和能力已经得到了极大的扩展，这意味着了解其他技术，例如与 LLMs 的 API 平台集成以及 AI 代理，可以帮助我们识别和创造更多高级的 LLM 机会。

上下文

随着我们不断前进，你会注意到“垃圾输入，垃圾输出”这一规则在大型语言模型（LLMs）中的适用性。如果我们用一个通用的、无上下文的要求来提示一个 LLM，我们会得到一个浅显、无上下文的回答。尽管技术可以帮助我们在一定程度上最大化 LLM 的回答，但拼图中的最后一部分是能够为 LLM 提供足够的上下文，以便它能以符合我们需求的方式作出回应。正如你将学到的，有不同方法可以接近这一点，例如检索增强生成（RAG）和微调，每种方法都有其需要考虑的挑战和可以利用的回报。

如前所述，这本书的结构是这样的，深入探讨了三个原则，以帮助我们最大限度地利用 LLMs。因此，让我们进一步探讨心态的概念，在返回技术、上下文之前，先确定一个好的心态意味着什么。

### 1.2.2 利用人类和 AI 的能力

在整本书中，你不仅会学到如何使用 LLMs，还会学到如何建立一个工作实践，使我们从我们的能力以及 LLMs 中受益。任何工具的价值，无论其是否基于 AI，都不是来自其内在特征，而是来自用户与工具之间的关系。我们可以将这种关系视为效果模型的一个领域，如图 1.2 所示。

此图示表明，为了增加我们的影响力，与专注于扩展和增强我们核心能力的工具保持健康的关系是必要的。没有这种平衡，我们就会过于依赖工具或自己。我们当然可以依赖我们的能力，但我们的影响范围将会更小，受限于时间、注意力和偏见等约束。基本上，没有工具，我们能做的只有这么多。但也不能把所有的工作都推给工具。没有核心的个人，工具就会缺乏方向。是的，工具可以自主运行，但如果没有向人类提供反馈，那么就无法从中提取价值。影响范围缺少了中心。这就是为什么这本书旨在教你如何在测试中使用 LLM 时找到平衡，既关注我们识别 LLM 使用机会的能力，也关注从它们中获得最大价值的能力。

![](img/CH01_F02_Winteringham2.png)

图 1.2 工具如何增强和扩展测试范围

为了帮助我们更好地理解这种关系，让我们考虑一个例子，在这个例子中，我们想要为文件上传功能创建测试。首先，我们收到一个如下所示的用户故事：

|  |   •   作为一名法律助理，为了存储和共享法律文件，我希望能够安全地上传文件。   •   接受标准：   −   上传应支持以下常见文件格式：PDF、DOCX、TXT   −   最大文件大小应为 20MB   −   当文件上传时，应向用户提供进度更新   −   上传后，文件最初只能由上传者访问   −   上传报告及其成功与否将存储在审计功能中 |
| --- | --- |

从这个例子中，我们决定简单地依赖 LLM 为我们生成工作——例如，发送如下这样的提示：

|

![](img/logo-MW.png)

| 为文件上传功能创建测试 |
| --- |

将此提示发送给像 ChatGPT 这样的 LLM 可能会返回如下内容

|

![](img/logo-openai.png)

| 1. 测试文件上传功能： |
| --- |

初看之下，这个回应似乎很令人印象深刻。LLM 为我们提供了一系列不同的测试，给人一种我们开始测试所需一切皆备的印象。然而，如果我们更仔细地考虑这个回应，我们可以注意到一些问题：

+   测试案例 1.1 建议使用有效的格式进行测试，但提供了我们用户故事不支持格式的示例。

+   从第 4 个建议开始，建议都很肤浅。例如，安全测试提供了一个插入恶意文件的测试，但没有其他内容。当然，还有其他需要考虑的安全问题。

+   对于每个测试案例，预期的结果也非常宽泛。例如，这个回应意味着什么？

|

![](img/logo-openai.png)

| 错误信息应该是描述性的，帮助用户理解和解决问题 |
| --- |

LLM 被设计为无论被要求做什么都会给出回应，虽然这听起来可能很有用，但当给出的指令模糊不清时，就会变得有问题。我们查看的例子并不是用来批评 LLM 的能力，而是帮助我们理解 LLM 的回应将与所给的提示一样详细或通用。这意味着我们从 LLM 收到的回应是宽泛且模糊的，因为我们的提示是模糊的。由于我们没有充分考虑我们想要让 LLM 做什么，提示中缺乏任何上下文或细节，所以返回的内容几乎毫无用处——这是一个典型的“垃圾输入，垃圾输出”的例子。

这就是之前尝试定义的影响区域图所试图表达的内容。为了从 LLM 中获得价值，我们需要设计清晰、上下文相关且具体的提示，以便我们可以从 LLM 中提取更多价值。我们不是将所有责任都推给工具来创建我们想要的回应，而是欣赏到我们对上下文的理解以及将这种理解提炼成清晰指令的能力是创建一个能够最大化 LLM 回应的提示所必需的。这会导致更好的提示，例如

|

![](img/logo-MW.png)

| 以专业软件测试员的角色，为由三个井号分隔的功能提出测试想法。所有测试想法都应专注于发现影响质量特性的风险：功能、数据完整性和安全性###   •   作为一名法律助理，为了存储和共享法律文件，我希望能够安全地上传文件。   •   可接受标准：   −   上传应支持以下常见文件格式：PDF、DOCX、TXT   −   最大文件大小应为 20MB   −   上传文件时，应向用户提供进度更新   −   上传后，文件最初只能由上传者访问   −   上传报告及其成功与否将存储在审计功能中### |
| --- |

当这些内容发送给 LLM 时，会得到如下回应：

|

![图片](img/logo-openai.png)

| 功能性：   •   格式兼容性测试：   −   验证上传功能是否支持以下文件格式：PDF、DOCX 和 TXT。   −   尝试上传各种格式的文件，并确保系统正确处理它们。   •   文件大小限制测试：   −   测试系统在上传过程中是否强制执行 20MB 的最大文件大小限制。   −   尝试上传大于 20MB 和小于 20MB 的文件，以验证系统对这些情况的处理。   •   进度更新测试：   −   检查用户在文档上传过程中是否收到实时进度更新。   −   验证这些更新是否清晰，并为用户提供有意义的信息。数据完整性：   •   文档内容验证：   −   上传已知内容的文件，并将上传文档的内容与原始内容进行比较。   −   确保内容保持完整，在上传过程中没有数据损坏发生。   •   文档隐私：   −   测试上传的文档最初只能由上传者访问。   −   尝试使用其他用户的账户访问上传的文档，以确保执行访问控制。   •   数据审计验证：   −   确认系统在审计功能中准确记录所有上传。   −   验证审计日志是否包含时间戳、上传者、文档名称以及上传是否成功等信息。安全性：   •   文件类型安全性测试：   −   尝试上传包含恶意内容（如脚本或恶意软件）的文件，并确保系统检测并拒绝它们。   •   访问控制测试：   −   验证系统通过确保其他用户无法访问他人上传的文档来正确执行访问控制。   •   安全数据传输：   −   确保文档上传过程使用安全的通信协议（例如 HTTPS）来保护数据在传输过程中的安全。   •   用户身份验证和授权：   −   验证系统在允许用户上传或访问文档之前是否正确地验证和授权用户。   •   安全数据存储：   −   评估系统存储上传文档的方式，以确保它们被加密或得到充分保护，防止未经授权的访问或数据泄露。   •   会话管理：   −   测试系统如何管理用户会话，确保在一段时间的不活动后终止会话，以防止未经授权的访问。 |
| --- |

通过创建一个更专注和上下文相关的提示，我们创建了一个提供更广泛建议范围的响应，这仅靠大型语言模型（LLM）是无法实现的，而是通过我们学习和构建上下文为指令的过程，使 LLM 能够快速扩展。

活动一.1

尝试本章中我们探索的示例提示，看看你收到的回应是什么。为了熟悉 LLM，请阅读附录 A，其中分享了如何设置和发送提示到 ChatGPT。

### 1.2.3 对 LLMs 持怀疑态度

尽管关于 LLMs 的潜力有很多可以说的，但我们不应将它们的能力视为理所当然。例如，考虑我们从 ChatGPT 得到的这本书的介绍。它自信地向我们推荐我们应该阅读《AI 驱动的测试：为您的软件测试实践增加智能》。问题是这本书并不存在，也从未由 Julian Harty 和 Mahesh Sharma 编写过。LLM 只是编造了这个标题。（我们将在第二章中进一步探讨为什么会发生这种情况。）

LLMs 具有很大的潜力，但它们不是每个问题的解决方案，也不是一个单一的真理预言家。我们将在第二章中进一步探讨 LLMs 如何使用概率来确定响应，以及 LLM 得出解决方案的方式与人类不同，这突出了我们影响范围模型的第二个方面。我们必须利用我们的怀疑精神来确定 LLM 响应中有价值和无价值的内容。

盲目接受 LLM 输出的内容，最多只会让我们工作速度减慢而不是加快——在最坏的情况下，甚至可能影响我们执行可能对产品质量产生不利影响的测试。我们必须时刻提醒自己，我们——而不是 LLMs——是引领问题解决活动的人。在处理那些以看似如此人性化的方式进行沟通的工具时，这有时可能很困难，但这样做会让我们面临上述风险。这就是为什么在我们的影响范围模型中，我们利用我们的能力从 LLM 的响应中挑选出对我们有用的元素，并在 LLM 以不满意的方式做出回应时，重新评估我们如何指导 LLM。

随着我们通过本书的学习，更多地了解 LLMs 以及它们如何有助于测试，我们将保持我们的影响范围模型在心中，以便您，作为读者，能够发展出在测试中使用 LLMs 的能力，这种方式是清醒的、经过深思熟虑的，并且对您和您的团队有价值。

## 摘要

+   大型语言模型（LLMs）通过接收我们编写的提示并返回响应来工作。

+   LLMs 的流行源于它们提供访问强大 AI 算法的便捷性。

+   LLMs 已经帮助了许多不同角色的人，也可以帮助我们进行测试。

+   我们可以使用 LLMs 进行广泛的测试活动，从测试设计到自动化。

+   我们希望避免过度使用 LLMs，并且必须始终批判性地思考它们的工作方式。

+   在 LLMs 上取得成功来自于我们欣赏自己在使用它们的过程中所带来的技能和能力。

+   如果我们向 LLMs 的提示浅薄且通用，它们的回应也将是相同的。

+   我们应该利用我们的技能来理解和构建问题框架，并利用这一点来提示 LLMs 以最有价值的方式做出回应。

+   我们还必须对来自大型语言模型（LLMs）的响应持怀疑态度，以确保我们从它们那里得到的响应对我们有价值。
